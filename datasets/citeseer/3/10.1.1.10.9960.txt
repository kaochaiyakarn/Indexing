online convex programming generalized nitesimal gradient ascent martin february cmu cs school computer science carnegie mellon university pittsburgh pa convex programming involves convex set convex function goal convex programming nd point minimizes introduce online convex programming 
online convex programming convex set known advance step repeated optimization problem select point seeing cost function step 
model factory production farm production industrial optimization problems unaware value items produced constructed 
introduce algorithm domain apply repeated games show really generalization nitesimal gradient ascent results imply generalized nitesimal gradient ascent giga universally consistent 
keywords multiagent learning online algorithms imagine farmer decides plant year 
certain restrictions resources land labour restrictions output allowed produce 
select crops grow knowing advance prices 
algorithm gradient descent earn knew prices advance produced amount crop year year 
example online convex programming problem 
online convex programming generalization studied experts problem 
imagine experts plan step cost 
round selects probability distribution experts 
de ned probability selects expert set probability distributions convex set 
cost function set linear convex 
algorithm general convex functions gradient descent 
algorithm applies gradient descent moves back set feasible points 
advantages algorithm 
rst gradient descent simple natural algorithm widely studying behavior intrinsic value 
secondly algorithm general experts setting handle arbitrary sequence convex functions solved 
online linear programs algorithm circumstances perform better experts algorithm 
bounds performance experts algorithms depends number experts bounds criterion may lower 
relationship discussed section comments related section 
main theorem stated proven section 
algorithm motivated study nitesimal gradient ascent algorithm repeated games 
result shows nitesimal gradient ascent universally consistent secondly shows giga nontrivial extension developed nitesimal gradient ascent games actions universally consistent 
giga de ned section proven universally consistent section 
bansal results oblivious routing domain 
online convex programming de nition set vectors convex de nition convex set function convex imagine convex function function described altitude function look valley 
de nition convex programming problem consists convex feasible set convex cost function optimal solution solution minimizes cost 
example convex programming problem farmer knows restrictions labor land begins knows demand goods advance 
suppose farmer aware demand products begins 
knows corresponding cost function convex unaware actual values 
year sold items aware pro plan year 
instance online convex programming problem 
de nition online convex programming problem consists feasible set nite sequence fc convex function 
time step online convex programming algorithm selects vector vector selected receives cost function information available decisions online algorithms reach solutions achieve certain goals 
see section 
de ne kxk 
kx remainder assumptions 
feasible set bounded 
exists 
feasible set closed 
sequences fx exists lim 
feasible set nonempty 
exists 
di erentiable 
exists 
exists algorithm produces rc 

exists algorithm produce argmin 
de ne projection argmin 
machinery describe algorithm 
algorithm greedy projection select arbitrary sequence learning rates time step receiving cost function select vector rc basic principle algorithm quite clear consider case sequence fc constant 
case algorithm operating unchanging valley 
boundary feasible set edge valley 
proceeding direction opposite gradient walk valley 
projecting back convex set edges valley 
assumption di erentiable algorithm exists algorithm produce vector 

analyzing performance algorithm measure performance algorithm comparison best algorithm hindsight knows cost functions selects xed vector 
de nition algorithm convex programming problem fc fx vectors selected cost time ca cost static feasible solution time regret algorithm time ra ca min goal prove average regret greedy projection approaches zero 
order state results bounding regret algorithm need specify parameters 
de ne kf max sup rst result derived theorem regret greedy projection algorithm rg kf lim sup rg 
rst part bound wrong side second part respond see cost function 
proof show loss generality exists 
arbitrary fc run algorithm compute fx de ne rc 
change 
behavior algorithm 
regret 
convex rc 





regret modi ed sequence functions 
de ne observe 
attempt bound regret playing action round 
kg observe expression ab potential ab immediate cost error factor 
fully ush properties 

kg 



summing get rg 

kf kf de ne dt plugging equation yields result 
regret dynamic strategy possibility ine algorithm allow small amount change 
instance imagine path ine algorithm follows limited size 
de nition path length sequence de ne set sequences vectors path length equal de nition algorithm maximum path length dynamic regret ra ra ca min ca theorem xed dynamic regret greedy projection algorithm rg kf lkf proof appendix 
lazy projection section de ne di erent algorithm performs 
algorithm lazy projection select arbitrary sequence learning rates de ne time step receiving cost function de ne rc select vector theorem constant learning rate lazy projection regret kf proof appendix 
generalized nitesimal gradient ascent section establish repeated games online linear programming problems application algorithm universally consistent 
repeated games perspective player repeated game sets actions utility function pair called joint action 
example section think matching game 
fa fy zero 
game played step player selecting action random past joint actions environment selecting action random past joint actions 
formalize 
history sequence joint actions 
set histories length de ne set nite histories history de ne jhj length history 
example history order access history de ne ith joint action 
utility history total jhj utility example total 
de ne history look replaced action player time step 
total 
done better playing action time 
de nition regret playing action total total example regret playing action 
regret playing action need positive 
instance 
de ne maximum regret just regret max 
important aspect de nition regret regret function resulting history independent strategies generated history 
introduce de nition behavior environment 
set de ne 
set probabilities distribution boolean predicate notation pr indicate probability true selected behavior 
function histories past actions distributions action player 
environment 
function history past actions distributions action environment 
de ne set nite histories hj history truncated rst rounds 
de ne 
distribution histories nite length play 
de nition behavior universally consistent exists pr hj words time high probability average regret exceeds 
observe convergence time uniform environments 
need distributions histories de ne 
de ne 
distribution histories length play 
addition operations jhj de ne 
distribution history play jhj rounds 
oblivious deterministic environments environment oblivious deterministic environment plays sequence actions regardless actions player 
type environment bridge gap results online linear programming repeated games 
formally environment 
oblivious deterministic environment exists function pr jhj formulating repeated game online linear program simplicity suppose consider case ng 
time step repeated game select distribution actions 
represented vector standard closed simplex set points 
de ne utility cost perform gradient ascent descent 
utility linear function environment action known 
algorithm generalized nitesimal gradient ascent choose sequence learning rates arbitrary vector round generally accepted de nition universally consistent appearing 
restrictive de nition originally appeared 

play play action probability 
observe action player calculate argmin 
online convex programming problem kf juj max min apply result greedy projection get result theorem expected regret giga oblivious deterministic environments 
hj self oblivious behavior important observe method constructing behavior actual behavior 
proper simulation reformulated behavior 
see history simulate constructed actions environment 
reformulated 
game 
self oblivious depends history actions environment 
de ne fh jhj de nition behavior self oblivious exists function 

self oblivious algorithms tend robust adaptive adversaries change technique past actions behavior 
giga self oblivious strategy current time step calculated constant past actions environment 
noted algorithms self oblivious 
instance kalai vempala describe algorithm self oblivious uses random seed adaptive adversary learn time settings 
lemma technique 
lemma self oblivious behavior exists deterministic oblivious environments 
hj universally consistent 
giga universally consistent 
proof appendix 
lazy projection fictitious play techniques smooth ctitious play simple version spirit ctitious play 
algorithm fictitious play choose 
time step de ne words total reward received played action entire history 
de ne argmin 
play round algorithm instance lazy projection 
converting old algorithms section order compare show na translate algorithms mixing experts algorithms online linear programs online linear programming algorithms algorithms online convex programs 
section discussion formal proofs 
formal de nitions de ning expert problem 
de nition experts problem set experts fe sequence cost vectors round expert algorithm ea rst selects distribution 
observes cost vector assume ea handle positive negative values 
easily extended shifting values positive range 
de ne online linear programming problem 
de nition online linear programming problem closed convex polytope sequence cost vectors round online linear programming algorithm rst plays distribution 
observes cost vector constructed ea described 
algorithm de ne vertices polytope online linear program 
choose fe experts vertex 
round receive distribution ea select vector expert selected 
de ne 
send ea cost vector optimal static vector vertex polytope linear program solution vertex polytope 
original ea best expert best static vector 
second observation ea bounds depend number experts 
number vertices convex polytope totally unrelated diameter normal expert bound incomparable bound greedy projection 
ea distribution uneven weighting experts 
ea may perform better scenario able tweak distribution spread evenly space way experts giving weight lonely vertices weight clustered vertices 
converting online convex programming algorithm reasons algorithm described online convex program 
rst online convex program arbitrary convex shape feasible region circle described convex hull nite number points 
second reason convex function may minimum edge feasible set 
instance fx 

minimum center feasible set 
rst issue dicult handle directly simply assume handle feasible region online convex programming problem 
handle arbitrary convex region convex region convex programming problem convex polytope 
handle second issue converting cost function linear 
theorem nd worst case cost function linear 
assumption depends properties algorithm algorithm deterministic property cost function observed rc 
form online convex programming algorithm 
algorithm exact round receive play ex 
send cost vector rc 
algorithm discrete observes gradient point assume cost function linear 
cost function linear ex ex may dicult compute explicitly calculating sample 
approximate convex region series increasingly complex convex polytopes solution undesirable 
algorithm approx select number samples taken round 
round sample independently distribution play send cost vector rc 
bound worst case di erence approx exact 
diculties doing 
rst approx randomized algorithm eventually takes derivative single point probability derivative points value derivative matter points 
secondly long term strategy adversary forces algorithm move certain directions depend random result 
try separate random element deterministic element new game 
round 
receive 

sample independently distribution 
calculate reveal adversary 
calculate reveal adversary ex 

adversary selects kg kh 

send game updates fashion exact algorithm 
de ne super regret 

min 
relate super regret regret exact approx algorithms 
second half super regret regret exact algorithm sequence linear functions 

bound 
number samples taken 

loss generality assume random variable fact prove 
kx kf kf choosing 
selecting properly prove approx 
imagine approx algorithm round adversary knew advance random selection selects cost function increases regret 
new game adversary selects rc 




adversary selects vector length direction 
kg kd 
nally 




min 
approx proper number samples approx related kalai vempala developed algorithms solve online linear programming speci type online convex programming 
attempting algorithm behave lazy fashion changing vector slowly attempting dynamic highlighted sections 
algorithms motivated algorithm applies gradient ascent repeated games 
extend algorithm games arbitrary number actions prove universal consistency 
extensive regret repeated games experts domain 
noteworthy old eld proves widely technique arti cial intelligence gradient ascent property interest game theory 
stated section experts algorithms solve online online linear programs online convex programming problems bounds may signi cantly worse 
studies online gradient descent related update functions example 
studies focus prediction problems loss functions convex bregman divergences 
considering arbitrary convex functions problems may may involve prediction 
ine case done proving gradient descent projection arbitrary bregman distances converges optimal result 
de ned online convex programming problem 
established gradient descent ective technique problem 
motivated trying better understand nitesimal gradient ascent algorithm techniques developed applied problem establish extension nitesimal gradient ascent universally consistent 
simplicity algorithm allows expansion results areas 
instance deal euclidean geometry considered gradient descent geometry 
simplicity giga allows algorithm extended stronger results wolf 
errors omissions sole responsibility author 
pat riley great help developing algorithm case repeated games adam kalai improving proof bounds main theorem michael bowling avrim blum nikhil bansal manfred warmuth help suggestions research 
amari 
natural gradient works eciently learning 
neural computation 
bansal blum chawla meyerson 
online oblivious routing 
submitted 
blackwell 
analog minimax theorem vector payo south paci mathematics pages 
bowling veloso 
convergence gradient dynamics variable learning rate 
proceedings eighteenth international conference machine learning pages 
cesa bianchi long warmuth 
worst case quadratic bounds online prediction linear functions gradient descent 
ieee transactions neural networks 
della pietra della pietra la erty 
duality functions bregman distances 
technical report cmu cs carnegie mellon university 
foster 
proof calibration blackwell theorem 
games economic behavior volume pages 
foster vohra 
regret line decision problem 
games economic behavior 
freund schapire 
adaptive game playing multiplicative weights 
games economic behavior volume pages 
fudenberg levine 
universal consistency cautious ctitious play 
journal economic dynamics control 
fudenberg levine 
theory learning games 
mit press 
fudenberg levine 
conditional universal consistency 
games economic behavior 
gentile warmuth 
proving relative loss bounds online learning algorithms bregman divergence 
th annual conference computational learning theory june 
tutorial 
hannan 
approximation bayes risk repeated play 
annals mathematics studies 
hart mas colell 
simple adaptive procedure leading correlated equilibrium 
econometrica 
hart mas colell 
general class adaptive strategies 
journal economic theory 
herbster warmuth 
tracking best linear predictor 
journal machine learning research 
hoe ding 
probability inequalities sums bounded random variables 
journal american statistical association march 
kalai vempala 
geometric algorithms online optimization 
technical report mit 
kivinen warmuth 
exponentiated gradient versus gradient descent linear predictors 
information computation 
kivinen warmuth 
relative loss bounds multidimensional regression problems 
machine learning journal 
levine 
personal communication 
littlestone warmuth 
weighted majority algorithm 
proceedings second annual conference computational learning theory 
williamson 
prior knowledge preferential structures gradient descent algorithms 
journal machine learning research 
singh kearns mansour 
nash convergence gradient dynamics general sum games 
proceedings sixteenth conference uncertainty arti cial intelligence pages 
proof dynamic bounds proof de ne dynamic optimal strategy time argue rg 
rg 

rg 



loss generality assume kak kbk kf kfk 
kf rg kf kf rg kf lkf proof lazy projection analyzing greedy projection potential distance optimal point 
analyzing lazy projection potentials distance optimal point ideal potential distance set projection potential 
ideal potential sense grow distant optimal point performing better optimal point 
projection potential bad sense farther go di erence vector wanted vector 
lazy projection potentials cancel 
closed convex sets de ne min 
proofs subcomponents general proof 
prove section 
lemma ideal potential convex set linear cost sequence de ning de nition lazy projection xed learning rate kf lemma projection potential convex set linear cost sequence de ning de nition lazy projection section example highlighting issues lemma 
section prove critical connection dimensional case dimensional case 
section complete proofs lemma lemma theorem 
motivating example order motivate technical lemmas consider example 
choose fx ag 
assume cost function time 
attempt bound di erence cost accrued played point assume 
de ne min equation lemma lemma proof algebraic manipulation form potential key step varies general case general 

prove section dot product 
geometric lemmas section contains technical details proof 
lemma lemma convex set 

words angle acute 
proof prove contrapositive theorem 
consider point 

prove 
de ne prove small positive values closer convex 

observe 
lemma lemma 
proof simple example 
suppose 
prove property holds vectors 

suppose speci proven property holds 
hold translation 

holds hold ky kx ky scaling ky kx 
ky ky 
ky kx ky kx ky kx property invariant rotation 
de ne transpose matrix transpose vector suppose orthonormal matrix 
ra 
rb ra rb rb 
ra rb 

prove property holds hold ry rx ry 
ry rx 
ry ry 

ry rx ry rx ry rx observe think embedded changing distance dot product 
vectors obtained translation scaling rotation 
property holds vectors lemma lemma 
angle acute 
corollary 
proof result trivial 
assume example 
assume 
part proof prove worst case occurs de ning replacing observe rst 
observe 






relationship gets tighter force property holds vectors lemma 
lemma prove property invariant transformation rotation scaling 
completing proof complete proofs 
rst part similar theorem second generalization argument section 
proof lemma ideal potential de ne quantity trying bound exists 

de nition similar theorem 
kg 
summing get kf proof lemma projection potential de ne quantity trying bound exists 



corollary proof theorem lazy projection deterministic algorithm considers rc worst case linear function 
need consider linear functions 
rg rg lemma lemma rg kf kf proof universal consistency analysis universal consistency rst xes behavior time step action attempt develop environment maximizes value pr decomposition theory stochastic processes divide regret expected part random part 
bound expected part regret lower worst case oblivious deterministic environment due fact behavior studying self oblivious 
bound random part old result theory martingales 
rst introduce concepts stochastic processes useful proof 
de nition martingale di erence sequence sequence variables sequences jx lemma azuma lemma martingale di erence sequence jx pr exp decomposition allows construct martingale di erence sequence arbitrary random sequence jz corollary random sequence jz pr jz exp spirit de ne functions rem jhj hj rem lemma self oblivious exists oblivious deterministic environment proof observe nite set 
de ne argmax choose de ne pr jhj jhj pr jhj construction deterministic oblivious environment 
play actions rst rounds 
observe self oblivious distribution actions time step plays actions past history fact bound high probability 
de ne juj max min lemma self oblivious behavior exists time oblivious deterministic environment time arbitrary environment pr juj proof choose arbitrary environment lemma de ne oblivious deterministic environment captured expected part regret arbitrary environment 
de ne tg de ne hj rem jy juj 
azuma lemma pr juj pr juj lemma behavior exists time oblivious deterministic time arbitrary environment pr juj proof pr pr pr juj proof lemma wish nd pr hj decomposing nite sequence events 
pr hj pr hj pr de ne 
exists pr juj summing get pr hj juj geometric series 
simplicity de ne exp juj important fact 
calculating sum pr hj de ne ln ln jaj dmax pr hj 
