eurasip journal applied signal processing publishing sparse coding sounds david klein institute university zurich eth zurich ch zurich switzerland email ini phys ethz ch peter nig institute university zurich eth zurich ch zurich switzerland email ini phys ethz ch konrad institute neurology university college london queen square london wc bg uk email konrad de received may revised form january studies biological auditory processing revealed sophisticated analyses performed central auditory systems various animals 
analysis typically matched statistics relevant natural sounds suggesting produces optimal representation animal acoustic 
address topic simulated neurons learn optimal representation speech corpus 
input neurons receive spectrographic representation sound produced peripheral auditory model 
output representation deemed optimal responses neurons maximally sparse 
optimization simulated neurons similar real neurons respects 
notably neuron analyzes input localized region time frequency 
addition multiple subregions excite inhibit neuron producing selectivity spectral temporal modulation patterns 
suggests brain solution particularly suited coding natural sound may prove useful design new computational methods processing speech 
keywords phrases sparse coding natural sounds receptive fields spectral representation speech 

brain evolves timescales embedded properties real world 
properties sensory system matched statistics natural stimuli typically operating 
suggest functionality sensory neurons understood terms coding optimally natural stimuli 
line inquiry fruitful visual modality 
properties mammalian visual system explained leading optimally sparse neural responses response pictures natural scenes 
paradigm possible reproduce properties neurons lateral geniculate nucleus lgn simple cells primary visual cortex 
term sparse representation studies address distinct albeit related meanings neurons population significantly distinct functionality order avoid redundancy neurons exhibit sparse activity time activity level close zero occasionally high 
large number independent component analysis ica cf 
studies effectively principle demonstrate computational advantages representation 
shown processing exhibited neurons central auditory system captured receptive field shares properties spatiotemporal processing visual system 
particular neurons primary auditory cortex ai understood linear filters acting spectrally temporally local extent peripherally encoded input 
demonstrate characteristics auditory system understood terms sparse activity response natural input case approximated speech data 
representations efficiently code speech data adequately represented spectrograms obvious technical eurasip journal applied signal processing interest right type sound representation key improved recognition natural language speech denoising speech generation 

methods inputs narratives distinct languages taken language illustrations part handbook international phonetic association ipa available www 
arts gla ac uk ipa html preprocessed simulated peripheral auditory neurons nsl tools matlab package courtesy neural systems laboratory university maryland college park available www isr umd edu pubs html 
peripheral analysis employs constant bandpass frequency analysis similar mammalian cochlea including highfrequency order highpass corner frequency hz followed nonlinear sigmoidal transduction half wave rectification smoothing firstorder lowpass corner frequency hz envelope extraction 
comparison obtained second dataset recording audio data voluntary human subject kpk reading german language texts standard microphone cool edit pro software software phoenix usa recording mono kbit bits precision 
resulting data viewed spectrograms represent time dependent spectral energy sound 
example shown figures aand show respectively input output peripheral model utterance nach come home right away german 
spectrograms points spectral axis covering frequency range hz 
corresponds spectral resolution approximately channels octave 
temporally data arranged overlapping blocks points covering milliseconds 
block data taken milliseconds 
data subjected principal component analysis pca components set unit variance called whitening subsequently input vectors length optimization algorithm 
subsequent samples input 
neuron model neurons simulated weight vector wi length 
activities ai neurons defined follows ai wi function 
neurons characterized linear threshold properties 
parameters simulated neurons optimized fast optimization algorithm called resilient backprop maximize objective function cauchy log ai sounds denotes average stimuli ai activity neuron 
simulated neurons furthermore properties decorrelated 
add second term cc ai aj std ai cc denotes coefficient covariation std standard deviation 
term biases neurons distinct activity patterns term effectively normalizes standard deviation 
optimization performed principal component space cf 
sake faster computation 
transformation done matlab routine 
analysis optimized analysis performed neurons characterized corresponding learned set optimal weights 
properties strfs measured manner similar neurophysiological studies 
best frequency bf best time bt defined spectral temporal locations respectively maximum weight 
db bandwidth duration defined spectral temporal extent portion peak value 
addition properties dimensional fourier transform strfs measured 
spectral temporal filtering input signal quantified peak cutoff db frequencies fourier transform spectral temporal axes 
addition extent encodes frequency modulation direction quantified directionality index 
index computed relative power difference quadrants fourier transform lies 
illuminating compare properties optimized network statistics employed stimulus ensemble 
output peripheral auditory processing subjected multiscale dimensional wavelet second derivative gaussian analysis energy distribution temporal spectral modulations function position computed 

results 
data properties principal components speech data shown 
evident components represent variance change slowly spectrum time 
principal components sparse coding sounds frequency hz frequency hz frequency hz fort nach hau se time ms model early auditory processing time ms time ms segments ms time ms network preprocesses input methods 
recorded speech data shown raw waveforms 
data input model auditory system early stages resulting spectrogram strength activity color coded 
spectrograms subsequently cut overlapping pieces length milliseconds 
principal components pca shown color coded scale blue represents small values red represents large values 
learning effectively low passes stimuli components learning account total variance data 
previously reported form lowest components robust changes resolution peripheral auditory model 
particularly conspicuous fine scale spectral features evident lower frequencies 
arise low frequency harmonics important conveying pitch voiced speech 
frequencies higher khz comparatively broader scale spectral features corresponding primarily speech formants evident 
eurasip journal applied signal processing frequency hz time ms optimally sparse strfs results optimising sparseness 
representative strfs neurons shown 
seen different delays 
case energy middle shown 

receptive field properties employed ipa speech database contains male female speakers variety languages 
filters optimal encoding dataset illustrated 
strfs neurons obtained optimizing sparseness neurons stimulus evoked activity 
number important properties observed strfs 
strfs typically time spectrum 
secondly strfs exhibit multiple peaks troughs form oscillations spectral temporal axes 
range frequency modulations seen strfs evidenced oblique orientations strfs see neurons 
noted properties exhibited strfs obtained neurophysiological experiments 
specific manifestation properties varies neuron neuron 
instance different strfs centered different regions plane different spectral temporal extents 
distribution position shape parameters entire population strfs shown sizes strfs reduced actual values 
addition frequency spectral temporal oscillations exhibited strfs amount dampening varies population shown figures 
fourier domain properties conspire produce selectivity specific modulations temporal spectral axis 
quantifies selectivity spectral domain shows spectral characteristics fourier transform vary function position 
half strfs peak fourier transform lies cycle octave upper cutoff lies radically different strategy seen low frequencies 
neurons pass significantly higher spectral modulations ranging due presence low frequency high scale harmonic patterns speech input 
shows stimulus contains high proportion high scale energy low frequencies 
situation somewhat different temporal domain 
general strfs highly damped temporal direction producing temporal modulation selectivity generally lowpass 
fact evident shows peak fourier transform rises hz furthermore cutoff frequency inversely correlated temporal width rises hz 
range temporal frequencies strfs largely consistent average temporal composition speech input majority power concentrated hz 
different strfs exhibit different degrees frequency modulation quantified direction selectivity index 
index exhibits solely positive going frequency modulations solely negative going frequency modulations equal amounts positive negative frequency modulation 
population distribution unimodal peaks index similar obtained neurophysiological experiments 
number important properties shared strfs real neurons 
extent temporal localization milliseconds spectral localization octaves learned strfs highly comparable real strfs obtained primary auditory cortex mammals 
applies range spectral hz modulations represented simulated strfs 
notable differences simulated actual strfs obtained animals 
biological strfs exhibit bandpass temporal processing simulated strfs primarily lowpass 
secondly exists large group artificial neurons directly encode fine scale multiple peaked spectral features pitch strfs observed auditory system animals 
sparse coding sounds 
mod 
freq 
cyc oct cutoff peak temporal width ms frequency hz time ms best frequency hz temp mod freq 
hz cutoff peak normalized power 
width oct full excitatory subfield best frequency hz temp 
mod 
freq 
hz neurons 
mod 
freq 
best frequency hz direction selectivity quantitative properties 
time frequency tiling properties neurons shown 
center ellipse represents bf bt neuron 
vertical horizontal extent ellipse represents width direction time spectrum 
factor introduced improve visibility data 
peak blue high frequency cutoff red frequency spectral modulation plotted function best frequency neuron 
spectral width red excitatory subregion blue plotted function bf neuron 
ipa stimuli analyzed fourier domain 
mean absolute values wavelet transforms spectrograms taken ipa database shown 
peak blue high frequency cutoff red frequency temporal modulation plotted function temporal width neuron 
normalized power shown function temporal modulation frequency 
index direction selectivity calculated histogram shown 

dependence neuron model current study far focused strfs produce optimally sparse activity linear threshold neu 
properties mimic properties real neurons exhibit negative firing rates 
ica studies purely linear neurons eurasip journal applied signal processing previous simulations repeated current simulation purely linear neurons 
representative results shown 
qualitatively speaking major features neurons strfs remain conserved 
spectral temporal extents strfs typically somewhat larger furthermore presence negative somewhat reduced 
combination properties produce analysis restricted low spectral temporal modulation frequencies 

dependence dataset sake comparison simulations neurons repeated different speech input time obtained single speaker see section 
sparseness requires neurons occasionally high activity having small activities time 
speaker expected distinguish specific elements speaker speech distinguishing utterances different speakers 
results generalize utterances speakers optimal utterances speaker 
shows learned receptive fields 
far neurons code changes pitch sounds 
number code compound features neuron frequencies rise fall 
dataset clearly influences data carefully considered 

dependence number principal components number principal components encode input potentially influence resulting receptive fields 
low order principal components tend lower frequency higher frequency components fewer principal components effect similar selectively reducing resolution peripheral analysis 
test influence effective smoothing simulations repeated reduced numbers principal components 
components typical properties described apply 
includes encoding low frequency spectral features due voice pitch 
number principal components limited influence resulting strfs 

discussion analyzing computational properties neural systems central importance thorough understanding input representation 
number theoretical studies optimal auditory processing raw acoustic pressure waveforms input representation 
example bell studied learning auditory temporal filters ica lewicki sejnowski showed overcomplete representations significantly frequency hz frequency hz linear neurons time ms single speaker data time ms dependence neuron model dataset 
representative strfs linear neurons shown 
representative strfs neurons optimized data single speaker shown 
sparse coding sounds frequency hz frequency hz time ms time ms dependence number principal components 
representative strfs shown simulation smaller number principal components 
shows results components shows results components 
improve model quality 
balanced dataset taken various sound sources possible approximately reproduce spectral analysis performed peripheral auditory system 
central auditory neurons combine features encoded peripheral neurons 
neurophysiological studies various species shown central auditory system jointly processes spectral temporal characteristics sound variety ways 
current study strives provide method speculation functionality processes 
doing raw waveforms preprocessed auditory peripheral model 
produces spectrogram representation sound better suited describing information bearing elements natural sounds speech 
furthermore central auditory neurons display largely linear processing envelope sound increases likelihood style inquiry fruitful 
fact results obtained spectrogram inputs exhibit rich properties real auditory neurons 
pca preprocess spectrogram feeding sparse coding algorithm 
resulting components capture prominent statistical properties data 
example banded structure low frequencies reflects dominant influence voice pitch 
possible preprocessing strongly influence resulting strfs 
argue likelihood analytical grounds 
assume number principal components identical number input samples spectrogram 
transformation principal component space orthonormal matrix full rank 
matrix inverted local optimum method pca space optimum method input space 
chosen principal components expected minor influence resulting strfs provided principal components 
simulations showed components fewer 
note possible albeit numerically expensive perform simulations pca preprocessing doing results similar strfs data shown 
strfs auditory system show functional similarity spatiotemporal receptive fields visual system 
properties visual neurons successfully learned maximizing sparseness quantitatively compare properties visual system properties simulated neurons 
study extends methods auditory data 
simulations able qualitatively reproduce important properties neurons ai thorough quantitative comparison properties remains important problem research 
doing necessary assemble rich database sounds accurately represents animal acoustic 
devise compact learning mechanism leads neuronal properties closely correspond observed experimentally 
necessitate development novel algorithms learning nonlinear neuronal properties 
assumption brain learns sparsely code natural sounds comes experimental eurasip journal applied signal processing prediction 
animal development able manipulate sparseness statistics acoustic environment neurophysiological properties neurons altered 
example raising animal auditory environment certain frequency band sparser enhance neural representation sparse frequencies 
furthermore facilitate auditory learning making underlying auditory features sparse 
fact training procedures children demonstrated interpreted framework 
visual modality sparse representation images enabled new computational approaches lead powerful algorithms image denoising image compression preprocessing image recognition 
suggests sparse coding data lead better algorithms denoising speech compression auditory data recognition natural language 
acknowledgments want swiss national science foundation snf swiss priority programs spp kpk swiss national fonds pk eu project kpk pk 
ada intelligent room project part expo partially pays djk part inspired project 
bruno olshausen tony bell heather read inspiring discussions technical assistance 
barlow possible principles underlying transformations sensory messages sensory communication ed pp 
mit press cambridge mass usa 
atick information theory provide ecological theory sensory processing network computation neural systems vol 
pp 

olshausen field emergence simple cell images nature vol 
pp 

van hateren van der schaaf independent component filters natural images compared simple cells primary visual cortex proc 
soc 
lond 
vol 
pp 
november 
bell sejnowski independent components natural scenes edge filters vision research vol 
pp 

comon independent component analysis proc 
int 
sig 
proc 
workshop higher order statistics ed france july 
hyv rinen sparse code shrinkage denoising nongaussian data maximum likelihood estimation neural computation vol 
pp 

simon klein spectro temporal response field characterization dy namic ripples ferret primary auditory cortex journal neurophysiology vol 
pp 

blake optimizing sound features cortical neurons science vol 
pp 

role space time auditory processing trends cognitive sciences vol 
pp 

yang wang auditory representations acoustic signals ieee transactions information theory vol 
pp 

wang spectral shape analysis central auditory system ieee trans 
speech audio processing vol 
pp 

riedmiller braun direct adaptive method faster backpropagation learning rprop algorithm proc 
ieee international conference neural networks ruspini ed pp 
san francisco calif usa march 
hyv rinen survey independent component analysis neural computing surveys vol 
pp 

chi gao ru spectro temporal modulation transfer functions speech intelligibility journal acoustical society america vol 
pp 

nig klein learning sparse auditory receptive fields proc 
international joint conference neural networks honolulu hawaii usa may 
bell sejnowski learning higher order structure natural sound network computation neural systems vol 
pp 

lewicki sejnowski learning overcomplete representations neural computation vol 
pp 

lewicki efficient coding natural sounds nature neuroscience vol 
pp 

miller read schreiner receptive fields auditory thalamus cortex journal neurophysiology vol 
pp 

sen theunissen feature analysis natural sounds auditory journal neurophysiology vol 
pp 

wiener volterra analyses applied auditory system hearing research vol 
pp 

cohen time frequency analysis prentice hall englewood cliffs nj usa 
kowalski analysis dynamic spectra ferret primary auditory cortex 
ii 
prediction unit responses arbitrary dynamic spectra journal neurophysiology vol 
pp 

olshausen sparse codes spikes probabilistic models brain perception neural function rao olshausen lewicki eds mit press cambridge mass usa 
jenkins johnson schreiner miller temporal processing deficits language learning impaired children ameliorated training science vol 
pp 

olshausen lewicki learning sparse image codes wavelet pyramid architecture advances neural information processing systems mit press cambridge mass usa 
sparse coding sounds david klein born florida usa 
undergraduate graduate education electrical engineering obtained georgia institute technology atlanta georgia university maryland college park maryland respectively 
currently working visiting scientist institute university eth rich rich switzerland developing models auditory cortical function investigating usefulness auditory knowledge various acoustical signal processing applications including sound recognition pitch extraction sound localization 
peter nig studied physics medicine university bonn bonn germany 
department neurophysiology max planck institute brain research frankfurt germany received habilitation degree 
working senior fellow neurosciences institute san diego calif joined institute rich switzerland 
experimental theoretical approaches study mammalian visual system particular interest processing natural stimuli 
konrad born darmstadt germany 
studied physics heidelberg rich 
got ph degree eth rich addressing optimality visual system 
worked biophysical modelling single cells oscillatory network dynamics spiking neurons 
worked learning rules replicate properties visual neurons trained natural stimuli 
main interests models optimal coding brain probabilistic models real world 
currently works ucl london addresses optimality motor system 
