fast outlier detection large multidimensional data sets amitabh alexander szalay andrew moore dept computer science johns hopkins university baltimore md cs jhu edu dept physics astronomy johns hopkins university baltimore md szalay pha jhu edu robotics inst 
school computer sc carnegie mellon univ pittsburgh pa cs cmu edu 
outliers objects comply general behavior data 
applications exploration science databases need fast interactive tools outlier detection data sets unknown distributions large size high dimensional space 
existing algorithms outlier detection slow applications 
algorithm innovative trees doesn assume probability model linear number objects number dimensions 
provide experimental results show practical solution problem 
outliers rare atypical data objects comply general behavior model data 
applications fraud detection customized marketing network intrusion detection weather prediction pharmaceutical research exploration science databases require detection outliers 
known algorithms detecting outliers fast underlying probability distribution unknown size data set large number dimensions space high 
applications need tools fast detection outliers exactly situations 
astronomers example discover new kinds bodies studying atypical space subset set attributes 
result users astronomical databases sloan digital sky survey sdss require interactive olap lter automatically just top fraction rarest objects large number objects satisfy search queries 
sdss queries typically return objects 
space typically dimensions 
interactive lter needs able detect outliers minute practically useful 
implies required algorithm preferably linear number objects number dimensions solution problem 
method uses tree partition data set groups objects group considered behave similarly respect outliers 
identify groups contain outliers 
algorithm assigns object value gives relative measure strong outlier object section gives details method 
section describes experiments real synthetic data 
proceed rst looking existing methods detecting outliers section 
related algorithms data mining literature nd outliers product clustering 
outliers objects belong cluster 
note detect outliers doesn need know rest data clustered 
algorithms inherently slower tuned exclusively nd outliers 
statistics community studied outlier detection extensively 
assume underlying probability model representing data nd outliers tests 
available tests single dimensional data 
knorr ng de ne object data set distance outlier respect parameters fraction objects lies distance greater algorithm detect outliers linear number objects exponential number dimensions :10.1.1.17.947
ramaswamy similar de nition outliers distance kth nearest neighbor :10.1.1.17.947
de nitions require existence metric distance function entire space possible applications 
breunig de nition outliers densities local neighborhood 
require de nition distance function 
algorithm linear number dimensions 
aggarwal yu evolutionary algorithms suited outlier detection high dimensions :10.1.1.131.2385:10.1.1.17.947
suitable purpose number dimensions relatively modest number objects larger 
algorithms give de nition outliers general purpose 
de nition 
consider detail subsection 
outliers smoothing factors de ne measure detecting outliers call deviations degree data element causes dissimilarity data set increase 
look subset data leads greatest reduction kolmogorov complexity amount data discarded 
formal de nition follows 
set items power set dissimilarity function cardinality function de ne smoothing factor sf say ix ix exception set required set outliers respect sf ix sf choices functions problem trivial solve 
non trivial polynomial time 
general problem np hard 
section shall ideas tree approach 
tree outlier detection essential idea approach partition data set groups objects group behave manner comes outliers 
partitioning data set groups problem reduces nding outlying groups time complexity dependent number groups number objects 
practical problems number groups expected number objects 
particular ord method time complexity super linear quadratic number groups 
applications sparseness region object measure 
moment proceed intuitive idea sparseness giving precise de nition 
suppose method partition space regions sparseness region nearly uniform 
objects region considered 
sparseness measured method comparing relative regions 
rank compute top fraction outlying objects 
note sparseness essentially inverse density uniformly sparse region uniformly dense 
space decomposition data structure tree form partitions 
sub section describes trees 
see regular tree directly serve purpose regions formed need uniformly dense 
sub sections modify tree structure get regions close uniformly dense 
space product space single dimensional metric spaces 
full dimensional metric euclidean metric de ned 
trees trees introduced bentley storing nite set points dimensional space widely 
point set region tree partitioning region point set 
node represents region axes orthogonal boundaries points lying inside region 
initially root node represents region points node particular dimension chosen plane orthogonal dimension chosen partition region ru disjoint regions rr node child nodes representing rr corresponding points lying 
number points ru constant number points region longer partitioned node leaf node 
note region represented node tree hyper rectangle dimensions 
call regions cells 
ensure cells bounding boxes points contained shrink partition required 
various common ways choosing partitioning dimension partitioning hyperplane 
cycle dimensions order node choose dimension region widest 
partitioning hyperplane choose plane middle chosen dimension choose plane partition points equally child nodes 
called partitioning median ensures tree balanced depth log number points trees widely answering various types spatial queries point location queries range queries nearest neighbor queries :10.1.1.17.947
ability aggregate properties data set multiple levels resolution 
tree nodes enhanced store aggregate characteristics associated point set useful computing em step :10.1.1.131.2385:10.1.1.17.947
allows fast computation em clusters 
aggregation capabilities trees detect outliers quickly 
leaf cell tree contains objects reduce problem detecting outliers detecting leaf cells high 
note middle median partitions result cells uniformly sparse 
objects cell regular tree general 
sub section modify trees better suit purpose 
enhancing trees special cuts consider node tree choose partitioning dimension partitioning hyperplane 
objects node dimension thick cluster objects close left region objects scattered evenly rest dimension want partition cell plane orthogonal cluster left child rest sparse region child 
child cells uniformly sparse dense relative parent 
sub sections methods doing 
simple heuristics get better partitions regular trees 
idea choose partitioning hyperplane separate cluster sparse region 
partitions called special cuts 
special cuts objects region unevenly distributed dense sub region sparse sub region 
estimate occurs simple ecient test center volume cell center mass objects cell far apart assume cell sub regions di erent densities 
precisely cm represent center mass objects cell cv represent center volume cell 
skewness cell de ned max dimension distance cm cv length region remember cells question hyper rectangles dimensions 
special cut skewness cell greater threshold value 
skewness threshold regular tree partition middle median 
dimension ratio maximized called dimension maximum skew 
describe simple heuristics special cuts 
wrap mean try partition region center mass separated 
distance cm cell closest dimension maximum skew dm partition orthogonal distance dm cm direction opposite closest 
child cell containing cm contain objects cluster child cell contain rest sparse region 
heuristic clearly works cluster cell 
cluster middle 
case skewness cell small large threshold skewness chosen regular partition special cut 
regular partition split regions child regions cluster 
child cells special cuts seperate clusters sparse regions 
lognormal distribution assume dense part cell contains objects modeled lognormal distribution 
compute parameters distribution mean variance objects dimension maximum skew choose point split distribution separate cluster sparse region 
note particular alternative stepping aside general rule assuming underlying probability distribution 
practice build tree regular partitions irrespective skewness cells 
special cuts skewness employed say levels tree 
essential allow special cuts levels allow dimension required 
ranking leaf cells tree leaf cells groups data partitioned 
rank basis 
de ned regions inverse density de ned 
ratio volume cell number objects 
say want identify top fraction outlying objects 
build tree special cuts levels 
sort leaf cells inverse density consider sparsest cells fraction objects 
objects cells set outliers 
experiments show scheme works practice see section 
shows algorithm progress original dimensional data sdss tree built note cells larger outlying areas top outliers identi ed tree algorithm 
fig 

sdss data 
tree data depth 
top outliers detected algorithm 
picture detail 
time build tree nd depth tree number objects number dimensions 
time sort cells 
constant depending desired amount resolution 
running time method nk 
space required method linear size data 
special cuts smoothing factors de nitions section easily lead practical scheme 
scheme trees hand works practice 
idea smoothing factors create sophisticated methods choosing special cuts computing leaf cells 
consider rst special cuts 
dimension maximum skew 
cut dimension separate sparse region clustered region 
objects sparse region outliers cell 
assume horizontal outliers left 
normalized position boundary varies left right 
point partitioning give set outliers choose largest smoothing factor 
dissimilarity function choose speci length normalized length divided size subset 
cardinality function choose size subset 
denote number points left total number points cell 
smoothing factor point sf expression simpli es sf sf maximum special cut hyperplane orthogonal consider measuring leaf cell smoothing factor 
de ne smoothing factor leaf cells rank value factor 
dissimilarity function choose inverse density speci volume subset objects considered 
cardinality function choose size subset 
volumes occupied entire tree single cell denoted vt respectively 
similarly number points entire tree cell nt respectively 
smoothing factor cell sf nt vt nt vt nt simpli es sf vt vt nt wish nd fraction atypical objects output objects cells largest smoothing factor values contain fraction objects 
choices dissimilarity function choose 
particular normalized length speci length special cuts volume speci volume measuring choices 
experiments quality outliers speed algorithm nearly choices 
indicates basic scheme quite robust 
results program implements scheme described subjected various tests synthetic data real astronomy data sloan digital sky survey 
report tests interest space 
tests described 
tests performed intel pentium ghz processor running red hat linux 
time taken measures include user system time 
analysis section implies time taken program linear number objects dimension space 
true tests 
shows time taken function number objects time taken function number dimensions 
consider measuring quality solution 
dicult standard benchmark method slow outlier detection 
lieu standard assume data generated gaussian mixture model run em clustering program long stabilize get representation actual model 
compute true outliers 
call set outliers standard 
assigned likelihood generated gaussian mixture model 
program developed base source code regular trees developed auton project carnegie mellon university 
time taken seconds number objects time taken seconds number dimensions fig 

time taken function number points data set 
time taken function number dimensions 
depth tree 
data sdss 
em clustering program :10.1.1.17.947
uses trees reduce cost em clustering :10.1.1.131.2385:10.1.1.17.947
automatically selects number initial locations gaussians rst identifying regions model density placing new gaussians repair model :10.1.1.17.947
compare tree algorithm standard consider top fraction outliers sets 
fraction objects common sets measure quality algorithm detecting top fraction outliers 
plot quality di erent values values method fraction common 
fraction common compared fraction outliers compared em standard tree inverse density depth fig 

fraction outliers common standard 
data sdss 
tree program inverse density measure took 
depth tree xed 
standard run 
state art implementation em clustering 
measure speed algorithm relative computed time run give solutions program 
words see long needs run converge set outliers 
quality outliers measured comparing output standard described earlier 
rst plot results dimensional sdss data followed dimensional synthetic data cases see algorithm quality runs times amount time 
total objects dimensional space generated 
form clusters 
center cluster chosen choosing value dimension uniformly random 
cluster formed fraction common compared fraction outliers compared em standard em em tree smooth depth tree inverse density depth fraction common compared fraction outliers compared em standard em em tree smooth depth tree inverse density depth fig 

time required em clustering converge outliers tree algorithm 
tree algorithms shown depth 
data sdss 
standard took 
tree algorithm em takes em takes 
synthetic data 
standard took 
tree algorithm em takes em takes cases takes approximately times amount time converge set outliers nearly tree algorithm 

aggarwal philip yu 
outlier detection high dimensional data 
acm sigmod conference 

agrawal raghavan 
linear method deviation detection large databases 
proc 
nd international conference knowledge discovery data mining 

barnett lewis 
outliers statistical data 
john wiley sons chichester new york 

bentley 
multidimensional binary search trees associative searching 
commun 
acm september 

markus breunig hans peter kriegel raymond ng org sander 
lof identifying density local outliers 
acm sigmod int 
conf 
management data pages 


applied spatial data structures large data sets 
phd thesis johns hopkins university 
preparation 

martin ester hans peter kriegel xu 
database interface clustering large spatial databases 
int conference knowledge discovery databases data mining kdd montreal august 

sudipto guha rajeev rastogi kyuseok shim 
cure ecient clustering algorithm large databases 
acm sigmod international conference management data pages june 

hawkins 
identi cation outliers 
chapman hall london 

edwin knorr raymond ng 
algorithms mining distance outliers large datasets 
proc 
th int 
conf 
large data bases vldb pages 

moore 
fast em mixture model clustering multiresolution kd trees 
advances neural information processing systems 

ng han 
ecient ective clustering methods spatial data mining 
matthias jarke carlo zaniolo editors th international conference large data bases september santiago chile proceedings pages los altos ca usa 
morgan kaufmann publishers 

auton project 

www org 
randomly choosing points small hyper cube center 
rest objects chosen randomly centers earlier 

sridhar ramaswamy rajeev rastogi kyuseok shim 
ecient algorithms mining outliers large data sets 
acm sigmod conference pages 

samet 
design analysis spatial data structures 
addison wesley reading ma 

sand moore 
repairing faulty mixture models density estimation 
international conference machine learning 

tian zhang raghu ramakrishnan miron livny 
birch ecient data clustering method large databases 
acm sigmod international conference management data pages montreal canada june 
