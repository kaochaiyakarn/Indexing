caching support push pull data dissemination data snooping routers ismail ari ari cs ucsc edu internet applications web audio video streaming file sharing depend wide area data dissemination 
clients applications suffer long delays due network queuing bandwidth limitations adverse effects bandwidth sharing different traffic 
caching reduces delays saves network bandwidth holding fetched data responding subsequent requests locally 
existing distributed caching solutions application specific support delivery push pull directions time 
proposed architecture called storage embedded networks gives application direction independent caching support memory embedded data snooping routers 
router caches act client proxy server accelerator 
compare architecture web caches operating forward proxy mode 
report additional reductions client response times server loads proxies cache sizes 
keywords storage embedded networks web proxy push pull network modeling 
internet applications depend wide area data dissemination 
delays incurred clients applications network big problem 
instance delays distract students distance learning online lectures annoy customers online stores leading monetary losses 
caches alleviate adverse effects network dynamics wide area data dissemination retaining fetched data responding subsequent requests data locally 
propose integration cache service internet infrastructure router caching improve data dissemination 
internet traffic studies show web dominant source internet traffic 
report emerging peer peer file sharing media streaming applications research supported storage technologies department hewlett packard laboratories 
ethan miller elm cs ucsc edu storage systems research center university california santa cruz clients isp nsp current routers internet backbone caching router nsp servers storage embedded network sen architecture gives caching service networks cache embedded data snooping routers 
sen routers reside inside internet network service providers isp nsp 
significant traffic contributors reaching traffic transferred links 
existing emerging applications depend wide area data dissemination subject long delays unpredictable network dynamics due sharing bandwidth applications 
user access characteristics emerging applications similar web access characteristics 
static nature content exchanged skewed popularity zipf distribution internet applications candidates benefit distributed caching 
distributed web proxy caches successfully decade reduce response times web clients :10.1.1.21.1584
designed serve web clients operate clients download pull direction 
called forward proxy mode 
push delivery happens data items sent servers clients explicit requests clients 
today web servers need deploy reverse proxies accelerators limited push capability content 
content distribution networks cdn emerged new business model combining server side acceleration client side caching 
research shows benefits supporting push pull paradigms wide area data dissemination 
due lack generic caching support covers applications push pull directions emerging applications obliged reinvent reimplement similar non interoperable cache services 
proposed storage embedded networks sen architecture shown provides application direction independent cache service internet published proceedings th international conference parallel distributed systems newport beach ca july 
infrastructure 
uses cache embedded snooping routers building blocks 
conventional routers capability 
sen routers capable making fast cache table lookups globally unique object identifiers 
applications new protocol called object transport protocol otp request retrieve objects 
introduce operation existing routers show extend caching capability 
describe details sen architecture data caching routers otp protocol 
extensive modeling simulations comparison web proxy caches sen architecture 
find caches serve requests directions sen caches utilize cache space better leading additional hit rates forward proxy caches amounts cache 
background routers network level devices forward packets source addresses destination addresses 
considered building blocks internet infrastructure ubiquitous 
packets traversing internet routers carry data pertaining applications networked protocols 
existing routers commonly internet protocol ip header information forward packets ignore rest packet contents 
overview operation existing routers show extend routers caching capability section 
router details shows simplified hardware model router 
data plane fast path forward packets second 
control plane slow path handles route updates management routines 
line cards fig 
network interface cards input output ports packets received transmitted respectively 
core data forwarding function line cards done forwarding engine fe 
fe maintains forwarding information base fib table partial full copy routing table 
fib downloaded route processor kept date 
processor fe consults local fib quickly find hop information 
switch fabric fig 
switching capacity faster combined speed input ports 
access shared memory switch done direct memory access dma 
route processor fig 
responsible maintaining routing tables 
performs spanning tree calculations route update information disseminated routing protocols 
control plane data plane line card fe fib fe forwarding engine fib forwarding info 
base route processor routing table switch fabric fe fib fe fib simplified model existing routers 
packet forwarding operation packets received temporarily stored line cards existing routers 
soon packet headers read link layer ethernet frame packet processor forwards packet header forwarding engine fe 
fe physically embedded line card connected switch 
fe reads destination ip address finds matching hop entry forwarding information base fib 
results quickly microseconds returned packet processor 
adjacency table holds link layer information hops 
processor moves packet line card memory switch fabric interface 
packet moved switch fabric frame frame stored pointer output port 
scheduling algorithm weighted round robin wrr determine frame scheduled output interface 
destination output interface signaled take packet frames known memory location 
frames sent network mac protocol output interface 
enabling technologies network processor units software programmable processors designed process packets wire speeds 
combine speed asics flexibility cpus 
packet fields perform table lookups pattern matching data manipulation 
advantages market fastest growing segment microprocessor industry soon 
shared internal memory store program code possibly small lookup tables 
additional data stored external memories 
enable data caching wire speeds sen routers 
fast tree lookup techniques implemented hardware 
techniques currently route lookups bit ipv bit ipv addresses 
caching routers requires similar table lookup determine requested object cached 
ipv addresses lookups second reported dram sram technologies respectively bit ipv addresses lookups second projected 
storage embedded networks sen architecture provides caching service current internet infrastructure 
extends current routers network card embedded memory data caching 
applications globally unique identifiers presentation layer protocol called object transport protocol otp request retrieve objects 
object identification connection application protocol specific numbers meaningful limited domain 
give generic cache service sen router identify objects different applications common format 
identifiers need globally unique avoid name clashes 
globally unique object identifiers obtain hashing file contents 
emerging peer peer applications object file systems identifying objects 
don need naming change benefit sen caches 
applications want router caching include embedded objects 
object modified essentially new object new value 
clients requests offset pairs 
case web pages objects embedded static objects 
update operation may change top level object object need retransmitted 
reception clients hash contents compare result expected object check data integrity 
object transport protocol otp data caching service provide routers enforced passing packets 
existing emerging applications see benefit caching need indicate willingness routers setting bit ip header including otp header 
otp runs top transport protocols carries objects identified 
otp generalization real time protocol rtp successfully employed today carry real time traffic 
rtp introduces object awareness tagging packet globally unique synchronization source ssrc identifier camera id time offset realtime payload carried 
specific fields rtp suitable real time traffic 
type port num 
application byte offset globally unique object id bits otp header ip udp otp bytes ip bytes tcp payload otp payload encapsulation otp header otp header encapsulation 
otp header shown keeps generic object offset value data packet transmitted 
length payload obtained transport layer 
type field indicates kind action application wants otp 
currently read type read request data type returned payloads defined 
types write publish error considered 
port number original application communicate request reception object original application 
reserved field assign priorities objects provide differentiated caching services 
shows encapsulation otp header transport tcp udp network ip headers sent network 
data caching router shows hardware details data caching router 
add new card call data cache engine router enable caching objects process object transport protocol otp headers 
route lookup line cards cache lookup data cache engine done parallel 
network processor unit quickly searches globally unique object identifiers cache table determines hit cache hit source destination addresses ip header flipped data returned client 
packet processor informed result packet forwarding proceeds usual 
client application reflects read request choosing otp read option request type field otp header 
example get requests web browsers retrieve web pages mapped otp read request 
router doesn object cached object retrieved server packets 
packet carries bytes starting offset byte previous packet stopped 
transport reliable handles packet losses ordering 
object cached router sub packet processor fast mem object cache line card payload header forwarding engine cache table engine ip hdr hit data otp hdr switch line card data cache engine specialized line card added sen routers 
lookups determine object cached 
sequent otp read request may result hit 
object sent client otp data field set otp header 
maximum transfer unit mtu router client bigger mtu router server router may send bytes packet 
incoming ip packet marked denoting contains cache able data forwarded output line card hop destination data cache engine 
operation similar ip multicast operation 
sen architecture backwards compatible 
deployed incremental fashion current internet infrastructure 
existing routers forward ip packets embedded otp headers usual sen routers forward unmarked ip headers existing routers 
methodology event driven simulations compare proposed storage embedded network sen architecture web caches operate forward proxy mode 
model multi level network topology nodes representing clients servers caches routers 
clients servers edges topology shown 
parse web requests real proxy trace file assign randomly selected clients 
simulated network nodes forward requests web servers contain objects calculated modulo object identifier 
caches paths clients server 
network model generate wide scale network topologies user directed input number nodes wide area network wan number metropolitan area network man nodes wan number local area network lan nodes man number fe hosts lan man wan man lan hosts network topology simulation 
hosts lan delays bandwidths link 
delays bandwidths links type links lan man levels 
topology simulations illustrated 
directed links 
network delays traceroute collections university machines different universities 
delay bandwidth parameters links follows wan wan ms mbps wan man ms mbps man lan links ms mbps lan host ms mbps network queuing delays fluid flow network queuing model 
data passes router queued fifo queue serviced bandwidth speed outgoing link 
parameters timestamp node 
timestamp time object received fifo queue 
estimate time object waiting delayed router 
updated time new object received ob bandwidth timestamp queue timestamp parameter initialized current simulation time initialized zero 
pending client requests nodes caching capabilities implement pending request queue measure round trip times rtt avoid duplicate requests traversing network paths 
objects currently fetched enqueued pending queue client timestamp information 
object retrieved requests pending object dequeued responded 
context pending defined holding subsequent requests object requested 
measure effects strategy web proxies sen architecture 
web proxy vs sen web proxy caches successfully today reduce response times web clients 
caches define parent child relationships structure hierarchy forming tree topology bottom leaf top layers 
clients connect leaf caches web requests wait proxy returns response 
leaf cache fulfill request contacts parent server contacted object fetched 
object traverses path backwards getting cached hierarchy 
sen caches topologically transparent clients servers 
clients append otp headers request packets expect improvements sen caches internet infrastructure 
requests directed server 
delayed additional forwarding path parent caches 
fairness comparison tree topology amounts cache architectures 
workload national laboratory applied network research nlanr operates global cache hierarchy squid proxy caches provided important web traces 
day long trace collected busy web proxy server sv nlanr squid cache hierarchy 
contains requests gigabytes unique web objects gigabytes 
infinite hit rate infinite byte hit rate 
client node sees portion workload 
cache replacement cache replacement policy keeps cached objects priority order replaces valuable objects 
object access time access frequency size commonly criteria making replacement decisions 
compare replacement policies lru 
lru replaces accessed object cache 
greedy dual size frequency policy replaces object smallest key ki ci fi si ci cost fetching object fi access frequency si object size running age factor 
set key value objects replaced cache ci 
results discussion compare web proxy sen architectures described network topology web workload 
comparison performance metrics hit rates effects client response times effects server load 
metric web proxy sen nodes evaluated separately request pending strategy pending 
different cache sizes tested architectures compared cache sizes fairness 
hit rates compares hit rates achieved node network node forward web proxy sen router cache 
hit rates plotted function increasing cache sizes 
network topology contains caches lan level edges wide area network 
shows node achieves higher hit rates sen node web proxy node lru replacement 
sen routers operate forward reverse proxies simultaneously getting hits directions 
shows hit rates greedy dual size frequency uses frequency size criteria replacement addition recency accesses 
policy reach hit rates achieved lru replacement fraction cache sizes lru 
results steep increase hit rates seen 
pending strategy effect hit rates decision pend request comes cache occurs hit rates calculated 
compares hit rates web proxy sen caches caches lan man levels 
hit rates reported path hit rates phr calculated adding hit rate level hr hit rate second level traffic missed level phr hr hr hr 
note path hit rate metric independent direction traffic phr hr hr hr phr due increased total cache space hit rates approximately higher comparison hit rates 
gap web proxy sen cache hit rates close 
reasons reduction follows 
web proxies serving relatively larger unified community download pull direction creating accelerated path lans man second multi level caches client sharing communities exploited avoid duplications caches saved cache space avoid capacity misses 
policy achieves high hit rates smaller cache sizes lru pending strategy affect hit rates 
client response times compares average client response times crt proxy sen caches caches located lan level 
find additional hit rates achieved sen caches proxy caches illustrated immediately result additional reductions crt 
single level cache sen router accelerate server content hit rate hit rate sen sen pend proxy proxy pend hit rate cache size megabytes cache size megabytes lru replacement 
replacement 
hit rate comparison forward web proxies vs sen routers caches lan level 
sen sen pend proxy proxy pend cache size megabytes lru replacement 
hit rate sen sen pend proxy proxy pend sen sen pend proxy proxy pend cache size megabytes replacement 
hit rate comparison forward web proxies vs sen routers caches lan man levels 
hop ms closer clients 
see immediate results increased hit rates server load section 
note crt sen caches slightly lower crt proxy caches 
emerging distinction seen better policy achieves higher hit rates lru smaller cache sizes 
success multi level sen caches multi level web proxies eminent 
sen caches reduce client response times additionally crt achieved web proxy caches 
providing caching paths data traversing directions limiting cache service client pull direction results better amount cache space 
important result seen effect pending policy client response times 
sen web proxy caches requests requested objects inside cache repeating requests responded object fetched request 
pending request router challenging pending requests web proxies routers meant forward packets fast possible 
server load shows comparison effects web proxy vs sen caches server load expressed number requests handled web servers cumulative 
caches located lan level 
web servers experience additional benefits sen caches starting lan level caching 
additional hits achieved sen caches result additional reductions load server hop away cache 
leads increased server scalability 
results level caching similar omitted 
related proposed globally distributed cache infrastructure relates distributed systems distributed caches 
include web proxy caches content distribution networks cdns peer peer networks 
technique differentiates complements mentioned architectures providing application direction independent cache resource internet 
content distribution networks cdn aka average client response time sec average client response time sec proxy sen proxy pend sen pend cache size megabytes lru replacement 
average client response time sec proxy sen proxy pend sen pend cache size megabytes replacement 
client response times crt comparison web proxy caches vs sen routers caches lan level 
server load requests day proxy sen proxy pend sen pend average client response time sec cache size megabytes cache size megabytes lru replacement 
replacement 
crt comparison web proxy caches vs sen routers caches lan man levels 
proxy proxy pend sen sen pend proxy sen proxy pend sen pend cache size megabytes cache size megabytes lru replacement 
replacement 
server load reduction comparison web proxy caches vs sen routers caches lan level 
server load requests day proxy proxy pend sen sen pend mai server side web content combine push pull content private networks 
sen cache architecture uses globally unique object identifiers routers cache service globally accessible entities internet 
sen architecture act cache infrastructure cdns push content client paths ensure delivery closest copies 
sen architecture provide stable caching service peers overlay network 
described design new caching architecture internet infrastructure called storage embedded networks sen 
compared sen architecture web caches operating forward proxy mode 
network topology web workload cache sizes comparisons 
able service requests network paths helps utilize cache spaces better leading improved performance 
benefits sen caches increase caches installed network paths additional reductions client response times served loads achieved web proxy caches 
network cost continuous memory cost time investment 
modest hit rates router data caches pay short period time 
akamai www akamai com 
cisco routers layer forwarding www cisco com 
squid web proxy cache www squid cache org 
acharya franklin zdonik 
balancing push pull data broadcast 
proceedings acm sigmod international conference management data pages tucson az may 
miller hollingsworth 
names package management tcl 
proceedings th annual tcl tk conference pages san diego ca sept 
usenix 
almeida bestavros crovella de oliveira 
characterizing locality www 
proceedings international conference parallel distributed information systems pdis 
arlitt friedrich jin 
evaluating content management techniques web proxy caches 
proceedings nd workshop internet server performance atlanta georgia may 
chankhunthod danzig neerdaels schwartz worrell 
hierarchical internet object cache 
proceedings usenix annual technical conference san diego ca 
ramamritham shenoy 
adaptive push pull disseminating dynamic web data 
proceedings th international world wide web conference pages hong kong china may 
robbins 
viability analysis cooperative proxy caching 
proceedings infocom pages 
keys moore claffy 
longitudinal study internet traffic 
technical report cooperative association internet data analysis caida 
moon lyles cotton khan moll seely diot 
packet level traffic measurements sprint ip backbone 
ieee network 
meier 
hardware assist ipv routing table lookup 
pages zurich switzerland 
mangione smith 
design evaluation network processor accelerator layer applications 
submitted acm transactions embedded computing systems 
mohamed 
demand media streaming internet 
proceedings international workshop trends distributed computing systems san juan puerto rico may 
nicol johnson 
fluid simulation communication networks ssf 
proceedings european simulation symposium erlangen germany oct 
pao liu wu yeung chan 
efficient hardware architecture fast ip address lookup 
new york ny june 
ieee 
partridge 
gb ip router 
ieee acm transactions networking june 
rodriguez spanner biersack 
web caching architectures hierarchical distributed caching 
proceedings th international www caching workshop 
saroiu gummadi gribble 
measurement study peer peer sharing systems 
proceedings multimedia computing networking mmcn pages 
spie acm jan 
schulzrinne casner frederick jacobson 
rtp transport protocol real time applications 
request comments rfc ietf jan 
shaikh greenberg 
experience black box ospf measurement 
proceedings acm sig comm internet measurement workshop 
tran hua 
zigzag efficient peer peer scheme media streaming 
proceedings infocom 
zipf 
human behaviour principle effort 
addison wesley 
