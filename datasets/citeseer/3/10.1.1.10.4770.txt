data structure analysis fast scalable context sensitive heap analysis chris lattner vikram adve university illinois urbana champaign lattner cs uiuc edu describes scalable heap analysis algorithm data structure analysis designed enable analyses transformations programs level entire logical data structures 
data structure analysis attempts identify disjoint instances logical program data structures internal external connectivity properties trying categorize shape 
achieve data structure analysis fully context sensitive sense names memory objects entire acyclic call paths builds explicit model heap robust handle full generality despite aggressive features algorithm extremely fast requiring seconds programs range lines code scalable practice 
features believe novel incrementally builds precise program call graph analysis distinguishes complete incomplete information manner simplifies analysis libraries portions programs uses speculative field programs order preserve ciency scalability 
shows key achieving scalability fully context sensitive algorithm approach combination importance clearly articulated 

alias analysis programs complex pointer data structures successful guiding traditional low level memory optimizations 
transformations rely disambiguating pairs memory identifying local interprocedural side ects statements 
contrast success transformations apply entire instances data structures lists heaps graphs 
reasons exist disparity including possibility non type safe memory accesses common programming languages potentially high cost analysis distinguish di erent instances logical data structure 
enabling analyses transformations requires powerful analysis capabilities full context sensitivity identifying disjoint instances data structures requires analysis algorithm distinguish heap objects created di erent call paths program naming objects entire acyclic call paths 
partially context sensitive algorithms attempt distinguish heap objects call paths unable detect key property :10.1.1.25.6013:10.1.1.22.4648
hand nave cloning easily lead explosion size heap representation number call paths may exponential size program recursion di cult handle 
field sensitivity identifying internal connectivity pattern data structure requires distinguishing points properties di erent structure fields 
field sensitivity supported analyses targeting languages type safe di cult support efficiently non type safe languages see :10.1.1.51.1358
explicit heap model analyzing heap data structures requires constructing explicit heap model including objects directly necessary identifying aliases 
common alias analysis algorithms steensgaard andersen algorithms build explicit heap representation provide context sensitivity :10.1.1.11.3368:10.1.1.109.6502
powerful analyses record alias pairs determine pointer aliasing properties :10.1.1.25.6013:10.1.1.43.4867:10.1.1.57.8460
retaining capabilities challenging 
practical alias pointer analysis algorithms attempted provide combination properties described potential cost 
contrast shape analysis algorithms powerful provide information identify particular structure linked list binary tree 
shape analysis far proven practical commercial optimizing compilers 
analysis algorithm called data structure analysis key foundation transformations apply disjoint instances logical data structures 
algorithm aims lie traditional pointer analyses powerful shape analysis algorithms 
provides required capabilities listed supports full generality programs including type unsafe code incomplete programs function pointers recursion setjmp longjmp 
believe cient scalable commercial compilers 
built algorithm develop novel compiler techniques including automatic transformation segregate disjoint data structures heap program safety analysis ensures pointer heap safety type safe programs garbage collection :10.1.1.19.8733:10.1.1.10.3316
key novel aspects algorithm plus key property articulated algorithm incrementally discovers accurate callgraph program fly call graph parts analysis 
algorithm completely non iterative visiting instruction call edge analysis 
ii algorithm explicitly distinguishes complete incomplete information enabling conservative intermediate stages analysis allowing analyze portions programs safely 
iii algorithm provides speculative field sensitivity assuming memory objects program type safe shown 
allows algorithm completely field sensitivity objects accessed type safe manner common case 
iv property believe fundamental achieving scalable fully context sensitive algorithm unification approach 
combination extremely analysis representation grow large despite contextsensitive field sensitive representation 
discussed section 
show worst case time memory complexity fk denote number instructions maximum size data structure graph single procedure number edges call graph total number functions 
practice small typically order nodes large programs 
evaluate algorithm programs showing algorithm extremely cient practice performance memory consumption 
includes programs contain complex heap structures recursion function pointers 
example requires seconds analysis time mb memory analyze povray program consisting lines code 
believe broader implication may show fully context sensitive analysis described practical significant large real world programs 
closest previous algorithms fahndrich liang harrold ruf 
context sensitive flow insensitive appear roughly comparable terms analysis time 
discussed section provide key features incremental call graph construction handling function pointers recursion support incomplete programs support type unsafe programs partial field sensitivity 

data structure graph data structure analysis computes graph call data structure graph ds graph function program summarizing memory objects accessible function connectivity patterns 
ds graph node represents potentially infinite set memory describe graph size limiting heuristic detect avoid rare case required practice 
typedef struct struct nt data nt void void fp nt fp data void nt void st nt num new ma oc new num st num new data num return new nt main st st code running example objects distinct nodes represent disjoint sets objects graph finite static partitioning memory objects 
dynamic objects may pointed single pointer variable field represented single node graph 
assumptions input program representation necessary describing graph representation details described section 
assume input programs simple type system structural equivalence having primitive integer floating point types predefined sizes plus derived types pointers structures record types arrays functions 
assume language explicit pointer types integer types size larger directly encode pointer value call pointer compatible types values handled conservatively analysis type fields returns set field names fields single degenerate field name scalar type field names assumed unique type 
array type known size may represented structure fields single field unknown size array represented 
assumptions input program representation described section 
assume load store program representation virtual registers memory locations distinct possible take address virtual register virtual registers represent scalar variables integer floating point pointer 
structures arrays functions strictly memory objects accessed load store call instructions 
arithmetic operations operate virtual registers 
memory partitioned heap objects allocated malloc instruction stack objects allocated explicit stack allocation instruction named alloca similar malloc global objects global variables functions 
ds graph function finite directed graph represented tuple dsg ev set nodes called ds nodes 
ds nodes attributes described section 
set edges graph 
formally function type ns fs nd fd ns nd fs fields ns fd fields nd denotes type information computed objects explained 
function source field single outgoing edge 
note source target edge fields ds node 
ev function type vars vars set virtual registers function conceptually ev edge register target field pointed type 
set call nodes graph represent unresolved call sites context current function 
call node tuple 
ak element tuple node field pair 
respectively denote value returned call pointer compatible function called 

ak denote pointer compatible values passed arguments call arguments represented 
conceptually tuple element regarded points edge graph 
ds node name variable call return value called function argument second argument call node graph notation illustrate ds graphs analysis algorithm code running example 
example creates traverses disjoint linked lists iteration recursion function pointers pointer subobject global variable 
despite complexity example data structure analysis able prove lists disjoint final ds graph computed main shown 
illustrate ds graphs computed various stages algorithm render ds graphs graphical notation shown 
shows example graph computed functions interprocedural information applied 
includes example call node case calls function pointed fp passing memory object pointed argument ignores return value call 
graph nodes fields ds nodes ds graph responsible representing information set memory objects corresponding node 
node pieces information associated identifies language specific type memory objects represented section describes computed nodes representing multiple incompatible memory objects 
represents possibly empty set global objects represented node lags set flags associated node possible flags defined 
type information determines number fields outgoing edges node 
node outgoing edge pointer compatible field 
incoming edge point arbitrary field node data temporary points integer field byte set 
section describes type unsafe code pointers arbitrary byte ests handled 
globals represented node find targets function pointers clients data structure analysis incrementally construct call graph analysis 
void list list int fp data call int int int global local memory allocation classes flags lags distinguish classes memory objects heap allocated stack allocated globals includes functions unknown objects 
multiple flags may single ds node example analysis finds pointer may point heap object stack object 
memory objects marked unknown instruction creating identifiable constant value cast pointer value example access memory mapped hardware device address arithmetic cases occur infrequently portable programs nodes representing objects created external unanalyzed function marked treated missing information described 
mod ref information analysis keeps track particular memory object modified read current scope analysis represented flags 
example function statement reads pointer element node pointed causes flag set lags node ev shown 
mod ref information useful variety client analyses 
aggressive analysis missing information practical algorithms correctly handle incomplete programs code functions unavailable program library code information clients 
order allow aggressive analysis situations ds node tracks may information missing 
example data structure analysis know incoming fp arguments hasn performed interprocedural analysis 
inside function determine treated list object construction algorithm looks pointers declared types read nodes variable points 
know information memory object correct larger scope 
example fp arguments speculatively represented di erent objects aliased called particular call site 
handle situations data structure analysis computes nodes graph complete marks complete flag node marked somewhat similar inside nodes 
complete information calculated ds node represents partial information treated conservatively 
particular node may assigned extra edges extra flags di erent type may merged incomplete node graph 
example graph alias analysis algorithm assume fp may alias 
nodes graph may complete nodes merged node allowing clients obtain useful information graphs partial information 
capability key incremental nature algorithm nodes keep track information final created graphs constructed algorithm conservatively correct intermediate steps analysis 
field sensitivity type safety particularly important benefit complete flag allows ds analysis ciently provide field sensitive information type safe subsets programs 
important field sensitivity type unsafe structure types expensive fact observe portable code completely type safe :10.1.1.51.1358
complete flag allows ds analysis assume speculatively access node type safe access node conflicts accesses 
node marked complete long potentially unprocessed accesses safe 
ds analysis provides field sensitive information associating language specific type ds node keeping track distinct outgoing edge pointer element type 
accesses objects node consistent type operations incompatible types defined section type safety violation possible objects node 
occurs type node assumed array bytes void fields edges node collapsed single field outgoing edge algorithm collapse cell null null target fields merge old target remove field remove old edge void reset type information new edge field lags lags mark node collapsed pseudo code cell node field pair sources edges ds graphs 
function described section merges cells nodes pointed cells 
ensures targets cells exactly equal 
algorithm merges outgoing edges node result field sensitivity speculated node node collapsed lags treated safe field insensitive manner 

construction algorithm early attempt data structure analysis preliminary algorithm exponential section describes type information inferred actual accesses declared types variables common idioms casting pointer void back cause loss precision :10.1.1.19.8733
relatively common cases expensive programs containing large numbers globals correctly handle function pointers recursion programs incomplete programs 
algorithm described greatly improved areas extensive experience larger complex programs 
ds graphs created refined step process 
phase constructs ds graph function program intraprocedural information local graph 
second bottom analysis phase eliminate incomplete information due callees function incorporating information callee graphs caller graph creating bu graph 
final top phase eliminates incomplete information due incoming arguments merging caller graphs callees creating td graph 
bu td phases operate known strongly connected components sccs call graph 
properties important understanding analysis works presence incomplete programs incrementally construct call graph operates sccs graph 
ds graph function correct subset potential callers potential callees incorporated graph information graph safely long limitations nodes flags respected described section 
intuitively key property simply node marked complete known callers callees potentially ecting node incorporated graph 
second result graph inlining operations call sites independent order operations 
follows basic property order set nodes merged ect final result 
primitive graph operations data structure analysis flow insensitive algorithm uses unification memory model similar steensgaard algorithm :10.1.1.11.3368
algorithm uses primitive operations ds graphs shown 
operations algorithm merge cells merge nodes aligning fields specified manner inline callee graph caller graph particular call site vice versa 
operations described section 
fundamental operation algorithm merges target nodes specified 
requires merging type information flags globals outgoing edges nodes moving incoming edges resulting node 
fields incompatible types int int short node types compatible fields misaligned int short resulting node collapsed described section rest information merged 
merging outgoing edges causes target node edges merged node collapsed resulting node outgoing edge merged edges 
perform recursive merging nodes ciently merging operations implemented tarjan union find algorithm 
local analysis phase merge cells di erent nodes update discard cell cell cell collapse merge fields edges union flags flags union globals globals merge target edge target corresponding field move edges corresponding fields destroy return collapsed clone merge corresponding nodes global copy graph add nodes edges node global merge node containing clone callee graph caller merge arguments return graph callee graph caller function callee callsite cs callee caller clear flags cloned nodes caller callee cs clone caller graph callee merge arguments return graph caller graph callee function callee callsite cs caller callee callee callee cs merge arguments return value resolving call site graph function fc callsite cs target cs target return value fc min fc cs target arg cs target formal fc primitive operations algorithm goal local analysis phase compute local ds graph function information callers callees :10.1.1.109.6502
phase inspects actual program representation phases operate solely ds graphs 
local ds graph function computed shown 
analysis terms minimal language powerful assumptions type system memory model language described section creates empty node target pointer compatible virtual register entering map ev creates separate node global variable 
analysis linear scan instructions function creating new nodes malloc alloca operations merging edges variables assignments return instruction updating type information selected operations 
type cell ev updated manner interprets type viz dereference operation load store indexing structure array pointed malloc alloca cast operations simply create node void type 
structure field accesses adjust incoming edge point addressed field noop node collapsed 
indexing array objects ignored arrays treated having single element 
return instructions handled creating special virtual register capture assume functions ev return new empty node type invoking typeof previous edge cell variable existed 
example incoming argument points node 
abuse notation 
ev 
change points 
compute local ds graph function function create empty graph virtual registers ev globals variables functions lags instruction case malloc heap allocation ev void lags node ev alloca stack allocation ev void lags node ev ev ev lags node ev ev ev lags node ev address struct field ev typeof collapsed field field ev idx address array element ev typeof ev return return pointer compatible value ev ev value preserving cast ev ev 
zn function call new ev ev ev op instructions ev ev ev ev lags node ev collapse node ev function return value :10.1.1.43.4867:10.1.1.109.6502:10.1.1.109.6502
function calls result new call node added ds graph entries value returned function pointer direct indirect calls 
example local graph shows call node created call function 
note empty node created merged entry order correctly merge type information argument type may match declared type formal argument return value 
instruction applied value cast pointer integer smaller pointer integer arithmetic nodes pointed operands result collapsed unknown flag set node final step local graph construction calculate ds nodes complete 
local graph nodes reachable formal argument global passed argument call site returned function call may marked complete 
reflects fact local analysis phase interprocedural information 
example nodes arguments marked 
bottom analysis phase compiler type safe pointer arithmetic represented idx operations 
create new empty node type type new node type flags globals fields return merge type field type may collapse fields update edges cell type void typeof return return operations bottom bu analysis phase refines local graph function incorporating interprocedural information callees function 
result bu analysis graph function summarizes total ect calling function imposed aliases mod ref information calling context information 
computes graph cloning bu graphs known callees caller local graph merging nodes pointed corresponding formal actual arguments 
describe single graph inlining operation explain call graph discovered traversed 
consider call function formal arguments 
fn actual arguments passed 
function shows call processed bu phase 
copy bu graph clearing stack node markers stack objects callee legally accessible caller 
merge node pointed actual argument pointer compatible type copy node pointed applicable merge return value call node copy return value node callee 
note unresolved call nodes bu graph copied caller graph objects representing arguments unresolved call callee graph represented caller 
basic analysis recursion complete bottom algorithm traversing calls shown 
explain di erent cases 
simplest case program direct calls non external functions recursion function pointers call nodes ds graph implicitly define entire call graph 
bu phase simply traverse acyclic call graph post order visiting callees callers cloning inlining graphs described 
support programs function pointers external functions recursion simply restrict post order traversal process call site function pointer targets complete node targets fully resolved explained potential callees non external functions line 
call site may resolved function passed function pointer argument known 
example call fp resolved function resolved bu graph function conclude call 
clone merge indirect callee bu graph graph function call site resolved merging actual formal arguments return values just line 
technique resolving call nodes function pointer targets completed ectively discovers call graph fly record call graph discovered 
note bu graph function containing void void list void int gc void int call local graph void int gc list list int call inlining list list int int gr global final bu graph construction bu ds graph original call unresolved call node 
revisit previously visited functions phase call node eventually resolved top phase 
bu graph function call resolved fully incorporates ect call 
example inlining bu graph yields finished graph shown 
modified flag node pointed obtained node ev merged second argument node inlined 
graph identical obtained inlined eliminating call node resulting graph inlined 
cloning merging complete function scc identify new complete nodes section line remove unreachable nodes graph line 
created copying inlining callee graphs bring excess nodes accessible current function accessible callers 
includes non global nodes reachable virtual register global node call node 
recursion function pointers strategy handling recursion essentially apply bottom process described strongly connected components sccs call graph handling multi node scc separately 
key di culty call edges known discovered incrementally algorithm 
bottom analysis algorithm shown 
uses adaptation tarjan linear time algorithm find visit strongly connected components sccs call graph postorder 
assume direct calls call graph known 
scc calls functions outside scc cloned resolved functions visited postorder traversal sccs 
step complete functions scc empty lists call sites intra scc calls calls external functions simply ignored 
scc function eventually need inline graphs functions scc directly graph callee 
naive algorithm produce exponential number inlining operations careful enumeration require inlining operations complex sccs encountered benchmarks 
infinite number call paths scc choose completely ignore intra scc 
simply merge partial bu graphs functions scc resolving intra scc calls context single merged graph 
program function val nextid unvisited functions visit main available new stack function stack stk nextid val nextid nextid stk push call sites known non external callees fc val fc fc unvisited fc min val fc val new scc top stack scc appears stack val maxint stk pop stk scc stack stk function resolvable call sites see text known callees fc fc process scc fc fc cs function merge scc resolvable call sites see text known callees fc note fc fc cs section remove unreachable nodes contains new resolvable call sites mark unvisited stk re visit scc bottom closure algorithm recursion function pointers final case consider recursive program indirect calls 
di culty indirect calls may induce cycles scc call edges discovered indirect call resolved 
key observation properties described earlier yields simple strategy handle situations call edges scc resolved discovering form part scc call site closing cycle discovered say context function ect complete scc incorporated bu graph graphs functions handled earlier 
observation slightly adapted tarjan algorithm revisit partial sccs discovered visiting unresolved call sites 
current scc fully processed step check scc graph contains newly inlined call nodes resolvable 
reset val entries functions scc check node visited 
causes nodes current scc revisited new call sites processed resolvable call sites resolved included steps 
example consider recursive call graph shown call indirect call 
assume call resolved function passes explicitly function pointer argument 
edge unknown visiting tarjan algorithm discover sccs 
find new call node graph find resolvable call mark unvisited 
causes tarjan algorithm visit phantom edge discover partial scc 
processing scc new call nodes discovered 
point bu graphs correctly reflect ect call graph top pass resolve call inlining graph note case algorithm resolves callee call site iteration required sccs induced indirect calls 
graph shows bu graph calculated main function example 
graph disjoint subgraphs lists pointed proved disjoint cloned inlined bu graph call 
shows combination context sensitivity cloning identify disjoint data structures complex pointer manipulation involved 
list list int list list int int global finished bu graph main top analysis phase top construction phase similar bottom construction phase 
bu phase identified call graph td phase traverse sccs call graph directly tarjan algorithm need re visit sccs bu phase 
note sccs may visited partially bu phase td phase responsible merging graphs 
td phase di ers bu phase ways td phase marks scc unvisited explained uses call edges discovered recorded bu phase 
second td phase visits sccs call graph computed bottom traversal reverse postorder postorder 
third top pass inlines function graph callees reverse inlines caller graph potential callees directly needs defer inlining operation potential callees call site known 
final di erence formal argument nodes marked complete callers function identified analysis function accessible external functions 
similarly global variables may marked complete accessible external functions 
globals graph algorithm far global variables accessed program propagate bottom main top functions program ballooning graph size factor 
key optimization add data structure analysis algorithm separate globals graph hold information global nodes 
di erent caller may cause edge resolved di erent function bu graph include information call edge necessarily calling contexts 
recursive call graph indirect call dotted call node edges inlining 


mark unvisited 

scc visitation order handling recursion due indirect call bottom phase nodes reachable global nodes 
allows remove global variables function graph current function may callers callees function 
example eliminates nodes example graphs 
liang harrold similar technique 
briefly describe optimization describe detail full version accepted 
bu phase step copy merge nodes globals graph global node current graph plus nodes reachable nodes 
step copy nodes back globals graph step eliminate global nodes bu graph reachable reach locally live nodes 
similar steps td phase information td graphs propagated globals graph information functions merged 
practice globals graph remarkable di erence running time global intensive programs 
bounding graph size common case merging behavior unification algorithm keeps individual data structure graphs compact occurs data structure processed loop recursion 
combination field sensitivity cloning theoretically possible program build data structure graphs exponential size input program 
cases occur program builds processes large complex data structure non loop non recursive code extremely occur practice 
technique limiting guard cases unattractive reduce precision reasonable data structures paths nodes long 
propose implementations simply impose hard limit graph size nodes example larger real program need 
limit exceeded node merging reduce size graph 
results section show maximum function graph size observed practice wide range programs nodes quite small exclude virtual registers propagated functions 
complexity analysis local phase adds new node entry edge instruction procedure node merging 
furthermore node merging collapsing reduces number nodes edges graphs 
implemented node merging data structure ensures phase requires time space program containing instructions :10.1.1.11.3368
bu td phases operate ds graphs directly performance depends size graphs cloned time clone merge graph 
denote respectively worst case 
depend average number callee functions caller call site denoted bu phase function inline graphs callee functions average 
inlining operation requires time requires fcl time functions program 
call sites scc introduce additional complexity potential callee inlined caller outside scc fact slightly faster single graph built causing common nodes merged 
time compute bu graph fcl 
space required represent bottom graphs fk 
td phase identical complexity bu phase 

experimental results implemented complete data structure analysis algorithm llvm compiler infrastructure front gcc 
analysis performed entirely link time stubs standard library functions reflect behavior :10.1.1.43.4867
evaluated data structure analysis benchmark suites olden benchmarks benchmarks spec integer floating point benchmarks set programs 
note povray includes sources zlib libraries 
table describes relevant properties benchmarks 
loc raw number lines code benchmark number memory instructions program llvm representation scc size largest scc call graph program 
evaluated time space usage analysis linux workstation ghz xeon processor 
compiled llvm gcc level optimization 
table shows running times memory usage ds analysis 
columns labelled local bu td show time spent phases analysis 
largest programs study vortex gap povray fairly large contain nontrivial sccs call graph 
takes seconds perform steps algorithm programs 
put perspective compared total time compile link benchmarks gcc level optimization system 
data structure analysis required gcc compile times vortex gap povray respectively 
note gcc includes aggressive interprocedural optimization indicating reasonable cost aggressive omit gcc perlbmk currently incidental bugs front 
memory instructions load store malloc alloca call addressing instructions 
code size analysis time sec mem kb nodes max loc scc local bu td total bu td total max olden olden olden mst olden perimeter olden health olden tsp olden power olden em olden voronoi olden bh anagram ks ft yacr bc art equake mcf bzip gzip parser ammp vpr twolf crafty vortex gap mb mb sim burg flex povray mb table program information analysis time memory consumption graph statistics ral analysis potential applications 
table shows memory consumption ds analysis quite small 
mem column shows amount memory results bu td analysis algorithm 
total memory consumed largest code bu td mb reasonable modern optimizing compiler 
numbers noteworthy considering algorithm performing context sensitive program analysis cloning memory consumption running time bottleneck scaling analyses large programs nodes columns show statistics construction process 
total aggregate number nodes contained td graphs functions max maximum size particular function graph collapsed total number td graph nodes collapsed due apparent type violations 
large programs consistently nodes collapsed 
common reason appears merging global nodes format strings passed printf program usually merged cases turn causes nodes merged 
importantly table shows aggregate number nodes graphs maximum graph grow quite slowly total program size 
examined scaling behavior analysis omitted due lack space 
experience shows closest comparable analysis example disabled povray program analysis fit physical memory 
judging loc appears zlib libraries linked program analysis 
running time appears scale roughly nlogn number memory instructions program range orders magnitude code size 

related vast literature pointer analyses see survey hind majority focuses context insensitive alias information attempt extract properties fundamental goals identifying disjoint data structure instances 
due limited space focus techniques goals similar 
powerful class related algorithms referred shape analysis 
algorithms strictly powerful allowing additional queries data structure instance singly linked list 
extra power comes significant cost speed scalability particularly due need flow sensitivity iteration 
significant research necessary algorithms scalable moderate large programs 
prior closely related goals algorithm liang harrold named 
structure similar algorithm including local bottom top phases separate globals graph 
analysis power precision similar data structure analysis 
algorithm limitations practical programs 
retain field sensitivity completely type safe programs turn entirely 
requires precomputed call graph order analyze indirect calls function pointers 
requires complete program significant limitation practice 
handling global variables complex data structure analysis handles just memory class 
algorithms similar compilation times require higher memory algorithm larger programs runs memory analyzing povray field sensitivity machine memory 
ruf synchronization removal algorithm java shares important properties including combining context sensitivity unification non iterative analysis local bottom top phases node flags mark global nodes 
algorithm requires call graph specified limited type safe programs appear handle incomplete programs 
fahndrich describe algorithm contextsensitive fairly limited form flow insensitive discovers call graph incrementally analysis 
appears comparable terms analysis time 
implemented naming heap objects allocation site identify disjoint data structure instances common programs 
algorithm liang harrold connection analysis ghiya hendren attempt disambiguate pointers referring disjoint data structures 
ignore heap locations relevant alias analysis algorithms higher complexity 
cheng hwu describe flow insensitive contextsensitive algorithm alias analysis limitations relative goals represent relevant alias pairs explicit heap model limiting technique lose connectivity information nodes links :10.1.1.43.4867
allow pointer multiple targets andersen algorithm precise introduces iterative phases incurs significantly higher time complexity algorithm 
deutsch presents powerful heap analysis algorithm flow context sensitive uses access paths represented regular expressions represent recursive structures ciently :10.1.1.152.183
access paths appears possible reconstruct heap information regular expressions created 
practice algorithm appears higher complexity 

heap analysis algorithm designed enable analyses transformations disjoint instances recursive data structures 
algorithm uses combination techniques balance heap analysis precision context sensitivity cloning field sensitivity explicit heap model ciency flow insensitivity unification completely non iterative analysis 
showed algorithm extremely fast practice uses little memory scales linearly analysis time benchmarks spanning orders magnitude code size 
believe algorithm enables novel approaches analysis transformation pointer intensive codes operating entire recursive data structures achieving goals shape analysis weaker cient approach 
exploring applications research including automatic pool allocation distinct data structures disjoint pools heap transparent pointer compression pointer prefetching automatic parallelization 

andersen :10.1.1.109.6502
program analysis specialization programming language 
phd thesis diku university copenhagen may 
:10.1.1.43.4867
cheng mei hwu 
modular interprocedural pointer analysis access paths design implementation 
acm conf 
prog 
lang 
design implementation vancouver 
das fahndrich rehof 
estimating impact scalable pointer analysis optimization 
th int static analysis symp 
deutsch :10.1.1.152.183
interprocedural may alias analysis pointers limiting 
acm conf 
prog 
lang 
design implementation pages june 
adve lattner :10.1.1.10.3316
memory safety runtime checks garbage collection 
proc 
languages compilers tools embedded systems san diego ca jun 
emami ghiya hendren 
context sensitive interprocedural points analysis presence function pointers 
acm conf 
prog 
lang 
design implementation orlando fl 
fahndrich rehof das 
scalable context sensitive flow analysis instantiation constraints 
acm conf 
prog 
lang 
design implementation vancouver canada june 
ghiya hendren 
connection analysis practical interprocedural heap analysis international journal parallel programming 
ghiya hendren 
tree dag cyclic graph 
shape analysis heap directed pointers symposium principles programming languages pages 
hind 
pointer analysis haven solved problem 
paste pages 
acm press 
larus hilfinger 
detecting conflicts structure accesses 
acm conf 
prog 
lang 
design implementation pages july 
lattner adve :10.1.1.19.8733
automatic pool allocation disjoint data structures 
proc 
acm workshop memory system performance berlin jun 
lattner adve 
llvm compilation framework lifelong program analysis transformation 
proc 
int symposium code generation optimization appear san jose usa mar 
liang harrold 
cient points analysis program analysis 
esec sigsoft fse pages 
liang harrold 
cient computation parameterized pointer information interprocedural analysis 
static analysis symposium july 
ruf 
ective synchronization removal java 
conf 
prog 
lang 
design implementation june 
sagiv reps wilhelm 
solving shape analysis problems languages destructive updating 
acm trans 
prog 
lang 
systems jan 
sedgewick 
algorithms 
addison wesley reading ma 
steensgaard :10.1.1.51.1358
points analysis type inference programs structures unions 
computational complexity pages 
steensgaard :10.1.1.11.3368
points analysis linear time 
symposium principles programming languages pages jan 
vivien rinard 
pointer escape analysis 
acm conf 
prog 
lang 
design implementation 
wilson lam 
ective context sensitive pointer analysis programs 
sigplan conference programming language design implementation pages june 
