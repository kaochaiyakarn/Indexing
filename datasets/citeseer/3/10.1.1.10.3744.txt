nonstationary covariance functions gaussian process regression christopher mark schervish department statistics carnegie mellon university pittsburgh pa cmu edu mark stat cmu edu introduce class nonstationary covariance functions gaussian process gp regression 
nonstationary covariance functions allow model adapt functions smoothness varies inputs 
class includes nonstationary version stationary covariance differentiability regression function controlled parameter freeing fixing differentiability advance 
experiments nonstationary gp regression model performs input space dimensions outperforming neural network model bayesian free knot spline models competitive bayesian neural network outperformed dimension state art bayesian free knot spline model 
model readily generalizes non gaussian data 
computational methods speeding gp fitting may allow implementation method larger datasets 
gaussian processes gps successfully regression classification tasks 
standard gp models stationary covariance covariance points function euclidean distance 
stationary gps fail adapt variable smoothness function interest 
particular importance geophysical spatial datasets domain knowledge suggests function may vary quickly parts input space 
example mountainous areas environmental variables smooth flat regions 
spatial statistics researchers progress defining nonstationary covariance structures kriging form gp regression 
extend nonstationary covariance structure gives special case class nonstationary covariance functions 
class includes form contrast covariance functions added flexibility parameter controls differentiability sample functions drawn gp distribution 
nonstationary covariance structure dimensional input spaces standard gp regression model done previously dimensional input spaces 
problem variable smoothness attacked spatial statistics mapping original input space new space stationarity assumed research focused multiple noisy replicates regression function development assessment method standard regression setting 
issue addressed regression spline models choosing knot locations fitting smoothing splines choosing adaptive integrated squared derivative 
general approach spline models involves learning underlying basis functions explicitly implicitly fixing functions advance 
alternative nonstationary gp model mixtures stationary gps :10.1.1.19.9008
methods adapt variable smoothness different stationary gps different parts input space 
main difficulty class membership function inputs involves additional unknown functions hierarchy model 
possibility stationary gps additional unknown functions reduce computational complexity local estimate class membership know resulting model defined probabilistically 
mixture approach intriguing compare model methods :10.1.1.19.9008
model unknown functions hierarchy model determine nonstationary covariance structure 
choose fully model functions gaussian processes recognize computational cost suggest simpler representations worth investigating 
covariance functions sample function differentiability covariance function crucial gp regression controls data smoothed estimating unknown function 
gp distributions distributions functions covariance function determines properties sample functions drawn distribution 
stochastic process literature gives conditions determining sample function properties gps covariance function process summarized common covariance functions 
stationary isotropic covariance functions functions euclidean distance particular note squared exponential called gaussian covariance function exp variance correlation scale parameter sample functions infinitely derivatives 
contrast spline regression models sample functions typically twice differentiable 
addition theoretical concern asymptotic perspective covariance forms better fit real data unknown function highly differentiable 
spatial statistics exponential covariance exp commonly form gives sample functions continuous differentiable 
spatial statistics focused form modified bessel function second kind order differentiability parameter 
form desirable property sample functions times differentiable 
approaches squared exponential form takes exponential form 
standard covariance functions require place prior probability particular degree differentiability allows accurately easily express prior lack knowledge sample function differentiability 
application may particular interest geophysical data 
suggest squared exponential covariance anisotropic distance arbitrary positive definite matrix standard diagonal matrix 
allows gp model easily model interactions inputs 
nonstationary covariance function introduce builds general form 
nonstationary covariance functions nonstationary covariance function introduced kx du locations kx kernel function centered show directly positive definite 
gaussian kernels covariance takes simple form ns exp ij quadratic form ij call kernel matrix covariance matrix gaussian kernel form squared exponential correlation function place fixed matrix quadratic form average kernel matrices locations 
evolution kernel matrices space produces nonstationary covariance kernels drop quickly producing locally short correlation scales 
independently derived special case kernel matrices diagonal 
unfortunately long kernel matrices vary smoothly input space sample functions gps covariance infinitely differentiable just stationary squared exponential 
generalize introduce functions sample path differentiability varies extend proven theorem ij defined 
stationary correlation function positive definite ns ij nonstationary correlation function positive definite 
example nonstationary covariance functions constructed way nonstationary version covariance ns ij ij 
provided kernel matrices vary smoothly space sample function differentiability nonstationary form follows stationary form nonstationary sample function differentiability increases 
bayesian regression model implementation assume independent observations 
indexed vector input feature values noise variance 
specify gaussian process prior gp ns ns nonstationary covariance function constructed set gaussian kernels described 
differentiability parameter prior varies non differentiability high differentiability 
proper diffuse priors main challenge parameterize kernel matrices evolution determines quickly covariance structure changes input space degree model adapts variable smoothness unknown function 
problems natural covariance structure evolve smoothly differentiability regression function determined put prior distribution kernel matrices follows 
location input space gaussian kernel mean covariance kernel matrix input space dimensional kernel matrix just scalar variance kernel stationary gp prior log variance variances evolve smoothly input space 
consider multi dimensional input spaces implicitly kernel matrices location input space multivariate process matrix valued function 
parameterizing positive definite matrices function input space difficult problem see 
spectral decomposition individual covariance matrix 


diagonal matrix eigenvalues eigenvector matrix constructed described 


functions input space construct 
refer eigenvalue eigenvector processes collectively 
log 
log 
denote 
kernel matrices vary smoothly ensure eigenvalues eigenvectors vary smoothly gp prior single stationary anisotropic correlation function common processes described 
shared correlation function gives smoothly varying kernels limiting number parameters 
force smooth fixing 
vary minimal impact regression estimate informed data 
parameterizing eigenvectors kernel matrices givens angles angle function input space difficult angle functions range compatible range gp 
avoid eigenvectors gaussian processes determine directions set orthogonal vectors 
demonstrate construction eigenvectors similar approach albeit parameters applies higher dimensional spaces probably infeasible dimensions larger 
construct eigenvector matrix individual location abc ab ac ab abc abc ab bc ab abc abc ab abc uv uv uv uv elements functions random variables abc ab 
constraint saves degree freedom dimensional subspace orthogonal elements random variables matrices vary smoothly space values processes 
input interest 
integrate function evaluated inputs gp model 
stationary gp model marginal posterior contains small number hyperparameters optimize sample mcmc 
nonstationary case presence additional gps kernel matrices precludes straightforward optimization leaving mcmc 
vector values process input locations priori matrix defined 
sample metropolis hastings separately 
parameter vector involving correlation scale parameters givens angles construct anisotropic distance matrix shared vectors creating stationary anisotropic correlation structure common 
sampled metropolis hastings 
generalized cholesky decomposition correlation matrix shared vectors deals left test functions dimension simulated set observations evaluation right shows test function inputs 
numerically singular correlation matrices setting ith column matrix zeroes numerically linear combination 

calculates defined need introduce jitter discontinuity covariance structure 
experiments dimensional functions compare nonstationary gp method stationary gp model neural network implementations bayesian adaptive regression splines bars bayesian free knot spline model successful comparisons statistical literature 
test functions smoothly varying function spatially inhomogeneous function function sharp jump 
generate sets noisy data compare models means averaged sets standardized mse posterior mean mean true values 
non bayesian neural network model fitted value simplification network optimal number hidden units functions giving overly optimistic assessment performance 
avoid local minima network fit minimized mse relative data place expression mse fits different random seeds 
higher dimensional inputs compare nonstationary gp stationary gp neural network models free knot spline methods bayesian multivariate linear splines bayesian multivariate automatic regression splines bayesian version mars 
choose compare neural networks implement stationary gp model replacing ns stationary correlation differentiability parameter allowed vary 
non bayesian model implementation statistical software fits multilayer perceptron hidden layer 
bayesian version results neal fbm software kindly provided vehtari 
table mean data samples confidence interval standardized mse methods test functions dimensional input 
method function function function stat 
gp 
gp bars bayes 
neural net 
neural network splines popular particular implementations ability adapt variable smoothness 
uses piecewise continuous linear splines uses tensor products univariate splines fit reversible jump mcmc 
datasets function inputs training inputs test inputs simulated datasets 
second real dataset air temperature function latitude longitude allows assessment spatial dataset distinct variable smoothness 
observation subset original data focusing western hemisphere fit models splits training examples test examples split training examples test example including data point test point 
third real dataset daily measurements ozone included plus statistical software 
goal predict cube root ozone features radiation temperature wind speed 
splits training examples test examples split training examples test example 
non bayesian neural network hidden units optimal datasets respectively 
table shows nonstationary gp better stationary gp bars better methods datasets input 
part difficulty nonstationary gp third function sharp jump parameterization forces smoothly varying kernel matrices prevents particular implementation picking sharp jumps 
potential improvement parameterize kernel matrices vary smoothly 
table shows known function dimensions gp models outperform spline models non bayesian neural network bayesian network 
stationary nonstationary gps similar indicative relative homogeneity function 
real datasets nonstationary gp model outperforms methods bayesian network temperature dataset 
predictive density calculations assess fits functions drawn mcmc similar point estimate mse calculations terms model comparison predictive density values non bayesian neural network implementation 
non gaussian data model non gaussian data usual extension linear model generalized linear model observations appropriate distribution link function poisson log count data binomial logit binary data 
take nonstationary gp prior integrated model lack conjugacy causes slow mcmc mixing 
improves mixing remains slow sampling scheme hyperparameters including kernel structure nonstationarity sampled jointly function values way information likelihood 
table test function inputs mean data samples confidence interval standardized mse test locations temperature ozone datasets cross validated standardized mse methods 
method function inputs temp 
data ozone data stat 
gp 
gp bayesian neural network neural network report value neural network implementation fit model tokyo rainfall dataset 
data presence rainfall greater mm calendar day 
assuming independence years conditional logit likelihood calendar day binomial trials unknown probability rainfall 
shows estimated function reasonably follows data quite variable data areas clustered 
model detects inhomogeneity function smoothness months smoothness 
prob 
rainfall calendar day kernel size 
posterior mean estimate nonstationary gp model probability rainfall function calendar day pointwise credible intervals 
dots empirical probabilities rainfall binomial trials 
posterior geometric mean kernel size square root geometric mean kernel eigenvalue 
discussion introduce class nonstationary covariance functions gp regression classification models allow model adapt variable smoothness unknown function 
nonstationary gps improve stationary gp models test datasets 
test functions dimensional spaces state art free knot spline model outperforms nonstationary gp higher dimensions nonstationary gp outperforms free knot spline approaches non bayesian neural network competitive bayesian neural network 
nonstationary gp may particular interest data indexed spatial coordinates low dimensionality keeps parameter complexity manageable 
unfortunately nonstationary gp requires parameters stationary gp particularly dimension grows losing attractive simplicity stationary gp model 
gp priors hierarchy model parameterize nonstationary covariance results slow computation limiting feasibility model approximately cholesky decomposition 
approach provides general framework ongoing simpler computationally efficient parameterizations kernel matrices 
approaches low rank approximations covariance matrix may speed fitting 
gibbs 
bayesian gaussian processes classification regression 
phd thesis univ cambridge cambridge 
mackay 
gaussian processes 
technical report univ cambridge 
higdon swall kern 
non stationary spatial modeling 
bernardo berger dawid smith editors bayesian statistics pages oxford 
oxford university press 
schmidt hagan 
bayesian inference nonstationary spatial covariance structure spatial deformations 
technical report university sheffield 
damian sampson guttorp 
bayesian estimation semi parametric nonstationary spatial covariance structure 

kass 
bayesian curve fitting free knot splines 
biometrika 
mackay takeuchi 
interpolation models multiple hyperparameters 
volker tresp 
mixtures gaussian processes 
todd leen thomas dietterich volker tresp editors advances neural information processing systems pages 
mit press 
rasmussen ghahramani 
infinite mixtures gaussian process experts 
dietterich becker ghahramani editors advances neural information processing systems cambridge massachusetts 
mit press 

nonstationary gaussian processes regression spatial modelling 
phd thesis carnegie mellon university pittsburgh pennsylvania 
stein 
interpolation spatial data theory kriging 
springer 
williams 
discovering hidden features gaussian processes regression 
kearns solla cohn editors advances neural information processing systems 
lockwood schervish small 
characterization arsenic occurrence source waters community water systems 
am 
stat 
assoc 
holmes mallick 
bayesian regression multivariate linear splines 
journal royal statistical society series 
denison mallick smith 
bayesian mars 
statistics computing 
friedman 
multivariate adaptive regression splines 
annals statistics 
wood jiang tanner 
bayesian mixture splines spatially adaptive nonparametric regression 
biometrika 
cleveland warner 
dependence ambient ozone solar radiation temperature mixing height 
american meteorological society editor symposium atmospheric diffusion air pollution pages 

adaptive bayesian regression splines semiparametric generalized linear models 
journal computational graphical statistics 
smola bartlett 
sparse greedy gaussian process approximation 
leen dietterich tresp editors advances neural information processing systems cambridge massachusetts 
mit press 
seeger williams 
fast forward selection speed sparse gaussian process regression 
workshop ai statistics 
