features statistical machine translation franz josef och usc isi kenji yamada xerox xrce katherine eng stanford alex fraser usc isi daniel gildea rochester jain pennsylvania describe methodology rapid experimentation statistical machine translation add large number features baseline system exploiting features wide range levels syntactic representation 
feature values combined log linear model select highest scoring candidate translation best list 
feature weights optimized directly bleu evaluation metric held data 
results small selection features level syntactic representation 
despite enormous progress machine translation mt due statistical techniques years state art statistical systems produce translations obvious errors 
grammatical errors include lack main verb wrong word order wrong choice function words 
frequent problems grammatical nature include missing content words incorrect punctuation 
attempt address problems exploring variety new features scoring candidate translations 
high quality statistical translation system baseline add new features existing set combined log linear model 
allow easy integration new features baseline system provides best list candidate translations reranked new features 
framework allows incorporate different types features including features syntactic analyses source target sentences hope address grammaticality translations lower level features 
best lists easily global sentence level features 
describing baseline system best rescoring framework conducted experiments 
selection new features progressing word level features shankar kumar johns hopkins sanjeev khudanpur johns hopkins shen pennsylvania zhen jin mt anoop sarkar simon fraser david smith johns hopkins dragomir radev michigan part speech tags syntactic chunks features treebank syntactic parses source target sentences 
log linear models statistical mt goal translation text source language target language 
source chinese sentence 
fj 
fj translated target english sentence 
ei 
ei possible target sentences choose sentence highest probability argmax alternative source channel approach brown directly model posterior probability och ney log linear combination feature functions 
framework set feature functions hm 
feature function exists model parameter 
direct translation probability exp mhm exp mhm obtain decision rule argmax mhm standard criterion training log linear model maximize probability parallel training corpus consisting sentence pairs fs es 

guarantee optimal performance metric translation quality system ultimately evaluated 
reason optimize parameters directly bleu metric held data 
difficult optimization problem search space longer convex 
example segmentation chinese sentence english translation alignment templates 
certain properties bleu metric exploited speed search described detail och 
method optimizing feature weights 
baseline mt system alignment templates baseline mt system alignment template system described detail och tillmann ney och ney 
give short description baseline model 
probability model alignment template system translating sentence thought distinct stages 
source sentence words grouped phrases phrase alignment template chosen sequence chosen alignment templates reordered 
phrase produces translation corresponding alignment template 
sequence phrases constitutes sequence words 
baseline system incorporated feature functions alignment template selection alignment template chosen probability estimated relative frequency 
corresponding feature function log linear model log probability product alignment templates 
word selection feature lexical translation probabilities estimated relative frequencies highest probability alignment training sentence 
translation probability conditioned source target position alignment template interpolated position independent probability 
phrase alignment feature favors monotonic alignment phrase level 
measures amount non monotonicity summing distance source language alignment templates consecutive target language 
language model features language model feature standard backing word trigram language model ney wessel 
baseline system includes different language model features trained different corpora news part bilingual training data large news corpus large afp news corpus set chinese news texts downloaded web 
word phrase penalty word penalty feature counts length words target sentence 
feature sentences produced tend short 
phrase penalty feature counts number phrases produced allow model prefer short long phrases 
phrases conventional lexicon baseline alignment template system chinese english lexicon provided ldc 
lexicon entry potential phrase translation pair alignment template system 
score lexicon entries normal translation probability feature function counts number times lexicon entry 
additional features major advantage loglinear modeling approach easy add new features 
explore variety features successively deeper syntactic representations source target sentences alignment 
new features discussed added feature value set baseline features re estimated feature weights development data obtained results test data 
experimental framework worked chinese english data evaluations large amounts sentence aligned training corpora multiple gold standard translations available 
standard data set making possible compare results systems 
addition working chinese allows existing chinese syntactic treebank parsers 
baseline mt system distinguish different sentence chunk aligned parallel training corpora training corpus train basic training corpus train alignment template translation model word lexicon phrase lexicon 
corpus consists english words 
large parts corpus aligned sub sentence level avoid existence long sentences filtered training process allow manageable word alignment training 
development corpus dev training corpus discriminative training log linear translation model 
experiments described report corpus consists sentences words languages 
test corpus test test corpus assess quality newly developed feature functions 
consists sentences words 
development test data english translations chinese sentence 
reranking best lists oracles sentence development test blind test corpus set different alternative translations produced baseline system 
extracting best candidate translations search 
best candidate translations basis discriminative training model parameters re ranking 
best reranking implementing new search algorithms 
development efficient search algorithms long range dependencies complicated research topic 
reranking strategy enabled quickly try lot new dependencies possible search algorithm changed new dependency 
hand best list rescoring limits possibility improvements available best list 
important analyze quality best lists determining improvement possible perfect reranking algorithm 
computed oracle translations set translations best list yields best bleu score 
methods compute bleu score oracle translation 
optimal oracle opt select oracle sentences give highest bleu score compared set translations 
compute bleu score oracle sentences set translations 

round robin oracle rr select different sets oracle sentences give highest bleu score compared translations 
compute set oracle sentences bleu score score chosen select oracle 
bleu scores averaged 
note due corpus level holistic nature bleu score trivial compute optimal set oracle translations 
greedy search algorithm oracle translations find local optimum 
empirically observe dependence starting point believe pose significant problem 
table oracle bleu scores different sizes best list 
scores computed respect translations averaged different choices holding 
rr opt opt human method provides theoretical upper bound bleu score obtained rescoring nbest list 
method best list obtain oracle translations outperform bleu score human translations 
oracle translations achieve human bleu score test data table best translations obtain human bleu score 
second method uses different selection scoring 
best list obtain oracle translations relative human bleu score 
results oracle experiment order rescoring computationally feasible features requiring significant computation hypothesis top translation candidates experiments 
baseline system bleu score test set equivalent best oracle table 
benchmark contributions additional features described remainder judged 
preprocessing precursor developing various syntactic features described report syntactic representations needed computed 
involved part speech tagging chunking parsing chinese english side training development test sets 
applying part speech tagger ungrammatical mt output best lists led unexpected results 
tagger tries fix ungrammatical sentences example looking verb china nnp cd open jj border nn cities nns achievements vbz remarkable jj achievements seen verb tagger training data prior verb position high cause tense verb tag produced 
addition inaccuracies mt system difference genre tagger training text cause problems 
example mt data include news article headlines verb headlines included wall street journal text tagger trained 
similarly tagger trained full sentences normalized punctuation leading expect punctuation sentence produce punctuation tag evidence support china nnp pos economic jj development nn cc opening vbg rp cd border nn cities nns remarkable jj achievements issues affect parser 
example parser create verb phrases exist example tagger correctly identify verb sentence effects serious implications designing syntactic feature functions 
features verb phrase may expect 
solution features involve probability parse subtree tag sequence allowing ask verb phrase solution detailed features examining structure verb phrase verb word level feature functions features directly source target strings words intended address problems translation choice missing content words incorrect punctuation 
model score ibm model brown feature functions 
model bag word translation model gives sum possible alignment probabilities lexical occurrence effect triggering effect expected 
captures sort topic semantic coherence translations 
defined brown 
model gives probability translation pair fj ei 
giza train model 
training data subset words english side entire corpus train baseline mt system 
missing translation word pair unknown words fj ei model constant fj ei smoothing value 
average bleu score average best different search initial points 
tried feature function obtain improvements due overlap word selection feature baseline system 
model score best performing features 
fix tendency baseline system delete content words improves word selection coherence triggering effect 
possible triggering effect selecting proper verb noun combination verb preposition combination 
lexical re ordering alignment templates shown alignment templates ats baseline system appear various configurations call left right monotone left right continuous 
built models distinguish types lexicalized re ordering ats left monotone model computes total probability ats left monotone lower left corner touches upper right corner previous 
note word current may may immediately follow word previous 
total probability product alignment templates ati left monotone ati left monotone 
right continuous model computes total probability ats right continuous lower left corner touches upper right corner previous word current immediately follows word previous 
total probability product alignment templates ati right continuous ati right continuous 
models probabilities estimated full training data train 
shallow syntactic feature functions shallow syntax mean output part ofspeech tagger 
hope features combine strengths tag chunk translation systems schafer yarowsky baseline system 
projected pos language model feature uses chinese pos tag sequences surrogates chinese words model movement 
chinese words sparse model movement attempt model movement chinese pos may successful 
hope feature compensate weak model word movement baseline system 
chinese pos sequences projected english word alignment 
relative positions indicated chinese tag 
feature function tried relative positions cd nn nn nn nn measure open border cities table shows example tagging english hypothesis showing generated chinese sentence 
feature function log probability output trigram language model sequence 
similar hmm alignment model vogel ney tillmann case movement calculated basis parts speech 
projected pos feature function strongest performing shallow syntactic feature functions bleu score 
feature function thought trade purely word models full generative models shallow syntax 
tree feature functions syntax mt shown promise wu wong alshawi bangalore douglas 
hope adding features treebank syntactic analyses source target sentences address grammatical errors output baseline system 
parse tree probability straightforward way integrate statistical parser system log parser probability feature function 
unfortunately feature function help obtain better results significantly hurt performance 
analyze reason performed experiment test statistical parser assigns higher probability presumably grammatical sentences 
table shows average log probability assigned collins parser best produced oracle translations hypothesis best oracle log observe average parser log probability best translation higher average parse log probability oracle translations 
turns parser assigning higher probabilities ungrammatical mt output presumably grammatical human translations 
reason mt output uses fewer unseen words typically frequent words lead higher language model probability 
performed experiments balance effect dividing parser probability word unigram probability normalized parser probability feature function yield improvements 
tree string alignment tree string model translation models 
model conditional probability 
model defined yamada knight yamada knight 
internally model performs types operations node parse tree 
reorders child nodes changing vp vb np pp vp np pp vb 
second inserts optional word node 
third translates leaf english words chinese words 
operations stochastic probabilities assumed depend node independent operations node nodes 
probability operation automatically obtained training algorithm english parse tree chinese sentence pairs 
probability operations ek assumed depend edge tree modified ek independent giving equation varies possible alignments particular operations ek edge ek model extended incorporate phrasal translations performed node input parse tree yamada knight 
english phrase covered node directly translated chinese phrase regular reorderings insertions translations 
model trained english parse tree chinese sentence pairs 
words english side parsed collins parser 
model computationally expensive added limitations model operations 
base mt system produce translation big word jump restrict model reorder child nodes node covers words 
node children reordering probability set uniform 
introduced pruning discards partial subtree substring alignments probability lower threshold 
model gives sum possible alignment probabilities pair chinese sentence english parse tree 
calculate probability best alignment model 
fol lowing feature functions log log max model computationally expensive sorted best list sentence length processed shorter ones longer ones 
cpus days development sentences test sentences processed 
average bleu score average best different search initial points 
processed development sentences model preferred oracle sentences produced sentence cases 
biggest problem model computationally expensive 
processed best lists long cpu hours 
addition processed short sentences 
long sentences practical model tree tree alignment tree tree translation model syntactic tree source target language 
tree string model set operations apply probability transform tree 
training model trees source target languages provided case chinese english parsers 
began tree tree alignment model gildea 
model extended handle dependency trees word level alignments produced baseline mt system 
probability assigned tree tree alignment model word level alignment candidate translation generated feature rescoring system 
trained parameters tree transformation operations sentence pairs parallel chinese english data foreign broadcast information service fbis corpus 
lexical translation probabilities pt trained ibm model word training corpus 
done overcome sparseness lexical translation probabilities estimated training tree tree model able training data 
test tree tree model discrimination performed oracle experiment comparing model scores sentence best list candidate giving highest bleu score 
best list sentence development set restricting sentences words branching factor chinese english tree achieved results sentences 
model preferred produced oracle time indicating fact significantly improve bleu scores reranking 
probability source chinese dependency parse aligning best hypothesis dependency parse feature function making word level alignments yields bleu score identical baseline 
markov assumption tree alignments tree feature functions described far limitations full parse tree models expensive compute long sentences trees flat constituents limited reordering observed best lists form basis experiments 
addition higher levels parse tree rarely observed reordered source target parse trees 
section attack problems simple markov model tree alignments 
guarantees tractability compared coverage approximately best list unconstrained tree models markov model approach provides coverage best list 
addition approach robust inaccurate parse trees 
algorithm works follows start word alignments parameters maximum number words tree fragment maximum height tree fragment 
proceed left right chinese sentence incrementally grow pair subtrees subtree chinese english word chinese subtree aligned word english subtree 
grow pair subtrees longer grow subtree violating parameter values note aligned subtree pairs properties similar alignment templates 
rearrange complex ways source target 
shows subtree pairs parameters drawn sentence pair 
experiments substantially bigger tree fragments parameters set 
subtree pairs obtained easily assert markov assumption tree tree tree string translation models exploits pairings 
consider sentence pair discovered subtree pairs call frag 
compute feature function sentence pair tree string translation model follows string frag 
string frag markov assumption tree alignments markov assumption tree alignments 
tree string model described section obtain coverage improvement coverage original 
accuracy tree string model improved bleu score best performing single syntactic feature 
tag elementary trees scoring word alignments section consider method carving full parse tree 
method subtree pairs consider decomposition parse trees provides word fragment original parse tree shown 
formalism tree adjoining grammar tag provides definition tree fragment addition decompose original parse trees provide fragments 
fragment tag elementary tree composition tag elementary trees tag derivation tree provides decomposition parse trees 
decomposition tag elementary trees done augmenting parse tree source target sentence head word argument complement information heuristics common contemporary statistical parsers easily available english chinese 
note word alignment information decomposition tag elementary trees 
tag elementary tree word create models score word alignments exploiting alignments tag elementary trees source target 
tfi tei tag elementary trees associated aligned words fi ei respectively 
experimented models alignments unigram model alignments fi tfi ei tei conditional model ei tei fi tfi fi tfi fi tfi trained models sri language modeling toolkit aligned parse trees 
extracted tag elementary trees chi word alignments tag elementary trees 
english 
unigram model gets bleu score conditional model gets bleu score 
bleu baseline ibm model tree string markov fragments right continuous alignment template tag conditional bigrams left monotone alignment template projected pos lm tree string tag unigram tree tree combination table results baseline features new feature added baseline features combination new features 
discriminative reranking best list produced state art statistical mt system allowed rapidly evaluate benefits shelf parsers pos taggers improving syntactic formedness mt output 
results summarized table best single new feature improved bleu score 
confidence intervals computed bootstrap resampling method 
addition experiments single features integrated multiple features greedy approach integrated step feature improves bleu score 
feature integration produced statistically significant improvement absolute bleu score 
single best feature fact single feature produce truly significant improvement ibm model score 
attribute success addresses weakness baseline system omit con tent words improves word selection employing triggering effect 
hypothesize allows better context example choosing senses source language word 
major goal find exploit annotated data treebanks chinese english state art deep shallow parsers improve mt quality 
unfortunately implemented syntactic features achieved statistically significant improvement bleu score 
potential reasons described section shelf taggers parsers various problems due various mismatches parser training data application domain 
explain parser probability feature function successful 
potential improvement adapt parser retraining full training data baseline system 
best list limits potential improvements 
possible improvements obtained larger best list word graph representation candidates 
bleu score possibly sufficiently sensitive grammaticality mt output 
difficult see improvement system output potentially mislead bleu optimization feature weights 
significantly larger corpus discriminative training evaluation yield smaller confidence intervals 
discriminative training technique directly optimizes bleu score development corpus overfitting problems large number features 
larger development corpus discriminative training investigate alternative discriminative training criteria 
amount annotated data train taggers parsers orders magnitude smaller parallel training data train baseline system word features 
possibly comparable amount annotated data treebank words needed obtain significant improvements 
large scale integration syntactic analysis operating different levels state theart phrase mt system 
methodology log linear feature combination approach discriminative reranking best lists computed state art baseline system allowed members large team simultaneously experiment hundreds syntactic feature functions common platform 
acknowledgments material supported national science foundation 
alshawi srinivas bangalore douglas 

learning dependency translation models collections finite state head transducers 
computational linguistics 
brown peter stephen della pietra vincent della pietra mercer 

mathematics statistical machine translation parameter estimation 
computational linguistics 
gildea daniel 

loosely tree alignment machine translation 
proc 
st annual meeting association computational linguistics acl sapporo japan 
ney hermann frank wessel 

extensions absolute discounting language modeling 
proc 
fourth european conf 
speech communication technology madrid spain 
och franz josef 

minimum error rate training statistical machine translation 
proc 
st annual meeting association computational linguistics acl sapporo japan 
och franz josef hermann ney 

discriminative training maximum entropy models statistical machine translation 
proc 
th annual meeting association computational linguistics acl philadelphia pa och franz josef hermann ney 

alignment template approach statistical machine translation 
computational linguistics 
accepted publication 
och franz josef christoph tillmann hermann ney 

improved alignment models statistical machine translation 
proc 
joint sigdat conf 
empirical methods natural language processing large corpora college park md schafer charles david yarowsky 

statistical machine translation coercive level syntactic transduction 
proc 
conference empirical methods natural language processing emnlp philadelphia pa vogel stephan hermann ney christoph tillmann 

hmm word alignment statistical translation 
coling th int 
conf 
computational linguistics copenhagen denmark 
wu wong 

machine translation stochastic grammatical channel 
coling acl th annual meeting association computational linguistics th int 
conf 
computational linguistics montreal canada 
yamada kenji kevin knight 

syntax statistical translation model 
proc 
th annual meeting association computational linguistics acl toulouse france 
yamada kenji kevin knight 

decoder mt proc 
th annual meeting association computational linguistics acl philadelphia pa 
