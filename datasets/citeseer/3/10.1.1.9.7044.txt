semi supervised active learning algorithm information extraction textual data wu william pottenger computer science engineering lehigh university memorial drive west pa 
email lehigh edu article semi supervised active learning algorithm pattern discovery information extraction textual data 
patterns reduced regular expressions composed various characteristics features useful information extraction 
major contribution semi supervised learning algorithm extracts information set examples labeled relevant irrelevant attribute 
approach semi supervised require precise labeling exact location features training data 
significantly reduces effort needed develop training set 
active learning algorithm assist semi supervised learning algorithm order reduce training set development effort 
active learning algorithm seeded single positive example attribute 
context seed automatically identify candidates additional positive examples attribute 
candidate examples manually pruned active learning phase semi supervised learning algorithm automatically discovers reduced regular expressions attribute 
successfully applied learning technique extraction textual features police incident reports university crime reports patents 
performance algorithm compares favorably competitive extraction systems criminal justice information systems 

homeland defense important application domain information extraction mining technologies 
law enforcement agencies world generate numerous reports narrative unstructured textual form 
information extraction techniques employed automatically identify extract data unstructured text store fielded relational form databases 
stored relational form extracted information useful variety everyday law enforcement applications search retrieval 
extracted information map modus physical descriptions criminal suspects application advanced modeling useful suspect identification 
regular expressions patterns extract features semi structured narrative text soderland 
studying hundreds police incident reports patents unstructured data regular expressions readily employed express patterns features 
example police incident report suspect height recorded cd feet cd inches tall cd part speech tag numeric value 
developed algorithm automatic discovery regular expressions nature 
lehigh university conducting information extraction research collaboration lockheed martin ds pennsylvania state police city police department 
target develop system extracts features related criminal modus physical descriptions suspects recorded narrative incident reports 
results wu pottenger demonstrate semi supervised learning algorithm achieves excellent performance features important homeland defense 
article results extending algorithm wu pottenger combining active learning algorithm 
combined semi supervised active learning algorithm requires significantly effort develop training set approaches 
training set developer need label inordinate amount data 
algorithm automatically generates small set candidate segments developer label 
second benefit algorithm training set developer need record specific feature interest occurs segment opposed labeling exact location feature segment 
instance feature interest height segment suspect feet inches tall weighing pounds training set developer need assign segment label height 
semi supervised active learning algorithm discovers reduced regular expression precisely matches extracts feature feet inches tall segment 
article organized follows 
section summarize previous conducted manual study regular expressions extracting features police incident reports 
provide definitions section 
section semisupervised reduced regular expression discovery algorithm analyze biases algorithm 
section describe active learning approach 
section discuss experimental results combined semi supervised active learning algorithm 
introduce related section discuss section 
give section acknowledge contributed 

previous lockheed martin pennsylvania state police purpose ascertain regular expressions suitable information extraction unstructured narrative police reports 
address question studied voluminous police incident reports manually developed regular expressions extracting key attributes useful criminal justice information systems 
source data drawn fairfax county virginia police incident reports 
training data manually generated regular expressions attributes listed table 
independent test dataset assess performance regular expressions 
seen table test performance promising 
achieved precision time age height hair color eye color weight 
race high precision 
addition recall features 
fact achieved precision recall time height eye color weight 
table 
test performance manual expressions attribute precision recall time race age height hair color eye color weight results concluded regular expressions suitable extraction attributes police incident reports 
course confirmed time consuming tedious create regular expressions information extraction manually 
embarked research effort develop data driven algorithm automatically discover regular expressions small training set 
describe resulting semi supervised active learning algorithm sections 
section define terminology article 

definitions section standard definition regular expression define reduced regular expression algorithm 
define terminology article 
regular expression finite alphabet set regular expressions alphabet defined regular expression denotes set 
regular expressions denoting languages respectively rs regular expressions denote sets rs respectively hopcroft ullman reduced regular expression rre reduced regular expression defined follows finite alphabet reduced regular expression defined set rre denotes set 
words lexicon part speech tags penn tag set manning sch tze belong 
start line line 
represents single numeric digit 
represents single alphabetic character upper lower case 
punctuation characters belong 
white space characters belong 
null symbol empty string 
rre single alphanumeric punctuation character 
rres denoting languages respectively rs rre denotes set rs 
major difference regular expressions reduced regular expressions reduced regular expressions support kleene closure 
examples regular expressions rres include arbitrary word partof speech members 
necessary support regular expressions achieve high accuracies 
feature smallest unit information extracted 
examples include values attributes height weight age segment portion sentence 
commas mark segment boundaries 
exception comma separates numbers 
comma phrase brown eyes hand segment boundary 
textual string segment boundaries segment 
item document features extracted 
experiments described police incident report full text patent 
true set system learning rre attribute true set consists segments labeled training set 
false set system learning rre attribute false set consists segments labeled training set 
element word rre frequency true set higher threshold word part speech tag rre frequency true set higher threshold tag 
root element discovered algorithm rre 
rand rre learned completion learning process 
input parameter algorithm fixes maximum number elements rre 
integer greater equal 
set word tokens lexicon employed approach combined part speech tag tokens penn tag set manning sch tze 
total number tokens 
semi supervised learning approach section semi supervised approach discovery rres small set labeled training segments 
process begins preprocessing 
apply greedy algorithm discover rres 
detail steps follows 

pre processing semi supervised learning algorithm requires pre processing steps segmentation segment labeling part speech tagging 

segmentation incident report split segments stage 
segment instance system 
step splits input sentences technique reynar ratnaparkhi detect sentence boundaries 
police incident report input split commas 
mentioned section small number cases commas segment boundaries 
assume features cross segment boundaries 
assumption practical number important attributes including discussed section 

segment labeling prior start labeling stage domain experts identify attributes extracted 
instance high level goal extract physical descriptions suspects list include height weight eye color training set development segment evaluated manually assigned labels 
example segment includes height weight information domain expert assigns labels segment 
labeling attribute true set false set 

part speech tagging part speech tags reduced regular expression discovery algorithm 
word training set assigned correct part speech tag learning process begins 
currently eric brill part speech tagger tag training sets 
brill tagger uses penn tag set manning sch tze table contains examples penn tags 
enhanced lexicon include extra tags feature extraction police incident reports 
example cds plural numbers 
table 
example tags penn tag set tag category example cd cardinal number fifteen preposition prp pronoun prp determiner possessive dt determiner article cc conjunction rb adverb ago jj adjective happy bad nn noun singular aircraft data nnp proper noun london reston nns plural noun books years vbg verb participle living vbp verb base take vbd verb auxiliary past vbz verb auxiliary 
learning reduced regular expressions goal algorithm discover sequences words part speech tags high frequency true set having low frequency outside true set 
algorithm discovers common element rre termed root rre 
algorithm extends rre operator discovers gaps elements rre 
start rre learned 
depicts entire learning process 
portrays process algorithmic form 
example section explains algorithm works stage learning process 
discover root learning process gap learning process rre start learning process fig 

rre discovery find root learning gap learning rre start learning prune true set true positives fig 

rre discovery algorithmic form approach employs covering algorithm 
rre discovered algorithm removes segments covered rre true set 
remaining segments new true set steps repeat 
learning process stops number segments left true set equal threshold 
threshold overfitting results segments discover rre 
parameter system integer 
default set approach semi supervised learning method 
labeling exact location features training set training set developer need record specific feature interest occurs segment 
rre learned algorithm precisely matches feature interest 
depict details step algorithm follows 

discovering root rre step word part speech tag specified simple rre true set segment matched segments 
performance rre terms van rijsbergen equation considered 
formula precision tp tp fp recall tp tp fn tp true positives fp false positives fn false negatives 
parameter ratio recall precision enables place greater lesser emphasis recall versus precision depending needs application 
pr element maximum chosen root rre 
algorithm discovers word part speech tag high frequency occurrence segments containing desired feature 
low frequency segments contain desired feature 
example root discovered attribute age example section part ofspeech tag 
element segment true set tested root discovery time complexity root discovery equal number elements true set 
approach places emphasis precision recall root discovery process 
parameter root default set control 
naturally results larger set segments match root 
segments necessarily true positives 
result gap start learning phases prune false positives set segments match root rre 
evident result high precision high recall 

learning process root discovered algorithm tests additional words part speech tags root 
algorithm places new candidate elements immediately root forming new rres 
rre highest replaces previous rre 
example starting root attribute age rre years gap may discovered pass learning process gap gap discovered elements intuitively element adjacency implies operator name learning process 
new rre extended way 
candidate elements inserted current rre 
algorithm measures performance extended rre rre maximum selected 
sense algorithm greedy 
continuing previous example rre second pass learning process may cd gap years gap cd years elements rre gap represents gaps learned 
candidate elements consist words part speech tags numeric tokens composed digits 
lengths tokens provide clues useful rre discovery 
example digit tokens person age digit tokens year 
similarly person height digit feet digits inches person weight usually digits 
complexity learning process depends number candidate elements maximum number elements rand 
equation depicts cand complexity process sij set candidate elements th position th pass learning process single iteration 
sij contain elements positions test pass learning process 
position current rre position current rre 
example sij changes learning process depicted 
actual size sij depends number candidate elements position segment 
algorithm datadriven regard 
generalizing example see learning process passes required test positions maximum elements 
learning process ends conditions met number elements rre reaches maximum details gap discovery discussed section 
candidate elements segment tested allowable positions 
fig 

learning example age attribute sij cand 
complexity cand bounded cand 
ij fact algorithm data driven improves performance deduced comparing actual complexity equation upper bound 
words due fact segment contain words practice sij 
fact value maximum number elements allowed rre 

gap learning process years cd years cd years cd years cd years nn gap learning process algorithm learns length gap elements rre 
example suppose rre learned date attribute cd month month part ofspeech tag january december 
algorithm designed learn gaps adjacent elements automatically example learn gap zero elements cd month optimal 
example type rre cd token month token word part speech tag 
rre allows elements number month dt th cd january month 
case word followed part speech tag followed word january form gap elements size 
simple date attribute example assumed gaps measured terms elements fact execution time performance algorithm significantly improved gaps measured terms characters 
result measure gaps terms characters input parameter control maximum gap allowed adjacent elements rre 
system initializes observation adjacent elements separated characters training data 
gap algorithm determines min longest gap segment true set elements consideration 
example segment dt th cd january month including spaces characters cd month min 
determined algorithm tests gap 
expression represents single character member 
syntax means single character member occur times 
algorithm turn tests gaps 
smallest gap decrease current rre performance final gap elements rre 
gaps different elements differ size 
time complexity gap learning process depicted equation gi number comparisons identify optimal gap rre element element 
gi 
maximum number elements rre complexity gap discovery 

gap 
start learning start symbol symbol segment useful rre discovery 
result algorithm tests current rre include start symbol symbol 
insert start symbol rre form new rre 
equal better performance compared previous rre new rre start symbol replaces previous 
deal symbol similar manner 
addition initial element rre part speech tag algorithm ensures rre covers word tag 
time complexity learning process candidate rres tested 

example section age attribute illustrate semi supervised learning algorithm detail 
tables contain initial true false sets respectively 
characters part speech tags 
male special tag words male gender female tag words female gender 
distinct age patterns true set 
illustrated feature years age 
semi supervised algorithm discovers distinct rres age pattern 
words example covering algorithm completes iterations rre discovery 
table 
true set example segment true segments number cd feet nns tall jj cc cd years nns age nn dt cd years nns age nn nns male cds standing vbg cd feet nns tall jj prp vbp prp cds female vbd female cds tom nnp vbz male early jj teens cds table 
false set example segment false segments number dt jj man male vbz male car nn dt vbg cds dt cd block nn cd years nns ago rb cd feet nns cd inches nns tall jj dt tall jj thin jj build nn weighing vbg cd pounds nns iteration algorithm root rre discovered 
learning process extends root rres portrayed sequence 
order prune false positives covered root set example default set system 
noted previously greater emphasis placed precision learning way 
rres 
example rand learned passes learning process 
root discovery learning process years cd years cd years cd years cd years nn gap learning process rand cd years nn cd years nn cd years nn cd years nn cd years nn fig 

iteration rre discovery rand discovered gap learning process takes place tailors rand improve precision 
process depicted example gap learning process 
process involves steps gaps elements rand 
intermediate rre produced gap learning example 
case inclusion start symbol rre decreases rre discovered gap learning remains unchanged 
rre depicted bottom covers segments true set 
prepare second iteration algorithm segments removed true set 
second iteration begins segments true set segments false set 
steps learn second rre portrayed 
root discovery cds learning process cds cds gap learning process cds cds rand fig 

second iteration rre discovery addition start symbol decreases 
result final rre second iteration rre depicted bottom 
covering algorithm terminates second iteration true segments left true set covered rres discovered 
example highlights distinguishing characteristic algorithm features attribute extracted precisely training set features imprecisely labeled 
instance rre cds precisely matches age feature male cds segment male cds standing vbg cd feet nns tall jj 
segment contains age height information labeled training set development algorithm discovers expression precisely matches extracts age features 
exemplified discovery rre extracting height holds true 
features height precisely matched extracted despite fact source segments imprecisely labeled 
summarize precise labeling features tedious time consuming technique reduces training set development time impacting performance 

biases section discuss various biases inherent rres information extraction 
includes language biases search biases overfitting biases inherent rre discovery algorithm 
semi supervised learning algorithm top search algorithm 
starts general description root rre extends specific rre 
general specific search bias 
crucial search bias algorithm attempts identify words part speech tags occur true set having low frequency false set 
search bias algorithm attempts discover elements rre detail attribute features 
elements rre discovered extension process terminates 
semi supervised learning algorithm employs forward pruning algorithm begins simplest search search find root rre 
subsequently segments true false sets containing root element step extend rre 
certain complex descriptions pruned considered 
way overfitting problems avoided witten frank 
approach clearly greedy search algorithm 
step extend rre learning process algorithm chooses word part speech tag extended rre greater equal previous rre 
words fi rre th extension fi rre th extension refer relationship equation 
greedy algorithms information extraction globally optimal decision tree algorithms transformation learning 
approach different respect greedy algorithms achieve excellent results 
results portrayed section provide evidence approach achieves near optimal performance 
bias algorithm recall rre monotonically decreases extension rre learning process 
proof fact contained 
result approach initially places emphasis precision recall root discovery process 
way avoid overfitting learning process 
forward pruning uses simplest search stops sufficiently complex concept description please refer section witten frank 
precision bias algorithm learning process precision rre monotonically increases 
simplify proof fact substituting symbol 
suppose rre th extension rre th extension attribute learning process 
rre show segments covered covered rre rre rre learning process ei ei element simple rre discovered th extension 
string accepted take form accepts rre accepts si si substrings strings accepted rre implies segment containing substring accepted include substrings accepted rre discovery start rre special form learning process holds 
gap learning process gap learned smallest 
strings accepted rre smallest gap discovered accepted rre containing elements having larger gaps elements 
conclude segments covered containing strings accepted rre covered rre rre covered rre implies tp tp furthermore tp fni tpi fni obviously true set segments covered tp tp fn tp tp fn fig 

proof monotonically decreasing recall important rre discovered high precision 
due fact precision expression greater equal lowest precision constituent rres 
words precision high constituent rres high precision 
bias aids ensuring precision high 
target discover rres high precision high recall 
analysis clear inverse relationship precision recall cleverdon rre discovery 
suppose pi precisions rre th th extensions respectively learning process 
wish prove assuming ri fi ri fi fig 

proof monotonically increasing precision semi supervised learning algorithm covering algorithm 
rres discovered sequence extract features previously unseen data 
single constituent rre matches feature recall improves sacrificing precision 
due fact attribute rre covers true positives 
result rres sequence true positives increase false negatives decrease 
general precision recall fr fr equations assumption incorrect 
biases algorithm enable algorithm discover expressions high precision high recall measured 

active learning approach training set developer need label exact location features segments supervised machine learning algorithms approach involves manual labeling segments 
order reduce training set development overhead extended semi supervised learning algorithm active learning method 
active learning algorithm seeded description attribute 
example feet tall may seed height 
choices seeds semi supervised learning algorithm discovers rres representing contexts surrounding seeds 
segments similar contexts candidates inclusion true set attribute 
input seed discover context segments seed generate rules prefix suffix combine form contextual rules extract candidate true set segments contextual rules form true false sets preparation rre discovery active learning phase apply rre discovery algorithm discover rres current feature fig 

active learning flow chart training set developer need select candidates contain description attribute 
active learning phase semisupervised learning algorithm applied discover rres attribute process described section 
portrays flowchart active learning process 
approach observation local context leveraged aid discovery process 
example person age may follow race precede height suspect physical description 
segment occurs race height age segment 
follows provide details approach 

context pattern discovery steps involved discovery context seed 
segments containing seed training dataset extracted 
set segment containing seed 
second segments immediately preceding member defined segment segment immediately contains seed 
third segments immediately member defined segment segment immediately preceding contains seed 
forming employ semi supervised learning algorithm discover rres 
combine prefix pattern suffix pattern form complete contextual pattern operator 
discover rres prefix true set false set 
rres discovered semi supervised learning algorithm form set prefix rre 
discover suffix rres true set prefix false set 
rres discovered semi supervised learning algorithm form set suffix rre 
combinations members form contextual patterns discover candidates true set attribute consideration 
possible combinations members occur training data algorithm employs data driven approach ensures combinations occur input text 
noted final expression extracting candidate true set segments consists logical members segment gap 
refer final expression contextual expression follows 

active selection true segments step active learning algorithm identifies candidates attribute contextual expression discovered described section 
course candidates true positive segments point training set developer selects segments form final true set 
define true set ta segment accepted contextual expression attribute occurs 
remaining segments selected false set fa segment accepted contextual expression contain attribute 
attribute ratio true false segments sets generally greater ratio true false segments training data 
words substantially effort required develop sets semi supervised active learning approach required sets manually generated labeling single segment training data 
fact seen section reduction effort great 
seen section performance rres discovered sets competitive performance rre discovery manually labeled training data 
final true set attribute final false set content prefix noted true false sets generated active learning algorithm attribute semi supervised learning algorithm applied time discover expression extracts features attribute interest 
summary section described active learning algorithm combined semisupervised learning algorithm 
experimental results reported section provide evidence approach significantly reduces training set development effort time preserving performance terms 

experimental results section depict results application semi supervised learning algorithm fold cross validation police incident reports consisting segments 
average number training examples average number test examples attributes evaluated experimental results reported 
results application combined semisupervised active algorithm training dataset items segments independent test dataset items segments 
compare results obtained approaches 
table summarizes results semi supervised learning algorithm active learning 
noted employed fold cross validation 
different attributes evaluated table column 
eye color 
gender weekday perfect performance part modified lexicon noted section 
performance age date hair color height race excellent 
performance time weight attributes achieve 
result conclude rres discovered features high quality 
table 
results semi supervised non active learning attribute average precision average recall average average true positives age date time eye color gender hair color height race week day weight table depicts reduction training set development effort gained active learning algorithm 
results show active learning algorithm significantly reduces labeling effort attributes 
second column table ratio true segments false segments generated active learning algorithm described section 
third column ratio true segments false segments training dataset 
fourth column reduction labeling effort calculated value fourth column value third column value second column 
table 
labeling effort saved attribute ratio ta fa ratio true false segments reduction labeling effort training examples active learning age date time eye color gender hair color height race week day weight results age gender table due fact attributes occur different contexts training data 
particular gender occurs possible context 
words active learning approach efficient attribute widely distributed contexts training data 
note necessarily imply performance extraction degraded noted table gender maintains 
table 
results semi supervised active learning attribute precision recall number true positives age date time eye color gender hair color height race week day weight disadvantage active learning approach size true set generally smaller true set training data 
time attribute example true set generated active learning process contains segments ta true segments training set 
particular case semi supervised active learning algorithm exceeds performance semi supervised learning algorithm vs 
cases performance semi supervised active learning algorithm degraded compared semi supervised learning algorithm 
result due part aforementioned bias active learning algorithm number segments true set generated active learning process tend fewer actual number true segments training data 
table summarizes test set results attributes interest semi supervised active learning algorithm 
eye color gender weekday 
implies rres attributes stable 
noted time attribute better test result semi supervised learning algorithm 
performance date table nearly identical performance table 
eye color time date weekday semi supervised active learning algorithm achieves significant reduction labeling effort maintains performance equivalent performance semisupervised algorithm 
test performances hair color height race weight table performance achieved semi supervised algorithm table 
labeling effort reduced dramatically attributes 
reduction attributes see tradeoff exists training set development cost performance extraction 
semi supervised active learning approach age attribute important sub pattern age discovered active learning phase 
seed sub pattern covers segments 
contextual patterns generated general find similar patterns 
result test performance age degraded compared semisupervised algorithm 
evaluated semi supervised active learning algorithm collection narrative text university crime reports 
training set consisted reports segments test set contained reports segments 
attributes interest considered experiments date time item value gender 
fourth column table portrays reduction labeling effort attributes 
reduction dramatic date item value gender attributes 
test performance attributes quite depicted table 
precision 
date gender recall 
time perfect recall 
general semi supervised active learning algorithm performed attributes extracted online university crime reports 
table 
labeling effort saved ratio ta fa ratio true false segments reduction labeling effort date time item value gender table 
results semi supervised active learning recall number true positives date time item value gender summary section experimental results semi supervised semisupervised active learning algorithms 
semi supervised algorithm achieved table attributes interest 
combined semi supervised active learning algorithm achieved significant reductions training set development effort attributes considered collections training data trade certain attributes reduction training set development effort extraction performance 
attributes interest algorithm achieved table achieved 
section deal related information extraction efforts academic research projects commercial products 

related done field information extraction relatively little focused automatic discovery regular expressions 
section highlight efforts related regular expression discovery 
touch related relevance statistics comparison existing commercial products 
stephen soderland developed supervised learning algorithm whisk uses regular expressions patterns extract features semistructured narrative text 
whisk active learning system 
iteration learning process whisk requires human expert label specific features instances system generates rules labels 
whisk uses segments clauses sentences sentence fragments instances 
crucial difference whisk approach whisk requires user identify precise location features labeling approach requires selection small number seeds 
noted represents significant reduction effort required develop training set 
eric brill applied transformation learning tbl framework learn reduced regular expressions correction grammatical errors text 
brill perform explicit information extraction correction process involves identifying grammatical errors 
major differences brill approach 
aforementioned soderland brill approach requires intensive feature specific labeling create ground truth tbl 
secondly approach require domain experts create templates tbl 
michael chau jennifer xu chen published results research extracting entities narrative police reports chau xu chen 
employed neural network extract persona names addresses drugs items personal property reports 
noun phrases candidates name fairfax county virginia police incident reports online university crime reports 
entities 
readily apparent chau xu chen evidently employ similar approach researchers feature specific labeling required training set development 
cross validation results vary low high various entities 
approach achieve significantly better results limiting noun phrases 
instance example feature extracted height attribute noun phrase feet inches feet tall 
ellen riloff developed autoslog ts system discovers patterns relevance statistics exact labeling attributes 
approach extracts noun phrases training data 
generates possible patterns set pre defined templates 
tests pattern performance relevance statistics 
human experts review select important patterns 
active learning component semi supervised active learning algorithm thought relevance statistics 
hand approach require pre defined templates noted attributes extracted limited noun phrases 
furthermore approach generate patterns 
quite possible autoslog ts generate tens thousands patterns 
approach usually patterns attribute 
commercial tools support information extraction 
advanced systems ibm intelligent miner text 
time writing deficiency ibm intelligent miner text system support user defined feature extraction 
severely limits types attributes extracted example possible codes basis information extraction tools despite fact codes form basis nation advanced criminal justice information systems 
hand support manual creation user defined attribute extraction rules 
results high knowledge engineering training set rule development cost users tools 
contrast approach supports automatic discovery user defined attributes semi supervised active learning algorithm 
significantly reduces knowledge engineering training set development cost system 
addition segmentation algorithm flexible provided example 
supports sentences paragraphs segments research determined sub sentence segment segmentation required precisely extract certain attributes 
result segmentation algorithm enables users define segmentation methods 
key capability distinguishes approach tools reduced regular expressions represent patterns 
example uses manual pattern formation method assigning words input text bins pattern 
theoretically rules created powerful reduced regular expressions defined section conducted experiments empirically verify fact algorithm result theoretically able represent wider range patterns 
published results relating criminal justice measure performance currently available commercial systems 
commercial systems surveyed results published 
widely employed metric van rijsbergen achieved performance template element extraction task muc 
muc collection newspaper articles 
results published winner kdd challenge cup competition biomedical domain regev finkelstein landau feldman 
addition results technical report nih biomedical computing interest group seminar weir 
search publicly available information published information extraction performance results terms precision recall measure related criminal justice domain commercial products surveyed 
say products effectively criminal justice domain unable identify publicly available materials report performance terms metrics 

tasks ahead leverage contextual information surrounding segment improve performance rre discovery 
currently rres discovered cross segments 
nearby segments contain information helpful determining feature accepted rre valid 
example rre discovered person race described jj 
rre covers description animal color 
false positives accepted rre described large red segment described large red boxer sentence dog described large red boxer bit boy right arm hypothesize algorithm discover contextual rules previous segment contains animal attribute identified race race false positive rate reduced 
fact developed approach automatic discovery rules nature termed error driven boolean logic rule learning wu khan fisher pottenger 
plan discover contextual rules improve performance rres discovered semi supervised active learning algorithm 
applied semi supervised algorithm extraction problem solved patents wu pottenger 
problem solved patent identifies particular solution insufficiency prior art patent addresses 
current results preliminary nature 
achieved average precision average recall average fold cross validation 
considering complexity natural language expressions patents consider result promising 
addition feedback corporate sponsor developed metric measures number patents discover true positive problem solved 
performance metric 
research patent domain ongoing 
drawback semi supervised approach learning difficulty splitting sub rules overlap 
example age approximately years age different expressions person age 
word age discovered algorithm root rre situation representations occur equal frequency algorithm uninformed choice direction extend rre learning phase 
result final expression may contain single word age poor performance terms 
solution problem open question addressed course 

semi supervised active learning algorithm extension semi supervised algorithm information extraction police incident reports united states patents 
experiments demonstrate reduced regular expressions extract information useful law enforcement applications high degrees precision recall 
furthermore algorithm significantly reduces knowledge engineering training set rule development cost performing information extraction 
funded part pennsylvania state police psp subcontract lockheed martin 
gratefully acknowledge dr lockheed martin psp team assistance completing 
supported part eastman kodak gratefully acknowledge dr dan phelps kodak contributions research efforts 
project supported number ij cx awarded national institute justice office justice programs department justice 
points view document authors necessarily represent official position policies department justice pennsylvania state police lockheed martin eastman kodak 
grateful help khan lars li workers family members friends 
gratefully acknowledge continuing help lord jesus christ lives 


available www com product html 
available www com index htm brill 
transformation error driven learning natural language processing case study part speech tagging 
computational linguistics 
brill 

pattern disambiguation natural language processing 
proceedings joint sigdat conference empirical methods natural language processing large corpora 
chau xu chen 

extracting meaningful entities police narrative reports 
proceedings national conference digital government research los angeles california 
weir 

drug discovery information extraction technology 
nih biomedical computing interest group seminar 

available www com cleverdon 

inverse relationship recall precision 
journal documentation 
hopcroft ullman 

automata theory 
languages computation addison wesley 
ibm intelligent miner text 
available www ibm com software data 
description extractor system muc 
proceedings seventh message understanding conference muc fairfax virginia april may 
manning sch tze 
foundations statistical natural language processing 
mit press 
muc 
proceedings seventh message understanding conference 
morgan kaufmann 
code manual 
available www leds state resources code manual pdf 
available www com index html regev finkelstein landau feldman 

rule extraction experimental evidence biomedical domain kdd cup task 
sigkdd explorations 
reynar ratnaparkhi 

maximum entropy approach identifying sentence boundaries 
proceedings fifth conference applied natural language processing washington riloff 

automatically generating extraction patterns untagged text 
proceedings thirteenth national conference artificial intelligence pages 
soderland 

learning information extraction rules semi structured free text 
machine learning 
van rijsbergen 

information retrieval nd edition 
london butterworths 
witten frank 

data mining practical machine learning tools techniques java implementations 
morgan kaufmann 
wu pottenger 

semi supervised algorithm pattern discovery information extraction textual data 
seventh pacific asia conference knowledge discovery data mining pakdd 
wu pottenger 

supervised learning algorithm information extraction textual data 
proceedings workshop text mining third siam international conference data mining san francisco 
wu khan fisher pottenger 

error driven boolean logic rule learning mining chat room conversation 
lehigh university cse department technical reports 
lu cse 

