pe cep ua intelligence box martigny switzerland phone fax mail secretariat idiap ch internet www idiap ch automatic facial expression analysis survey beat fasel juergen luettin idiap rr november published pattern recognition idiap institut molle intelligence arti perceptive rue du cp martigny switzerland beat fasel idiap ch ag applicable research technology ch switzerland juergen luettin ch idiap research report automatic facial expression analysis survey beat fasel juergen luettin november published pattern recognition 
decade automatic facial expression analysis active research area nds potential applications areas engaging human computer interfaces talking heads image retrieval human emotion analysis 
facial expressions re ect emotions mental activities social interaction physiological signals 
survey introduce prominent automatic facial expression analysis methods systems literature 
facial motion deformation extraction approaches classi cation methods discussed respect issues face normalization facial expression dynamics facial expression intensity regard robustness environmental changes 
idiap rr listener responses conviction communication non verbal mental states physiological activities felt emotions manipulators facial expressions verbal communication emotions pain social regulators sources facial expressions 
facial expression analysis goes back nineteenth century 
darwin demonstrated universality facial expressions continuity man animals claimed things speci emotions originated associated habits 
ekman friesen postulated primary emotions possess distinctive content unique facial expression 
emotional displays referred called basic emotions 
universal human cultures comprise happiness sadness fear disgust surprise anger 
past facial expression analysis primarily research subject psychologists preliminary investigation automatic facial expression analysis image sequence 
nineties automatic facial expression analysis research gained inertia starting pioneering mase pentland 
reasons renewed interest facial expressions multiple mainly due advancements accomplished related research areas face detection face tracking face recognition availability relatively cheap computational power 
various applications automatic facial expression analysis envisaged near fostering interest doing research di erent areas including image understanding psychological studies facial nerve grading medicine face image compression synthetic face animation video indexing robotics virtual reality 
facial expression recognition confused human emotion recognition done computer vision community 
facial expression recognition deals classi cation facial motion facial feature deformation classes purely visual information human emotions result di erent factors state revealed number channels emotional voice pose gestures gaze direction facial expressions 
furthermore emotions source facial expressions see 
contrast facial expression recognition emotion recognition interpretation attempt demands understanding situation availability full contextual information 
facial expression measurement facial expressions generated contractions facial muscles results temporally deformed facial features eye lids eye brows nose lips skin texture revealed wrinkles 
typical changes muscular activities brief lasting seconds rarely seconds ms accurately measure facial expressions need useful terminology description 
importance location facial actions intensity dynamics 
facial expression intensities may measured determining geometric deformations facial features density wrinkles appearing certain face regions 
example degree smiling communicated idiap rr magnitude cheek lip corner raising displays 
inter personal variations regard amplitudes facial actions dicult determine absolute facial expression intensities referring neutral face subject 
note measuring intensity spontaneous facial expressions dicult measuring posed facial expressions usually displayed exaggerated intensity identi ed 
nature deformation facial features conveys meaning relative timing facial actions temporal evolution 
static images clearly reveal subtle changes faces essential measure dynamics facial expressions 
importance correct timing widely accepted studies investigated aspect systematically smiles 
facial expressions described aid temporal parameters onset attack apex sustain set relaxation 
obtained human coders lack precision 
studies relate problem automatically computing onset set facial expressions especially relying approaches facial emg 
main methodological approaches measure afore mentioned characteristics facial expressions message judgment sign vehicle approaches 
directly associate speci facial patterns mental activities represent facial actions coded way prior eventual interpretation attempts 
judgment approaches judgment approaches centered messages conveyed facial expressions 
classifying facial expressions prede ned number emotion mental activity categories agreement group coders taken ground truth usually computing average responses experts non experts 
automatic facial expression analysis approaches literature attempt directly map facial expressions basic emotion classes introduced ekman friesen 
sign approaches sign vehicle approaches facial motion deformation coded visual classes 
facial actions abstracted described location intensity 
complete description framework ideally contain possible perceptible changes may occur face 
goal facs facial action coding system developed ekman friesen considered foundation describing facial expressions 
appearance convey information mental activities associated expressions 
facs uses aus action units description facial actions regard location intensity levels magnitude 
individual expressions may modeled single action units action unit combinations 
similar coding schemes emotional facial action coding system max maximally discriminative facial movement coding system system identifying ect expressions 
directed emotions 
mpeg mpeg object multimedia compression standard synthetic natural hybrid coding standard encompasses analysis coding animation faces talking heads 
describing facial actions aid purely descriptive aus scores sign approaches may interpreted employing facial expression dictionaries 
friesen ekman introduced dictionary facs framework 
ekman database called facial action coding system ect interpretation database allows translate emotion related facs scores ective meanings 
emotion interpretations provided experts agreed ects included database 
reliability ground truth coding labeling employed databases determines system attempts recognize interpret facial expressions may uence achievable recognition accuracy especially comes facial expression timing intensity estimations 
furthermore chosen classi cation schemes ect design facial expression classi ers uence number nature facial action categories treated 
ekman points need addressed measuring facial expressions separate agreement index scoring speci facial actions typically actions easier recognize spontaneous posed facial actions various subjects including infants children adults aged populations limiting disagreement idiap rr basic emotions mental activities facial actions mapping coded facial features muscle illumination scale model parameters classification pattern face facial features separation component projection tracking motion extraction facial feature pose segmentation face representation facial feature motion background separation face normalization face facial expression models coding facial actions feature point images interpretation extraction image optical flow dense extraction tracking deformation recognition generic facial expression analysis framework 
encircled numbers system diagrams section indicate relevant processing stages 
note face normalization face segmentation facial feature representation stages necessary conjunction speci facial feature extraction classi cation methods 
judgment facial actions providing minimal intensity threshold facial actions inclusion expert beginners measurement facial actions reliability reported type intensity dynamics facial actions 
points probably easier ful lled sign judgment approaches provided limited labeling accuracy 
example single basic emotion category room interpretation 
cross cultural studies shown furthermore judgment facial expression culturally dependent partially uenced learned display rules 
afore mentioned basic emotions universal cultures assessment hampered encoder decoder di erent cultures 
sign coding schemes hand increase objectivity coders required record speci concerted facial components performing facial expression interpretation 
advantage sign methods possibility decomposing facial expression recognition facial expression interpretation 
performance employed analysis methods may evaluated directly regard visual performance 
automatic facial expression analysis automatic facial expression analysis complex task faces vary individual quite considerably due di erent age ethnicity gender facial hair cosmetic products occluding objects glasses hair 
furthermore faces appear disparate pose lighting changes 
variations addressed di erent stages automatic facial expression analysis system see 
closer look individual processing stages remainder chapter 
face acquisition ideally face acquisition stage features automatic face detector allows locate faces complex scenes cluttered backgrounds 
certain face analysis methods need exact position face order extract facial features interest coarse location face available 
case active appearance models 
hong hong system ste ens order perform realtime tracking faces 
exact face dimensions obtained tting labeled graph bounding box containing face previously detected system 
essa pentland located faces view modular eigenspace method pentland 
face analysis complicated face appearance changes caused pose variations illumination changes 
idea normalize acquired faces prior analysis pose appearance facial expressions depends angle distance face observed 
pose variations occur due scale changes plane plane rotations idiap rr deformation extraction holistic methods local methods image neural network intensity pro les gabor wavelets high gradient components pca neural networks model active appearance model geometric face model point distribution model view point models labeled graphs motion extraction holistic methods local methods dense optical flow dense ow elds region ow motion models motion models parametric motion models deformable models motion models feature point tracking feature tracking di erence images holistic di region di erence images marker highlighted facial features dot markers table facial feature extraction methods overview prominent deformation motion extraction methods task facial expression analysis :10.1.1.39.8427:10.1.1.39.8427
faces 
especially plane rotated faces dicult handle perceived facial expression distorted comparison frontal face displays may partly invisible 
limited rotations addressed warping techniques center positions distinctive facial features eyes nose mouth serve points order normalize test faces generic face models see 
scale changes faces may tackled scanning images resolutions order determine size faces normalized accordingly 
illumination common approach reducing lighting variations lter input image gabor wavelets see 
dicult solve problem partly faces addressed task face recognition belhumeur suciently facial expression analysis 
specular re ections eyes teeth wet skin may encountered brightness models 
note face normalization may reasonable approach conjunction face analysis approaches mandatory long extracted feature parameters normalized prior classi cation 
appearance model local motion model approaches dealt signi cant plane rotations relying face normalization 
facial feature extraction representation feature extraction methods categorized focus motion deformation faces facial features respectively act locally holistically 
table gives overview methods employed computer vision community task facial expression analysis 
local versus holistic approaches facial feature processing may take place holistically face processed locally focusing facial features areas prone change facial expressions 
distinguish types facial features facial features face may deformed due facial expressions 
eyelids eyebrows mouth mainly involved facial expression displays 
tissue texture facial hair permanent furrows constitute types facial features uence appearance facial expressions 
transient facial features encompass di erent kind wrinkles occur facial expressions 
especially forefront regions surrounding mouth eyes prone contain transient facial features 
opening closing eyes mouth may furthermore lead iconic changes local changes texture predicted antecedent frames 
idiap rr face segmentation allows isolate transient features faces separate faces interest background 
segmentation boundaries determined heuristically guidance provided priori knowledge human observers 
note holistic feature extraction methods determining prevalent facial expressions local methods able detect subtle changes small areas 
suitable especially rule interpretation attempts see 
deformation versus motion approaches motion extraction approaches directly focus facial changes occurring due facial expressions deformation methods rely neutral face images face models order extract facial features relevant facial actions caused wrinkles due old age 
contrast motion approaches deformation methods applied single images image sequences case processing frames independently 
feature extractors low level directional ow information reconstruct pixel motion 
high level motion facial features may inferred face facial feature models allow estimate possible ow directions 
image versus model approaches image methods extract features images relying extensive knowledge object interest 
advantage typically fast simple 
image approaches unreliable unwieldy di erent views object considered 
facial structure described aid face models 
allow model facial features faces appearance attempting recover volumetric geometry scene see 
types models muscle motion models 
signi cantly improve precision motion estimations physically possible motion considered 
models require complex mapping procedures generate heavy computational requirements 
addition accurate head face models constructed manually tedious undertaking 
appearance versus muscle approaches contrast appearance image model approaches processing focuses ects facial muscle activities muscle frameworks attempt interfere muscle activities visual information 
may achieved muscle models allow map extracted optical ow muscle actions 
modeled facial motion restricted muscle activations allowed muscle framework giving control possible muscle contractions relaxation orientation properties 
face complex information readily muscle motion directly observable 
example thirteen groups muscles involved lip movements 
mase pentland complex models determine muscle activities 
translated motion prede ned windows directly coarse estimate muscle activity 
muscle approaches suited recognition facial expression animate synthetic faces 
deformation extraction deformation facial features characterized shape texture changes lead high spatial gradients indicators facial actions may analyzed image spatial frequency domain 
computed high pass gradient gabor wavelet lters closely model receptive eld properties cells primary visual cortex 
allow detect line endings edge borders multiple scales di erent orientations 
features reveal lot facial expressions transient facial features give raise contrast change regard ambient facial tissue 
mentioned gabor lters remove variability images occur due lighting changes 
shown perform task facial expression analysis image approaches combination labeled graphs 
illustration gabor lters applied face images see 
idiap rr test faces au au au gabor representations resolution facial feature extraction gabor wavelets shown distinct facial expression displays left hand side corresponding gabor representations right hand side 
obtained face images left hand side di erently oriented wavelet kernels resolution 
distinguish holistic local image deformation extraction approaches holistic image approaches authors taken faces features gabor wavelet ltered faces 
main emphasis put classi er deal face case image domain face processing lighting variations 
common holistic face analysis approaches need thorough face background separation order prevent disturbance caused clutter 
local image approaches cottrell cottrell metcalfe extracted facial expressions windows placed facial feature regions eyes mouth employed local principal component analysis pca representation purposes 
local transient facial features wrinkles measured image intensity pro les segments determining density high gradient components windows interest 
model approaches constitute alternative image deformation extraction 
model approaches allow separate fairly di erent information sources facial illumination deformation changes 
lanitis interpreted face images employing active appearance models aam 
faces analyzed dual approach shape texture models 
active shape models asm allow simultaneously determine shape scale pose tting appropriate point distribution model pdm object interest see 
drawback appearance models manual labor necessary construction shape models 
landmark points need precisely placed facial features training models 
huang huang pdm represent shape face shape parameters estimated employing gradient method 
type holistic face models constitute called labeled graphs comprised sparsely distributed ducial feature points 
nodes feature graphs consist gabor jets component jet lter response speci gabor wavelet extracted image point 
labeled graph matched test face varying scale position 
obtained graph compared graphs order determine facial expression display hand 
kobayashi hara geometric face model consisting facial characteristic points fcp 
measured intensity distribution vertical crossing facial lines aid neural network 
pantic rothkrantz point model composed frontal side views 
multiple feature detectors applied redundantly order localize contours prominent facial features prior modeling 
idiap rr point distribution modes point models mode mode mode mode mode mode mode mode mode mode mode mode mode mode au au low au au high au au high neutral au au low facial feature representation active shape models rst row shows manually placed point models pm employed create point distribution model represented discrete instances point distribution modes shown row mode mode intensities ranging 
point distribution modes computed active shape model toolbox implemented matthews 
motion extraction motion extraction methods task facial expression analysis nd dense optical ow feature point tracking di erence images 
dense optical ow applied locally holistically holistic dense optical flow approaches allow face analysis employed 
lien analyzed holistic face motion aid wavelet multi resolution dense optical ow 
representation resulting ow elds computed pca eigen ows horizontal vertical directions 
shows sample dense optical ow elds computed facial expression sequences 
local dense optical flow region dense optical ow mase pentland order estimate activity totally facial muscles 
muscle window face image de ned axis muscle expands contracts 
dense optical ow motion quanti ed directions allowed coarse estimation muscle activity 
ohya estimated facial motion local regions surrounding eyes mouth 
feature vectors obtained fourier transforms vertical horizontal optical ow elds 
divided normalized test faces regions local dense optical ow computed quanti ed region wise ternary feature vectors indicating upwards downwards movements neglecting horizontal facial movements 
di erent optical ow algorithms applied facial motion analysis 
instance lien employed wu approach optical ow estimate facial motion scaling functions wavelets cai wang capture local global facial characteristics 
essa simoncelli coarse ne optical ow yacoob davis rosenblum employed optical ow 
apart certain vulnerability image noise non uniform lighting holistic dense optical ow methods result computational requirements tend sensitive motion discontinuities iconic changes non rigid motion 
optical ow analysis done conjunction motion models allow increased stability better interpretation extracted facial motion muscle activations idiap rr au au au au au au facial motion extraction dense optical flow shown sample facial expression sequences left hand side corresponding optical ow images right hand side computed nagel algorithm 
note asymmetric facial action display lower facial expression sequence 
idiap rr holistic motion models terzopoulos waters eleven principal deformable contours known snakes track lip facial features image sequences aid force eld computed gradients images 
frontal faces allowed facial enhance contrast 
essa pentland employed sophisticated motion muscle models facial expression recognition increased tracking stability kalman ltering 
decarlo metaxas formal methodology integration optical ow deformable models applied human face shapes facial motion estimation 
relatively small number parameters describe rich variety face shapes facial expressions 
girod employed face models specify shape texture motion 
models describe facial expressions caused speech parameterized mpeg coding scheme 
local motion models black yacoob yacoob davis introduced local parametric motion models allow local regions space time accurately model non rigid facial motions provide concise description motion associated edges mouth nose eyelids eyebrows terms small number parameters 
employed motion models focus main facial features involved facial expressions eyes eye brows mouth analysis transient facial features occurring residual facial areas considered 
basu convincing approach track human lip motions models 
addition low level dense optical ow higher level variants focus movement generic features points patterns markers feature point tracking motion estimates obtained selected set prominent facial features :10.1.1.39.8427:10.1.1.39.8427
order reduce risk tracking loss feature points placed areas high contrast preferably facial features illustrated right hand side 
facial movement deformation measured tracking displacement corresponding feature points 
motion analysis directed objects interest computed extraneous background patterns 
facial motion extracted selected feature point locations facial activities ignored altogether 
automatic initialization feature points dicult done manually 
ohya feature point tracking approach feature points selected human expertise chosen automatically rst frame facial expression sequence 
achieved acquiring potential facial feature points local extrema saddle points luminance distributions 
tian di erent component models lips eyes brows cheeks employed feature point tracking adapt contours models deformation underlying facial features :10.1.1.39.8427:10.1.1.39.8427
rosenblum tracked rectangular facial feature enclosing regions interest aid feature points 
marker tracking possible determine facial actions reliability previously discussed methods measuring deformation areas underlying muscles interact 
unfortunately skin regions relatively poor texture 
highlighting necessary done applying color salient facial features skin colored plastic dots prede ned locations subject face see illustration left hand side 
markers allow render tissue motion visible employed 
note tracking feature points markers allows extract motion relative feature point locations deformation information analysis facial expressions :10.1.1.39.8427:10.1.1.39.8427
way extract image motion di erence images speci cally facial expression analysis di erence images created subtracting facial image previously registered image containing neutral face subject 
comparison optical ow approaches ow direction extracted di erences image intensities 
addition accurate face normalization procedures necessary order align faces test faces 
holistic di erence image motion extraction employed 
choudhury pentland motion eld histograms modeling eye eye brow actions 
motion extracted di erence images taken consecutive image frames processed idiap rr marked test faces extracted marker pattern tracked feature points marker test faces feature point tracking marker tracking au au au au neutral neutral neutral neutral au au au au marker versus feature point tracking left hand side shown faces markers 
corresponding extracted marker patterns depicted column 
scale normalized distances marker points allow determine underlying muscle activities 
marker feature point tracking approach shown right hand side 
feature points pixel windows determine displacement eyebrows 
local receptive eld histograms order increase robustness regard rotation translation scale changes 
classi cation feature classi cation performed stage automatic facial expression analysis system 
achieved attempting facial expression recognition sign facial action coding schemes interpretation combination judgment sign dictionary frameworks 
distinguish spatial spatio temporal classi er approaches spatio temporal approaches hidden markov models hmm commonly eld speech recognition useful facial expression analysis allow model dynamics facial actions 
hmm classi cation approaches literature employed conjunction image motion extraction methods 
recurrent neural networks constitute alternative hmms task facial expression classi cation 
way temporal evolution facial expression account called spatio temporal motion energy templates 
facial motion represented terms motion elds 
euclidean distance templates estimate prevalent facial expression 
spatial approaches neural networks facial expression classi cation applied directly face images combined facial features extraction representation methods pca principal component analysis ica independent component analysis gabor wavelet lters 
unsupervised statistical analysis methods allow considerable dimensionality reduction simpli es enhances subsequent classi cation 
methods employed holistic manner locally mosaic patches extracted small facial regions 
cottrell applied local pca gabor jets task facial expression recognition obtained quantitatively indistinguishable results representations 
shows illustration pca ica components obtained facial expression images 
unfortunately neural networks dicult train classi cation basic emotions unconstrained facial expressions 
problem great number possible facial action combinations au combinations identi ed facs framework 
idiap rr ica components pca components difference images facial feature representation data driven methods sample di erence images shown rst row corresponding holistic ica components second pca components third row 
di erence images computed subtracting neutral face image face images displaying facial actions 
alternative classically trained neural networks constitute compiled rule neural networks employed 
facial expression recognition traditional approaches modeling characteristics facial motion deformation relied handcrafted rules symbolic mid level representations emotional states introduced computer scientists course investigations facial expressions 
human expertise necessary map symbolic representations emotions 
facial signals consist numerous distinct expressions speci facial action intensity evolutions 
addition individual realizations facial expressions di er subtle ways 
task manually creating facial expression classes dicult 
group researchers relied facial expression coding schemes mpeg facs :10.1.1.39.8427:10.1.1.39.8427
essa pentland proposed extension facs called facs consist set control parameters vision observations 
contrast facs facs describes dynamics facial expressions 
facial expression interpretation automatic facial expression analysis systems literature attempt directly interpret observed facial expressions terms basic emotions 
systems rules facial expression dictionaries order translate coded facial actions emotion categories 
approaches advantage accurately describing facial expressions resorting interpretation allow animate synthetic faces facs coding framework 
interest animated synthetic faces direct inspection automatically recognized facial expressions possible 
see automatic facial expression interpretation 
representative facial expression recognition systems section closer look representative facial expression analysis systems 
discuss deformation motion feature extraction systems 
introduce hybrid facial expression analysis systems employ image analysis methods complete allow better performance 
multi modal frameworks hand integrate non verbal communication channels improved facial expression interpretation results 
uni ed frameworks focus multiple facial characteristics allowing synergy ects di erent modalities 
idiap rr deformation extraction systems cottrell automatic facial expression interpretation system capable identifying basic emotions 
facial data extracted pixel blocks placed eyes mouth projected top pca eigenvectors random patches extracted training images 
classi cation normalized projections fed ensemble neural networks 
output summed normalized dividing average outputs possible emotion networks respective deviation entire training set 
largest score particular input considered emotion ensemble networks 
altogether images emotions males females analyzed generalization performance measured novel face images 
lyons gabor wavelet facial expression analysis framework featuring node grid gabor jets similar von der malsburg group task face recognition 
test image convolved set gabor lters responses highly correlated redundant neighboring pixels 
necessary acquire samples speci points sparse grid covering face 
projections lter responses discriminant vectors calculated training set compared corresponding spatial frequency orientation locations face images normalized dot product measure similarity gabor response vectors 
lyons placed graphs manually faces order obtain better precision task facial expression recognition 
experiments carried subsets totally di erent posed expressions neutral faces japanese female undergraduates 
generalization rate obtained recognition new expressions known subjects recognition facial expressions novel 
motion extraction systems black yacoob analyzed facial expressions parameterized models mouth eyes eye brows represented image ow low order polynomials 
concise description facial motion achieved aid small number parameters derived mid high level description facial actions 
considered temporal consistency mid level predicates order minimize ects noise inaccuracies regard motion deformation models 
facial expression modeled registering intensities mid level parameters temporal segments apex 
extensive experiments carried subjects laboratory correct recognition rate television movie sequences resulting correct recognition rate 
black yacoob proved recognition basic emotions possible presence signi cant pose variations head motion 
essa pentland complete computer vision system featuring automatic face detection face analysis 
facial motion extracted aid holistic dense optical ow coupled motion muscle face models 
allowed describe facial structure including facial tissue muscle actuators force deformation 
essa pentland located test faces automatically view modular eigenspace method determined position facial features 
employed order warp face images match canonical face meshes turn allowed extract additional feature points corresponding xed nodes meshes 
initial model image registration simoncelli coarse ne optical ow compute image motion 
addition kalman lter control framework applied order prevent chaotic responses physical system 
employed dynamic face model allowed extract muscle observed facial expressions possible produce noise corrected motion elds control theoretic approach 
classi ed motion energy templates order extract facial actions 
experiments carried frontal view image sequences correct recognition rate muscle motion energy models 
hybrid systems hybrid facial expression analysis systems combine facial expression analysis methods 
bene cial individual estimators produce di erent error patterns 
bartlett proposed system integrates holistic di erence image motion extraction coupled pca feature measurements prede ned intensity pro les estimation wrinkles holistic dense optical ow face idiap rr facs representation actions recognition extraction extraction zation normalization segmentation facial expression facial feature deformation motion code manual interpretation mental activity categories feature facial matches difference images profile measures face face lower part upper part profiles intensity template flow neural pca network projections dense optical flow warping scaling hybrid facial expression analysis system proposed bartlett 
analysis methods employed showed produce di erent error patterns allow improved recognition performance combined 
motion extraction see 
methods compared regard contribution task facial expressions recognition 
bartlett estimated feature measurement decrease facial expression recognition improvement gained methods combined 
faces normalized alignment scaling rotation warping aspect ratios 
eye mouth centers located manually neutral face frame test sequence start 
facial expression recognition achieved aid feed forward neural network hidden output units 
input neural network consisted pca component projections feature density measurements optical ow template matches 
winner takes wta judgment approach chosen select nal au candidates 
initially bartlett hybrid facial expression analysis system able classify upper facs action units database containing subjects correctly recognizing au activations au intensities 
extended allow classi cation lower facs action units achieved accuracy lower upper face actions 
cohn lien introduced systems holistic image ow analysis feature point tracking high gradient component analysis methods integrated spatio temporal framework combined hmm recognition stage see 
local face motion estimated feature point tracking 
pyramidal multi scale search approach employed sensitive subtle feature motion allowed track large displacements feature motion sub pixel accuracy 
holistic facial motion hand estimated employing wu multi resolution wavelet optical ow 
forehead cheek chin regions analyzed transient facial features component analysis horizontal vertical diagonal line edge detectors spatial domain frame comparisons temporal domain 
allowed separate transient facial features hair occlusion 
face tracking face alignment manually initialized selecting facial feature points rst frame test image sequence 
lien system trained analyze activity intensity facs aus situated brow eye mouth regions 
holistic dense optical ow approach gave best average au recognition rates followed feature point tracking high gradient component analysis approach see table 
lien facial expression analysis system performed dicult sequences containing baby faces 
di er adult faces morphology tissue texture 
unfortunately heavy computational requirements optical ow 
uni ed frameworks facial expression recognition may improved considering facial actions face characteristics identity gender age ethnicity 
lanitis proposed uni ed framework employs active shape models yield aligned test face face appearance parameters possible estimate pose identity gender facial expressions 
training shape models derived set images statistical analysis landmark point positions 
represent main facial features placed manually training images prior shape model creation process see 
testing facial features located test idiap rr facs facs actions intensity representation frame deformation motion facial expression interpretation code normalization segmentation facial feature point zation recognition extraction extraction mental activity categories manual feature motion shortest distance max 

hmm projection distribution gradient vector pca ment vector point feature optical dense transient gradient flow face image lation scale rotation rigid component analysis regions hybrid facial expression analysis system proposed lien 
facial expression analysis framework situated spatio temporal domain including classi cation stage driven hidden markov models hmm 
authors subjects faces facs extraction classi cation rec 
test train test train aus methods methods rate di img jets near 
neigh 
bartlett di img 
ica neigh 
optical flow motion 
fasel di img 
ica eucl 
dist cohn feat 
point track 
hmm feat 
point track 
hmm feat 
point track 
hmm lien optical flow pca hmm high grad 
comp 
hmm high grad 
comp 
hmm pantic multi feat 
detect 
expert rules table selected facial expression recognition systems classi cation facial actions facs 
upper face facs coding 
lower face facs coding 
asymmetric facs classes intensity levels face sides 
idiap rr representation basic emotions categories motion manual face normalization segmentation code facial feature facial expression interpretation recognition extraction extraction mental activity face zation warping image masking face distance matches patch free model fitting shape model uni ed facial expression analysis framework proposed lanitis 
active shape models asm 
shape information extract shape free face patches represent texture information 
image asm search guided exible shape models obtained training 
gray level pro le information collected model point determine best tting shape model 
lanitis deformed test faces mean face shape previously registered shape information order extract holistic shape patches account facial texture 
hong proposed online facial expression recognition system personalized galleries uses identity information conjunction facial expression analysis 
faces interest detected tracked live video sequences aid system recognition facial expressions achieved performing elastic graph matching 
nodes employed graphs comprised gabor jets tted test faces 
obtained graph rst determine identity subject choosing closest matching graph 
second stage closest matching graph personalized gallery identi ed person determine displayed facial expression allowing better focus intra personal variations 
multimodal frameworks today facial expression analysis systems unimodal type focus facial expressions determining mental activities 
evaluation multiple communication channels may foster robustness improve correct interpretation facial expressions ambiguous situations 
attempts channel fusion bimodal type integrate voice addition facial expressions 
vocal expressions conveyed prosodic features include fundamental frequency intensity rhythm voice 
cohn katz chen focused fundamental frequency important voice feature emotion recognition easily extracted 
discussion survey automatic facial expression analysis discussed automatic face analysis regard di erent motion deformation extraction methods model image representation techniques recognition interpretation classi cation approaches 
possible directly compare facial expression recognition results face analysis systems literature due varying facial action labeling di erent test beds assessment 
complete facial expression database kanade 
lack publicly available encompassing facial expression databases allow testing facial expression analysis methods transparent way 
tried characterize selected systems regard employed feature extraction classi cation methods 
table lists systems perform facial expression recognition classifying facial actions table presents systems attempt direct interpretation emotional facial displays indirect interpretation facial expression dictionaries 
application currently available automatic facial expression recognition systems restricted due limited robustness hard constraints imposed recording conditions 
systems assume faces centered input image seen near frontal view test sequence 
idiap rr authors subjects faces em 
extraction classi cation rec 
test train test train class 
methods methods rate lyons wav el gr 
lda pca cl kobayashi feed forw 
nn rosenblum sq 
sq 
optical flow rbf nn pca nn essa sq 
sq 
opt motion 
lanitis appear 
mod 

distance black sq 
motion mod 
expert rules pantic mul 
feat 
det expert rules table selected facial expression interpretation systems classi cation emotional displays 
note systems rows perform facial action recognition prior dictionaries order interpret facial actions 
taken granted small rigid head motions consecutive frames 
addition facial expression analysis systems require important manual intervention detection accurate normalization test faces initialization facial feature tracking approaches warping video sequences 
facial expression analysis systems limited analysis static images image sequences 
ideal system capable analyzing static images image sequences image sequence available respectively motion extracted order obtain directional information skin facial feature deformation 
measurement facial expression intensities addressed systems 
importance interpretation facial expressions especially attempting analyze temporal evolution timing facial actions 
plane rotated faces dicult tackle approaches literature able deal problem active appearance models local parametric models motion models degree feature point tracking approaches :10.1.1.39.8427:10.1.1.39.8427
hybrid facial expression analysis systems interest combine di erent face analysis methods may give better recognition results individual methods applied 
true employed extraction algorithms focus di erent facial features combined extraction representation recognition stages produce di erent error patterns 
today facial expression analysis systems attempt map facial expressions directly basic emotional categories unable handle facial actions caused non emotional mental physiological activities 
facs may provide solution dilemma allows classify facial actions prior interpretation attempts 
far marker systems able reliably code facs action unit activities intensities 
done eld automatic facial expression interpretation regard integration communication channels voice gestures 
facial expressions occur conversations cited approaches consider possibility 
automatic facial expression analysis systems operated autonomously current feature extraction methods improved extended regard robustness natural environments independence manual intervention initialization deployment 
abdel chellappa rosenfeld 
binocular motion stereo map estimation 
ieee cvpr pages 
bartlett 
face image analysis unsupervised learning redundancy reduction 
phd thesis university california san diego 
idiap rr bartlett viola sejnowski golomb larsen hager ekman 
classifying facial action 
advances neural information processing systems volume 
mit press 
blake 
separability pose expression facial tracking animation 
proceedings international conference computer vision 
basu oliver pentland 
modeling tracking human lip motions 
proceedings iccv bombay india january 
belhumeur hespanha kriegman 
eigenfaces vs fisherfaces recognition class speci linear projection 
ieee transactions pattern analysis machine intelligence 
bergen anandan hanna hingorani 
hierarchical model motion estimation 
sandini editor second european conference computer vision eccv volume lncs series pages 
springer verlag may 
black fleet yacoob 
framework modeling appearance change image sequences 
sixth international conference computer vision iccv 
ieee computer society press january 
black yacoob 
recognizing facial expressions image sequences local parameterized models image motion 
international journal computer vision 
cai wang 
adaptive multiresolution collocation methods initial boundary value problems nonlinear pdes 
society industrial applied mathematics june 
chen huang 
multimodal human emotion expression recognition 
proceedings international conference automatic face gesture recognition fg nara japan april 
ieee 
choudhury pentland 
motion field histograms robust modeling facial expressions 
proceedings international conference pattern recognition icpr barcelona spain september 
cohn katz 
bimodal expression emotion face voice 
workshop face gesture recognition applications sixth acm international multimedia conference september 
cohn lien wu kanade 
automated face coding method facial expression analysis 
th european conference facial expression measurement meaning pages july 
cootes taylor lanitis 
multi resolution search active shape models 
th international conference pattern recognition volume pages los alamitos california 
ieee cs press 
cootes edwards taylor 
active appearance models 
university manchester wolfson image analysis unit department medical biophysics 
cottrell metcalfe 
face gender emotion recognition holons 
lippman moody touretzky editors advances neural information processing systems volume pages 
cottrell 
pca gabor expression recognition 
technical report cs ucsd 
darwin 
expression emotions man animals 
murray london 
daugman 
complete discrete gabor transform neural networks image analysis compression 
ieee transactions acoustics speech signal processing 
idiap rr decarlo metaxas 
integration optical flow deformable models applications human face shape motion estimation 
proceedings international conference computer vision pattern recognition cvpr pages 
donato bartlett hager ekman sejnowski 
classifying facial actions 
ieee transactions pattern analysis machine intelligence october 
marchal wang rubinstein sei poon lun ng 
review objective topographic facial nerve evaluation methods 
american journal september 
edwards cootes taylor 
face recognition active appearance models 
proceedings fifth european conference computer vision eccv volume pages university freiburg germany june 
girod 
facial expression analysis model coding video sequences 
picture coding symposium pages september 
ekman 
brows emotional conversational signals 
con editors human ethology pages 
cambridge university press 
ekman 
emotions human face 
cambridge university press 
ekman 
methods measuring facial actions 
scherer ekman editors handbook methods nonverbal behaviour research pages 
cambridge university 
ekman friesen 
constants cultures face emotion 
journal personality social psychology 
ekman friesen 
facial action coding system technique measurement facial movement 
consulting psychologists press palo alto 
ekman rosenberg hager 
facial action coding system ect interpretation database 
com expression html july 
essa pentland 
facial expression recognition dynamic model motion energy 
ieee proceedings th international conference computer vision iccv pages cambridge ma 
essa pentland 
coding analysis interpretation recognition facial expressions 
ieee transactions pattern analysis machine intelligence 
beat fasel juergen luettin 
recognition asymmetric facial action unit activities intensities 
proceedings international conference pattern recognition icpr barcelona spain 
taylor 
comparing template supervised classi cation facial expressions static images 
proceedings circuits systems communications computers pages 
friesen ekman 
emotional facial action coding system 
unpublished manual 
friesen ekman 
dictionary interpretation facs scoring 
unpublished manuscript 

physiology speech production 
academic press new york ny 
hoch girod 
modeling animation facial expressions 
visual computer pages november 
hai hong hartmut neven christoph von der malsburg 
online facial expression recognition personalized galleries 
proceedings second international conference automatic face gesture recognition fg pages nara japan april 
ieee 
idiap rr huang huang 
facial expression recognition model feature extraction action parameters classi cation 
journal visual communication image representation 
izard 
maximally facial movement coding system max 
available instructional resource center university delaware newark delaware 
izard dougherty 
system ect expressions holistic judgments 
unpublished manuscript 
kaiser 
automated coding facial behavior human computer interactions facs 
journal nonverbal behavior 
kanade cohn tian 
comprehensive database facial expression analysis 
ieee proceedings th international conference automatic face gesture recognition fg march 

emotion recognition feature extraction models 
proceedings imacs international multiconference circuits systems communications computers pages athens greece 
kimura yachida 
facial expression recognition degree estimation 
ieee conference computer vision pattern recognition pages june 
kobayashi hara 
dynamic recognition basic facial expressions discrete time recurrent neural network 
proceedings international joint conference neural network pages 
kobayashi hara 
facial interaction animated face robot human beings 
proceedings international conference systems man cybernetics pages 
lades buhmann lange von der malsburg 
distortion invariant object recognition dynamic link architecture 
ieee transactions computers volume pages 
lanitis taylor cootes 
automatic interpretation coding face images flexible models 
ieee transactions pattern analysis machine intelligence 
lien 
automatic recognition facial expression hidden markov models estimation expression intensity 
phd thesis robotics institute cmu april 
lien kanade cohn li 
automated facial expression recognition facs action units 
ieee proceedings second international conference automatic face gesture recognition fg nara japan april 
rumelhart 
facial expression recognition neural network 
proceedings th international flairs conference 
aaai press 

automatic facial expression interpretation human computer interaction arti cial intelligence cognitive science intersect 
pragmatics cognition special issue facial information processing multidisciplinary perspective 
lyons akamatsu 
automatic classi cation single facial images 
ieee transactions pattern analysis machine intelligence december 
mase pentland 
recognition facial expression optical flow 
ieice transactions october 
matsumoto 
cultural similarities di erences display rules 
motivation emotion 
matsumoto 
ethnic di erences ect intensity emotion judgments display rules emotional expression 
motivation emotion 
idiap rr matthews 
active shape model toolbox 
university east uk july 
matlab toolbox version 
fogel dickson 
smile 
developmental psychology 
nagel 
estimation optical flow relations di erent approaches new results 
arti cial intelligence 
oliver pentland 
real time lips face tracker facial expression recognition 
proceedings ieee conference computer vision cvpr juan puerto rico 
ohya 
extracting facial motion parameters tracking feature points 
proceedings international conference advanced multimedia content processing pages november 
ohya 
spotting segments displaying facial expression image sequences hmm 
ieee proceedings second international conference automatic face gesture recognition fg pages nara japan april 
cottrell 
representing face image emotion classi cation 
mozer jordan petsche editors advances neural information processing systems volume pages cambridge ma 
mit press 
cottrell 
categorical perception facial emotion classi cation 
proceedings th annual conference cognitive science society 
pantic rothkrantz 
expert system automatic analysis facial expression 
image vision computing journal 
pentland moghaddam starner 
view modular eigenspaces face recognition 
ieee conference computer vision pattern recognition pages 
pollen 
phase relationship adjacent simple cells visual cortex 
science 
rob 
mpeg project overview 
international organisation iso iec jtc sc wg la october 
rosenblum yacoob davis 
human expression recognition motion radial basis function network architecture 
ieee transactions neural networks 
rowley baluja kanade 
neural network face detection 
ieee transactions pattern analysis machine intelligence january 
schiele crowley 
probabilistic object recognition multidimensional receptive field histograms 
proceedings international conference pattern recognition icpr vienna austria august 
schwartz fair salt mandel 
facial expression imagery depression study 
medicine 
simoncelli 
distributed representation analysis visual motion 
phd thesis massachusetts institute technology 
ste ens neven 
fast robust system human detection tracking recognition 
proceedings second international conference face gesture recognition fg pages nara japan april 

preliminary note pattern recognition human emotional expression 
proceedings th international joint conference pattern recognition pages 
idiap rr terzopoulos waters 
analysis facial images physical anatomical models 
proceedings third international conference computer vision pages 
tian kanade cohn :10.1.1.39.8427:10.1.1.39.8427
recognizing action units facial expression analysis 
ieee transactions pattern analysis machine intelligence february 

fuzzy system emotion classi cation mpeg facial de nition parameter 
european association signal processing eusipco 
wang yachida 
expression recognition time sequential facial images expression change model 
ieee proceedings second international conference automatic face gesture recognition fg pages nara japan april 
wu kanade cohn li 
optical flow estimation wavelet motion model 
ieee international conference computer vision pages bombay india january 
yacoob davis 
recognizing human facial expression long image sequences optical flow 
ieee transactions pattern analysis machine intelligence 
shirai 
facial expression recognition discrete hop eld neural networks 
proceedings international conference image processing icip volume pages 
zhang lyons schuster akamatsu 
comparison geometry facial expression recognition multi layer perceptron 
ieee proceedings second international conference automatic face gesture recognition fg pages nara japan april 
zhao kearney 
classifying facial emotions backpropagation neural networks fuzzy inputs 
proceedings international conference neural information processing volume pages 
