transport layer approach achieving aggregate bandwidths multi homed mobile hosts due availability wide variety wireless access technologies mobile host potentially subscriptions access wireless network time 
consider multi homed mobile host address problem achieving bandwidth aggregation striping data multiple interfaces mobile host 
show link layer striping approaches application layer techniques stripe data multiple tcp sockets achieve optimal bandwidth aggregation due variety factors specific wireless networks 
propose transport layer approach called ptcp effectively performs bandwidth aggregation multi homed mobile hosts 
show simulations ptcp achieves desired goals variety network conditions 
categories subject descriptors computer communication networks network protocols general terms algorithms design performance keywords multi homed mobile host bandwidth aggregation striping 
explosive growth number mobile internet users accompanied equally staggering increase number wireless access technologies 
mobile user today choose myriad options ranging networks iridium satellite access cdpd gprs edge wide area access ricochet metropolitan area access ieee sponsored national science foundation award 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
mobicom september atlanta georgia usa 
copyright acm 
hung yun hsieh sivakumar school electrical computer engineering georgia institute technology atlanta ga usa ece gatech edu hiperlan networks local area access 
interesting obvious challenge arises independent options exist technologies exist providing best wireless access possible mobile users 
step addressing challenge approaches proposed performing vertical handoffs network mobile user migrates coverage areas 
coverage areas networks overlap say wide area local area user provided access higher data rate connection 
consider identical scenario mobile host having multiple wireless interfaces 
mobile host provided access interfaces consider problem providing simultaneous access active interfaces 
example user subscribed wide area wireless network data rate mbps indoors systems local area wireless network effective data rate mbps ieee assuming user range access points networks address question application requires reliable sequenced delivery data provided data rate mbps interfaces 
tcp far dominant protocol reliable sequenced data delivery tcp discussions henceforth generic term sockets refer tcp sockets 
simple approach aggregate bandwidths multiple sockets active interface application layer striping 
fact similar schemes proposed improve application layer throughput albeit different context striping done sockets share long fat path goal fill bandwidth delay product path impossible ends supporting window scaling option 
context multi homed mobile hosts turns approach fails achieve aggregate data rate specific case connections having vastly differing products result effective aggregate data rate lower data rate slowest connection 
identify reasons involved discuss detail section briefly performance degradation occurs due head line blocking buffer receiving application 
pending packet arrivals receiving slower connection stall tcp sender faster connection eventually enters persist mode zero window advertisement receiving 
link layer striping schemes assuming stable link characteristics proposed earlier bandwidth aggregation 
schemes unfortunately inapplicable wireless links 
adaptive mechanism monitors quality wireless links stripes accordingly optimal bandwidth aggregation achieved context multi homed mobile hosts different interfaces potentially belong different access networks 
authors propose channel striping algorithm channel defined logical fifo path layer protocol stack including transport layer 
discuss section approach exhibits drawbacks limitations specifically pertain link layer striping schemes 
goal study problems involved achieving bandwidth aggregation application mobile host uses multiple interfaces simultaneously propose transport layer approach effectively addresses problems 
propose purely transport layer approach called ptcp parallel tcp wrapper slightly modified version tcp refer tcp tcp virtual 
ptcp socket opened application ptcp opens maintains tcp connection interface connection striped 
ptcp manages send buffer tcp connections decouples loss recovery congestion control performs intelligent striping data tcp connections data reallocation handle variances bandwidth delay product individual connections redundantly stripes data catastrophic periods blackouts resets defined interface tcp allows different congestion control schemes different tcp connections 
show ns simulations ptcp outperforms simple sophisticated schemes employed application layer 
ptcp transport layer solution simplicity implemented true session layer solution provided sufficient support provided transport layer 
contributions summarized follows 
consider mobile hosts multiple interfaces corresponding independent wireless access networks investigate multiple sockets application layer support result desired bandwidth aggregation 

propose transport layer approach called ptcp effectively provides applications aggregate bandwidths available multiple interfaces mobile host 
rest organized follows section discusses multiple sockets result aggregate bandwidths 
section presents assumptions key tenets ptcp design 
section describes ptcp approach detail ptcp state diagram handshakes packet header formats 
section provides simulation results ptcp approach 
section revisits assumptions considers impact relaxing 
discusses deployment issues ptcp 
section discusses related section concludes 

motivation section consider approach application opens multiple tcp sockets interface performs striping data different sockets achieve bandwidth aggregation 
consider unaware application knowledge underlying connection data rates smart application knowledge available data rates consequently enable stripe intelligently 
case socket blocks write sending application moves socket 
case sending application stripes data ratio determined estimation available rates different connections pipes 
goal perform reliable sequence data delivery receiving application finite buffer 
simplicity assume application level sequence numbers facilitate process restrict discussions packet streams opposed byte streams 
receiving application continues read packets socket long buffer available space 
application buffer full stops reading sockets delivered packets sequence numbers larger expected application level sequence number 
enters peek mode available packet sockets reads packet sequence packet 
note application buffer size zero application read sequence packets sockets 
hand increasing size application buffer effect reducing chances faster pipe stalled slower 
elaborate phenomenon section discuss impact data rate differential multiple pipes 
proceed identify key constraints application layer striping approach data rate differential data rates pipes unaware application different aggregate bandwidth achieved simple approach remains tight function data rate slowest pipe 
intuitively explained follows consider pipes data rates mbps mbps respectively 
application stripes data keeping send buffer pipe filled send buffer worth application data injected mbps pipe block data 
blocked pipe application proceed inject data second mbps pipe block data 
pipe drain data faster application filling second pipe inject data pipe block data 
assume data rate difference pipe delivers drained second pipe 
additional data block order queued buffer receiving application pending arrival entire block data second pipe 
pipe continue transfer data faster rate eventually result application buffer overflowing 
receiving application reading data pipe turn cause pipe tcp receiver buffer fill 
tcp receiver advertise window size zero completely stalling pipe 
sequence data block sent originally second pipe reaches receiver releases space buffer pipe active 
note head line blocking artifact unaware striping mechanism refer individual connections pipes differentiate aggregate connection 
recv socket call variants support peek flag set allows receive operation retrieve data receive buffer removing data buffer 
application 
way reducing coupling faster slower pipes increase buffer size application layer 
larger buffer size time faster pipe remain active inhibited flow control 
specifically pipes bandwidths respectively equal delays application buffer required steady state effectively aggregate bandwidths default socket buffer size 
assuming buffer requirements accommodated buffering handle stalls occur due losses slower pipe 
application smart striping problem exist long striping ratio exactly match data rate ratio different pipes 
elaborate issue constraint 
furthermore tcp performance degradation simple approach severe phenomenon persist timers 
sender faster pipe receives window advertisement zero enters persist mode 
single window update receiver happens lost due congestion random wireless losses sender probes receiver persist timer expires seconds 
persist timer value doubles unsuccessful probe capped seconds 
effectively brings progress faster pipe crawl impact severe slower pipe potentially enter persist mode persist timer induced stalling faster pipe 
tcp effect data rate differential different pipes potentially catastrophic application resulting aggregate throughput lower data rate slowest pipe 
results section illustrate phenomenon 
fluctuating data rates problem due data rate differential overcome employing intelligent striping scheme performing intelligent striping inherently difficult problem reasons pipes pipes traverse multiple hops sender receiver available bandwidth fluctuate dynamically ii dynamic nature wireless link characteristics pipes exhibit highly varying data rates 
application stripes estimated data rates pipes data rates change purpose intelligent striping defeated resulting degraded performance 
note dynamic characteristics wireless link consequent difficulty performing accurate rate estimation part reason degraded performance 
coupling congestion control loss recovery aggregate connection exists individual tcp pipes functioning independent contributing factor 
example packets assigned tcp pipe application withdrawn pipe notwithstanding bandwidth reduction pipe may experience 
bandwidth reduction occur packets assigned pipe transmitted due lack space reduced congestion window reassigned active pipe 
blackouts blackouts extreme cases rate fluctuations available data rate falls zero remains zero extended period time 
causes phenomena include temporary loss connectivity user passing tunnel fading interference moving source observations occurrence phenomena related 
multiple sockets approach blackouts subset pipes stall entire aggregate connection buffer overflow receiving application 
obviously undesirable phenomenon 
solution problem feedback mechanism application layer application realize particular pipe stalled substantially increase overhead complexity application 
application complexity application layer approaches simple sense require protocol changes transport layer complexity overhead application layer considerable 
essentially application implement mechanism reordering performed pipe tcp 
sequence numbers facilitate included application defined headers application explicitly ensure application layer segments unique application layer sequence numbers get fragmented 
conceivable way application ensure application layer segments fragmented write exactly mss worth data write 
enabled achieve desired goal 
similarly order stripe intelligently application redundantly implement bandwidth estimation mechanism spite bandwidth estimation performed tcp congestion control mechanism 
furthermore order solve problems identified consequences blackouts application implement feedback mechanism recover pipes stalled effect duplicate reordering loss recovery mechanisms implemented tcp individual pipes 
clearly undesirable overload applications manner applications mobile host require similar functionality 
note arguments hold session layer approaches absence appropriate interfaces session layer transport layer 
multiple congestion control schemes different wireless network technologies possess diverse characteristics terms throughput delay jitter loss rates approaches improve tcp performance wireless networks typically proposed specific scenarios 
example snoop proposed primarily wlans shows snoop inappropriate due key assumption wireless link delays insignificant compared delays 
wtcp proposed stand inappropriate wlans due reliance inter packet separation key congestion metric 
low data rates result inter packet delay large turn robust realistic metric 
wlans bandwidths order tens megabits second longer serves reliable congestion metric 
similarly approaches specif ically improve tcp performance satellite links possess large bandwidth delay products proposed 
mobile host multiple interfaces conceivable scenario unified transport layer framework derived interface specific transport protocols 
simple application layer striping approach numerous roles assigned application task choosing appropriate transport protocol different pipes rely application 

ptcp design section key design elements ptcp approach overcome drawbacks identified earlier application layer approaches 
assumptions basic design ptcp mobile hosts multiple interfaces ideally simultaneously single application connection ii sender receiver support ptcp iii bandwidth bottlenecks purely wireless links individual pipes iv application ideally unaware striping process 
briefly assumption iii ensure tcp friendliness aggregate connection backbone internet paths multiple pipes may merge 
assumptions primarily simplifying presentation ptcp revisit assumptions ii iii section discuss required modifications ptcp assumptions relaxed 
ptcp approach key design elements decoupled congestion control reliability described section ptcp wrapper modified tcp refer tcp 
details interaction ptcp tcp section briefly ptcp maintains controls single send buffer tcp pipes aggregate connection 
individual tcp pipes perform congestion control loss recovery just regular tcp 
segment transmission tcp preceded explicit call ptcp requesting application data 
ptcp control buffer retransmission tcp level need retransmission ptcp level 
amount data sent tcp pipe strictly determined tcp congestion control algorithm employed respective pipe 
tcp controls amount data sent ptcp controls data send 
fashion ptcp decouples congestion control reliability 
describe go decoupling contributes improved performance functionality ptcp 
congestion window data striping tcp pipe space congestion window transmissions requests ptcp data 
exists data ptcp registers concerned tcp pipe active pipe data 
tcp pipe waits subsequent resume call ptcp requesting data 
ptcp receives new data application issues resume call tcp pipes registered active 
note striping different striping conditional buffer availability seen simple application layer approach 
ptcp data tcp pipe space congestion window data sent 
note inherently assumes congestion window true representative bandwidth delay product pipe 
tcp congestion window approximation bandwidth delay product possible incorrect estimation say example due deep buffers network 
revisit issue section 
striping data congestion window individual pipes removes problem arises due differences rates pipes provided fluctuation available bandwidth 
dynamic reassignment congestion recall possible congestion window estimate especially just congestion occurs 
result undesirable hold data pipes congestion window reduced 
example consider scenario congestion window pipe pi 
worth data assigned pi window cut due bandwidth fluctuations worth data falls outside congestion window pi blocked transmission till opens 
equivalent static scenario application undesirably assigned data pipe carry process slows faster pipes 
ptcp solves problem leveraging decoupling exists congestion control reliability 
pipe experiences congestion irrespective detection duplicate timeout window reduced half 
congestion window pipe reduced ptcp immediately data bound sequence numbers concerned pipe fall outside current congestion window 
pipe space congestion window requests data unbound data available reassignment pipe 
original pipe requests data corresponding sequence number unbound new application data bound ptcp returned pipe 
reassignment strategy greatly improves performance ptcp dynamic conditions illustrate simulation results section 
trade offs reassignment strategy potential overhead performing unnecessary retransmissions 
simulation results show overhead insignificant 
redundant striping blackouts strategy described data falls pipe congestion window deal mss worth data mss congestion window fall congestion window irrespective state pipe 
failure deliver mss worth data potentially stall entire aggregate connection concerned pipe undergoes multiple timeouts suffers blackout 
ptcp redundantly stripes mss data congestion window suffered timeout pipe 
doing binding data changed new pipe old pipe access copy data 
reason leaving copy regular reassignment old pipe require mss worth data send order recover 
time providing new mss worth data potential pitfall overview ptcp key data structures chances blocking pipe experiencing severe conditions 
selective acknowledgments ptcp design impose requirements design tcp protocol individual pipes 
tcp sack helps performance ptcp certain conditions 
argument tcp ptcp preferentially tcp sack 
multiple losses congestion window tcp reno tcp newreno recover losses rate loss round trip time 
multiple losses occur congestion window pipe time taken recover loss farther congestion window increases 
default tcp acceptable alternative take pessimistic attitude tcp tahoe default treats packets hole lost starts retransmitting 
ptcp delayed recovery hole potentially stall entire aggregate connection 
rate loss recovery done critical 
tcp sack loss recovery done faster multiple holes filled round trip time sack information exchanged 
results ptcp experiencing better performance 
tcp sack preferred general internet setting wireless environments enable faster recovery random channel errors believe recommendation sack ptcp reasonable 

ptcp protocol overview provides architectural overview ptcp approach 
ptcp acts central engine interacts application ip tcp respectively 
interface application achieve bandwidth aggregation ptcp creates maintains tcp pipe 
assume choice number interfaces external decision conveyed ptcp socket option 
illustrates key data structures maintained aggregate connection 
ptcp controls maintains send receive socket buffers connection 
application data writes served ptcp data copied send buffer 
list active tcp pipes space congestion window transmit pipes maintained ptcp 
tcp pipe placed inactive pipes initially created ptcp 
availability data needs transmitted ptcp sends resume command active tcp pipes 
resume issued pipe corresponding pipe removed active pipes 
tcp pipe receives command builds regular tcp header state variables gives segment sans data ptcp send interface 
ptcp binds unbound data segment buffer header virtual segment tcp built maintains binding data structure called bindings appends header sends ip layer 
resumed tcp continues issue send calls till space left congestion window ptcp responds back data return value freeze concerned pipe note tcp pipe needs perform rollback operations account unsuccessful transmission 
ptcp receives send call unbound data left returns data value adds corresponding pipe active pipes 
ptcp receives ack strips ptcp header hands packet appropriate tcp pipe receive interface 
correct tcp pipe recognizable tcp tuple 
tcp pipe processes ack regular fashion updates state variables including virtual send buffer 
virtual buffer thought list segments appropriate header information 
virtual send receive buffers required ensure regular tcp semantics congestion control connection management tcp pipe 
ptcp header carries cumulative ptcp level ack information ptcp uses purge receive buffer required 
incoming data segment received ptcp strips ptcp header data enqueues data buffer provides appropriate tcp skeleton segment contain data 
tcp treats segment regular segment application data queued virtual receive buffer 
rest section describe different components ptcp protocol including interfaces tcp header formats connection management congestion flow control 
tcp interface seen functions act interface ptcp tcp open close established closed receive send resume shrunk 
ptcp uses open close calls inputs tcp state machine opening closing tcp pipe respectively 
uses established closed interfaces inform ptcp state machine reaches established closed states respectively 
send call tcp send virtual segments ptcp bind segments real data 
receive interface hand ptcp deliver virtual segments tcp 
ptcp uses resume inform tcp additional unbound data available 
tcp receiving call attempts send data possible till gets data return value send call freezes 
tcp uses shrunk interface inform ptcp change congestion window ptcp perform reassignment described section 
ptcp header format header formats presents header formats ptcp protocol 
note header addition regular tcp header tcp 
regular ptcp header consists fields source connection identifier ii destination connection identifier iii ptcp sequence number iv ptcp number pack 
connection identifiers uniquely identify aggregate ptcp connection ends 
sequence number aggregate connection level independent tcp sequence number 
pack cumulative similar tcp field 
individual tcp pipes tcp ack fields perform congestion control recall congestion control loss recovery coupled tcp reused ptcp 
ptcp responsible performing flow control controls buffer requires field window advertisement tcp 
tcp pipes perform flow control merely maintain virtual buffers ptcp reuses overrides tcp window advertisement field performing flow control 
reuse interfere progress individual tcp pipes due fact ptcp advertised window greater actual window individual pipe elaborate section 
addition regular ptcp header fields header format connection establishment phase augmented fields number transmitting interfaces nt ii number receiving interfaces iii list ip addresses corresponding nt ipt iv list ip addresses corresponding 
nt field number interfaces source ideally transmissions effect require nt pipes maintained ends field maximum number interfaces source willing serve reverse path 
note multiple interfaces pipes terminate interface 
typical setup multi homed mobile host communicates internet backbone host interface 
connection management state machine ptcp connection establishment handshake respectively discussions 
note state machine tcp default tcp interface ptcp tcp section 
assume number interfaces ends 
establishment ptcp state machine active open issued client application ptcp socket transmission control block tcb similar tcp tcb additional state variables introduced earlier section created 
ptcp socket created ptcp creates tcp tcb issues open call 
tcp sy packet sent ptcp sets nt field corresponding ip addresses ipt appends additional ptcp connection management header information packet 
ptcp server receives passive open checks see willing support tcp pipes 
assuming receiver support required number pipes creates tcp tcb issues passive open process takes syn rcvd state 
sy ack sent tcp server destination ip address appropriately set information received sy source address reflects local host interface tcp pipe bound 
sy ack message carries field server agreed support corresponding ip addresses 
client ptcp receives sy ack creates remaining tcp issues open calls 
tcp pipe stage enters established state sending back ack server 
ptcp goes established state start accepting data application 
pipes experiencing connection setup problems ptcp ensure data flow client server 
source ip address outgoing sy ns set local interface tcp pipe bound 
destination address set addresses sy ack sent server 
tcp reasons including memory processor limitations security considerations receiving host desire limit number pipes 
connection establishment handshake pipe server receives ack enters state participate data exchange client 
ptcp server enters established state 
server receives sy messages remaining tcp pipes creates corresponding tcp assigns respective sy ns syn rcvd state 
exchange information server tcb corresponding client tcb similar tcp 
individual tcp pipes enter established state issue established call ptcp making ptcp move state machine shown 
individual pipes enter es state ptcp enters established state 
termination teardown ptcp connection relatively simpler connection establishment 
application closes connection ptcp uses close interface individual tcp pipes close 
pipe closes tcp regular closing handshake 
tcp pipe enters closed state state machine invokes closed callback ptcp 
closed message ptcp receives moves ptcp state machine 
successful completion tcp pipes ptcp enters closed state confirms close application layer 
congestion control flow control ptcp perform congestion control 
individual tcp pipes solely responsible controlling amount data transferred pipe 
hand flow control ptcp performed ptcp layer 
primary reason fact ptcp control receive buffer helps better utilization buffer multiple pipes 
example case simple application layer approach irrespective bandwidth delay product bdp individual tcp pipes pipe constant buffer kb default 
result wastage buffer space pipes smaller wastage capacity pipes larger 
ptcp buffer space shared individual pipes respective 
note network topology property achieved approaches proposed related 
buffer space send receive available ptcp layer assumed number tcp pipes default tcp buffer size 
segment belongs ptcp connection carries available space ptcp receive buffer irrespective pipe belongs 
ptcp sender keeps track number outstanding bytes connection ensures receive buffer overflows 
individual tcp pipes see available buffer space contend simultaneously space provided space congestion windows ptcp control data transmissions prevents excess data transmitted 
example consider scenario receiver advertised window size bytes 
assuming exist tcp pipes sender bytes space left congestion window pipes attempt transmit bytes worth data 
pipe succeeds transmitting bytes pipes ano data value returned send calls ptcp aware global situation 
far described key components ptcp protocol 
section performance evaluation results ptcp protocol comparing performance simple sophisticated application layer techniques 

performance evaluation simulation model ns network simulator generic topology shown simulations 
emulate toend path multi homed mobile host destination custom bandwidth delay jitter loss modules added link object ns 
assume bottleneck wireless link explicitly sophisticated backbone topology simulations 
introduce variations delay jitter modules capture variations connections expect observe 
primary types links simulations links bandwidths ranging kbps mbps round trip time ms representative connection wlan ii links bandwidth mbps round trip time ms representative connection wwan pico cell iii links bandwidth kbps round trip time ms representative connection wwan macro cell 
packet loss rates simulations identify specific link characteristics simulations different results 
tcp sack implementation transport layer default 
application layer techniques comparisons unaware approach identical application throughput mbps tcp sequence number ideal throughput sum ptcp smart application unaware application unaware application wnd update bandwidth ratio throughput vs bandwidth ratio wlan link ptcp wlan link unaware application wwan link time sec sequence number progression ratio scalability rate differential described section smart approach uses striping ratio average bandwidths different links 
ptcp implemented wrapper tcp sack explained section 
ideal performance bandwidth aggregation multiple applications application socket link summing respective throughputs 
explicitly introduce cbr traffic udp background traffic necessary 
packet sizes set kb 
simulations run period seconds averaged samples randomness introduced 
measure throughput aggregate instantaneous metric comparisons 
tcp sequence number progression connection appropriate 
results rest section scalability respect rate differential ii scalability respect number interfaces iii resilience rate fluctuations iv resilience blackouts existence different congestion control schemes 
simulation results rate differential section topology active links source destination 
fix bandwidth links kbps increase bandwidth link kbps mbps increments kbps 
round trip time fixed ms link ms application throughput mbps ideal throughput sum ptcp smart application unaware application number links scalability multiple links second 
link representative wwan link second link representative wlan link 
value bandwidth second link monitor throughput performance ptcp smart application unaware application 
plot ideal aggregate throughput curve 
aggregate throughput results 
xaxis value represents ratio bandwidth second link 
observed ptcp smart application achieve near ideal performance unaware approach performs significantly worse exhibits non increasing aggregate throughput ratio 
simulate scenario window update tcp receiver lost 
sending tcp faster pipe enters persist mode turns causes slower pipe 
shown result aggregate throughput lower slowest pipe explained section 
non performance unaware application explained section illustrated results sequence number progression shown small time window pipes bandwidth ratio 
case ptcp 
observed unaware application head line blocking receiver due slower pipe stalls faster pipe 
faster pipe exhibits distinct idle periods results degraded performance unaware application 
contrast results ptcp scenario exhibits smooth flow transmissions faster pipe 
attributed congestion window assignment strategy adopted ptcp 
number links results section topology consider performance ptcp approaches number links increased 
scenario links fix bandwidth link kbps bandwidth second link mbps bandwidths remaining links values kbps mbps randomly chosen 
presents aggregate throughput enjoyed application different striping techniques number links increased 
randomness introduced form variable link bandwidth assignment averages scenarios result 
observed performance ptcp scales increasing number links performance unaware application 
note throughput degradation observed smart application number instantaneous throughput packets sec application throughput mbps ptcp reassignment ptcp reassignment time sec effect dynamic reassignment ideal throughput sum ptcp smart application unaware application number links bandwidth fluctuations throughput vs number links impact fluctuations links increases fact due particular implementation 
smart application stripes data multiple pipes bandwidth ratio underlying links minimum striping unit packet short term unfairness exhibited individual pipes decrease effectiveness algorithm 
number links increases shortterm unfairness occur frequently periodic tcp probing losses link contribute unfairness degrading aggregate throughput enjoyed smart application 
acknowledge sophisticated implementation smart application conceivably solve problem performance degrade due reasons shown sections 
rate fluctuations characteristics wireless links exhibit high variances bandwidths delays section investigate performance ptcp presence fluctuations available capacity individual pipes 
show ptcp dynamic reassignment design element effective addressing capacity fluctuations compare performance ptcp approaches 
consider topology links 
links fixed bandwidth mbps round trip time ms bandwidth link initially set mbps round trip time ms 
square wave cbr flow period amplitude mbps background traffic cause fluctuation second link 
available bandwidth second link fluctuates mbps mbps period seconds 
fluctuations caused varying cbr background load appropriate links representative congestion rate changes wireless channel condition rate changes 
result shown obtained seconds 
number packets delivered application second time window instantaneous throughput compare performance ptcp dynamic reassignment 
clear dynamic reassignment ptcp able perform bandwidth fluctuations 
compare performance different striping techniques multi link topology section 
bandwidth link randomly fluctuates second normal value 
example link capacity mbps available bandwidth application randomly fluctuates mbps mbps simulation 
average bandwidth link capacity 
observe dynamic environment performance ptcp closely follows ideal performance 
case smart unaware applications 
scenario appropriate demonstrating smart application layer approach rate estimation 
performance suffer long rate estimation coarser actual fluctuations 
smart application eventually adapt changed rate packets pipe slowed 
blackouts section show impact blackouts performance ptcp application striping techniques 
link topology previous sections introduce long seconds blackout available bandwidth wwan link mbps decreases zero 
packets transmitted wwan link blackout period dropped 
shows sequence number progression smart application wlan wwan pipes 
obvious wwan link stops sending data blackout period head line blocking problem described section wlan link stalls blackout period resulting aggregate connection coming 
hand seen ptcp wwan link stalls blackout period wlan link continues progress minor stall 
possible redundant striping policy ptcp segment congestion window wwan pipe wlan pipe prevents experiencing head line blocking 
different congestion control schemes section demonstrate ability ptcp protocol different congestion control schemes aggregate connection 
consider link topology bandwidths mbps wlan mbps wwan roundtrip times ms ms respectively 
loss module inserted wwan link 
module inserts losses packet error rates ranging 
consider performance ptcp wlan link uses regular tcp wwan link uses tcp eln 
tcp eln receives explicit loss notification underlying link layer packet dropped due random wireless loss react losses 
note tcp sequence number tcp sequence number wlan link wwan link time sec smart application blackouts wlan link wwan link time sec ptcp blackouts impact blackouts sophistication transport protocol key importance ability ptcp approach accommodate different congestion control schemes framework 
presents throughput performance results ptcp smart application tcp tcp eln links ideal performance sum throughputs independent tcp eln connection wwan link independent tcp connection wlan link 
seen ptcp achieves maximum achievable performance illustrating seamless nature ptcp allows congestion control schemes exist 

issues discussion section discuss issues ptcp design 
congestion window bandwidth delay product key assumptions ptcp performs congestion window striping congestion window tight approximation available bandwidth delay product 
true 
example deep buffering network artificially inflate congestion window larger true product connection 
plausible solution problem complement basic congestion control scheme tcp mechanisms help estimate bdp accurately 
example rate incoming acks particular pipe monitored keep track application throughput mbps ideal tcp wlan eln wwan ptcp tcp wlan eln wwan smart application eln wlan eln wwan smart application tcp wlan tcp wwan packet drop probability wwan link multiple congestion control schemes ptcp available rate sending rate pipe exceeds bdp rate incoming acks hit plateau 
ptcp indication cap amount data assigned pipe 
note ptcp implemented transport layer approach easier access states tcp higher layer approach 
current involves studying problem closely 
tcp friendliness important consideration multiple interfaces bandwidth aggregation aggregation plays role tcp friendliness connection 
happen performing aggregation connection loses tcp friendly nature 
assumption earlier bottlenecks solely wireless domain true issue 
bottlenecks happen wired domain possible multiple tcp pipes share single bottleneck wired domain aggregate ptcp connection aggressive single regular tcp connection 
possible solutions problem works proposed schemes heuristically determine connections share bottleneck monitoring packet loss patterns inter arrival times 
inferred tcp pipes sharing bottleneck link approaches employed take care aggregate behavior tcp pipes mimics single regular tcp connection 
ii approach extensively explored different context variant tcp vegas 
tcp vegas shown tcp reno tcp newreno flows 
variant tcp vegas congestion window reset detection consistent increase history round trip times maintained bandwidth reno newreno flows 
ptcp tcp pipe reno newreno congestion control scheme pipes variant tcp vegas congestion control algorithm lessening tcp unfriendly effect multiple tcp pipes share bottleneck 
backward compatibility assumption sender receiver ptcp aware 
believe assumption reasonable scenarios mobile users predominantly communicate proxies mobile host aware 
mobile hosts communicate static hosts potentially unaware problem handled just handled protocols tcp sack timestamp option tcp 
syn packet sent start connection option enabled 
replies option awareness inferred respective protocol 
replies option normal tcp operation resumes 
ptcp headers connection establishment handshakes implemented tcp options place ptcp permitted techniques realistic solution ensure correct operations ptcp aware host communicates ptcp unaware host 
handoffs consider handoffs explicitly note handoff experienced individual tcp connection handled default manner handled pipe application 
fact ptcp ensures stalls caused pipe due handoffs pipes remain unaffected 
soft handoff easily achieved mobile host connected multiple access points intersection coverage areas ptcp pipes established access points handoffs 
complexity sources complexity ptcp cause potential problems creation maintenance multiple tcb states drain host resources 
ptcp connection establishment phase addresses problem allowing host accept requests aggregate connection specifying limit number pipes support 
ii overheads incurred buffer management ptcp individual tcp pipes 
ptcp manipulation socket buffer incurs overhead buffer management mechanisms regular tcp socket 
additional overheads occur packets unbound congestion window reduction 
case unbound packets need re inserted list sorted sequence numbers 
currently investigating efficient data structures reduce overheads incurred reinsertion performed 

related classify related proposed approaches achieve bandwidth aggregation performed application layer transport layer link layer 
application layer techniques approaches proposed multiple tcp connections parallel provide higher throughput application 
example authors develop library stripe data multiple tcp sockets better utilization network bandwidth avoiding time consuming process manually tuning tcp buffer size 
authors develop new application called uses multiple tcp connections overcome limitation tcp window size long fat links satellite links 
similarly extension ftp protocol called gridftp developed bulk data transfer parallel tcp connections increase throughput bottleneck link 
authors characterize substantiate performance improvement aggregate connection uses parallel tcp connections path 
note class related deals multiple tcp connections path 
discuss section pitfalls approaches context multi homed mobile hosts 
transport layer techniques stream control transmission protocol sctp reliable transport protocol designed transport message signaling information ip networks 
salient feature sctp support multi streaming multi homing 
sctp connection consist multiple data streams multiple interfaces 
sctp provides reliable sequence delivery data stream provide total ordering data streams 
head line blocking different data streams avoided sctp provide bandwidth aggregation ptcp 
sctp user stripe data multiple data streams handle packet 
distinct difference sctp ptcp lies congestion control mechanism 
multiple data streams sctp connection subject common flow congestion control mechanism 
context multi homed mobile hosts different data streams traverse vastly differing wireless links heterogeneous access networks design unnecessary leads bandwidth underutilization aggregate connection 
reliable multiplexing transport protocol rmtp rate transport layer approach specifically designed aggregate bandwidths multi homed mobile hosts 
rmtp targets scenario ptcp differs ptcp ways rmtp performs explicit bandwidth striping 
available bandwidth underlying pipe estimated periodically sending probes 
effectiveness rmtp greatly depends accuracy bandwidth estimation 
bandwidth probing rate limits fast detect adapt bandwidth fluctuations 
bandwidth fluctuations occur time scale smaller bandwidth probing period rmtp exhibit problem smart application shown section 
ii rmtp design explicitly address interaction component pipes aggregate connection ptcp delayed binding dynamic reassignment redundant striping 
show earlier sections design components play important role achieving effective bandwidth aggregation multi homed mobile hosts 
iii rmtp provide interfaces allowing flexible inclusion different congestion control mechanisms optimized different wireless links 
link layer techniques mentioned section conventional link layer striping techniques perform context multi homed mobile hosts multiple interfaces belong different network domains altogether 
ideal striping algorithm deal highly dy namic vastly differing set wireless links address fluctuations capacity caused multi hop nature paths 
authors propose channel striping algorithm channel defined logical fifo path protocol layer 
authors show striping load sharing algorithm fact reverse fair queueing algorithm 
reversing direction packet flow fair queueing algorithm sender achieve optimal load sharing channels different capacities 
receiver running fair queueing algorithm sender packets lost delivery achieved 
algorithm generic approach striping logical channel including transport layer due nature fair queueing algorithm capacity channel known priori ends 
states algorithms ends synchronized ensure sequence delivery 
packet losses cause loss synchronization sender receiver 
algorithm periodically insert marker packets channels achieve resynchronization 
wireless environments high loss rates marker packets may get lost resulting degrading performance striping algorithm potentially delivering packets order application 
fluctuations channel capacity limit applicability approach targeted environment 

consider problem multiple interfaces mobile host provide aggregate bandwidths applications 
multiple interfaces potentially belong different wireless network domains link layer striping schemes achieve bandwidth aggregation 
time show application layer techniques default tcp sockets scale link characteristics different fluctuating 
context propose transport layer approach called ptcp achieves bandwidth aggregation combination mechanisms including decoupled congestion control reliability ii congestion window striping iii dynamic window reassignment iv redundant striping handle blackouts support different congestion control schemes exist single transport layer framework 
show simulations ptcp achieves bandwidth aggregation efficiently variety network conditions 

varghese 
reliable scalable striping protocol 
proceedings acm sigcomm palo alto ca usa aug 
allman kruse ostermann 
application level solution tcp satellite inefficiencies 
proceedings workshop satellite information services ny usa nov 
balakrishnan padmanabhan katz 
comparison mechanisms improving tcp performance wireless links 
ieee acm transactions networking dec 
balakrishnan rahul seshan 
integrated congestion management architecture internet host 
proceedings acm sigcomm boston ma usa sept 
balakrishnan seshan katz 
improving reliable transport handoff performance cellular wireless networks 
acm wireless networks dec 

inverse multiplexing 
ieee communications magazine apr 
hacker 
performance effects parallel tcp sockets lossy wide area network 
proceedings ieee ipdps fort lauderdale fl usa apr 
henderson katz 
transport protocols internet compatible satellite networks 
ieee journal selected areas communications jsac feb 
lee gunter tierney allcock tuecke 
applied techniques high bandwidth data transfers wide area networks 
proceedings computers high energy physics chep beijing china sept 
kravets 
transport level mechanisms bandwidth aggregation mobile hosts 
proceedings ieee icnp riverside ca usa nov 
mathis mahdavi floyd romanow 
tcp selective options 
ietf rfc oct 
nagle 
congestion control ip tcp internetworks 
ietf rfc jan 
rubenstein kurose towsley 
detecting shared congestion flows measurement 
proceedings acm sigmetrics santa clara ca usa june 
semke mahdavi mathis 
automatic tcp buffer tuning 
proceedings acm sigcomm vancouver canada sept 
network simulator 
ns 
www isi edu nsnam ns 
sinha sivakumar bharghavan 
wtcp reliable transport protocol wireless wide area networks 
proceedings acm mobicom seattle wa usa aug 
sivakumar bailey grossman 
case application level network striping data intensive applications high speed wide area networks 
proceedings ieee supercomputing sc dallas tx usa nov 
snoeren 
adaptive inverse multiplexing wide area wireless networks 
proceedings ieee globecom rio de brazil dec 
stemm katz 
vertical handoffs wireless overlay networks 
mobile networks applications 
stewart stream control transmission protocol 
ietf rfc oct 
smith 
striping network subsystem 
ieee network magazine july 
wright stevens 
tcp ip illustrated volume 
addison wesley publishing reading ma usa oct 
