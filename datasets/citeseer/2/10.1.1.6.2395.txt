concept lattice composite classifiers high predictability xie hsu liu li lee school computing national university singapore lower kent ridge road singapore comp nus edu sg school computing shanghai university china shanghai china mail shu edu cn concept lattice model core structure formal concept analysis successfully applied software engineering knowledge discovery 
integrate simple base classifier na bayes nearest neighbor node concept lattice form new composite classifier 
develop new classification systems employ efficient constraints search interesting patterns voting strategy classify new object 
integrates na bayes base classifier concept nodes incorporates nearest neighbor base classifier concept nodes 
experimental results indicate composite classifiers greatly improve accuracy corresponding base classifier 
addition outperforms state art classification methods nbtree cba rules 
classification kernel task data mining applications 
deal task various methods developed decision rule na bayes decision tree nearest neighbor neutral network 
different classification methods different decision planes appropriate different situations 
single method best situations 
result years researchers focus efforts improving predictive accuracy integration number different classifiers 
na bayes tree learner nbtree kohavi lazy bayesian rule learning algorithm lbr zheng examples efforts :10.1.1.57.4952
main thrust nbtree lbr contextual rule classification normal classification rule 
machine learning classification rule takes form pr cj pi descriptor attribute value pair relational table object cj class label 
rule means object classified cj satisfies descriptors pi 
nbtree lbr generalize classification rule define contextual rule pr cls classifier called base classifier 
contextual rule means classify object object satisfies descriptors 
thinking cj classifier classifies object cj clear normal classification rule just special case contextual rule 
na bayes tree learner called nbtree kohavi combines na bayesian classification decision tree learning :10.1.1.57.4952
uses tree structure split instance space sub spaces defined path tree 
na bayesian classifier generated sub space 
leaf na bayesian tree contains local na bayesian classifier 
learning algorithms tree structure nbtree suffers small disjunct problem 
tackle problem zheng zheng applied lazy learning techniques bayesian tree induction resulting lazy bayesian rule learning algorithm lbr 
lbr constructs bayesian rule specifically input test example uses rule predict class label example 
due flexibility allowing different classifiers different sub instances data space nbtree lbr achieved better accuracy na bayes classifiers 
improvement accuracy limited principle local search 
local maxima accuracy search interesting useful rules 
propose framework employs expressive structure concept lattice avoid local maxima 
concept lattice structure enables exhaustively extract bayesian rules 
strategies pruning concept lattice important efficient learning 
types constraints integrated top construction procedure prune lattice structure 
addition proposed framework works simple classification method long efficient technique accuracy estimation classification method available 
highlight important fact test example multiple rules matched corresponding classifiers get activated 
majority voting strategy applied classify test example 
voting strategy similar multi classifier techniques bagging breiman boosting freund multiple classifiers vote decision 
different framework activated classifiers classifier activated determined input test example take part voting bagging boosting classifiers vote regardless input test example 
reason difference classifier root classifier algorithm framework induced subset training examples share common features classifier bagging boosting learnt sample training set randomly sampling 
organized follows 
section provides background information simple classification methods na bayes nearest neighbor 
short discussion accuracy estimation techniques methods 
section presents algorithm framework embedding simple classifier concept node concept lattice 
types constraints pruning concept lattice structure proposed 
post processing pruning strategy designed chi square test 
majority voting strategy classifying new object 
section shows realization framework form new classification learning systems called concept lattice na bayes classification learning system concept lattice nearest neighbour classification learning system 
experimental results datasets shows systems shown great improvement terms predictive accuracy corresponding base classifiers 
addition outperforms state art classifiers 
simple classifiers accuracy estimation simplicity assume dataset relational data table nominal attributes consists descriptions objects form tuples 
objects classified known classes cq 
object database described distinct attributes attr attri instantiation object description attribute attri takes value vij domain attri 
denote set objects denote set attributes 
various kinds classification method developed induce classifiers dataset classifier thought function assigning class label newly seen object 
existing classification methods na bayes duda nearest neighbor dasarathy simplest efficient classification techniques studied widely 
induce base incorporated concept nodes 
accuracy estimation approximate classifier performance 
accuracy estimation techniques base classifiers efficiency taken consideration 
na bayes classifier na bayes typical eager learning algorithm simple computational efficient 
spite simplicity proved surprisingly successful method outperformed complicated methods application domains 
addition robust noise irrelevant attributes easy understand 
na bayes assumption attributes conditionally mutually independent class label 
formally probability class label value ci unlabelled instance am consisting attribute values ci ci 
assumption holds ci class label highest probability instance predicted class 
note need compute value 
constant na bayes typically leave strategy obtain accuracy training set 
strategy implemented efficiently time complexity linear number objects number attributes number label values kohavi 
nearest neighbor classifier nearest neighbor classification called memory case learning lazy 
finds nearest neighbors unlabelled instance training set metric distance function predicts class label class occurs frequently neighbors 
various distance metrics developed nearest neighbor algorithm probability metrics promising 
sf metric short 
relies probabilistic consideration generalized multi class hand 
instance sf distance defined follows sf applying bayes theorem independent assumption na bayes sf represents number classes 
ci ci distance metric defined nearest neighbor classification procedure easily applied predict class unknown instance assigning class nearest respect metric defined 
distance instances depends estimates probabilities count information needs updated removal instances efficient implement leave accuracy estimation strategy 
solve problem approximate solution adopted just compute pair wise distances instances estimates probabilities updating count information 
probability estimation implementing classifiers techniques developed estimate 
simplest probability estimates occurrence frequencies estimate ci ci number training examples ci number training examples class ci 
estimating conditional probability ci adopt laplace corrected estimate leads ci ci ci nj number values th attribute factor default value domingos 
contextual composite classifiers wille wille proposed theory formal concept analysis early concept lattice widely successfully fields including data mining machine learning 
knowledge discovery concept lattice constructed relational data set various kinds rules implication rules godin association rules pasquier classification rules extracted 
focuses classification incorporation base classifiers concept nodes 
details subsections 
contextual classifier formal concept meets base classifier formal concept analysis formal context triple set objects set descriptors binary relation functions defined 
pair called formal concept satisfies called extent intent 
intent extent represent intent extent concept 
clearly concept represents subspace training instance space 
subspaces overlap different decision tree leaf nodes form partition instance space 
set concepts hierarchical order relation defined formal concepts called subconcept denoted provided intent intent equivalent extent extent 
case 
different concepts called child called parent concept satisfying 
set concepts hierarchical order defined form concept lattice dataset object set attribute set transformed formal context setting attri vij attri vij domain attri xr attri vij iff attri vij simplicity expression contextual rule take form cls formal concept cls base classifier induced extent easy covert form introduced section intent cls 
clearly training set contextual classifier extent accuracy estimation method applied directly acc denote estimated accuracy cls 
contextual classifier cls object said activated intent activated cls predict class object predicted class denoted 
number concept nodes large medium size data set correspondence relationship concept nodes contextual classifiers practical calculate entire set contextual classifiers 
effective constraints adopted restrict search space 
discussed subsection 
constraints search contextual classifiers concept feature concept called direct subconcept 
child node certainly direct subconcept direct subconcept necessarily child 
set contextual classifiers called composite classifier 
composite classifier ruleset reduced satisfies types constraints support constraints threshold values constraint 
hand contextual rule cls satisfy extent default value 
hand contextual classifiers cls cls ruleset ancestor size extent large acc cls default value 
support constraints guarantee generalization ability learnt model 
accuracy constraint contextual classifiers cls cls ruleset ancestor estimated accuracies satisfy acc acc log extent extent 
default value set experiment 
smaller value larger search space explored 
reject constraint contextual classifier cls ruleset contextual classifier cls ruleset satisfies intent intent size extent larger extent default value 
constraint prevent occurrence contextual rules similar 
definition direct sub concept types constraints algorithm pseudo code listed searches interesting contextual classifiers top manner 
begins general node root node 
node algorithm compute direct subconcepts satisfies contraints removed 
ruleset add root nil ruleset contextual rule nil ruleset satisfies constraints support reject train base classifier cls extent update rule nil cls satisfies constraint accuracy intent intent intent concept hs extent insert hs nil rule intent hs endfor remove ruleset delete endif remove ruleset delete endif endfor endfor pruning searching contextual classifier space constraint relatively weak ensure interesting patterns obtained 
searched contextual classifier space adopt stronger pruning strategy ensure reliable improvement root classifier constructed training set 
chi square test comparison observed frequencies expected frequencies employed define statistical improvement accuracy 
contextual classifier cls cls get contingency table correctly classified wrongly classified column total cls cls row total extent acc extent acc extent acc extent acc extent extent table observed frequencies 
mij represent expected frequency corresponding nij 
mij ni 
table chi square value defined nij ij ij threshold value significance level adopted default value determining statistical difference accuracies contextual rules 
statistical difference accuracies estimated accuracy higher say statistically accurate 
current implementation simple strategy prune set contextual rules contextual rule root contextual rule pruned statistically accurate root contextual rule 
voting classify new objects unseen object composite classifier set contextual classifier voting strategy applied predict class 
accomplished steps step 
mark contextual classifiers activated unseen object 
usually classifiers activated input object 
line step 
activated contextual rule cls cls clear activated status intent intent 
line step 
activated contextual rule exists activated contextual rule statistically accurate clear activated status 
line step 
perform majority voting strategy input object set activated rules 
tie occurs vote contextual classifier highest accuracy tie breaker 
line cls intent contextual rule cls cls intent intent remove active endif cls active statistically accurate remove active endif endfor count class count contextual rule set major max count decisions count major decisions return decisions predicted class contextual rule maximal accuracy active decisions return predicted class endif experimental results concept lattice framework implemented template class visual win system 
concept lattice template takes base classifier class parameter 
experiments generate new instantiations concept lattice framework na bayes base classifier nearest neighbor base classifier 
experiments datasets uci machine learning repository merz liu 
detailed information datasets listed table 
current version algorithm deal nominal attribute entropy discretization algorithm fayyad preprocessing 
error rate comparison compare accuracy results classifiers produced generated corresponding base classifiers na bayes nearest neighbor generated state art classifiers nbtree kohavi state art hybrid classifier improves accuracy na bayes classifier significantly cba liu classifier association rules rules release 
error rates different algorithms experimental domains listed table 
error rates obtained fold cross validation 
training test set split classification methods experiments 
data sets clear produce accurate classifiers na bayes nearest respectively 
average accuracy increases na bayes nearest neighbor 
average error rate lower nbtree lower cba lower rules 
dataset 
attrs 
classes size dataset 
classes anneal australian auto breast cleve crx diabetes german glass heart hepatitis horse hypo ionosphere iris labor led lymph size pima sick sonar tic tac toe vehicle waveform wine zoo table datasets 
dataset nbtree cba rules nb nn anneal australian auto breast cleve crx diabetes german glass heart hepatitis horse hypo ionosphere iris labor led lymph pima sick sonar tic tac toe vehicle waveform wine zoo average table error rates nb nn cba nbtree computational requirements give idea computational requirements measurements running time training second running time testing second number contextual rules generated pruning number contextual rules generated pruning results experiments listed table 
values averaged folds 
discovered important fact table table datasets contextual rules pruning average accuracy improvement nb datasets average accuracy improvement nn datasets 
contrary datasets contextual rules pruning average accuracy improvement nb datasets average accuracy improvement nn datasets 
clearly experiments accuracy improvement composite classifier corresponding base classifier mainly caused data sets contextual classifiers generated pruning 
dataset 
nodes running time 
nodes running time bef 
aft 


bef 
aft 
class 
anneal australian auto breast cleve crx diabetes german glass heart hepatitis horse hypo ionosphere iris labor led lymph pima sick sonar tic tac toe vehicle waveform wine zoo average table computational requirements algorithm framework integrating base classifier concept node concept lattice 
algorithm framework realized form novel hybrid classification methods simple classification methods na bayes nearest neighbor respectively 
experimental results datasets indicate hybrid classification methods perform better corresponding base classifiers outperforms state art classifiers 
research includes looking different approach probability estimation smoothed estimation parameter friedman improve na bayes probability estimation count information investigate detailed voting information classify test example 
example consider evidences votes contextual classifiers may able techniques evidence theory accumulate collected evidence 
may result improvement performance algorithms 
aha aha 
lazy learning kluwer academic publishers 
ricci 
minimum risk metric nearest neighbor classification 
proceedings sixteenth international conference machine learning icml bled slovenia june 
breiman breiman 
bagging predictors 
machine learning vol pag es 
dasarathy dasarathy ed 
nearest neighbor nn norms nn pattern classification techniques 
ieee computer society press domingos domingos pazzani 
optimality simple bayesian classifier zero loss 
machine learning duda duda hart 
pattern classification scene analysis 
new york john wiley sons 
fayyad fayyad irani 
multi discretization continuous valued attributes classification learning 
ijcai pp 
freund freund 
boosting weak learning algorithm majority 
information computation friedman friedman geiger goldszmidt 
bayesian network classifiers 
machine learning ganter ganter wille 
formal concept analysis mathematical foundations 
springer godin godin missaoui 
incremental concept formation approach learning databases 
theoretical computer science special issue formal methods databases software engineering october kohavi kohavi :10.1.1.57.4952
scaling accuracy na bayes classifiers decision tree hybrid 
proceedings second international conference knowledge discovery data mining 
menlo park ca aaai press 

pp 
liu liu hsu ma integrating classification association rule mining 
proceedings fourth international conference knowledge discovery data mining 
new york usa 

galois lattice framework concept learning 
design evaluation refinement 
proc 
th intl 
conf 
tools artificial intelligence new orleans usa november ieee press 
pp 
merz merz murphy 
uci repository machine learning database www cs uci edu mlearn mlrepository html hand 
multiclass metric problem nearest neighbour discrimination rules 
pattern recognition pasquier pasquier bastide taouil lakhal 
efficient mining association rules closed itemset lattices 
information systems 
short short fukunaga 
optimal distance measure nearest neighbour classification 
ieee transactions information theory wille wille 
restructuring lattice theory approach hierarchies concepts 
rival eds ordered sets reidel dordrecht 
pp 
zheng zheng webb 
lazy learning bayesian rules 
machine learning 
