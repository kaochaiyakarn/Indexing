data fusion visual tracking particles patrick rez jaco andrew blake invited effectiveness probabilistic tracking objects image sequences revolutionized development particle filtering 
kalman filters restricted gaussian distributions particle filters propagate general distributions albeit approximately 
particular benefit visual tracking inherent ambiguity visual world stems richness complexity 
important advantage particle filtering framework allows information different measurement sources fused principled manner 
fact acknowledged fully exploited visual tracking context 
introduce generic importance sampling mechanisms data fusion discuss fusing color stereo sound teleconferencing motion surveillance camera 
show cues modeled appropriate data likelihood function intermittent cues sound motion best handled generating proposal distributions likelihood functions 
effective fusion cues particle filtering demonstrated real teleconference surveillance data 
keywords color data fusion motion particle filters sound visual tracking 
visual tracking entails detection recursive localization objects generally features video sequences 
tracking objects ubiquitous elementary task online offline image applications including visual servoing surveillance gestural human machine interfaces smart environments video compression augmented reality visual effects motion capture environmental imaging 
sequential monte carlo methods known particle filters popular tools solve tracking problem :10.1.1.110.383
popularity manuscript received march revised november 
rez blake microsoft research cambridge cb fb signal processing laboratory engineering department university cambridge cambridge cb pz digital object identifier ieee stems simplicity flexibility ease implementation modeling success wide range challenging applications 
visual tracking context methods pioneered seminal isard blake term condensation coined 
subsequently led vast body literature shall attempt review 
see examples 
important advantage sequential monte carlo framework allows information different measurement sources fused principled manner 
fact acknowledged fully exploited visual tracking context host cues available increase reliability tracking algorithm 
data fusion particle filters confined skin color edge cues inside simple silhouette shapes context face hand tracking 
particle filter visual tracker fuses cues novel way color motion sound fig 

specifically introduce color main visual cue fuse depending scenario consideration sound localization cues motion activity cues 
generic objective track specified object region interest sequence images captured camera 
employ weak object models restrictive types objects algorithm track achieve robustness large variations object pose illumination motion generic context contour cues appropriate color cues characterize visual appearance tracked entities 
edge cues requires class objects tracked known priori precise silhouette models learned 
note conditions met number tracking applications shape cues routinely 
color localization cues obtained associating color model object interest 
model compared sense similar models extracted candidate regions image proceedings ieee vol 
march fig 

types raw data 
consider color tracking combined motion cues surveillance static camera stereo sound cues speaker face tracking teleconference setup 
corresponding measurements follows 
left rgb color video frames 
center absolute luminance differences pairs successive frames 
right stereo pairs sound signal sections 
fig 

setup audiovisual tracking 
system calibration parameters microphone separation camera focal length width image plane real world width pixels digital image smaller discrepancy candidate models higher probability object located corresponding image region 
color model obtained automatic detection module allowing user label object interest hand 
model defined parametric form instance mixtures gaussians :10.1.1.4.7932
histogram color model inspired powerful deterministic color trackers comaniciu :10.1.1.28.41
likelihood built histogram distance empirical color distribution hypothesized region color model 
lines introduce motion cues histogramming successive frame differences 
form similar color likelihood motion likelihood designed favor regions exhibiting temporal activity larger average temporal activity scene 
prove particularly effective drawing attention tracker back objects moving front background cases lock temporarily lost 
audiovisual tracking system setup consists single camera stereo microphone pair 
line connecting microphones goes optical center camera orthogonal camera optical axis 
sound localization cues obtained measuring time delay arrival tdoa signals arriving microphones comprising pair 
tdoa gives indication bearing sound source relative microphone pair 
configuration system bearing turn related horizontal position image fig 

color cues tend remarkably persistent robust changes pose illumination 
prone ambiguity especially scene contains objects characterized color distribution similar object interest 
motion sound cues hand tend intermittent discriminant allow object located low ambiguity 
localization cues impact particle filter tracker number ways 
standard practice construct likelihood model cues 
models assumed mutually independent assumption justified light correlation may exist color motion sound object weak 
intermittent discriminant nature motion sound cues excellent candidates construction detection modules efficient proposal distributions 
exploit characteristic extensively 
differing nature cues configuration system allow experiment order manner cues incorporated 
example sound cue gives localization information horizontal direction image search direction confine search remainder state space regions horizontal image component deemed highly contain object interest 
strategy known partitioned sampling allows efficient exploration state space 
remainder organized follows 
section ii briefly outlines bayesian sequential estimation framework shows monte carlo implementation thereof leads particle filter 
presents proceedings ieee vol 
march alternative particle filter architectures cases information multiple measurement sources available 
section iii presents discusses ingredients proposed data fusion tracker color motion sound 
section concluded summary tracking algorithm 
section iv presents tracking scenarios illustrates performance tracking algorithm variety conditions 
usefulness localization cue combined impact evaluated 
conclude section summary suggestions research 
ii 
sequential monte carlo data fusion sequential monte carlo techniques filtering time series specific context visual tracking described length literature :10.1.1.110.383
follows give brief summary framework discuss detail architectural variations afforded presence multiple measurement sources 
denote hidden state object interest measurements discrete time respectively 
tracking distribution interest posterior known filtering distribution denotes observations current time step 
bayesian sequential estimation filtering distribution computed step recursion prediction step follows marginalization new filtering distribution obtained direct application bayes rule 
recursion requires specification dynamic model describing state evolution model gives likelihood state light current observation conditional independence assumptions recursion initialized distribution initial state sequence filtering distributions known point estimates state obtained appropriate loss function leading example maximum posteriori map estimate minimum mean square error mmse estimate tracking recursion yields closed form expressions small number cases 
known kalman filter linear gaussian likelihood state evolution models 
models encountered visual notation means conditional distribution left proportional function right multiplicative constant may depend conditioning argument 
tracking nonlinear non gaussian multimodal combination 
reason stems fact observation model specifies part data interest state leading nonlinear multimodal respect state renders tracking recursion analytically intractable approximation techniques required 
sequential monte carlo methods known particle filters gained lot popularity years numerical approximation tracking recursion complex models :10.1.1.110.383
due simplicity flexibility ease implementation modeling success wide range challenging applications 
basic idea particle filters simple 
starting weighted set samples approximately distributed new samples generated suitably chosen proposal distribution may depend old state new measurements maintain consistent sample new importance weights set new particle set approximately distributed approximations desired point estimates obtained monte carlo techniques 
time time necessary resample particles avoid degeneracy importance weights concentration weight single particle 
absence resampling phenomenon occurs practice dramatically degrading sample approximation filtering distribution quality point estimate 
resampling procedure essentially multiplies particles high importance weights discards low importance weights preserving asymptotic properties sample approximation filtering distribution 
procedure applied time step invoked measure quality weights falls threshold 
full discussion degeneracy resampling falls outside scope detail :10.1.1.110.383
synopsis generic particle filter iteration table 
performance particle filter hinges quality proposal distribution 
bootstrap filter modern variant particle filter uses state evolution model proposal distribution new importance weights proportional corresponding particle likelihoods 
leads seen considering sample trajectories 
distributed true target distribution importance sampling theory discrepancy compensated associating importance weights proportional ratio target distribution proposal distribution yields case recursion 
rez data fusion visual tracking particles table generic particle filter simple algorithm requiring ability simulate state evolution model evaluate likelihood 
performs poorly narrow likelihood functions especially higher dimensional spaces 
proved optimal choice proposal distribution terms minimizing variance importance weights posterior normalizing constant distribution rarely available closed form making direct sampling optimal proposal distribution impossible 
challenge particle filtering applications design efficient proposal distributions approximate optimal choice closely possible 
give careful consideration issue design tracker section iii 
multiple measurement sources general particle filtering framework applied 
possible devise strategies increase efficiency particle filter exploiting relation structure model information various measurement modalities 
follows suppress time index notational compactness 
assume measurement sources instantaneous measurement vector written assume measurements conditionally independent state likelihood factorized setting generic table weight update involving likelihood evaluations 
factorized structure likelihood better exploited 
introduce framework assume state evolution proposal distributions decompose auxiliary state vectors 
equation simply amounts splitting original evolution model successive intermediary steps 
example done state dimensional corresponding component wise evolution models independent evolution model linear gaussian easily fragmented successive steps lower variances 
approximation likelihood th measurement modality incorporated applying th state evolution model set recursion compute new target distribution takes form respectively previous new filtering distributions recursion approximated layered sampling strategy th stage new samples simulated monte carlo approximation distribution associated importance weight proportional yield properly weighted sample 
synopsis generic layered sampling strategy data fusion table 
stands layered sampling approach provides obvious advantage standard particle filtering framework 
true benefit arises cases measurement modalities differ level information provide state 
measurement modalities ordered coarse fine layered sampling approach effectively guide search state space stage refining result previous stage 
special applications likelihood state evolution models independent component wise partitioning state space models nature layered sampling procedure proceedings ieee vol 
march table generic layered sampling particle filter fuse observation modalities exact known partitioned sampling 
effectively replaces search full state space succession easier search problems lower dimensional space 
strategies designing tracking algorithm section iii 
iii 
data fusion visual tracker section describe detail ingredients tracking algorithm color motion sound 
system configuration object model proceed discuss localization cues impact tracking algorithm detail 
section concluded summary tracking algorithm 
audiovisual system setup setup tracking system depicted fig 

consists single camera stereo microphone pair 
line connecting microphones goes optical center camera orthogonal camera optical axis 
note experiments object interest talking head front camera 
cases sound measurements generally absent rely visual cues 
system requires small number calibration parameters microphone separation camera focal length width camera image plane real world width pixels digital image parameters normally easy obtain 
tracking algorithm develop robust reasonable inaccuracies system setup variations calibration parameters 
probabilistic nature errors easily accommodated explicitly modeling measurement uncertainty corresponding likelihood models 
objective track specified object region interest sequence images captured camera 
raw measurements available images audio signals captured microphones composing pair 
tracking performed video sequence discrete time index corresponds video frame number 
opposed video sequence naturally discretized audio samples arrive continuously notion natural audio frames 
purposes tracking algorithm define th audio frame window audio samples centered sample corresponding th video frame 
denote sampling period video frames audio samples respectively center audio frame corresponding th video frame computed denotes rounding operation 
number samples audio frame normally taken duration audio frame roughly ms raw image audio frames high dimensional contain lots information redundant regard object tracking 
pass raw data signal processing front purpose extracting features important tracking process 
specifically extract color motion features image data tdoa features audio data 
color persistent feature object main visual cue fuse intermittent motion sound cues 
follows denote combined color motion sound measurements time suppress time index cases danger ambiguities arising 
measurement procedures cues described detail relevant sections follow 
object model objective track specified object region interest image sequence 
aim models weak assumptions precise object configuration restrictive types objects tracked achieve robustness large variations object pose illumination motion approach adopted shape region denoted fixed priori 
ellipse rectangular box modeling framework places restrictions class shapes accommodated :10.1.1.28.41
complex hand drawn learned shapes relevant 
rez data fusion visual tracking particles tracking amounts recursively estimating parameters transformation apply implied region frame best matches original region 
affinity transforms popular choices 
color model describe section iii global respect region interest consider translation scaling region 
means region parameterized center region bounding box width height respectively 
define hidden state denoting state space corresponding candidate region variables form center candidate region acts scale factor 
objects move fairly predictable way 
practice general design state evolution model capture salient features object motion 
desire algorithm applicable object may interest including people faces motor vehicles large population objects variability characteristics object motion high 
furthermore interested tracking image sequence real world 
mapping motion dimensional world dimensional image representation dependent system configuration direction motion unknown practice 
acknowledge uncertainties adopting weak model state evolution 
specifically assume state components evolve mutually independent gaussian random walk models 
augment models small uniform component capture rare event erratic motion real world perceived jumps image sequence 
aids algorithm recovery lock period partial complete occlusion 
complete state evolution model written denotes gaussian distribution mean covariance denotes uniform distribution set weight uniform component diagonal matrix variances random walk models components object state 
weight uniform component typically set small 
object model completed specification distribution initial state assume uniform state space color cues specific class objects distinctive shape considered complete model shape learned offline contour cues powerful capture visual appearance tracked entities 
dramatically contaminated clutter edges detailed silhouette models 
adapted scenarios predefined class objects tracked class objects interest exhibit distinctive silhouettes 
tracking scenarios consider fall respectively categories 
shape modeling appropriate color information powerful alternative characterize appearance tracked objects 
demonstrated example robust tracking achieved simple color model constructed frame presence dramatic changes shape pose :10.1.1.28.41
color features object region interest form persistent localization cue 
tracking scenarios interested color information naturally chosen primary ingredient 
section derive color likelihood model 
color cues powerful tracking simplicity results lack discriminative power comes re initialize tracker 
sections iii iii show motion sound cues combined color cues resolve ambiguities increase robustness tracker distinct scenarios 
particular detection properties offered auxiliary modalities fully exploited design proposal densities 
color localization cues obtained associating color model object region interest 
model obtained hand labeling automatic detection module 
assess candidate region contains object interest color model form model computed region compared model 
smaller discrepancy candidate models higher probability object located inside candidate region 
color modeling independent normalized histograms channels red green blue rgb color space 
denote bin histogram model channel recall section iii region image corresponding state region estimate histogram color model denoted obtained denotes histogram bin index associated intensity pixel location channel color image denotes kronecker delta function normalizing constant color likelihood model defined way favor candidate color histograms close histogram 
need define distance metric histogram models 
case base distance bhattacharyya similarity coefficient defining proceedings ieee vol :10.1.1.28.41
march fig 

color histograms color likelihood 
left threefold color histogram gathered initial frame region picked manually automatically learned offline skin color 
center sequence hypothesized state candidate color histogram gathered region compared histogram bhattacharyya similarity measure 
right exponentiated similarity yields color likelihood plotted subsampled grid function location scale factor fixed ai 
note ambiguity strong responses arise faces section door 
contrast kullback leibler divergence distance proper metric bounded empty histogram bins singular 
distance define color likelihood model assumption squared distance exponentially distributed empirical evidence gathered number successful tracking runs 
histogram definition color likelihood summarized fig 

object interest composed patches distinct color face clothes person histogram color model successfully capture color information 
information relative spatial arrangement different patches lost 
keeping track coarse spatial layout distinct color regions may benefit performance tracking algorithm 
goal easily achieved modeling framework splitting region interest subregions color model 
formally consider partition associated set color histograms subregions rigidly linked 
possible introduce additional state variables model relative movement scaling subregions necessary 
assuming conditional independence color measurements different subregions defined state color likelihood histogram collected region color likelihood model contrast foreground background models developed :10.1.1.4.7932
hypothesized state models evaluate pixels grid nodes covered object foreground model remaining pixels grid nodes location dependent background models 
likelihood scene obtained multiplying individual pixel grid node likelihoods independence assumption 
type likelihood principled suffers numerical instabilities experience histogram color model proposed powerful tracking cue 
histogram color measurements construct efficient proposal particle filter guiding regions state space characterized color distribution similar object interest 
setting distribution form motion measurements described section iii 
due ambiguity inherent color measurements tracking scenarios considered prefer intermittent ambiguous motion sound measurements construct proposal distributions 
motion cues color instantaneous motion activity captures important aspects sequence content extensively studied various perspectives 
particular problem motion detection detection objects moving relative camera covered abundant literature shall attempt review see review 
case static camera basic ingredient heart analysis absolute frame difference computed successive pairs images 
cue consider 
propose embed frame difference information likelihood model similar developed color measurements 
unifies description implementation ensures similar order magnitude visual cues 
alternative models easily accommodated 
denote absolute difference times case color model measurement histogram associated region implied state region color information collected rez data fusion visual tracking particles fig 

frame difference histograms motion likelihood 
left uniform histogram 
center instant sequence hypothesized state candidate motion histogram gathered extended region compared histogram bhattacharyya similarity measure 
right exponentiated similarity yields motion likelihood plotted subsampled grid function location scale factor fixed ai 
lie inside object interest 
contrast large part motion activity generated moving object concentrated silhouette object 
ensure silhouette included consider larger region motion measurements set pixel units experiments 
construction learning histogram model motion measurements straightforward task 
amplitude measurements depends appearance object contours current motion 
examined region contains movement measurements fall lower bin histogram 
movement commences measurements usually fall bins definitive pattern uniform regions produce low absolute frame difference values higher values characterize contours silhouette photometric edges 
accommodate variations chose motion histogram uniform similar color likelihood define motion likelihood construction likelihood illustrated fig 

motion proposal majority cases perceived motion object interest image sequence satisfy minimum smoothness constraints 
cases proposal distribution mimics characteristics state evolution model sufficient successful tracking 
happens lock lost due short periods partial total occlusion necessary reinitialize tracker 
setting objects interest moving entities 
cases useful design sophisticated proposal distribution exploits motion measurements allow jumps state space regions significant motion activity 
build proposal distribution evaluating histogram similarity measure subset locations image keeping scale factor fixed locations taken nodes regular grid step size depends affordable computational load 
typically step size pixel units 
simple thresholding locations satisfy retained 
locations high motion activity denoted define mixture proposal object location component gaussian random walk location state evolution model ensures smoothness motion trajectories 
second component mixture centered detected locations high motion activity 
location weight random walk component set 
fig 
illustrates construction motion proposal distribution 
sound cues section describes sound localization cues 
case motion cues sound cues intermittent discriminating 
sound localization cues obtained measuring tdoa audio signals arriving microphones comprising pair 
due configuration system tdoa gives indication bearing sound source relative microphone pair turn related horizontal position image 
follows describe tdoa measurement procedure 
derive likelihood model tdoa measurements 
develop efficient tdoa proposal particle filter inversion likelihood model 
proposal especially useful initialization recovering lock cases track lost brief periods partial total occlusion 
shift focus different speakers take turns conversation 
tdoa measurement process numerous strategies available measure tdoa audio signals arriving spatially separated microphones 
tracking application tdoa estimation strategy proceedings ieee vol 
march fig 

frame difference histograms motion proposal 
left absolute luminance frame difference instant 
center similarity measure candidate histogram uniform histogram plotted subsampled grid function location scale factor fixed ai 
locations high motion activity detected thresholding function indicated crosses 
right mixture gaussians high motion activity locations forming motion proposal distribution 
required computationally efficient strong assumptions number audio sources exact characteristics audio signals 
popular strategy satisfies requirements involves maximization generalized cross correlation function 
strategy various modifications applied success number sound source localization systems 
subsequently adopt obtain tdoa estimates tracking algorithm 
computation described length omit detail 
essentially correlation function versions signals arriving microphones 
positions peaks taken estimates sound sources acoustic environment microphones 
apart true audio sources ghost sources due reverberation contribute peaks 
attempting remove signal processing retain peaks predefined threshold candidates true tdoa 
specifically frame sound measurement vector denoted maximum tdoa measured easily obtained microphone separation value speed sound normally ms note number tdoa measurements varies time quite frequently tdoa measurements available 
cope ambiguity due presence multiple candidates true tdoa develop likelihood model described 
tdoa likelihood model section develop likelihood model tdoa measurements 
similar likelihood models developed radar tracking clutter tracking single multiple objects video sequences 
tdoa measurements depend position image furthermore hypothesis object position image deterministic hypothesis tdoa computed function simple linear mapping relates position image corresponding position camera image plane 
width image measured pixels width image plane measured metric units 
pinhole model camera focal length function relates position camera image plane sound source bearing 
function approximation relate sound source bearing hypothesized tdoa 
mapping entirely deterministic likelihood written form likelihood exposition 
assume candidate tdoa measurements independent likelihood factorized practice clutter measurements due reverberation expected somewhat coherent true source violating independence assumption 
accurate modeling reverberation requires detailed knowledge composition acoustic properties environment difficult obtain practice attempted 
model performed demonstrate section iv 
tdoa measurements associated true source remainder associated clutter 
distinguish cases introduce classification label associated true source associated clutter 
likelihood measurement true source taken rez data fusion visual tracking particles fig 

tdoa measurement statistics 
tdoa measurement error histograms gaussian approximations range signal noise levels reverberation times 
denotes indicator function set normalizing constant erf erf erf gaussian error function 
range admissible tdoa values measurement assumed true tdoa corrupted additive gaussian observation noise variance empirical studies proved reasonable assumption results fig 
show 
similar done example likelihood measurements associated clutter taken clutter assumed uniformly distributed admissible interval independent true source tdoa 
measurements total possible hypotheses 
measurements due clutter measurements corresponds true source remainder clutter 
formally likelihoods hypotheses follow straightforwardly removed 
set measurements correct hypothesis known final likelihood obtained summing possible hypotheses prior probability th hypothesis 
follows fix prior probability clutter hypothesis set prior probabilities remaining hypotheses equal 
assumptions likelihood tdoa measurements case tdoa measurements available likelihood simply set construction tdoa likelihood illustrated fig 

tdoa proposal case motion possible sound localization cues design efficient proposal distribution particle filter 
proposal allow tracker recover lock brief periods partial total occlusion 
setting objects interest speakers participating video teleconference 
case sound proposal aid tracker switch focus speakers take turns conversation 
objectives achieved designing proposal distribution object position incorporates tdoa measurements available 
informally inverse mapping easy obtain 
tdoa measurement passed resulting inverse mapping yield plausible position object 
capture notion smooth motion trajectories exploiting information tdoa measurements define tdoa proposal object position form component gaussian random walk component state evolution model ensures smoothness motion trajectories 
second component mixture incorporates tdoa measurements obtained inverting part likelihood model 
tdoa measurements equally weighted mixture 
derivative mapping easily obtained chain rule 
weight random walk component set measurements available case jumps allowed object position 
generating samples tdoa proposal straightforward 
mixture component picked sampling discrete distribution equal mixture proceedings ieee vol 
march fig 

sound measurements tdoa likelihood 
left stereo pair sound samples corresponding seconds video frame 
center stereo signals detected peak 
right associated likelihood function tdoa horizontal pixel coordinate image frame respectively 
table particle filter visual tracking color sound table particle filter visual tracking color motion 
notation stands location weights 
sampling random walk component trivial 
sampling component th tdoa measurement achieved sampling candidate delay passing resulting delay inverse mapping tracker architecture conclude section summarizing composition tracking algorithm 
consider main scenarios 
summarized table desktop setting depicted fig 
color main cue fuse information sound localization cue 
setting forms basis video teleconferencing applications 
second setting summarized table representative surveillance monitoring applications involving static camera 
sound localization cues generally absent fuse color motion localization cue 
settings employ form partitioned sampling 
setting sound likelihood gives information object coordinate image 
simulate resample component simulating new values remaining state components object coordinate scale factor resampling respect color likelihood 
implies search directly state space partition inference rez data fusion visual tracking particles table model parameters tracking experiments fig 

color tracking single models 
global color model generated hand selected region initial frame region interest player top sequence child bottom sequence tracked robustly despite large motions significant motion blur dramatic shape changes partial occlusions distracting colors background players top sequence sand face mother bottom sequence 
top sequence single region regions corresponding face shirt child bottom sequence 
box frame indicates mmse estimate 
search dimensional space followed space 
general increases efficiency particle filter allowing achieve accuracy smaller number particles 
follow similar strategy second setting fuse color motion simulate resample location parameters respect motion likelihood simulating scale factor resampling respect color likelihood 
iv 
demonstrations section demonstrate performance tracking algorithm number challenging video sequences 
consider behavior tracker cues isolation show shortcomings single modality trackers eliminated fusing information multiple cues 
values table fixed parameters likelihood proposal state evolution 
due efficiency motion sound proposals relatively low dimensionality state space tracking results achieved reasonably small number particles 
experiments particles 
single modality tracking color color object persistent feature main cue tracking algorithm 
case deterministic color trackers proposed probabilistic tracker color able robustly track objects undergoing complex changes shape appearance :10.1.1.28.41
exemplified sequence football player top row fig 

robustness tracker color clutter large movements increased ability incorporate color models illustrated home video example bottom row fig 

downside color persistence lack discriminating power certain settings 
cases background contains objects similar color characteristics object interest likelihood exhibit number modes 
typical example office scene fig 
wooden door close color space faces subjects tracked 
circumstances ambiguities lead inaccurate tracking worst case complete loss lock 
scenarios robustness tracking algorithm greatly increased fusing color cues proceedings ieee vol 
march fig 

tracking moving objects motion cues 
uniformly initialized particle filter locks moving vehicle frames enters scene motion proposal 
tracker maintains lock moving vehicle drives parking lot 
box represents mmse estimate 
fig 

motion cues 
vehicle tracked sequence fig 
eventually stops motion cues disappear particles diffuse dynamics 
rectangles indicate hypothesized regions resampling lighter rectangles depicting best particles 
cues exhibiting complementary properties lower persistence prone clutter 
discussed motion sound cues 
prove valuable addition color static camera settings smart environment monitoring combine color teleconferencing applications calibrated stereo microphone pair easily added broadcasting recording equipment 
demonstrate power limitations motion sound single modality tracking cues investigate fusion scenarios 
motion section illustrate behavior tracker frame difference motion cue 
cue moving objects tracked reasonable degree accuracy result sequence fig 
indicates 
motion cue intermittent motion ceases localization information particles diffuse dynamics illustrated fig 

see section iv fusion motion color effectively eliminates shortcomings 
sound section illustrate behavior sound tracker tracking horizontal position speaker image tdoa measurements obtained stereo microphone pair 
evident cue allows localization coordinate endows tracker ability switch focus speakers take turns conversation 
consider sequences featuring subjects discussion front camera 
sequence environment relatively noise free speech consistently detected 
fig 
shows snapshots tracking result sequence 
clear proposal defined allows tracker maintain focus current speaker sufficient degree accuracy 
facilitates switching focus speakers alternate conversation 
note tracking accurate limit image plane evident subject right 
result encouraging light obtained low cost shelf equipment 
extreme care placement microphones relative camera required 
system roughly calibrated proved robust exact values chosen intrinsic parameters camera 
furthermore explicit attempts compensate reverberation background noise 
second sequence snapshots fig 
signal noise ratio higher due higher level air conditioner noise background subjects microphones 
due higher noise level speech undetected exemplified graphs fig 
show speech detections speaker relation ground truth 
detection failures result rapid diffusion particles evident number snapshots fig 

sound cue lacks persistence detection failures absence speech sound tracker unable provide consistent tracking time 
addition sound cue gives information vertical location scale factor object tracked 
see section iv fusion sound color solve problems retaining desirable properties sound localization cue 
rez data fusion visual tracking particles fig 

sound tracking accurate speech detection 
period silence frames uniformly initialized particles keep diffusing sound tracker consistently tracks horizontal position current speaker 
vertical segments indicate positions particles current time step lighter segments depicting best particles 
particles falling inside image displayed 
particle cloud partly completely invisible tracker correctly follows speaker right exiting field view camera frames 
fig 

sound tracking sporadic speech detection 
due low signal noise ratio speech occasionally detected frames 
remainder time localization cues available particle filter simply diffuses dynamics frames 
fig 

speech detection ground truth subjects sequence fig 

left respectively right graph concerns subject left respectively right scene 
lines indicate speech detections correspond correct horizontal localization speaker image 
shaded area indicates hand labeled ground truth 
multiple modality tracking color motion mentioned section iv greatest weakness color localization cue ambiguity results due presence scene objects regions color features similar object interest 
extreme example tracking color fails completely fig 

fusing color motion cues ambiguity greatly reduced object interest moving 
exemplified likelihood maps individual cues combination cues fig 

illustration combination color motion allows accurate tracking vehicle fig 
color tracking failed 
periods motion tracker utilizes mainly information motion cue proceedings ieee vol 
march fig 

color tracking ambiguity 
color histogram generated region selected hand moving vehicle frame leads high degree ambiguity 
soon uniform initialization tracking algorithm gets stuck strong local minimum color likelihood corresponding parked vehicles 
box represents mmse estimate 
fig 

color motion compound likelihood 
head movement captured motion likelihood helps reduce ambiguity inherent color cues exemplified likelihood maps color likelihood motion likelihood product likelihoods plotted function location scale factor fixed ai 
fig 

fusing color motion 
case fig 
color model generated region selected hand moving vehicle frame 
motion proposal allows tracker lock moving vehicle soon enters scene 
lock maintained period motion due presence motion cues 
motion ceases sequence tracker relies color cues maintain lock contrast motion tracking fig 

box represents mmse estimate 
relying color information localization motion ceases sequence 
utility motion proposal illustrated tracking results sequence fig 

case localization information ambiguous color motion cues considered individually 
event motion proposal uniformly initialized tracker simply settles spurious modes combined likelihood 
help motion proposal tracker able lock target face soon enters scene 
motion pro continues generate hypotheses regions significant motion activity face torso monitor comply color likelihood eliminated resampling procedure lock maintained shown fig 

color sound demonstrate fusion color sound consider second sequence section iv 
initialize color model composed subregions better positioning accuracy face left subject depicted fig 

color particle filter uniform initial rez data fusion visual tracking particles fig 

color motion cues motion proposal 
top example person traversing field view motion cues ambiguous due activity face torso moving person computer monitor 
second row color model initialized face person leads additional ambiguities 
uniform initialization particles settle spurious local mode color likelihood 
sequence face approaches region particles lock desired target 
third row combining color motion modalities retaining smooth proposal alter behavior color tracker significantly particles move face frames earlier 
bottom contrast combined tracker motion proposal allows tracker lock face soon enters scene track 
regions high motion activity continually explored face torso monitor comply color model discarded resampling procedure 
rectangles indicate hypothesized regions resampling lighter rectangles depicting best particles 
fig 

color motion cues motion proposal 
mmse result tracker combines color motion localization cues motion proposal sequence fig 

ization locks subjects random maintains lock subject video sequence shown fig 

incorporating sound localization cues tracker able jump subjects take turns conversation depicted fig 

absence proceedings ieee vol 
march fig 

different runs color tracker 
color model defined threefold selection left frame 
uniform initialization tracker rapidly locks subjects random maintains lock subject sequence 
rectangles indicate bounding boxes particles lighter rectangles depicting best particles 
fig 

fusing color sound 
tracking result fusion color sound cues frames fig 

sound proposal allows tracker jump subjects alternate conversation frames 
absence sound cues lock maintained active speaker due information color cues 
rectangle frames depicts mmse estimate particle bounding box 
sound cues detection failures periods silence tracker maintains accurate lock active speaker due information color cues 
introduced generic mechanisms data fusion particle filtering develop particle filter tracker combining color motion sound localization cues novel way 
color persistent main cue tracking 
ambiguity inherent color representations resolved intermittent ambiguous motion stereo sound cues 
considered main scenarios 
color combined sound desktop setting forms basis video teleconferencing applications 
second representative general tracking applications surveillance fused color motion localization cue 
scenarios combination cues proved robust cues individually 
standard practice defined independent likelihood models localization cues 
constructed mixture proposal distributions motion sound cues available 
proposals act detection initialization modules particle filter 
facilitate efficient exploration state space aid recovery lock periods partial complete occlusion 
context tracking event proposals essential detection new objects appear scene 
different stratified sampling procedures increase efficiency particle filter 
layered procedures effectively substitute difficult estimation problem complete state space sequence easier estimation problems reduced space 
combination appropriate conditionally independent data models event proposal densities layered importance sampling extended visual tracking scenarios involving fusion information shape cues predefined class object tracked 
considered fusion multiple measurement modalities essential requirement adaptive systems 
scenarios high degree confidence modality facilitates adaptation model parameters associated complementary modalities simultaneously minimizing risk learning wrong appearance model background 
adaptive systems useful tracking systems may desirable generic model objects scene 
rez data fusion visual tracking particles acknowledgment authors contribution experimental phase investigation 
anderson moore optimal filtering 
englewood cliffs nj prentice hall 
blake curwen zisserman framework spatiotemporal control tracking visual contours int 
comput 
vis vol 
pp 

blake isard active contours 
london springer verlag 
computer vision face tracking component perceptual user interface proc 
workshop applications computer vision pp 

carter coherence time delay estimation proc 
ieee vol 
pp 
feb 
chen liu trust region methods real time tracking proc 
int 
conf 
computer vision pp 
ii ii 
choo fleet people tracking hybrid monte carlo filtering proc 
int 
conf 
computer vision pp 
ii ii 
collins liu line selection discriminative tracking features proc 
int 
conf 
computer vision pp 

comaniciu ramesh meer real time tracking nonrigid objects mean shift proc :10.1.1.28.41
conf 
computer vision pattern recognition pp 
ii ii 
kernel object tracking ieee trans 
pattern anal 
machine intell vol 
pp 
may 
crowley coutaz things see machine perception human computer interaction commun 
acm vol 
pp 

average residual algorithm lara tracking motion arctic sea ice ieee trans 

remote sensing vol 
pp 
july 
dellaert burgard fox thrun con algorithm robust vision mobile robot localization proc 
conf 
computer vision pattern recognition pp 
ii ii 
doucet de freitas gordon eds sequential monte carlo methods practice 
new york springer verlag 
doucet godsill andrieu sequential monte carlo sampling methods bayesian filtering stat 
comput vol 
pp 

geweke bayesian inference econometrics models monte carlo integration econometrica vol 
pp 

gordon hybrid bootstrap filter target tracking clutter ieee trans 

electron 
syst vol 
pp 
jan 
gordon salmond smith novel approach nonlinear non gaussian bayesian state estimation iee proc 
vol 
pp 

haritaoglu harwood davis real time surveillance people activities ieee trans 
pattern anal 
machine intell vol 
pp 
aug 
isard blake condensation conditional density propagation visual tracking int 
comput 
vis vol 
pp 

unifying low level high level tracking stochastic framework proc 
eur 
conf 
computer vision pp 

smoothing filter condensation proc 
eur 
conf 
computer vision pp 

isard maccormick bramble bayesian multiple blob tracker proc :10.1.1.4.7932
int 
conf 
computer vision pp 
ii ii 
jepson fleet el robust online appearance models visual tracking proc 
conf 
computer vision pattern recognition dec pp 

kervrann heitz hierarchical markov modeling approach segmentation tracking deformable shape graph 
models image process vol 
pp 

kitagawa monte carlo filter smoother non gaussian nonlinear state space models comput 
graph 
stat vol 
pp 

knapp carter generalized correlation method estimation time delay ieee trans 
acoust speech signal processing vol 
assp pp 
aug 
koller meier ade tracking multiple objects condensation algorithm robot 

syst vol 
pp 

konrad motion detection estimation handbook image video processing bovik ed 
new york academic pp 

leymarie levine tracking deformable objects plane active contour model ieee trans 
pattern anal 
machine intell vol 
pp 
june 
liu chen sequential monte carlo methods dynamic systems amer 
stat 
assoc vol 
pp 

maccormick blake probabilistic exclusion partitioned sampling multiple object tracking int 
comput 
vis vol 
pp 

maccormick isard partitioned sampling articulated objects interface quality hand tracking proc 
eur 
conf 
computer vision pp 

chaumette visual servoing ieee trans 
robot 
automat vol 
pp 
apr 
marchand chaumette virtual visual servoing framework real time augmented reality proc 
eurographics pp 

moeslund granum survey computer vision human motion capture comput 
vis 
image understand vol 
pp 

bouthemy unsupervised segmentation low clouds infrared images contextual spatio temporal labeling approach ieee trans 

remote sensing vol 
pp 
jan 
pentland looking people sensing ubiquitous wearable computing ieee trans 
pattern anal 
machine intell vol 
pp 
jan 
rez hue color probabilistic tracking proc 
eur 
conf 
computer vision pp 

robust tracking position velocity kalman snakes ieee trans 
pattern anal 
machine intell vol 
pp 
june 
davis sampling condensation proc 
eur 
conf 
computer vision pp 

dahl french flanagan bianchi dsp implementation source location microphone arrays proc 
spie vol 
pp 

rui chen better proposal distributions object tracking unscented particle filter proc 
conf 
computer vision pattern recognition pp 
ii ii 
sidenbladh black learning people images videos int 
comput 
vis vol 
pp 

sidenbladh black fleet stochastic tracking human figures image motion proc 
eur 
conf 
computer vision pp 
ii ii 
sidenbladh black sigal implicit probabilistic models human motion synthesis tracking proc 
eur 
conf 
computer vision pp 

silverman stage algorithm determining talker location linear microphone array data comput 
speech lang vol 
pp 

sminchisescu triggs covariance scaled sampling monocular body tracking proc 
conf 
computer vision pattern recognition pp 

importance sampling proc 
eur 
conf 
computer vision pp 

schiele robust multi cue integration visual tracking int 
workshop computer vision systems vancouver bc canada 
acoustic source location dimensional space spectrum phase proc 
ieee int 
conf 
acoustic speech signal processing pp 

ph 
torr cipolla shape context chamfer matching cluttered scenes proc 
conf 
comp 
vision pattern rec pp 

proceedings ieee vol 
march toyama blake probabilistic tracking metric space proc 
int 
conf 
computer vision pp 
ii ii 
blake rez sequential monte carlo fusion sound vision speaker tracking proc 
ieee int 
conf 
computer vision pp 

rez blake improved observation models visual tracking selective adaptation proc 
eur 
conf 
computer vision pp 

crowley face tracking coding video compression proc 
int 
conf 
computer vision systems pp 

wang chu voice source localization automatic camera pointing system videoconferencing proc 
ieee int 
conf 
acoustic speech signal processing pp 

wren azarbayejani darrell pentland pfinder real time tracking human body ieee trans 
pattern anal 
machine intell vol 
pp 
july 
wu huang inference approach robust visual tracking proc 
int 
conf 
computer vision pp 
ii ii 
patrick rez born 
received eng 
degree cole paris paris france ph degree university rennes rennes france 
inria postdoctoral researcher department applied mathematics brown university providence ri 
full time researcher inria rennes france 
joined microsoft research cambridge research interests include probabilistic models understanding analyzing manipulating moving images 
jaco born south africa 
received eng 
eng 
degrees university south africa respectively ph degree university cambridge cambridge 
postdoctoral researcher microsoft research cambridge currently senior research associate signal processing group engineering department university cambridge 
research interests include audiovisual tracking techniques multimedia manipulation statistical signal processing methods machine learning 
andrew blake received degree mathematics electrical sciences trinity college cambridge ph degree university edinburgh edinburgh 
faculty computer science university edinburgh edinburgh royal society research fellow 
department engineering science university oxford oxford professor royal society senior research fellow 
appointed senior research scientist microsoft research cambridge continuing visiting professor oxford 
published number papers vision book visual reconstruction cambridge ma mit press zisserman book active contours london springer verlag isard edited active vision yuille cambridge ma mit press 
research interests computer vision signal processing learning 
dr blake elected fellow royal academy engineering 
rez data fusion visual tracking particles 
