parallel job scheduling status report dror feitelson school computer science engineering hebrew university jerusalem jerusalem israel larry rudolph laboratory computer science massachusetts institute technology cambridge ma usa uwe computer engineering institute universitat dortmund dortmund germany scheduling parallel jobs popular research topic years 
couple surveys written topic context parallel supercomputers 
purpose update material extend include concerning clusters grid 
part deals algorithmic research issues 
covers main approaches today backfilling gang scheduling 
advances reviewed terms perform scheduling terms understanding performance results 
second part covers current usage 
presents short overview vendor offerings reviews scheduling frameworks top ranking parallel systems 
advances parallel job scheduling research different ways schedule parallel jobs threads 
mechanisms practice studied detail 
approaches dominated decade backfilling gang scheduling 
section review variants connections 
review special requirements scheduling parallel jobs grid algorithms developed address 
backfilling basic batch scheduling algorithm come fcfs 
algorithm jobs considered order arrival 
processors available run job processors allocated job started 
processors available job wait currently running job terminate free additional processors 
subsequent jobs wait violate fcfs order 
may lead waste processing power processors sit idle waiting accumulate 
backfilling optimization tries balance goals utilization maintaining fcfs order 
allows small jobs move ahead run processors remain idle 
done subject restrictions avoid situations fcfs order completely violated jobs run phenomenon known starvation 
particular jobs need wait typically reservation time 
reservations included early batch schedulers 
backfilling small jobs move forward utilize idle resources introduced 
done context easy extensible argonne scheduling system developed large ibm sp installation argonne national lab 
improved algorithms concept backfilling quite simple variants subtle differences 
described settings different parameters algorithm 
parameter number reservations 
original easy backfilling algorithm queued job received reservation 
means job run sufficient processors available estimate processors available reserve job 
jobs may violate reservation 
terminate time reservation known shadow time processors required job 
problem backfilling may cause delays execution waiting jobs get reservation 
obvious alternative reservations jobs 
approach named conservative backfilling 
simulation results indicate delaying jobs rarely problem conservative backfilling tends achieve reduced performance comparison aggressive easy backfilling 
maui scheduler includes tunable parameter allows system administrators decide reservations 
chiang suggest making reservations compromise 
intriguing idea context reservations adaptively needed 
realized noting different jobs delayed previous backfilling decisions 
job delayed reservation job 
essentially equivalent earlier flexible backfilling jobs reservations backfilling allowed violate reservations certain slack 
setting slack threshold adaptive reservations equivalent making reservation delay exceeds threshold 
second parameter backfilling algorithm order queued jobs 
original easy scheduler systems designs fcfs order 
general alternative prioritize jobs way select jobs scheduling including candidates backfilling priority order 
flexible backfilling combines types priorities administrative priority set favor certain users projects user priority differentiate jobs user scheduler priority guarantee job starved 
maui scheduler priority function includes components 
special type prioritization depends job characteristics 
particular chiang proposed set criteria resource consumption generalizations known shortest job sjf scheduling algorithm 
shown improve performance metrics especially particularly sensitive performance short jobs slowdown 
third parameter amount lookahead queue 
previous backfilling algorithms consider queued jobs time try schedule 
order jobs scheduled may lead loss resources fragmentation 
alternative consider queue try find set jobs maximize desired performance metrics 
done dynamic programming leading optimal packing improved performance 
effect user runtime estimates backfilling depends estimates long job run 
estimates additional processors available verify jobs terminate time violate reservations 
source estimates typically user runs job 
jobs try run estimated runtime usually terminated system 
regard estimates upper bounds tight estimates 
initial expectations user runtime estimates tight low estimates improve chance backfilling 
comparisons user estimates real runtimes show tend inaccurate users requested provide best possible estimate danger having job killed estimate low 
attempts derive better estimates automatically historical information previous runs successful suffered estimations backfilling lead killed jobs 
surprisingly studies demonstrated inaccurate runtime estimates lead improved average performance 
simply result backfilling due holes schedule inflated runtime estimates create holes schedule enlarge potential jobs making harder fit holes 
result sequence events small jobs prevent holes closing leading strong preference short jobs automatic production sjf schedule 
motivates construction algorithms explicitly favor short jobs proposed 
necessarily indicate accurate runtime estimates impossible useless 
estimates bad cases users provide reasonably accurate estimates 
studies indicate users provide reliable estimates benefit jobs receive better service scheduler 
deriving estimates automatically possible jobs possible short jobs jobs exhibited especially small variability past 
inaccurate user runtime estimates shown surprising effects performance evaluations 
nutshell seen workloads numerous long single process jobs inaccurate estimates allow significant backfilling jobs aggressive easy backfilling conservative backfilling 
turn detrimental performance short jobs delayed long jobs 
accurate estimates effect reversed leading situation short jobs favored long ones 
evaluation methodology scheduling technology 
gang scheduling main alternative batch scheduling gang scheduling jobs preempted re scheduled unit involved processors 
notion introduced ousterhout analogy working set memory pages argue working set processes scheduled application efficient progress 
subsequent emphasized gang scheduling affair job processes run 
point gang scheduling provides environment similar dedicated machine job threads progress time allows resources shared 
particular preemption improve performance face unknown 
prevents short jobs stuck queue waiting long ones improves fairness 
flexible algorithms problem gang scheduling requirement job processes run causes fragmentation 
led proposals flexible variants 
variant called paired gang scheduling designed alleviate inefficiencies caused activity 
conventional gang scheduling processor running processes perform remain idle duration operation 
paired gang scheduling jobs complementary characteristics paired processes perform compute 
job mix lead improved resource utilization little penalty individual jobs 
general approach monitor communication behavior applications try determine really benefit gang scheduling 
gang scheduling need 
processes belonging jobs filler reduce fragmentation cause gang scheduled jobs 
dealing memory pressure early evaluations gang scheduling assumed arriving jobs started immediately 
high loads lead situations dozens jobs share processor 
unrealistic jobs need memory resident suffer paging interfere synchronization job threads 
simple approach avoiding problem admission controls allow additional jobs start memory available 
alternative placing oblivious cap multiprogramming level mpl usually range jobs 
avoids need estimate memory new job need vulnerable situations memory paging may occur 
admission controls jobs wait queue question queue order presents 
simplest option obviously fcfs order 
improved performance obtained backfilling allowing small jobs move ahead queue 
fact backfilling fully compensates loss performance due limited number jobs run concurrently 
schemes may suffer situations long jobs allocated resources short jobs remain queue await turn 
solution preemptive long range scheduling scheme 
construction long scheduler allocates memory waiting jobs short scheduler decides jobs run memory resident 
long turn scheduler may decide swap job memory long time room queued job waiting long time 
scheme designed tera cray mta machine 
system integration commercially successful implementation gang scheduling far connection machine cm 
implementations intel paragon suffered significant overheads generally 
advances implementation gang scheduling experimental systems 
gang scheduling requires context switching synchronized nodes machine 
hard achieve large machines may suffer significant overheads 
modern interconnection networks provide hardware support global operations exploited runtime system 
done storm parallel system activities expressed terms basic primitives turn supported hardware quadrics network 
particular design resulted scalable implementation gang scheduling 
high performance networks enable efficient implementation system primitives may cause problems multiprogramming 
difficulty arises due user level communication user processes access network interface cards nics directly avoid overheads involved trapping operating system 
result protection available job nics 
solved switching communication buffers part gang scheduling context switch operation 
possible problem reduced memory available nics continues grow 
tighter integration communication scheduling buffered scheme proposed feng 
scheme execution jobs partitioned system phases 
phase processes executed try perform communication operation blocked communication buffered 
phase required communications scheduled achieve optimal performance performed phase 
leads complete overlap computation communication 
gang scheduling originally developed order support fine grain synchronization parallel applications 
greater benefit may contribution reducing interference 
problem nodes parallel machines clusters typically run full operating system various user level daemons required various system services 
daemons may wake unpredictable times order perform function 
obviously interferes application process running node 
interferences synchronized nodes application slowed considerably different processes delayed 
gang scheduling possible run daemons different nodes time eliminate interference user jobs running 
done full capabilities hardware achieved 
parallel job scheduling grid parallel computers part called computational grid 
name grid chosen analogy electrical power grid power plants provide numerous consumers electrical power consumer aware origin power draws net 
similarly goal computational grid simply grid allow users run jobs suitable computer belonging grid 
way computational load balanced machines 
clearly grid mainly interest large computational jobs jobs large data set smaller jobs usually run locally 
grid restricted kind jobs cover wide range general services 
moment large computational jobs form dominant grid application 
addressing scheduling problem grid necessary point differences parallel computer grid 
parallel computer central resource management system control individual processors 
grid compute resources typically different owners distributed systems central control 
compute resource typically local resource management system implements policy owner 
grid scheduling architecture built top existing local resource management systems 
requires communication different layers scheduling system grid 
distributed system central grid scheduler may result performance bottleneck lead failure system scheduler fails 
appropriate decentralized grid scheduler architecture distributed algorithms 
grid resources heterogeneous hardware software imposes constraints suitability resource job 
addition user may accepted machine due implemented owner policy 
grid scheduler determine resources specific submitted job problem usually encountered parallel processor cluster computers 
grid subject frequent changes compute resources may temporarily withdrawn grid due maintenance privileged non grid request owner 
obtain data grid scheduler needs specific grid information service necessary date information assumed available parallel computer 
today main purpose grid computing considered area cross domain load balancing 
support idea globus toolbox provides basic services allow construction grid scheduler 
help basic services grid schedulers constructed run top commercial resource manage ment systems lsf pbs 
existing systems condor adapted include grid scheduling abilities allow integration grid scheduler 
parallel computer embedded grid large variety jobs different users run machine 
increasingly difficult implement usage policy owner help simple scheduling criteria today utilization response time 
assumed grid change job scheduling strategies parallel computers 
practise effect observed 
large grid application projects lcg datagrid griphyn frequently include construction grid scheduler 
unfortunately scope scheduler usually restricted corresponding application project 
hand academic projects specifically address scheduling issues generation distribution selection resource offerings 
various means instance economic methods 
approach job responsible scheduling 
speak application scheduler 
important jobs complex workflow subject complex parallelization constraints 
example approach taken apples project 
continuation metacomputing ideas considered computational grid single parallel processor computational resources parallel computers grid combined solve single large problem situation network performance varies greatly communication parallel computer communication parallel computers 
models derived evaluate performance called multi site computing 
practice approach implemented possible exception combination specific parallel computers specific purpose 
important component grid single parallel resource allocation 
means resources different machines need allocated job time 
hard accomplish due fact different resources belong different owners common resource management infrastructure 
way circumvent problem try reserve resources different machines required reservations successful 
parallel job scheduling practice vendor offerings commercial scheduling software parallel jobs comes types portable standalone systems components specific system 
main competitors market scheduling software 
platform computing load sharing facility lsf utopia project 
portable batch system pbs 
provide similar functionality 
particular provide support various administrative tasks lacking research prototypes 
addition vendors parallel supercomputers typically provide sort scheduling support systems 
includes schedulers ibm sp cray origin hp sun systems 
actual usage order determine job scheduling strategies parallel processors applied practice considered powerful parallel computers actual top list 
information strategies case mainly retrieved publicly available information sources web 
addition sites contacted directly asked provide information 
parallel computers classified groups parallel vector processors computers belong class consist nec leader top list installations cray 
parallel processors considered computers true parallel processors 
types ibm sp power ibm 
clusters larger variety types clusters xeon clusters clearly dominate cluster installation considered computer systems 
parallel vector processors cray installations scheduling system consisting pbs pro load balancer gang scheduler 
able obtain additional information 
scheduling different earth simulator currently powerful parallel processor top list 
system uses queue small batch requests queue queue large batch requests queue 
queue ers ii scheduling system 
ers ii supports gang scheduling feature queue 
customized scheduler support gang scheduling 
earth simulator scheduling systems support backfilling checkpointing 
parallel processors ibm systems supports backfilling 
allows job prioritization mentioned feature description installations 
direct replies confirmed job prioritization may assume systems explicitly mentioned 
newer versions support gang scheduling descriptions 
max plank society germany explicitly states gang scheduling possible 
shows installations decided gang scheduling 
lawrence livermore national labs developed home grown resource management system called livermore computing resource management system supports backfilling reservation preemption gang scheduling 
system asci white installation cluster installations lawrence livermore national labs 
asci white system batch partition interactive partition uses single queue classes jobs expedited normal stand 
currently preemption feature 
utilization 
reservation installation european centre medium range weather forecast 
enhanced special job filter 
system separates serial parallel jobs assigning different classes classes serial jobs classes parallel jobs 
utilization system 
similar utilization achieved mentioned parallel processor max plank society elaborate scheme job queues 
able obtain information parallel processors gang scheduling supported asci red system consisting intel xeon processors paragon operating system 
clusters various commercial resource management systems cluster installations including various form pbs lsf 
frequently combined maui scheduler 
mentioned lawrence livermore national labs clusters 
linux clusters simple linux utility resource management especially low priority jobs 
pittsburgh supercomputing center developed custom scheduler called simon top order support variety advanced scheduling features advance reservation backfilling checkpointing 
general stated scheduler cluster installations support backfilling job prioritization 
gang scheduling preemption advance reservations checkpointing frequently parallel processor installations 
installations computing nodes single partition 
exceptions 
instance pacific northwest national lab additional partitions management user log nodes nodes lustre file system nodes 
partitions relatively small comparison total number nodes compute partition 
cluster los alamos national labs file serving nodes allow interactive access lsf 
los alamos national lab uses queues active queues special purpose queues installations addition queues specifically set project 
clusters users submit different queues 
utilization systems depends applications ranges approximately los alamos national lab days pittsburgh supercomputing center 
kahan mccann smith scheduling tera mta 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

measurement simulation study processor allocation multicluster systems 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

feitelson gang scheduling memory considerations 
th intl 
parallel distributed processing symp pp 
may 
influence communication performance 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

influence structure sizes jobs performance allocation 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 


chiang arpaci dusseau vernon impact accurate requested runtimes production job scheduling performance 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

cirne berman adaptive selection partition size supercomputer requests 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

das sharma pradhan job scheduling mesh multicomputers 
intl 
conf 
parallel processing vol 
ii pp 
aug 
hamscher enhanced algorithms multi site scheduling 
proceedings rd international workshop grid computing baltimore springer verlag lecture notes computer science lncs 
hamscher advantages grid computing parallel job scheduling 
proc 
nd ieee acm int symp 
cluster computing grid ccgrid ieee press berlin may 
hamscher effects machine configurations parallel job scheduling computational grids 
international conference architecture computing systems arcs pp 
vde karlsruhe april 
hamscher economic scheduling grid computing 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

grid resource management state art trends chap 
applying economic scheduling methods grid environments pp 

kluwer academic publishers 
feitelson user level communication system gang scheduling 
th intl 
parallel distributed processing symp apr 
feitelson experimental analysis root causes performance evaluation results backfilling case study 
technical report school computer science engineering hebrew university mar 
feitelson metric workload effects computer systems evaluation 
computer pp 
sep 
feitelson survey scheduling multiprogrammed parallel systems 
research report rc ibm watson research center oct 
feitelson mu weil utilization predictability scheduling ibm sp backfilling 
th intl 
parallel processing symp pp 
apr 
feitelson rudolph gang scheduling performance benefits fine grain synchronization 
parallel distributed comput 
pp 
dec 
feitelson rudolph parallel job scheduling issues approaches 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springerverlag 
lect 
notes comput 
sci 
vol 

feitelson fernandez parallel job scheduling dynamic workloads 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

feitelson fernandez flexible mitigating load imbalance improving utilization heterogeneous resources 
th intl 
parallel distributed processing symp apr 
fernandez coll storm lightning fast resource management 
supercomputing nov 
hamscher evaluation job scheduling strategies grid computing 
proc 
th int conf 
high performance computing pp 
springer berlin lecture notes computer science lncs bangalore 
henderson job scheduling portable batch system 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

intel ipsc multi user accounting control scheduling utilities manual 
order number may 
jackson snell clement core algorithms maui scheduler 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

lee hardy user runtime estimates inherently inaccurate 
th job scheduling strategies parallel processing jun 
anl ibm sp scheduling system 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

litzkow livny mutka condor hunter idle workstations 
th intl 
conf 
distributed comput 
syst pp 
jun 
moreira chan fong franke infrastructure efficient parallel job execution computing environments 
supercomputing nov 
reducing variance point point transfers parallel real time programs 
ieee parallel distributed technology pp 
winter 
mu feitelson utilization predictability workloads user runtime estimates scheduling ibm sp backfilling 
ieee trans 
parallel distributed syst 
pp 
jun 
ousterhout scheduling techniques concurrent systems 
rd intl 
conf 
distributed comput 
syst pp 
oct 

feng buffered new methodology multitasking parallel jobs distributed systems 
th intl 
parallel distributed processing symp pp 
may 

feng time sharing parallel jobs presence multiple resource requirements 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

case missing supercomputer performance achieving optimal performance processors asci 
supercomputing nov 
pruyne livny parallel processing dynamic resources 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springerverlag 
lect 
notes comput 
sci 
vol 

analysis come serve parallel job scheduling 
proceedings th siam symposium discrete algorithms pp 
january 
fairness parallel job scheduling 
journal scheduling 
john wiley 
grid resource management state art trends chap 
attributes communication grid scheduling instances pp 

kluwer academic publishers 
shmueli feitelson backfilling lookahead optimize performance parallel job scheduling 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

mohammed dynamic allocation service multicluster systems 
th job scheduling strategies parallel processing jun 
snell clement jackson gregory performance impact advance reservation meta scheduling 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

srinivasan sadayappan selective reservation strategies job scheduling 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

feitelson supporting priorities improving utilization ibm sp scheduler slack backfilling 
th intl 
parallel processing symp pp 
apr 

preparation 
uno tani job scheduling earth simulator 
nec res 
develop 
pp 
jan 
ggf attributes communication scheduling instances 
www ggf org documents pdf dec 
feitelson paired gang scheduling 
ieee trans 
parallel distributed syst 
pp 
jun 
yoo simple linux utility resource management 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

zhang franke moreira integrated approach parallel scheduling gang scheduling backfilling migration 
ieee trans 
parallel distributed syst 
pp 
mar 
zhang franke moreira improving parallel job scheduling combining gang scheduling backfilling techniques 
th intl 
parallel distributed processing symp pp 
may 
zhou zheng wang delisle utopia load sharing facility large heterogeneous distributed computer systems 
software pract 
exp pp 
dec 
keleher job length estimation performance backfilling schedulers 
th intl 
symp 
high performance distributed comput aug 

