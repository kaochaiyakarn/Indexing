combining pairwise sequence similarity support vector machines remote protein homology detection li liao central research development du pont de li liao usa dupont com key element understanding molecular machinery cell understand meaning function protein encoded genome 
successful means inferring function previously unannotated protein sequence similarity proteins functions known 
currently powerful homology detection methods svm fisher method jaakkola haussler ismb 
method combines generative profile hidden markov model hmm discriminative classification algorithm known support vector machine svm 
current presents alternative method protein classification 
method svm pairwise uses pairwise sequence similarity algorithm smith waterman place hmm svm fisher method 
resulting algorithm tested ability recognize previously unseen families scop database yields significantly better remote protein homology detection svm fisher profile hmms psi blast 
proceedings sixth international conference computational molecular biology april 
pp 
william stafford noble department computer science columbia genome center columbia university noble cs columbia edu 
protein homology detection core problem computational biology 
detecting subtle sequence similarities proteins useful sequence similarity typically implies homology turn may imply functional similarity 
discovery statistically significant similarity proteins frequently justify inferring common functional role proteins 
past years researchers developed battery successively powerful methods detecting protein sequence similarities 
development broken stages 
early methods looked pairwise similarities proteins 
algorithms smith waterman dynamic programming algorithm accurate heuristic algorithms blast fasta trade reduced accuracy improved efficiency 
second stage accuracy achieved collecting aggregate statistics set similar sequences comparing resulting statistics single unlabeled protein interest 
profiles hidden markov models hmms methods representing aggregate statistics :10.1.1.148.3886
methods allow biologist infer nearly times homologies simple pairwise alignment algorithm 
stage additional accuracy gleaned leveraging information large databases unlabeled protein sequences 
iterative methods psi blast sam improve profile methods iteratively collecting homologous sequences large database incorporating resulting statistics central model :10.1.1.17.9507
resulting statistics generated positive examples sequences known posited evolutionarily related 
stage additional accuracy gained modeling difference positive negative examples 
homology task requires discriminating related unrelated sequences explicitly modeling difference sets sequences yields extremely powerful method 
svm fisher method couples iterative hmm training scheme discriminative algorithm known support vector machine svm currently accurate known method detecting remote protein homologies 
presents svm protein classification method uses pairwise sequence similarity algorithm place hmm svm fisher method 
svm fisher method new method called consist steps converting set proteins fixed length vectors training svm vectorized proteins 
methods differ vectorization step 
svm fisher method protein vector representation gradient respect profile hidden markov model svm pairwise method vector list pairwise sequence similarity scores 
pairwise score representation protein offers primary advantages profile hmm gradient representation 
pairwise score representation simpler dispenses profile hmm topology parameterization including training expectationmaximization 
second pairwise scoring require multiple alignment training set sequences 
distantly related protein sequences profile alignment may possible example sequences contain shuffled domains 
collection pairwise alignments allows detection motif domain sized similarities entire model easily aligned 
third advantage pairwise score representation negative training set 
profile hmm trained solely collection positive examples sequences known believed homologous 
svm adds model ability learn negative examples discriminating classes 
svm pairwise method discriminative advantage extended algorithm 
vector space defined pairwise scores includes dimensions sequence similarity scores unrelated positive training set 
dimensions contain significant similarity scores provide important evidence protein belonging positive class 
example query protein somewhat similar sequences positive class similar proteins negative class slight similarities positive class safely ignored 
absence negative examples classification sequence remain doubt 
section describes detail protein vectorization methods 
section followed experimental comparison protein homology detection methods 
methods include svm fisher svm pairwise methods blast algorithms psi blast family pairwise search fps profile hmm method sam variants svm pairwise algorithm called svm pairwise :10.1.1.17.9507:10.1.1.148.3886
measure ability algorithm discover previously unseen families scop database training sets members family superfamily :10.1.1.13.2991
experiments induce complete ranking methods order performance sensitive sensitive fps sam psi blast svm fisher svm pairwise svm pairwise 
set data algorithm described produces accurate means detecting remote homologs methods 
positive training set expectation maximization hidden markov model single protein positive negative training set single protein forwardbackward algorithm pairwise sequence comparison gradient vector pairwise score vector schematic diagram protein vectorization step svm fisher top bottom algorithms 

algorithm svm algorithm provides framework svm fisher svm pairwise methods simple 
algorithm addresses general problem learning discriminate positive negative members class dimensional vectors 
algorithm operates mapping training set possibly highdimensional feature space attempting locate space plane separates positive negative examples 
having plane svm predict classification unlabeled example mapping feature space asking side separating plane example lies 
svm power comes criterion selecting separating plane candidates planes exist svm chooses plane maintains maximum margin point training set 
statistical learning theory suggests classes behaved data choice maximum margin hyperplane lead maximal generalization predicting classification previously unseen examples 
svm algorithm extended cope noise training set multiple classes 
important requirement svm input collection fixed length vectors 
proteins course variable length sequences amino acids directly input standard svm 
svm fisher method hmm provides necessary means converting proteins fixed length vectors 
hmm trained positive members training set 
gradient vector sequence positive negative unlabeled computed respect trained model 
component gradient vector corresponds parameter hmm 
vector summarizes different sequence typical member protein family 
svm trained collection positively negatively labeled protein gradient vectors learns classify proteins extremely 
current accomplish similar method train svm pairwise positives negatives svm fisher positives negatives psi blast positives sam positives fps positives knn pairwise positives negatives svm pairwise positives negatives table protein homology detection methods conversion protein amino acid sequence fixed length numeric vector 
straightforward method suggested family pairwise search fps algorithm 
fps extends pairwise sequence comparison algorithm smith waterman blast carry sequence versus family comparisons combining multiple pairwise comparison scores 
blast fps efficient shown perform competitively hmm methods 
place explicit model protein family fps uses members family 
implicit model provides easy way vectorize protein simply store vector pairwise similarity scores respect member training set 
svm fisher method vectorized proteins fed svm 
call algorithm svm pairwise 
difference algorithms illustrated 
methods experiments reported compare performance algorithms svm pairwise svm fisher psi blast sam fps simplified versions svm pairwise called svm pairwise knn pairwise see table 
assess recognition performance algorithm testing ability classify protein domains superfamilies structural classification proteins scop version 
sequences selected astral database astral stanford edu removing similar sequences value threshold procedure resulted distinct sequences grouped families superfamilies 
family protein domains family considered positive test examples protein domains outside family superfamily taken positive training examples 
data set yields families containing family members positive test superfamily members outside family positive train 
negative examples taken outside positive sequences fold randomly split train test sets ratio positive examples 
details various families listed table complete data set available www 
cs columbia edu svm pairwise 
experimental setup similar jaakkola important difference current experiments positive training sets include additional protein sequences extracted large unlabeled database 
recognition tasks performed difficult jaakkola principle methods described applied iterative framework auxiliary database 
vectorization step svm pairwise uses smith waterman algorithm implemented hardware accelerator www com 
feature vector corresponding protein fx fx fx 
fxn total number proteins training set fxi value smith waterman score sequence ith training set sequence 
default parameters gap opening penalty extension penalties respectively blosum matrix 
svm implementation employs optimization algorithm described software available www 
cs columbia edu svm 
heart svm kernel function acts similarity score pairs input vectors 
base svm kernel normalized vector length feature space 
kernel transformed radial basis kernel follows width median euclidean distance feature space positive training example nearest negative example 
constant added kernel order translate data away origin 
translation necessary svm optimization algorithm employ requires separating hyperplane pass origin 
asymmetric soft margin implemented adding diagonal kernel matrix value fraction training set sequences label current sequence see details 
output svm discriminant score rank members test set 
svm parameters svm fisher svm pairwise tests 
hidden markov models trained sequence alignment modeling sam toolkit www soe ucsc 
edu research sam html :10.1.1.148.3886
models built unaligned positive training set sequences local scoring option sw 
component dirichlet mixture prior developed kevin karplus comp www soe ucsc edu research 
model obtained straightforward compare test sequences model local scoring option 
resulting values rank test set sequences 
svm fisher method uses trained hmms vectorization step 
baum welch training algorithm hmms forward backward matrices combined yield count observations parameter hmm 
shown counts converted components gradient vector equation ij ej ej ej ej number times amino acid positive set negative set positive set negative set id train test train test id train test train test table scop families included experiments 
family numbers sequences positive negative training test sets listed 
observed state ej emission probability amino acid state gradients computed hmm parameter svm fisher method uses gradient components correspond emission probabilities match states 
furthermore compact gradient vector derived mixture decomposition emission probabilities 
mixture gradient calculation analogous equation follows ej ej corresponds ith amino acid th dirichlet distribution 
experiments employ component dirichlet mixture mentioned 
profile hmm containing match states resulting vector contains components 
vectors input svm described 
comparison include experiments psi blast algorithm probably widely protein homology detection algorithm :10.1.1.17.9507
straightforward compare psi blast requires input single sequence methods svm fisher take multiple input sequences 
address problem randomly selecting positive training set sequence serve initial query 
psi blast run iteration database consisting remaining positive training set sequences 
extremely high value threshold applied training set sequences included resulting profile 
profile additional iteration time test set database 
resulting values rank test set sequences 
note psi blast run test set multiple iterations restriction lows fair comparison non iterative methods included study 
family pairwise family protein homology detection method blast algorithm 
include study simple form fps called fps minp 
method simply ranks test set sequence minimum blast values respect positive training set 
test variants svm pairwise algorithm 
order evaluate benefit provided negative elements pairwise score vector tested version svm pairwise negative training set creation score vectors 
method called svm pairwise negative examples training svm 
second order evaluate utility svm svm pairwise algorithm include method knn pairwise replaces svm simpler discriminative classifier nearest neighbor algorithm 
algorithm takes input feature vector svm svm pairwise 
classifying query protein orienting respect separating plane knn locates training set proteins nearest query protein euclidean distances vectors 
kernel version nearest neighbor kernel function svm 
predicted classification simply majority classification neighbors 
study 
sequences ranked number distance weighted votes positive class 
methods produces output ranking test set sequences 
measure quality ranking different scores receiver operating char roc scores median rate false positives rfp 
roc score normalized area curve plots true positives function false positives varying classification thresholds 
perfect classifier puts positives top ranked list receive roc score data random classifier receive roc score close 
median rfp score fraction negative test sequences score high better median scoring positive sequence 
rfp scores jaakkola evaluating fisher svm method 

results results experiments summarized 
graphs rank homology detection methods roc median rfp scores 
graph higher curve corresponds accurate homology detection performance 
performance measure svm pairwise method performs significantly better methods 
assess statistical significance differences methods tailed signed rank test 
resulting values conservatively adjusted bonferroni correction multiple comparisons 
shown table nearly differences apparent figures statistically significant threshold 
resulting induced performance ranking methods svm pairwise svm pairwise svm fisher psi blast sam fps 
differences psi blast sam svm pairwise svm pairwise statistically significant 
results agree previous assessments 
example relative performance svm fisher sam agrees results relatively poor performance fps algorithm task 
result probably due difficulty recognition task 
previous assessment fps competitive profile hmms tested algorithms remote homologies 
fps algorithm improved smith waterman values blast computing values sequence family comparisons 
expect improvements algorithm competitive best algorithms experiment 
surprise relative ranking sam psi blast previous sam significantly outperforms psi blast 
difference may explanations 
may improperly sam software setting parameters differently expert 
order reduce possibility repeated experiment align sequences build models score 
resulting roc median rfp scores similar scores produced sam data shown sets scores statistically significantly different psi blast scores 
second benefit sam may improved context iterated search 
third explanation improvement psi blast performance just psi blast algorithm improved considerably years may perform sam experimental paradigm 
svm pairwise svm fisher family family comparison fisher svm svm pairwise point graph corresponds scop superfamilies listed table 
axes roc scores achieved primary methods compared study svm fisher svm pairwise 
svm pairwise algorithm performs svm pairwise algorithm 
result implies power svm pairwise lie entirely negative training set vectorization 
large size negative training set svm pairwise considerably faster svm pairwise provides quite powerful efficient alternative 
placement knn pairwise algorithm psi blast svm fisher significant respects 
hand result shows pairwise similarity score representation brings considerable power method resulting state art classification method simple classification algorithm 
hand result shows utility svm algorithm svm methods perform better knn method 
certainly possible improve nearest neighbor implementation example generalization parzen windows 
reason suspect improvement yield better performance method 
significant result experiments performance svm pairwise method 
result illustrated shows family comparison roc scores computed method 
svm pairwise method scores higher svm fisher method nearly family 
outlier family relatively small training set 
family family results methods available www cs columbia edu svm pairwise 

discussion shown svm pairwise method yields significantly improved remote homology detection relative number existing state art algorithms 
svm fisher algorithm svm pairwise exploits negative 
families performance 
families performance svm pairwise svm pairwise svm blast svm fisher knn pairwise psi blast sam fps roc svm pairwise svm pairwise svm blast svm fisher knn pairwise psi blast sam fps median rfp relative performance homology detection methods graph plots total number families method exceeds score threshold 
top graph uses roc scores bottom graph uses median rfp scores 
series corresponds protein homology detection methods shown table 
svm svm knn psi sam fps pairwise fisher pairwise blast svm pairwise svm pairwise svm fisher knn pairwise psi blast sam table statistical significance differences pairs homology detection methods 
entry table value tailed signed rank test comparing paired roc scores methods families 
values conservatively adjusted multiple comparisons adjustment 
entry table indicates method listed current row performs significantly better method listed current column 
indicates value greater 
statistics median rfp scores similar 
training set yield accurate predictions 
svm fisher svm pairwise extends discriminative component vectorization step 
inclusion negative examples vectorization step adds small degree power algorithm 
important difference lies method proteins converted vector form 
vector pairwise similarity scores relaxes requirement multiple alignment training set sequences 
hypothesize difference explains excellent performance algorithm 
significant characteristic homology detection algorithm computational efficiency 
respect svm pairwise algorithm significantly better svm fisher 
algorithms include svm optimization roughly number training set examples 
vectorization step svm fisher requires training profile hmm computing gradient vectors 
gradient computation dominates running time nmp length longest training set sequence number hmm parameters 
contrast vectorization step svm pairwise involves computing pairwise scores 
smith waterman computation yielding total running time 
assuming svm pairwise vectorization takes approximately times long svm fisher vectorization 
ways speed svm pairwise vectorization 
obviously possible carry vectorization linear time approximation smith waterman blast 
modification immediately remove factor running time change presumably decrease accuracy algorithm 
second approach explicit vectorization set proteins creating feature vectors 
current implementation svm pairwise compares training test set sequence sequence training set 
reason columns vector matrix correspond training set sequences 
relatively small collection widely distributed sequences library profile hmms provide powerful concise vector signature protein 
different approach combining pairwise similarity scores svm build similarity score directly svm 
authors derived kernel functions allow direct comparison strings 
methods appealing protein homology detection obviate need explicit vectorization step 
direct comparison methods svm pairwise subject research 
acknowledgments mark providing access detailed results prior software computing fisher gradient vectors 
timothy bailey helpful discussion lewis implementation nearest neighbor algorithm 
supported award bioinformatics foundation national science foundation dbi isi 
resource provided national biomedical computation research san diego supercomputer center 
funded national center research resources rr 

altschul gish miller myers lipman 
basic local alignment search tool 
journal molecular biology 
altschul madden schaffer zhang zhang miller lipman :10.1.1.17.9507
gapped blast psi blast new generation protein database search programs 
nucleic acids research 
bailey grundy 
classifying proteins family product correlated values 
pevzner waterman editors proceedings third annual international conference computational molecular biology pages 
acm april 
baldi chauvin mcclure 
hidden markov models biological primary sequence information 
proceedings national academy sciences united states america 
bishop 
neural networks pattern recognition 
oxford oxford uk 
brenner levitt 
astral compendium sequence structure analysis 
nucleic acids research 
brown grundy lin cristianini jr ares haussler 
knowledge analysis microarray gene expression data support vector machines 
proceedings national academy sciences united states america 
cristianini shawe taylor 
support vector machines 
cambridge 
eddy 
multiple alignment hidden markov models 
rawlings editor proceedings third international conference intelligent systems molecular biology pages 
aaai press 
gribskov thy eisenberg 
profile analysis 
methods 
gribskov robinson 
receiver operating characteristic roc analysis evaluate sequence matching 
computers chemistry 
grundy 
family homology detection pairwise sequence comparison 
pevzner waterman editors proceedings second annual international conference computational molecular biology pages 
acm 
haussler 
convolution kernels discrete structures 
technical report ucsc crl university california santa cruz santa cruz ca july 
henikoff henikoff 
embedding strategies effective information multiple sequence alignments 
protein science 
jaakkola haussler 
fisher kernel method detect remote protein homologies 
proceedings seventh international conference intelligent systems molecular biology pages menlo park ca 
aaai press 
jaakkola haussler 
discriminative framework detecting remote protein homologies 
journal computational biology 
karplus barrett hughey 
hidden markov models detecting remote protein homologies 
bioinformatics 
krogh brown mian haussler :10.1.1.148.3886
hidden markov models computational biology applications protein modeling 
journal molecular biology 
leslie eskin noble 
spectrum kernel string kernel svm protein classification 
proceedings pacific symposium biocomputing 
appear 
brenner hubbard chothia 
scop structural classification proteins database investigation sequences structures 
journal molecular biology 
park karplus barrett hughey haussler hubbard chothia 
sequence comparisons multiple sequences detect times remote pairwise methods 
journal molecular biology 
pearson 
rapid sensitive sequence fasta 
methods 
salzberg 
comparing classifiers pitfalls avoid recommended approach 
data mining knowledge discovery 
smith waterman 
identification common molecular subsequences 
journal molecular biology 
thompson higgins gibson 
improving sensitivity progressive multiple sequence alignment sequence weighting position specific gap penalties weight matrix choice 
nucleic acids research 
vapnik 
statistical learning theory 
adaptive learning systems signal processing communications control 
wiley new york 
watkins 
dynamic alignment kernels 
smola bartlett sch lkopf schuurmans editors advances large margin classifiers 
mit press 
