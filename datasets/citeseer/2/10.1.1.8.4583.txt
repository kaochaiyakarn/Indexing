comparative study generative models document clustering shi zhong joydeep ghosh department electrical computer engineering university texas austin austin tx generative models multivariate bernoulli multinomial distributions widely text classification 
spherical means algorithm desirable properties text clustering shown special case generative model mixture von mises fisher vmf distributions 
compares probabilistic models text clustering theoretically empirically general model clustering framework 
model investigate strategies assigning documents models maximum likelihood means assignment stochastic assignment soft assignment 
experimental results large number datasets show terms clustering quality bernoulli model worst text clustering vmf model produces better clustering results bernoulli multinomial models soft assignment leads comparable slightly better results hard assignment 
deterministic annealing da improve vmf soft clustering compare model algorithms state art discriminative approach document clustering graph partitioning cluto spectral clustering method 
cluto da perform best computationally expensive spectral algorithm fares worse vmf methods 
document clustering increasingly important technique unsupervised document organization automatic topic extraction fast information retrieval filtering 
example web search engine returns thousands pages response broad query making difficult users browse identify relevant information 
clustering methods automatically group retrieved documents list meaningful categories achieved search engines northern light vivisimo 
similarly large database documents pre clustered facilitate query processing searching cluster closest query 
till mid nineties hierarchical agglomerative clustering suitable similarity measure cosine dice jaccard formed dominant paradigm clustering documents rasmussen cutting 
increasing interest processing larger collections documents led new emphasis designing efficient effective techniques leading explosion diverse approaches document clustering problem including multilevel self organizing map kohonen mixture gaussians spherical means dhillon modha bi means steinbach mixture multinomials vaithyanathan dom meila heckerman multi level graph partitioning karypis clustering bipartite spectral graph partitioning dhillon 
clustering methods proposed data mining divided categories discriminative similarity approaches indyk scholkopf smola vapnik generative model approaches rose cadez 
similarity approaches optimizes objective function involving pairwise document similarities aiming maximize average similarities clusters minimize average similarities clusters 
model approaches hand attempt learn generative models documents model representing particular document group 
focus model approaches provide advantages 
model partitional clustering algorithms complexity number data samples 
similarity approaches just calculating pairwise similarities requires time 
second cluster described representative model provides richer interpretation cluster 
third online algorithms easily constructed model clustering competitive learning techniques banerjee ghosh kaski 
online algorithms useful clustering stream documents news feeds incremental learning situations 
introduced unified framework probabilistic model clustering zhong ghosh includes generic treatment model partitional clustering methods 
basically generic model partitional clustering algorithm centers steps model re estimation step data re assignment step 
step view allows easily combine different models different assignment strategies 
shall exploit property assess data assignment strategies objective function point view 
specifically shall describe compare probabilistic models multivariate bernoulli multinomial von mises fisher clustering documents types data assignments leading total algorithms 
models directly handle high dimensional vectors dimensionality reduction recommended document clustering involves grouping vectors high dimensional sparse non negative entries directional vectors directions important typically normalized unit length 
contrast gaussian models means perform poorly datasets strehl 
instantiated algorithms compared number document datasets derived trec collections internet newsgroups 
goal empirically investigate suitability model document clustering identify model works better situations 
deterministic annealing da sophisticated soft clustering approach vmf models compared model algorithms state art graph approaches cluto karypis algorithm bipartite spectral method 
mccallum nigam performed comparative study bernoulli multinomial models text classification clustering 
comparisons different document clustering methods done steinbach karypis kumar zhao karypis 
focused comparing partitional hierarchical approaches model similarity clustering algorithms cluto toolkit 
meila heckerman compared hard vs soft assignment strategies text clustering multinomial models 
best knowledge comprehensive comparison different probabilistic models clustering documents done 
organization follows 
section summarizes general model partitional clustering framework analyzes data assignment strategies 
section describes algorithm mk means input data samples model structure set parameters model set parameters 
model represents cluster 
output trained models partition data samples cluster identity vector yn yi steps 
initialization initialize cluster identity vector 
model re estimation cluster oj oi yi parameters model log re estimated arg max oj 
sample re assignment data sample set yi arg max log oi 
change go back step 
model means algorithm 
probabilistic models clustering text documents 
section compares clustering performance different models data assignment strategies number text datasets 
section concludes 
model partitional clustering model means mk means algorithm fig 
generalized version standard means 
assumes parameterized model cluster 
set parameters th model denoted typically models family family exponential distributions 
basically algorithm iterates model re estimation step sample re assignment step 
fig 
maximum likelihood ml assignment step 
alternatively employ soft assignment em clustering sample gets fractionally assigned clusters posterior probability model trained posterior probability weighted samples 
information theoretic analysis assignment strategies kearns mansour ng empirical study meila heckerman multinomial models 
variant ml assignment strategy stochastic assignment sample stochastically assigned exactly clusters posterior probability 
call clustering algorithm assignment strategy stochastic mk means 
soft clustering additional set parameters mixture weights specify prior probabilities component models introduced 
generalize weight parameters construct general objective function maximized model partitional clustering zhong ghosh log log oi ij set model parameters estimated ij model mixture weights subject constraints ij applying em algorithm maximize derive general re estimation formula follows new arg max oi log oi new ij oi oi posterior probability cluster sample oi parameters oi oi 
ij oi equation model re estimation step posterior probabilities oi sample re assignment weights 
popular algorithms differ ij oi set 
setting ij yi cluster identity yi arg maxj log oi leads mk means algorithm 
constraining ij independent individual data samples ij results em clustering algorithm 
case re estimation needs modified new oi 
stochastic mk means ij discrete random variable takes value posterior probability 
worth emphasizing different assignment strategies change generic model re estimation formula plug probabilistic model formulation get series model clustering algorithms different assignment methods 
computational complexity algorithms described linear number data samples provided constant maximum number iterations model training algorithm linear complexity 
specifically complexity kn mk means stochastic mk means soft em clustering 
probabilistic models text documents traditional vector space representation text documents document represented high dimensional vector word counts document 
dimensionality equals number words vocabulary 
briefly introduce generative models studied experiments 
multivariate bernoulli model multivariate bernoulli model mccallum nigam document represented binary vector space words 
th dimension vector representing document di denoted bil indicating word wl occurs document 
number occurrences considered 
na bayes assumption probability document di cluster di pj wl bil pj wl bil 
indicator function takes value predicate argument true 
broad sense may represent individual words stemmed words tokenized words short phrases 
pj wl pj wl probability word wl cluster pj wl probability word wl cluster avoid zero probabilities estimating pj wl employ laplacian prior derive solution mccallum nigam pj wl di bil di di posterior probability cluster multinomial model na bayes assumption multinomial model cluster represents document di multinomial distribution words document di pj wl nil nil number word wl occurrences document di 
note pj wl represent word distribution cluster subject pj wl 
different pj wl estimated counting number documents cluster number times wl occurs documents cluster nigam 
laplacian smoothing parameter estimation multinomial models amounts pj wl di nil di nil di nil di nil size word vocabulary dimensionality document vectors 
von mises fisher model von mises fisher distribution analogue gaussian distribution directional data sense unique distribution normalized data maximizes entropy second moments distribution mardia 
shown spherical means algorithm uses cosine similarity metric measure closeness data point cluster centroid derived generative model vmf distribution certain restrictive conditions banerjee ghosh banerjee 
vmf distribution cluster written di exp dt di normalized unit length norm document vector bessel function normalization term 
measures directional variance dispersion higher peaked distribution vmf means algorithm assume clusters results spherical means dhillon modha dhillon 
model estimation case simply amounts nj yi di nj number documents cluster estimation mixture clustering algorithm difficult due bessel function involved 
banerjee em maximum likelihood solution derived including updates 
approximation estimating computationally expensive vmf means algorithm 
convenience simpler soft assignment scheme similar deterministic annealing 
constant models iteration start low value gradually increase distributions peaked unison iteration 
note effect inverse temperature parameter 
experimental results evaluation criteria objective clustering evaluation criteria internal measures external measures 
internal measure objective function clustering algorithm explicitly optimizes sum squared error criteria standard means 
document clustering external measures commonly typically documents category labels known course clustering process 
examples external measures include confusion matrix classification accuracy measure average purity average entropy mutual information ghosh 
simplest scenario number clusters equals number categories correspondence established external measures fruitfully applied 
number clusters differs number original classes confusion matrix hard read accuracy difficult impossible calculate 
argued mutual information governing cluster labels governing class labels superior measure purity entropy strehl ghosh 
normalizing measure lie range quite impartial choices normalization entropies 
shall follow definition normalized mutual information nmi geometrical mean nmi strehl ghosh practice sample estimate nmi nh nh log nh log nh nl log nl nh number data samples class nl number samples cluster nh number samples class cluster nmi value clustering results perfectly match external category labels close random partitioning 
better measure purity entropy biased high solutions strehl strehl ghosh 
experiments nmi evaluation criterion 
text datasets newsgroups data number datasets cluto toolkit karypis 
datasets provide representation different characteristics number documents ranges number terms number classes balance 
balance dataset defined ratio number documents smallest class number documents largest class 
value close indicates un balanced dataset 
summary datasets shown table 
kdd ics uci edu databases newsgroups newsgroups html www cs umn edu karypis cluto files datasets tar gz table summary text datasets dataset nd total number documents nw total number terms number classes nc average number documents class data source nd nw nc balance ng newsgroups ng overlapping subgroups ng classic cacm cisi cranfield medline ohsumed webace hitech san jose mercury trec reviews san jose mercury trec sports san jose mercury trec la la times trec la la times trec la la times trec tr trec tr trec tr trec tr trec ng dataset collection messages collected different usenet newsgroups messages 
preprocessed raw dataset bow toolkit mccallum including chopping headers removing words words occur documents 
resulting dataset document represented dimensional sparse vector total documents empty documents removed 
ng dataset subset ng containing messages categories different aspects politics 
categories expected difficult separate 
preprocessing step resulting dataset consists documents dimensional vector space 
datasets associated cluto toolkit preprocessed zhao karypis removed words appear fewer documents 
classic dataset obtained combining cacm cisi cranfield medline abstracts past evaluate various information retrieval systems dataset ohsumed collection hersh 
contains documents categories antibodies carcinoma dna vitro molecular sequence data pregnancy prognosis receptors risk factors tomography 
dataset webace project han 
document corresponds web page listed subject hierarchy yahoo 
www yahoo com 
datasets trec collections trec nist gov 
particular hitech reviews sports derived san jose mercury newspaper articles 
hitech dataset contains documents computers electronics health medical research technology reviews dataset contains documents food movies music radio restaurants sports dataset contains articles baseball basketball bicycling boxing football hockey 
la la la datasets obtained articles los angeles times categories entertainment financial foreign metro national sports 
datasets tr tr tr tr derived trec trec trec collections 
available ftp ftp cs cornell edu pub smart 
experimental setting compare model clustering algorithms resulting combination models assignment strategies 
example algorithms bernoulli model stochastic mixture abbreviated respectively 
similarly abbreviated names multinomial algorithms vmf algorithms 
soft vmf algorithm reason 
mentioned section estimation parameter vmf model difficult needed mixture algorithm 
simple heuristic iteration number 
constant clusters iteration gradually increasing iterations 
realizing purely ad hoc implemented standard deterministic annealing constant clusters iteration algorithm runs convergence follows exponential schedule starting 
call algorithm 
vmf algorithms log idf weighted normalized document vectors 
model algorithms maximum number iterations fair comparison 
experiment run times time starting different random initialization 
averages standard deviations nmi running time results reported 
state art graph clustering algorithms included experiments 
cluto karypis clustering toolkit metis graph partitioning algorithms karypis kumar 
worth mentioning cluto positioned clustering drops strong balance constraints original metis partitioning 
toolkit default setting 
modification bipartite spectral clustering algorithm dhillon 
modification ng generates slightly better results original bipartite clustering algorithm 
graph partitioning algorithms uses fast heuristics dependent order nodes input graph 
run algorithm times run different order documents 
results table shows nmi results ng ng datasets table nmi results classic datasets different number clusters dataset 
numbers table shown format average standard deviation 
save space show nmi results datasets specific table table 
models vmf model appears best multivariate bernoulli model worst 
bernoulli algorithms significantly methods datasets 
indicates noting word occurs document number occurrences limited representation 
vmf algorithms perform better multinomial ones especially smaller datasets ng tr tr tr tr deterministic annealing algorithm improves performance significantly shown table 
different data assignment strategies produce comparable clustering results datasets 
soft assignment slightly better classic dataset soft assignment multinomial model clearly best 
vmf log eigen directions normalize projected data vector 
table nmi results ng ng datasets ng ng cluto cluster table nmi results classic datasets classic cluto cluster models exact em clustering banerjee achieve significant improvement hard assignment 
surprisingly bipartite spectral clustering algorithm vmf methods gives poor results nmi values close 
graphbased algorithm cluto performs better best algorithms compared 
surprising built sophisticated multi level graph partitioning engine karypis kumar 
disadvantage approach similaritybased algorithms general lies computational complexity 
note standard deviations model clustering results larger cluto results indicating initialization effect model methods larger 
means develop initialization strategy results model clustering lean upper performance range shall see results comparable cluto results 
deterministic annealing improves local solutions sees moderate variation runs 
substantially improve initialization robustness model clustering remains challenging problem 
table shows running time results ng largest dataset experiments 
numbers recorded ghz pc running windows memory large hold individual dataset reflect clustering time including data cost 
table nmi results hitech reviews sports la la la datasets hitech reviews sports la la la cluto cluster table nmi results tr tr tr tr datasets tr tr tr tr cluto cluster clearly algorithms soft assignment take longer time hard assignments suggesting choose hard versions practice soft version buy performance case bernoulli multinomial models nmi results 
algorithm fastest 
cluto software package written algorithms matlab expect model algorithms re written considerably faster cluto 
concluding remarks unaware comprehensive comparative study generative models document clustering comparison models discriminative ones 
central goal fill void 
general framework model partitional clustering describe compare probabilistic models multivariate bernoulli multinomial von mises fisher clustering documents 
empirical results large number high dimensional text datasets highlighted trends bernoulli model appropriate text clustering von mises fisher model outperforms multi table running time results ng dataset seconds ng cluto cluster cluto written algorithms matlab 
nomial model clustering documents algorithms soft assignment run slower slightly improve clustering performance bernoulli multinomial models 
note full fledged em algorithm 
concurrent ut em algorithm allows different dispersion values different clusters lets em re estimate values iteration indicates substantial gains achieved banerjee 
preliminary investigation indicates superior results due annealing effect produced small initial automatically determined annealed em procedure 
analogous large initial variances mixture gaussians model 
results deterministic annealing soft vmf clustering show significant improvements obtained 
currently studying issue determine annealing augment model soft clustering methods 
model algorithms da computational advantage approaches need better initialization strategies generate clustering results comparable cluto 
meila heckerman compared initialization techniques clearly better quest effective techniques continues 
bradley fayyad employed sampling meta clustering clustering multiple solutions sampled datasets refine initial cluster centroids 
technique deserves investigation 
second direction improving local solution model algorithms tweak clustering process 
example local search employed dhillon 
improve performance spherical means algorithm 
online updates reported better batch updates spherical means dhillon soft vmf clustering banerjee ghosh online extensions model approaches need investigated 
observations currently fully explained need examination 
mixture multinomials competitive general perform best classic dataset 
small number separated clusters 
secondly spectral clustering perform dataset classic dataset poorly datasets 
spectral clustering methods kannan 
ng 
fare better 
matter deserves investigation 
acknowledgments dhillon guan banerjee helpful discussions results anonymous reviewers helpful comments improved technical quality 
partly supported ibm faculty partnership award ibm tivoli ibm research intel 
banerjee dhillon ghosh sra 

clustering hyperspheres expectation maximization technical report tr 
department computer sciences university texas 
banerjee ghosh 

frequency sensitive competitive learning clustering highdimensional hyperspheres 
proc 
ieee int 
joint conf 
neural networks pp 



survey clustering data mining techniques 
unpublished manuscript available accrue com 


gentle tutorial em algorithm application parameter estimation gaussian mixture hidden markov models technical report 
university california berkeley 
bradley fayyad 

refining initial points means clustering 
proc 
th int 
conf 
machine learning pp 

cadez smyth 

general probabilistic framework clustering individuals objects 
proc 
th acm sigkdd int 
conf 
knowledge discovery data mining pp 

cutting karger pedersen tukey 

scatter gather cluster approach browsing large document collections 
proc 
acm sigir pp 

dhillon 

clustering documents words bipartite spectral graph partitioning 
proc 
th acm sigkdd int 
conf 
knowledge discovery data mining pp 

dhillon fan guan 

efficient clustering large document collections 
grossman kamath kegelmeyer kumar eds data mining scientific engineering applications 
kluwer academic publishers 
dhillon guan kogan 

iterative clustering high dimensional text data augmented local search 
proc 
ieee int 
conf 
data mining 
dhillon modha 

concept decompositions large sparse text data clustering 
machine learning 
ghosh 

scalable clustering methods data mining 
ye ed handbook data mining 
lawrence erlbaum 
han boley gini gross hastings karypis kumar mobasher moore 

webace web agent document categorization exploration 
proc 
nd int 
conf 
autonomous agents pp 

hersh buckley leone 

ohsumed interactive retrieval evaluation new large test collection research 
proc 
acm sigir pp 

indyk 

sublinear time approximation scheme clustering metric spaces 
proc 
th symposium foundations computer science pp 

kannan vempala 

clusterings bad spectral 
st annual ieee symp 
foundations computer science pp 

karypis 

cluto clustering toolkit 
dept computer science university minnesota 
karypis kumar 

fast high quality multilevel scheme partitioning irregular graphs 
siam journal scientific computing 
kearns mansour ng 

information theoretic analysis hard soft assignment methods clustering 
proc 
th conf 
uncertainty artificial intelligence pp 

kohonen kaski lagus honkela saarela 

self organization massive document collection 
ieee trans 
neural networks 
mardia 

statistics directional data 
royal statistical society 
series methodological 
mccallum nigam 

comparison event models naive bayes text classification 
aaai workshop learning text categorization pp 

mccallum 

bow toolkit statistical language modeling text retrieval classification clustering 
www cs cmu edu mccallum bow 
meila heckerman 

experimental comparison model clustering methods 
machine learning 
ng jordan weiss 

spectral clustering analysis algorithm 
advances neural information processing systems pp 

mit press 
nigam 

unlabeled data improve text classification 
doctoral dissertation school computer science carnegie mellon university 
rasmussen 

clustering algorithms 
frakes baeza yates eds information retrieval data structures algorithms 
prentice hall 
rose 

deterministic annealing clustering compression classification regression related optimization problems 
proceedings ieee 
scholkopf smola 

learning kernels 
mit press 
sinkkonen kaski 

clustering conditional distributions auxiliary space 
neural computation 
steinbach karypis kumar 

comparison document clustering techniques 
kdd workshop text mining 
strehl ghosh 

cluster ensembles knowledge reuse framework combining partitions 
journal machine learning research 
strehl ghosh mooney 

impact similarity measures web page clustering 
aaai workshop ai web search pp 

stuetzle 

hierarchical model clustering large datasets fractionation 
proc 
th acm sigkdd int 
conf 
knowledge discovery data mining 
vaithyanathan dom 

model hierarchical clustering 
proc 
th conf 
uncertainty artificial intelligence pp 

vapnik 

statistical learning theory 
new york john wiley 
zhao karypis 

criterion functions document clustering experiments analysis technical report 
department computer science university minnesota 
zhong ghosh 

unified framework model clustering applications clustering time sequences technical report 
department ece university texas austin 
zhong ghosh 

scalable balanced model clustering 
rd siam int 
conf 
data mining 
appear 
