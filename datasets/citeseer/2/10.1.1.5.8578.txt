nonlinear time series prediction weighted vector quantization lendasse francois verleysen universit catholique de louvain av 
tre louvain la neuve belgium lendasse francois auto ucl ac dice pl du louvain la neuve belgium verleysen dice ucl ac 
classical nonlinear models time series prediction exhibit improved capabilities compared linear ones 
nonlinear regression drawbacks overfitting local minima problems user adjusted parameters higher computation times need simple nonlinear models restricted number learning parameters high performances reasonable complexity 
method nonlinear forecasting quantization vectors concatenating inputs regressors outputs predictions 
weighting techniques applied give importance inputs outputs respectively 
method illustrated standard time series prediction benchmarks 
time series prediction problem applications various domains finance electrical load river flood forecasting problem consists predicting value series known specific time known past values series possibly exogenous data 
classical methods ar arma box jenkins methodology various successes 
cases linear models sufficient predict series reasonable accuracy 
cases linear models reveal sufficient making nonlinear ones necessary 
potential increased performances nonlinear models dealing nonlinear processes balanced drawbacks learning concerns number learning parameters adjust increased computation times convergence difficulties overfitting need develop simple nonlinear models easy learning restricted number user adjusted parameters showing high performances datasets inherently non linear 
presents nonlinear regression method applied case time series prediction problem completion missing values quantization concatenated vectors 
general framework different schemes proposed weight respective importance variable inputs output concatenated vectors quantify 

eds iccs lncs pp 

springer verlag berlin heidelberg lendasse vector quantization vq problem show deal missing values section 
show vq missing values regression general time series prediction particular section including weighting inputs outputs 
section weighting technique applied non linear regression model radial basis function networks 
methods illustrated running examples inserted sections clarity 
section draws 
vector quantization definition vector quantization way summarize information contained large database 
define database example table 
database definition variable variable variable variable st data nd data rd data th data th data vi vi vij vid th data vnd elements observations data vectors database lines elements ij 
principle vector quantization vq replace database containing fewer vectors dimension 
number vectors parameter method 
new vectors called centroids deemed distribution similar distribution initial ones 
centroids fixed algorithm vector quantized nearest neighbor centroid arg min vi vq 
voronoi region associated centroid region space associated equation 
words region space nearest centroid 
determining best set centroids set minimizes average data contained original database quantization error defined distance equation nonlinear optimization problem 
algorithms proposed literature determine centroids batch algorithms lloyd line adaptive ones competitive learning method 
nonlinear time series prediction weighted vector quantization example competitive learning works follows 
iteration data drawn randomly initial database 
nearest centroid determined equation moved adapted direction data time decreasing adaptation factor 
operation repeated times database 
course vq algorithms find set centroids correspond local minimum quantization error criterion global 
initialization methods adaptation rules proposed literature aiming find compromise quality local minimum computational complexity number 
missing data easy understand known property vq databases missing data quantized easily 
imagine initial database form table 
database missing data variable variable variable variable st data nd data rd data th data th data vi vi vij vid th data vnd table corresponds value measured memorized reason missing values 
vq process defined equations remains valid computation euclidean distance equation replaced distance computed know variables missing ones course assumed centroids missing values 
similarly adaptation centroids equation performed corresponding existing coordinates data missing ones 
vq missing data proved efficient find estimations missing values databases 
missing value replaced corresponding variable centroid nearest observation 
technique may viewed estimating missing value function available variables observation ij kj nearest centroid equation distance computation restricted known coordinates known informa lendasse tion certainly appropriate replacing missing value average corresponding variable observations average column database case dealing incomplete data 
vq may viewed simple efficient way information contained known coordinates vector prediction vq missing data quantization weighting time series prediction may viewed regression problem expressed follows exogenous variables 
equation estimation unknown value time series time known past values series form regressor 
set parameters estimator estimator linear nonlinear general case 
past knowledge series concatenated dimensional vectors form vectors may viewed vectors initial database 
vq applied vectors 
vq model may incomplete vectors missing value precisely 
model equation consists approximation missing value corresponding coordinate nearest centroid equation 
method illustrated known time series benchmark mackey glass series 
series generated dy dt 
series sampled sampling period 
part series illustrated fig 
points generated ones learning vq ones validation 
regressor contains values series recommended literature 
order validate method define normalized mean square error nmse data validation set follows nv nmse yt nv yt nonlinear time series prediction weighted vector quantization fig 

mackey glass series see text parameters 
remind number centroids parameter vq method 
nmse validation set respect number centroids illustrated fig 
nmse number centroids fig 

nmse mackey glass series prediction vq 
surprisingly shows optimal number centroids high number learning data 
result surprising considered fact data generated equation noiseless 
centroids vq method equivalent lazy learning method consists looking learning data closest regressor 
lazy learning proved efficient noiseless problems 
method applied series added variance noise gives results illustrated fig 
optimal number centroids optimal nmse 
sake comparison linear model regressor gives nmse learning validation sets 
general comment number centroids decreases amount noise vq allows eliminate noise averaging voronoi region 
course price paid increased quantization error noiseless equivalent problem 
illustration wellknown bias variance dilemma 
lendasse nmse number centroids fig 

nmse mackey glass additive noise series prediction vq 
quantization weighting output method illustrated previous section obvious limitation size regressor large relative weight predictions quantization vectors equation decreases counts coordinate regards coordinated regressor 
straightforward extension method give different weight quantization predictions building vectors follows ky 
increasing means vq biased give importance prediction 
parameter may determined way number centroids vq optimization validation set 
optimization realized practice scanning range parameters double optimization timeconsuming 
suggested optimize parameters consecutively possibly iterative way 
way optimizing parameters guarantee find global minimum reasonable compromise quality optimization computational load 
noisy mackey glass series starting result previous section optimization gives 
value optimization results see fig 

optimizations improve result anymore 
quantization weighting inputs vq process implements particular nonlinear model defined equation 
compared nonlinear models mlp multi layer perceptrons equation drawback inputs coordinates vectors weighted equally 
evidently optimal 
step weight inputs building vectors follows nmse nonlinear time series prediction weighted vector quantization number centroids fig 

nmse mackey glass additive noise series prediction weighted vq 
ky 
optimization parameters heavy 
full search practicable gradient descent computed finite differences validation set results may slow 
reason suggest weights method 
quantization weighting inputs linear model building linear model yt yt 
yt coefficients may considered importance weighting variable plays output 
words partial derivative output respect specific input 
coefficients considered firstorder approximation coefficients needed 
course resulting linear hypothesis optimum sense defined previous section 
looking compromise impracticable full search inefficient priori choice 
coefficients linear model appear efficient regarding compromise 
linear model dimensional regressor previous example noisy mackey glass series gives roughly identical coefficients 
consequence coefficients improve previously results 
illustrate weighting vq coefficients linear model known time series prediction benchmark santafe series 
noise variance added 
part series illustrated fig 

previous example points learning validation 
regressor size 
fig shows nmse resulting weighting coefficients linear model improvement significant 
weighting output obtained method described section 
lendasse nmse fig 

santafe series 
number centroids fig 

nmse obtained prediction noisy santa fe series vq model dashed weighting inputs plain weighting inputs coefficient linear model 
radial basis function networks rbfn weighted inputs radial basis function networks rbfn class nonlinear approximators defined coefficients model centers resulting vector quantization inputs standard deviations multiplying factors learning rbfn models may achieved ways see example 
time series prediction problem vector inputs replaced regressors 
rbfn different vq methods 
cases underlying principle divide space spanned inputs voronoi regions 
differences vq rbfn 
nonlinear time series prediction weighted vector quantization 
vq applies specific exclusive model voronoi regions models centroid rbfn equation gaussian functions overlapping adjacent voronoi zones 

region specific model vq constant equal coordinate centroid see equations equivalent rbfn gaussian functions parameters 
regard comments rbfn viewed generalization vq models smoother approximation capabilities 
weighting output rbfn model sense appropriate output weights computed optimization standard procedure rbfn learning 
rbfn suffer drawback vq concerns priori identical weighting inputs 
rbfn context illustrated scalar standard deviation variance covariance matrix 
principle weighting inputs context vq may applied rbfn 
fig 
shows results rbfn model trained noisy santafe series inputs weighted coefficients linear model 
training rbfn model realized 
improvement due weighting clear 
nmse fig 

nmse obtained prediction noisy santa fe series rbfn model dashed weighting inputs plain weighting inputs coefficient linear model 
presents nonlinear time series prediction method quantization vectors missing data 
vectors concatenate inputs regressors outputs predictions 
estimating missing values predict outputs 
method restricted times series prediction may applied regression problems 
weighting regressor values predictions proposed improve quality estimation 
weighting scheme give adequate importance inputs rbfn model 
method illustrated standard time series prediction benchmarks results show clear improvements decreasing prediction error validation sets 
lendasse 
michel verleysen senior research associate belgian national fund scientific research 
lendasse fran ois supported attraction poles initiated belgian federal state ministry sciences technologies culture 
scientific responsibility rests authors 

lendasse lee verleysen width optimization gaussian kernels radial basis function networks esann european symposium artificial neural networks bruges 

birattari bersini lazy learning local modeling control design international journal control 

gray vector quantization ieee mag vol 


classification analyse des correspondences phd thesis paris 

kohonen self organizing maps springer series information sciences vol 
third edition 

lendasse lee de verleysen approximation radial basis function networks application option pricing accepted publication connectionist approaches economics management sciences ed kluwer academic publishers 

mackey glass oscillations chaos physiological control systems science 

som local models time series prediction proceedings workshop self organizing maps 

weigend gershenfeld times series prediction forecasting understanding past addison wesley publishing 
