inferring query models computing information flow language modelling approach information retrieval compute query models 
query model envisaged expansion initial query 
prominent query models literature probabilistic basis term vocabulary probability query computed 
introduces alternative nonprobabilistic approach query modelling strength information flow computed query term information flow reflection strongly informationally contained query words basis query model generation information inference 
information flow model hyperspace analogue language hal vector representations reflects lexical cooccurrence information terms 
research cognitive science demonstrated cognitive compatibility hal representations human processing hal vectors potentially useful basis inferring query expansion terms 
query models computed trec queries hal information flow compared experimentally probabilistic query language models 
experimental results provided showing hal information flow model superior query models computed markov chains effective probabilistically motivated relevance model 
main topics retrieval language models retrieval query expansion fusion information retrieval theory bruza song distributed systems technology centre university queensland australia bruza dstc edu au 
cranfield experiments document retrieval sixties known user queries information retrieval system typically imprecise descriptions information need 
phenomenon particularly emphasized respect queries web 
web queries average terms length 
short queries certainly poor descriptions associated information need 
various query expansion techniques developed order improve initial query user 
goal automatic query expansion automatically expand user initial query terms related query terms yielding query expanded query return documents user 
various models techniques proposed determining expansion terms 
thesaurus techniques thesaurus ontology source expansion terms example wordnet 
global collection expansion techniques involve analyzing collection documents computing term associations collection example basis term cooccurrence 
initial query expanded terms strongly associated query terms 
local collection expansion techniques generally follow process referred pseudo relevance feedback 
initial query issued retrieve ranked list documents 
top documents constitutes local collection 
terms extracted documents expand example local context analysis identifies terms neighbourhood query terms documents local collection 
techniques involve implicit relevance feedback assuming documents local collection relevant selecting terms local collection various methods example simple term frequency probabilistic basis robertson selection value :10.1.1.32.9922
global local techniques initial query massively expanded query hundreds terms 
language modelling approach information retrieval allowed query expansion re considered language modelling problem 
specifically query language model comprises estimating probability term vocabulary light initial query intuitively terms probabilities threshold considered useful candidate terms expanding initial query number promising approaches proposed estimating query language models 
lavrenko croft estimate query language model terms relevance model 
query considered random sample unknown relevance model envisaged unknown process words sampled query sampled terms probability term sampled 
essentially probability expressed term probability occurrence estimated sampling query terms number unigram top ranked documents retrieved distributions query serve distributions 
stated traditional ir perspective method massive query expansion technique 
approach query language modelling lafferty zhai generate query language models markov chains 
query model word probability expanding calculated language model estimated markov chain method prior probability translation model generating query model markov chain starts initial word alternates words documents 
word document selected document language model 
selected document word selected posterior probability 
markov chain lasts query term selected limit steps reached 
probabilistic approaches query language modelling promising points departure 
growing body research cognitive science corpus representations terms concepts computed correlate human processing 
model hyperspace analogue language hal 
hal represents words vectors high dimensional space lexical occurrence 
hal significant term associations computed model correlate human judgements word association tasks 
words hal representations promising basis compute term associations query expansion 
proposed information flow model hal vectors 
goal model produce information inferences correlate human inferences regard information 
essence hal information flow model computes degree term informationally contained conveyed carried terms im theoretical basis information inference drawn barwise seligman account information flow 
philosophical point view model accord views rdenfors advocate semiotic cognitive stance regard information representation processing probabilistic 
terms query terms terms flowing informationally query terms considered candidate query expansion terms 
probabilistic foundation query language model propose query language model degree information flow query vocabulary term goal hal information flow model compute query language model evaluate effectiveness comparing performance prominent probabilistic query language models 
broader level aiming gain initial picture information inference fares relation traditional probabilistic inference 

computing hal information flow hal hyperspace analogue language human encountering new concept derives meaning accumulation experience contexts concept appears 
opens door learn meaning concept concept appears context concepts 
idea burgess lund developed representational model semantic memory called hyperspace analogue language hal automatically constructs high dimensional semantic space corpus text 
space comprises high dimensional vector representations term vocabulary 
word vocabulary hal space matrix constructed moving window length corpus word increment ignoring punctuation sentence paragraph boundaries 
words window considered occurring strengths inversely proportional distance 
traversing corpus accumulated occurrence matrix words target vocabulary produced 
note word pair hal direction sensitive occurrence information words preceding word occurrence information words recorded separately row column vectors 
purposes computing information flow useful preserve order information term represented addition row column vectors hal matrix 
quality hal vectors influenced window size longer window higher chance representing spurious associations terms 
burgess lund size studies 
experiments reported window size construct hal matrix previous value tended produce precise representations terms 
addition useful identify called quality properties 
intuitively quality properties concept term terms appear context quality properties identified dimensions hal vector certain threshold average weight vector 
hal vectors normalized unit length information flow computation 
example part normalized hal vector computed corpus associated press news feeds follows american basic bulk called capacity carry ceramic commercial consortium cooled current develop dover electricity energy field goal high higher improved japan loss low materials new require research researching resistance retain scientists semiconductors states switzerland technology temperature theory united university example demonstrates word represented weighted vector dimensions comprise words 
weights represent strength association words seen context window higher weight word lexically occurred context 
summary concept vector representation ci ci ci pn pn called dimensions dimensionality hal space denotes weight vector dimension termed property weight greater zero 
property concept termed quality property iff non zero threshold value 
qp denote set quality properties concept combining concepts concept combination important ir combinations words query topic may represent single underlying concept example space program 
important intuition concept combination concept dominate 
example term space considered dominate term program carries information phrase 
concepts wc wc pn wc wc pn resulting combined concept denoted concept combination heuristic essentially restricted form vector addition quality properties shared concepts emphasized weights properties dominant concept re scaled higher resulting vector combination heuristic normalized smooth variations due differing number contexts respective concepts appear 
step re weight order assign higher weights properties pi wc pi max pk pi 

max pi pk example 
property weights transferred interval property weights transferred interval scaling dimensions dominant concept higher 
term concept somewhat loosely envisaged term traditional ir sense step strengthen weights properties appearing multiplier resultant highly weighted dimensions constitute significant properties resultant combination 
pi qp pi qp wc pi wc pi wc pi pi step compute property weights composition step normalize vector resultant vector considered new concept turn composed concepts applying heuristic 
order deploy information flow model experimental setting queries analysed concept combinations 
particular question concept dominates concept needs resolved 
reliable theory determine dominance heuristic approach taken dominance determined multiplying query term frequency qtf inverse document frequency idf value query term 
specifically query terms re ranked qtf idf 
assume ranking query terms 
terms combined concept combination heuristic described resulting combined concept dominates higher ranking 
combined concept degree dominance average respective qtf idf scores process recurses ranking resulting composed query concept denotes single vector query models derived 
single query term corresponding normalized hal vector query model derivation 
important weight query terms highly weights query terms appeared initial query boosted resulting query model adding score 
due way hal vectors constructed possible initial query term represented resulting query model 
cases query term added weight 
pilot experiments show boosting heuristic performs better query models boosting query terms 
computing information flow barwise seligman proposed account information flow provides theoretical basis establishing informational inferences concepts 
example space program satellites illustrates concept satellites carried informationally combination concepts space program 
said satellites flows informationally space program 
information flows determined underlying information state space 
hal vector considered represent information state particular concept combination concepts respect corpus text 
degree information flow satellites combination space program directly related degree inclusion respective information states represented hal vectors 
total inclusion leads maximum information flow visualised follows inclusion relation concept space 
example diagram denoted space program satellites 
definition hal information flow iff degree ci denotes conceptual representation token threshold value 
ease exposition referred combinations concepts concepts 
note information flow shows truly inferential character concept necessarily dimension degree inclusion computed terms space program satellites ratio intersecting quality properties number quality properties source ci qp qp degree ci qp terms experiments reported set quality properties ci source hal vector ci defined dimensions non zero weight 
set quality properties target hal vector defined dimensions greater average dimensional weight definitions determining quality properties source concept target concept determined pilot studies information flow computation 
deriving query models information flow query query model derived way compute term degree vocabulary ci represents conceptual combination hal vectors individual query terms qi ct represents hal vector term query model tk comprises top information flows observe weight associated term ti query model probabilistically motivated denotes degree infer terms underlying hal space 

experiments experimental set experiments reported ap collection disk trec topics ap collection disks trec topics 
titles topics queries 
attempted set experiment allow comparison markov chain relevance trec stands text retrieval conference series run nist 
see trec nist gov models mentioned 
table summarizes collection query characteristics experiment experiment query set topics titles topics titles average query length collection ap ap number documents size vocabulary table test collections queries hal spaces constructed collections window size words 
stemming performed hal space construction 
query models evaluated effectiveness hal information flow model im model chosen investigate information flow analysis contributes positively query model derivation 
im global collection model query expansion 
top information flows query model 
value produced best performance series pilot studies 
information flow model pseudo relevance feedback im pseudo pseudo relevance feedback consistently generated improved effectiveness 
model implemented constructing high dimensional context hal space top documents response query deriving query model deriving local collection 
documents retrieved baseline model 
top information flows query model 
value produced best performance series pilot studies 
query topic query terms combined concept combination heuristic single query vector 


vector derive query model 
baseline model documents indexed document term frequency inverse collection frequency components okapi bm formula parameters 
query vectors produced query term frequency query length normalization defined similarly bm 
document term frequency parameter matching function employed document query vectors dot product advocated lafferty zhai 
note baseline markov chain relevance models terms stemmed information flow models pseudo feedback terms stemmed pilot studies revealed information flow models perform slightly better stemming 
results experiment experiment evaluated effectiveness im ap collection trec query topics 
experiment allows direct comparison hal information flow model lafferty zhai markov chain query model feedback 
results detailed table 
note results include topic omitted lafferty zhai experiments 
results experiment second experiment information flow model investigated context larger ap collection trec topics 
experiment allows performance comparison information flow model lavrenko croft relevance model 
results shown table figures 
discussion observation low baseline performance average precision 
query topic sets 
due titles 
average precision scores corresponding title description narrative queries 
results experiment suggest hal information flow model outperforms markov chain query language model 
notable information flow model feedback outperforms markov chain model feedback 
note baseline performance collections poor due titles queries 
results experiment comparison information flow model pseudo relevance feedback pseudo relevance model pertinent relevance model uses feedback 
documents sampling distributions 
comparison shows hal information flow model outperforms relevance model topic sets 
notable interest information flow model feedback im similar performance relevance model query topics slightly inferior performance relevance model query topics 
words global collection query expansion model performing similarly local collection query expansion model 
experiences trec conference series consistently revealed local collection expansion techniques outperform global collection techniques 
order see result accident compared im model global collection model pseudo relevance feedback model term frequency top ranked documents retrieved baseline 
frequently occurring terms selected query expansion 
average precision scores ap topics ap topics ap topics respectively 
im model performance 
evidence suggest global collection information flow model performs near local collection techniques 
major disadvantage existing global techniques criticized context insensitivity 
example program may occur different contexts software postgraduate program space program 
contexts exist program vector constructed term occurrence methods 
addressed problem model introducing concept combination information flow inference 
program appears context space related dimensions nasa defense enhanced combining space program concept combination heuristic 
irrelevant dimensions postgraduate accordingly eliminated adjusted lower weights 
information flow analysis allows true inference 
terms example satellites dimensions composed query vector space program inferred query expansion 
im model comprises components hal representations information inference 
order understand effectiveness im originating experiment carried evaluated effectiveness im model inference component ap collection topics 
words query topics translated query vectors normalized retrieval 
average precision achieved 
represents improvement baseline model 
im model average precision scored represents improvement baseline 
similarly respect recall model inference component produced improvement relevant documents retrieved versus improvement recall im model 
figures suggest inference component contributes precision underlying hal representation 
performance increases im model baseline marked query topics 
topics average longer topic sets may case translation heuristic topics concept combinations may effective longer queries 
experimentation needed bear 
improvement im model pseudo feedback im model pseudo feedback parallels general trend local collection query expansion techniques outperforming global collection query expansion techniques 
interesting improvements marked improvement registered markov model 

related sch tze pedersen apply singular value decomposition svd algorithm term occurrence matrix produced moving word sliding window dimensional reduction 
svd latent semantic analysis lsa specifically ir latent semantic indexing lsi reduce number dimensions term passage matrix 
performances reasonable inductions words occurring passage inferred weights originally occurring terms changed 
svd information flow model complementary address different aspects informational inference problem 
svd strong mathematical basis inferential character comes matrix decomposition dimension reduction 
information flow model hal vectors calculation degree inclusion vectors compute strength inference 

compares effectiveness query models derived information flow computations vector representations terms produced hyperspace analogue language model information representation cognitive science prominent probabilistic language models 
specifically information flow model outperforms markov chain query language model relevance query language model 
addition hal information flow model performs local global collection expansion 
information flow approach differs probabilistic approaches query language models ways query terms considered independent 
vector representations embody associations terms context sensitive 
information flow analysis involves concept combination individual vector representations query terms treating separately 
degree information flow informational inference term query weight words query model 
weights reflect strongly informationally contained conditional probability 
information flow model comprises components 
hal representation second information inference component 
improvements average precision appear arise primarily information inference component 
suggests research directed tune component 
addition investigating inference component tandem alternative vector representations terms example latent semantic analysis interesting avenue exploration 
reported funded part cooperative research centres program department prime minister cabinet australia 
baseline im markov chain im pseudo markov chain pseudo recall table comparison various query models ap collection trec topics titles including topic precision recall precision recall curves comparing baseline information flow model feedback ap collection trec topics titles base im topics baseline im im pseudo relevance model recall recall table comparison query models ap collection topics titles adding query topic recall baseline im im pseudo 
precision recall precision recall curves comparing baseline information flow model feedback ap collection trec topics titles precision recall precision recall curves comparing baseline information flow model feedback ap collection trec topics titles allan callan croft lu 
experiments inquery 
harman ed proceedings th text retrieval conference trec 
barwise seligman 
information flow logic distributed systems 
cambridge tracts theoretical computer science 
buckley salton allan singhal 
automatic query expansion smart trec 
harman ed proceedings rd text retrieval conference trec 
burgess lund 
explorations context space words sentences discourse 
discourse processes 
deerwester dumais furnas landauer 

indexing latent semantic analysis 
journal american society information science 

base im base im rdenfors 
conceptual spaces geometry thought 
mit press 
gauch wang 
corpus analysis approach automatic query expansion 
proceedings th international conference information knowledge management cikm pp 

hofmann 
probabilistic latent semantic indexing 
proceedings nd annual international conference research development information retrieval sigir pp 

jing croft 

association thesaurus information retrieval 
proceedings intelligent multimedia information retrieval systems riao pp 

lafferty zhai 
document language models query models risk minimization information retrieval 
proceedings th annual international conference research development information retrieval sigir pp 

landauer foltz laham 
latent semantic analysis 
discourse processes 
lavrenko croft 
relevance language models 
proceedings th annual international conference research development information retrieval sigir pp 

lund burgess 
producing high dimensional semantic spaces lexical occurrence 
behavior research methods instruments computers 

cognitive space information space 
journal american society information science 
qui frei concept query expansion 
proceedings th annual international conference research development information retrieval sigir pp 

robertson walker spark jones hancock beaulieu 
okapi trec 
proceedings rd text retrieval conference trec 
sch tze pedersen 
thesaurus applications information retrieval 
information processing management pp 

song bruza 
discovering information flow high dimensional conceptual space 
proceedings th annual international conference research development information retrieval sigir pp 

xu croft 
improving effectiveness information retrieval local context analysis 
acm transactions information systems vol 
pp 

zhai 

notes lemur tfidf model 
unpublished report 
voorhees harman 

overview sixth text retrieval conference trec 
proceedings rd text retrieval conference 
voorhees hou 
vector expansion large collection 
proceedings trec pp 

