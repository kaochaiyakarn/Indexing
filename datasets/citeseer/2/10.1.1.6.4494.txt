mining topic signals text khalil thesis university waterloo fulfilment thesis requirement degree doctor philosophy computer science waterloo ontario canada khalil declare am sole author thesis 
true copy thesis including required final revisions accepted 
understand thesis may electronically available public 
ii aims studying ect word position text understanding tracking content written text 
thesis uses word position text topic word selectors topic flow signals 
topic word selectors identify important words called topic words spread text 
underlying assumption words repeat text relevant main topic text ones concentrated small segments 
experiments show manually selected keywords correspond closely topic words extracted selectors words chosen traditional indexing techniques 
correspondence indicates topic words identify topical content documents words selected traditional indexing measures utilize word position text 
second approach applying word position topic flow signals 
representation words replaced topics refer 
flow topic traced document viewed signal rises word relevant topic falls irrelevant word occurs 
reflect flow topic larger segments text simple smoothing technique 
resulting smoothed signals shown correlated ideal topic flow signals document 
characterize documents importance topic words spread words document 
incorporated support vector machine classifier representation shown drastically reduce vocabulary size improve classifier performance compared traditional word vector space representation 
iii possible support individuals am deeply grateful 
notably am grateful support guidance patience supervisor prof frank tompa 
hope day students mentor teacher appreciation extended committee members dr charles clarke dr robin cohen dr chris dr marti hearst dr alexander valuable comments suggestions 
studies fortunate meet benefit experience knowledge individuals 
go dr rick kazman dr dimarco prof graeme hirst dr mu zhu people open text especially saman larry fitzpatrick mei dent michael dent palmer raymond tsui gary 
alongside academic knowledge strong net support encouragement weaved family friends 
am deeply indebted advice support sisters brother friends especially dr eid dr nadia 
go people computing research repository making collection available responding requests bell university labs intel canadian network centres excellence natural sciences engineering research council canada nserc university waterloo providing financial support possible 
iv parents unconditional love encouragement guiding star 
su ce endless sacrifices 
husband patience support 
kids mostafa need fulfill dreams 
right give 
contents text signal logical views text 
text bag words 
documents structured units 
words context 
documents collections topics 
representing flow topics text 
topic relevance measures topic relevance 
measuring topic relevance 
measuring topic relevance document frequency 
measuring topic relevance modified document frequency 
vi measuring topic relevance term frequency 
incorporating relative word positions measuring topic relevance 
evaluation 
corr database 
preprocessing 
creating baseline 
evaluation method 
results 

putting building topic flow signal constructing initial signal 
zooming representing topic flow larger segments 
evaluation 
ideal topic flow signal 
evaluation sequences 
evaluation method 
results 

vii application text categorization text categorization 
definition applications 
preprocessing 
document representation 
document classification 
text categorization support vector machines 
model selection 
topic distribution documents support vector machines previous 
incorporating topic distribution document features experiments 
database 
experimental setup 
evaluation measures 
results analysis 

bibliography subject areas corr database viii list algorithms construct topic flow signal topic input document 
construct topic flow signal topic input document segment size 
averaging algorithm haar wavelet transform 
gradual averaging algorithm 
ix list tables corr database categories evaluation 
corr category csa category mapping number csa records mapped corr category 
number csa records collected create target list corr categories number words resulting target list 
frequent word stems ai identifier list example phrases containing identifier words 
size corr database index topic relevance measure simple indices 
number ta na abstracts belonging corr topics evaluation sequences number ota ona documents ta na documents topic correct topic 
correlation concatenated ideal test signals sequences 
correlation coe cient resolution levels sequences 
topic topic column name ideal topic flow signal 
row similar column identifies topics test signals highest correlation ideal signal correlation coe cient value student ttest statistical significance witha confidence interval 
correlation concatenated ideal test signals sequences 
correlation coe cient resolution levels sequences 
topic topic column name ideal topic flow signal row similar column identifies topics test signals highest correlation ideal signal correlation coe cient value student ttest statistical significance confidence interval 
number training documents belonging topics frequently occuring categories training documents category 
number td training documents belonging corr topics number documents td documents identify topic 
top correlated test topics ideal signal resolution level text 
xi correlated test categories ideal signal sequence resolution level statistical significance correlation coe cients confidence interval 
number test files category 
values search best category model corr category 
ratio number negative category examples number positive examples training database ratio negative positive examples parameter 
cost factor optimization parameter factor rbf kernel degree polynomial kernel top ranking models corr cat tf idf approach 
table shows vc dimensions selected classifier leave estimate precision recall breakeven point 
cost factor optimization parameter factor rbf kernel degree polynomial kernel top ranking models corr cat bag ranks approach 
table shows vc dimensions selected classifier leave estimate precision recall breakeven point 
cost factor optimization parameter factor rbf kernel degree polynomial kernel top ranking models corr cat topic spread approach 
table shows vc dimensions selected classifier leave estimate precision recall breakeven point 
xii cpu time cpu seconds taken methods build selected classification model classify corr categories 
experiments run cpu shared sun sparc machine sunos 
micro macroaveraged precision recall breakeven points approaches tf idf bag ranks topic spread 
maximum values methods bold faced 
xiii list figures views document collection topics 
relevance content word positions sentence topic artificial intelligence 
positions containing non content words ignored 
relevance signal topic artificial intelligence relevance values table 
vertex signal labeled word generated vertex 
concepts topically relevant artificial intelligence 
steps involved creating indices evaluation experiments 
sample record csa computer information systems abstracts database 
average interpolated point average precision recall word target list 
average interpolated point average precision recall word target list 
xiv average interpolated point average precision recall word target list 
average interpolated point average precision recall word target list 
average interpolated point average precision recall word target list 
average interpolated point average precision recall word target list 
average interpolated point average precision recall word target list 
average precision word lists generated df df df df measures simple stem indices 
average precision word lists generated df df df df measure simple stem indices 
average precision word lists generated df df df df measures simple indices versus unstemmed ideal list 
average precision word lists generated df df df df measures simple indices versus unstemmed ideal list 
precision simple index words sorted frequencies smart stopword list 
xv topic flow signal topic artificial intelligence relevance values table 
vertex signal labelled word generated vertex 
topic flow signals topics computation language artificial intelligence example 
vertex signal labelled word generated vertex 
note higher ranks wider variation ranks artificial intelligence signal 
segment sizes di erent resolution levels word text 
transform computation language triangles artificial intelligence asterisks signals segment sample sequence abstracts 
abstracts belong computation language second networks internet 
computation language ideal topic flow signal word level level increasingly larger segment sizes levels sample document consisting abstracts computation language abstracts second networks internet 
example highly correlated ideal test topic flow signals 
signals represent flow computation language sequence resolution level 
xvi example weakly correlated ideal test topic flow signals 
signals represent flow computational engineering finance science sequence resolution level 
example moderately correlated ideal test topic flow signals 
signals represent flow software engineering sequence resolution level 
computation language ideal signal resulting concatenating signals resolution levels sequence computation language test signal resulting concatenating signals resolution levels sequence computation language scatter plot resolution levels ideal test signals sequence 
vector representing sample document consists terms bank money term weights respectively 
general architecture text categorization system 
system categorizing document categories system trained recognize categories training documents categories 
example linear data set linear hyperplane separating positive negative examples margin 
nonlinear data set separated linear hyperplane converting example bag ranks representation 
converting example topic spread representation 
xvii chapter text intensely rich medium words structure situational context interact weave text meaning 
varying aspects fabric meaning researchers text retrieval text classification text summarization various natural language understanding tasks 
basic level individual words document provide crude picture text content 
retrieval systems adopt approach measuring similarity document documents users requests 
smart sal earliest examples systems 
interested examining augment bag words approach obtain characterization text better suited text retrieval text classification related text manipulation tasks 
systems improve basic model utilizing semantic interaction words recognizing words tend occur similar contexts 
latent semantic indexing ddl linear squares fit yc achieve numerical analysis methods measure pos chapter 
occurrence words context morris hirst mh green gre gre utilize online thesaurus create semantic links words process called lexical chaining 
syntactic structure understanding text 
clarke instance parse users questions identify specific information requested question 
useful aspect document logical structure 
structure helps indicate importance words sentences content useful identifying extracting important sentences tasks summarization see example systems go attempting capture information situation text produced 
example project indexed video conferences aspects including content discussion meeting agenda forms interaction participants arguments discussions brainstorming question answer 
methods useful creating idea text content generally tend group document words regardless position text losing information order 
methods difficult tracking change topic degree change document 
researchers attempt address problem dividing document fixed segment sizes studying content segments hea approach restricts understanding text content segment sizes 
cases approach requires knowledge text content analyzed msb making unsuitable tracking content incoming streams text 
bookstein chapter 
exploit influence content word usage extracting index words useful satisfying user requests 
predict words tend occur close proximity pattern occurrence text quite di erent expected random pattern occurrence 
extend bookstein predictions extract words signal certain topics text 
find intuitive topics change words 
tracking words able track change topic new text produced 
hope information readily available quite useful providing insight text content real time varying levels detail 
describing view text comparing popular views 
uses word position text topic word selectors topic flow signals 
topic word selectors identify important words called topic words spread text 
example word occurs times single paragraph document considered important occurs occurrence spread document 
underlying assumption words spread text relevant main topic text ones concentrated small segments 
show manually selected keywords correspond closely topic words words selected traditional indexing techniques 
correspondence indicates topic words identify subject matter documents words selected traditional indexing measures utilize word position text 
armed better topic identifiers move tracking flow topics text call topic flow signals 
representation topic chapter 
words replaced relative relevance topic 
flow topic traced document viewed signal remains strong words relevant topic weakens irrelevant word occurs 
reflect flow topic larger segments text simple smoothing technique 
resulting smoothed signals shown correlate ideal topic flow signals document 
represent documents relative importance topic words spread words document 
representation incorporated support vector machine text classification shown drastically reduce vocabulary size loss classifier performance compared traditional tf idf representation 
chapter text signal solid comprehension retrieval approach rooted clear vision approach view text criteria attempts preserve model 
chapter discuss view text addition text views past 
focus represent text view adopt 
logical views text natural language text encodes large amounts information levels including syntactic semantic structural levels 
far know information text needed retrieval task 
logical view text defines criteria capture essential contents document task hand 
dimensions view text word level second document level 
word level view defines chapter 
text signal semantics word objects refers document level view determines words text weave meaning text 
simplest text just unordered collection words 
bag words approach 
involved views take account information text information regarding structural content context word position word text 
remainder section focuses document level views examples 
text bag words bag words view assumes words document su cient capture main contents document 
assumes probability word independent words document position word text 
view text flat entity structural information 
earliest text views common current information retrieval research 
main attraction simplicity 
may ective simple retrieval tasks requiring exact word matching 
general systems view attempt enhance system performance boosting word semantics views removing grammatical inflections ignoring empty words stopword removal preprocessing tasks 
early example systems bag words view earlier versions smart sal sm 
systems augment bag words view knowledge word occurrence attempt boost word semantics view done linear squares fit approach yc latent semantic indexing chapter 
text signal lsi system ddl 
lsi example document viewed bag words represented words contains 
system uses algebraic methods distinguish words tend occur database documents 
assumption words occurring context share common 
system realizes words stocks shares instance occur frequently database query containing word shares may retrieve document stocks word shares document 
pure bag words method retrieves documents containing word shares 
simplicity ectiveness view main reasons popularity 
bag words view simple user task 
text viewed unordered collection words lose information text structure 
systems view retrieve relevant segments document identify key content indicators analyze flow discussion text 
capabilities important text segmentation systems document visualization systems paragraph retrieval systems 
documents structured units bag words method views documents flat unordered sequences words 
reality documents sophisticated physical entities 
baeza yates neto divide physical structure documents types flat fixed structures hypertext hierarchical structures 
flat structures separate document list independent units bag words 
emails example consist fields sender name chapter 
text signal recipient name date subject message 
newspaper articles technical reports may viewed titles followed lists paragraphs 
flat structures advantage retain simplicity bag words view capable searching retrieving relevant units retrieving document 
may provide additional information contents text boost ectiveness retrieval system 
versions smart sab combined bag words view view document list paragraphs 
salton allan buckley measured input query full document flat bag words form single paragraphs 
paragraphs relevant query full text paragraphs returned system returned text relevant 
combined view proved ective simple bag words view sab 
flat structures document linear list structural units hypertext graph structures view document set interconnected units 
html web pages example structures 
view usually extended database case document acts node web interconnected documents 
hypertext view adopted world wide web search engines 
search engines utilize document document connections evaluating retrieval results 
google pagerank measures importance web page expected usefulness user number web pages pointing page question 
google example links documents provide rich resource system understand document contents author view documents relate 
graph structures usually expensive process chapter 
text signal quality links dependent context appear authors judgment 
documents prepared hypertext documents 
hierarchical structures compromise richness hypertext simplicity flat structured text 
examples tree structured documents books containing chapters contain sections turn may contain subsections markup languages usually reflect relation units structure allow search engines exploit structure tom tom 
pat st multitext ccb web search engines google example allow users specify particular substructure called region interested searching 
imposing structure text usually conveys author view consecutive portions text share common attribute 
helps users search understand document database 
structure little amend drawbacks bag words view adopted segments structure 
structured text search retrieve smaller segments text contents segments represented unordered set words missing information regarding local context segment topic flow text 
words context attempting impose structure text research tasks require detailed view local context text 
local context word words surrounding document 
immediate context usually assists reader restricting possible meanings word chapter 
text signal topics discussion 
example word bank carry di erent meanings including commercial bank river bank 
phrase river immediately adjacent bank phrase river bank disambiguates clarifies local content text 
idea surrounding words disambiguate text investigated di erent applications word sense disambiguation cl les query expansion character recognition varying degrees success 
definition local context window varies systems define local context words immediately preceding word done gram language model ms 
model word assumed independent words text words immediately preceding 
researchers defined word context words immediately preceding succeeding 
gale instance local context sense disambiguation 
studied relaxed definition local context context word begins words away interestingly words far away words may useful disambiguation task 
recognizing importance local context pat st web search engines altavista google allow users search words proximity 
multitext relevance paragraph set terms influenced proximity matched terms paragraph 
view text retains partial information relative order text words su cient applications local contexts interest 
local context provide global view text insu cient representing flow topics document appropriate chapter 
text signal topic paragraph paragraph paragraph paragraph paragraph topic topic text connected set topics subtopic subtopic subtopic text main topics enclose sequence subtopics subtopic subtopic text collection main topics enclose parallel subtopics views document collection topics tasks requiring unified view text 
documents collections topics text words weave topics conveyed document 
words view fragments text lacks insight text unit run possibly overlapping topics 
shows text views focus document collection topics 
view text connected set topics 
view assumptions regarding organization topics text 
topic may discussed set text segments may discussed 
main topic defined discussed greatest number segments 
view adopted salton chapter 
text signal represented topic set mutually similar segments 
document segmented paragraphs 
similarity paragraph measured paragraph paragraphs similarity higher preset threshold assumed discuss common topic 
attractiveness view flexibility allowing topics interrupted re introduced times course text 
view flexibility entails loss hierarchical relations main topic subtopics 
text view shown accounts relation main topics subtopics 
view text set main topics run text parallel subtopics 
subtopics expected linearly consecutive mutually exclusive 
hearst adopted view automatic segmentation system hea hea 
goal discover points topic shift thematic change document boundaries guides automatically segmenting text 
version hearst algorithm divides document segments 
measures similarity adjacent segments places topic boundaries sudden decrease similarity relative adjacent segments 
version algorithm topic set consecutive segments text bounded topic boundaries 
second version algorithm lexical chains morris hirst mh showed coherent texts usually contain groups semantically related words 
groups called lexical chain 
version represents topic set parallel lexical chains places topic boundary set chains ends new set begins 
chapter 
text signal view adopted versions algorithm assumes subtopics consecutive mutually exclusive 
linearity mutual exclusion expectations justified automatic segmentation context generally accurate assumptions 
interruptions topic re expected types text 
time ability recognize main topics subtopics provides deeper insight flow topics text 
view text combination previous views 
adopt hearst view text set main topics running text parallel subtopics view salton topics modeled independent entities may temporarily interrupted revisited number times paragraph may discuss number topics simultaneously 
reflects view 
main topic discussed text context main topic subtopic subtopic discussed segments document second subtopic subtopic discussed middle text temporarily intersects subtopic model general model adopted salton assumes common theme document 
assumption true news stories technical reports allows simpler representation 
model flexible adopted hearst hea hea 
flexibility simplicity model largely dependent choose represent 
representing flow topics text ideal representation topic flow model preserve model flexibility possible permit simultaneous topics point chapter 
text signal text 
best achieved representing topic text independently topics 
text consist parallel topic flow representations problem reduces representing flow individual topic document 
topic flow reflects degree relevance topic various points document 
assume measure relevance level word point document topic measure md 
view relevance topic point containing content word document plot relevance levels measure position document 
resulting plot reflect flow topic document take example sentence example belief revision focuses agent change beliefs adopts particular new belief 
fh assume relevance measure md produces relevance levels shown table word position containing content word sentence topic artificial intelligence important relevance level 
plots relevance artificial intelligence versus word positions sentence 
note variation height relevance level defined measure word position artificial intelligence changes 
stream importance levels represents flow topic artificial intelligence sentence 
stream conveys information source called signal sig 
flow topic represented thesame text resulting multiband signal topic flow information 
signals powerful versatile representation forms represent audio speech image 
brewster bm represent docu chapter 
text signal word position word relevance belief revision agent change beliefs belief relevance content word positions sentence topic artificial intelligence 
positions containing non content words ignored 
ments terms signals 
identifying content bearing words method proposed bookstein 
highest weighted content words weights higher preset threshold called topics 
weights threshold higher lower threshold called cross terms remaining content words lower weights discarded 
signal channel reflects association document term topic 
collection topic signals build single composite energy signal meant represent document content basis document visualization segmentation prototype 
experimental results reported accuracy channels collective energy signal representing text content usefulness purposes visualization 
forming single compound signal represent documents multiple signals reflects topic characterized user defined collection documents 
representing topics signals allows preserve flow information chapter 
text signal word position text belief example ai belief revision agent change beliefs belief relevance signal topic artificial intelligence relevance values table 
vertex signal labeled word generated vertex 
chapter 
text signal retain flexibility original flow model 
provides multiple views text simultaneously ciently 
text streams produced real time easily represented terms moving topic signals 
features prove useful areas information retrieval including text segmentation text summarization paragraph retrieval text filtering 
opens text processing wide range cient ective signal processing tools applied conjunction representations text 
course quality signal sensitive relevance measure md constructing signal 
chapter discuss compare candidate measures 
chapter adopt measures build topic flow signals 
study ect relevance measures word position text classification 
chapter topic relevance measures previous chapter argued representing topic flow text form signals 
showed signal representation examples hypothetical topic relevance values point sample text 
chapter define topic relevance define compare di erent topic relevance measures word topic attend basic question topic relevance 
topic relevance word strongly relevant topic reflects concept discussed subtopic example belief networks agents strongly relevant topic artificial intelligence corpora discourse analysis strongly relevant topic computational linguistics conductor relevant topic 
shows list concepts strongly relevant artificial intelligence taken index encyclopedia artificial chapter 
topic relevance measures bayes theorem bayesian belief networks bayesian decision theory belief networks belief revision constraint logic programming constraint networks constraint propagation constraint satisfaction feature detection concepts topically relevant artificial intelligence intelligence sha 
document keywords may viewed topic words 
keywords indicate main topics document set keywords describe topic documents acts partial set topic words topic discussed document 
keywords preset keyword field document recognized visual features document 
kb example extracts keywords called topic phrases documents set heuristics visually significant features italics document structure 
keywords topic documents build decision trees reflect topic content 
chapter 
topic relevance measures topically relevant words damerau domain oriented vocabulary dam 
damerau defines vocabulary list content words necessarily complete characteristically talking particular subject say education opposed list words talk say aviation 
dam damerau tests di erent approaches extract domain oriented vocabulary body plain text documents 
sorts list words domain documents frequency eliminates words bearing little content called stopwords list list size predetermined constant removing lowest frequency words 
second approach creates domain lists list extracts dictionary words label domain second list indexes words domain documents 
creates final domain list words common lists 
previously unseen set documents domain damerau domain list appeared domain documents words domains lists 
acceptance test guarantee words domain oriented 
shows selected words domain documents 
words easily accepted topic words test happened domain domains tested 
case may discriminators domain topically relevant words 
di erence topically relevant words discriminators applies traditional information retrieval index terms 
topically relevant words topic words importance index term information retrieval chapter 
topic relevance measures measured discriminate topic document topics documents relevant content topic document van sal dam 
example earnings earnings forecasts category reuter database reu contains term lt place left bracket names 
lt discriminator category categories database ms 
lt may discriminator earnings earnings forecasts category relevant meaning category 
discriminators appropriate category markers lack essential content relevance information acceptable topic words 
definition relevance topic flow representation representation distribution non statistical sense topic concepts document 
furthermore variation relevance values reflects variation strength topic relevance various concepts text 
ability measure relevance topic word implies knowledge word topic 
information retrieval knowledge usually acquired analyzing sample documents topics belong 
assume access representative sample plain text documents topic set possible topics document represented words contains order occur document 
chapter call set sample documents database training documents simply database 
task recognize strongly relevant words topic representative sample 
remainder chapter discuss compare di erent measures relevance 
chapter 
topic relevance measures measuring topic relevance topic words clearly associated topics 
hard argue characteristically discussing topic 
measure association pointwise mutual information pmi 
pmi extension information theoretic measure mutual information ms 
di erent retrieval tasks including feature extraction yp word concordance discovery ch 
pmi measures likelihood observing events simultaneously opposed observing event separately 
measure defined follows log probability observing database 
probability observing separately 
context topic relevance topic word relevance interest reflects relative likelihood word discussing topic compared independently relative likelihood observed instance word refers topic compared independently 
order measure pmi word topic probability occurrence estimated probabilities occurring separately 
probability occurrence word usually chapter 
topic relevance measures estimated observable statistic word number documents occurs document frequency word total number instances database term frequency 
follows discuss document frequency term frequency measure relevance topic word compare ectiveness statistics word statistics 
measuring topic relevance document frequency document frequency df number documents word occurs 
df pmi measure relevance word topic df log log df db df db db db log df db df db log df df db log db df number topic documents containing word df db number database db documents containing word number documents database main topic db number documents database 
chapter 
topic relevance measures term log db independent words fixed topic database db df equation compares words ratio df df db words occur significantly documents rest database weighed heavily occurring relatively fewer documents rest database 
measuring topic relevance word number documents occurs assumes words frequently variety documents usually occur document strongly relevant main topic document word strongly relevant topic higher proportion documents appears falling example word occurs documents higher weight word documents belong find basic assumption measure troublesome 
particular measure assign high weight singletons words occurring document misspellings infrequent irrelevant words 
instance mentioning word treaty thesis mean word strongly relevant topic thesis 
measure count thesis evidence relevance word main topic text 
way filter irrelevant words discard documents word singleton shall see 
measuring topic relevance modified document frequency mentioned previous section problem pure df measuring topic relevance importance single occurrences chapter 
topic relevance measures document 
overcome drawback suggest discarding df count documents word occurs 
case topic relevance measure df log df db df db log df df db log db df number topic documents containing occurrence word df db number database db documents containing occurrence word db number documents db respectively 
new measure assumes probability occurrences irrelevant word quite low words occurring twice document may strongly relevant main topic document 
assumptions katz kat argued word relevant topic document occurs burst repetitions 
church df db adaptation measures chu shows content words tend occur twice documents strongly relevant 
manning schutze define non content words informally words taken isolation 
give information contents document ms 
note content word usually relevant topic discussed document need 
chapter 
topic relevance measures assumptions proportion topic documents containing occurrence word high measure assumes word strongly relevant replacing document frequency df alleviates singleton word problem 
df df assumes independence number times word document degree relevance word document topic 
statistics word repetition times document repeating word twice document 
researchers assert valid 
katz example states total number observed occurrences content word phrase document ought function degree relatedness concept named word document words intensity concept treated 
kat luhn hypothesized frequency word document strong indicator word significance text van 
measuring topic relevance term frequency researchers information retrieval community term frequency tf indicator importance word document 
carry concept frequency indicator importance measuring topic relevance plugging tf equation tf log tf db tf db log tf tf db log db chapter 
topic relevance measures tf number occurrences topic documents 
tf db number occurrences database db 
db number terms db respectively 
equation assumes strongly relevant words occur frequently topic database 
damerau essentially measure determining domain oriented vocabulary dam discussed uses function similar equation extract word domain phrases set pre specified domains ratio frequency phrase domain frequency database dam 
assumption domain phrases tend occur average domain documents database 
incorporating relative word positions measuring topic relevance term frequency document frequency measures proposed far assume bag words document view total number occurrences topic documents database su cient describe contents topic regardless words occur 
bag words view incomplete notion text collection topics 
argued chapter position words document useful understanding document content 
chapter 
topic relevance measures chapter text collection topics main topic spanning length text 
words atomic units describing document content expect topic words span text 
topic words occur small segments text repeat text 
bookstein behavior content bearing words extract index words useful satisfying users requests 
authors apply goodness measures words compare word occurrence behavior text expected random occurrence 
define occurrence behaviors word tendency clump repeating close proximity single textual unit paragraph word tendency occur consecutive textual units document 
experiments show information word occurrence improves quality words selected indexing compared pure inverse document frequency 
experiments indicate link content bearing words words tendency clump 
method identifies content words authors show method characterize topic document words indicative topic 
katz kat notes content words repeat close proximity treated heavily continuously text occur length text 
speculate intensely treated content words strongly related main topic document topic words 
challenge identify words repeat text evaluate tendency span length text topic documents 
identify words repeat text turn second measure chapter 
topic relevance measures introduced church chu 
church uses notion word spread show content words adapt probability occurrence changes lexical content document 
church divides document halves half called history second called test 
shows content word appears history probability occurring test segment rises significantly 
word spans length text occur halves document 
adopting church idea segmenting document halves topic relevance measure df log log df db df db db db log df db df db log df df db log db df number topic documents containing word halves document 
df db number database db documents containing word halves document 
number documents database main topic db number documents database 
chapter 
topic relevance measures measure topically relevant words occur halves document topic significantly halves database documents 
idea segmenting document halves easily generalized number segments 
case words said spread document occur segments 
measure topic relevance dfn log df df db log db df number topic documents containing word segments document 
df db number database db documents containing word segments document 
number documents database main topic db number documents database 
df restricts frequency count number documents word occurs segments 
words occur segments document database frequency df db 
words assumed topically relevant topic database excluded dfn vocabulary topics immediate ect df frequency count vocabulary size smaller df tf df higher value words excluded larger reduction size vocabulary 
reduction acceptable chapter 
topic relevance measures harm ectiveness dfn measure recognizing topic words 
follows look ectiveness dfn extracting topic words di erent values compare topic relevance measures 
evaluation section proposed di erent functions measure relevance word topic 
measures pmi formula equation di erent definitions word topic deliberately ignoring question constitutes topic 
discussion general apply topic may think politics today lunch 
order compare topic relevance measures experimentally simplify concept topic easily captured quantified 
evaluation purposes define topic predefined subject category classes yahoo classification hierarchy subject classes acm computing classification system acm classification reuter database reu 
evaluation corr database cora classification system database 
purposes corr advantage longer documents having pages widely databases reuter database having paragraphs 
documents longer paragraphs essential testing ectiveness dfn measure segmenting document small sections 
predetermined set categories database manually classified chapter 
topic relevance measures documents generate topic words evaluate measures 
corr database corr database cora online repository research computer science 
database consists theses technical reports conference papers journal papers decade 
documents range length pages pages average pages long 
mainly latex format pdf ps html files 
document corr database classified authors pre determined categories listed appendix 
version database consists documents submitted january june total documents latex format 
latex documents converted text version det modified ignore text preceding document command ignoring abstracts footnotes 
pdf files converted adobe pdf txt 
total text files converted successfully 
categories contain documents 
documents belong exclusively small categories removed database leaving documents 
remaining categories sizes number documents shown table 
categories quite small useful understanding ect category size quality extracted vocabulary 
chapter 
topic relevance measures category description size cl computation language documents lo logic computer science documents ai artificial intelligence documents cc computational complexity documents cg computational geometry documents ds data structures algorithms documents pl programming languages documents se software engineering documents lg learning documents dc distributed parallel documents cluster computing ce computational science engineering documents finance ni networking internet architecture documents table corr database categories evaluation chapter 
topic relevance measures preprocessing details preprocessing vary system certain steps considered system designers 
define building blocks called tokens text 
input text merely sequence characters prior preprocessing 
responsibility preprocessor break sequence semantic units tokenization step 
units simple words words program creation multi word phrases united states opposed united states 
define tokens case insensitive sequences alphanumeric characters consisting letter 
abbreviations containing dot interleaved accepted words containing underscore sequence total vocabulary version corr database unique words 
pre processing steps widely indexing databases stopword removal word stemming 
stopword removal ignores words generally accepted content free stemming removes morphological inflections words 
researchers opt remove stopwords preset stopword list ciency ectiveness sm yl joa 
removing words drastically reduces system vocabulary size improving ciency allows system focus important content words improving ectiveness 
di culty step remove stopwords 
remove non stopwords leave stopwords increase noise database reduce system ectiveness 
balance hard strike di erent databases di erent stopwords constitutes chapter 
topic relevance measures word database may important content word 
consider example word computer computer may stopword computer science database content word general science database 
alternatively systems resort general feature selection methods aim weigh uniqueness word value categorization task keep words deemed important task yp lew 
stopword removal raises concern df frequency counts removing words body document disrupt position remaining words document disrupting df frequency counts 
approach choose deal change df frequencies depends view role word position importance word position ected word content stopword positions little importance safely ignored 
hand word position document rough reflection word sentence position word positions important including stopwords words occur segment document stopword removal occur segment stopword removal 
case removing stopwords positions held null word safely discarded df frequencies counted 
stemming common preprocessing step 
reduces words varying morphological inflections common representation 
runs running represented stem run 
process reported help compress index fra 
stemming increase number documents search systems strong evidence ectiveness discovering documents satisfy users request fra 
di erent approaches stemming simple table look chapter 
topic relevance measures predefined stemming rules methods attempt discover stems statistically prior knowledge stemming rules 
approaches shown outperform terms precision retrieval ectiveness di er compactness simplicity 
compact porter stemmer fra gradually reduces word simplest form iteratively looking longest su remove set predefined rules por 
possibilities representing documents words stopwords stemming 
explore ects stopword removal stemming precision topic relevance measures created independent indices corr database 
index simple simplest stopwords removed stemming performed 
second index stem remove stopwords replaces words stems porter stemmer prior frequency count 
third index removes stopwords smart stopword list sto stem remaining words 
fourth version corr index removes stopwords done index stems remaining words done stem index 
opted replace stopwords indices null word order preserve words original positions database 
resulting topic word lists indices consist stemmed words simple indices may include di erent morphological variants stem subsequently convert unstemmed topic word lists simple stemmed lists topic words follows word list stemmed porter stemmer assigned unstemmed word weight 
variants stem occur list chapter 
topic relevance measures raw word stream transform topic list stems experiment form topic list words simple stopwords remove stem form topic list stems stem steps involved creating indices evaluation experiments occurrence stem preserved giving highest relevance weight variants 
removes unstemmed lists variations word produces homogeneous topic word lists cross compared easily 
creation process di erent indices shown 
important note stemming topic word list generation di erent stemming prior index creation 
words stemmed indexed frequency counts include occurrence morphological variants word database 
stemming done initial topic word lists created stem assigned highest topic relevance weight variants treated separately 
final topic word lists turn method evaluate relevance measures 
chapter 
topic relevance measures creating baseline chapter define topic words category 
definition highlights criterion judge topic relevance measures word identified relevance measure acceptable topic word word humans discussing topic 
criterion evaluate topic relevance measure comparing manually selected list topic words category 
obvious source words keyword fields corr papers 
fields usually assigned authors briefly describe main contents 
classified artificial intelligence instance keywords describe issues discussed artificial intelligence 
collection keywords artificial intelligence papers form list manually selected topic words artificial intelligence category 
unfortunately papers corr database contain keyword field 
luckily goal compare ectiveness topic relevance measures capturing humans consider topic words database discussing category potential source manual topic word list 
furthermore seeking target topic word list source corr database advantage words database independent 
success topic relevance measure finding words ideal list indication measure success recognizing vital topic words independently database 
ideal list extracted external source success topic relevance measures finding words shows topic words universal topic su cient amount data topic topic words measures fact representations chapter 
topic relevance measures topic 
source ideal list index encyclopedia artificial intelligence sha provides comprehensive list artificial intelligence concepts 
online journal indices provide topic words di erent categories 
indices easily searchable large databases reduce chances missing topic words category index 
accessible index range topics corr database computer information systems abstracts index cambridge scientific abstracts csa database csa 
online index database records 
record contains fields describing serial article 
fields include title article author classification field contains list general classes article falls descriptors field contains list closed vocabulary items describing category article list identifiers open vocabulary terms human indexers strongly relevant contents article 
shows sample csa record 
assume identifiers believed relevant article relevant categories article belongs 
identifiers discussing categories equivalent calling topic words 
large list identifiers category expect topic words appear list 
create list category collect large number csa records classified category extract identifiers describe papers indexed records 
call identifier list identifiers topic relevance measure discover better measure 
identifier lists contain phrases individual words 
deal chapter 
topic relevance measures ti title hardness approximate reasoning au author roth dan af author affiliation harvard univ cambridge ma usa source artificial intelligence artif intell vol 
pp 
issn pb publisher elsevier science amsterdam netherlands ab problems formalized reduce evaluating probability propositional expression true 
show problem computationally intractable surprisingly restricted cases settle approximation probability 
consider various methods approximate reasoning computing degree belief bayesian belief networks reasoning techniques constraint satisfaction knowledge compilation approximation avoid computational difficulties reduce model counting problems propositional domain 
prove counting satisfying assignments propositional languages intractable horn monotone formulae size clauses number occurrences variables extremely limited 
contrasted case deductive reasoning horn theories theories binary clauses distinguished existence linear time satisfiability algorithms 
surprising show approximating number satisfying assignments approximating approximate reasoning intractable restricted theories 
identify restricted classes propositional formulae efficient algorithms counting satisfying assignments 
la language english py publication year pt publication type journal article de descriptors approximation theory probability computational methods constraint theory algorithms problem solving id identifiers approximate reasoning bayesian belief networks model counting problems propositional languages horn theory cl classification artificial intelligence numerical methods probability theory computer theory includes formal logic automata theory switching theory programming theory sf computer information systems abstracts accession number sample record csa computer information systems abstracts database chapter 
topic relevance measures single words identifier phrase broken constituent words 
stopwords removed resulting identifier list remaining words stemmed porter stemmer sorted total number csa records stem occurs 
order csa database evaluating topic relevance measures attend issue classification hierarchy defined csa database quite di erent categories defined corr database twelve categories corr database mapped ones csa database 
corr category mapped acceptable equivalent documents reliable evaluation 
mappings remaining twelve corr category areas shown table 
corr categories equivalent csa classes classification field artificial intelligence maps artificial intelligence class programming languages maps computer programming languages class specific classes mapped descriptors computational linguistics example mapped descriptor natural language processing 
categories cover class descriptor csa database 
example networking internet architecture covers di erent descriptors csa database pertaining aspect category wide area networks network protocols computer networks 
summary create ideal topic list corr categories shown collected total csa records satisfying csa equivalent corr category 
table shows exact number records collected corr categories 
extracted identifiers identifier fields csa records category 
identi chapter 
topic relevance measures corr csa csa csa category equivalent field records ai artificial intelligence classifiers pl programming languages classifiers lo formal languages grammars classifiers mathematical logic formal logic formal languages descriptors theorem proving computational logic lambda calculus set theory temporal logic verification correctness proofs logic programming cc computational complexity descriptors cg computational geometry descriptors se software engineering descriptors cl natural language processing descriptors ds data structures algorithms descriptors ni computer networks communication descriptors networks network protocols wide area networks packet networks table corr category csa category mapping number csa records mapped corr category chapter 
topic relevance measures corr csa target list category records size ai pl lo cc cg se cl ds ni table number csa records collected create target list corr categories number words resulting target list 
phrases broken single words words smart stopword list sto removed remaining words stemmed porter stemmer por 
number words category identifier list shown table 
identifier lists created list sorted number occurrences identifier stem 
sorting de emphasizes words rarely discuss category may discuss additional categories indexed belongs 
table shows frequent stems ai identifier list 
final identifier list pruned top words form target topic word list 
experimented target lists size words 
chapter 
topic relevance measures identifier word stem example identifier phrase neural neural networks network neural networks learn cooperative learning method system multi agent systems model recurrent fuzzy neural model algorithm learning algorithms function horn function base knowledge systems method cooperative learning method fuzzy rules table frequent word stems ai identifier list example phrases containing identifier words chapter 
topic relevance measures evaluation method target lists provide basis comparing ectiveness topic relevance measures 
lists contains sample set space words discuss list corresponding category 
measure consistently finds stems especially stems near start topic word list deemed ective extracting topic words measures 
remainder section target list refers list identifiers stems presumed represent topic topic word list word list refers list words extracted topic relevance measure category 
word list sorted decreasing order topic relevance value 
aim experiments evaluate relative ectiveness topic relevance measures extracting words humans view topic words 
see ect stemming stopword removal measure word list 
compare ectiveness topic relevance measures follow standard procedure information retrieval experimentation average interpolated point precision recall curves har 
precision point sorted word list defined ratio target words point list number words seen far recall word sorted list ratio number target words point sorted word list total number identifiers target list 
point precision recall curves show precision recall points increments 
specifying recall values allows compare results di erent topic word list sizes 
recall points may exist sorted list interpolated point precision recall curves curves 
interpolated chapter 
topic relevance measures curves precision recall points highest precision recall greater equal current recall point 
average interpolated point precision recall curves average curves calculated corr categories topic relevance measure compare average ectiveness measure 
results section study ectiveness topic relevance measures tf df df dfn indices simple stem curves measures produced target lists comprising maximum word stems 
recall lists sample set topic words taken di erent database covers topics similar corr database 
expect measures reach high precision recall values 
measure consistently succeeds discovering target words measures comparison measure better topic relevance measure 
average curves list sizes simple index shown figures 
curve figures labeled type frequency topic relevance measure associated curve 
example curve tf labeled tf lists produce similar pattern traditional measures tf df df lower precision dfn pattern apparent increase target list size 
measures pure count occurrences tf df lowest precision values 
accounting minimum frequency term calculating document frequency df improves precision df falls chapter 
topic relevance measures dfn recall levels 
df improvement df indicates term occurs document influences term relevance contents document 
corroborated improvement precision dfn 
figures show precision may start degrade high values maximum recall decrease 
interestingly increased precision dfn traditional measures coupled large decrease vocabulary size 
tf df produce total vocabulary words simple index df extracts vocabulary words 
vocabulary size tf df vocabulary sizes measures tested shown table simple indices 
mentioned section reduction expected words non zero df tf values non zero df values database 
smaller vocabulary size drawback fewer words mean smaller chance finding target words word list 
translates recall 
reasonable values improve precision tf df significant loss recall 
word lists indices produced similar graphs shows relative ectiveness topic relevance measures influenced stemming stopword removal performed long pre processing functions done measures uniformly 
say stemming stopword removal ect precision topic relevance measures 
fact stopword removal improves precision stemming degrades 
figures show graphs dfn chapter 
topic relevance measures measure simple voc 
voc 
tf df df df df df df df df df df table size corr database index topic relevance measure simple indices 
chapter 
topic relevance measures recall average interp 
prec stopwords kept csa id stemmed csa ident 
tf df df df df df df df df df df full curve interpolated precision recall average interp 
prec stopwords kept csa id stemmed csa ident 
df df df df df curves df df average interpolated point average precision recall word target list recall average interp 
prec stopwords kept csa id stemmed csa ident 
tf df df df df df df df df df df full curve recall average interp 
prec stopwords kept csa id stemmed csa ident 
df df df df df curves df df average interpolated point average precision recall word target list chapter 
topic relevance measures recall average interp 
prec stopwords kept csa id stemmed csa ident 
tf df df df df df df df df df df full curve interpolated precision recall average interp 
prec stopwords kept csa id stemmed csa ident 
df df df df df curves df df average interpolated point average precision recall word target list recall average interp 
prec stopwords kept csa id stemmed csa ident 
tf df df df df df df df df df df full curve interpolated precision recall average interp 
prec stopwords kept csa id stemmed csa ident 
df df df df df curves df df average interpolated point average precision recall word target list chapter 
topic relevance measures recall average interp 
prec stopwords kept csa id stemmed csa ident 
tf df df df df df df df df df df full curve interpolated precision recall average interp 
prec stopwords kept csa id stemmed csa ident 
df df df df df curves df df average interpolated point average precision recall word target list recall average interp 
prec stopwords kept csa id stemmed csa ident 
tf df df df df df df df df df df full curve recall average interp 
prec stopwords kept csa id stemmed csa ident 
df df df df df df curves df df average interpolated point average precision recall word target list chapter 
topic relevance measures recall average interp 
prec stopwords kept csa id stemmed csa ident 
tf df df df df df df df df df df full curve recall average interp 
prec stopwords kept csa id stemmed csa ident 
df df df df df df curves df df average interpolated point average precision recall word target list top target words topic words simple stem indices 
figures clearly show stopword removal produces highest precision stemming generates precise word lists 
negative ect stemming due factors genre technical writing tends repeat words form 
stemmer aggressive 
porter stemmer reduces words smallest stem possible 
clusters words common meaning factory factorial emphasizing incorrect words 
weaker stemmer limited stemming positive ect precision 
ect stopword removal precision surprising 
stopwords expected behave similar manner topics getting low topic chapter 
topic relevance measures recall effect word stemming stopword removal average interpolated precision df ident 
stopwords kept stemming stopwords removed stemming stopwords kept words stemmed stopwords removed words stemmed df recall effect word stemming stopword removal average interpolated precision df ident 
stopwords kept stemming stopwords removed stemming stopwords kept words stemmed stopwords removed words stemmed df recall effect word stemming stopword removal average interpolated precision df ident 
stopwords kept stemming stopwords removed stemming stopwords kept words stemmed stopwords removed words stemmed df recall effect word stemming stopword removal average interpolated precision df ident 
stopwords kept stemming stopwords removed stemming stopwords kept words stemmed stopwords removed words stemmed df average precision word lists generated df df df df measures simple stem indices 
chapter 
topic relevance measures recall effect word stemming stopword removal average interpolated precision df ident 
stopwords kept stemming stopwords removed stemming stopwords kept words stemmed stopwords removed words stemmed df recall effect word stemming stopword removal average interpolated precision df ident 
stopwords kept stemming stopwords removed stemming stopwords kept words stemmed stopwords removed words stemmed df recall effect word stemming stopword removal average interpolated precision df ident 
stopwords kept stemming stopwords removed stemming stopwords kept words stemmed stopwords removed words stemmed df interpolated precision recall effect word stemming stopword removal average interpolated precision df ident 
stopwords kept stemming stopwords removed stemming stopwords kept words stemmed stopwords removed words stemmed df average precision word lists generated df df df df measure simple stem indices 
chapter 
topic relevance measures relevance weight 
case frequent stopwords usually bottom sorted topic word list 
stopwords common topics 
example near top df word list categories ai cl considered topic word category 
positive ect stopword removal evident figures 
figures compare unstemmed word lists obtained stem indices unstemmed target list created manner target list far skip stemming step sort csa identifier words total frequency unstemmed form 
chapter define topic relevance distinguish topically relevant words traditional information retrieval index terms 
di erent measures topic relevance di erent word frequency statistic 
measures document bag words 
measures frequency statistics independent word position text assess word topic relevance 
measure dfn view text sequence topic indicators 
view position word document useful understanding document content 
measure evaluates topic relevance word spreads document 
show dfn ective selecting topically relevant words measures medium values produce best topic word lists 
measures generate chapter 
topic relevance measures recall effect stopword removal average interpolated precision df identifiers stopwords kept stemming stopwords removed stemming df recall effect stopword removal average interpolated precision df identifiers stopwords kept stemming stopwords removed stemming df recall effect stopword removal average interpolated precision df identifiers stopwords kept stemming stopwords removed stemming df recall effect stopword removal average interpolated precision df identifiers stopwords kept stemming stopwords removed stemming df average precision word lists generated df df df df measures simple indices versus unstemmed ideal list 
chapter 
topic relevance measures recall effect stopword removal average interpolated precision df identifiers stopwords kept stemming stopwords removed stemming df recall effect stopword removal average interpolated precision df identifiers stopwords kept stemming stopwords removed stemming df recall effect stopword removal average interpolated precision df identifiers stopwords kept stemming stopwords removed stemming df interpolated precision recall effect stopword removal average interpolated precision df identifiers stopwords kept stemming stopwords removed stemming df average precision word lists generated df df df df measures simple indices versus unstemmed ideal list 
chapter 
topic relevance measures recall average interp 
prec 
database index sorted pure freq smart stopword list df tf df df df df df df df df df recall partial average interp 
prec 
database index sorted pure freq smart stopword list df tf df df df df df df df df df precision simple index words sorted frequencies smart stopword list 
vocabulary sizes size traditional measures 
evaluations indicate stopword removal improves precision topic words extracted stemming degrades 
preset stopword list stopword removal evaluation preferable able remove stopwords automatically preset list 
possible approach sort index words pure df database frequency remove top words sorted list 
example plan df weigh topic words start sorting simple index words df db removing top words index 
compares sorted pure frequency lists smart stopword list 
plots traditional point precision recall plot smart stopword list target vocabulary 
plots show high proportion top words sorted lists stopwords smart stopword list 
removing words improve precision chapter 
topic relevance measures df measure losing non stopwords list 
approach similar adhoc feature selection method mentioned yang pedersen yp report removing words highest df values ective feature selection methods text categorization 
leave studies lines 
evaluations replaced stopwords null term preserve positions text 
completeness interesting study ect simply removing stopwords preserving position 
aspect investigate ect stemmer aggressive porter stemmer evaluations 
weaker stemmer reduce number words incorrectly represented stem aggressive stemmer utilized time recognize words slightly varying morphological formats plurals treated di erent words stemming performed 
interesting explore ect relaxing spread measure allow documents word appears segments df preset value recognize major topic interrupted places tangential discourse 
chapter putting building topic flow signal topic flow signals reflect variation intensity discussion related topic text 
heavily discussed topics text tend recur remain relevant document 
topics continuous stream strongly relevant topic words text 
topics discussed intensely relevant limited portions text interrupted shifting focus discussion away topic 
topics sparse distribution relevant topic words indicating weaker presence text 
generating topic flow signal text simply matter representing relevance topic segment text 
start describing signal construction algorithm generates basic topic flow signals 
constructed signals view flow topic varying levels detail text 
show chapter 
building topic flow signal topic flow signals reflect actual change intensity discussion document 
constructing initial signal basic topic flow signal relies earlier observation sufficient list topic words category find strongly relevant topic words text segments discuss category 
tracking topic relevance words text construct word representation topic flow text 
algorithm representing flow topic document algorithm 
algorithm iterates document word position text corresponding position signal assigned value reflecting word relevance topic 
measure topic relevance sorted topic word lists df seen previous chapter produces accurate topic word lists little loss vocabulary 
topic word lists sorted df weights word position text algorithm assigns corresponding signal position value equal rank sorted topic word list topic described rank subroutine algorithm 
topic word list topic list assigned plus maximum rank topic list discarded 
resulting topic flow signal remain low points strong relevance topic peak points shifts away topic 
signal provide representation progression topic chapter 
building topic flow signal document 
seen sample signal chapter text example example belief revision focuses agent change beliefs adopts particular new belief 
fh signal constructed df topic word list artificial intelligence 
signal reproduced vertex labelled word generated vertex topic relevance value 
take example shows computation language signal segment entitled applying natural language generation indicative summarization kmk example model indicative multi document summarization natural language generation 
model summary content document features describing topic structure extracted text 
kmk expected signal relatively low ranks terms relevant computation language model language content text 
flow topic text represented similar manner signal 
assumption number topics discussed simultaneously document topics represented separate topic flow signal 
topic flow artificial intelligence example shown 
variation vertex values word ranks signal higher computation language signal indicating relatively weaker presence artificial intelligence topic words segment relatively weaker discussion topic 
chapter 
building topic flow signal algorithm construct topic flow signal topic input document input document number word positions topic topic word list sorted df oc topics topic word list output topic flow signal topic document sig position text position text position text position word text position sig position rank sig position oc sig position maximum rank sig position ignore continued chapter 
building topic flow signal sub rank find number weights lower word topic word list input word sorted topic list output rank weight tmp rank prev wt done prev wt prev wt tmp rank ord done true return tmp rank algorithm continued chapter 
building topic flow signal word position text belief example ai belief revision agent change beliefs belief topic flow signal topic artificial intelligence relevance values table 
vertex signal labelled word generated vertex 
chapter 
building topic flow signal word position text topic word rank summarization example model indicative summarization natural language generation model summary content document features describing topic structure extracted text computation language topic flow signal word position text topic word rank summarization example ai indicative summarization natural language generation model summary content document features structure topic describing extracted text model artificial intelligence topic flow signal topic flow signals topics computation language artificial intelligence example 
vertex signal labelled word generated vertex 
note higher ranks wider variation ranks artificial intelligence signal 
chapter 
building topic flow signal zooming representing topic flow larger segments topic flow signals constructed previous section represent change topic relevance individual word positions 
words basic units expressing topic topic sequence words complex function variables including constituent words structure governing words order words situational context text produced 
simplicity focus identifying general topic sequence words constituent words context word 
word sequence long document 
segment text case topic relevance word sequence represents topic relevance document particular segment 
dividing text consecutive word sequences represent topic flow text text segments representing individual word positions 
resulting segment topic flow signal provide general view text varying segment size monitor change topic flow di erent levels detail 
assume relevance single segment topic function importance constituent words topic 
ranks individual words sorted topic word list segment topic relevance represented average rank words segment seg seg topic word topic rank seg chapter 
building topic flow signal seg importance topic segment seg 
rank rank topic relevance value word sorted topic word list defined rank subroutine algorithm 
seg number words segment seg 
set possible topics 
approach allows include words segment estimating topic relevance 
averaging words ranks smoothes ect occasional noise word 
view topic flow document word segment size start dividing document equal segments consisting approximately words 
calculate seg importance topic segments described equation 
algorithm slightly modified version word signal construction algorithm described algorithm construct topic flow signal segment size 
operations generate topic flow increasingly larger segment sizes starting word signals get topic flow word segment sizes averaging pair consecutive words signal 
signal word segment size generate word segment signals 
similarly segment size signal segment size algorithm shown algorithm extremely cient requiring operations construct topic flow signals segment sizes log number words document chapter 
building topic flow signal algorithm construct topic flow signal topic input document segment size input document divided segments size number segments topic topic relevance value seg segment seg output topic flow signal topic document seg num seg num seg num seg segment seg num seg num seg chapter 
building topic flow signal algorithm averaging algorithm haar wavelet transform construct topic flow signals larger segment sizes word topic flow signal input word topic flow signal topic document number points signal output set topic flow signals log topic flow signal representing text segments size log max log max max position position position position position position chapter 
building topic flow signal just averaging pairs consecutive points signal smoothes signal di erence pairs emphasises local changes topic relevance usually due noise 
adding averaged signal di erence signal reproduces original unsmoothed signal 
similarly keep signal representing topic flow segments size value di erence consecutive pairs levels preceding signal reconstruct initial word signal 
case transformed initial signal equivalent representation provides di erent view text 
transformation called haar wavelet transform simplest type wavelet transforms applications including noise reduction image processing signal compression sn 
interested noise signal interested reconstructing signal keep di erences 
interested various views text di erent segment sizes reflects flow di erent level detail 
call levels detail levels resolution 
wavelet transformation cient method obtain multiresolution signals 
require signal length power 
case signal extended nearest power size padding constant repeating portion signal signal extension method sn 
context topic flow concatenating signal artificial value disrupts real topic flow representation 
problem posed serious concerns regarding accuracy extended signals reflecting topic flow 
solution turns quite simple 
power length requirement stems averaging approach average consecutive words starting word topic flow signal 
start recursively dividing text segments equal sizes 
chapter 
building topic flow signal level resolution certain segments roughly size representing equal portions text artificial values added 
detailed algorithm algorithm 
instance document consisting words divided word segments segments divided word segments respectively topic flow lower detailed segment size 
bottom find consecutive segments size word segment size 
segment sizes level resolution word text shown 
segments roughly equal size level resolution proceed finding topic relevance segment certain resolution level constructing topic flow signal resolution starting detailed level general levels larger segments 
main di erence original averaging step wavelet transform segment sizes necessarily power length text 
need know apriori total size text may available situations streams text received signals constructed real time 
shows topic flow signals topics computation language artificial intelligence resolution levels sample text 
evaluation far concerned building topic flow signals viewing flow topics di erent levels resolution 
assumption words atomic units describe topics discussion kat relevance words topic manage create signal chapter 
building topic flow signal algorithm gradual averaging algorithm construct topic flow signals larger segment sizes word topic flow signal input word topic flow signal topic document number points signal output set topic flow signals topic flow signal resolution level general level consists point representing average relevance text 
get number words segment level transform get segment sizes segment sizes max max create level transform max get sums segment sizes max max position position position position position position position position segment sizes position position position segment sizes position segment sizes continued chapter 
building topic flow signal sub get segment sizes input output segment sizes array containing number words include segment level transform max maximum level segment sizes segment sizes max number elements segment sizes segment sizes segment sizes segment sizes segment sizes segment sizes algorithm continued chapter 
building topic flow signal sub get sums input segment sizes array containing number words include segment level transform topic flow signals array current resolution level output topic flow signal resolution level position number elements segment sizes sizes position position position segment sizes algorithm continued chapter 
building topic flow signal resolution level segment sizes di erent resolution levels word text segment position text topic flow signals ai cl summarization example different levels resolution transform computation language triangles artificial intelligence asterisks signals segment chapter 
building topic flow signal reflect topic flow text 
gradually smoothing word signal get robust topic flow representation larger text segments 
section aims evaluating signals ability represent topic flow 
ideal topic flow signal evaluating quality topic flow signals requires comparing signals ideal topic flow representation text 
ideal topic flow signal remain low corresponding text discussion topic indicating strong topic relevance peak corresponding text significantly reduces discussion topic indicating 
knowledge topic discussion necessitates usage documents different segments manually categorized segment size 
manual categorization reflect flow topics di erent segment sizes including temporary take small segments subtopics may span larger segments 
alternative manually categorizing document segments construct evaluation documents smaller pre categorized texts 
ideally smaller texts discuss topics categorized text topic 
criteria best met abstracts technical papers abstracts concise possibility minimal aim describe main topics discuss topics 
sequence abstracts belongs category ideal topic flow signal category sequence reflection distribution category abstracts 
signal indicate strongest chapter 
building topic flow signal compares tasks part speech pos tagging word sense tagging disambiguation wsd argues tasks related grain quite different kinds task particularly pos corresponding sense novelty 
argues reintegration sub tasks separated evaluation 
describes design control management network mobile wireless asynchronous transfer mode atm network 
mobile wireless atm network part rapidly deployable radio network 
system consists packet radio network overlays mobile wireless atm network network element network uses global positioning system gps information control beamforming antenna subsystem provides spatial reuse 
proposes novel virtual network configuration vnc algorithm predictive network configuration 
mobile atm private network network interface pnni vnc discussed 
prelude system implementation results simulation system discussed 
memory learning mbl approach shallow parsing pos tagging chunking identification syntactic relations formulated memory modules 
experiments reported show competitive results value wall street journal wsj treebank np chunking vp chunking subject detection object detection 
sample sequence abstracts 
abstracts belong computation language second networks internet 
topic relevance points belongs category peak highest rank values indicating topic relevance 
shows sample sequence abstracts 
topic flow signals constructed previous sections 
ideal signals similarly word 
unrealistic assumption categorized topic vocabulary word relevant topic 
restrictive assumption hypothesizes absolutely noise abstracts possible vocabulary words rel chapter 
building topic flow signal topic 
believe due concise nature abstracts noise reduction ect averaging assumption huge impact evaluation 
sequence abstracts proceed build ideal word topic flow signals follows start removing abstracts words 
vocabulary word known topic word categories df topic word lists 
create ideal topic flow signal corr categories topic trace word abstracts mark corresponding position signal belongs topic max rank belong max rank maximum possible rank topic word list get ideal topic flow larger segments simply gradual averaging algorithm described earlier 
shows ideal word topic flow signals topic flow resolution levels simple document third abstracts computation language abstracts second networks internet 
evaluation sequences created evaluation sequences abstracts technical papers submitted corr website cora january dec 
evaluation sequences called sequence consists abstracts summarizing corr papers system creating list topic words 
corresponding set full papers called corr training set 
important note training set chapter 
building topic flow signal segment position text sample ideal signal cl computation language ideal topic flow signal word level level increasingly larger segment sizes levels sample document consisting abstracts computation language abstracts second networks internet chapter 
building topic flow signal extract topic words abstracts stripped set papers 
papers abstracts come training set abstracts 
system trained topic words appearing abstracts 
sequence assist evaluating topic flow signals system recognizes important topic words inconsistency categorization segments sequence versus training set papers 
second evaluation sequence called sequence consists abstracts papers submitted corr website january december papers part training set 
papers abstracts belong training chances missing topic words higher sequence 
document useful evaluating robustness topic flow signals presence noise due missing topic words due inconsistencies categorizing abstracts compared training set 
table shows number abstracts fall categories tested number abstracts belong solely category topic abstracts sequences 
ensure bias order abstracts concatenated created di erent versions sequence version contains random ordering abstracts sequence 
call sequence versions sequence chapter 
building topic flow signal topic abs topic abs topic abs abs ta ota na ona cl cc se cg ni dc ai pl lo ds lg ce table number ta na abstracts belonging corr topics evaluation sequences number ota ona documents ta na documents topic correct topic chapter 
building topic flow signal evaluation method evaluation sequences generate ideal topic flow signals representing flow corr database topics 
signals smoothed resolution levels maximum size log size evaluation sequence 
sequences generate topic flow signal described sections corr categories 
call test signals 
sequence ideal signals compared test signals 
signals match perfectly rise fall exactly point 
match indicates signals reflect flow 
appropriate statistical measure purposes correlation coe cient ost signals matched composed sequence ranks average ranks respectively 
highest correlation coe cient indicating perfect match 
correlation coe cient higher indicates strong correlation correlation coe cient indicates weak correlation shapes signals indicates reverse correlation means high low vice versa 
shows example highly correlated test ideal signals evaluation sequence topic computation language resolution level segments 
correlation coe cient signals level 
note signals rise decline chapter 
building topic flow signal pace indicating similar changes topic flow 
non correlated signals correlation coe cient shown computational engineering finance science ideal test signals sequence resolution level 
case test signal fluctuations independent ideal signal painting di erent pictures topic flow document 
highly correlated signals weakly correlated ones signals said moderately correlated 
example moderately correlated signals shown 
test ideal signals represent topic flow software engineering resolution level evaluation sequence 
signals correlation coe cient value 
ideal signal indicates strong topic relevance low rank value test signal test signal fluctuates points ideal signal constant 
correlation test ideal signals measured level resolution 
detailed levels expect ect noise high signals consequently correlation low 
proceed lower resolution levels noise gradually diminish correlation increase flow signals similar 
ideally noise diminished completely resolution level point signal corresponds average size 
segment size represented low ranked point reflect fact discusses topic minimal 
noise smoothed previous levels resolution 
sequences segment size corresponds resolution levels log log respectively 
resolution level general level noise minimal correlation ideal test signals high 
order evaluate correlation test ideal chapter 
building topic flow signal cl train list signals transform level test signal ideal signal example highly correlated ideal test topic flow signals 
signals represent flow computation language sequence resolution level chapter 
building topic flow signal ce resolution level segment position text test signal ideal signal example weakly correlated ideal test topic flow signals 
signals represent flow computational engineering finance science sequence resolution level chapter 
building topic flow signal se resolution level segment position text test signal ideal signal example moderately correlated ideal test topic flow signals 
signals represent flow software engineering sequence resolution level chapter 
building topic flow signal average rank level level level level levels computation language ideal signal resulting concatenating signals resolution levels sequence signal pairs levels resolution start concatenating topic test signals resolution levels sequences levels sequences 
concatenation process done ideal signals 
levels excluded contain points meaningful correlation coe cient values 
figures show concatenated signals computation language category 
concatenating signals get single pair vectors determining correlation test ideal signals multiple levels resolution 
chapter 
building topic flow signal position concatenated signal level level level level levels computation language test signal resulting concatenating signals resolution levels sequence chapter 
building topic flow signal results measured correlation concatenated ideal signal concatenated test signals sequences 
tables show top correlation coe cients signal pairs sequences 
table shows consistently high correlation ideal signal corresponding test signal topic sequences statistically significant confidence interval 
ideal signals sequences best resemble corresponding test signal category 
shows su cient topic words provided categorization consistency guaranteed topic flow representation algorithms succeed creating signals accurately reflect flow topic 
table shows ect extracting topic word list training set multi category documents 
corr training documents may belong category resulting topic word lists may influenced single document 
example topic word chunker computation language word 
occurs computation language learning training document word occurs learning topic word list 
topic flow signals tend share topic words expected 
higher proportion training documents group categories share stronger similarity signals 
table shows number training documents belonging category corr database top categories shares documents 
looking back table note second similar test signals topic ideal signal sequences top occurring categories 
chapter 
building topic flow signal lg lg lg ds ds ds chapter 
building topic flow signal ideal test corr signif test corr signif test corr signif cg cg cg cg cc cc cc ds ds ds ds cc cc cc chapter 
building topic flow signal ideal test corr signif test corr signif test corr signif pl pl pl ce ce ce chapter 
building topic flow signal ideal test corr signif test corr signif test corr signif resolution levels sequences 
topics test signals highest significance witha confidence interval chapter 
building topic flow signal lg lg lg ds ds ds chapter 
building topic flow signal ideal test corr signif test corr signif test corr signif cg cg cg cg cc cc cc ds cg cg cg cc cc cc chapter 
building topic flow signal ideal test corr signif test corr signif test corr signif pl pl pl ce ce ce chapter 
building topic flow signal ideal test corr signif test corr signif test corr signif resolution levels sequences 
topics test signals highest significance confidence interval 
chapter 
building topic flow signal ect sharing training documents evident sequence results table categories sharing highest proportion documents category top signals similar ideal signal 
sequence results reveal ect topic word lists insu ciently words categorization inconsistent training set 
sequence generally lower correlation sequences categories high medium correlation corresponding test signal ideal signals ce ds similar test signal di erent topic 
suspect due combination factors including training set size multi topic training documents important keywords discarded sequences training documents 
way reduce noise topic word lists consequently topic flow signals extract lists training set high proportion single category documents 
number single category training documents corr training set shown table 
table shows proportion single category documents total number training documents corr category 
categories containing highest proportion documents succeed generating test topic flow signals highly moderately correlated corresponding ideal signal 
categories containing lowest proportion single category documents generate test signals best weakly correlated corresponding ideal signal 
correlation values seen far show approach generating topic flow signals succeeds creating signals reflect flow topic text 
correlations concatenated signals incorporate noise resolution levels 
noise causes correlation lower chapter 
building topic flow signal topic training topic docs topic docs topic docs cl ai lg se pl lo cc ds cc ds ai lo lg ce ds cc ai table number training documents belonging topics 
building topic flow signal topic training topic ratio docs td training docs td cl cc se cg ni dc ai pl lo ds lg ce table number td training documents belonging corr topics number documents td documents identify topic chapter 
building topic flow signal correlation test ideal signals individual resolution levels 
example correlation test ideal concatenated learning signals text correlation individual levels text respectively 
higher correlation observed topics sequences 
table example shows correlated test signals ideal signal resolution level 
table top correlated test topics ideal signal resolution level text ideal test corr signif ai ai lo pl se cl cl lg cg ni cc cc ds cg ce se se pl ni chapter 
building topic flow signal table continued ideal test corr signif ce ce ce ds cg cc cg cg ds cc ce ds ds ce cg ni dc dc ni ce lg lg lg cl ni dc lo lo ai chapter 
building topic flow signal table continued ideal test corr signif pl se ni ni dc lg ce pl pl se lo ai table correlated test categories ideal signal sequence resolution level statistical significance correlation coe cients confidence interval 
interestingly noise ects correlation rooted test signals 
noise especially lower levels comes ideal signals 
remember building ideal signals assumed words topic topic words topic topic 
discussion assumed time reach resolution level segment size approximately equal size noise resulting assumption disappeared 
scatter plots ideal signal values versus test signal values re chapter 
building topic flow signal noise takes levels dissipates see 
scatter plots show value ideal signal specific resolution level values corresponding positions test signal level resolution 
example ideal signal computation language resolution level value points signal point number number 
points test signal values respectively 
shows scatter plot computation language ideal signal versus test signal resolution levels 
plot shows linear relationship ideal test signals category 
general ideal signal low test signal 
range test signal values correspond specific ideal signal value generally narrow extremes 
extremes correspond lowest possible highest possible ranks computation language category 
segment resolution level high extreme values words extreme values case occurs ideal signal segment topic topic 
test signal hand value cases words topic undoubtedly topic words topic may appear topic 
ratio topic words ect average rank creating wide range possible values plays role lowering correlation test ideal signals resolution level 
chapter 
building topic flow signal scatter plot computation language ideal values resolution lev resolution lev resolution lev resolution lev resolution lev resolution lev resolution lev resolution lev computation language scatter plot resolution levels ideal test signals sequence 
chapter 
building topic flow signal chapter shown construct signals represent flow topics text 
started basic algorithm construct word topic flow signals 
averaging algorithm allows word topic flow signals viewing flow topics various sized segments text 
tested quality topic flow signals showed topic word list algorithm able represent flow topic accurately 
experiments revealed quality topic flow signal dependent quality topic word list turn dependent training set create list 
propose study ect varying proportion single category documents training set quality topic word lists generated topic flow signals 
propose experiment ect di erent smoothing methods topic flow signal 
particular reduce oscillation topic segments reducing noise segments clarifying topic flow 
topic flow signals provide versatile representation text content 
important distinction topic flow signals fields text segmentation individual point topic flow signal represents relevance individual segment text independent rest text 
relevance measured unique topic relevance measure dfn described previous chapter 
quite di erent plots segmentation texttiling hea example point plot represents similarity consecutive segments 
signals meant represent content text way variety applications including text segmentation topic detection topic tracking chapter 
building topic flow signal document visualization 
chapter possible application topic flow signals text categorization 
chapter application text categorization view text sequence topics beneficial retrieval tasks rely text content similar tasks text summarization text segmentation document clustering text categorization 
chapter examines benefits topic spread text categorization 
define text categorization general categorization model 
describe support vector machines stateof art categorization method show improve performance topic words topic distribution text 
chapter 
application text categorization text categorization definition applications text categorization systems group text data pre specified set labels categories 
applications automatic text categorization numerous obvious automating manually categorized databases yahoo infoseek 
automation provides consistent expensive cient categorization 
useful application text filtering system learns user interests filters incoming documents emails fall categories deemed interesting user 
addition automatic text categorization large amounts data manageable may browse data topic search data belongs certain categories view search results category viewing long lists documents cd hea 
applicability text categorization dependent ectiveness robustness noisy real life data 
approaches proposed advantages disadvantages 
systems share common general model describe 
preprocessing input text categorization system set categories document categorized output subset categories relevant input text 
text comes di erent formats contains significantly information categorizer requires input document usually preprocessed passed classifier 
tokenization stopword removal stemming steps discussed detail section apply 
chapter 
application text categorization document representation input text tokenized stemmed stopwords removed text converted representation acceptable categorizer 
common representation document represented vector dimension associated unique feature value feature represents weight text 
method calculate feature weight varies general weight meant reflect dominance feature document 
researchers see example van sm mn experimented words document features word weighted pure term frequency binary value occurrence document tf idf function tf idf tf log df word document 
tf term frequency document 
number documents training set 
df document frequency word term frequency generally perform better binary feature weights extent improvement influenced classification method database mn ms joa 
take simple example assume categorizer vocabulary bank commerce money input text tokenization chapter 
application text categorization bank money commerce commerce bank money vector representing sample document consists terms bank money term weights respectively 
stemming consists words bank money 
vector representation document shown weights bank money input text 
document classification input ready forwarded categorizer 
system categorize documents needs model category category set 
method achieve supervised learning 
supervised learning involves training system pre labeled data 
labels data reflect document categories usually prepared human assumed correct 
data system identifies criteria distinguish documents belonging category categories 
chapter 
application text categorization training phase done categorizer ready accept categorize unlabeled input documents 
binary text classification supervised learning approaches set training documents labeled humans positive negative examples category 
system creates training data approximation function represents criteria distinguishing positive negative training examples category 
learned model classifier category label previously unseen documents belonging category 
category binary classifiers built category 
documents classifier independent decision document belongs category 
cases document allowed single label 
possible approach case attach confidence level category label document allow label highest confidence joa 
examples supervised learning systems rocchio algorithm naive bayes algorithm lew support vector machines joa 
general approach shown 
variations architecture 
instance skip learning stage represent category directly training documents 
called lazy learning 
type learning system minimal training stage 
compares incoming unlabeled input documents directly training data 
prominent example class nearest neighbor mit 
categorization methods support vector machines svms perform better categorization systems joa yl coo 
follows discuss basics svms fol chapter 
application text categorization training preprocessing system representation category training documents category training documents category system representation category stemming removal stopword categorization feature extraction tokenization categories general architecture text categorization system 
system categorizing document categories system trained recognize categories training documents categories 
chapter 
application text categorization lowing description joachims joa explore ect replacing traditional documents bags words vectors representations reflect distribution topics document 
text categorization support vector machines simplest type svms linear support vector machines 
linear svms create hyperplane separating positive examples negative ones 
placing hyperplanes svms attempt maximize distance negative positive examples closest turn minimizes error 
distance negative positive examples closest hyperplane called margin closest training examples called support vectors 
separating hyperplane maximizes margin described weight vector maximum margin 
plane resulting classification function requires document relevant category 
shows example set training examples separated hyperplane margin 
indication expressiveness svm vc dimension vcdim 
vcdim model small model overfit data creating false negatives vcdim large may indicate model simple classifier may tend generalize means classifier tends generate false positives 
joachims reports vapnik joa showed hyperplane optimum vcdim largest distance closest training examples 
chapter 
application text categorization svms separate positive examples negative ones called svms 
cases possible find hyperplane 
case possible soften condition separation allow training examples wrong side hyperplane cost svms called soft margin svms 
positive examples negative ones vice versa case may desirable assign di erent costs type example avoid putting emphasis avoiding errors assigning frequent type examples 
cases training data may linearly separable 
shows example 
svms solve problem seed functions called kernel functions succeed mapping data non linear space simpler linear space training 
specifically kernel functions map data original space high dimensional space implicit basis expansion 
classifier created kernel function map test documents linear space classified 
examples popular kernels svms polynomials poly radial basis functions rbf 
example document features non linear space mapped linear space polynomial kernel degree poly rbf kernel rbf exp values set user svm learner 
detailed description svms parameters joachims dissertation joa 
chapter 
application text categorization example linear data set linear hyperplane separating positive negative examples margin 
nonlinear data set separated linear hyperplane 
model selection svm training set mission generate classifier training data 
possible di erent kernels variations parameter values generate classifier 
unfortunately automatic way select generate best performance unseen documents 
choose classifiers follow algorithm described joachims joa select set parameters variables consider 
combination values calculate estimate expected performance training data choose model best estimate 
joachims joa tested ectiveness di erent estimates predicting classifier performance determined leave precision recall chapter 
application text categorization break point bep loo ective 
leave cross validation estimation system trains training examples tests performance remaining document records succeeded predicting class document 
process repeated times training documents test classifier performance 
results calculate classifier leave estimation precision recall mean bep loo model 
topic distribution documents support vector machines previous svm expects training documents represented weighted vectors features 
researchers experimented svms words document features word weighted pure term frequency binary value occurrence document tf idf function joa yl 
definition feature word datum helps distinguish documents belonging category documents 
interesting features studied suggested documents represented vectors semantically similar word clusters generated automatically information bottleneck approach ib 
initially word labeled classes occurs 
main idea ib cluster words minimal loss mutual information words class labels maximizing chapter 
application text categorization cw cw set labeled words 
cw clusters created set labels 
cw cw mutual information cw cw 
factor controlling allowed amount reduction mutual information caused clustering cw compare cluster svm tf idf svm uses tf idf weights feature selection 
tests show improvement microaveraged bep tf idf svm frequent categories reuters database reu 
word clustering group words occurrence statistics called latent semantic kernels 
features approach document words latent semantic kernels create map individual words cluster semantically related words 
unfortunately tests reuters database result improved performance linear tf idf svm classifier 
chapter 
application text categorization incorporating topic distribution document features thesis show benefits word spread identifying important topic words representing relevance topics document 
words document features represent documents number occurrences relevance rankings document defined chapter 
document vector contain list ranking levels weighted number occurrences document 
dominant category top ranking words stronger evidence document relevance category 
represent document relevance ranking words category replacing word document relevance ranking 
importance rank document weighted number times rank occurs document 
example previous chapter saw signal example example belief revision focuses agent change beliefs adopts particular new belief 
fh example words belief revision beliefs belief top rank category ai remaining vocabulary words agent change lower ranks respectively 
assuming maximum rank topic word list category ai vector representing example respect ai features feature having weight features having weight features having weight shown 
procedure followed represent chapter 
application text categorization relevance rank 


convert bag ranks representation belief revision agent change beliefs belief words replace ranks converting example bag ranks representation 
document respect category category topic word ranks 
representation relevance rankings replace words bagof words method position information retained 
call bagof ranks representation 
experiments chapter show word position information may useful identifying better topic words 
idea dfn measure discuss topic topic words spread length text occur segments document 
important topic words segments occur stronger evidence document topic 
measure spread rank number segments occurs 
approach vector representing document category dimensional matrix rows reflecting maximum number segments features row maximum rank category feature weight feature number times relevance rank occurs segments 
example chapter 
application text categorization 


number segments relevance rank segments divide ranks replace words agent revision belief belief beliefs change agent revision belief change representation topic spread convert belief beliefs converting example topic spread representation 
divide example segments segment consist vocabulary words belief revision agent correspond ranks respectively 
second segment consist change beliefs belief correspond ranks respectively 
vector representation text matrix feature having weight relevance rank occurs twice segments feature having weight rank occurs twice segment features having weight relevance ranks occur segment features having weight shown 
call representation topic spread representation 
experiments experiments follow compare performance svm classifier tf idf document representation tf idf svm bag ranks document representation bag ranks svm topic spread representation chapter 
application text categorization topic spread svm 
joachim svm implementation sv light joa methods 
database training database categories described section 
test documents consist submitted corr website july december 
test documents converted text version det convert training documents 
removing empty test documents ones belong categories training database left test documents categorized category 
test documents correct category belonging corr categories considered tests test files correct categories corr categories considered 
table shows number test files categories 
experimental setup training sets category 
category preprocessing training document done section 
document represented vector features tf idf svm tf idf function weigh document words bag ranks svm uses category topic word list sorted df replace document words relevance ranking 
ranking weighed frequency occurrence document 
topic spread method linearize dimensional matrix dimensional vector representation expected sv light chapter 
application text categorization category test files ni lg ce se cg ds dc lo pl ai cc cl table number test files category chapter 
application text categorization row major order mapping feature dimensional matrix rank number segments maximum value 
document divided segments rank occurrences document counted ranking sorted df topic word list category 
weight feature minimum number occurrences rank segments weight feature minimum number occurrences rank segments forth 
document vectors created methods vector normalized length labeled training set positive example belongs category negative example 
training set category constructed move selecting best model category 
experimented di erent values cost factor factor adjusts misclassification cost positive examples keeping cost negative examples polynomial degree factor rbf kernel 
combination values sv light produces leave estimate precision recall 
model produces highest loo category choose classify test documents respect category 
table shows values search best classifier category 
discuss observations regarding resulting models results section 
evaluation measures categorization systems usually evaluated comparing category assignments humans 
popular evaluation measures precision chapter 
application text categorization general parameters polynomial kernel rbf kernel table values search best category model corr category 
ratio number negative category examples number positive examples training database category ratio ai cc ce cg cl dc ds lg lo ni pl se table ratio negative positive examples parameter 
chapter 
application text categorization recall 
precision proportion correct categories assigned system test documents total number categories system assigns 
recall proportion correct categories assigned system total number categories assigned humans 
test documents calculate precision counting number correct categories assigned test documents dividing total number categories assigned system est corr num est set test documents 
corr number correct categories assigned system test document num number categories correct incorrect assigned system test document recall calculated similar manner dividing number correct categories assigned system total number correct categories assigned humans est corr corr est corr 
chapter 
application text categorization corr number categories assigned human judges test document measures combined measure called measure reflects ectiveness system assuming precision recall equally important lew yl ms defined pr precision recall 
precision recall calculating breakeven point bep point precision expected equal recall 
higher bep better performance system 
case binary classifiers defined mean precision recall values bep 
measures pool classifiers decisions called microaveraged bep microaveraged performance measures give categorization decision equal weight categories 
measures influenced heavily categories higher number test documents 
alternatively group test documents human assigned categories calculate precision recall bep values group 
average values macroaveraged bep respectively 
microaveraged version weighs categories equally 
chapter 
application text categorization experiments reporting microaveraged macroaveraged bep recall precision 
results analysis model selection starting parameter values shown table sv light joa evaluate leave bep combination tf idf bag ranks topic spread methods 
models equal bep model lower vc dim selected 
resulting models ranked bep top model category method selected 
selected models parameters shown tables 
tables show kernel model parameters apply kernel vc dimension model leave estimate precision recall bep 
models highest bep values models bep close top 
agrees joachims observation usually range classifiers produce similar performance joa 
interesting note tf idf method tends select linear polynomial rbf kernels bag ranks topic spread methods tend select polynomial kernel varying degrees 
note wide di erence bep loo values tf idf models bag ranks topic spread svm 
estimates indicate tendency overfitting data topic spread bag ranks document representations succeed capturing useful information document content 
presence chapter 
application text categorization cat kernel vcdim recall prec bep ai poly cc rbf ce rbf cg poly cl rbf dc poly ds rbf lg rbf lo rbf ni poly pl rbf se rbf table cost factor optimization parameter factor rbf kernel degree polynomial kernel top ranking models corr cat tf idf approach 
table shows selected classifier leave estimate precision recall breakeven point 
chapter 
application text categorization cat kernel vcdim recall prec bep ai poly cc poly ce rbf cg poly cl poly dc poly ds poly lg poly lo rbf ni rbf pl poly se poly table cost factor optimization parameter factor rbf kernel degree polynomial kernel top ranking models corr cat bag ranks approach 
table shows selected classifier leave estimate precision recall breakeven point 
chapter 
application text categorization cat kernel vcdim recall prec bep ai poly cc poly ce poly cg poly cl poly dc poly ds rbf lg poly lo poly ni poly se rbf pl rbf table cost factor optimization parameter factor rbf kernel degree polynomial kernel top ranking models corr cat topic spread approach 
table shows selected classifier leave estimate precision recall breakeven point 
chapter 
application text categorization complete topic word lists representations produce accurate models tf idf svm 
overfitting problem expect test results show recall falling tf idf method 
table shows number cpu seconds method create selected classification models shared sun machine cpu ram running sunos 
average time topic spread method cpu seconds tf idf method average time bags ranks approach average time tf idf approach 
models selected classify test documents 
categorization performance average classification time approaches shown table 
average time topic spread bag ranks approaches tf idf method 
topic spread method average classification time cpu seconds classification time tf idf approach bag ranks approach average classification time cpu seconds time tf idf approach 
table shows performance results test data 
micro macro averaged bep topic spread method highest methods indicating positive ect df frequency topic spread information classification performance 
note coupled fact topic spread method bag ranks method vocabulary chapter 
application text categorization classification building classification model cg cl dc model classify corr categories 
experiments run cpu shared sun 
application text categorization bep bep bep ce cg ds ni pl micro chapter 
application text categorization size vocabulary tf idf method 
average recall bag ranks topic spread methods higher tf idf reflects ect relevance ranking identifying relevant documents unrecognized tf idf function 
method ect recall high bep loo values seen training due overfitting 
topic spread information produces accurate category model produced tf idf approach 
improvement recall statistically significant confidence interval degrees freedom 
improvement comes cost slightly lower precision goes tf idf bag ranks 
adding topic word spread information method manages compensate lost precision bringing 
ect microaveraged precision recall similar 
bep values statistically insignificant confidence interval 
tf idf method macroaveraged bep close estimated bep loo table 
tf idf method bep topic spread bag ranks methods quite di erent predicted training set falling estimated macroaveraged bep loo seen tables respectively bep 
di erence probably due coverage df topic word list created multi labeled training documents introducing noise lists adversely ecting quality vector representations methods 
resulting classifiers perform tf idf method vocabulary size chapter 
application text categorization tf idf svm 
chapter presents text categorization possible application topic spread topic relevance methods discussed previous chapters 
proposes document representations topic relevance rankings bag ranks distribution rankings document topic spread 
tests show representations produce small improvements performance svm uses traditional tf idf vector representation vocabulary size size vocabulary tf idf vector representation 
proposed methods reduce model creation time little average time tf idf approach classification time average classification time tf idf approach 
experiments chapter explore ect df topic word lists bag ranks topic spread representations 
interesting investigate ect topic word lists produced dfn 
similarly study ect increasing maximum number segments topic spread approach 
suspect multi labeled documents creating topic word lists ected quality results introducing lists topic words relevant frequently occurring categories 
interesting look change performance resulting restricting training documents single labels 
chapter originated experience project 
project aimed indexing aspects including content discussion meeting agenda forms interaction participants 
project highlighted importance temporal positioning words tracking content 
word position information useful tasks requiring local content analysis topic flow identification passage retrieval text summarization segmentation 
thesis methods utilize word position text topic word selectors topic flow signals 
topic word selectors identify important words called topic words spread text 
example word occurs times single paragraph document considered important occurs occurrence spread document 
underlying assumption words spread text relevant main topic text ones concentrated small segments 
experiments divide document chapter 
equal length segments preset value spread topic word defined number documents word occurs segments document df experiments showed manually selected keywords correspond closely topic words selected selectors words selected traditional indexing measures 
correspondence indicates topic words identify topical content documents words selected traditional indexing measures utilize word position text 
experiments indicated topic word quality improves number segments increases certain value quality words starts decrease 
word stemming porter stemmer por degrades quality selected words remains seen aggressive stemmer di erent ect topic word quality 
study ect relaxing condition word spread allowing topic word occur subset document segments 
interesting explore ect document length quality generated topic words 
issue worth investigating stopword removal 
predefined stopword list thesis stopword removal preliminary experiments indicate df feature selection acceptable alternative 
topic words useful applications 
instance short context topic words form helpful starting point users trying create lexicon particular topic selecting set short topic word contexts reflect topic 
idea evaluating quality word spread document may prove useful feature selection help improve performance categorization text retrieval systems 
second approach representing word position topic flow signals 
chapter 
representation words replaced measure relevance topic 
flow topic traced document viewed signal remains low word relevant topic rises indicate irrelevant word occurrence 
intended flow topics represented multi band signal 
reflect flow topic larger segments text simple smoothing technique 
resulting smoothed signals shown correlated ideal topic flow signals text sequence 
explore ect smoothing techniques quality signals 
incorporating immediate short context words may useful refining signals preliminary experiments moving window smoothing signal show substantial improvements 
results shown topic flow signals succeed representing flow topic document su cient list topic words 
suspect quality topic word lists quality resulting topic flow signals influenced proportion multi labeled training documents 
relationship multi labeled training documents extract topic word lists quality topic flow signals lists left study 
topic flow signals versatile text representations emphasizing relevance topic individual point text 
applications topic flow signals 
example topic flow signals may topic tracking spoken discussions 
kazman introduced interesting interface prototype 
system users view progress meeting terms parallel streams representing speech content meeting participant 
topic flow signals implement similar interface users track change intensity discussion particular topic chapter 
moment meeting participant 
smoothing technique allow users view change di erent levels detail real time 
similar application possible visualization tool proposed miller 
text visualization prototype allows users view changes text content content signal navigate text keywords signal levels resolution 
topic flow signals allow richer view text signal reflects individual topic 
topic flow signals useful text segmentation recognizing points text sudden change topics discussed done di erent representations green gre hearst hea 
may segment text topic individual topic flow signals 
case di erent text segments reflect di erent degrees relevance topic 
relevant segments assist summarizing document respect topic 
important note topic flow signals discussed quite di erent hearst texttiling hea 
representations look signals graphs generated texttiling reflect inter similarity consecutive text segments 
inter segment similarity represented topic flow signals 
point signal reflects relevance corresponding point text specific topic 
signal smoothed get average topic relevance text segment smoothed portion cross similarity points segment 
text represented number simultaneously running topic flow signals 
methods compare bands signals ectively need study 
defined topics stationary entities represented chapter 
fixed set topic words 
may able allow dynamic topic representations continuously introducing new training documents discussing relevant issues seen system 
dynamic representation essential tasks topic content changes continuously topic tracking task topic detection tracking conference tdt tdt 
tdt context topics defined events set newspaper stories acd way 
progress event viewed part topic 
example topic cow infected mad cow disease updates story take place part topic 
dynamic topic representation topic flow signals may tracking progress topic incoming stream text 
support vector machines show benefits topic spread text categorization 
experiments showed way topic words spread document indication document main topics 
reflect topic spread proposed document representations topic spread bags ranks define document features relevance document words topic df topic relevance selector spread relevance values document 
compared categorization ectiveness representations svm traditional words features representation weighted tf idf function tf idf svm 
document representations improved recall levels tf idf svm classifier reducing average document vector length length traditional tf idf vector representation vocabulary size vocabulary size tf idf representation 
proposed methods reduced svm model creation time little average time tf idf svm classification time little average chapter 
classification time tf idf svm 
ect topic relevance selectors dfn categorization performance left study 
written text focus thesis 
expect word position beneficial spoken discussions important issues discussed longer periods time reintroduced repeatedly meeting 
step studying ect word position text understanding tracking content text 
results seen far promising 
expect refinement achieve accurate picture written spoken text content 
bibliography acd allan carbonell doddington yamron yang 
topic detection tracking pilot study final report 
proceedings darpa broadcast news transcription understanding workshop 
acm acm computing classification system 
www acm org class ccs html 
ron ran el yaniv naftali tishby winter 
distributional word clusters vs words text categorization 
journal machine learning march 
abraham bookstein shmuel klein timo 
clumping properties content bearing words 
journal american society information science 
bm mary brewster nancy miller 
information retrieval system utilizing wavelet transform 
united states patent 
ricardo baeza yates berthier ribeiro neto 
modern information retrieval 
acm press addison wesley 
bibliography ccb charlie clarke cormack burkowski 
retrieval heterogeneous structured text 
technical report cs university waterloo 
clarke cormack 
question answering passage selection 
proceedings ninth text retrieval conference trec gaithersburg maryland november 
cd chen dumais 
bringing order web automatically categorizing search results 
proceedings chi human factors computing systems 
ch church hanks 
word association norms mutual information lexicography 
computational linguistics 
chu church 
empirical estimates adaptation chance noriega closer 
coling pages 
cl choueka 
disambiguation short contexts 
computers humanities 
coo cooley 
classification news stories support vector machines 
ijcai workshop text mining stockholm sweden august 
cora computing research repository corr 
arxiv org archive cs 
subject classes corr index 
arxiv org archive cs intro html 
bibliography csa computer information systems abstracts 
www csa com csa ids databases collections shtml 
dam fred damerau 
evaluating computer generated domain oriented vocabularies 
information processing management 
dam fred damerau 
generating evaluating domain oriented multiword terms texts 
information processing management 
ddl deerwester dumais landauer furnas harshman 
indexing latent semantic analysis 
journal society information science 
det 
www cs purdue edu homes 
dumais platt heckerman sahami 
inductive learning algorithms representations text categorization 
cikm proceedings seventh international conference information knowledge management 
fh nir friedman joseph halpern 
modeling belief dynamic systems 
computing research repository corr 
www arxiv com archive cs 
fra william frakes 
stemming algorithms 
william frakes baeza yates editors information retrieval data structures algorithms pages 
prentice hall englewood cli nj 
bibliography william gale kenneth church david yarowsky 
method disambiguating word senses large corpus 
computers humanities 
gre green 
automatically generating hypertext computing semantic similarity 
phd thesis department computer science university toronto 
gre stephen green 
automated link generation better term repetition 
computer networks isdn systems 
har harman editor 
common evaluation measures gaithersburg md 
department commerce national institute standards technology 
hea hearst 
context structure automated full text information access 
ph thesis ucb csd uc berkeley computer science april 
hea hearst 
categories provide context full text retrieval results 
proceedings riao intelligent multimedia information retrieval systems management pages 
hea marti hearst 
multi paragraph segmentation expository text 
nd 
annual meeting association computational linguistics pages new mexico state university las cruces new mexico 
hea hearst 
texttiling segmenting text multi paragraph subtopic passages 
computational linguistics 
bibliography arne anders la 
ripples mathematics discrete wavelet transform 
springer 
joa joachims 
making large scale support vector machine learning practical 
smola scholkopf burges editor advances kernel methods support vector machines 
mit press cambridge ma 
joa thorsten joachims 
text categorization support vector machines learning relevant features 
claire nedellec rouveirol editors proceedings ecml th european conference machine learning number pages chemnitz de 
springer verlag heidelberg de 
joa joachims 
learning classify text support vector machines methods theory algorithms 
kluwer 
kazman hunt mantei 
paradigms indexing video conferences 
ieee multimedia 
kat slava katz 
distribution content words phrases text language modelling 
natural language engineering 
kb bruce krulwich chad 
agent learning user interests heuristic phrase extraction 
ieee expert 
kmk min yen kan kathleen mckeown judith klavans 
applying natural language generation indicative summarization 
proceedings eighth european workshop natural language generation 
bibliography julian kupiec jan pedersen chen 
trainable document summarizer 
research development information retrieval pages 
les lesk 
automatic sense disambiguation tell pine cone ice cream cone 
proceedings conference acm pages 
lew lewis 
feature selection feature extraction text categorization 
proceedings speech natural language workshop pages san mateo california 
morgan kaufmann 
lew lewis 
evaluating optimizing autonomous text classification systems 
fox ingwersen fidel editors proceedings th annual international acm sigir conference research development information retrieval pages seattle washington 
acm press 
lew david lewis 
naive bayes independence assumption information retrieval 
claire nedellec rouveirol editors proceedings ecml th european conference machine learning number pages chemnitz de 
springer verlag heidelberg de 
david lewis robert schapire james callan ron papka 
training algorithms linear text classifiers 
hans peter frei donna harman peter schauble ross wilkinson editors proceedings sigir th acm international conference re bibliography search development information retrieval pages zurich ch 
acm press new york 
mh jane morris graeme hirst 
lexical cohesion computed thesaural relations indicator structure text 
computational linguistics 
mit tom mitchell 
machine learning 
mcgraw hill press new york 
mn mccallum nigam 
comparison event models naive bayes text classification 
aaai workshop learning text categorization 
ms christopher manning hinrich schutze 
foundations statistical natural language processing 
mit press cambridge massachusetts 
msb mitra singhal buckley 
automatic text summarization paragraph extraction 
mani maybury editors proceedings th national conference artificial intelligence aaai pages 
nancy miller pak chung wong mary brewster foote 
topic islands wavelet text visualization system 
david ebert hans hagen holly rushmeier editors ieee visualization pages 
ost bernard 
statistics research basic concepts techniques research workers 
iowa state university press ames 
bibliography lawrence page sergey brin rajeev motwani terry winograd 
pagerank citation ranking bringing order web 
technical report stanford digital library technologies project 
por porter 
algorithm su stripping 
program july 
reu reuters text categorization test collection 
www research att com lewis reuters html 
sab salton allan buckley 
approaches passage retrieval information systems 
sigir acm pages new york 
sal salton 
smart retrieval system experiments automatic document processing 
prentice hall 
sal salton 
dynamic information library processing 
prenticehall englewood cli new jersey 
sha stuart shapiro editor 
encyclopedia artificial intelligence 
john wiley new york ny 
silverstein henzinger marais 
analysis large altavista query log 
technical report dec systems research center 
sig digital signal processing 
www com intro htm 
sm salton mcgill 
modern information retrieval 
mcgraw hill 
bibliography sn gilbert strang truong nguyen 
wavelets filter banks 
wellesley cambridge press 
gerard salton amit singhal chris buckley mandar mitra 
automatic text decomposition text segments text themes 
uk conference hypertext pages 
st tompa 
pat expressions algebra text search 
acta linguistica pages 
sto smart stopword list 
ftp ftp cs cornell edu pub smart english 
tdt topic detection tracking homepage 
www nist gov speech tests tdt 
tom tompa 
tagged text 
proceedings th annual conference uw centre new oxford english dictionary pages oxford england 
tom frank tompa 
views text 
digital media information base 
naftali tishby fernando pereira william bialek 
information bottleneck method 
proc 
th annual allerton conference communication control computing pages 
van van rijsbergen 
information retrieval 
nd ed butterworths 
bibliography way charles wayne 
topic detection tracking tdt overview perspective 
proceedings darpa broadcast news transcription understanding workshop va 
yahoo 
www yahoo com 
yc yang chute 
application squares fit mapping text information retrieval 
proceedings th ann int acm sigir conference research development information retrieval sigir pages 
yl yiming yang xin liu 
re examination text categorization methods 
proceedings acm sigir conference research development information retrieval sigir pages 
yp yiming yang jan pedersen 
comparative study feature selection text categorization 
proc 
th international conference machine learning pages 
morgan kaufmann 
appendix subject areas corr database ar architecture covers systems organization architecture 
roughly includes material acm subject classes 
ai artificial intelligence covers areas ai vision robotics machine learning multiagent systems computation language natural language processing separate subject areas 
particular includes expert systems theorem proving may overlap logic computer science knowledge representation planning uncertainty ai 
roughly includes material acm subject classes 
cc computational complexity covers models computation complexity classes structural complexity complexity tradeo upper lower bounds 
appendix subject areas corr database roughly includes material acm subject classes 
material may appropriate data structures algorithms primary subject area 
material may logic computer science primary subject area 
cg computational geometry roughly includes material acm subject classes 
ce computational science engineering finance covers computational methods areas science including computational biology computational chemistry engineering finance 
roughly includes material acm subject classes 
cl computation language subsumes cmp lg covers natural language processing 
roughly includes material acm subject class 
cv computer vision pattern recognition covers image processing computer vision pattern recognition scene understanding 
roughly includes material acm subject classes 
cy computers society covers impact computers society computer ethics information technology public policy legal aspects computing computers education 
roughly includes material acm subject classes 
cr cryptography security covers areas cryptography security including authentication public key proof carrying code roughly includes material acm subject classes 
appendix subject areas corr database db databases covers database management datamining data processing 
roughly includes material acm subject classes 
ds data structures algorithms covers data structures analysis algorithms roughly includes material acm subject classes 
dl digital libraries covers aspects digital library design document text creation 
note overlap information retrieval separate subject area 
roughly includes material acm subject classes 
dm discrete mathematics covers combinatorics graph theory applications probability 
roughly includes material acm subject classes 
dc distributed parallel cluster computing covers fault tolerance distributed algorithms parallel computation cluster computing 
roughly includes material acm subject classes 
gl general literature covers introductory material survey material predictions trends biographies miscellaneous computer science related material 
roughly includes acm subject class include conference proceedings listed appropriate subject area 
gr graphics covers aspects computer graphics 
roughly includes material acm subject class appendix subject areas corr database computational geometry primary subject area 
hc human computer interaction covers human factors user interfaces collaborative computing 
roughly includes material acm subject classes multimedia primary subject area 
ir information retrieval covers indexing dictionaries retrieval content analysis 
roughly includes material acm subject classes 
lg learning covers machine learning computational pac learning 
roughly includes material acm subject class 
lo logic computer science covers aspects logic computer science including finite model theory logics programs modal logic program verification 
programming language semantics programming languages primary subject area 
roughly includes material acm subject classes 
ms mathematical software roughly includes material acm subject class 
ma multiagent systems covers multiagent systems distributed artificial intelligence intelligent agents coordinated interactions 
practical applications 
roughly covers acm subject class 
mm multimedia roughly includes material acm subject class 
ni networking internet architecture covers aspects computer communication networks including network architecture design network appendix subject areas corr database protocols internetwork standards tcp ip 
includes topics web caching directly relevant internet architecture performance 
roughly includes acm subject class distributed parallel cluster computing primary subject area 
ne neural evolutionary computation covers neural networks connectionism genetic algorithms artificial life adaptive behavior 
roughly includes material acm subject class 
na numerical analysis roughly includes material acm subject class 
os operating systems roughly includes material acm subject classes 
oh classification documents fit 
pf performance covers performance measurement evaluation queueing simulation 
roughly includes material acm subject classes 
pl programming languages covers programming language semantics language features programming approaches object oriented programming functional programming logic programming 
roughly includes material acm subject classes 
ro robotics roughly includes material acm subject class 
appendix subject areas corr database se software engineering covers design tools software metrics testing debugging programming environments roughly includes material acm subject classes program verification probably logics computer science primary subject area 
sd sound covers aspects computing sound sound information channel 
includes models sound analysis synthesis audio user interfaces sonification data computer music sound signal processing 
includes acm subject class intersects 
sc symbolic computation roughly includes material acm subject class 
