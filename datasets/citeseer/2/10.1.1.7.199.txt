logic regression ingo charles michael leblanc logic regression adaptive regression methodology attempts construct predictors boolean combinations binary covariates 
regression problems model developed relates main ects predictors transformations thereof response interactions usually kept simple way interactions 
especially predictors binary interaction predictors may causes di erences response 
issue arises example analysis snp microarray data data mining problems 
proposed methodology set binary predictors create new predictors true true 
speci terms try regression models form boolean expression predictors 
estimated simultaneously simulated annealing algorithm 
discuss logic regression models carry model selection models give examples 
key words adaptive model selection boolean logic binary variables interactions simulated annealing snp data 
ingo assistant professor johns hopkins university department biostatistics school public health wolfe street baltimore md email ingo jhu edu 
charles michael leblanc members fred hutchinson cancer research center division public health sciences po box seattle wa mail clk org crab org 
regression problems model developed relates main ects predictors transformations thereof response 
interactions predictors considered interactions usually kept simple way interactions 
especially predictors binary interaction predictors causes di erences response 
example publication ott concerned analyzing relationship disease loci complex traits 
ott recognize importance interactions loci potential shortcomings methods take interactions appropriately account current methods analyzing complex traits include analyzing localizing disease loci time 
complex traits caused interaction loci varying ect 
authors state nding interactions desirable solution problem infeasible 
patterns interactions loci example disease phenotype caused locus locus clearly identi cation involved loci dicult 
simultaneous analysis single way pair markers feasible overwhelmingly computationally burdensome analyze way way way patterns patterns combinations loci 
example types problems concerned 
set binary true false predictors try create new better predictors response considering combinations binary predictors 
example response binary requirement method discussed attempt nd decision rules true true response class 
words try nd boolean statements involving binary predictors enhance prediction response 
near example arise snp microarray data see daly possible application interested nding association variations dna sequences disease outcome cancer 
introduces methodology developed nd solutions kind problems 
tight association boolean logic decided call methodology logic regression 
wealth approaches building binary rules decision trees decision rules computer science machine learning lesser extent statistics literature 
provide literature review serves highlight di erences methodology methods hope clear sections 
knowledge logic regression methodology searching boolean combinations predictors entire space combinations completely embedded regression framework quality models determined respective objective functions regression class 
contrast methods discussed literature review models cox proportional hazards model logic regression long scoring function de ned 
making computationally feasible search entire space models compromising desire optimality think logic regression models able ll void regression classi cation methodology 
section introduce basics logic regression 
sections search best models model selection explain nd best models 
section illustrate features case study simulated data data cardiovascular health study describe results obtained analyzing snp array data th genetic analysis workshop 
concludes discussion section 
explanations technical details logic regression deferred appendix 
logic regression describing second part section models interested introduce terminology article 
logic expressions want nd combinations binary variables high predictive power response variable 
combinations boolean logic expressions predictors binary combinations predictors binary 
assume familiarity basic concepts boolean logic 
closely follow peter online tutorial boolean logic circuits cs ru ac za func bool contains thorough boolean algebra 
values values true false 
variables symbols variables represent possible values 
operators operators combine values variables 
di erent operators 
called conjugate expressions combination values variables operators results expressions 
example logic boolean expression built variables operators 
equations equation assigns name expression 
example refer expression simply stating brackets boolean expression generated iteratively combining variables variable boolean expression boolean expressions shown equation 
expression read statement generated boolean expressions 
understood statement generated boolean expressions 
interpretation boolean expressions enables represent boolean expression binary tree format shown 
evaluation tree logic statement particular case occurs bottom fashion recursive substitution 
prediction tree value appears root de nition see procedure 
terminology rules logic trees similar terminology breiman 
decision trees 
logic tree representing boolean expression 
simplicity index variable shown 
white letters black background denote conjugate variable 
location element variable conjugate variable operators tree knot 
knot zero sub knots 
sub knots knot called children knot called parent sub knots 
sub knots siblings 
knot parent called root 
knots children called leaves 
leaves occupied letters conjugate letters predictors knots operators 
note representation boolean expression unique representation logic tree 
example boolean expression equation written method construct logic tree boolean expressions described result logic tree looks complex equivalent tree sense trees yield results set predictors 
see discussion simpli cation boolean expressions context logic regression 
described standard boolean expressions introduced logic trees way represent boolean expressions conveniently simplify implementation algorithm discussed section 
appendix discuss relation trees known constructs example boolean expressions disjunctive normal form play key role publications computer science engineering literature see example decision trees introduced breiman 
see section 
logic regression models binary predictors response variable 
try regression models form boolean expression predictors refer models logic models 
framework includes example linear regression logistic regression log 
model type de ne score function re ects quality model consideration 
example linear regression score residual sum squares logistic regression score binomial deviance 
try nd boolean expressions minimize scoring function associated model type estimating parameters simultaneously search boolean expressions principle models classi cation models cox proportional hazards model implemented long scoring function de ned 
come back section 
approaches modeling binary data large number approaches regression classi cation problems machine learning computer science statistics literature appropriate predictor variables binary 
section discuss number approaches 
boolean functions played key role machine learning engineering literature past years emphasis boolean terms disjunctive normal form example michalski apte weiss hong deshpande 
especially machine learning literature methods algorithms boolean functions generally decision trees decision rules 
known algorithms quinlan id quinlan quinlan quinlan 
cart breiman sliq mehta agrawal rissanen belong category 
rule methods include aq family michalski cn algorithm clark niblett swap algorithms weiss indurkhya weiss indurkhya weiss indurkhya ripper slipper cohen cohen singer system gama grasp deshpande cws domingos 
approaches nd optimal association rules proposed knowledge discovery data mining community bayardo agrawal webb 
authors proposed combine simpler existing rule models complex classi ers liu hsu ma 
mentioned nice review apte weiss describing decision trees rule induction data mining examples 
categories trees versus rules methods di er aim classi cation versus regression cart mars exceptions classi cation regression settings 
vast majority algorithms published literature concerned classi cation 
previously mentioned id cn sliq ripper slipper swap 
myriad algorithms derivations methods exist variety applications see example apte damerau weiss 
weiss indurkhya introduced extension swap algorithm learns regression rules form ordered disjunctive normal form dnf decision rules 
swap deals regression transforming classi cation problem 
gama extend idea proposing processor works classi cation method regression framework 
methods transform regression classi cation searches logical conditions format build piece wise regression models constructs tree piece wise linear models 
models trees linear regression components terminal nodes known statistical literature models chipman george mcculloch 
commercial package developed quinlan learns rules linear models 
example rule 
similarity algorithm tree algorithm linear functional models terminal nodes 
noteworthy di erence objectives methods desired format solutions particular interpretability 
authors strongly argue compact easily interpretable rules example clark niblett quinlan weiss indurkhya cohen emphasize care accuracy predictive power 
particular case boolean neural networks method choice nd logic rules gray michel ott anthony 
nice review michalski compares decision tree learning method rule learning method aq neural net trained backpropagation algorithm classi er system genetic algorithm cfs respect predictive accuracy simplicity solutions 
multivariate adaptive regression splines mars friedman methodology intended binary predictors regression methodology automatically detect interactions smooth nonlinear spline transformed continuous predictors 
high amount adaptivity see section classi cation problems binary predictors problem mars designed produce quite reasonable results 
search best models number logic trees construct set predictors huge straightforward way enlist logic trees yield di erent predictions 
impossible carry exhaustive evaluation di erent logic trees 
simulated annealing stochastic search algorithm discussed section 
implemented greedy search algorithm example shown section 
rst introduce move set search algorithms 
moving search space de ne neighbors logic tree trees reached logic tree single move 
stress move counter move move potentially get back new tree old tree important underlying markov chain theory simulated annealing discussed 
allow moves alternating leaf pick leaf replace leaf position 
example leaf initial tree replaced leaf avoid tautologies possible moves alternate leaf alternate operator grow branch initial tree prune branch split leaf delete leaf 
permissible moves tree growing process 
starting tree panel lower left moves illustrated panels 
previous gure index variable shown white letters black background denote conjugate variable 
sibling leaf leaf leaf replaced sibling complement sibling 
clear counter move alternating leaf changing replaced leaf back move alternating leaf 
changing operators replaced vice versa example operator root initial tree changed 
moves complement move counter move 
growing pruning knot leaf allow new branch grow 
done declaring sub tree starting knot right side branch new sub tree position left side branch leaf representing predictor 
side trees connected location knot 
example initial tree grew branch knot occupied panel 
counter move growing called pruning 
leaf trimmed existing tree sub tree starting sibling trimmed leaf shifted start parent trimmed leaf 
illustrated initial tree pruned 
splitting deleting leaf split creating sibling determining parent leaves 
example leaf initial tree split leaf new sibling 
counter move delete leaf pair siblings leaves illustrated deleted initial tree 
move set logic tree reached logic tree nite number moves referred irreducibility markov chain theory 
true example omits moves pruning growing 
sense moves absolutely necessary move set 
inclusion additional moves move set enhances performance search algorithm 
section discuss choose optimal model candidates 
simply consider maximum number trees xed 
note model maximum trees allowed permissible move add tree single leaf 
vice versa model tree single leaf permissible move delete tree model 
greedy search similar search algorithm cart breiman greedy algorithm search logic models 
context logic regression rst step nd variable single predictor minimizes scoring function loss generalization lower scores better 
predictor neighbors states reached single move state investigated new state chosen state 
better score original state 
best score considered neighbors 
state exist greedy algorithm stops neighbors new state examined state chosen described criterion 
guarantee algorithm nds best scoring state possible 
happen search gets stuck example better tree reached moves move 
potential problem presence noise data happen tree representing correct underlying model reached search exist additional moves improve score nal model ts data 
contrast greedy search cart greedy move logic trees result tree lower equal complexity example deleting leaf changing operator respectively 
example shows parts outcome greedy search logic tree classi cation problem simulated data set 
data generated simulating binary predictors total cases value predictor independent sample bernoulli random variable probability underlying boolean equation chosen certain case boolean equation true response sampled bernoulli random variable probability sampled bernoulli random variable probability score greedy search chosen number misclassi ed cases proposed tree predicted wrong response 
best single predictor turned predictor having mis classi cation rate cases 
second step splitting rst leaf reducing mis classi cation rate 
steps correct tree visited lower left panel 
true mis classi cation rate example algorithm tree number misclassification rate 
sequence rst trees visited greedy search 
number upper right corner percentage mis classi ed observations simulated data cases respective tree predictor 
panel lower right shows mis classi cation rates solid squares true mis classi cation rates calculated model open squares 

possible moves tree improved score best splitting leaf resulted tree having fewer mis classi cations tree representing true boolean expression 
greedy algorithm took steps displayed trees stopped yielding low mis classi cation rate 
misclassi cation rates displayed lower right panel solid squares 
true mis classi cation rates respective trees calculated model displayed panel open squares 
tree number represents true underlying boolean expression true mis classi cation rate decreasing tree number greedy search 
trees noise true mis classi cation rate increases expected 
emphasizes need statistical tools model selection real life problems truth unknown subject search 
emphasis model selection simulated annealing discussed section 
developed randomization tests similar described section simulated annealing greedy search 
see details tests 
example possible correct tree visited 
happen search gets stuck shown incorrect variable gets chosen 
happens frequently particularly predictors correlated 
show generated data set exactly time substituted variable model surrogate case chose bernoulli random variable probability true bernoulli probability 
outcome search displayed 
second step variable selected remains model 
true mis classi cation rate takes big dip step resulting tree basically surrogate better tree tree leaves 
tree number misclassification rate 
sequence rst trees visited greedy search data predictors independent 
number upper right corner percentage mis classi ed observations simulated data cases respective tree predictor 
panel lower right shows mis classi cation rates solid squares true mis classi cation rates calculated correct model open squares 
search simulated annealing simulated annealing algorithm statistical properties discussed numerous publications books otten van van laarhoven aarts 
brie outline basics simulated annealing describe nd scoring logic models 
annealing algorithm de ned state space collection individual states 
states represents con guration problem investigation 
states related neighborhood system set neighbor pairs de nes substructure elements called moves 
states called adjacent reached single move 

similarly said connected set moves 
applications state space nite 
basic idea annealing algorithm certain state pick move selection scheme set permissible moves leads new state 
compare scores old new state 
score new state better score old state accept move 
score new state better score old state accept move certain probability 
acceptance probability depends score states consideration parameter re ects point time annealing chain parameter usually referred temperature 
pair scores ahead annealing scheme lower acceptance probability proposed state score worse score old state 
algorithm generally leads scoring states see otten van van laarhoven aarts 
various options implement annealing algorithm logic models 
trees model simultaneously 
requires computational reasons maximum number trees chosen arbitrarily large hardware permitting conservative choice priori idea trees maximally want larger necessary model trimmed needed 
section discussed detail 
assume known xed 
usually select tree current logic model randomly pick pre determined distribution move move set tree 
re parameters new model determine score compare score previous state logic model described 
details simulated annealing general implementation particular appendix fitting models binary data methods discussed section distinguished mechanism guides search nd solutions 
general scalability highest priority analyzing data nd boolean functions predictive power 
especially data mining problems fast ecient search algorithms crucial 
greedy type algorithms similiar discussed section standard give satisfactory results murthy salzberg 
years search methods gained popularity 
case logic regression greedy algorithms necessarily nd global optimum recognized alternatives considered computational expense prohibitive 
alternatives proposed genetic algorithms vafaie dejong bala dejong giordana saitta michalski simulated annealing sutton thermal training procedure somewhat similar simulated annealing frean 
statistics literature seen wealth alternatives straight greedy tree searches 
buntine proposed bayesian approach stochastic search tool classi cation trees chipman 
denison 
published bayesian algorithms cart trees 
approaches proposed em algorithm jordan bootstrapping techniques bagging breiman bumping tibshirani knight iterative reweighting schemes boosting freund schapire randomized decision trees amit geman dietterich 
comparisons methods example carried quinlan dietterich breiman 
alternative greedy searches patient rule induction method prim friedman fisher 
model selection simulated annealing gives chance nd model best close best possible score 
presence noise data know model ts data 
section introduce model selection tools simulated annealing search algorithm 
similar tools greedy search discussed 
total number leaves logic trees involved model measure model complexity call model size 
di erent measures certainly possible easily implemented discussed 
rst part section describes ensure nd best models size necessary certain types model selection 
parts section describe model selection techniques case studies 
examples model selection techniques section 
potential alternative method model selection penalize score function size model spirit aic bic gcv 
di erence models traditional set ups measures logic regression complicated models necessarily parameters 
plan investigate measures 
models fixed size certain situations interest know best scoring tree best model certain size 
example case cross validation determine best model size see 
simulated annealing run carried move set described section tree model size changes constantly guarantee nal model desired size 
determine best model xed size prohibit moves increase tree desired size reached 
words carry simulated annealing suggest branching tree splitting leaf tree desired size 
strictly speaking guarantees nd best desired size 
smaller tree sizes desirable general problem 
reality maximum desired tree size reached provided size large 
alternative approach alter move set discussed section include moves keep size model unchanged requires de nition new moves 
experience altered move set approach computationally considerably ecient programmer complicates code considerably computer simulated annealing algorithm converges slower approach described 
training test set cross validation training test set cross validation approach determine size logic tree model best predictive capability 
sucient data available training set test set approach 
randomly assign cases groups pre determined sizes part data training set part test set 
entire data model tting model evaluation process described models xed size training set pick model size scoring models independent test set 
sucient data independent test set available cross validation 
assume want assess best model size performs comparison models di erent sizes 
split cases data set approximately equally sized groups 
groups cases say group proceed follows remove cases group data 
find best scoring model size described section data remaining groups score cases group model 
yields score ki cross validated test score model size ki compare cross validated scores models various sizes 
randomization implemented types randomization tests 
rst referred null model test test signal data 
second test generalization test test model size determine optimal model size 
section introduce ideas tests 
null model test test signal data model class consider methodology linear regression logistic regression rst nd best scoring model data 
null hypothesis want test association predictors response 
hypothesis true best model data response randomly indicated binary yield score best model original data binary general chosen binary solely illustrate randomization technique 
repeat procedure desired claim proportion scores better score best model original data exact value indicating evidence null hypothesis 
perm permutation 
setup null model randomization test shown binary response test randomly permute entire response 
test detect optimal model size described test showed existence signal data want determine model describes association predictors response best 
assume best scoring model score size nd best scoring models sizes nd model size optimal carry sequence randomization tests 
null hypothesis test optimal model size better score obtained models larger sizes due noise kg 
assume null hypothesis true optimal model size score condition model considering tted values logic model 
model trees tted classes 
shows setup models trees 
randomly permute response classes 
exact model size considered best scores note models size potentially perm permutation permutation permutation permutation 
setup sequential randomization test test permute response group cases tted values existing trees 
score better 
nd best model size randomized data 
model score usually better null hypothesis true model size optimal sample distribution estimate distribution closely desired repeating procedure times 
hand optimal model size larger randomization yield average worse scores carry sequence randomization tests starting test null model exactly test signal data described previous subsection 
condition best model size generate randomization scores 
condition best model size 
general model selection best carried comparing successive histograms randomization scores need automatic rule pick smallest model size fraction randomization scores scores better typically choose larger want exclude possibly useful association 
approaches model selection models binary data model selection di ers greatly methods discussed section 
especially early works boolean functions assumed noise data authors minimal complete consistent rules simplest boolean functions perfectly classify examples example michalski quinlan hong 
real life examples noise assumption usually hold methods result tting 
account variety algorithms proposed 
simply modi cations previously mentioned algorithms 
example clark niblett pointed id easily modi ed showed extensions exist circumvent noise assumption zhang michalski proposed method called sg trunc implemented aq released version aq 
cross validation commonly model selection example quinlan gama 
pruning techniques minimum description length principle sliq mehta agrawal rissanen cost complexity consideration example cart breiman 
pruning techniques comparison mehta rissanen agrawal 
examples simulation study discussed section exist algorithms elds machine learning computer science statistics model binary data 
statistics literature best known adaptive algorithms cart breiman especially useful modeling binary predictor data mars friedman designed continuous predictors applied binary data 
type models considered approaches di erent hard come example logic regression outperforms mars cart vice versa 
intent simulation study section show logic regression better sense cart mars provide example shows exist situations underlying model particularly complicated logic regression outperforms cart mars 
coming reverse examples straightforward 
simulation considers example especially dicult cart 
designed way cart tends choose wrong initial split easily recover 
true model fairly simple logic regression rule 
exists cart tree equivalent logic regression rule model cart produce tree practice 
mars better study cart logic regression 
generated data sets cases binary predictors 
predictors independent bernoulli distribution 

predictor equal probability bernoulli random variable note simulation 
data sets generated response classi cation response linear regression 
classi cation response case sampled bernoulli distribution true bernoulli distribution 
regression case model chosen 
classi cation regression picked best logic model data sets separately cross validation randomization procedure 
best model cart chosen minimizing fold cross validation estimates prediction error 
mars models chosen minimize gcv score penalty 
mars models restricted fourth order interactions maximum model size terms 
results shown tables 
plus program tree run cart version mars written tibshirani hastie available www stats ox ac uk pub 
classi cation mars tted regression model binary response thresholded tted values 
smallest model logic regression model size smallest cart model shown terminal nodes smallest mars model terms 
classi cation problem mars produce correct tted values model 
table refer number terminal nodes cart models number terms mars model model size 
logic regression model selection randomization yields models similar size cross validation 
automated procedure described section cut 
visually examined plots section table 
results classi cation part simulation study 
results averages runs 
logic regression true model terms cart needs terms mars needs terms 
error rate calculated di erences true signal predictions classi er method truth logic cart mars selection cv random 
cv gcv true model size tted model size number predictors number predictors number predictors fraction times error rate relative truth table 
results regression part simulation study 
results averages runs 
note logic regression true model terms cart needs terms mars needs terms 
root mean squared error calculated squared di erences true signal predictions tted model method truth logic cart mars selection cv random 
cv gcv true model size tted model size number predictors number predictors number predictors fraction times root mean squared error relative truth selected di erent models automated procedure ended results randomization procedure better cross validation 
cart selects larger models includes wrong predictors 
general predictor classi cation mars substitutes correct predictors mars correct predictors selected model model usually larger smallest model needed leading interpretable results 
regression part simulation study methods perform better signal stronger 
logic regression approaches get correct model time cart mars picks correct predictors times usually complicated model 
regression part simulation study cart ends models considerably terminal nodes needed 
table provide error rate tted model relative true model classi cation regression design points see table captions 
classi cation problem note logic regression yields error rates mars cart error rates respectively 
compared noise added truth 
regression problem logic regression approaches nd correct model random variation estimates coecients root mean squared error rmse relative truth exactly 
regression problem mars better cart 
rmse approaches compared noise standard deviation 
cardiovascular health study cardiovascular health study chs study coronary heart disease stroke elderly people fried 
subjects age recruited communities united states 
increase minority representation study additional african americans recruited 
subset patients agreed undergo mri scan 
blinded identity characteristics patients read images attempted identify presence locations de ned area brain tissue damaged lack oxygen due compromised blood ow 
chs participants mri detected strokes bigger mm recorded entries region atlas brain 
identi ed subject locations single detectable regions 
patient recorded binary variables absent regions 
table list regions chs atlas number patients regions 
details scanning procedure see bryan 

goals mri sub study chs assess associations stroke locations various response variables resulting mini mental state examination screening test dementia 
patients participate question answer session score points correct answer 
nal score sum points earned number correct answer correct 
details test see teng chui 
analysis focused demonstrating logic regression methodology 
practice subset predictors included analysis example spatial correlations predictors 
clustering approach mcclelland reported improvements adjusting gender age variables available started analyzing data include model 
discusses approaches include continuous predictors logic regression models 
see example snp data section included continuous predictors additional variables 
patients scored mini mental test logarithmic transformation bene cial investigating potential model violations non normally distributed skewed residuals 
mini mental score number de ned response variable log mini mental score usually transformation avoided parameter interpretation association original mini mental score dicult methodology deal small number classes patients see analysis importance tted values associated mini mental score simply listed causing confusion 
models investigated linear models form fl trueg 
flp trueg table 
regions cardiovascular health study brain atlas 
predictor number display logic trees describe linear models counts number chs patients diagnosed 
letters rst column indicate standard anatomical clusters locations 
cerebral cortex cluster cerebellar cortex cluster cerebellar white matter cluster basal ganglia cluster brain stem cluster cerebral white matter cluster 
cluster predictor region counts anterior cerebral artery frontal lobe anterior cerebral artery parietal lobe middle cerebral artery frontal lobe middle cerebral artery parietal lobe middle cerebral artery temporal lobe posterior cerebral artery parietal lobe posterior cerebral artery temporal lobe posterior cerebral artery occipital lobe superior cerebellar artery anterior inferior cerebellar artery posterior inferior cerebellar artery cerebellar white matter nuclei internal capsule anterior limb internal capsule posterior limb thalamus watershed aca mca watershed mca pca cerebral white matter various numbers boolean expressions 
models de ne groups patients similar stroke patterns brain atlas group di erent average scores groups 
analysis residual variance residual sums squares divided number cases considered scoring function 
rst carried null model randomization test described section tting tree allowing leaves tree 
null model tting intercept score 
simulated annealing best scoring model score 
permuted response re model recorded score repeated procedure times 
compare score best scoring model score null model histogram scores obtained randomization procedure 
randomization scores considerably worse score conclude information predictors discriminatory power transformed mini mental score 
results got models tree similar 
get better idea ect varying model sizes show training scores averages training scores fold cross validation linear models trees varying tree sizes combined 
model class models trees leaves class models trees leaves 
model score deviance lowest scoring model deviance null model 
residual variance scores null model randomization test 
scores histogram came linear models single tree allowing leaves 
number leafs training score 
training cross validation scores best linear models various numbers leaves trees 
number trees allowed linear model indicated white number super imposed black squares 
class models trees leaves class models trees leaves 
results expected comparing models number trees allowed model involving leaves better training score 
trees allow model better score xed number leaves 
allowing second tree linear models larger ect training scores relative models tree ect allowing third tree addition trees 
larger models imply better cross validation test scores shown 
number leafs cross validated score 
cross validation test scores linear models various numbers leaves trees 
number trees allowed linear model indicated white number superimposed black squares 
cross validated scores models identical number leaves di erent numbers trees look remarkably similar 
regardless allow trees models size favored 
allowing tree obviously bene cial respect cross validation error pick simplicity model tree leaves 
keep mind model trees involves estimating parameters 
model trees number leaves model tree complex 
compare cross validated training test scores scores complete data 
model sizes scores obtained complete data scores obtained cross validation training data 
indicates predictors selected models cross validation training data compared sized models tted complete data 
expected scores cross validation test data worse training scores 
test score model leaves remarkably close training scores indicating predictors selected models size cross validation training data 
vast gap training test scores models size strongly discourages selection models 
shows histograms randomization scores conditioning various numbers leaves indicated number upper left corner panel 
averages randomization scores decrease increase model size condition condition model leaves 
best score models tree indicated left vertical bar gure looks sample distribution estimated randomization scores conditioning leaves supporting choice leaves selected model 
model leaves selected automated rule described section 
searching best linear model single tree size complete data yielded fl trueg number leafs score complete data training cv data test cv data 
comparison scores obtained model tting complete data open squares scores obtained cross validation training sets black triangles test sets black squares allowing tree models 
table 
summary regular regression model compares logic regression model mini mental score data 
value intercept region region region region logic tree shown 
comparison modeling approaches patients region patients region patients region patients region 
occurred di erent patients predictors pairwise exclusive 
boolean expression operators model similar linear regression model predictors main ects summarized table 
linear regression model backwards stepwise regression 
initial model contained predictors interactions 
note parameter estimate logic model con dence region region parameter linear regression model 
linear model looks similar model logic model clearly simpler interpretation logic regression methodology classes patients di er health history performance mini mental test 
tted 
residual variance scores randomization test model selection 
randomization scores obtained conditioning leaves indicated number upper left corner panel 
solid bar right panels indicates score null model solid bar left indicates best score original non randomized data 
dashed bar panel indicates best score models tree respective size original non randomized data 
values model state estimated median transformed mini mental score patients region compared patients regions 
translates median mini mental score patients region compared median mini mental score patients regions 
residual error exactly models 
standard linear regression model binary predictors de nes possible classes patient 
patient strokes regions 
classes empty 
signi cant di erence performance mini mental test patients strokes regions 
signi cant additive ect patients strokes regions perform worse people stroke regions 
logic model simpler appropriate 

logic tree selected model equation representing boolean equation mars model similar linear regression model 
chosen minimize gcv score penalty equal 
maximum number terms model building set interactions degree permitted 
model search yielded additional term compared linear regression model concerns patients stroke regions patients applies 
patients performed poorly mini mental state examination 
term certainly search space logic model show logic model selected cross validation randomization applied patients 
score residual error mars model identical previously discussed models 
cart returned model variables linear logic model shown 
variables zero patient stroke regions small value predicted 
fact simple analysis variance test show signi cant di erence group means bundles obtains logic model 
model displayed fairly simple cart tree feel logic model easier interpret 
application snp data section brie describe application logic regression algorithm genetic snp data 
application described detail leblanc hsu 
single base pair di erences single nucleotide polymorphisms snps form natural sequence variation common genomes estimated occur bases average 
snps coding region lead amino acid substitutions impact function encoded protein 
understanding snps relate disease outcome helps understand genetic contribution disease 
diseases interactions snps thought particularly important see quote ott 
typically particular snp possible nucleotides occur cell contains pair think snp random variable values example corresponding nucleotide pairs aa ta tt respectively 
re code variable corresponding dominant gene recessive gene 
way generate 
cart tree mini mental score data 
binary predictors snps 
logic regression algorithm suited relate binary predictors disease outcome 
part th genetic analysis workshop workshop organizers provided simulated genetic data set 
data simulated model common disease 
total independent data sets generated consisting pedigrees individuals alive 
variables reported living subject included ection status age onset ected gender age exam sequence data genes quantitative traits environmental variables 
randomly picked data sets training set randomly chosen data set test set 
sequence data total sites mutations distributed genes 
coded binary variables 
remainder identify sites coding variables follows gi sj refers site gene dominant coding gi sj variant allele exist 
similarly gi sj refers site gene recessive coding gi sj variant alleles exist 
identify complements superscript gi sj primary response variables ected status 
tted logistic regression model form logit ected environ environ gender gender coded female male environ environmental factors provided logic expressions predictors created sequence data 
initially models allowing logic expressions size training data 
show deviance various tted logic regression models 
larger models data validated models computing tted deviance independent test set 
test set results shown 
di erence solid lines dotted lines gure shows amount adaptivity logic regression algorithm 
gure see models logic trees combined total leaves lowest test set deviance 
goal investigation identify sites possibly linked outcome preferred larger models 
addition repeated experiment training set replicates test set replicates model leaves slightly lower test set deviance model leaves results shown 
carried randomization test con rmed model leaves tted data better model leaves 
trees model leaves tted single replicate 
logistic regression model corresponding logic regression model logit ected environ environ gender second environment variable model statistically signi cant 
number terms score 
training solid test open set logic regression models ected state 
number boxes indicate number logic trees 
data simulated data correct solution logic regression model 
solution look selected model showed ect genes ect gene site ect gene site ect gene various sites gene 
addition model showed interaction genes ect gene additive di erent scale logit scale 
subjects sequence data replicate site gene exactly opposite site indicated correct site solutions example person variant alleles site variant alleles site copy data 
similarly logic regression algorithm identi ed site gene identical persons site site indicated solutions 
note correct site gene appears twice logic tree model 
recessive coding 
fitted logic regression model ected state data trees leaves 
variables printed white black background complement indicated 
ectively dominant coding replicate site suggesting true model may additive 
remaining leaves model part gene site close ends gene site center 
sites gene dominant 
summary logic regression model identi ed sites related ected status correct interaction genes identi ed false positives 
described logic regression approach di erent approaches identi ed correct sites false positive snps 
discussion logic regression tool detect interactions binary predictors associated response variable 
strength logic regression nd complicated interactions predictors may play important roles application areas genetics identifying prognostic factors medical data 
logic regression considers novel class models di erent established methodologies cart mars 
clearly depending application area situations method outperforms method 
see logic regression additional tool statistical modelers toolbox 
logic regression models restricted classi cation linear regression existing methodologies 
regression model considered long scoring function determined 
software logic regression implemented cox proportional hazards model partial likelihood score 
simple classi cation problems trivial implement example weighted number mis classi cations score 
complicated models need considered analyzing data family structure case genetic data 
family members genetically related share environment observations longer independent take dependencies account modeling covariance structure 
envision logic regression useful analyzing genetic data plan investigate scoring functions take dependence account 
class models consider logic regression large critical search algorithm 
believe simulated annealing algorithm ecient nding model standard greedy algorithms 
plan investigate markov chain monte carlo algorithms assess uncertainty selected models 
similarity simulated annealing mcmc computationally conceptually straightforward 
case adaptive regression methodologies straightforward application logic regression algorithm data 
overcome discussed variety model selection techniques select best logic regression model 
point techniques computationally fairly expensive running time nding best model best model particular size mini mental data took minute current generation linux machine fold cross validation investigated models di erent sizes randomization tests took hours 
techniques computationally intense feasible 
includes example likelihood penalized size model score require run search algorithm 
similar quantities aic bic gcv adaptive regression methodologies 
discuss approach wanted restrict length 
logic regression software available bear org logic 
algorithm includes option search models conjunctive disjunctive boolean expressions 
achieved straightforward manner altering move set allow type operator 
versions include approaches include continuous predictors logic regression models 
relationship logic trees decision trees cart boolean expressions disjunctive normal form disjunctive normal form dnf widespread type notation logic statements engineering computer science literature 
dnf boolean expression written combinations terms 
example boolean expression written disjunctive normal form shown boolean expressions logic trees logic constructs boolean expressions dnf equivalent sense classes logic expressions represent 
means example boolean expression represented dnf logic tree 
logic trees introduced may appear resemble classi cation trees breiman 
classi cation tree leaf reached path tree making decisions knot 
tree binary decisions reduce checking condition investigated particular knot true false 
reach certain leaf conditions path satis ed 
true 
general multiple paths reach leaf predicts class 
outcome classes collection paths reach leaf predicting complete description binary classi cation tree 
tree predicts class boolean equation 
true 
binary classi cation tree immediately written boolean equation dnf 
example tree predicts class boolean equation true 
binary classi cation tree 
logic tree 

equivalence trees binary classi cation tree logic tree predict exactly outcome set values obvious boolean expression dnf directly expressed classi cation tree 
reason classi cation tree rst knot part path 
de morgan rules standard boolean operations shown classi cation tree constructed boolean expression 
classi cation trees result awkward looking constructs complex simple logic trees constructed boolean expression 
example tree means classi cation tree corresponds simple boolean expression displayed simple logic tree done incidentally dnf 
feel simplicity logic trees big attractions 
practical aspects simulated annealing simulated annealing addition previously described scoring functions move set specify selection probability moves acceptance function cooling scheme 
implemented simulated annealing algorithm logic regression methodology practical aspects considered run search 
section list believe important issues 
stage algorithm temperature see section 
suppose current state algorithm score old new proposed state score new smaller scores better 
new state accepted probability min exp old new note markov chain monte carlo metropolis hastings seen simulated annealing algorithm remains constant 
see otten van van laarhoven aarts discussion acceptance probability 
general selection probability moves ects performance annealing algorithm 
logic regression bene cial give highest preference moves alternate leafs 
alternating operators change prediction logic tree consideration considerably usually assign moves somewhat lower probability 
fundamentally di erent ways implement simulated annealing algorithm 
way slightly decrease temperature step algorithm 
way keep temperature constant certain number iterations decrease temperature somewhat larger amount 
performances algorithms studied otten van van laarhoven aarts general claim way running chain superior 
nd monitoring convergence process straightforward sequence homogeneous markov chains runs constant temperature 
simulated annealing run high temperatures virtually proposed moves accepted 
proposed move rejected 
crunch time want spend computing time 
speed simulated annealing avoid spending time run implemented features running markov chain xed temperature keep track moves accepted 
number reaches pre determined threshold exit markov chain number iterations speci ed reached lower temperature value 
avoids spending time run random models 
annealing algorithm able reach threshold markov chains run full lengths 
threshold typically pre speci ed number iterations chain xed temperature 
specify lowest temperature starting simulated annealing run 
criteria considered exit simulated annealing run early search virtually nished example case moves accepted substantial number consecutive chains 
avoids running algorithm way improvement achieved anymore 
allows setting lowest temperature arbitrarily low exit criteria chosen independently lowest temperature considered 
implement simulated annealing run specify temperature scheme 
means choose starting highest temperature nishing lowest temperature cooling scheme determines total number chains run constant temperatures 
making decision usually trial error involved practice cooling scheme depends data analyzing 
theory simulated annealing thoroughly discussed example books van laarhoven aarts otten van stating conditions simulated annealing run guarantee nd optimal scoring state 
obvious problem run chains length nity required optimal state may reached practice 
need sure individual chains run come close limiting distributions cool suciently slowly achieved reasonable number iterations chain 
choices parameters pick uence 
explained picking highest lowest temperature problem 
want starting temperature high rst chains essentially random walks controlled monitoring acceptance rate 
lowest temperature chosen described exit criterion terminates chain 
depending size data set usually choose exit criterion number chains acceptance 
temperatures usually lowered equal increments log scale 
number chains subsequent powers depend data usually number 
translates decreasing temperature homogeneous chains factor ca 

lengths individual chains data looked far 
search single best model usually takes minutes pentium processor randomization tests depending number permutations carried usually require hours cpu time 
logic tree nite number neighbors 
especially run low temperatures moves get accepted 
simulated annealing probabilistic search move get rejected times accepted 
worst bottle neck terms computing time evaluation logic trees deriving values underlying boolean equation leaves case 
acceptance move temperature score current model depends score proposed model implemented subroutine keeps track states visited scores table 
decision accept certain move state trees proposed model evaluated speeds search dramatically lower temperatures 
move accepted old table ushed new table generated 
theory trees size grown considering applications want able interpret models sense limit tree sizes reasonable number leaves 
usually limit number leaves maximum tree 
previously noted limit number trees allow 
case studies carried optimal logic regression models typically logic trees 
usually allow trees search models 
acknowledgments richard mcclelland providing data section permission data manuscript 
organizers permission data 
ingo charles supported part nih ca 
michael leblanc supported nih ca 
authors supported part nih ca 
workshop supported nih gm 
amit geman 
shape quantization recognition randomized trees neural computation 
anthony 
discrete mathematics neural networks selected topics siam monographs discrete mathematics applications 
apte damerau weiss 
language independent automated learning text categorisation models research development information retrieval 
apte weiss 
data mining decision trees decision rules generation computer systems 
bala dejong 
learning noise tolerant classi cation procedures integrating inductive learning genetic algorithms proceedings international workshop multistrategy learning msl 
bayardo jr agrawal 
mining interesting rules knowledge discovery data mining 
breiman friedman olshen stone 
classi cation regression trees belmont ca wadsworth 
breiman 
bagging predictors machine learning 
breiman 
random forests random features technical report department statistics university california berkeley 
bryan elster 
method evaluate ects cardiovascular disease brain cardiovascular health study 
buntine 
learning classi cation trees statistics computing 
chipman george mcculloch 
bayesian cart model search discussion journal american statistical association 
chipman george mcculloch 
bayesian models machine learning 
clark niblett 
cn induction algorithm machine learning 
cohen 
fast ective rule induction international conference machine learning 
cohen singer 
simple fast ective rule learner proceedings annual conference american association arti cial intelligence 
daly scha ner hudson lander 
high resolution haplotype structure human genome nature genetics 
denison mallick smith 
bayesian cart algorithm biometrika 
deshpande 
greedy randomized adaptive search procedure math 
computer modelling 
dietterich experimental comparison methods constructing ensembles decision trees bagging boosting randomization machine learning 
domingos 
linear time rule induction knowledge discovery data mining 

exclusive representations boolean functions ibm journal research development 
martin phoenix 
simulated annealing tool logic optimization cad environment proc 
int 
conf 
computeraided design 
frean 
small nets short paths optimising neural computation phd thesis university edinburgh center cognitive science 
freund schapire experiments new boosting algorithm proceedings th international conference machine learning 
fried newman leary tracy weiler 
cardiovascular health study design rationale annals epidemiology 
friedman 
multivariate adaptive regression splines discussion annals statistics 
friedman fisher 
bump hunting high dimensional data statistics computing 
giordana saitta 
integrated system learning relations genetic algorithms proceedings second international workshop multistrategy learning msl 
gray michel 
training algorithm binary feedforward neural networks ieee transactions neural networks 
hong cain 
mini heuristic approach logic minimization ibm journal research development 
hong 
mini iterative approach generating minimal rules examples ieee transactions knowledge data engineering 
jordan jacobs 
hierarchical mixtures experts em algorithm neural computation 
leblanc hsu 
sequence analysis logic regression genetic epidemiology supplement 
liu hsu ma 
integrating classi cation association rule mining proceedings international conf knowledge discovery data mining 
ott 
neural network analysis complex traits genetic epidemiology 

simulated annealing construction near optimal decision trees selecting models data ai statistics iv springer new york 
mcclelland 
regression variable clustering data reduction phd thesis university washington department biostatistics 
mehta rissanen agrawal 
mdl decision tree pruning proceedings international conference knowledge discovery data mining kdd 
mehta agrawal rissanen 
sliq fast scalable classi er data mining extending database technology 

extending naive bayes classi ers long itemsets knowledge discovery data mining 
michalski hong lavrac 
multi purpose incremental learning system aq testing application medical domains proceedings aaai 
murthy salzberg 
decision tree induction ective greedy heuristic knowledge discovery data mining 
otten 
annealing algorithm boston kluwer academic publishers 
quinlan 
induction decision trees machine learning 
quinlan 
learning continuous classes th australian joint conference arti cial intelligence 
quinlan 
programs machine learning san mateo ca morgan kaufmann 
quinlan 
bagging boosting proceedings aaai national conference arti cial intelligence 

logic regression statistical issues related protein folding problem phd thesis university washington department statistics 
sutton 
improving classi cation trees simulated annealing proceedings rd symposium interface 
ed interface foundation north america 
teng chui 
modi ed mini mental state ms examination journal clinical psychiatry 

neural networks construction method boolean logic ieee international conference tools arti cial intelligence 
tibshirani knight 
model search inference bootstrap bumping journal computational graphical statistics 

data fitting rule regression proceedings nd international workshop arti cial intelligence techniques ait brazdil 
eds brno czech republic 
gama 
regression classi cation brazilian symposium arti cial intelligence 
vafaie dejong 
improving performance rule induction system genetic algorithms proceedings international workshop multistrategy learning msl 
van laarhoven aarts 
simulated annealing theory applications boston kluwer academic publishers 
webb 
ecient search association rules proceedings sixth international conference knowledge discovery data mining kdd 
webb 
discovering associations numeric variables proceedings seventh international conference knowledge discovery data mining kdd 
weiss indurkhya 
optimized rule induction ieee expert december 
weiss indurkhya 
rule regression proceedings th international joint conference arti cial intelligence ijcai 
weiss indurkhya 
rule machine learning methods functional prediction journal arti cial intelligence research 
amos falk king martinez meyers neuman olson rich spence thomas 
analysis complex genetic traits applications simulated data 
genetic epidemiology supplement 

analysis sequence data population structure genetic epidemiology supplement 
michalski 
comparing symbolic subsymbolic learning studies machine learning multistrategy approach michalski tecuci 
eds morgan kaufmann 
zhang michalski 
rule optimization sg trunc method ewsl 

