diversity ensemble feature selection cunningham department computer science trinity college dublin ireland cs tcd cunningham cs tcd tel fax department computer science information systems university jyv skyl finland cs fi acknowledgments science foundation ireland financial support 
research partly supported graduate school university jyv skyl finland 
uci machine learning repository databases domain theories data generators data sets mlc library source code study 
diversity ensemble feature selection ensembles learnt models constitute main current directions machine learning data mining 
ensembles allow achieve higher accuracy achievable single models 
shown theoretically experimentally order ensemble effective consist high accuracy base classifiers high diversity predictions 
technique proved effective constructing ensemble accurate diverse base classifiers different feature subsets called ensemble feature selection 
ensemble feature selection strategies incorporate diversity component fitness function search best collection feature subsets 
known number ways quantify diversity ensembles classifiers little research done appropriateness ensemble feature selection 
compare measures diversity regard possible ensemble feature selection 
conduct experiments data sets uci machine learning repository comparing ensemble accuracy characteristics ensembles built ensemble feature selection considered measures diversity 
consider search strategies ensemble feature selection simple random subsampling genetic search hill climbing ensemble forward backward sequential selection 
experiments show cases ensemble feature selection process sensitive choice diversity measure question superiority particular measure depends context diversity data processed 
keywords ensemble classifiers ensemble diversity feature selection search strategy dynamic integration classifiers current electronic data repositories growing quickly contain huge amount data commercial scientific domain areas 
data includes currently unknown potentially interesting patterns relations uncovered knowledge discovery data mining methods 
popular method creating accurate classifier set training data train different classifiers combine predictions 
integration multiple classifiers improve classification results currently active research area machine learning neural networks communities 
dietterich integration multiple classifiers important directions machine learning research 
shown domains ensemble accurate single classifiers ensemble 
theoretical empirical research demonstrated ensemble base classifiers ensemble accurate tend err different parts instance space high diversity predictions 
important issue creating effective ensemble choice function combining predictions base classifiers 
shown increasing coverage ensemble diversity ensure increased prediction accuracy integration method utilize coverage benefit arises integrating multiple models 
effective approach generating ensemble accurate diverse base classifiers different feature subsets called ensemble feature selection :10.1.1.44.7302
varying feature subsets generate base classifiers possible promote diversity produce base classifiers tend err different subareas instance space 
traditional feature selection algorithms goal finding best feature subset relevant learning task selected inductive learning algorithm task ensemble feature selection additional goal finding set feature subsets promote disagreement base classifiers :10.1.1.44.7302
ho shown simple random selection feature subsets may effective technique ensemble feature selection lack accuracy ensemble members compensated diversity 
random base number ensemble feature selection strategies gefs hc :10.1.1.44.7302
feature selection algorithms including ensemble feature selection typically composed components search strategy searches space feature subsets fitness function inputs feature subset outputs numeric evaluation :10.1.1.44.7302:10.1.1.17.626
search strategy goal find feature subset maximizing function 
acknowledged effective ensemble consist high accuracy classifiers disagree predictions fitness functions ensemble feature selection include explicitly implicitly accuracy diversity 
measure fitness proposed opitz defines fitness classifier corresponding feature subset proportional classification accuracy diversity classifier fact contribution classifier total ensemble diversity measured average pairwise diversity pairs classifiers including coefficient degree influence diversity :10.1.1.44.7302
fitness function experiments experiments 
common measure classification accuracy percentage correct classifications test data set average class accuracy average percentage correct classifications class class distributions significantly uneven 
simple percentage correct classifications measure successfully vast majority cases reflects classification performance 
diversity situation straightforward known number ways measure diversity ensembles classifiers research done appropriateness superiority measure 
consider different measures ensemble diversity component fitness function measure total ensemble diversity general characteristic ensemble goodness 
goal compare considered measures diversity context ensemble feature selection particular tasks 
knowledge existent research papers comparing different measures ensemble diversity common way comparison analyze correlation measures diversity different ensemble characteristic ensemble accuracy difference ensemble accuracy average base classifier accuracy difference ensemble accuracy maximal base classifier accuracy contrast common way compare measures diversity wrapper approach applying component fitness function guiding search ensemble feature selection comparing resulting accuracies ensemble characteristics 
organized follows 
section consider general task constructing effective ensemble review different techniques generating base classifiers especially ensemble feature selection strategies ensemble feature selection 
section consider question integration ensemble classifiers review different integration methods 
section different measures diversity classification ensembles 
section experiments measures conclude section summary research topics 
ensemble diversity section consider question constitutes ensemble effective techniques generating base classifiers ensembles place ensemble feature selection search strategies ensemble feature selection shall experiments 
ensemble goodness criteria interrelation ensemble generally accurate base classifiers ensemble 
theoretical empirical research shown effective ensemble consist base classifiers high classification accuracy errors different parts input space :10.1.1.131.1931:10.1.1.37.8876
brodley lane show main objective generating base classifiers maximize coverage data percentage instances base classifier classify correctly 
achieving coverage greater accuracy best base classifier requires diversity base classifiers 
researchers theoretical evidence supporting claim :10.1.1.37.8876
example hansen salamon proved average classification error rate instance base classifiers ensemble independent production errors expected error instance reduced zero number base classifiers included ensemble goes infinity majority voting integration 
assumptions rarely hold practice example outlier may easily predicted classification error rate higher classification error rate instances necessarily reduced zero 
assume significant percentage instances predicted average error gains generalization achieved 
key assumption analysis base classifiers independent production errors 
krogh vedelsby shown classification error ensemble neural network base predictors related generalization error base networks disagreement 
proved ensemble generalization error average generalization errors base networks weighted corresponding beliefs ensemble ambiguity measured weighted average squared differences predictions base networks ensemble 
ambiguity way measure disagreement common disagreement numeric predictors neural networks measured 
similar dependency derived tumer ghosh classifiers predict posteriori probabilities output classes pi ensemble generalization error optimal bayesian error size ensemble pi prior probability class average correlation factor classifiers prediction posteriori probabilities class average error base classifier 
disagreement measured correlation predictions posteriori probabilities 
theoretical results hold true regression systems classifiers predict posteriori probabilities similar dependencies known common case classifiers crisp predictions focus 
number approaches quantify ensemble diversity case crisp classification consider section 
techniques generation base classifiers ensembles task ensemble models broken basic questions set learned models generated predictions learned models integrated 

generate set accurate diverse learned models approaches tried 
way generating diverse set models learning algorithms heterogeneous representations search biases decision trees neural networks instance learning approach models homogeneous representations differ method search data trained 
approach includes techniques generating base models learning base models different subsets training data 
example known ensemble methods type bagging boosting 
base models homogeneous representations may binary classifiers integrated implement multiclass learner number class labels greater 
classifier ensemble learnt distinguish class label 
example dietterich bakiri map class label bit string prior learning 
bit strings class labels designed separated serving error correcting output codes ecoc 
shelf system learning binary classifications build multiple classifiers bit output code 
instance classified predicting bit output code label classifying instance label closest matching output code 
natural process model search random weight setting backpropagation algorithm training neural networks build different models homogeneous representation 
injected artificially 
example randomised decision tree induction algorithm generates different decision trees time run purpose 
way building models homogeneous representations proved effective different subsets features model 
example base classifiers built different feature subsets feature subset includes features relevant distinguishing class label number base classifiers equal number classes 
finding set feature subsets constructing ensemble accurate diverse base models known ensemble feature selection :10.1.1.44.7302
combination techniques considered useful order provide desired characteristics generated models 
example combination boosting kind bagging technique considered webb 
addition general purpose methods generating diverse ensemble models learning algorithm specific techniques 
example opitz shavlik employ genetic algorithm backpropagation search population neural network classifiers 
ensemble feature selection focus section consider search strategies experiments 
search strategies ensemble feature selection section consider different search strategies ensemble feature selection hill climbing hc genetic algorithm ensemble feature selection ga ensemble forward sequential selection efss ensemble backward sequential selection ebss 
hill climbing search local search wrapper approach shown effective single feature subset selection 
hill climbing hc ensemble feature selection strategy research proposed composed major phases construction initial ensemble random iterative refinement ensemble members sequential mutation hill climbing 
initial feature subsets constructed random subspace method 
initial ensemble formed 
iterative refinement ensemble members improve accuracy diversity base classifiers 
iterative refinement hill climbing search 
feature subsets attempt switch include delete feature 
resulting feature subset produces better performance validation set fitness function returns better value change kept 
process continued improvements possible 
normally passes necessary 
genetic search important direction feature selection research 
genetic algorithms shown effective global optimization techniques feature subset selection 
genetic algorithms ensemble feature selection proposed :10.1.1.44.7302
genetic algorithm ensemble feature selection ga strategy begins hc creating initial population classifiers classifier generated randomly selecting different subset features :10.1.1.44.7302
new candidate classifiers continually produced genetic operators crossover mutation feature subsets 
producing certain number individuals process continues selecting new subset candidates selecting members randomly probability proportional fitness known roulette wheel selection 
process producing new classifiers selecting subset generation continues number times known number generations 
predefined number generations fittest individuals population comprises ensemble :10.1.1.44.7302
implementation representation individual feature subset simply constant length string bits bit corresponds particular feature 
crossover operator uses uniform crossover feature children takes randomly value parents 
feature subsets individuals current population chosen randomly probability proportional fitness 
mutation operator randomly toggles percentage bits individual 
efss ebss sequential feature selection strategies add delete features hill climbing procedure polynomial complexity 
frequently studied variants plain sequential feature selections algorithms select single feature subset forward backward sequential selection fss bss :10.1.1.17.626
fss begins zero attributes evaluates feature subsets exactly feature selects best performance 
adds subset feature yields best performance subsets larger size 
cycle repeats improvement obtained extending current subset 
bss begins features repeatedly removes feature removal yields maximal performance improvement :10.1.1.17.626
efss ebss iteratively apply fss bss form base classifiers predefined fitness function 
efss ebss polynomial complexity regard number features number base classifiers total number features number features included deleted average fss bss search 
hc similar polynomial complexity passes passes average number passes feature subsets hc improvement usually 
complexity gefs depend number features gen number individuals feature subsets generation gen number generations 
experiments average strategies looks feature subsets number base classifiers average number features average percentage included deleted features efss ebss number passes hc number individuals population ga number generations 
comparative experiments strategies collection data sets medical field acute abdominal pain classification considered :10.1.1.13.9571
best search strategy context efss best data set considered generating diverse ensembles compact base classifiers 
efss generated extremely compact base classifiers including features average features 
results genetic search disappointing improved generations 
comparison number changes genetic search strategy :10.1.1.13.9571
new version considered full feature sets allowed random may crossover operator produce full feature subset 
individuals crossover selected randomly proportional log fitness just fitness adds diversity new population 
generation children identical parents prohibited crossover operator child parents mutation operator applied 
provide better diversity length feature subsets population general different mutation operators adds features randomly probability deletes features 
operator applied exactly half individuals mutated 
pilot studies shown minor changes help significantly improve ga converge single generation local extremum :10.1.1.13.9571
parameter settings implementation genetic search ga include mutation rate proposed population size search length feature subsets offsprings current population classifiers generated crossover operator mutated offsprings :10.1.1.44.7302
generations individuals produced pilot studies shown cases configuration ensemble accuracy improve generations due overfitting training data 
techniques integration ensemble models brodley lane shown simply increasing coverage ensemble diversity insure increased prediction accuracy 
integration method utilize coverage benefit arises integrating multiple classifiers 
diversity coverage ensemble sufficient conditions ensemble accuracy 
important ensemble accuracy integration method utilize diversity base models 
challenging problem integration decide classifiers rely combine results produced base classifiers 
techniques basic approaches suggested solution integration problem combination approach base classifiers produce classifications final classification composed selection approach classifiers selected final classification result produced 
effective techniques combination classifiers proposed 
popular simplest techniques combine results base classifiers simple voting called majority voting select majority sam 
voting technique classification base classifier considered equally weighted vote particular classification 
classification receives biggest number votes selected final classification ties solved arbitrarily 
weighted voting vote receives weight usually proportional estimated generalization performance corresponding classifier 
weighted voting wv works usually better simple majority voting 
sophisticated combination techniques include method correspondence analysis nearest neighbor search correspondence analysis results techniques combine minimal nearest neighbor classifiers stacked generalization framework 
effective classifier combination techniques stacked generalization called arbiter combiner chan 
hierarchical classifier combination considered 
experimental results chan stolfo showed hierarchical multi level combination approach dataset distributed number sites able sustain level accuracy global classifier trained entire dataset 
number selection techniques proposed solve integration problem 
popular simplest selection techniques cross validation majority cvm call simply static selection ss experiments 
cvm cross validation accuracy base classifier estimated training set classifier highest accuracy selected ties solved voting 
sophisticated selection approaches include estimation local accuracy base classifiers considering errors instances similar predictions learning number meta level classifiers referees predict corresponding base classifiers correct new instances referee tree recognizes classes 
todorovski dzeroski trained meta level decision tree dynamically selected base model applied considered instance level confidence base models correctly classifying instance 
approaches classifier selection divided subsets static dynamic selection 
static approaches propose best method data space dynamic approaches take account new instance classified neighbourhood 
cvm example static approach selection techniques considered examples dynamic approach 
techniques combining classifiers static dynamic 
example widely weighted voting static approach 
weights base classifier vote depend instance classified 
contrast reliability weighted voting introduced dynamic voting approach 
uses classifier dependent estimation reliability predictions particular instance 
usually better results achieved classifier integration done dynamically account characteristics new instance 
consider experiments dynamic approaches local accuracy estimates dynamic selection ds dynamic voting dv dynamic voting selection dvs 
local accuracy estimates 
ds simply selects classifier predicted local classification error proposed 
dv base classifier receives weight proportional estimated local accuracy base classifier final classification produced combining votes classifier weights 
dvs base classifiers highest local classification errors discarded classifiers errors fall upper half error interval base classifiers locally weighted voting dv applied remaining base classifiers 
diversities number ways quantify ensemble diversity 
section consider different measures ensemble diversity pairwise able measure diversity predictions pair classifiers total ensemble diversity average classifier pairs ensemble plain disagreement fail non fail disagreement statistic correlation coefficient kappa statistic non pairwise measure diversity predictions ensemble entropy ambiguity 
experiments compare pairwise measures guiding diversity ensemble training process component fitness function consider correlation total average ensemble diversity measures difference ensemble accuracy average base classifier accuracy 
plain disagreement measure plain disagreement measure diversity probably commonly measure diversity ensembles classifiers crisp predictions 
example measuring diversity decision forests correlation forests accuracy 
component fitness function guiding process ensemble construction 
classifiers plain disagreement equal ratio number instances classifiers different predictions total number instances question div diff ci xk number instances data set ci class assigned classifier instance diff diff 
plain disagreement varies 
measure equal classifiers return classes instance equal predictions different 
fail non fail disagreement measure fail non fail disagreement defined percentage test instances classifiers different predictions correct div disi ab number instances data set classified correctly incorrectly classifier correctly incorrectly classifier denominator equal total number instances 
equal binary classification problems number classes 
shown div disi div instances contributing disagreement measure form subset instances contributing plain disagreement 
fail non fail disagreement varies 
measure equal classifiers return classes instance different incorrect classes equal predictions different correct 
statistic measure yule statistic assess similarity classifiers outputs div qi ab meaning 
statistically independent classifiers expected value 
varies 
classifiers tend recognize objects correctly positive values commit errors different objects render negative 
case undefined value division zero assume diversity minimal equal 
experiments diversity component fitness function normalize measure vary corresponds maximum diversity div div 
comparative experiments uci breast cancer wisconsin data set phoneme recognition cone torus data sets experiments emulated ensembles artificially generating possible cases base classifiers outputs recommended best measure purposes developing committees minimize error account experimental results simplicity comprehensibility ease interpretation 
experiments show question superiority particular measure depends context diversity data processed 
problem noticed measure pilot studies insensitivity small data sets 
quite case small number instances equal 
case equal maximal diversity matter big values reflection real diversity classifiers outputs 
correlation coefficient correlation outputs classifiers measured div ab meaning 
numerator classifiers div div qi sign proven div div qi 
normalize measure vary way 
measure fail non fail disagreement statistic considered group measures comparative experiments 
kappa degree agreement statistic nij number instances data set recognized class classifier class second ni number instances recognized classifier number instances recognized nii ni lv ri estimates probability classifiers agree lv iru estimates probability classifiers agree simply chance case classifier chooses assign class label randomly 
pairwise diversity div defined follows div kappa :10.1.1.131.1931
kappa equal agreement classifiers equals expected chance kappa equal classifiers agree example 
negative values occur agreement expected chance systematic disagreement classifiers :10.1.1.131.1931
kappa able track negative correlations similar manner correlation 
normalize measure vary way correlation 
dietterich measure scatter plots called error diagrams kappa plotted mean accuracy classifier pair :10.1.1.131.1931
error diagrams introduced useful tool visualising ensembles 
entropy non pairwise measure diversity associated conditional entropy error measure concept entropy div ent log number instances data set number base classifiers number classes number base classifiers assign instance class keep measure diversity range logarithm taken base measure evaluated medical prediction problem shown predict accuracy ensemble 
shown entropy measure diversity added advantage models change diversity size ensemble 
may useful measure diversity allow gauge contribution individual classifier diversity pairwise measure 
shall total measure diversity experiments correlation total ensemble diversity difference ensemble accuracy base classifier accuracy 
variance measure ambiguity non pairwise measure diversity associated variance measure diversity proposed regression problems called ambiguity 
diversity proven direct relation ensemble error motivated associated diversity measure classification 
classification task decomposed regression tasks number classes 
output regression tasks class membership instance binary output case crisp classification considered 
diversity classification ensemble calculated average ambiguity pseudo regression tasks instances ni div amb ln lns number classes number instances number base classifiers number base classifiers assign instance class ck class assigned classifier instance truth predicate 
entropy non pairwise measure shall experiments correlation total ensemble diversity difference ensemble accuracy base classifier accuracy 
experimental investigations section experiments measures diversity ensemble feature selection 
experimental setting described results experiments 
experiments conducted data sets taken uci machine learning repository 
data sets include real world synthetic problems vary characteristics previously investigated researchers 
main characteristics data sets table 
table includes name data set number instances included data set number different classes instances data set numbers different kinds features included instances data set 
data sets uci repository strongly criticized 
new experiments uci data sets run risk finding significant results statistical accidents 
believe uci data sets provide useful benchmark estimates great help experimental analysis comparisons learning methods results looked carefully final 
table 
data sets characteristics data set instances classes features categorical numerical balance breast cancer ljubljana car pima indians diabetes glass recognition heart disease ionosphere iris plants led led liver disorders lymphography monk monk monk soybean thyroid tic tac toe endgame vehicle voting zoo experimental setting experiments updated version setting test efs sbc algorithm ensemble feature selection simple bayesian classification 
extended efs sbc setting implementation new search strategies existing hc ga efss ebss section implementation new measures diversity existing plain disagreement fail non fail disagreement statistic correlation coefficient kappa statistic entropy ambiguity section 
simple bayesian classification base classifiers ensembles 
shown experimentally theoretically simple bayes optimal na feature independence assumption violated wide margin 
second simple bayes applied subproblems lower dimensionalities random error bias bayesian probability estimates caused feature independence assumption smaller 
easily handle missing feature values learning instance allowing feature values contribute 
advantages terms simplicity learning speed classification speed storage space possible conduct experiments reasonable time 
shown global contingency table needed ensemble simple bayes employed ensemble feature selection 
believe results depend significantly learning algorithm similar known learning algorithms 
estimate ensemble accuracy ensemble feature selection random sampling cross validation 
test runs efs sbc search strategy diversity measure data set 
test run data set split training set trs validation set vs test set ts stratified random sampling 
stratified random sampling called proportional random sampling simple random sample instances class taken class distributions instances resulting sets approximately initial data set 
shown sampling gives better accuracy estimates simple random sampling 
time percent instances assigned training set 
remaining percent instances data set divided sets approximately equal size vs ts 
validation set vs ensemble refinement estimate accuracy diversity guiding search process 
test set ts final estimation ensemble accuracy 
division data training validation test sets search strategy guiding diversity avoid unnecessary variance provide better comparison 
ensemble size selected 
shown ensembles biggest gain accuracy achieved number base classifiers 
experimented different values diversity coefficient 
run algorithm collect accuracies types integration base classifiers section static selection ss weighted voting wv dynamic selection ds dynamic voting dv dynamic voting selection dvs 
dynamic integration strategies ds dv dvs number nearest neighbors local accuracy estimates pre selected set values data set separately number instances training set permitted 
values chosen nearest neighbor procedure dynamic integration distance weighted 
distances test instance neighboring training instances computed calculate estimates local accuracies 
shown dynamic integration sensitive choice number neighbors local accuracy estimates sensitive small number neighbors 
heterogeneous euclidean overlap metric calculation distances 
dynamic integration fold cross validation building cross validation history estimation local accuracies base classifiers 
select best conducted separate series experiments wrapper approach combination search strategy guiding diversity integration method data set 
experiments repeated pre selected values test set classification accuracies base classifiers ensembles collected characteristics ensemble accuracies validation set measure overfitting total ensemble diversity measures section ensemble coverage average relative number features base classifiers 
ga strategy ensemble characteristics collected generations 
test environment implemented mlc framework machine learning library 
multiplicative factor laplace correction simple bayes 
numeric features discretized equal length intervals observed value whichever done 
approach slightly accurate sophisticated ones advantage simplicity sufficient comparing different ensembles simple bayesian classifiers global simple bayesian classifier 
sophisticated discretization approaches lead better classification accuracies base classifiers ensembles influence results comparison 
correlation total ensemble diversity difference ensemble accuracy average base classifier accuracy measured correlation total ensemble diversity difference ensemble accuracy average base classifier accuracy 
measure correlation commonly pearson linear correlation coefficient non parametric counterpart spearman rank correlation coefficient rcc 
rcc nonparametric distribution free rank statistic proposed spearman measure strength associations variables 
measure monotone association distribution data pearson correlation coefficient undesirable misleading 
kuncheva whitaker rcc similar experiments motivating choice fact relationships linear 
rcc difference ranks corresponding variables number observations rank xi rank yi rcc 
case equal corresponding different measures total ensemble diversity difference ensemble accuracy average base classifier accuracy cross validation runs data set 
measured correlations search strategies ebss efss ga hc simple random subsampling rs 
search strategies pairwise measures diversity considered section 
finding correlation depends greatly data set varying depend search strategy difference corresponding correlation coefficients data set continue analysis ensembles built random subsampling 
table pearson correlation coefficient quantifies correlation total ensemble diversity difference ensemble accuracy average base classifier accuracy ensembles built random subsampling 
diversity measures section considered corresponding different columns table plain disagreement div plain fail non fail disagreement div dis statistic div correlation coefficient div corr kappa statistic div kappa entropy div ent ambiguity div amb 
measured correlations integration methods dvs strongest dynamic integration methods weighted voting wv plain non weighted voting lines table 
cell corresponding measure diversity integration method contains values average maximal minimal values correlation coefficients calculated data sets 
table structure table presents spearman rank correlation coefficients rcc 
table 
pearson correlation coefficient total ensemble diversity difference ensemble accuracy average base classifier accuracy average maximal minimal values dvs wv voting div plain div dis div div corr div kappa div ent div amb table 
spearman rank correlation coefficient rcc total ensemble diversity difference ensemble accuracy average base classifier accuracy average maximal minimal values dvs wv rcc div plain div dis div div corr div kappa div ent div amb voting tables seen rcc coefficients uncover dependencies diversities context 
fact vast majority data sets difference rcc diversities data sets small negative correlations 
correlations change greatly data sets seen minimal maximal values 
naturally data sets ensembles little correlations low negative 
dvs integration method strongest integration method best correlations shown div plain div dis div ent div amb 
div kappa close best 
div div corr behave similar way reflects mentioned similarity formulae 
div surprisingly worst average correlation dvs 
correlation significantly decrease change integration method wv voting happens diversities 
div corr 
decrease correlations change integration method dvs wv wv voting explained fact dvs better utilizes ensemble diversity comparison wv shown example wv better utilizes ensemble diversity voting naturally correlation coefficients change 
fact div div corr decrease change integration method surprising probably explained different way calculation diversity needs research 
div dis best measure diversity average context 
div plain equal div amb difference 
possibly similarity proven theoretically 
div amb measure diversity classifiers output posteriori probability output classes needs research 
line maximal correlations corresponds soybean data set 
dependency perfectly linear data set diversities div div corr 
behaviour probably explained characteristics data set smallest data set including instances easy learn needs research 
comparison test set accuracy different strategies diversity metrics integration methods ensemble accuracy shown different search strategies including simple random rs pairwise measures diversity fitness function 
best integration method selected data set results averaged data sets 
ebss efss ga hc rs 
average test set accuracy different search strategies guiding diversities see ga best average hc strategy second best 
strategies random subsampling rs shows results data sets 
rs better efss diversities better equal ebss 
surprisingly best acute abdominal pain data sets efss significantly worse strategies collection data sets :10.1.1.13.9571
line results aha bankert show simple feature selection backward sequential selection better forward sequential selection forward selection able include groups correlated features high relevance separate features group :10.1.1.17.626
significant difference guiding diversities 
significant dependencies div significantly worse diversities ebss efss ga div kappa better diversities ga dependency expected goes line results tables 
second dependency div plain div dis div div corr div kappa unexpected explained probably peculiarities genetic search 
hc sensitive choice guiding diversity starts accurate ensemble rs search global ga div plain div dis div div corr div kappa gen 
average test set accuracy different numbers generations ga search strategy different guiding diversities average ensemble accuracy shown ga strategy guiding diversities generations 
see ensembles diversities show improvement search progresses number generations 
ensembles built div div corr degenerate ensembles improve average accuracy improvement starts tail 
corresponds results tables measures diversity shown worst average correlation difference ensemble accuracy average base classifier accuracy dvs 
shown previous best diversity ga div kappa 
guiding diversity search strategy data set compared ensemble accuracy cross validation runs student test significance difference proportions level significance 
results table 
shown resampled test commonly significance tests unacceptably high probability detecting difference generalization performance difference exists type error 
commonly procedure comparing learning methods provide approximate confidence intervals great help interpreting experimental comparisons learning methods 
cell table compares diversity metric corresponding line metric corresponding column contains win tie loss information data sets search strategies correspondingly ebss efss ga hc total numbers gray bold italic 
line column calculated total numbers compare corresponding diversity summing corresponding cells 
table 
student test results comparing guiding diversities different search strategies cross validation runs win tie loss bss fss ga hc total div plain div dis div corr div div kappa total div plain div dis div corr div div kappa total table supports 
significant difference guiding diversities cases 
div significantly worse ebss losses wins comparisons efss losses wins ga losses wins 
hc difference diversity 
div kappa best diversity ga wins losses works ebss wins losses unstable efss wins losses 
differences insignificant 
rest dependencies section depend guiding diversity consider div plain guiding diversity 
average ensemble accuracies integration methods ss wv ds dv dvs shown combination search strategies ebss efss ga hc rs 
ss wv ds dv dvs 
average test set accuracy different integration methods different search strategies see dynamic methods better average static methods dvs best dynamic method supports 
dvs ga shows best accuracy dvs hc second best 
dynamic methods ranking search strategies ga hc ebss rs efss 
average test set accuracy different search strategies integration methods data sets different numbers features figures information average ensemble accuracy integration methods search strategies rs shown groups data sets features data sets equal features data sets correspondingly 
ebss efss ga hc rs ss wv ds dv dvs 
average test set accuracy different integration methods different search strategies data sets number features data sets see figures behavior search strategies groups dependencies 
interesting finding rs dynamic methods ds dv dvs group data sets works relatively better rs dynamic methods second group case ga works better second group ga hc ebss better rs dynamic methods 
shows rs works better data sets having smaller numbers features 
surprisingly static methods rs relatively better second group counterintuitive may due relatively lower diversity ensembles generated rs data sets bigger numbers features 
data sets bigger numbers features search strategies able achieve better diversities rs supported difference accuracy dynamic static methods group second 
ebss efss ga hc rs ss wv ds dv dvs 
average test set accuracy different integration methods different search strategies data sets number features equal data sets integration methods ga search strategy average ensemble accuracies integration methods ga strategy generations 
see static integration methods ss wv dynamic ds start overfit validation data set generations show lower accuracies accuracies dv dvs continue grow 
shows ebss efss importance selection appropriate integration method ga search strategy 
ga hc rs ss wv ds dv dvs gen 
average test set accuracy different integration methods ga search strategy different numbers generations overfitting search strategies integration methods measure overfitting show average ensemble accuracy test validation sets correspondingly search strategies dvs integration method 
rs ensemble accuracy shown sake comparison 
see highest difference test set validation set accuracies ga efss search strategies lowest difference test validation set accuracies hc search strategy ebss search strategy difference equal 
ebss efss ga hc rs validation 
overfitting different search strategies dvs integration method test set validation set accuracies measure overfitting show average ensemble accuracy test validation sets correspondingly integration methods averaged search strategies 
see highest difference test set validation set accuracies wv integration method 
dv ss dvs ds 
general static integration methods show overfitting dynamic counterparts case ga search strategy 
worth noting dvs returns best accuracy unseen test data 
test ss wv ds dv dvs validation 
overfitting different integration methods averaged search strategies test set validation set accuracies pre selected alpha integration methods search strategies pre selected values alpha shown integration methods search strategies 
naturally ebss bigger values alpha selected needs diversity achieve better ensemble accuracy classifiers include identical features 
case static integration methods especially wv diversity important diversity extent dynamic integration 
general alpha dynamic methods bigger strategies static ones 
efss hc ga strategies alpha selected average 
test ss wv ds dv dvs ebss efss 
average pre selected alpha values different integration methods search strategies average numbers features selected different search strategies integration methods average relative numbers features selected base classifiers search strategies rs integration methods shown 
numbers features correspond different alpha values selected combination search strategy integration method data set case rs numbers correspond simply random sets depend integration method 
see naturally rs selects exactly half features average 
surprisingly ga strategy selects biggest number features higher ebss strategy 
possible explanation due global nature search able achieve better diversity classifiers including bigger feature subsets having features common 
expected efss strategy selects lowest number features average 
rule features selected static integration methods dynamic ones corresponding bigger alpha values 
ga hc ebss efss ga hc rs 
average relative numbers features base classifiers different search strategies integration methods pre selected neighborhood dynamic integration average numbers nearest neighbors pre selected dynamic integration methods shown 
see ds needs bigger values explained fact prediction classifier selected unstable 
bigger values provide stability ds 
equal ds average dv 
dvs hybrid strategy 
selected values change significantly search strategies 
outlier value dvs ga strategy 
high value probably explained differences nature search ga strategies 
ss wv ds dv dvs ds dv dvs 
average numbers nearest neighbors pre selected dynamic integration methods considered diversity metrics pairwise component fitness function guide process ensemble training ensemble feature selection plain disagreement div plain fail non fail disagreement div dis statistic div correlation coefficient div corr kappa statistic div kappa non pairwise entropy div ent ambiguity div amb 
measures measure total ensemble diversity characteristic ensemble goodness 
consider search strategies ensemble feature selection hill climbing hc genetic algorithm ensemble feature selection ga ensemble forward sequential selection efss ensemble backward sequential selection ebss 
implementation search strategies employ fitness function proportional accuracy diversity corresponding base classifier 
diversity context pairwise diversities considered 
integrate base classifiers generated search strategies integration methods static selection ss weighted voting wv dynamic selection ds dynamic voting dv dynamic voting selection dvs 
experiments analyse total ensemble diversity calculated considered metrics 
check goodness measure diversity calculated correlation ebss efss ga hc rs difference ensemble accuracy average base classifier accuracy 
correlations depend search strategy depend significantly data set 
best correlations averaged data sets shown div plain div dis div ent div amb 
div div corr behaved similar way supported similarity formulae 
surprisingly div worst average correlation 
correlations div div corr changed change integration method showing different diversity integration methods 
correlation div amb div plain 
compared ensemble accuracies search strategies pairwise diversity metrics integration methods 
diversities ga best strategy average hc second best 
power strategies explained fact random subsampling 
surprisingly efss significantly worse strategies collection data sets 
significant difference guiding diversities findings div significantly worse average diversities ebss efss ga div kappa better diversities ga hc sensitive choice guiding diversity 
results student test significance supported findings 
dynamic integration methods ds dv dvs worked better average static methods ss wv dvs best dynamic method average 
ga dvs best combination search strategy integration method 
analyse overfitting ensembles measured ensemble accuracies validation test sets 
search strategies ga efss biggest overfitting average 
integration methods discovered static integration methods show overfitting dynamic counterparts 
experimental results change data set data sets needed check analyse reported findings 
experiments needed check behaviour diversity metrics depends data set characteristics best metric particular data set 
interesting topic research 
measure ensemble diversity considered shown high correlation ensemble accuracy double fault df measure 
interesting topic research consider measure guiding diversity experimental setting check correlation improvement accuracy considered measures diversity 
aha bankert comparative evaluation sequential feature selection algorithms fisher lenz eds proc :10.1.1.17.626
th int 
workshop artificial intelligence statistics pp 

bauer kohavi empirical comparison voting classification algorithms bagging boosting variants machine learning 
blake keogh merz uci repository machine learning databases www ics uci edu mlearn mlrepository html dept information computer science university california irvine ca 
brodley lane creating exploiting coverage diversity proc 
aaai workshop integrating multiple learned models portland pp 

chan extensible meta learning approach scalable accurate inductive learning 
dept computer science columbia university new york ny phd thesis technical report cucs 
chan stolfo accuracy meta learning scalable data mining 
intelligent information systems 
reliability parameters improve combination strategies multi expert systems pattern analysis applications 
cunningham carney diversity versus quality classification ensembles feature selection dem plaza eds proc 
ecml th european conf 
machine learning barcelona spain lncs springer pp 

dietterich experimental comparison methods constructing ensembles decision trees bagging boosting randomization machine learning :10.1.1.131.1931
dietterich machine learning research current directions ai magazine 
dietterich bakiri solving multiclass learning problems error correcting output codes journal artificial intelligence research 
domingos pazzani optimality simple bayesian classifier zero loss machine learning 
fayyad piatetsky shapiro smyth uthurusamy advances knowledge discovery data mining aaai mit press 
roli methods dynamic classifier selection proc 
th int 
conf 
image analysis processing ieee cs press pp 

hansen salamon neural network ensembles ieee transactions pattern analysis machine intelligence 
heath kasif salzberg committees decision trees 
mey eds cognitive technology search interface elsevier science pp 

ho random subspace method constructing decision forests ieee transactions pattern analysis machine intelligence 
kohavi wrappers performance enhancement oblivious decision graphs dept computer science stanford university stanford usa phd thesis 
kohavi sommerfield dougherty data mining mlc machine learning library tools artificial intelligence ieee cs press 
engelson integrating multiple classifiers finding areas expertise aaai workshop integrating multiple learning models improving scaling machine learning algorithms portland pp 

krogh vedelsby neural network ensembles cross validation active learning touretzky leen eds advances neural information processing systems vol 
cambridge ma mit press pp 

kuncheva whitaker measures diversity classifier ensembles relationship ensemble accuracy machine learning 
dietterich pruning adaptive boosting proc 
th int 
conf 
machine learning morgan kaufmann pp 

merz classification regression combining models dept information computer science university california irvine usa phd thesis 
merz dynamical selection learning algorithms fisher 
lenz eds 
learning data artificial intelligence statistics springer 
merz correspondence analysis combine classifiers machine learning 
opitz feature selection ensembles proc :10.1.1.44.7302
th national conf 
artificial intelligence aaai press pp 

opitz shavlik generating accurate diverse members neural network ensemble touretzky mozer eds advances neural information processing systems vol mit press pp 

tumer dimensionality reduction classifier ensembles computational sciences division nasa ames research center technical report nasa arc ic 
dynamic integration algorithm ensemble classifiers ras eds foundations intelligent systems th int 
symp 
ismis warsaw poland lnai springer pp 

quinlan bagging boosting proc 
th national conf 
artificial intelligence aaai portland aaai press pp 

salzberg comparing classifiers critique current research methods data mining knowledge discovery 
schaffer selecting classification method cross validation machine learning 
kuncheva relationship combination methods measures diversity combining classifiers information fusion 
skalak combining nearest neighbor classifiers dept computer science university massachusetts amherst ma phd thesis 
skalak sources increased accuracy proposed boosting algorithms aaai workshop integrating multiple models improving scaling machine learning algorithms conjunction aaai portland oregon usa pp 

todorovski dzeroski combining multiple models meta decision trees ri proc 
pkdd lyon france lnai springer pp 

cunningham search strategies ensemble feature selection medical diagnostics mitra lee eds proc :10.1.1.13.9571
th ieee symp 
computer medical systems cbms mount sinai school medicine new york ny ieee cs press pp 

patterson ensemble feature selection simple bayesian classification information fusion elsevier science 
ensemble feature selection dynamic integration classifiers int 
icsc congress computational intelligence methods applications bangor wales pp 

tumer ghosh error correlation error reduction ensemble classifiers connection science special issue combining artificial neural networks ensemble approaches 
webb technique combining boosting machine learning 
cunningham diversity preparing ensembles classifiers different feature subsets minimize generalization error raedt flach eds proc 
ecml th european conf 
machine learning lncs springer pp 


