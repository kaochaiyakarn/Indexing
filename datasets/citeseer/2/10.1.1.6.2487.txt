parallel open source data linkage system datamining anu edu au linkage html peter tim churches markus department computer science australian national university canberra act australia peter anu edu au centre epidemiology research new south wales department health locked mail bag north sydney nsw australia health nsw gov au centre mathematics applications mathematical sciences institute australian national university canberra act australia markus anu edu au 
data mining projects information multiple data sources needs integrated combined linked order allow detailed analysis 
aim linkages merge records relating entity patient customer 
time linkage process challenged lack common unique entity identi er non trivial 
linking todays large data collections increasingly dicult traditional linkage techniques 
data linkage system called febrl includes new probabilistic approach improved data cleaning standardisation innovative indexing methods parallelisation approach implemented transparently user data set generator allows random creation records containing names addresses 
implemented open source software febrl ideal experimental platform new linkage algorithms techniques 
keywords record linkage data matching data cleaning standardisation parallel processing data mining preprocessing 
data linkage improve data quality integrity allow re existing data sources new studies reduce costs orts data acquisition research studies 
health sector example linked data contain information needed improve health policies information traditionally collected time consuming expensive survey methods 
linked data help health surveillance systems enrich data pattern detection data mining systems 
businesses routinely link data sets compile mailing lists taxation ces departments social security data linkage catch people register bene ts multiple times collect unemployment money 
application current interest data linkage crime terror detection 
security agencies crime investigators increasingly rely ability quickly bring les particular individual may help prevent crimes terror early intervention 
data linkage important preprocessing step data analysis mining 
unique entity identi er key available data sets linked problem linking entity level trivial simple join operation sql equivalent data management systems required 
cases unique key shared data sets sophisticated linkage techniques need applied 
techniques broadly classi ed deterministic rules approaches sets complex rules classify pairs records links relating person entity non links probabilistic approaches statistical models classify record pairs 
probabilistic methods divided classical probabilistic record linkage theory developed fellegi sunter newer approaches maximum entropy clustering machine learning techniques :10.1.1.39.4336:10.1.1.46.6676
computer assisted data linkage goes back far 
time linkage projects ad hoc heuristic methods 
basic ideas probabilistic data linkage introduced newcombe kennedy theoretical foundation provided fellegi sunter 
basic idea link records comparing common attributes include person identi ers names dates birth demographic information 
pairs records classi ed links common attributes predominantly agree non links predominantly disagree 
data sets linked record pairs classi ed product space set true matches set true non matches 
fellegi sunter considered ratios probabilities form jm ju arbitrary agreement pattern comparison space example consist patterns representing simple agreement disagreement name surname date birth street address suburb postcode 
alternatively additionally account relative frequency speci values occur 
example surname value miller normally common value dijkstra resulting smaller agreement value 
ratio monotonically increasing function logarithm referred matching weight 
decision rule upper designate record pair link lower upper designate record pair possible link lower designate record pair non link thresholds lower upper determined priori error bounds false links false non links 
mainly consists agreements ratio large record pair designated link 
hand primarily consists disagreements ratio small 
class possible links record pairs human oversight known clerical review needed decide nal linkage status 
theory person undertaking clerical review access additional data may able seek enables resolve linkage status 
practice additional data available clerical review process applying human intuition experience common sense decision available data 
key aspects parallel open source data linkage system febrl freely extensible biomedical record linkage implemented object oriented open source scripting language python freely available project web page see url title page 
due availability source code febrl ideal platform rapid development implementation new improved data linkage algorithms techniques 
overview related section discuss section newly developed probabilistic data cleaning standardisation method hidden markov models hmm 
important task blocking indexing aims reducing computational complexity linkage process topic section section parallelisation techniques febrl 
random data set generator described section conclude giving outlook section 
related processes data cleaning standardisation data linkage various names di erent user communities 
statisticians speak record data linkage process referred data eld matching data scrubbing data cleaning preprocessing object identity problem computer scientists database community called merge purge processing data integration list washing etl extraction transformation loading commercial processing customer databases business mailing lists :10.1.1.37.5212
historically statistical computer science community developed techniques cross 
improvements classical fellegi sunter approach include application expectation maximisation em algorithm improved parameter estimation approximate string comparisons calculate partial agreements attribute values typographical errors :10.1.1.39.4336
fuzzy techniques methods information retrieval www python org fig 

example name address standardisation 
main app 
rd miller main peter rd app 
address name geocode locality doc canberra canberra title surname year month day postcode territory 
unit type name 
peter miller main canberra act apartment road doctor date birth address data linkage problem 
approach represent records document vectors compute cosine distance vectors 
possibility sql language allows approximate joins cluster building similar records decision functions decide records represent entity 
methods include statistical outlier identi cation pattern matching clustering association rules approaches 
years researchers started explore machine learning data mining techniques improve linkage process 
authors describe hybrid system rst step uses unsupervised clustering small sample data set create data second step classify record pairs links non links 
learning eld speci distance weights binary classi er support vector machines svm approach 
system capable link large data sets billions records special sorting preprocessing techniques 
probabilistic data cleaning standardisation real world data collections contain noisy incomplete incorrectly formatted information data cleaning standardisation important preprocessing steps successful data linkage data loaded data warehouses analysis 
data may recorded captured various possibly obsolete formats data items may missing date contain errors 
cleaning standardisation names addresses especially important data linkage sure misleading redundant information introduced duplicate records 
main task data cleaning standardisation conversion raw input data de ned consistent forms resolution inconsistencies way information represented encoded 
example record shown consisting input components cleaned fig 

simple example hidden markov model names 
surname start title standardised output elds dark coloured boxes 
comparing output elds individually corresponding output elds records results better linkage quality just comparing name address string name address records 
rule data cleaning standardisation currently done commercial systems cumbersome set maintain needs adjustments new data sets 
developed implemented febrl new probabilistic techniques hidden markov models hmms showed achieve better standardisation accuracy easier set maintain compared popular commercial linkage software 
approach steps 
input strings cleaned 
involves converting input lower case characters replacing certain words abbreviations replacements listed look tables edited user 
second step input strings split list words numbers characters tagged look tables mainly names addresses hardcoded rules numbers hyphens commas 
thirdly tagged lists segmented output elds hmm shown 
assume example input record contains name component doc peter paul miller 
cleaning step input converted lower case title doc replaced standard word doctor title replacement look table 
tagging look tables input split list element word tagged doctor peter paul miller ti gm gm sn ti tag title words gm tag male names sn tag surnames 
third step tag list hmm shown viterbi algorithm path hmm gives corresponding output elds states hmm doctor peter paul miller title surname details eciently train hmms name address standardisation experiments real world data 
training hmms quick require specialised skills 
addresses hmm approach produced equal better standardisation accuracies widely rule system 
accuracies worse simpler name data 
blocking indexing classi cation data linkage considers distribution record pairs product space determines pairs links 
number possible pairs equals product sizes data sets straight forward approach consider pairs model distribution 
performance bottleneck data linkage system usually expensive evaluation similarity measure pairs records approach computationally feasible large data sets non scalable :10.1.1.10.4563
linking data sets records result potential links comparisons 
hand maximum number links possible corresponds number records smaller data set assuming record linked record 
space potential links sparser increasing number records computational orts increase exponentially 
reduce huge amount possible record comparisons traditional data linkage techniques blocking fashion record attributes postcode year birth split data sets blocks :10.1.1.39.4336
records having value blocking variable compared block 
technique problematic value blocking variable recorded wrongly corresponding record inserted di erent block 
overcome problem iterations di erent blocking variables normally performed 
blocking indexing techniques reduce number comparisons possible eliminating comparisons records obviously links important potential link overlooked indexing process 
trade reduction number record pair comparisons number missed true matches accuracy 
febrl currently contains di erent indexing methods included 
fact exploration improved indexing methods major research areas :10.1.1.10.4563
rst indexing method standard blocking method applied traditional data linkage systems :10.1.1.39.4336
second indexing method sorted neighbourhood approach records sorted alphabetically values blocking variable sliding window moved sorted records record pairs formed records window 
third method uses grams sub strings length allows fuzzy blocking current implementation bigrams 
values blocking variable converted lists bigrams permutations sub lists built threshold value possible permutations 
resulting bigram sub lists converted back strings keys inverted index record numbers stored 
inverted index retrieve blocks 
assume example blocking variable value peter bigram threshold set 
bigram list pe te er elements threshold results rounded means sub list permutations length calculated pe te pe er pe te er te er 
record numbers records blocking variable value peter inserted inverted index blocks keys 
initial experiments showed innovative indexing methods improved traditional blocking data linkage research needs conducted :10.1.1.10.4563
research groups investigated grams high dimensional approximate distance metrics form overlapping clusters 
record pair index vector containing matching weights calculated eld comparison functions 
vector classify pair link non link possible link case decision done human review 
classical fellegi sunter simply sums weights vector matching weight alternative classi ers possible improve 
example separate weights calculated names addresses machine learning techniques classi cation task 
febrl system currently classi ers implemented 
rst classical fellegi sunter classi er described earlier second exible classi er allows exible calculation matching weights various functions 
parallelisation computing power increased tremendously decades large scale data cleaning standardisation data linkage processes 
relatively advances decade way probabilistic data linkage undertaken particularly respect tedious clerical review process needed decisions pairs records linkage status doubtful 
order able link large data sets parallel processing essential 
issues addressed ecient data distribution fault tolerance dynamic load balancing portability scalability data size number processors 
con dentiality privacy considered data linkage deals partially identi ed data access restrictions required 
highperformance computing centers traditionally multi user environments problematic 
attractive alternative networked personal comput fig 

speedups parallel internal linkage processes 
number processors step loading indexing records records records speedup number processors step record pair comparison classification records records records speedup number processors step assignment saving records records records number processors total records records records ers workstations available large numbers businesses organisations 
oce clusters virtual parallel computing platforms run large scale linkage tasks night weekends 
parallelism febrl currently initial stages 
known message passing interface mpi standard python module provides bindings important subset mpi routines parallelism implemented transparently user febrl 
give idea parallel performance febrl initial timing results experiments parallel computing platform sun enterprise shared memory smp server mhz ultra sparc ii processors giga bytes main memory section 
internal linkage deduplication processes performed records respectively health data set containing data records provided nsw department health 
data set earlier standardised clean form stored csv comma separated values text le 
eld comparison functions classical blocking index technique indexes passes applied 
standard fellegi sunter classi er classify record pairs nally assignment procedure applied order restrict record data set linked maximal record 
datamining anu edu au table 
memory usage internal linkage processes mega bytes 
number processors records records records internal linkage processes run processors respectively 
speedup de ned time processor divided time processors respectively results shown scaled number records total elapsed run times divided number records calculate speedup 
results show record comparison classi cation step takes total run times scalable building blocking indexes assignment steps result low speedup values scalable 
time spent record pair comparison classi cation step parallel performance quite scalable 
communication times neglected total run times experiments 
table shows maximal amount memory internal linkage experiments 
amount memory increases linearly compared number records fold increase number records results fteen fold increase amount memory needed 
additionally parallel processing febrl results increased amount memory needed due replication various data structures parallel febrl processes 
data set generation data linkage dealing data sets contain partially identi ed data names addresses dicult acquire data sets testing evaluating newly developed linkage algorithms techniques 
user dicult learn apply evaluate customise data linkage algorithms ectively example data sets linkage status record pairs known 
overcome developed database generator ideas hernandez stolfo 
generator create data sets contain names frequency look tables surnames names addresses frequency look tables street numbers names state territory names dates dates birth identi er numbers randomly create example social security numbers 
generate data set user provide number original duplicate records created maximal number duplicates created original record probability distribution duplicates created possible uniform poisson zipf probabilities fig 

randomly generated example data set 
rec id address address suburb postcode rec org place ret rec dup ret rec dup ret place rec dup place ret rec dup parade ret rec org stuart street rec org griffiths street rec dup griffith rec dup griffith street rec org place sydney random modi cations introduced duplicate records insert new character random position eld attribute 
delete character random position eld 
substitute character eld character possibility set probabilities randomly choosing neighbouring key keyboard row column 
transpose characters random position eld 
swap replace value eld value randomly selected look table possible values 
insert space eld splitting word 
delete space available eld merging words 
set eld value missing user de nable missing value 
swap values elds surname name record 
rst step original records generated second step duplicates original records created randomly introduced modi cations 
records unique identi er allows evaluation accuracy error rates false linked record pairs un linked true matches data linkage procedures 
shows small example data set containing records originals duplicates randomly created australian address frequency look tables 
written object oriented open source scripting language febrl data linkage system ideal experimental platform researchers develop implement evaluate new data linkage algorithms techniques 
current system perform simple data cleaning standardisation linkage tasks needs done allow ecient linkage large data sets 
plan improve febrl areas 
data cleaning standardisation improving developed probabilistic techniques hidden markov models hmms baum welch forward backward algorithm reestimate probabilities hmms explore techniques developing hmms explicitly specifying hidden states 
aim explore alternative techniques indexing highdimensional clustering inverted indexes fuzzy gram indexes terms applicability indexing scalability data size parallelism 
current methods record pair classi cation traditional fellegi sunter approach apply semi parametric mixture models em algorithm estimation underlying densities clustering classi cation links non links :10.1.1.39.4336
investigate performance data mining non parametric techniques including tree classi ers sparse grids bayesian nets 
advantage methods allow adaptive modelling correlated data deal complex data curse dimensionality 
methods current tting algorithms adapted new ones developed 
continue improve parallel processing functionalities febrl emphasis running large linkage processes clusters personal computers workstations available businesses organisations 
oce pc clusters additional software installed virtual parallel computing platforms run large scale linkage tasks night weekends 
con dentiality privacy aspects need considered data linkage cases deals identi ed data 
acknowledgments project funded australian national university anu new south wales department health anu industry collaboration scheme 
additional funding provided australian partnership advanced computing 

baxter churches comparison fast blocking methods record linkage 
acm sigkdd workshop data cleaning record linkage object consolidation august washington dc pp 


bertsekas auction algorithms network flow problems tutorial 
computational optimization applications vol 
pp 


chaudhuri ganti motwani robust ecient fuzzy match online data cleaning 
proceedings acm sigmod intern 
conference management data diego usa pp 


churches zhu probabilistic name address cleaning standardisation 
proceedings australasian data mining workshop canberra dec 

churches lim zhu preparation name address data record linkage hidden markov models 
biomed central medical informatics decision making dec 
available online www com 
cohen integration heterogeneous databases common domains queries textual similarity 
proceedings sigmod seattle 

verykios elmagarmid tailor record linkage toolbox 
proceedings icde san jose usa 

fellegi sunter theory record linkage 
journal american statistical society 

galhardas florescu shasha simon extensible framework data cleaning 
proceedings inter 
conference data engineering 

gill methods automatic record matching linking national statistics 
national statistics methodology series london 

adaptive sparse grids 
vol 
pp 


hernandez stolfo merge purge problem large databases 
proceedings acm sigmod conference 

hernandez stolfo real world data dirty data cleansing merge purge problem 
data mining knowledge discovery kluwer academic publishers 

maletic marcus data cleansing integrity analysis 
proceedings conference information quality iq boston october 

mccallum nigam ungar ecient clustering high dimensional data sets application matching 
knowledge discovery data mining pp 


gropp lusk skjellum mpi nd edition portable parallel programming message passing interface mit press 

nahm bilenko mooney approaches handling noisy variation text mining 
proceedings icml workshop text learning pp 
sydney australia july 

newcombe kennedy record linkage making maximum discriminating power identifying information 
communications acm vol 


porter winkler approximate string comparison ect advanced record linkage system 
research report rr bureau census 

rabiner tutorial hidden markov models selected applications speech recognition 
proceedings ieee vol 
feb 

rahm data cleaning problems current approaches 
ieee data engineering bulletin 

verykios elmagarmid dalal completeness accuracy record matching process 
proceedings mit conference information quality boston ma october 

winkler state record linkage current research problems 
research report rr bureau census 

winkler em algorithm weight computation model record linkage 
research report rr bureau census 

program extracting probable matches large file record linkage 
research report rr statistical research division bureau census march 
