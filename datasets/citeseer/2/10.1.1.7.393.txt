global tree optimization non greedy decision tree algorithm kristin bennett email rpi edu department mathematical sciences rensselaer polytechnic institute troy ny non greedy approach constructing globally optimal multivariate decision trees fixed structure proposed 
previous greedy tree construction algorithms locally optimal optimize splitting criterion decision node typically node time 
contrast global tree optimization explicitly considers decisions tree concurrently 
iterative linear programming algorithm minimize classification error entire tree 
global tree optimization construct decision trees initially update existing decision trees 
encouraging computational experience reported 
global tree optimization gto new approach constructing decision trees classify sets dimensional points 
essential difference prior decision tree algorithms cart id gto non greedy 
greedy algorithms best decision node optimizing splitting criterion 
process started root repeated recursively points correctly classified 
sets classified disjoint greedy decision tree algorithm construct tree consistent points sufficient number decision nodes 
trees may generalize correctly classify previously seen points due fitting parameterizing problem 
practice decision nodes pruned tree 
typically pruning process allow remaining decision nodes adjusted tree may material research supported national science foundation 
appeared computing science statistics pg 

parameterized 
strength greedy algorithm growing tree pruning greedy algorithm determines structure tree class leaves decision non leaf node 
limitations greedy approaches locally decisions may result bad tree existing trees difficult update modify 
gto overcomes limitations treating decision tree function optimizing classification error entire tree 
function similar proposed mars mars greedy algorithm 
greedy algorithms optimize node time fix resulting decisions 
gto starts existing tree 
structure starting tree number decisions depth tree classification leaves determines classification error function 
gto minimizes classification error changing decisions concurrently keeping underlying structure tree fixed 
advantages approach greedy methods fixing structure helps prevent overfitting problem locally bad globally decisions existing trees re optimized additional data domain knowledge readily applied 
gto requires structure tree input complements replaces existing greedy decision tree methods 
complementing greedy algorithms gto offers promise making decision trees powerful flexible accurate widely accepted paradigm 
minimizing global error decision tree fixed structure non convex optimization problem 
problem constructing decision tree fixed number decisions correctly classify sets special case np complete polyhedral separability problem 
consider seemingly simple npcomplete problem tree just decision nodes correctly classify disjoint point sets 
gamma fl gamma fl gamma fl gamma fl gamma fl gamma fl gamma fl gamma fl class class typical class decision tree problem formulated bilinear program 
extend general decision trees resulting multilinear program solved frank wolfe algorithm proposed bilinear case 
organized follows 
brief review known case optimizing tree consisting single decision 
tree represented system linear inequalities system solved linear programming 
section show general decision trees expressed system disjunctive linear inequalities formulated multilinear programming problem 
section explains iterative linear programming algorithm optimizing resulting problem 
computational results section 
gto applies binary trees multivariate decision node form point classified decision node xw fl point follows right branch xw fl point follows left branch 
choice branch point follows equality arbitrary 
type decision greedy algorithms 
univariate decisions cart continuous variables considered special cases type decision nonzero component point classified path point tree reaches leaf node 
point strictly classified tree reaches leaf correct class equality hold decision path leaf xw fl decision path 
gto applicable problems classes simplicity limit discussion problem classifying sets sample tree 
consist points contained consist points contained tree greedy lp algorithm tree gto geometric depiction decision trees denote jth point optimizing single decision methods exist minimizing error tree consisting single decision node 
briefly review approach formulates problem set linear inequalities uses linear programming minimize errors inequalities 
reader referred full details practical theoretical benefits approach 
xw fl plane formed decision 
point xw fl point classified class xw fl point classified class xw fl class chosen arbitrarily 
points strictly classified exist fl gamma fl gamma fl equivalently gammaa fl gamma fl note equations alternative definitions linear separability 
choice constant arbitrary 
positive constant may 
linearly separable equation feasible linear program lp zero minimum 
resulting fl forms decision strictly separates equation feasible lp minimizes average misclassification error class 
min fl gamma fl gammab fl lp recursively greedy decision tree algorithm called method tree 
compares favorably greedy decision tree algorithms suffers problem greedy approaches 
locally globally poor decisions near root tree result overly large trees poor generalization 
shows example case phenomenon occurs 
depicts planes completely classify points 
decisions chosen near root tree largely redundant 
result decisions near leaves tree unnecessarily small number points 
constructed excessively large tree reflect underlying structure problem 
contrast gto able completely classify points decisions 
problem formulation general decision trees tree represented set disjunctive inequalities 
multilinear program minimize error disjunctive linear inequalities 
consider problem optimizing tree structure briefly consider problem general trees 
recall point strictly classified tree point reaches leaf correct classification equality hold decisions path leaf 
point strictly classified follows path tree fourth leaf node gamma fl gamma fl ae gammaa fl gamma fl gammaa fl equivalently gamma fl delta gamma fl gammaa fl delta gamma fl delta gammaa fl 
similarly point strictly classified follows path tree second third fifth leaf node gamma fl gammab fl ae gammab fl gamma fl gamma fl gammab fl gammab fl ae equivalently gamma fl delta gammab fl gammab fl delta gamma fl delta gamma fl gammab fl gammab fl decision tree exists strictly classifies points sets equation feasible solution delta delta delta gamma fl gammaa fl gamma fl gammab fl number decisions tree furthermore fl satisfying form decisions tree strictly classifies points sets equivalently exists decision tree structure correctly classifies points sets multilinear program zero minimum min fl delta delta delta gamma fl gammaa fl gamma fl gammab fl coefficients chosen identical lp single decision case guaranteeing unique solution case 
coefficients help method numerically stable large training set sizes 
general approach applicable multivariate binary decision tree classify sets 
error term point training set 
error point product errors leaves 
error leaf sum errors decisions path leaf 
point correctly classified leaf error path zero product leaf errors zero 
space permit discussion general formulation refer reader details 
multilinear programming multilinear program general formulation optimized iterative linear programming frank wolfe type method proposed 
outline method refer reader mathematical properties algorithm 
consider problem min subject polyhedral set containing constraint continuous partial derivatives bounded 
frank wolfe algorithm problem algorithm frank wolfe algorithm start compute follows 
arg vertex min ii iii gamma arg min gamma algorithm arg vertex min denotes vertex solution set indicated linear program 
algorithm terminates satisfies minimum principle necessary optimality condition gamma accumulation point sequence fx satisfies minimum principle 
gradient calculation gto function straightforward 
example algorithm applied problem linear subproblem solved step fl min fl delta delta delta delta delta delta delta gamma fl gammaa fl gamma fl gammab fl fixed results gto implemented general decision trees fixed structure 
order test effectiveness optimization algorithm random problems known solutions generated 
dimension tree decision nodes randomly generated classify points unit cube 
points unit cube randomly generated classified grouped training set points testing set points 
greedy algorithm discussed section generate greedy tree correctly classified training set 
tree pruned known structure number decision nodes tree 
pruned tree starting point gto 
training testing set error tree pruned tree denoted gto tree measured training time 
experiment repeated trees ranging nodes dimensions 
results averaged trials 
summarize test results refer reader details 
presents average results randomly generated trees decision nodes 
results typical observed experiments 
achieved correctness training set excessive number decisions 
training testing set accuracy pruned trees dropped considerably 
trees optimized gto significantly better terms testing set accuracy unpruned pruned trees 
computational results promising 
algorithm converges relatively iterations improved solution 
gto find global minimum 
expect problem local minima np complete 
plan investigate global optimization techniques avoid local minima 
execution time gto tends grow problem size increases 
parallel computation improve execution time expensive lp subproblems 
lp subproblems problem block separable structure divided independent lps solvable parallel 
introduced non greedy approach optimizing decision trees 
gto algorithm starts existing decision tree fixes structure tree formulates error tree optimizes error 
iterative linear programming algorithm performs np complete problem 
gto optimizes decisions tree potential applications decreasing greediness constructive algorithms existing trees additional data available pruning greedy decision trees incorporating domain knowledge decision tree 
bennett 
decision tree construction linear programming 
evans editor proceedings th midwest artificial intelligence 
