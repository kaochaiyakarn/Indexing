presents overview tracking focus attention meeting situations 
developed system capable estimating participants focus attention multiple cues 
system employ omni directional camera simultaneously track faces participants sitting meeting table neural networks estimate head poses 
addition microphones detect speaking 
system predicts participants focus attention acoustic visual information separately combines output audio video focus attention predictors 
addition reports experimental results order determine predict subject focus attention solely basis head orientation conducted experiment recorded head eye orientations participants meeting special tracking equipment 
results demonstrate head orientation sufficient indicator subjects focus target time 
furthermore discuss neural networks estimate head orientation adapted new locations new illumination conditions 
years research done building computerized intelligent environments aim supporting humans various tasks situations 
research projects include digital office intelligent house adapts illumination heating user needs intelligent classrooms automatically takes notes provides students relevant web pages smart conferencing rooms aim support cooperative help document analyze activities occur meetings 
order intelligent interactive environments respond appropriately users needs necessary equip perceptive capabilities capture relevant information users context act possible 
obtaining knowledge person focus attention major step better understanding users tracking focus attention meetings rainer stiefelhagen interactive systems laboratories universit karlsruhe th germany mail stiefel ira uka de interact refer 
research address problem tracking focus attention participants meeting tracking looking meeting 
information example control interaction smart meeting room index analyze multimedia meeting records 
body research literature suggests humans generally interested look close relationship gaze attention social interaction emphasized 
addition user studies reported strong evidence people naturally look objects devices interact 
step determine focus attention find direction person looks 
contributing factors formation person looks head orientation eye orientation 
head orientation considered sufficient cue detect person direction attention 
relevant psychological literature offers number convincing arguments approach feasibility approach demonstrated experimentally 
practical reason head orientation estimate person focus attention scenarios addressed head orientation estimated non intrusive methods eye orientation 
approach tracking participants look focus attention 
detect participants scene 
estimate participant head orientation 
map estimated head orientation targets probabilistic framework 
approach course perfect 
eye gaze neglected certain amount errors introduced 
noisy estimation head orientations camera images introduces additional errors 
improve robustness focus attention tracking combine various sources information 
focus attention correlated speaking meeting possible estimate person focus attention information talking moment 
estimate 
panoramic view scene table 
faces automatically detected 
person looking speaking probability distributions participants looking certain speaking constellations 
accuracy sound prediction focus attention furthermore significantly improved history speaker constellations account 
trained neural networks predict focus attention speaking short period time 
head pose sound estimations combined obtain multimodal estimation participants focus attention 
significant improvements compared just modality focus attention tracking 
system focus attention detection meetings successfully installed labs universit karlsruhe germany carnegie mellon university pittsburgh usa 
problem porting system new location need appropriate training images neural network approach head orientation estimation 
investigated training adaptation data necessary port system new location 
remainder organized follows section discuss participants tracked head pose estimated system 
section introduce probabilistic approach model subjects look head orientations 
section user study investigating reliably focus attention estimated head orientation meetings 
section suggest focus attention tracking benefit tracking relevant cues show information speaking moment improve focus attention tracking accuracy 
section discuss portability issues system 
conclude section 
simultaneous head pose tracking meetings omni directional camera capture scene meeting table 
compared cameras capture scene simplifies recording camera control calibration synchronization necessary 
panoramic view meeting scene see example detect participants faces searching skin colored regions heuristics distinguish skin colored hands faces 
detected participant rectified perspective view computed see 
faces extracted views estimate participant head pose 
head pose estimation neural networks neural networks estimate head pan tilt facial images 
approach preprocessed facial images input neural networks networks trained estimate horizontal pan vertical tilt head orientation input images 
separate networks trained estimate head pan tilt 
networks contained hidden layer output unit encodes head orientation degrees 
training multi user networks images twelve users achieved average estimation errors low degrees pan tilt 
images new users head orientation estimated average error degrees pan tilt 
details 
head pose focus attention approach estimate persons head orientation detect person looking estimated head orientation 
compared directly classifying person focus attention target images person face example approach advantage different numbers positions participants meeting handled 
problem treated multi class classification problem classifier neural network trained directly learn focus attention target facial images user number possible focus targets known advance 
furthermore approach difficult handle situations participants sit different locations sitting collection training data 

perspective views participants 
prior prob 
true adapted head pan degrees class conditional probs 
head pan degrees posterior probs 
left opposite right head pan degrees 
unsupervised adaptation model parameters find see text 
developed bayesian approach estimate target person looking observed head orientation 
precisely wish find ti xs probability subject looking certain target person ti subject observed horizontal head orientation xs output neural network head pan estimation 
bayes formula decomposed foc ti xs xs foc ti foc ti xs xs denotes head pan person degrees ti persons table 
order compute xs necessary estimate class conditional probability density function xs class prior xs person 
finding xs trivial done just building histogram observed head orientations person time 
order adapt parameters model varying target locations different head turning styles participants developed unsupervised learning approach find head pan distributions participant looking 
approach assume class conditional head pan distributions modeled gaussian distributions 
distribution head pan observations person result mixture gaussians individual component densities gaussian distributions nj 
number gaussians set number participants detected table 
parameters mixture model adapted maximize likelihood pan observations mixture model em algorithm details see 
initialize means mixture model means clustering performed pan observations 
parameters iteratively updated follows adaptation mixture model individual gaussian components approximation meeting avg 
accuracy table 
correctly assigned focus targets head pan percent class conditionals focus focus attention model described equation 
furthermore priors mixture model focus priors focus 
assign individual gaussian components priors corresponding target persons relative position participants table 
shows example adaptation pan observations user 
mixture gaussian distribution adapted distribution head pan observations user fig 

depicts components mixture model 
comparison real head pan distributions shown 
depicts resulting posterior distributions 
experimental results evaluated approach meetings recorded 
meetings participants sitting table discussing freely chosen topic 
video captured panoramic camera audio recorded microphones 
frame manually labeled participant looking 
labels left right straight meaning person looking person left right person opposite 
person wasn looking targets person looking table staring ceiling label assigned 
addition labels indicating person speaking manually assigned participant video frame 
table shows evaluation results recorded meetings 
table average accuracy participants meeting indicated 
evaluation faces participants automatically tracked 
head pan computed neural network system estimate head orientation 
meeting participants class conditional head pan distribution focus class priors focus observation distributions adapted described previous section posterior probabilities focus ti person computed 
evaluation target highest posterior probability chosen focus attention target person frame 
evaluation manually marked frames subject face occluded face correctly tracked 
frames evaluation 
face occlusion occurred captured images 
occlusion happened user covered face arms coffee mug example face occluded posts camera 
frames face correctly tracked 
frames subject look persons table 
happened frames 
frames evaluation indications 
head pose versus eye gaze head orientation predict person focus attention meetings 
done head orientation assumed reliable indicator direction attention social interaction eye gaze meeting participants easily tracked intrusive hardware 
estimate person looking head orientation question suggests predict person looking merely basis head orientation 
answer question analyzed gaze people meetings special hardware equipment measure eye gaze head orientation 
analyzed gaze head orientation data people answer questions 
head orientation contribute gaze 

accurately predict person looking head orientation 
data collection setting experiments round table meeting 
participants meeting session data minutes participant collected 
session participants subject wears head mounted gaze tracking system system estimate record data frame rate hz subject head position head orientation eye orientation pupil diameter gaze line sight direction 
estimations precision better degree 
head mounted gaze tracker 

participant wearing head mounted eye head tracking system 
contribution head orientation gaze analyzed contribution head orientation eye orientation gaze direction horizontal axis 
data participants frames head orientation eye gaze pointed direction left right 
frames calculated contribution head orientation line sight orientation 
horizontal component line sight sum horizontal head orientation horizontal eye orientation percentage head orientation horizontal direction gaze computed head contribution table summarizes results experiment sessions 
results see interesting points time subjects rotate heads eyes direction look focus attention target 
subjects vary usage head orientation change gaze direction subject subject average 
subject head contribution participants head orientation contributes half gaze direction 
eye blinks eye tracking failures take frames means commercial accurate system eye orientation gaze direction obtained fifth time 
subject eye blinks direct 
head contrib 
average table 
eye blinks contribution head orientation gaze 
samples los az gaze direction degrees samples los az gaze direction degrees 
histograms horizontal gaze directions subjects 
predicting gaze target head orientation approached second question proposed particular meeting application accurately predict subject looking basis head orientation 
answering question gives idea upper limit accuracy obtained focus attention target estimated head orientation 
labeling gaze direction automatically determine target person subject looking focus attention gaze direction 
shows histograms horizontal gaze direction participants 
histograms seen peaks 
assume belong direction participants table sitting 
automatically determined peaks horizontal line sight means algorithm 
peaks directions persons sitting frame focus attention labels assigned distance actual horizontal line sight target directions 
prediction results see accurate focus target estimated observing head orientation exactly method find focus targets described section 
difference previous experiment focus determined noisy head pan estimates neural networks focus targets accurate head pan measurements gaze tracking equipment 
subject avg 
accuracy table 
focus detection exact measurements horizontal head orientation percent 
table summarizes results participants 
results show focus attention target correctly estimated head orientation data subject subject frames average 
seen upper limit accuracy get head orientation focus attention estimation scenario 
results show head orientation reliable cue detecting participants look meetings 
predicting focus sound attention clearly influenced external stimuli noises movements speech persons 
monitoring cues help bias certain targets interests 
focus attention correlated speaking meeting possible estimate person focus attention information talking moment 
experiment predict focus sound speakers analyzed participants recorded meetings looking certain speaking conditions 
speaking treated binary vector participants labeled speaking speaking video frame 
binary speaking vector having participants exist possible speaking conditions frame ranging participants speaking participants speaking 
speaker labels sound focus prediction able predict correct focus participant time evaluation meetings 
temporal speaker information predict focus investigated prediction focus attention benefit temporal speaker information 
trained neural networks estimate target person subject looking history audio observations input 
neural net consists input layer input units corresponding audio observation vectors hidden layer output units corresponding target persons subject look 
audio observations time step binary audio observation vectors described previous section chosen 
output representation representation training output corresponding correct target class set output units set zero 
error criterion commonly mean square error criterion 
training network approximate posteriori probabilities focus targets fi sequence observed focus 

sound focus prediction results different audio history lengths different number hidden units 
shows average sound focus prediction results evaluation meetings different histories audio vectors input networks different amounts hidden units 
best accuracy 
achieved hidden units history audio vectors corresponding approximately seconds audio information 
please refer details 
combining head pose sound predict focus independent predictions person focus focus sound focus combined obtain prediction person focus observation speaking person head rotation 
combined predictions computing weighted sum modalities focus focus head pose focus sound 
setting achieved average accuracy recorded meetings 
table summarizes results obtained sound focus prediction head orientation focus estimation combined estimation 
head pose sound combined meeting meeting meeting meeting average table 
focus prediction results percent 
combination head pose sound prediction done heuristically choosing weighting parameter expect advanced adaptive fusion methods better combination results obtained 
portability system section discuss system focus attention tracking installed new location 
main problem installing system new location illumination conditions new location completely different conditions training data neural networks head orientation estimation collected 
investigate steps necessary successfully move focus attention tracking system new location installed system labs universit karlsruhe germany carnegie mellon university pittsburgh usa 
remainder section report experiments neural network head pan estimation adapted new conditions 
examine adaptation data necessary obtain reasonable focus attention tracking performance compare results adapted networks results obtained neural networks trained scratch new data 
data collection cmu order train neural networks head pan estimation new location collected training images twelve users lab cmu new location 
data collection karlsruhe subjects wear head band polhemus pose tracker sensor attached true head pose determined 
images person head captured omni directional camera described section recorded person head pose 
person collected training images locations meeting table 
data collection took fifteen minutes participant 
altogether collected training images twelve persons 
training new networks scratch trained neural networks head pan estimation data collected cmu 
see training data necessary reasonable generalization trained different networks increasing subsets data 
evaluate performance networks data subjects kept aside user independent test set 
trained networks images subjects training set 
neural network architecture training identical networks trained data karlsruhe 
networks trained training data set cross evaluation set determine number training iterations 
shows results obtained user independent test set cmu top curve 
seen average pan estimation error test set high degrees images subject training 
pan estimation error gradually decreases training images subjects average error degrees cmu uka weights adapted training data persons 
pan estimation results new location newly trained adapted network see text 
added 
subjects training average pan estimation error degrees obtained 
trained neural network images available twelve subjects 
training images 
images remaining images test set 
multi user network pan estimation achieved average error degrees test set 
adapting trained network investigated network previously trained data collected karlsruhe uka network adapted new cmu images different training data sets cmu adaptation 
adapted uka network retraining weights different adaptation data sets cmu 
training done standard back propagation learning parameter 
determine adaptation process cross evaluation set containing images additional subject 
typically adaptation stopped iterations 
adapted uka net images subjects cmu training set 
performance adapted networks evaluated cmu 
results shown lower curve 
unadapted uka network average error degrees obtained test set 
images subject cmu adaptation average error decreases degrees 
training data subjects adaptation average pan estimation error decreases degrees 
seen pan estimation works significantly better adapted networks little data available training adaptation 
experiments newly trained network reached performance adapted uka network training images subjects available training 
correct foa upper limit unsupervised uka net uka uka uka uka cmu net network 
accuracy focus attention detection meeting recorded cmu see text 
focus attention detection results measure focus attention estimated different neural networks collected meeting participants lab cmu 
focus attention tracking system run recorded meeting different networks pan estimation 
evaluation unadapted adapted uka networks neural network trained images twelve subjects data set cmu 
network evaluated focus attention detection accuracy mixture gaussian approach chapter 
parameters gaussian mixture model adapted completely unsupervised 
shows focus attention detection accuracy meeting recorded cmu different networks head pan estimation 
uka network head pan estimation focus attention detected time meeting possible upper limit 
adapting uka network data collected cmu performance increases focus attention detection accuracy images subjects adaptation set uka 
performance performance obtained cmu network trained images twelve subjects collected cmu 
discussion experiments suggest network trained estimate head pan images taken location adapted new location different illumination conditions collecting limited number images new location adapting networks weights new images 
experiments achieved focus attention tracking results new location adaptation images subjects 
images collected approximately hour 
experiments showed adapting existing network pan estimation trained images taken different lighting cam era conditions leads better pan estimation results training networks scratch images new location small amount training images available 
system track focus attention participants meeting 
participants simultaneously tracked panoramic view head poses estimated neural networks 
participant probability distributions looking participants estimated head orientations unsupervised learning approach 
distributions predict focus attention head pose 
accuracy predication accurate detecting participants focus attention test data 
furthermore demonstrated focus attention predicted knowledge currently speaking audio prediction improved history utterances account 
recorded meetings participants focus attention predicted correctly frames audio information 
addition shown audio video predictions fused get accurate robust estimation participants focus attention 
head pose sound focus attention detected frames recorded meetings 
answer precisely focus attention predicted meeting just participants head orientations recorded eye gaze head orientations subjects meeting 
user study clearly demonstrated head orientation reliable cue detect attending 
meetings recorded study able correctly determine subject looking time just subject head orientation 
investigated neural network head pan estimation adapted new location 
experiments showed adaptation images subjects sufficient achieve focus attention detection accuracy new location completely different illumination conditions 
acknowledgments everybody interactive systems labs carnegie mellon university karlsruhe great support years 
special helped organizing meetings data collection sessions cmu everybody participated sessions 
abowd atkeson feinstein kooper long sawhney tani 
teaching learning multimedia authoring classroom project 
proceedings acm multimedia conference pages november 
argyle 
social interaction 
methuen london 
argyle cook 
gaze mutual gaze 
cambridge university press 
barber 
perception information chapter information acquisition 
methuen london 
black jepson newman saund taylor 
digital office overview 
proceedings aaai spring symposium intelligent environments volume aaai technical report ss 
aaai aaai press march 
brumitt krumm meyers shafer 
light comparing interfaces homes 
ieee personal communications august 
chiu wilcox 
room rear view meeting capture multimedia conference room 
ieee multimedia magazine oct dec 
emery 
eyes function evolution social gaze 
neuroscience reviews 
nielsen 
eye controlled media state 
technical report university copenhagen www diku dk users panic 
isc 
www com 
maglio campbell zhai smith 
gaze speech attentive user interfaces 
proceedings international conference multimodal interfaces volume lncs 
springer 
mozer 
neural network house environment adapts inhabitants 
intelligent environments papers aaai spring symposium number technical report ss pages 
aaai aaai press 
stiefelhagen yang waibel 
simultaneous tracking head poses panoramic view 
international conference pattern recognition volume pages september 
stiefelhagen yang waibel 
estimating focus attention gaze sound 
workshop perceptive user interfaces pui orlando florida november 
stiefelhagen yang waibel 
modeling focus attention meeting indexing multiple cues 
ieee transactions neural networks 
special issue intelligent multimedia processing july 
stiefelhagen zhu 
head orientation gaze direction meetings 
conference human factors computing systems chi minneapolis april 
von 
role orienting behaviour human interaction 
editor environmental space behaviour 
plenum press new york 
waibel finke stiefelhagen 
meeting browser tracking summarizing meetings 
penrose editor proceedings broadcast news transcription understanding workshop pages virginia february 

darpa morgan kaufmann 

eye movements perception complex objects 
editor eye movements vision pages 
plenum press new york 
