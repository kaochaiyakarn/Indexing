automatically generating custom instruction set extensions nathan clark umich edu tang umich edu advanced computer architecture lab department electrical engineering computer science university michigan ann arbor mi general purpose processors utilized cores incapable achieving challenging cost performance power demands high performance audio video networking applications 
meet demands systems employ number hardware accelerators load computationally demanding portions application 
alternative strategy examine customizing computation capabilities core processor particular application 
goal enable computation loaded accelerators taken customized core 
computation capabilities core processor extended hardware form set custom function units new instructions 
compiler responsible analyzing target application identifying set cost effective custom function units 
provide overview system developing automatically identify instruction set extensions report preliminary analysis media benchmarks 

years markets pdas cellular phones digital cameras network routers high performance special purpose devices grown 
devices perform computationally demanding processing images sound video packet streams 
systems application specific hardware design meet challenging cost performance power demands 
popular design strategy build system consisting number special purpose asics coupled low cost core processor arm 
asics specially designed hardware accelerators execute computationally demanding portions application run slowly implemented core processor 
approach effective asics costly design offer hardwired solution permits 
alternative design strategy augment core processor special purpose hardware increase computational capabilities cost effective manner 
instruction set core processor extended feature additional set operations 
hardware support added execute operations form new function units processor sub scott mahlke mahlke umich edu systems 
couple benefits approach 
system tolerate changes application 
degree application change arbitrary intent customized processor achieve similar performance levels modest changes application bug fixes incremental modifications standard 
second asics unnecessary augmented core achieve desired level performance 
lowers cost system design time 
key questions approach augmented core achieve desired level performance design efficient set extensions processor core 
focus question goal define set instruction set extensions accelerate target application cost effective manner 
process time consuming expensive designing asic done manually believe automation key making strategy successful 
approach compiler identify critical computation subgraphs application 
subgraphs analyzed determine desirability specialized hardware accelerate 
number issues considered determine desirability including estimated performance gain estimated cost custom hardware encoding new operation core processors instruction format expected usability custom hardware 
data place set hardware extensions processor selected compiler generates code selected subgraphs replaced new instructions 
presents progress customized processor design system developed university michigan 
focus issues associated designing application specific instruction set extensions give overview current system 
case studies embedded applications illustrate cost performance tradeoffs augmenting core processor 
related large body research gone automatic design instruction sets 
earliest focused generating cisc instructions effectively support high level languages increase code density 
efficient algorithms instruction selection processors cisc instructions proposed 
high level sis systems address issue automatically designing specialized datapaths suit application 
instruction set synthesis identifies best instruction set fixed datapath 
asia system extends previous integrate instruction set synthesis code generation :10.1.1.54.7637
custom instructions common reconfigurable computing 
large functional blocks identified mapped reconfigurable hardware prism garp systems 
fine grained approach taken prisc disc projects smaller units identified reconfigurable hardware utilized specialized function units 
systems propose automated design application specific vliw processors 
systems focus customizing function unit mixture cache subsystem instruction format fetch decode path 
specific example vliw application specific processor targeted security domain achieves performance gain utilizing specialized instructions 
previous area compiler identification custom instructions looked sequences operations suitable chaining 
large set potential operations identified compiler analysis 
instruction scheduler final chaining decisions 
probably similar arnold investigated application specific instruction set extensions move architecture 
identified commonly occurring operation patterns created specialized function units generated code new function units 
differs arnold consider generalized subgraphs compiler driven approach trace driven approach examine cost performance tradeoffs involved selecting custom instructions 

customization issues loosely define custom function unit cfu hardware implementation set primitive operations connected dataflow graph 
primitive operations assembly operations generic risc architecture add load 
assumptions regarding connection graph nodes linear tree shaped cyclic graphs implemented custom function units 
disconnected graphs considered 
primitive operation values associated delay cost io format identify candidate cfus 
delay propagation time longest path preferred hardware realization opcode 
operation delays summed combined clock frequency determine estimate latency cfu terms clock cycles 
cost area estimate hardware cell implements opcode 
lastly io format input output requirements restrictions source destination operands opcode 
selecting set cfus application engineering problem important balance trade offs 
characterize trade offs associated cfus categories performance cost io requirements usability 
section discuss trade offs illustrate example dataflow graph dfg 
example contrived similar dataflow graphs saw encryption benchmarks 
performance compelling reason adding cfus processor potential increased performance 
realization performance gain determined factors 
implementation dfg cfu require fewer cycles primitive operations executed individually 
problem operations hardware implementation simple 
instance logical operations level logic trivial chain cycle meet timing constraints 
arithmetic operations strong candidates chaining processor cycle times constrained alu speed 
second factor occur achieve performance gain critical dependence path target code block reduced cfus 
cfus reduce non critical portions code little effect performance 
important consideration processors exploit instruction level parallelism 
assuming node latency cycle dfg takes minimum cycles execute critical dependence path nodes 
consider creating cfu nodes 
poor choice graph take cycles execute nodes critical path 
variable bit shifts node typically large delays barrel complicated hardware cells 
result cfu nodes reduce cycle latency required just execute primitive operations 
better cfu choice nodes 
subgraph ideal performance perspective occurs critical path constituent operations relatively simple subtract shift constant logical 
highly reduce cycle subgraph cycle cfu 
important issue consider cfu selection process cfu selected critical path potentially change 
example instantiated cfus able execute cycle critical path change go nodes 
attempt create new cfus patterns old critical path fruitless take cycles execute code 
cost consider cost die area impact processor adding cfu 
metric sum area cfu additional inter connect control logic impact decode logic change register file area support cfu 
register file cost increases amortized multiple cfus difficult measure impact decode control logic 
simplifying assumption cfu area dominant term equation 
estimated code cfu sum hardware implementation costs primitive operation comprises cfu 
goal respect cost maximize design constraints cost 
selecting cfus pat lsl lsl reg sub reg xor add sub xor output terns contain inexpensive operations ideal candidates 
custom opcodes example logical operations shift constant require area 
compare cost implementing custom opcode expensive barrel shifter node easy pick cfu better implement assuming give speedup optimizing performance 
io requirements io requirement cfu number inputs outputs needed cfu 
property ramifications areas 
instructions large number inputs outputs difficult represent conventional instruction set number bits necessary encode large number sources destinations 
processor fetch decode paths may capable handling new instruction format differs greatly baseline instruction formats 
large numbers inputs outputs may require increased number ports register file 
cost register files increase square number ports major impact cost processor 
lastly operation graphs want generate cfus identical number inputs outputs necessary decide want create separate cfus cfu maximum inputs maximum outputs instances 
example pick custom opcode custom op lsl example dataflow graph 
custom opcode reg output reg custom opcode output output custom opcode code custom opcode inputs outputs custom opcode inputs output 
decision implement single cfu inputs outputs implement separately 
case probably sense create cfu custom opcode inputs 
implement custom opcode number inputs outputs increase probably add ports register file support custom opcode 
encoding sources destinations instruction may prohibitive cost possible considered 
usability difficult issues quantify usability cfu 
usability refers degree compiler recognize candidate subgraphs execute cfu 
issue important striving system cfu utilized similar applications generations analyzed application 
usability generally inverse relationship size regularity dfg 
larger irregular cfus difficult compiler 
usability concerns counterbalance performance concerns 
performance angle large subgraphs desirable offer best potential speedup 
ability collapse nodes single cfu leads largest reductions critical path length 
code segment execute efficiently entire subgraph converted cfu selecting custom opcode cfu 
finding repeated occurrences subgraph difficult task compiler due complexity 
larger subgraphs susceptible small source code changes obsolete carefully designed cfu 
example node converted add multiply new version algorithm cfu custom opcode worthless 
current system empirically seen indication usability cfu utilization 
cfu effectively target application poor choice cfu 
obviously easy find exceptions behavior investigating precise ways quantify usability 

case studies ran benchmarks automated cfu generation system demonstrate potential performance gains application specific processor achieve cfus 
benchmarks part mediabench program suite 
encode implementation ccitt international telegraph telephone committee voice compression algorithms 
audio part adpcm family speech compression algorithms 
ad pcm algorithms complicated ones convert bit linear pcm samples bit samples 
djpeg benchmark utility jpeg format image decompression 
final benchmark encryption algorithm part suite 
blowfish symmetric block cipher meant alternative des idea 
benchmarks computationally intense spend execution time small number usually functions prime candidates cfus 
cfu generation system infancy focus section types cfus generated selected deal potential cfus application specific processors 
despite address point briefly 
expect add load add store commonly generated cfus prominence base plus displacement memory accesses 
add followed compare instruction fairly common 
cfus generated obvious 
example cfu generated blowfish chain operations add xor add xor shift constant add shift constant add 
chain inputs outputs occurred unique locations blowfish dfg 
accounted cycles critical path 
operations compressed cycles timing models potentially yield tremendous speedup 
clearly naive pattern recognition system cfus yield major performance benefits 
experiments show speedup baseline machine plus cfus compared baseline machine 
baseline machine wide pipelined vliw machine predication support single cycle cache latency mhz clock 
necessary assume clock speed order determine cycles cfu need execute 
baseline machine issue integer floating point memory branch instruction cycle benchmarks integer essentially issue machine 
assumption cfus add parallelism baseline machine cfus integer execution slot compete register ports instructions machine 
convincing argument integer execution slot cfus add load increasing parallelism machine second memory unit integer issue slot 
benchmarks experimented tended computationally bound memory bound memory issue slot type cfu difference measured speedups 
difference memory issue slot tended improve measured speedup slightly 
performance benchmarks measured multiplying profile weights basic block number cycles takes execute block summing number cycles entire program 
shows results set benchmarks 
left graphs vary maximum number operations allowed cfu allowing generation unlimited number unique cfus 
right graphs vary number cfu generated allowing number operations length 
cost cfus speedup program represented curves graph 
idea take away left graphs increase maximum number operations allowed cfu speedup generally increases 
occurs opportunities combine operations single cycle 
certain point diminishing return cost decrease speedup encode number operations large 
results combine instance operation particular cfu longer execute operation different 
words select large cfu away opportunity group constituent operations operations part cfu 
tradeoff generating large cfu versus smaller ones 
speedup decreases cfu selection algorithm described section incorrectly chooses large cfu smaller cfus better choice 
right graphs demonstrate obvious fact increase number cfus system performance increases 
important point graphs note performance increases 
direct measure quality cfu selection algorithm 
ideally select cfus want select set gave best speedup 
biggest leaps performance speedup occur cfus selected see selection algorithm needs 
interesting fact note right set graphs djpeg see incredibly large speedup went relative speedup cost varying maximum operations allowed cfu number cfus allowed application 
cost measured relative area bit ripple carry adder 
large number cfus 
occurred djpeg smaller cfus benchmarks got greatest speedups large cfus 

system goal system automate process selecting synthesizing cfus application specific processor 
accomplished stages diagrammed 
section describes current functionality cfu discovery selection process steps envision system going 
compilation synthesis steps process scope 
step initial step cfu generation custom opcode pattern recognition get idea cfus potentially useful 
experiments take profiled assembly language program hpl pd instruction set input 
program construct dataflow graph initialize set custom opcode patterns individual operation 
pattern recognition techniques broke assembly code termed micro ops pattern recognition unnecessary situation hpl pd primitives sufficiently simple build hardware :10.1.1.54.7637
complex instruction set case 
initialization recursively expand custom opcode patterns dataflow edges depth manner 
example start node add new pattern nodes nodes nodes nodes 
currently track data flow memory pointer chasing code difficult certainly possible memory accesses done arrays 
optimization left potential improvement 
depth expansion terminates data flow edges operation reach store instruction destination data flow edge branch destination load branch dataflow edge source destination operations 
terminating load instructions done non deterministic latency memory system impossible determine operations done result load meeting cycle time limitations 
branch instructions cause termination expansion branch intermediate operands conditionally 
instruction result feeds second instruction side branch may need write result instruction register file second instruction executed 
exposing intermediate results outputs cfu potentially cause register porting requirements unwieldy reduction register pressure gained having write intermediate results register file 
regardless fact operations cfu spanned branches necessary add control cfu conditionally execute operations happened side branch 
terminating custom opcodes branch boundaries differentiates approaches pattern matching execution trace control flow graph 
limitation current pattern recognition algorithm currently looking straight line chains operations intermediate result forwarded operation cfu generate 
restriction completely artificial plan remove 
concrete restriction system recognize patterns start single node 
restriction artifact starting pattern single node growing depth search 
see weakness algorithm 
discussed section ideally cfus generate inputs requiring single starting operation way artificially push solutions direction 
step pattern recognition comes cfu characterization phase get general idea cfu potential utilization application register port requirements cost measured die area timing power characteristics 
rough idea cfu utilization garnered execution profile weights operations form custom opcode pattern control flow graph 
determine characteristics need generate hardware 
cost timing power characteristics primitive operations hpl pd instruction set stored external library fed system 
synthesized synopsis design compiler component library typical micron process currently characteristics cfu defined sum characteristics constituents add custom latency add primitive followed primitive empirical evidence shows overly pessimistic 
performance results definitely 
step characteristics cfus generated send filter function removes bad candidates 
candidate considered bad potential reasons including limited unreasonable register port requirements combining operations yield cycle time decrease potential utilization cfu low encoding instruction isa require bits 
implementation filter cfus occurrences critical path initial control flow graph 
restriction potentially results implementing cfu cause path critical 
potentially reduced length new critical path filtered cfus 
step filtering performed select cfus implement 
selection fairly straight forward function characteristics mentioned 
example potentially select cfus give biggest speedup cost ones improve energy delay product 
experiments greedy algorithm select cfus greatest potential speedup measured product number stances custom opcode pattern critical path number cycles gained combining primitive operations cfu die area 
words best performance improvement cost 
output functionality selected cfus translated hardware intermediate language level description cfu functionality 
simulator uses level descriptions model cfu functionally behave execute 
hardware intermediate language synthesizer create hardware description language hdl code processor cfus 
addition hdl synthesizer generates machine description processor fed back retargetable compiler 
compile customized machine graph matching algorithm described construct potential candidates 
candidates compared graphs specified machine description matches replaced custom opcodes final program 
technique allows take advantage cfus intrusion compiler code generation algorithm 

currently cfu generation system recognizes generates cfus linear acyclic graphs 
vision extend system recognize general acyclic graphs exotic structures simple cyclic subgraphs 
example application looked spent considerable amount time loop simply counting number bits set integer 
loop prime candidate replacement single cfu easily implement functionality simple combinational logic 
adding residual state cfus plan investigate 
cfus utilized loop bodies result fed back input loop iteration 
cfu design flow cfu generation system 
remember result computed need communicate value register file 
final improvement looking better selection algorithms 
graphs section clear current greedy selection method leaves desired 
shown naive graph recognition techniques large speedups high possible automatically designed custom function units 
technology provides engineers quick cost effective way meet increasing demand computational resources embedded spaces 

bose davidson design instruction set support high level languages proceedings th annual international symposium computer architecture june 
bennett methodology automated design computer instruction sets 
phd thesis university cambridge 
liao devadas tjiang instruction selection covering code size optimization international conference computer aided design pp 

leupers marwedel instruction selection embedded dsps complex instructions design automation conference sept 
man accelerator data path synthesis high throughput signal processing applications 
boston ma kluwer academic publishers 
holmer automatic design computer instruction sets 
phd thesis university california berkeley 
huang synthesis instruction sets microarchitectures :10.1.1.54.7637
phd thesis university southern california 
athanas silverman processor reconfiguration instruction set metamorphosis ieee computer vol 

hauser wawrzynek garp mips processor reconfigurable coprocessor symposium fpgas custom computing machines apr 
smith high performance microarchitecture hardware programmable function units proceedings th annual international symposium microarchitecture pp 
nov dec 
hutchings disc dynamic instruction set computer field programmable gate arrays fast board development reconfigurable computing pp 

fisher custom fit processors letting applications define architectures proceedings th annual international symposium microarchitecture pp 
dec 
aditya rau automatic architecture synthesis compiler retargeting vliw epic processors tech 
rep hpl hp laboratories 
wu weaver austin fast flexible architecture secure communication proceedings th annual international symposium computer architecture pp 
june 
onion nicolau dutt compiler feedback asip design tech 
rep university california irvine sept 
aditya cycle time aware architecture synthesis custom hardware accelerators proceedings international conference compilers architecture synthesis embedded systems oct 
arnold instruction set extensions embedded processors 
phd thesis delft university technology 
lee potkonjak mangione smith mediabench tool evaluating synthesizing multimedia communications systems proceedings th annual international symposium microarchitecture dec 
ernst austin mudge brown free commercially representative embedded benchmark suite ieee th annual workshop workload characterization dec 
schlansker rau hpl architecture specification version tech 
rep hpl hewlett packard laboratories feb 
