manuscript 
inserted editor comprehensive survey fitness approximation evolutionary computation jin honda research institute europe main germany email jin honda ri de date receipt acceptance inserted editor evolutionary algorithms eas received increasing interests academy industry 
main diculty applying eas real world applications eas usually need large number tness evaluations satisfying result obtained 
tness evaluations straightforward real world applications 
explicit tness function exist evaluation tness computationally expensive 
cases necessary estimate tness function constructing approximate model 
comprehensive survey research tness approximation evolutionary computation 
main issues approximation levels approximate model management schemes model construction techniques reviewed 
conclude open questions interesting issues eld discussed 
keywords evolutionary computation tness approximation meta model optimization evolutionary computation wide range applications various elds science engineering 
evolutionary algorithms proved powerful global optimizers 
generally evolutionary algorithms outperform conventional optimization algorithms problems discontinuous non di erential multi modal noisy de ned problems art design music composition experimental designs 
evolutionary algorithms suitable multi criteria problems 
despite great successes achieved real world applications evolutionary algorithms encountered challenges 
evolutionary algorithms large number tness evaluations performance calculations needed acceptable solution 
real world applications tness evaluation trivial 
situations tness evaluation dicult computationally ecient approximations tness function adopted 
issues need addressed employing tness approximations evolutionary computation 
levels tness approximation 
experimental veri cation seen true tness value solution fully computational simulations simpli ed computational simulations functional approximations meta models tness calculation 
far models tness approximation 
popular ones polynomials known response surface methodology kriging model popular design analysis computer experiments feedforward neural networks including multi layer perceptrons radial basis function networks support vector machines 
due lack data high dimensionality input space dicult obtain perfect global functional approximation original tness function 
tackle problem main measures taken 
firstly approximate model original tness jin function 
cases original tness function available computationally expensive 
important original tness function eciently 
known model management conventional optimization evolution control evolutionary computation 
secondly quality approximate model improved possible limited number data 
aspects important improve model quality selection model active data sampling weighting line line selection training method selection error measures 
tness approximation evolutionary computation distributed di erent areas 
survey aims provide readers comprehensive picture tness approximation evolutionary computation 
section di erent motivations approximation evolutionary computation 
section major levels approximation problem approximation functional approximation evolutionary approximation 
di erent approaches incorporation tness approximations described section 
main functional approximation models tness approximation introduced section 
data sampling techniques important quality models section 
open questions promising research topics discussed section 
motivations far approximation tness function evolutionary computation applied mainly cases 
computation tness extremely timeconsuming 
example structural design optimization 
aerodynamic design optimization necessary carry computational uid dynamics cfd simulations evaluate performance structure 
cfd simulation usually computationally expensive especially simulation dimensional takes hours high performance computer calculation 
approximate models widely structure optimization 
fitness approximation reported protein structure prediction evolutionary algorithms 
neural network feature extraction amino acid sequence evolutionary protein design drug design 
explicit model tness computation 
situations art design music composition areas industrial design evaluation tness depends human user 
generally problems addressed interactive evolutionary computation 
human user easily get tired approximate model embodies opinions human evaluator helpful 
environment evolutionary algorithm noisy 
usually methods deal noisy tness functions 
rst sample tness times average 
method requires large number additional tness evaluations 
second method calculate tness individual averaging value individual individuals neighborhood 
avoid additional computational cost individuals participate averaging chosen current previous generations 
exible alternative estimate tness individuals neighborhood statistical model constructed history data 
tness landscape multi modal 
basic assumption global model constructed approximate local optima original multi modal tness function changing global optimum location 
gaussian kernel realize coarse ne smoothing original multi modal function 
approximation smoothing multi modal functions reported global polynomial models gaussian kernel functions 
note generally dicult build approximate model global optimum location 
coarse ne modeling approach realistic 
comprehensive survey fitness approximation evolutionary computation levels approximation concept approximation optimization new 
traditionally basic approaches functional approximation problem approximation 
additionally special approximation techniques evolutionary tness evaluation suggested 
problem approximation 
problem approximation tries replace original statement problem approximately original problem easier solve 
example evaluate performance turbine blade wind tunnel experiments need carried 
computational uid dynamics cfd simulations wind tunnel experiments evaluate performance blade design 
cfd simulations uid dynamics described dimensional navier stokes equations turbulence model 
viscosity mass diffusion thermal conductivity ow neglected ow dynamics described dimensional euler equations 
euler equations computationally ecient solve navier stokes equations 
certain conditions ow eld solved computations known quasi solvers computationally ecient 
course ad hoc methods developed 
example random sampling complete sampling solving image registration problems genetic algorithms 
example reported tness approximation studied terms discretization 
functional approximation 
functional approximation alternate explicit expression constructed objective function evolutionary computation usually called tness function 
take blade design example evaluating performance cfd simulations explicit mathematical model constructed inputs outs blade geometry blade performance respectively 
evolutionary approximation 
type approximation speci evolutionary algorithms 
popular class evolutionary approximation methods known tness inheritance 
methods tness evaluations spared estimating tness value spring individuals tness value parents 
second class tness approximation individuals clustered groups 
individual represents cluster evaluated tness function 
tness value individuals cluster estimated representative individual distance measure 
term tness imitation contrast tness inheritance 
incorporation approximate fitness models incorporation mechanisms incorporation approximate models constructed history data evolutionary computation seen methods incorporating knowledge evolutionary systems 
interestingly approximate models embedded element evolutionary algorithms including migration initialization recombination mutation tness evaluations 
approximate tness evaluations migration 
island model architecture proposed incorporate information approximate models speed evolutionary algorithm illustrated fig 

seen sub population introduced level approximation 
usually population evolves separately level approximation 
certain frequency individuals sub populations uses higher accuracy approximations migrated approximations lower accuracy 
extension architecture suggested individuals migrate sub populations approximations higher accuracy sub populations approximate models lower accuracy vise versa fig 

approximate tness models initializing population guiding crossover mutation 
approximate models population initialization guidance genetic operators directly tness evaluations believed jin migration direction medium accuracy accuracy highest accuracy fig 
island model parallel ga incorporating approximate tness models 
gure large circle means sub population small circles denote individuals tness function highest accuracy rectangles denote individuals models medium accuracy triangles individuals models lowest accuracy 
migration direction medium accuracy accuracy highest accuracy fig 
hierarchical ga incorporating approximate tness models 
reduce risk misleading search direction approximate models 
reason initialization crossover mutation usually carried randomly 
initializations genetic operations guided approximate model lower accuracy usually better randomly 
reduction tness evaluations may signi cant 
approximate tness models tness evaluations 
research approximate model directly tness evaluations order reduce number tness calculation 
di erent approximate models including polynomials kriging models neural networks applied 
interesting idea con dence interval tness estimation calculated modify model prediction search unexplored regions encouraged 
strategy leads better performance especially original tness function multimodal 
approximate tness evaluations employed evolutionary multiobjective optimization 
model management evolution control approaches incorporating approximate models approximate models tness evaluations may reduce number tness evaluations signi cantly 
application approximation models evolutionary computation straightforward may expect 
major concerns approximate models tness evaluation 
ensured evolutionary algorithm converges global optimum near optimum original tness function 
second computational cost reduced possible 
essential point dicult construct approximate model globally correct due high dimensionality ill distribution limited number training samples 
approximate model tness evaluation evolutionary algorithm converge false optimum 
false optimum optimum approximate model original tness function refer fig example 
false minimum fig 
example false minimum approximate model 
solid line denotes original tness function dashes line approximate model dots available samples 
essential cases approximate model original tness function 
regarded issue model management evolution control 
evolution control meant evolutionary computa comprehensive survey fitness approximation evolutionary computation tion approximate models original tness function evaluate individuals individuals generations 
individual evaluated original tness function called controlled individual 
similarly generation individual evaluated original tness function called controlled generation 
generally model management evolutionary computation divided main approaches viewpoint evolution control 
evolution control 
approximate model assumed high delity original tness function evolutionary computation 
fixed evolution control 
importance approximate model original function tness evaluation recognized 
generally approaches evolution control individual generation 
individual control meant generation individuals approximate model tness evaluation original function tness evaluation 
individual evolution control random strategy best strategy select individuals controlled 
best strategy best individual ranking evaluated approximate model current generation reevaluated original function see fig random strategy individuals controlled selected randomly 
shown best strategy shows reduce computational cost evolution control carried selected number generations 
contrast random strategy selects certain number individuals randomly reevaluation original tness function 
alternative best strategy random strategy evaluate mean individuals current population 
generation evolution control implemented 
generation evolution control carried evolutionary algorithm converges approximate model 
heuristically evolution control carried xed number generations see fig 

ind ind ind am am am ind ind am am ind ind ind am ind ind ind ind evolution process am am am generation model update model update model update generation generation fig 
best individual controlled generation 
am approximate model original function 
ind ind ind am am am ind ind am am ind ind ind am ind ind ind generation generation am am generation ind ind ind ind model update evolution process am am am am ind fig 
generation evolution control 
am approximate model original function 
drawback aforementioned methods frequency evolution control xed 
practical delity approximate model may vary signi cantly optimization 
fact prede ned evolution control frequency may cause strong oscillation optimization due large model errors observed 
adaptive evolution control 
straightforward imagine frequency evolution control depend delity approximate model 
method adjust frequency evolution control trust region framework suggested generation approach 
framework approximate model management suggested successfully applied dimensional aerodynamic design optimization see fig 

jin model quality estimation new data weight model update evolution control cycle am am am adaptation fig 
adaptive generation evolution control 
evolution control cycle generations generations controlled 
am approximate model original function 
approximation models polynomial models widely polynomial approximation model second order model form coecients estimated number terms quadratic model total number input variables 
estimate unknown coecients polynomial model square method lsm gradient method square method get unique estimation coecients lsm required number samples drawn original function equal larger number coecients 




equation holds lsm algorithm works follows denotes estimate 
assumption rows linearly independent 
gradient method main drawback square method computational expense unacceptable dimensionality increases 
address problem gradient method 
de ne square error function th sample de ned equation straightforward get update rule unknown coe cients 





kriging models kriging model seen combination global model plus localized deviation known function global model original function gaussian random function zero mean non zero covariance represents localized deviation global model 
usually polynomial cases reduced constant covariance expressed cov 
correlation function samples symmetric correlation matrix dimension values unity diagonal 
form correlation matrix selected user form exp jx unknown correlation parameters th component sample points comprehensive survey fitness approximation evolutionary computation prediction function unknown parameters :10.1.1.51.7990
estimated value samples current input estimated value vector length de ned eqn 
unit vector length correlation vector length input samples fx 

estimation parameters carried maximum likelihood method 
advantage kriging models con dence interval estimation obtained additional computational cost 
note necessary perform matrix inversions estimating output kriging model increases computational expense signi cantly dimensionality high 
neural networks neural networks shown ective tools function approximation 
feedforward multilayer perceptrons radial basis function networks widely 
multilayer perceptrons mlp input layer hidden layers output neuron described equation kl ik input number number hidden nodes 
called activation function usually logistic function az constant 
radial basis function networks theory radial basis function rbf networks tracked back interpolation problems 
rbf network single output expressed follows 
set radial basis functions 
usually euclidean norm samples 
centers radial basis function unknown coecients 
model expensive implement number samples large 
generalized rbf network practical main di erence number hidden nodes ordinarily smaller number samples centers basis functions unknown parameters learned 
usually output generalized rbf network normalized support vector machines theory support vector machines mainly inspired statistical learning theory 
major advantages support vector machines machine learning models neural networks local minima learning generalization error depend dimension space 
samples construction model reduced minimization regularized insensitive loss function jjwjj 
max fjy tolerable error regularization constant function estimated 
minimization equivalent constrained optimization problem minimize jjwjj 
subject 

quadratic programming techniques applied solve minimization problem 
jin comparative remarks papers compare performance di erent approximation models :10.1.1.25.7123
clear advantages disadvantages di erent approximation models drawn 
reasonable performance may depend problem addressed criterion needs considered 
important factors accuracy training data test data computational complexity transparency 
approximate model may introduce false optima performance training data refer fig 

harmful lower approximation accuracy model global optimization evolutionary optimization 
methods prevent neural network model generating false minima suggested ective lower dimensional problems 
general remarks di erent approximation models dicult provide explicit rules model selection 
firstly recommended implement rst simple approximate model problem example lower order polynomial model see samples reasonably 
simple model samples model higher complexity considered higher order polynomials neural network models 
input space design space high dimensional number samples limited neural network model preferred 
recalled estimate unknown parameters secondorder polynomial model data samples required 
model undetermined 
secondly neural network model particular multilayer perceptrons network necessary consider regulating model complexity avoid tting 
may necessary try cient training methods gradient descent method slow convergence 
rbf networks accuracy fast training studies 
data sampling techniques approximate model evolutionary computation line line training involved evolution controlled 
line learning denotes training process model evolutionary computation 
contract line learning denotes update model optimization 
usually samples line learning generated monte carlo method shown di erent research areas active selection samples improve model quality signi cantly 
line learning data selection strongly related search process 
line data sampling data sampling methods suggested elds design experiments statistics machine learning 
popular methods design experiments doe orthogonal arrays oa central composite designs ccd optimality widely design experiments 
rst order orthogonal design diagonal matrix extended sample array de ned eqn 

words columns mutually orthogonal 
central composite design enables ecient construction second order polynomial models 
basically rst order designs augmented star points obtained perturbing variable positive positive directions central point central point allow estimation coecients second order model 
example ccd designs fig 
twodimensional problem 
optimality takes advantage properties polynomial models data sampling 
accuracy square estimate eqn 
de ned var variance estimate error 
eqn 
seen improve quality maximize determinant optimality select samples way determinant comprehensive survey fitness approximation evolutionary computation fig 
central composite designs 
dots represent sample points 
samples solid lines rst order design dashed lines central star points 
maximized 
developed polynomial models optimality shown bene cial data selection constructing neural networks 
active learning active learning widely studied eld neural network learning 
basic idea select location sampling data way objective function optimized 
objective function information gain entropy reduction generalization error 
shown active data selection improve generalization ability neural networks increasing number training samples 
line data sampling active data selection important case training data collected target select subset data ecient training 
bagging boosting bagging boosting statistical learning methods developed improve quality approximate model bootstrap techniques 
bagging bootstrap aggregating number bootstrap models constructed di erent bootstrap samples nal output average models 
shown bagging able reduce variance estimate error eciently 
adaptive bagging technique reduce variance bias 
boosting algorithms able boost weak learning algorithm strong 
weak algorithm inaccurate rules thumb slightly better random guess 
main di erence boosting bagging boosting bootstrap samples ected performance current model 
addition nal output weighted average di erent models 
active data selection statistical active learning methods applied type data selection 
special case integrated mean square error called integrated squared bias criterion select subset available data improve learning performance 
assumed data noiseless 
data weighting guided evolution method weight available data information evolutionary algorithm suggested 
basic idea information search direction evolutionary algorithm available larger weight data samples located region evolutionary algorithm probably visit generation 
strategies data sampling studied 
example strategies best individuals replace worse ones training samples ones randomly selected 
strategies create new points randomly replace worst ones training samples 
strategy simply re evaluates best individuals best sense approximate model original tness function exhibits best performance 
best strategy individual evolution control 
discussions fitness approximation evolutionary computation research area attracted sucient attention evolutionary computation community 
points need clari ed theoretically unclear way evolutionary algorithm bene approximate jin model studies shown promising results approximate models evolutionary computation 
sense pointed approximate model prevent information history optimization lost approximate models create new information 
type models helps local global 
straightforward imagine global model able simplify search process approximate model change properties original tness function 
viewpoint modeling build local model feasible build global model 
local approximate models constructed local search lamarkian framework evolution 
ective way approximate models 
generally speaking incorporation approximate models migrations ecient mainly due fact models lower complexity false optima tness values higher correct computationally complex models migrations di erent subpopulations help sense 
contrast approximate models genetic operations lower requirement model quality theoretically approximate models help long prediction model better random guess 
unclear evaluations spared 
approximate models tness evaluation reduce number tness calculation ectively 
poor model quality degrade ciency lead false optima 
addition topics deserve research 
development learning algorithms ecient sensitive number training data 
learning problem class incorporation priori knowledge possible approaches 
preliminary study shown structurally optimized neural networks exhibit better performance fully connected neural networks tness approximation aerodynamic design optimization 
approximate model variable input dimension 
optimization input dimension may change cases 
example adaptive representation design optimization number parameters increases decreases optimization 
handle problems general nonlinear constraints 
optimization penalty term usually added object function constraints 
unfortunately samples containing large penalty value cause big diculties model training 
knowledge constraints extracted reused proper way directly incorporated approximate model 
management di erent levels approximation 
far functional approximation discussed 
di erent levels problem approximation applications 
example computational uid dynamics simulation equations navier stokes equations quasi simulations simulations di erent approximations original problem 
combining di erent levels approximation approximate model interesting 

albert goldberg 
ecient scheduling multiple dimensions 
proceedings genetic evolutionary computation conference pages 
morgan kaufmann 

anderson 
computational fluid dynamics basics applications 
mcgraw hill 

anderson hsu 
genetic crossover strategy approximation concept 
ieee congress evolutionary computation pages washington 
ieee 

barthelemy 
approximation concepts structural design review 
structural optimization 


genetic algorithm generating jazz 
proceedings international computer music conference pages 

bradshaw 
calculation compressible turbulent boundary layers comprehensive survey fitness approximation evolutionary computation straight tapered swept wings 
aiaa journal 


creating robust solutions means evolutionary algorithms 
proceedings parallel problem solving nature lecture notes computer science pages 
springer 

schmidt 
ecient tness estimation noisy environment 
spector editor proceedings genetic evolutionary computation pages san francisco ca july 
morgan kaufmann 

breiman 
bagging predictors 
machine learning 

breiman 
adaptive bagging regressions 
technical report dept statistics university california berkeley 

dennis frank sera ni torczon trosset 
rigorous framework optimization expensive functions surrogates 
structural optimization 

bull 
model evolutionary computation 
soft computing 

carpenter 
barthelemy 
comparison polynomial approximation arti cial neural nets response surface 
technical report aiaa 

carpenter 
barthelemy 
common misconceptions neural networks approximators 
journal computing civil engineering 


chen goldberg 
ho sastry 
fitness inheritance multi objective optimization 
proceedings genetic evolutionary computation conference 
morgan kaufmann 

mount campbell 
training data development optimality criterion 
ieee transactions neural networks 

dennis torczon 
managing approximate models optimization 
alexandrov editors multidisciplinary design optimization state art pages 
siam 

punch goodman 
evaluation injection island model ga performance design optimization 
third conference adaptive computing design manufacturing pages 
springer 

efron tibshirani 
bootstrap 
chapman hall 

el keane 
optimization multi level problems comparison various algorithms 
parmee editor proceedings third international conference adaptive computing design manufacture pages 
springer 

el nair keane 
metamodeling techniques evolutionary optimization computationally expensive problems promises limitations 
proceedings genetic evolutionary conference pages 

emmerich ack 
metamodel assisted evolution strategies 
parallel problem solving nature number lecture notes computer science pages 
springer 


minimal cost hybrid strategy pareto optimal front approximation 
evolutionary optimization 


neural network generalized response surface multiobjective evolutionary algorithms 
congress evolutionary computation pages 
ieee press 

fitzpatrick grefenstette 
genetic algorithms noisy environments 
machine learning 

freund 
boosting weak learning algorithm majority 
information computation 

emmerich 
low stochastic optimization engineering applications 
proceedings international conference evolutionary methods design optimization control applications industrial problems 

watson 
comparison approximation modeling techniques polynomial versus interpolating models 
technical report aiaa 
jin 
grefenstette fitzpatrick 
genetic search approximate tness evaluations 
proceedings international conference genetic algorithms applications pages 

pak 
optimal sizing geometrical topological design genetic algorithm 
structural optimization 

haftka scott cruz 
optimization experiments survey 
applied mechanics review 

jin structure optimization neural networks evolutionary design optimization 
gecco workshop approximation learning evolutionary computation pages 

evolutionary optimization problem classes lamarckian inheritance 
ieee symposium combinations evolutionary computation neural networks pages 

jin chen simpson 
comparative studies metamodeling techniques modeling criteria 
technical report aiaa 

jin 
knowledge evolutionary learning systems 
shaker aachen 

jin evolutionary optimization approximate tness functions 
proceedings genetic evolutionary computation conference pages 
morgan kaufmann 

jin managing approximate models evolutionary aerodynamic design optimization 
proceedings ieee congress evolutionary computation volume pages may 

jin framework evolutionary optimization approximate tness functions 
ieee transactions evolutionary computation 

jin knowledge incorporation neural networks fuzzy rules 
neural processing letters 

poli 
gp music genetic programming system music generation automated tness raters 
john koza wolfgang banzhaf kumar chellapilla kalyanmoy deb marco dorigo david fogel max garzon david goldberg hitoshi iba rick riolo editors proceedings third annual conference genetic programming pages 

kenji 
statistical active learning multilayer perceptrons 
ieee transactions neural networks 


kim 
cho 
ecient genetic algorithms tness evaluation clustering 
proceedings ieee congress evolutionary computation pages 
ieee 


composite sandwich structural optimization application satellite components 
aiaa journal 

lee hajela 
parallel genetic algorithms implementation multidisciplinary rotor blade design 
journal aircraft 


liang yao newton 
combining landscape approximation local search global optimization 
congress evolutionary computation pages 


liang yao newton 
evolutionary search approximated dimensional landscape 
international journal knowledge intelligent engineering systems 

mackay 
information objective functions active data selection 
neural computation 

morimoto de hashimoto 
intelligent approach optimal control fruit storage process neural networks genetic algorithms 
computers electronics agriculture 

myers montgomery 
response surface methodology 
john wiley sons new york 

nain deb 
computationally ective multi objective search optimization techniques coarse ne grain modeling 
ppsn workshop evolutionary multiobjective optimiza comprehensive survey fitness approximation evolutionary computation tion 

nair keane 
combining approximation concepts algorithm structural optimization procedures 
proceedings th aiaa ahs asc structures structural dynamics materials conference pages 

neumaier 
molecular modeling proteins mathematical prediction protein structures 
siam review 

roy 
multiobjective optimization rolling rod product design metamodeling approach 
genetic evolutionary computation conference pages new york 
morgan kaufmann 

jin adaptive encoding aerodynamic shape optimization 
proceedings ieee congress evolutionary computation volume pages may 

ong nair keane 
evolutionary optimization computationally expensive problems surrogate modeling 
aiaa journal 


structural optimization evolution strategies neural networks 
fourth national congress computational mechanics san francisco 


optimization large scale evolution strategies neural networks 
int 
space structures 


application evolutionary algorithms protein folding prediction 

hao editor proceedings arti cial evolution volume lecture notes computer science pages 
springer 


blade design navier stokes solver arti cial neural network 
asme journal 

white 
selecting concise training sets clean data 
ieee transactions neural networks 

powell 
radial basis functions multi variable interpolation review 
mason cox editors algorithms approximation pages 
oxford university press oxford 


informed operators speeding genetic algorithm design optimization reduced models 
proceedings genetic evolutionary computation conference pages las vegas 
morgan kaufmann 

ni 
comparison methods reduced models speed design optimization 
proceedings genetic evolutionary computation conference pages new york 
morgan kaufmann 


accelerating convergence evolutionary algorithms tness landscape approximation 
eiben th 
ack schoenauer 
schwefel editors parallel problem solving nature volume pages 


optimal sampling strategies learning tness model 
proceedings congress evolutionary computation volume pages washington july 

redmond parker 
actuator placement reachable set optimization expected disturbance 
journal optimization theory applications august 

reed marks ii 
neural 
mit cambridge ma 

robinson keane 
case multilevel optimisation aeronautical design 
proceedings conf 
multidisciplinary design optimisation pages pp 

royal aeronautical society 

sano kita 
optimization noisy tness functions means genetic algorithms history 
schoenauer editor parallel problem solving nature volume lecture notes computer science 
springer 

sastry goldberg pelikan 
don evaluate inherit 
proceedings genetic evolutionary computation conference pages 
morgan kaufmann 

schneider 
neural networks useful tools drug design design 
neural networks jin 

schneider schr odl 
peptide design arti cial neural networks evolutionary search 
proceedings national academy science 

schneider 
arti cial neural networks simulated molecular evolution potential tools sequence oriented protein design 


schoenauer 
surrogate deterministic mutation 
arti cial evolution pages 
springer 


schwefel 
evolution optimum seeking 
wiley 

periaux 
hierarchical genetic algorithm multiple models optimization 
parallel problem solving nature volume lecture notes computer science pages 
springer 

tucker 
response surface neural network techniques rocket engine injector optimization 
technical report aiaa 

simpson korte 
comparison response surface kriging models design optimization 
technical report aiaa 

smith dike 
fitness inheritance genetic algorithms 
proceedings acm applied computing pages 
acm 

takagi 
interactive evolutionary computation 
proceedings th international conference soft computing information intelligent systems pages japan october 
world scienti 
vapnik 
statistical learning theory 
wiley 

parmee 
cooperative multi level chc ga optimization 
proceedings fourth european congress intelligent techniques soft computing volume pages aachen 

vijayakumar ogawa 
improving generalization ability active learning 
neural computing 

yang 
evolutionary algorithms coarse ne function smoothing 
ieee international conference evolutionary computation pages perth australia 
ieee press 

zhang cheng 
design vector quantization codebooks genetic algorithm 
proceedings ieee conference evolutionary computation pages 
ieee 
