game theoretic bayesian prediction roos complex systems computation group helsinki institute information technology box fin hut roos hiit nd may consider sequential probabilistic prediction problem statistician chooses probability distribution sequence observations 
sequence observed statistician incurs loss depending chosen distribution observed sequence 
review di erent optimality concepts prediction strategies discuss optimal prediction strategies respect 
keywords sequential prediction optimality bayesianism expert approach game theory information theory minimax maximin regret 
contents admissible strategies bayesian strategies minimax maximin strategies minimax maximin regret strategies experiment discussion appendix aims inference divided primary classes ones 
point view inference aims extracting information data 
view states true objectives prediction control 
attitude prevalent statistics view commonly held machine learning 
take position consider prediction strategies decisions consequences measured units utility loss 
doing frequently apply tools decision theory game theory information theory 
general decision problem step sequence observations statistician prediction outcome prediction represented probability distribution jx possible values observing statistician incurs loss quanti ed loss function jx depending prediction observation possible prediction strategies statistician represented joint probability distributions domain words predictions restricted way requiring statistician specify conditional predictions possible initial segments observations available change strategy 
equivalence terms prediction strategy distribution interchangeably 
obvious question setting optimal prediction strategy 
trivial sense answer incurs minimal loss 
unfortunately know sequence optimal strategy sense 
consider strategies optimal weaker sense 
mainly set 
section give formal de nitions related loss functions basic compelling form optimality admissibility pareto optimality 
section discuss bayes optimality related bayesian approach prediction 
section discuss game theoretic optimality concepts minimax maximin optimality 
section consider minimax maximin regret optimality game theoretic called expert approach 
section simple experiment di erent prediction strategies compared 
section repeat central aspects try put wider context 
admissible strategies analysis prediction strategies requires explicitly express utilities attach various outcomes 
loss functions values thought negative utilities 
de nition log loss 
logarithmic loss log loss log short negative logarithm probability log jx log jx log loss particularly interesting probabilistic prediction due things interpretations terms information code length gambling growth rate capital 
convenient technical properties see lemma obtain bounds loss functions see lemma 
base logarithm qualitative ect results discuss 
numerical values base logarithm gives log loss bits 
de nition zero loss 
loss function called zero loss frequently classi cation correct classi cation causes zero loss mistake causes unit loss 
probabilistic prediction discrete domain considered classi cation choosing value highest predicted probability suggested class value 
loss zero observed value assigned highest probability 
de nition cumulative loss 
cumulative loss obtained sequential prediction sequence jx lemma turn useful comparing di erent prediction strategies 
lemma 
log loss cumulative log loss strictly decreasing function joint likelihood log log jx log jx log lemma 
zero loss bounded base log loss log proof 
mistake predicting jx log jx log jx number mistakes lemma follows 
way comparing strategies consider dominates sense de nition domination 
strategy weakly dominates strategy words strategy strategy better 
de nition admissibility 
admissible pareto optimal strategy dominated strategy 
game theory admissibility compelling form optimality pro table dominated strategy 
signi cance probabilistic prediction limited result shows 
theorem 
log loss zero loss prediction strategy dominated strategy strategies admissible 
proof 
distributions 
identical assign lower probability sequence lemma shows log loss dominated arbitrary proves log loss part theorem 
zero loss prediction strategy easy construct sequence strategy incurs zero loss strategy gives di erent predictions incurs non zero loss 
dominated arbitrary proves zero loss part 
bayesian strategies requiring strategy better strategies cases including worst case informative consider average performance 
de nition bayes optimality 
bayes optimal strategy bayes minimizes expected loss respect distribution bayes min expected loss strategy obviously expected loss bayes strategy depend strongly choice distribution possible solution bayesian approach inference 
bayesian subjective interpretation probability uncertainty represented probability distribution unknown quantities 
particular subjective probability distribution assigned possible sequences practice easy specify distribution truly express beliefs statistician 
cases easier obtain distribution larger domain additional nuisance variables marginalization 
call formulae form bayes mixtures 
bayes mixtures regular basis bayesian statistics joint distribution decomposed called likelihood part prior 
obvious reasons resulting distribution called marginal likelihood 
instance taken sequence coin tosses bias number prior interpreted uncertainty true parameter value 
obviously requires know true model model class parametrized example class binomial distributions 
alternatively mixture thought technical construction secondary interest needed obtain convenient representation subjective distribution see de finetti bernardo smith 
prediction problem bayesian statistician chooses bayes strategy respect subjective distribution 
bayes strategies respect general loss functions derived directly instance result due shannon theorem 
log loss unique bayes strategy bayes proof 
expected log loss strategy rewritten log log log denotes kullback leibler divergence relative entropy denotes entropy expected log loss expressed sum unavoidable term excess loss due kullback leibler divergence 
zero positive theorem follows 
theorem shows log loss distributions bayes optimal respect 
distribution subjective respect expectation taken criterion bayes optimality remains vague criterion admissibility 
minimax maximin strategies discuss game theoretic optimality de nitions 
thorough presentation instance berger 
de ne versions minimax optimality probabilistic deterministic 
de nition probabilistic minimax optimality 
strategy minimax optimal probabilistic setting incurs minimal expected loss wrt 
worst possible distribution max min max known game theory maximization distributions restricted just deterministic selection 
words maximizing distributions deterministic version 
de nition deterministic minimax optimality 
strategy minimax optimal deterministic setting incurs minimal loss worst possible sequence max min max deterministic version akin admissibility bayes optimality involve expectations distributions 
reason avoids philosophical issues related hypothesized distributions subjective distributions 
zero loss log loss minimax optimality prediction simple theorems imply 
prove theorems deterministic version minimax optimality noted results probabilistic version identical 
theorem 
log loss unique minimax strategy uniform distribution uni cardinality domain proof 
uniform distribution sequence theorem 
zero loss distributions minimax 
proof 
strategies sequence strategy maximal number mistakes 
bayesian approach considered expected loss respect subjective distribution 
de nitions game theoretic approach choosing distribution 
de nition favorable distribution 
distribution favorable expected loss bayes optimal strategy wrt 
maximal min max min de nition maximin optimality 
maximin optimal strategy bayes optimal wrt 
favorable distribution min case minimax optimality maximin optimality turns interesting log loss 
theorem 
log loss maximin strategy favorable distribution equal uniform distribution 
proof 
rewriting expected log loss proof theorem maximin expected log loss max min log max min max favorable distribution maximum entropy uniform distribution see shannon 
fact maximin strategy equal favorable distribution follows directly theorem 
log loss minimax maximin criteria satisfactory intuitive point view focus unpredictable worst case sequences 
section try nd remedy pessimistic situation 
minimax maximin regret strategies previous sections succeeded proving intuitive fact prediction strategy perform cases 
lots possible cases completely unpredictable chaotic indi erent prediction strategy chosen 
possible reply phenomenon question predictable case worthwhile try predict possible unpredictable case matter 
try nd prediction strategies predictable cases 
kind reasoning appeal somewhat circular requires distinguish priori predictable cases prediction strategy speci ed determine sequences predict 
acknowledging comes ex necessary abandon absolutely non informative objective attitude resort informative speci cation interesting predictable sequences domain speci background knowledge 
mentioned bayesian approach possibility 
say real life problems feasible specify exactly subjective distribution statistician directly likelihood prior decomposition 
discuss approach incorporating background knowledge prediction call expert approach lack established terminology 
expert approach includes frameworks prediction individual sequences cesa bianchi cesa bianchi lugosi universal prediction merhav feder minimum description length mdl principle barron rissanen competitive line statistics vovk 
expert approach assumed data generating mechanism necessarily existence 
accordingly relative prediction performance guaranteed 
de ne pool experts model class 
de nition model class 
model class set probability distributions domain xing model class performance prediction strategy measured relative model class 
relative loss called regret 
de nition regret 
model class regret strategy min 
speci loss function denote log log regret 
general intuition minimize loss relative best expert 
applying de nitions preceding sections particular minimax maximin optimality regret yields interesting results 
call corresponding optimality properties minimax regret optimality maximin regret optimality de ned obvious way replacing loss function regret de nitions 
de nition theorems due shtarkov see xie barron cesa bianchi lugosi 
de nition 
shtarkov normalized maximum likelihood nml distribution nml max max theorem 
log loss nml distribution unique minimax regret optimal strategy 
proof 
max denote denominator de nition 
regret nml distribution constant sequences nml log nml min log log max log log max log nml distributions sequence nml implies log theorem 
log regret nml unique favorable maximin regret optimal distribution 
proof 
favorable distribution gives maximin expected regret max min log max min log min log max log max log max log log nml log max log nml log max nml log log maximizing nml theorem implies maximin strategy identical favorable distribution 
example gives idea nml distribution looks special case binomial distributions 
example nml binomial distributions 
binary sequence length model class set binomial distributions bin bias 
denominator approximately 
induced distribution number ones sequence shown 
consider particular sequence 
predictions nml distribution shown 
seeing data chances rst bit fty fty 
rst bit zero conditional probability nml jx nml nml marginal probabilities form nml nml nml second zero gives nml jx 
probability climbs third bit yielding nml jx forth 
number ones relative probabilities number ones binary sequence length induced nml distribution binomial distributions 
predictions nml distribution sequence 
branching corresponds branching corresponds zero 
percentages arrows denote predicted probabilities 
cumulative log loss nml distribution string bits consistent probability 
log loss maximum likelihood binomial distribution bin bits 
regret approximately bits 
fact known regret log sequences length 
example remarks noteworthy 
nml distribution depends length sequence horizon problematic cases horizon known advance 
secondly computing marginal probabilities requires evaluation sum number terms exponential length sequence seen 
dependency horizon tends diminish length sequence grows possible nml distribution strings length predicting th symbol 
solutions avoids evaluation exponential number terms 
warmuth call procedure strictly speaking minimax problem slightly di erent step minimax algorithm prove performance nml 
bayesian point view may interesting ask nml distribution model class expressed bayes mixture prior model class 
unfortunately turns case 
seen fact marginals nml distribution depend horizon case bayes mixtures 
bayes mixtures certain priors near optimal similar sense step minimax algorithm 
section discuss simple experiment performance prediction strategies assessed 
experiment suppose want predict binary sequences length model class set binomial distributions indexed bias parameter 
compare log loss log regret performance nml distribution step minimax algorithm bayes mixture 
bayes mixture di erent priors uniform prior called je reys prior 
priors special cases beta distribution uniform distribution je reys prior 
priors shown 
note similarity je reys prior distribution induced nml distribution 
de nition beta distribution 
density variable beta distribution evaluation predictions nml distribution tedious 
order evaluate log loss log regret necessary predictions log regret nml distribution log log loss obtained log regret simply adding log loss best maximum likelihood binomial model 
evaluation tedious needs evaluated length mentioned predictions uniform jeffreys uniform prior je reys prior 
step minimax algorithm easy compute 
theorem gives predictions bayes mixture beta priors 
theorem 
binomial likelihood prediction rule corresponding bayes mixture beta prior jx number proof 
see appendix illustrates worst case log loss log regret performance bayes mixtures uniform je reys prior step minimax algorithm nml distribution 
methods worst case logloss slightly larger length sequence 
expected nml worst case log regret de nition minimizes quantity 
step minimax algorithm bayes mixture je reys prior nearly nml slightly better 
bayes mixture uniform prior clearly worst performance 
approximation log nml log regret nml distribution xie barron 
fact step minimax algorithm better worst case regret performance bayes mixture je reys prior shown warmuth 
methods boundary sequences maximize regret 
boundary sequences excluded results change slightly max log sequence length uniform jeffreys step nml max log sequence length uniform jeffreys step nml approx 
performance bayes mixture uniform prior bayes mixture je reys prior step minimax algorithm nml sequences length 
left maximum log loss 
right maximum wrt 
binomial distributions 
approx refers asymptotic formula log nml log 
seen 
bayes mixture je reys prior asymptotically minimax regret optimal boundary sequences xie barron case step minimax algorithm 
je reys prior de ned models simple binary case see clarke barron barron important invariance properties gives central role bayesian statistics bernardo smith 
discussion reviewed basic concepts prediction point view 
particular di erent optimality de nitions discussed corresponding optimal prediction strategies identi ed 
foremost approaches discussed bayesian approach expert approach having natural optimality criteria 
approaches seen ways incorporate background knowledge subjective beliefs classes experts prediction 
bayesianism bayes optimal strategies 
cases log loss case strategies easily obtained max log sequence length uniform jeffreys step nml approx 
maximum log regret wrt 
binomial distributions sequences excluded 
second highest curve step minimax algorithm 
je reys prior nml 
long distribution respect expectations taken 
procedure far nite regress gives little advice obtaining distribution 
statistics problem solved assuming parametric model supposed govern phenomenon question 
bayesian statistics particular prior distribution assigned parameters model 
cases certainly easier give prior model parameters give distribution observable variables directly 
statistical arguments classical bayesian variety necessarily somewhat metaphysical exempli ed quote degroot statistics problems probability distribution generated experimental data completely known values parameters 
dictum represents contradictory view bernardo smith models false useful 
fairly mysterious opposite views merged friction bayesian statistics community 
expert approach domain speci expert classes minimax regret criterion 
role experts accident described quote bernardo smith 
philosophical point view expert approach di ers classical bayesian statistics assume data generated distribution model class considered data generating distribution exists 
accordingly performance relative set experts guaranteed 
expert approach immature theory applications compared competitors remains seen conditions cesa bianchi 
satis ed believe results extended general loss functions learning prediction scenarios corresponding optimal estimation constants rates worst case viewpoint may ultimately provide fruitful alternative foundation statistical theory learning prediction 
simple binary experiment bayesian expert approaches shown give similar results 
expected certain bayesian methods known near optimal minimax regret sense 
brings question practical success bayesian methods explained bayesian theory framework 
answer rissanen states bayesian methods simply approximate minimum description length mdl principle 
view mirror image buntine authors mdl approach bayesian methods disguise anti bayesian colleagues 
leave nal decision matter reader conclude methods independent theoretical justi cations 
importantly methods reasonably practice 
appendix proof theorem proof theorem 
bayes rule conditional probability sequence proportional probability continued denoted jx denominator beta distribution left normalizing constant 
expanding likelihood term yields beta integral value see bernardo smith gamma function essence generalization factorial reals 
similar argument conditional probability zero proportional jx ratio probabilities jx jx means probability jx barron rissanen yu 
minimum description length principle coding modeling 
ieee trans 
information theory 
berger 
statistical decision theory nd 
ed 
new york springerverlag 
bernardo smith 
bayesian theory 
john wiley sons buntine 
guide literature learning probabilistic networks data 
ieee trans 
knowledge data engineering 
cesa bianchi lugosi 
worst case bounds logarithmic loss predictors 
machine learning 
cesa bianchi freund haussler helmbold schapire warmuth 
expert advice 
jacm 
clarke barron 
information theoretic asymptotics bayes methods 
ieee trans 
information theory 
de finetti 
la ses lois logiques ses sources 
annales de institute henri poincar 
reprinted foresight logical laws subjective sources studies subjective probability kyburg eds dover 
degroot 
probability statistics nd ed 
reading addisonwesley 
merhav feder 
universal prediction 
ieee trans 
information theory 
rissanen 
mdl denoising 
ieee trans 
information theory 
rissanen 
personal communication 
shannon 
mathematical theory communication 
bell system technical journal july october 
warmuth 
step minimax algorithm 
pages proc 
th international conference algorithmic learning theory 
vovk 
competitive line statistics 
international statistical review 
xie barron 
asymptotic minimax regret data compression gambling prediction 
ieee trans 
information theory 

