parallel reinforcement learning matthew mathematics computer science denison university oh usa examine dynamics multiple reinforcement learning agents interacting learning environment parallel 
due stochasticity environment agent different learning experience ultimately converge value function 
agents accelerate learning process sharing information periodic points learning process 
keywords reinforcement learning parallel agents multi agent learning investigate problem multiple reinforcement learning agents attempting learn value function particular task parallel 
agent simultaneously engaging separate learning experience task 
intuitive agent learning experience accelerated agents share information learning process 
examine complexities information exchange propose simple algorithm successfully demonstrates accelerated learning performance parallel reinforcement learning agents 
remainder briefly review problem reinforcement learning discuss previous efforts parallel reinforcement learning 
section presents parallel reinforcement learning problem context armed bandit task 
section provides algorithmic solution parallel reinforcement learning 
section empirical evidence accelerated learning armed bandit task 
section suggests possible avenues research 
reinforcement learning rl process learning behave optimally trial error experience 
agent interacts environment observing states selecting actions action choice moves agent new states environment 
agent receives reward state action choice 
goal agent maximize sum rewards experienced 
major challenge reinforcement learning agent defer immediately large rewards larger rewards choose actions lead states opportunity larger rewards 
interested reader referred comprehensive reinforcement learning :10.1.1.32.7692
despite apparent simplicity surprisingly little parallel reinforcement learning 
research concerns multiple agents learning different inter related tasks 
littman studies competing rl agents context markov games 
sallans hinton study agents cooperate solve different parts larger task 
claus boutilier sen examine various complex interrelations multiple agents cooperating solve common task 
common feature existing agents solving different parts task working environment altered actions agents concentrate simplified version problem multiple agents independently interact stationary environment 
see initial line multiple rl robots learn parallel broadcasting learning tuples real time 
parallel rl means study behavior parallel rl object investigation 
parallel reinforcement learning problem introduce problem parallel reinforcement learning armed bandit task illustrate concepts 
armed bandit task named slot machines studied extensively fields mathematics optimization machine learn ing 
follow experiments sutton barto constructing simple agents action value methods estimate payoff reward arm action :10.1.1.32.7692
reinforcement learning bandit trial agent selects arm action set arms receives payoff result action payoff normally distributed random variable mean standard deviation 
agent maintains estimate mean payoff bandit arm averaging rewards received pulling arm ka number total trials counting actions number trials allocated specifically action ka individual samples rewards experienced choosing action different trials 
order avoid storing rewards arms incremental approach stores current estimate number trials arm line incremental update rule ka action selected 
shows learning performance single rl agent interacting armed bandit 
greedy policy average different experiments contains trials 
experiment created randomly sampled normal distribution mean standard deviation 
clear value agent payoff estimate particular action directly related number trials allocated action agent gains experience estimate reward arm approaches true mean 
problem parallel learning experiment previous section reveals importance agent experience 
number trials average reward trials percentage optimal actions single agent armed bandit task trials currency agent gauge success trials better reward estimates probable agent able select optimal action 
clearly change basic algorithm provides agent experience improve agent learning performance 
consider case multiple agents learning armed bandit task parallel 
keep mind agents experiencing exact series payoffs agent sampling independently able allocate total samples actions differently 
agent accumulating different experience 
illustration consider case agents agent agent armed bandit action payoff 
point learning state agents follows agent selected action twice received payoffs 
agent es payoff 
agent selected action received payoff 
agent estimates payoff 
say agent estimate probably accurate agent agent twice learning experience action 
agent trials independent claim agents trials samples 
agents combine experience follows total experience agent experience agent experience agent agent combined estimate agent estimate weighted experience agent estimate weighted experience agent agent agent agent agents combining experience depict exchange information 
notion entirely correct problem arises attempt combine shared experience 
agent agent truly trials learning experience 
true combined trials experience base estimates distinct case agent separate trials experience 
problem arise agents experience independent 
subtle problem elucidated consider agents meet decide share learning experience way agent comes away second swapping episode believing trials experience base estimate 
agents continue swap information indefinitely reach infinite amount experience fact original trials 
agents swap information third agent actual trials experience credit third agent information statistically overwhelmed correspondingly larger accumulated experience agent agent really possesses actual trials experience 
parallel reinforcement learning solution overcome problem agent keep track sets parameters set actual independently experienced trials particular agent additional set combined trials agents better way depict agents shown 
agent maintains action keep track trials directly experienced agent 
added combined estimates agents experience parameters 
specifically total number trials action experienced agents average payoff estimate agents 
new arrangement enables important computations possible 
agents accurately share accumulated experience keeping separate parameters independent experience trials combined experience agents 

agents compute accurate estimate global experience 
estimate computed weighted average agent independent experience accumulated experience agents choose include agent experience combined experience results 
way agent continue learn additional trials effectively remember combine experience agents 
agent agent agent agent agent agent storing independent experience separately shared experience 
agents continue accurately gain new experience adding continue improve estimates may able continue share parameters agents 
armed bandit results section empirically demonstrate improvement allowing parallel agents share learned experience armed bandit task 
agent experiences trials actions different experiments results averaged experiments 
experiment randomly select average payoffs chosen 
case vary number agents 
agents share accumulated experience trial separate episodes parameter sharing agents trials 
shows average payoff percentage optimal actions agents experiments 
clearly individual agent performs worst experience 
expected adding agents accelerates learning process larger pool accumulated experience base estimates 
experiment parallel agents learns fastest 
trials agent agents agents agents average reward trials agent agents agents agents percentage optimal actions parallel agents armed bandit task directions concept parallel reinforcement learning relatively simple benefits obvious area 
numerous opportunities extended currently investigation quantify possible theoretical speed parallel agents 
investigate increased complexity exploitation exploration 
parallel agents sharing information additional pressure agents exploit actions exploring 
extend process multi state tasks 
expect greater benefit episodic tasks state 
curious inversion effect performance group increases agents share information frequently 
hypothesize dynamics similar island models genetic algorithms prevent system prematurely converging non optimal solution 
andrew 
robust architecture multiple agent reinforcement learning 
master thesis university florida 
berry 
bandit problems 
chapman hall 
caroline claus craig boutilier 
dynamics reinforcement learning cooperative multiagent systems 
proceedings fifteenth national conference artificial intelligence aaai 
aaai 
michael littman 
markov games framework multi agent reinforcement learning 
proceedings eleventh international conference machine learning pages 
michael littman 
value function reinforcement learning markov games 
journal cognitive systems research 
sandip sen evaluating concurrent reinforcement learners 
proceedings fourth international conference multiagent systems pages 
ieee press 
narendra 
automata 
prentice hall 
brian sallans geoffrey hinton 
free energies represent values multiagent reinforcement learning task 
advances neural information processing systems nips volume 
mit press 
richard sutton andrew barto :10.1.1.32.7692
reinforcement learning 
mit press 
