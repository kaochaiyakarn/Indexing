compiler tool predict memory hierarchy performance scientific codes fraguela zapata 
de sistemas de informatica universidade da na campus de na na spain 
de de campus de universidad de malaga malaga spain received march received revised form february accepted september parallel computing study understanding memory hierarchy behavior essential critical current systems performance 
design optimising environments compilers allow guidance program transformation applications order improve cache performance little user intervention possible particularly interesting 
introduce fast analytical modelling technique suitable arbitrary set associative caches lru replacement policy overcomes weak points approaches literature 
model integrated polaris parallelizing compiler allow automated analysis loop oriented scientific codes drive code optimizations 
results detailed validations known benchmarks show model predictions usually accurate code optimizations proposed model nearly optimal 
elsevier rights reserved 
keywords memory hierarchy cache behavior performance prediction compiler optimizations supported part ministry science technology spain contract tic 
corresponding author 
mail addresses es fraguela es juan es ac uma es zapata 
see front matter elsevier rights reserved 
doi www elsevier com locate fraguela parallel computing 
widening disparity processor main memory speeds memory hierarchy performance critical factors influences global system performance 
programmers aware try hand tune codes time consuming trial error process intuitively costly traditional techniques trace driven simulations profiling built hardware counters :10.1.1.39.6945
methods suitable ones provide little information reasons memory hierarchy behavior time requirements high 
result lot effort automatically efficiently guide kind optimization 
compiler technology usually relies limited scope heuristics simple analyses lack necessary generality precision 
new general techniques analysing cache performance required give accurate predictions memory hierarchy behavior improve understanding provide information needed propose improvements cache configuration code structure 
analytical models direct analysis source code reasonable approach meet challenges overcome limitations strategies 
traditionally important disadvantages respect aforementioned techniques 
lack accuracy models give rough approximations number misses precise quantitative estimations 
surprising cache behavior known highly unstable sensitive small changes large number parameters code structure problem sizes base addresses cache layout drawback analytical models limited scope way restrict code structure memory hierarchy analyse :10.1.1.133.892
construction models point allowing integration frameworks apply automatically 
resulting tools analyse cache performance propose suitable program transformations order optimize cache behavior input codes 
group developed fast analytical model accurate predictions performance set associative caches lru replacement policy general loop oriented codes 
generation set denote probabilistic equations 
equations provide estimators number misses generated loop 
models bibliography consider separately loop nest takes consideration probability hits due reuse data structures accessed loops different nests 
important misses may occur loop executions 
conservative approach applied current implementation analysis real scientific codes limiting study isolated loop nests feasible 
mentioned model kind probabilistic approach 
property enables predict memory system performance knowing base addresses data structures model 
addresses available model uses improve prediction 
final property model velocity enables extensive searches optimization space large codes 
unified different cases generating equations exposed single expression 
furthermore model integrated polaris parallelizing compiler framework automatically performance estimations propose code optimizations 
model validated small kernels codes specfp suite feasibility driving compiler optimizations lead optimal optimal solutions analytical model shown 
fact see optimizations proposed tool usually better current production compiler 
structured follows section provides detailed review related 
section introduces underlying modelling ideas 
explains derive formulae give number misses set nested loops probabilities generated accesses performed reuse distances formulae require 
details structure functionality tool integrated polaris analyse real codes suggest code optimizations section 
section compares model predictions measurements trace driven simulations evaluate accuracy speed 
section focuses automatic code optimization 
section follows 

related fraguela parallel computing number analytical models code structure developed differ distinct levels coverage respect scope applicability type results delivered accuracy execution times required obtaining model results implementation compiler framework 
example ferrante consider arbitrary degree associativity estimate number different lines loop nest access real number misses 
misleading conflict misses play important role considered 
model code considers kinds misses applied general numerical codes restricted direct mapped isolated perfect loop nests 
formulae model calculation footprints cache different loop 
ghosh harper overcome restrictions 
introduces cache equations system linear diophantine equations solution corresponds potential cache generated seconds standard benchmark programs accurate try predict optimize cache behavior heavy computing requirements 
hand harper focus class nests base approach footprints 
model devoted set associative fraguela parallel computing caches modeling times similar tool 
tests show error model usually times smaller theirs example codes propose 
works referenced share common limitation overcome modelling suitable regular access patterns isolated perfectly nested loops take account probability hits reuse data structures referenced previous loops 
important issue pointed mckinley 
case model capable handling non perfect loop nests analysing code isolated loop nests 
vera xue reduced computing requirements applying statistical techniques extended model handle complete codes regular computations 
table compares accuracy speed model cache configurations evaluations 
matrix product blocking dimensions vera xue compare model tomcatv swim known specfp codes 
see accuracy similar model faster 
notice models applied hundreds thousands times search optimization space optimal block sizes typical compiler applications require computing times orders magnitude longer required single evaluation models 
approach presburger formulae addresses reuse non perfect loop nests gives exact predictions small kernels include certain conditional statements non linear data layouts allowing certain amount symbolic analysis 
drawbacks exist handle modest levels associativity time consuming currently reduces applicability 
propose model completely focused symbolic evaluation analysis addresses set associative caches 
strategy table comparison vera xue algorithm confidence interval probabilistic model kbyte cache lines bytes different degrees associativity benchmark bj bk tomcatv ref 
input set swim ref 
input set error err expressed absolute difference predicted measured ratios 
modeling times time ms models measured mhz pentium iii 
involves instrumenting source codes symbolically evaluated generate symbolic trace files store program symbolic expressions recurrences 
symbolic evaluation trace file cache parameters yields final analytical cache hit function 
unfortunately evaluated simple kernels yields accurate results information computing requirements 
important advantage exclusive model able predict behavior code knowing base addresses data structures quite common situation 
reason applicable physically indexed caches dynamically allocated data structures 
designed tools delphi splat analyse codes run time profiling analytic models 
delphi bases model stack distances generating stack histograms individual loop nest 
restricts accurate estimation fully associative caches lru replacement policy includes probabilistic approach handle general set associative caches causes loss reuse information different loop nests 
delphi includes model indirect accesses cpu model complement model section obtain real computing time estimations 
locality analysis splat uses series phases 
volume phase cache behavior considered similar lru fully associative cache interference phase model focuses direct mapped caches 
relies estimate behavior set associative caches 
tools delphi splat require computing times perform analysis typically orders magnitude larger tool 
cases prediction errors usually similar larger consider codes vast majority accesses sequential tomcatv swim 
kinds codes better suited strategy modelling direct mapped caches fully associative 
experiments matrix product blocking code presents larger variety access patterns show large deviations appeared predictions delphi access splat model generates predictions see section 

model concepts fraguela parallel computing classify misses cold interference misses 
line accessed time gives place cold remaining misses line take place processor tries reuse line line replaced due accesses lines interfere cache set 
example way associative cache lru replacement condition cache line replaced different lines mapped cache set accessed access line 
analysing access patterns different portion program execution provides knowledge different lines accessed reused fraguela parallel computing lines accessed reuses 
way equations estimate number misses generate constructed 
model differs related works bibliography probabilistic approach 
builds estimation probabilities line reuses 
probabilities depend cache area affected accesses performed consecutive accesses line 
consider initial modelling scope develop ideas 
scope set normalized nested loops fig 
arrays accessed indexed affine functions enclosing loop variables 
nesting level imperfectly nested loops analysed 
number iterations loop known compile time execution loop 
code executed machine arbitrary cache size line size degree associativity 
limitation regarding cache replacement policy lru 
conditions depict common indexing scheme scientific engineering codes pme nesting level generated simple ideas loop enclosing gives place stride accesses may zero fixed number accesses stride 
way function estimate number misses generated execution loop built see section 
existence array gives place reuses lines accessed group reuse 
result equations loops reuses occur reflect total size loops number iterations consecutive reuses 
order simplify analysis model computes reuse fig 

general perfectly nested loops regular code 
translation indices differ added constants 
reuse scientific codes comes kind groups 
cache area affected accesses number executions enclosing loops computed analytically simulation mixed approach 
probability accesses generate interferences affect specific derived cache area see section 
ideas developed clear reason restrict study single simple nest 
computing reuse distances interference probabilities located different nests done number restrictions met see information 
modelling requires data size loops indices 
times data available compile time 
cases code instrumentation capture data run time example approach delphi 
data locations model available predict memory behavior completely probabilistic approach 
model applied codes include conditional structures 
discuss probabilities sections respectively 
interesting note basic modelling scope allows analysis programs modelling ideas general allow expansion scope number ways 
example model supports kinds loop dependences blocking loops different number iterations different executions triangular loops 

probabilistic equations fraguela parallel computing model associates probabilistic estimator fri enclosing loop nesting level estimates number misses generates execution loop 
estimator function probability access line data structure execution loop 
probability input parameter estimator nesting level depends access patterns accesses outer previous loops 
enclosed loop fri calculated pme terms fr iteration loop involves execution immediate inner loop fr includes access pattern loop misses generated 
hand analysis loop provides immediate inner loop 
analysis starts innermost loop contains finishes outermost loop 
innermost loop containing inner loop analyze carries information access pattern 
result pme generates estimator loop fr estimator really corresponds execution loop body execution inner loop 
fraguela parallel computing way pme generates estimator innermost loop fr replaced probability single access 
input probability outermost loop code portions data structure cache execution begins 
notice generation estimation loop facilitates detection loops data accesses serious bottleneck hot spots 
ni number iterations loop nesting level lri number iterations reuse lines loop estimator fri obtained pme fri ni lri fr pr carries reuse 
represents memory regions accessed iterations loop nesting level pr interference probability access region generates accesses section elaborate mapping accessed regions interference probabilities generate 
formula reflects probability lri loop iterations reuse loop depends accesses patterns outer loops probability remaining iterations accesses function regions accessed portion program executed reuses iteration loop 
indices affine functions enclosing loop variables constant stride sri associated loop result lri calculated ni lri sri ls number array elements cache line holds 
formula estimates number accesses exploit temporal spatial locality equivalent estimating number different lines accessed ni iterations stride sri 
hand index loop index sri lri 
correct case single iteration cold accesses respect loop remaining iterations potential reuses due temporal locality 
hand indexed loop variable sri accesses different data items different iterations 
case reuse lines related execution loop possible exploiting spatial locality 
access lri different lines ni iterations loop stride sri locality exploited remaining ni lri iterations 
way eq 
captures temporal spatial locality case reuse distance iteration loop considered justifies eq 

formulae applied carries reuse 
belongs group translation exhibit strides may differ constants indices 
gives rise possible spatial temporal systematic group reuse taken account building corresponding 
model sorts descending order base address order compare estimate reuse distance measured loop iterations lines accessed groups 
corresponding term expresses number accesses reuse distance multiplied probability associated distance 
algorithm explained 
example 
order illustrate model explain modelling simple loop numbered real consider example computer byte words way kw cache word lines 
ls loop nesting level iterations fr pr fr stride sr loop implies eq 
lr stride sr resulting lr 
notice lri number different lines accesses loop 
loop contains loops fr replaced explained 
pme derived eq 
exhibits group reuse respect 
kind modeling explained illustrate example simple reasoning 
pme fr pr iterations loop accessing line accessed previous iteration iterations accessing line accessed previous iteration 
yields total accesses reuse distance execution loop consideration 
remaining iterations accessing line intermediate accesses accesses result misses 
result iterations represented pme 

probabilities fraguela parallel computing section interference probability represented reuse distance consecutive accesses line accessed behavior studied 
process calculate probability associated reuse distance steps access pattern description cache impact quantification area vectors addition 
involves description fraguela parallel computing access pattern followed inside reuse distance 
achieved examining indices dimension number iterations reuse distance loop controls indices 
considering factors obtain shape size accessed region 
second step cache impact quantification region analyzed order describe way access affects cache 
involves calculating cache footprint region contribution probability estimating 
represented model interference area vectors 
data structure way associative cache call sa sa sa sak area vector associated accesses period program execution 
element ith position vector stands ratio sets received lines structure 
exception sa ratio sets received lines 
sa probability accesses array produce interference considering caches lru replacement policy 
notice estimating area vector region just means counting different lines region fall cache set 
region kinds interference area vectors associated 
self interference area vectors contain information required estimate probability access region depict 
hand cross interference area vectors generated accesses regions 
calculation kinds area vectors access pattern different line generate interferences calculations similar 
number typical access patterns account vast majority accesses scientific codes 
previous focused non automatic modeling irregular codes describes formulae algorithms estimate area vectors associated patterns 
common regular patterns loop oriented scientific engineering applications sequential access access regions size separated constant stride 
simulation lack analytical tools calculate impact 
show sequential access words example order illustrate area vector estimation approach 
cross interference area vector ss estimated ss ss ssi ls cs average number lines access placed set finishes 
expression ls stands line size cs cache size 
term ls added stands average extra words brought cache accessed lines 
formula expresses cache sets keep lines access remaining cache sets keep lines 
self interference area vector associated access ssa expresses interference lines associated access generate 
estimated ssa ss cs self interference individual line equivalent cross interference generated sequential access cs words average number lines access compete line set 
value calculated ls cs 
effect cache accesses different data structures calculated third step area vectors addition required add order obtain global effect cache 
relative position data structures known area vector scaled addition amount overlapping region data structure associated pme calculated expressed coefficient 
scaling done area vectors added considering area ratios independent probabilities 
area vectors su sv addition represented operator calculated su sv xk su sv xk fraguela parallel computing xk svi sv mentioned analysed translation access pattern sequential array base addresses known optimized algorithm considers pathological conflicts may arise cases applied 
example 
calculated example section completed corresponding probabilities 
fr fr depend probability line access due regions accessed loop iteration 
iterations example loop elements separated element accessed 
access pattern equivalent point view cache footprint access consecutive elements 
way regions modeled sequential access 
degree associativity area vectors depict regions elements 
cross interference area vectors associated regions ss array ss matrix calculated eq 

area vectors data structures ssa ssa regions interferes cache 
explained step order calculate probabilities add area vectors corresponding different data structures accessed considered period program execution 
example pr pr fraguela parallel computing element area vector yields eq 

result final expression example code fr fr fr 
compiler framework analytical modelling final purpose modelling task described previous section integration model compiler environment 
allows analysis real scientific codes effectively quickly way code optimizations proposed 
modelling technique embedded polaris parallelizing compiler development infrastructure 
environment includes delphi cpu model 
computation cycles predicted delphi added stall cycles caused misses predicted model order estimate real execution times 
memory hierarchies arbitrary size block size associativity memory level lru replacement policy nowadays far common considered depict behavior memory systems 
basically framework takes inputs memory hierarchy parameters fortran program returns system performance results analytical models 
provides timing results stage tool desired level monitoring capabilities user level 
tool structure depicted fig 
consists blocks cache parameters configuration file user specifies level memory hierarchy size line size expressed number words degree associativity weight 
file contains switches enable disable code generation simulator analyser shown fig 

parameters specified command line 
modelling library set routines collect modular way analytical model described previous section 
delphi cpu modelling library cases predictions involving processor execution time required 
optimization library analyses input code uses predictions memory hierarchy behavior cpu required suggests code restructuring order reduce total execution time 
example optimization currently implemented selection optimal block size points program blocking pattern detected 
parser integrator integrative part framework 
analyses source code detects array patterns inside loop uses corresponding model modelling library 
note functionality performance model embedded compiler environments changing module 
optimization library modelling library analyser code fraguela parallel computing delphi cpu modelling library fortran code parser integrator modelling optimized results source code tool provides general detailed information cache behavior modelling results global number misses misses data structure misses loop set loops 
cache hot spots detected localized drive code optimizations 
optionally files generated analyser code program appropriate calls modelling library obtains modelling results input code cache parameters optionally data structures base addresses altered 
aim code testing purposes machine independently polaris environment 
simulator code code trace driven simulator validates analytical results obtained specific input code 
case analyser allows modification memory hierarchy parameters data structures base addresses 
simulation performed optimized library functions simulation library fig 
extensively validated matching results simulator component toolset :10.1.1.39.6945
text simulation library text fig 

tool diagram 
cache parameters polaris library simulator code fraguela parallel computing optimized source code input code source source transformation 
case blocking transformation currently implemented blocking original block size replaced optimal block size computed means analytical models 

experimental results main validation model performed comparing number misses predicts values measured trace driven simulations 
code perform simulations generated automatically tool simulator code simulation library fig 

applied approaches series codes wide variety combinations cache parameters data structure dimensions 
combination simulations approximately performed changing value data structure base addresses random generator 
kinds metrics calculated cache parameter combination dmr ratio dnm number misses 
metric dmr average differences predicted measured ratios obtained combination array base addresses tried cache dnm average error prediction number misses trials expressed percentage number measured misses 
ratio differences percentage error prediction number misses taken absolute value calculate averages negative positive values compensate 
standard deviation number measured misses simulations expressed percentage average number measured misses taken account help understand memory behavior algorithms 

validation synthetic codes validation performed kernels covering different access patterns loop nests synthetic code fig 
represents type code non perfect nestings 
number parameter combinations simulations tried 
matrix matrix product blocking fig 
validated checking parameter combinations resulting simulations 
system solver forward substitution shown fig 
involves triangular loop included parameter combinations tried requiring total simulations 
table includes validation results codes 
dmr values highly satisfactory small errors 
codes perform average pre fraguela parallel computing fig 

example code non perfect nestings 
fig 

matrix matrix product blocking dimensions 
diction absolute number misses deviations somewhat higher 
difference validation metrics means important deviations take place parameter combinations small number misses obtained 
memory behavior analysis produces little optimization 
relatively small error prediction number misses combinations generates large values dnm average 
fraguela parallel computing fig 

forward substitution code triangular loop 
table average validation values percentage algorithm dmr dnm non perfect nestings matrix product forward substitution example combinations code non perfect nestings dnm average ratio dmr remaining combinations average ratio 
meaningful fact parameter combinations ratios smaller considered calculation average dnm just memory hierarchy behaving drops 
tables show validation results parameter combinations codes shown figs 
respectively 
tables follows cs stands cache size ls line size words degree associativity bj bk stand problem size see related codes 
tables include average times seconds trace driven simulation validation sim 
modelling mod measured sgi origin server processors mhz 
recall efforts optimize simulator simulation times table validation time results corresponding non perfect nestings code dmr dnm sim 
mod 
fraguela parallel computing table validation time results corresponding matrix product code bj bk dmr dnm sim 
mod 
table validation time results corresponding forward substitution code dmr dnm sim 
mod 
shorter obtain general standard simulators 
modelling typically orders magnitude faster 
exception forward substitution code triangular loop halves number accesses simulation time irregularity forces tool perform sampled simulation estimate area vector 
modelling faster simulation 
large values dnm arise non perfect nestings code combinations small ratio prediction error small number misses absolute terms large relative error explained 
general important reason behavior model combinations 
due probabilistic nature model convergence kind approach favoured small problems misses generated 
additional reason large deviations codes non perfect nestings conservative approach estimation number misses data structures accessed previous loops 
simple quick strategy affects accuracy prediction codes non perfect nestings giving place overestimation 
interesting fact tables parameter combinations greatest prediction errors wide variation high number misses depending relative positions data structures 
prediction deviations similar noticeably smaller fraguela parallel computing standard deviation real number misses making reasonable prediction relative error large 
effort explained probabilistic nature model tends predict number misses close average number misses generated different simulations particular values generated different simulations may far average value 

validation specfp suite order demonstrate wide range validity tool applied programs belonging specfp suite shown table 
case specfp programs analysed code remaining codes chosen cpu time consuming routine 
cases routine calls routines inlined calling routine 
benchmarks considered study different reasons turb apsi demanding loops small generate misses main routines contain non regular loops conditional sentences wave indirect accesses suitable analysis techniques 
table shows resulting number loops analyzed loops refs columns respectively percentage program execution time associated ex 
validation results code 
previous experiments section ratio errors dmr maximum average value 
average errors relative number misses somewhat larger small range corresponding notice largest relative deviations usually take place codes smallest ratios memory hierarchy working better small number misses turns error misses large relative error 
case dnm exhibits excellent values 
fact fig 
proves high precision model caches different sizes degrees associativity 
benchmark su cor included reduced number misses number misses generated tomcatv swim scaled fit plot 
tables shows ratio deviations dmr modelling times cache configurations respectively 
times refer model execution include time required polaris read file parse table main code parameters average validation values percentage benchmark loops refs ex 
dmr dnm tomcatv swim su cor hydro filter mgrid resid applu number misses cache cs ls fraguela parallel computing applu applu swim swim hydro hydro tomcatv tomcatv mgrid mgrid fig 

measured versus predicted misses specfp codes 
cache size cs line size ls words stands degree associativity 
table ratio errors dmr model suite codes considering different cache configurations benchmark cache configuration cs ls tomcatv swim su cor hydro filter mgrid resid applu table modeling times suite codes different cache configurations seconds benchmark cache configuration cs ls tomcatv swim su cor hydro filter mgrid resid applu fraguela parallel computing 
modelling times order magnitude faster simulation respect execution time 
example tomcatv amd swim benchmarks require respectively executed input set corresponding cache simulation order magnitude slower 

automatic code optimization additional set experiments model check possibility driving optimizations real memory hierarchy systems described 
high degree accuracy obtained validation experiments shown preceding section support idea 
matrix matrix product blocking shown fig 
chosen case study purpose 
tried derive optimal block sizes representative architectures feeding tool code parameters describing memory hierarchy levels systems see table pc mhz pc pii digital personal workstation au mhz pw au sgi origin processors mhz nodes fujitsu ap multicomputer ultrasparc ii processors mhz ap ii 
memory hierarchy level systems specified model means csi lsi ki new parameter wi relative penalty 
obtained values wi different memory levels machines corresponding manuals 
way cost block bj bk system levels computed cost bj bk xl wim csi lsi ki bj bk function provides number misses model estimates cache level block 
code run machines trying possible blocks sizes divisors matrix dimensions order measure execution times 
table shows difference execution times predicted optimal block best execution time expressed table difference predicted real optimal block execution times expressed percentage execution time real optimal block stands matrix size pc pii pw au ap ii percentage 
see model proposes optimal near optimal blocks cases 

optimal block selection fraguela parallel computing results achieved preceding set experiments real systems high speed model confirmed feasible drive completely automatic optimizations tool 
example built module choose optimal block sizes inside optimization library fig 

estimation block size leading minimum execution time requires account stalls due cache misses computation cycles implies need cpu model 
scope took cpu model delphi explained section 
cpu computation cycles predicted delphi added stall cycles caused misses predicted model estimate total number execution cycles code 
platform chosen set experiments sgi origin reasons cpu parameters microprocessor required delphi known compiler version flags allow control optimization code generation process available 
procedure performing experiment code fed compiler way decided apply blocking size block optimization level 
resulting code analysed rewritten framework modifying block sizes sentences related predictions model 
set block sizes evaluated tool dimension size original values proposed compiler dn discarding values differed units 
mentioned model run account relative position data structures just pure probabilities 
obvious execution mode accurate information perform modelling 
conservative approach taken algorithm running compiler really information going locate different data structures 
experiment applied codes table compiler chose apply blocking tomcatv swim hydro filter 
point codes benefit reuse borders blocks block case typical example matrix matrix product 
result large improvements execution time expected optimizing size blocks 
execution time loops modified code small difficult measure meaningfully 
problem overcome hydro program measurements just changing block sizes places compiler chose apply blocking 
table shows percentage improvement execution time obtained applying tool respect obtained compiler fraguela parallel computing table improvement execution time analyzed codes optimization level benchmark tomcatv swim hydro optimization levels 
excepting case tool improved execution times expected big improvements mainly due reasons previously mentioned 
think improvements quite account column row blocks reused comparing results compiler 
points difficult compare approach traditional algorithms tile size selection 
algorithms focus memory hierarchy behavior approach far know takes account cpu time 
happened play essential role ignoring lead choice small blocks maximum reuse management requires computing overheads high 
important point referenced algorithms consider just parameters cache level approach takes account levels memory hierarchy simultaneously order selection 
furthermore works specifically devoted driving tile size optimization case tiling just particular application general purpose system prediction memory hierarchy behavior 
important fact algorithms look block sizes allow keeping block cache reuses blocks codes reuse borders interesting keep row column 
approaches consider block matrix pay little attention interaction data structures blocks generated dimension partitioning implied blocking 
interferences taken account particularly dimension tiling may simultaneously affect arrays accessed nesting codes giving place blocks interacting caches 
problem tool oriented broader scope 

fast flexible analytical modelling technique study memory hierarchy performance validated embedded compiler framework 
model concepts pme nesting level probability access line 
probabilities derived cache areas affected reuses line repre sented means unified notation area vectors 
produces structural advantages 
example allows estimation number misses loop 
area vectors allow study relative contribution different data structure probability accesses associated 
advantages obvious illustrated ability take account probability hits due reuses data accessed previous loops enables analysis non perfect nestings programs 
model easily extended modularity developing area vectors associated new access pattern need study 
calculations may performed analytically simulations sampled reduce computing requirements 
achieved model allowed implementation inside polaris parallelizing compiler additional capabilities shown section 
allowed construction complete compiler framework giving place powerful tool system designers programmers 
validations performed comparison trace driven simulations shows relatively large errors may arise number predicted misses number misses ratio small predictions acceptable average accuracy model 
hand time required model predictions small comparison required simulation comparison compilation execution time example codes 
properties model ideal guide compiler optimizations 
applied choose optimal block sizes case study parameters memory hierarchies real systems 
successful results number different hardware platforms achieved current commercial compilers outperformed real codes specfp suite 
fraguela parallel computing lebeck wood cache profiling spec benchmarks case study ieee computer :10.1.1.39.6945
uhlig mudge trace driven memory simulation survey acm computing surveys 
zagha larson turner performance analysis mips performance counters acm eds proc 
supercomputing conference acm press ieee computer society press pp 

lam rothberg wolf cache performance optimizations blocked algorithms proc 
fourth int 
conf 
architectural support programming languages operating systems asplos iv acm sigarch sigplan sigops ieee computer society santa clara ca pp 

jalby cache interference phenomena proc 
sigmetrics conference measurement modeling computer systems acm press pp 

compile time performance prediction scientific programs ph thesis department computer science university illinois urbana champaign 
fraguela parallel computing ghosh martonosi malik cache equations compiler framework analyzing tuning memory behavior acm transactions programming languages systems 
harper analytical modeling set associative cache behavior ieee transactions computers 
vera xue study program behaviour analytically proc 
th int 
symposium high performance computer architecture hpca pp 

chatterjee parker lebeck exact analysis cache behavior nested loops proc 
acm sigplan conference programming language design implementation pldi pp 

fraguela zapata automatic analytical modeling estimation cache misses proc 
int 
conf 
parallel architectures compilation techniques pact pp 

mckinley quantitative analysis loop nest locality proc 
seventh int 
conf 
architectural support programming languages operating systems asplos vii acm press cambridge massachusetts pp 

blume eigenmann lawrence lee padua paek pottenger rauchwerger tu parallel programming polaris ieee computer 
ferrante sarkar thrash estimating enhancing cache effectiveness banerjee gelernter nicolau padua eds proc 
fourth international workshop languages compilers parallel computing lecture notes computer science vol 
intel springer verlag santa clara ca pp 

scholz symbolic cache analysis real time systems real time systems 
sanchez gonzalez analyzing data locality numeric applications ieee micro 
fraguela zapata modeling set associative caches behavior irregular computations acm performance evaluation review proc 
sigmetrics performance 
saavedra smith measuring cache tlb performance effect benchmark run times ieee transactions computers 
rivera 
tseng comparison compiler tiling algorithms proc 
th int 
conf 
compiler construction lecture notes computer science vol 
pp 

