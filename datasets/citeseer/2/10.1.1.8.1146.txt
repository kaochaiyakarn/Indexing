model animation gesture virtual conversational agents supposed combine speech nonverbal modalities intelligible utterances 
automatic synthesis gestures problems naturalness procedurally generated animations flexibility pre defined movements synchronization speech 
focus generating complex multimodal utterances including gesture speech descriptions overt form 
describe coordination model reproduces transition effects modalities 
particular efficient kinematic approach creating gesture animations shape specifications provides fine adaptation temporal constraints imposed synchrony 

techniques artificial intelligence computer animation human computer interaction converging growing field embodied conversational agents 
agents envisioned properties humans face face conversation including ability generate simultaneous verbal nonverbal behaviors 
includes gestures humans produced automatically unconsciously speech part integrated utterance 
modalities tightly coupled semantics pragmatics timing observed gestures influenced communicative intent verbal utterance ways 
consequence animation gestures requires high degree control flexibility gesture shape time properties time ensuring naturalness movement 
demand realism real time capability multimodal agents led gestural behaviors cap stefan artificial intelligence group faculty technology university bielefeld bielefeld germany mail uni bielefeld de tured real humans manually predefined large extent 
employed techniques suffer limited flexibility comes adjusting gesture timing accompanying speech cf 
concatenating continuous motion 

multimodal interaction max 
lab anthropomorphic agent max see fig 
scenario acts assembly expert immersive virtual environment simulated construction design tasks 
agent demonstrates assembly procedures user combining facial upper limb gestures spoken utterances 
synthesizing max utterances focusses creating synchronized gestural verbal behaviors solely descriptions outer form 
gesture animation process builds hierarchical model planning controlling upper limb movements articulated planning stages explained 
discussing related section section describes specify utterances agent 
section explains approach motion control creating appropriate gesture animations real time 
coordination framework producing fluent complex multimodal utterances multiple verbal gestural parts section 
related concerning animation lifelike gesture embodied agents relies concatenating predefined motion elements drawn static libraries 
conversational agents communicative acts usually mapped motion planning behaviors identified stereotyped movements 
motion primitives slightly parameterized combined form complex movements means highlevel script languages 
animated conversation rea system beat system succeeded predicting timing gesture animations stroke coincides nuclear stress speech :10.1.1.111.5468
cassell states problem creating final gesture animations synchronizing speech solved far due part difficulty reconciling demands graphics speech synthesis software 
extent ascribed lack sufficient means modulating shortening stretching single gesture phases cf 
preserving human movement characteristics :10.1.1.111.5468
fully automatic creation upper limb movements means applying appropriate control models targetted researchers 
approaches control algorithms dynamic simulations optimization criteria provide high level control may lead physically realistic movements 
techniques suffer difficulties formulating appropriate control schemes highly articulated figures immense computational cost 
koga proposed purely kinematic model simulating pre planned arm movements grasping manipulating objects 
particular succeeded applying findings neurophysiology create natural arm postures 
apply generic error correcting controllers generating sign language script specifications 
models succeeded simulating natural movement characteristics extent focus meet various timing constraints required gesture 
summary problem synchronizing synthetic gestural spoken utterances solved far bringing single points modalities coincidence 
commonly agreed insufficient virtual agents shall able produce extensive multimodal utterances smooth lifelike fashion 

specification utterances approach synthesizing multimodal utterances starts straightforward descriptions overt form xml specification language see fig 

descriptions contain verbal utterance augmented nonverbal behaviors including gesture 
utterance specification take id time bar true time id id time big 
id time specification id gesture affiliate onset function name refer loc gesture param name value loc bar function gesture id gesture affiliate onset constraints gesture symmetrical dominant right arm symmetry parallel static slot handshape value static slot value mode absolute static value slot slot dynamic segment type linear value type start name value name type direction value type distance name segment dynamic parallel symmetrical constraints gesture utterance definition 
sample xml specification multimodal utterance 
correspondence gesture speech surface level commonly assumed exist certain units different levels hierarchical structure modalities 
kendon defined units gestural movement consist gesture phrases comprise subsequently performed movement phases notably preparation holds stroke retraction 
intonational contour connected speech english languages including german organized intonational phrases cf 

phrases separated significant pauses display meaningful pitch contour exactly prominent pitch accent nucleus adopt empirically suggested assumption continuous speech gesture produced successive units expressing single idea unit 
define chunks speech gesture production consist intonational phrase overt speech expressive gesture phrase complex utterances multiple gestures considered consist chunks 
chunk gesture supports prominent concept stroke corresponds focussed constituent affiliate single word subphrase words intonational phrase nuclear accent 
element focussed primary pitch accent ex presses prominence 
specification language points time defined inserting markups verbal utterance 
time tags annotated define chunk borders furthermore express cross modal correspondence specifying onset affiliate definition gesture see fig 

particular gesture stated terms spatiotemporal features stroke meaningful phase 
underlying idea xml gesture representation gestural movement considered combination defining features location wrist shape hand orientation wrist described direction extended fingers palm orientation 
feature value defined numerically symbolically augmented sign language descriptions constrained held certain period time static perform significant dynamic composed subsequent segments 
structure gesture relationships feature constraints moving hand keeping fist 
simultaneity repetition symmetry features denoted specific xml elements constituting constraint tree gesture 
explicitly describing features appropriate gesture desired communicative function behavior stated sufficient agent choose gesture lexicon xml definitions 

iconic gesture described fig 
gesture 
fig 
shows description utterance comprising deictic iconic gesture specified terms required communicative function refer loc 
second gesture defined movement right hand addition static wrist orientation hand shape 
left hand movement results gesture mirror symmetry sagittal plane 
resulting utterance german language created specification generation model described sections max web page iconic gesture depicted fig 

addition gestures nonverbal behaviors incorporated xml utterance spec www uni bielefeld de persons max html replacing gesture tag 
includes arbitrary body movements facial animations defined timed keyframe animations joint angles face muscle values 

gesture planning animation creation gesture animations feature descriptions requires model motion planning control upper limb movements 
higher level planning described movement constraints gesture stroke fully qualified parameter assignment timing temporally ordered separately transferred independent motor control modules 
currently system provides distinct modules hand wrist arm neck face agent 
integration various motion generators vital simulating complex hand arm movements adopt functional decomposition motion control limb motion controlled motor program employs local motor programs animating necessary limited set dofs designated period time see fig 

may differ employed motion generation method working external coordinates joint angles 
lower level planning instantiated prepared motor control modules respective scope hand module adds affecting joints hand 
different movement phases may need created different motion generators concatenated assigning predecessor successor relationships 
example preparation stroke phases wrist bending controlled externally applying quaternion interpolation lmp wrist retraction created joint angle space 
arm control wrist control hand control preparation stroke retraction overshoot motor program 
composition motion control hand arm gesture 
result motor program gesture stroke created fly motor control modules feature constraints disposal 
example composition low level controllers visualized fig 

gesture planned separately subsidiary gesture phases fluent transitions completely prepared planning 
act behaviors able activate run time current movement conditions indicated dashed edges lmp boxes fig 
connect boundary conditions 
addition lmp may transfer control predecessor successor respectively 
activated applied kinematic skeleton agent 
frame externally formulated wrist position preparation stroke wrist flexion invoked 
inverse kinematics arm solved analytical algorithm 
arm redundancy interpreted angle elbow shoulder wrist axis controlled dedicated lmp determined sensorimotor transformation proposed flanders applied system koga 
directly affect joint angles neck hand motion wrist retraction influence solution configuration adding continuous displacement overriding certain set angles 
employ suitable motion generation methods 
particular importance control arm movement accomplished joint angle space terms wrist trajectory cartesian coordinates 
gestures reproduce shape properties prescribed xml specification decided create arm movement trajectories working space stroke phase 
describe method constructing parametric curves meet position timing constraints resembling natural arm trajectories 

formation arm trajectories approach forming wrist trajectories rests assumption complex arm movements consist subsequently performed elementary units stereotypical properties short targetted movements approximately straight exhibit symmetrical bell shaped velocity profile working point quasi linear relation amplitude peak velocity approximate logarithmic relation amplitude movement duration fitts law holds 
segmentation complex movements corresponds points maximum curvature working point trajectory breakpoints 
points move ment speed drops estimated radius trajectory assumed constant space front 
relying assumptions path kinematic arm movements reproduced local behavior trajectory segmentation points 
intermediate representation formed arm motor control module continuous movement phase rest periods 
consists sequence linear guiding strokes bridging segmentation point combined approximate curvilinear circular segments 
lmp created fig 
activated run time completes trajectory formation inserting preparatory guiding stroke current start conditions estimating velocities interior segmentation points constructing parametric curve 
direction velocity guiding strokes unit tangent assumed parallel chord velocity depends spans adjacent guiding strokes time intervals breakpoints average velocity estimated eq 

reciprocal radius small angles equals rate change tangent assume tangent vector tends direction estimate trajectory radius vectors eq 

speed derived angle law 
note reducing value constant causes sharp lower velocities breakpoints greater values lead continuous smoother movement 
constant assigned value large ensure velocity drops segmentation points 
non uniform cubic splines applied construct composite curve satisfies position velocity constraints breakpoints 
interior knot set double multiplicity equal corresponding breakpoint 
narrows influence control points intended fact movement determined local properties breakpoints 
consequently interior velocities major means controlling trajectory 
resulting continuous spline calculated position velocity constraints gives smooth trajectory reproduces symmetrical bell shaped velocity profiles movement unit 
furthermore quasi constant relationship amplitude maximum speed human movement constant durations accounted 
dynamic properties may play important role gestures emphasized synchrony speech 
accentuation movement created acceleration additionally deferring velocity peak resulting shorter period stronger deceleration extended trajectory formation model adjustable 
sample arm movement speed profile deferred velocity peak 
placing moment maximum velocity single guiding strokes 
example trajectory velocity profile simple performed gesture comprising guiding strokes shown fig 

bell shaped speed profiles lower velocity breakpoint due higher curvature automatically reproduced 
addition velocity peak second guiding stroke depicting pulling action deferred emphasize gesture execution 
animation examples created real time solely xml feature descriptions aforementioned web page 

speech gesture coordination described gesture generation methods need embedded larger production framework combines cross modal synchrony chunk seamless flow speech gesture successive chunks 
planning execution subsequent chunks system interleaved chunk processed separate blackboard running series processing states see fig 

planning separate modules speech synthesis movement planning contribute concurrently planning process 
stage connecting effects created chunk anticipated pitch level speech kept gesture retraction planned lead interim rest position 
chunk planning completed state set 
chunk uttered preceding chunk see scheduler passes control chunk lurking behaviors activate autonomously 
point preceding gesture may fully retracted fluent gesture transitions emerge depending placement affiliate verbal phrase see fig 

depending feedback information behaviors permanently collected blackboard chunk state switches eventually intonational phrase gesture stroke completed retracting active 
phonological encoding chunk chunk movement planning phonological encoding speech gesture movement planning affiliate stroke done skipped retraction pending lurking affiliate stroke 
incremental chunk processing 
speech gesture case affiliate located early intonational phrase gesture preparation precedes speech gesture anticipates verbal utterance observed humans 
due predefined movement acceleration limits vocal pause subsequent intonational phrases may stretched depending size preparation phase cf 
fig 

adaptation gesture speech articulated prepared text speech system 
chunk gesture scheduled onset stroke precedes coincides primary stress accompanying speech segment 
assignment gesture xml specification affects intonation verbal phrase 
utilizing set sable tags affiliate marked emphasized text speech system controls prosodic parameters speech rate intonation order create natural pitch accents 
resulting timing information asserted chunk blackboard utilized compose lip synchronous speech animations schedule accompanying gesture applying scheduling onset gesture stroke set precede affiliate onset approximately syllable duration sec :10.1.1.111.5468
stroke set span affiliate retraction starts 
dynamic strokes currently done simply adjusting execution velocity 
alternatively stroke may performed comfortable speed compensate longer affiliate extraordinary hold additional strategies observable humans 
gesture dynamically created described section 
sable international standard marking text input speech synthesizers 

lifelike multimodal utterances great variety highly desired conversational agents 
drawing predefined behaviors fixed libraries existent systems verbal nonverbal utterances system created fly xml specifications overt form 
hierarchically organized model motion control developed generating gesture animations real time 
comprises informed method forming parametric curve models natural path kinematics required wrist movement space 
novel approach creating gesture animations scratch provides satisfactory quality allows finely adapt gestural movements speech synchrony phoneme level achieved 
embedded framework incrementally planning executing complex utterances systematically employs articulation transition effects order reconcile continous flow speech movement temporal synchrony constraints 
exceeds ability current multimodal agents synchronization synthetic gestural spoken utterances accomplished simply bringing single points behaviors coincidence independent respects 
natural employ flexibility method temporal adjustment movement enable coordination modalities level gesture stroke affiliate 
particular synchronisation moments stress gesture speech may yield coordinated accentuation underlying rhythmic pulse 
include timing velocity peaks single movement phases taken account approach 
likewise text speech system offers mechanisms synchronize stressed syllable external events 
addition gesture animation model explored variations constants influence relationship trajectory curvature velocity 
modulating values systematically reasonable limits may enable modulation agent style movement 
cassell 
nudge nudge elements face toface conversation embodied conversational agents 
cassell chapter pages 
cassell bickmore campbell yan 
human conversation system framework designing embodied conversational agents 
cassell chapter pages 
cassell pelachaud badler steedman becket douville prevost stone 
animated conversation rule generation facial expression gesture spoken intonation multiple conversational agents 
proceedings siggraph 
cassell sullivan prevost churchill editors 
embodied conversational agents 
mit press cambridge ma 
cassell bickmore :10.1.1.111.5468
beat behavior expression animation toolkit 
proceedings siggraph 
churchill cook hodgson prevost sullivan 
may help designing embodied conversational agent allies 
cassell chapter pages 

high level specification animation communicative gestures 
journal visual languages computing 
kendon 
speech aspects process utterance 
key editor relationship verbal nonverbal communication pages 
hague mouton 
koga kondo latombe 
planning motions intentions 
proc 
st annual conference computer graphics pages 

knowledge approach lifelike gesture animation 
horn editor ecai proceedings th european conference artificial intelligence pages amsterdam 
ios press 

control human movement 
human kinetics publishers champaign il usa 
levelt 
speaking 
mit press cambridge massachusetts 
mcneill 
hand mind gestures reveal thought 
university chicago press chicago 
morasso 
trajectory formation 
morasso editors human movement understanding 
elsevier science publishers north holland 
perlin goldberg 
improv system scripting interactive actors virtual worlds 
siggraph proceedings rd annual conference computer graphics pages 
henning 
version hamburg notation system sign languages introductory guide volume international studies sign language communication deaf 
signum press hamburg germany 
rickel johnson 
animated agents procedural training virtual reality perception cognition motor control 
applied artificial intelligence 
flanders 
sensorimotor representations pointing targets dimensional space 
journal neurophysiology 
badler 
real time inverse kinematics techniques anthropomorphic limbs 
graphical models 

lifelike gesture synthesis timing conversational agents 
proceedings gesture workshop london uk 
appear 
zeltzer 
motor control techniques animation 
ieee computer graphics applications november 
