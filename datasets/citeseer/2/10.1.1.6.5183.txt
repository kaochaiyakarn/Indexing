active learning multiple views ion alexandru muslea dissertation faculty graduate school university southern california partial fulfillment requirements degree doctor philosophy computer science december copyright ion alexandru muslea dedication possible mara parents 
ii acknowledgments soon grows old 
gratitude 
aristotle half years advisors craig knoblock steve minton played crucial role life 
insights support patience allowed grow person am today 
craig steve gave opportunity join institution isi topic dreams machine learning find way researcher 
am extremely grateful 
want members thesis committee kevin knight margaret mclaughlin ray mooney paul rosenbloom feedback support greatly appreciated 
years kevin knight influenced ways provided fresh perspective initiated secrets em algorithms ed hovy introduced fascinating world natural language processing 
paul rosenbloom played key role development dissertation 
ability find weak points helped clean tighten arguments 
challenging part dissertation formal results origins question asked april qual exam 
iii ray mooney great mentor keeps amazing friendliness ness constant support 
ray helped member machine learning community 
trust constant source motivation 
phd student chance ray years school fortunate encounter teachers motivated shaped thinking greatly influenced maria valentin mihai ian moldovan kalman ia william yolanda gil len adleman ed hovy 
deserves express 
wonderful friends ways successes theirs 
live think didn adrian sa fritsch diana moldovan robin ma daniel marcu marius mihai dan lg iu lin ca alm si marcu monica moldovan look back started answer parents ioana mica people revolving provided unique environment prepared journey 
lucky belong world wish create similar experience kids 
people give sense life mara love support sacrifice dissertation happened 
really mattered love care smile proud 
love 
iv contents dedication ii acknowledgments iii list tables viii list figures ix xi motivating problem wrapper induction 

testing multi 
emt interleaving active semi supervised learning 
view validation views adequate multi view learning 

contributions 
thesis overview 
preliminaries 
minimizing required amount labeled data 
semi supervised learning 

multi 

summary 
testing family active learning algorithms testing vs single view selective sampling 

learning strong weak views 

high low 
convergence properties single view algorithms 
convergence properties multi view algorithms 
views independent label 

discussion 
testing wrapper induction 
naive testing stalker 


wrapper induction experiments 



wrapper induction 
discussion 
summary 
active semi supervised robust multi view learning 
semi supervised algorithms comparison 

semi supervised em algorithm 


testing em emt 


discussion 

summary 
view validation 
features view validation 


generating wi ptct datasets 

influence size lk 
distribution errors 

summary 
vi related 
active learning query construction 

testing vs existing active learners 
semi supervised concept learning 
single view semi supervised classification 

expectation maximization 
unlabeled data background knowledge 
multi view semi supervised learning 
emt vs 
meta 

knowledge 

meta 

main contributions 


multi view vs single view model selection 
limitations 

list appendix 
convergence properties single view algorithms 
convergence properties multi view algorithms 
views independent label 

appendix semi 
vii list tables 
algorithms empirical comparison ad courses 


newsgroups included domain 
viii list figures 

pseudo code semi supervised learning 
pseudo 
pseudo training 
illustrative clumps courses domain 
illustrative testing step 
illustrative testing step 
illustrative testing step 

forward backward content extraction rules 
illustrative dhl 
illustrative dhl 
version space dhl 
ff fb 
hierarchy stalker wildcards 
empirical results testing wrapper induction 
convergence results wrapper induction tasks 
empirical results ad tf problems 
empirical results courses problem 
ix high level description training semi supervised em em results controlled experiment ptcp 
emt 

illustrative learning curves emt 
empirical results ptct 
illustrative clumps courses domain 



varying size lk 
varying size lk keeping constant 
distribution errors wi ptct 
distribution false positives negatives wi ptct 
illustrative trees wi ptct 
possible distributions examples dhl 
applying training dhl 
ideal solution dhl 
applying training dhl 
illustrative scenarios contention points 



labeling training data machine learning algorithms tedious time consuming error prone 
consequently utmost importance minimize amount labeled data required learn target concept 
focus reducing need labeled data multi view learning tasks 
key characteristic multi view learning tasks target concept independently learned different views disjoint sets features sufficient learn concept interest 
instance robot navigation view learning task robot learn avoid obstacles sonar vision sensors 
dissertation main contributions 
introduce testing active learning algorithm exploits multiple views 
testing idea learning mistakes 
precisely queries examples views predict different label views disagree guaranteed mistake 
variety real world domains information extraction text classification discourse tree parsing testing outperforms existing active learners 
second show existing multi view learners perform views incompatible correlated 
cope problem introduce robust multi view learner emt interleaves semi supervised active multi view learning 
empirical results show emt outperforms existing multi view learners wide variety learning tasks 
third introduce view validation algorithm predicts views adequate solving new unseen learning task 
view validation uses information xi acquired solving exemplar learning tasks train classifier discrim tasks views adequate inadequate multi view learning 
experiments wrapper induction text classification show view validation requires modest amount training data high accuracy predictions 
xii chapter men nature desire knowledge 
aristotle induction plays central role variety disciplines artificial intelligence philosophy statistics psychology 
inductive learning defined inferring generalization series examples typically described set features 
inductive learning algorithms set classified examples asked generate class description concepts classes interest class descriptions subsequently classify new unseen examples 
words human labels number training examples inductive algorithm creates classifier discriminates various concepts interest 
learning algorithms successfully plethora fielded applications making credit decisions michie classifying celestial objects fayyad reducing banding printing evans fisher improving separation gas oil 
practice labeling training examples tedious time consuming error prone process 
furthermore application domains labeling example extremely expensive may require running costly laboratory tests 
multi view learning algorithms represent development coping problem 
algorithms apply learning problems multiple views disjoint sub sets features views sufficient learn concepts interest 
instance described blum mitchell classify segments broadcast video audio information classify web pages words appear documents hyperlinks pointing :10.1.1.114.9164:10.1.1.114.9164
existing research multi view learning blum mitchell collins singer pierce cardie focused semi supervised learning techniques learn concept definition combining small set labeled large set unlabeled examples :10.1.1.114.9164:10.1.1.114.3629
unlabeled examples provide direct information concepts learned 
shown miller uyar nigam shahshahani landgrebe ghahramani jordan raskutti kowalczyk distribution boost accuracy classifier learned small set labeled examples :10.1.1.1.5684
intuitively existing multi view algorithms proceed follows small labeled training set learn classifier view bootstrap views augmenting training set unlabeled examples views high confidence predictions 
algorithms try best possible implicit information provided distribution unlabeled examples 
focus improve accuracy classifiers learned small set labeled data 
contrast semi supervised learning active learning algorithms seung opper cohn atlas ladner lewis catlett roy mccallum tong koller aim minimizing amount labeled data required learn concept interest :10.1.1.119.2797
active learners typically detect ask user label informative examples domain reducing user involvement data labeling process 
goal thesis reduce user burden minimizing amount labeled training data sacrificing accuracy learned classifiers 
reach goal introduce testing algorithm muslea minton knoblock novel approach active learning 
testing multi view active learner maximizes benefits labeled training data providing principled way detect informative examples domain allowing user label 
analyzing testing properties formal empirical introduce extensions cope main limitations inability exploit unlabeled examples queried difficulty deciding learning task appropriate multi view learning 
address issue introduce new algorithm emt interleaves testing em nigam ghani semi supervised multi view algorithm 
hybrid algo rithm combines benefits active semi supervised learning detecting informative examples boosting accuracy classifiers exploiting remaining unlabeled examples 
second introduce adaptive view validation algo rithm predicts multi view learning appropriate new unseen learning task 
view validation algorithm meta learner predictions experiences acquired solving past learning tasks 
motivating problem wrapper induction world wide web computer users gained access large variety com information repositories 
web browsing paradigm difficult retrieve integrate data multiple sources 
information integration systems ariadne knoblock whirl cohen information mediator example information agent plots map location restaurants interest 
agent combines data information sources restaurant reviews county department health web site tiger maps service 
information manifold kirk address problem enabling informa tion pre specified sets web sites accessed combined database queries 
consider illustrative agent takes input queries show map locations thai restaurants los angeles rated county department health services 
order answer query agent combine data web sources web site obtain name address thai restaurants county web site get health rating restaurants interest site obtain latitude longitude physical address tiger map service plot map location geographic location latitude longitude 
information agents generally rely wrappers extract information semi structured web pages document semistructured location relevant infor mation described concise formal grammar 
wrapper consists set extraction rules code required apply rules 
manually writing extraction rules time consuming task requires high level expertise re searchers designed wrapper induction algorithms learn extraction rules user provided examples muslea minton knoblock kushmerick hsu dung 
practice information agent may hundreds extraction rules updated format corresponding web documents changes 
manually labeling training examples extraction rule tedious error prone task utmost importance wrapper induction algorithm learns high accuracy rules minimal number labeled examples 
note minimal training sets high accuracy rules crucial successful deployment information agent 
minimizes amount required create information agent making task manageable 
required order ensure quality agent answer query 
illustrate practical importance having high accuracy extraction rules consider scenarios extraction rules sources accurate extract correctly items interest follows restaurants satisfy query displayed map contrast extraction rule accurate follows thai restaurants extracted site 
similarly health ratings extracted restaurants retrieved county site agent rated thai restaurants 
provided latitudes extracted correctly follows restaurants interest displayed 
despite practical importance learning highly accurate wrappers small number labeled examples little active learning wrap induction 
furthermore existing general purpose active learners applied straightforward manner wrapper induction 
practical importance lack efficient solutions wrapper induction main motivating problem dissertation 
algorithms introduced thesis specific wrapper induction applied multi view problems including wrapper induction 
approach section wrapper induction problem illustrate main butions dissertation 
precisely provide intuitive high level description novel algorithms introduce thesis 
chapters come algorithms applied variety multi view learning problems web page classification advertisement removal text classification discourse tree parsing 
testing multi view active learning testing multi view approach active learning works follows 
uses small set labeled examples learn classifier view 
applies learned classifiers unlabeled examples asks user label examples views predict different labels 
adds newly labeled example training set repeats process 
intuitively testing relies observation classifiers learned view predict label unlabeled example classifiers mistake particular prediction 
asking user label example testing guaranteed provide useful information view mistake 
real world noise effects intrude learning process translating simple intuition effective algorithm raises interesting issues analyzed thesis 
order understand testing works wrapper induction consider illustrative task extracting restaurant phone numbers documents similar web page fragment shown 
order extract information wrapper name phone cuisine 
forward rule backward rule detect restaurant phone number 
forward backward rules semantics differ terms applied start document direction 
detect phone number 
instance order find phone number begins rule skipto phone rule applied forward page ignores finds string phone 
note way detect phone number begins 
alternative way perform task rule backto cuisine backto number applied backward document 
ignores finds cuisine skips number parentheses 
note represent descriptions concept phone number learned different views 
views consist sequences characters precede follow item respectively 
view called forward view backward view 
views testing applied straightforward manner wrapper induction 
shown chapter testing clearly outperforms existing state art algorithms wrapper induction variety real world domains 
emt interleaving active semi supervised learning natural extension testing minimize need labeled data learning unlabeled examples queried 
thesis introduce novel algorithm emt interleaves active semi supervised learning 
precisely emt combines testing em nigam ghani multi view semi supervised algorithm 
intuitively em represents iterative step process uses hypotheses learned view probabilistically label unlabeled examples 
em learns new hypothesis view training probabilistically labeled examples provided view 
interleaving active semi supervised learning emt creates powerful syn ergy 
hand testing boosts em performance providing highly informative labeled examples randomly chosen ones 
hand em provides testing accurate classifiers em testing small set labeled examples complemented large set unlabeled ones allowing testing learn accurate hypotheses informative queries 
emt directly applied wrapper induction stalker probabilistic learning algorithm 
illustrate main idea hind emt describing generic wrapper induction algorithm emt wi combines active semi supervised learning 
precisely emt wi combines testing semi supervised wrapper induction algorithm described 
order perform semi supervised wrapper induction third view evaluate confidence extraction 
new content view describes actual item extracted 
example phone numbers extraction task labeled examples learn simple grammar describes field content number number number 
similarly extracting urls learn typical url starts string www ends string html contains html tags 
forward backward content views implement follow ing semi supervised wrapper induction algorithm 
small set labeled examples learn hypothesis views 
forward backward views feed unlabeled examples high confidence ex tractions 
high confidence extractions strings extracted forward backward rule compliant grammar learned third content view 
testing semi supervised learner implement emt wi works follows 
small set labeled large set unlabeled examples semi supervised learning 
second extraction rules learned previous step testing 
making query newly labeled example added training set process repeated number iterations 
empirical study chapter shows emt outperforms testing semi supervised learners considered comparison 
view validation views adequate multi view learning 
dissertation introduce problem view validation multi view learning task user choose solving multi single view algorithm 
words know multi view learning outperform pooling features applying traditional single view learner 
note question answered having access just labeled examples applying single multi view active learners comparing relative performances self defeating strategy doubles amount required labeled data label queries algorithms 
need view validation algorithm motivated observation applying testing dozens extraction tasks noticed forward backward views appropriate learning problem 
view adequacy issue tightly related best extraction accuracy reachable view 
consider example extraction task forward backward rules lead high low accuracy rule respectively 
note testing appropriate solving tasks definition multi view learning applies tasks view sufficient learning target concept obviously low accuracy view sufficient accurately extracting item interest 
order cope problem introduce adaptive view validation novel meta learner uses experiences acquired solving past learning tasks predict views new unseen task adequate multi view learning 
view validation algorithm takes input solved extraction tasks labeled user having views adequate inadequate multi view learning 
uses solved extraction tasks learn classifier new unseen tasks predicts views adequate multi view learning 
meta features view validation properties hy solved task learned view percentage unlabeled examples rules extract string difference complexity forward backward rules difference errors training set shown chapter wrapper induction additional text classifica tion problem view validation algorithm high accuracy predictions modest amount labeled data 
thesis statement dissertation introduce evaluate approach multi view active learning 
thesis dissertation multi view active learning maximizes accuracy learned hypotheses minimizing amount labeled training data 
contributions thesis main contributions 
introduce novel approach active learning 
describe testing family multi view active learning algorithms applied multi view learning problem regardless algorithm learn classifiers view outperforms existing active learning algorithms variety real world domains including wrapper induction web page classification advertisement removal discourse tree parsing 
analyze practical problems arise multi view assumptions violated introduce extensions cope problems 

introduce novel multi view learning algorithm emt obtains ro bust behavior wide spectrum problems interleaving active semi supervised multi view learning 

formalize view validation problem introduce adaptive view validation algorithm uses meta learning predict multi view learning appropriate new unseen learning task 
thesis overview dissertation organized follows 
chapter presents terminology notation rest dissertation 
discusses intuition multi view learning underlying assump tions 
chapter introduces testing family multi view active learning algorithms 
formalizing testing approach active learning series experiments compare testing existing single view active learning algorithms 
chapter describes simple experiment emphasizes drawbacks exist ing semi supervised multi view algorithms 
presents novel multi view algorithm emt interleaves active semi supervised learning 
chapter introduces view validation goal predict multi view learning appropriate new unseen learning task 
chapter compares contrasts related approaches 
chapter concludes summarizing contributions proposing directions 
appendix provides proofs formal properties chapter 
appendix describes semi artificial family multi view text classification tasks control level multi view assumptions violated 
problems evaluate robustness various multi view algorithms 
chapter preliminaries static repetitive boring 
dynamic random confusing 
lies art 
john locke goal dissertation minimize amount labeled data required learn concept interest reducing user burden creating systems machine learning techniques 
situated confluence areas research active learning semi supervised learning multi view learning 
chapter introduces main ideas fields reader notation terminology dissertation 
terminology notation noted mitchell machine learning involves acquiring general concepts specific training examples 
concept learning algorithm automatically infer definition concept starting examples members non members concept interest 
example consider problem discriminating sake simplicity chapter discusses concept learning scenario learner discriminates classes interest 
notation terminology generalize straightforward manner classes 
students faculty computer science department 
descriptions students faculty inductive algorithm may learn say faculty year 
terminology 
learning problem set possible examples called instance space denoted represents particular example instance 
example represented feature vector stores values various attributes features 
instance student faculty problem feature vector may contain attributes name salary social security number age number publications 
concept learned called target concept seen boolean function classifies instance member concept interest 
example student faculty problem classify examples student faculty respectively 
order learn target concept user typically provides set training examples consists instance label 
notation denotes training example 
instances called positive examples ones called negative examples 
symbol denote set labeled training examples known training set 
definition algorithm uses training labeled examples called supervised learner 
similarly learning algorithm trains labeled unlabeled called semi supervised unsupervised learner trained solely unlabeled examples clusters unlabeled examples similarities 
training set target concept inductive learning algorithm searches function 
learner searches set possible hypotheses typically determined person designs learning algorithm 
hypothesis consistent training set 
version space represents subset hypotheses consistent training set minimizing required amount labeled data labeling examples training set tedious time consuming error prone process 
consequently important learn target concept possible labeled examples 
dissertation am primarily interested types techniques reduce need labeled training data semi supervised learning active learning 
boosts accuracy supervised learner additional set unlabeled examples minimizes amount labeled data asking user label informative examples domain 
semi supervised active learning techniques share important 
set labeled examples additional working set examples examples seen pairs signifies example label unknown 
second semi supervised active learning techniques try maximize accuracy supervised base learner learn target concept 
semi supervised learning semi supervised learning tries improve accuracy supervised learner exploiting availability large set unlabeled examples typical semi supervised algorithm proceeds follows uses base learner small set labeled examples learn initial hypothesis applied unlabeled examples examples label predicted added entire process repeated number iterations 
base learner sets labeled unlabeled examples number iterations performed number examples added iteration semi supervised learning loop iterations leth classifier obtained training examples confident predictions mcp remove add semi supervised learning learn hypothesis labeled examples apply unlabeled examples add confident predictions training set 
repeat process number iterations 
intuition semi supervised learning straightforward initial hypothesis learned small training set highest confidence predic tions correct 
consequently adding high confidence examples training set obtains larger training set learn accurate hypothesis 
turn accurate hypothesis label examples 
shows pseudo code typical semi supervised learning algorithm 
general framework covers wide variety algorithms form self training nigam ghani semi supervised em mccallum nigam nigam :10.1.1.1.5684
adds just examples iteration size adds entire set re labeled iteration 
active learning definition passive learning algorithm takes input randomly chosen training set contrast active learning algorithm ability choose examples words active learning algorithms try detect informative examples learning algorithm sets labeled unlabeled examples number queries utility function utility selective sampling loop iterations leth classifier obtained training remove ask user label add selective sampling learn hypothesis labeled examples query unlabeled example maximizes utility function utility 
instance space ask user label 
examples chosen labeling called queries 
main approaches active learning query construction selective sampling 
queries example constructed setting value attribute resulting query informative possible 
contrast selective sampling form active learning queries chosen working set unlabeled examples selective sampling popular type active learning real world problems easy obtain large number unlabeled examples may able artificially construct query unlabeled exam ple informative examples high risk user may able label example correspond real world entity see lang baum details 
focuses selective sampling techniques terms active learning selective sampling interchangeably 
shown selective sampling starts small set labeled examples large set unlabeled examples uses base learner induce hypothesis queries unlabeled example maximizes utility function 
adding process repeated number iterations 
depending way generate hypothesis types active learning algorithms single hypothesis committee 
applies base learners reliably estimate confidence prediction 
single hypothesis active learners typically utility functions uncertainty reduction user asked label unlabeled example confident prediction 
expected error minimization system queries example maximizes ex pected reduction classification error 
contrast utility function committee active learning measures percentage version space removed query 
committee approach generates hypotheses committee queries example prediction committee split 
intuitively query removes half version space converging target concept log size queries 
multi view learning problems previous sections traditional single view machine learning scenario learners access entire set features domain 
contrast multi view setting partition domain features subsets views sufficient learning target concept 
instance perform speech recognition lip motions sounds determine robot position vision sonar sensors 
multi view learning problem example described different set features view 
example domain views labeled example triple label descriptions learning problem views base algorithm sets labeled unlabeled examples number iterations performed number examples added iteration training loop iterations create classifiers pl unlabeled examples confident predictions foreach pl pl remove pl add add training repeatedly learns hypothesis view adds training set confident predictions unlabeled examples 
views 
similarly unlabeled example denoted example denotes descriptions 
similarly consists descriptions examples previous approaches multi view learning consist semi supervised algorithms bootstrap views order boost accuracy classifier learned labeled examples 
multi view algorithms succesfully applied variety real world domains natural language processing collins singer pierce cardie sarkar speech recognition de sa ballard web page classification blum mitchell :10.1.1.114.9164:10.1.1.114.3629
illustrate intuition multi view learning briefly consider basic idea training algorithm blum mitchell :10.1.1.114.9164
training uses small set labeled examples learn initial classifier views see 
classifier applied unlabeled examples training detects examples classifier confident predictions 
high confidence examples labeled estimated class labels added training set 
updated training set new classifier learned view process repeated iterations 
note training similar semi supervised learner described 
main difference algorithms training views single view case algorithm self training nigam ghani 
practice multi view algorithms shown outperform single view counterparts nigam ghani ghani collins singer muslea minton knoblock muslea minton knoblock :10.1.1.114.3629
section briefly presents theoretical justification multi view learning pooling features single view learning algorithm 
issues multi view setting blum mitchell proved problem views target concept learned labeled unlabeled examples provided views compatible uncorrelated 
condition requires examples labeled identically target concepts view 
means example independent proof blum mitchell argument learn weak hypothesis labeled examples apply unlabeled examples :10.1.1.114.9164:10.1.1.114.9164
views uncorrelated newly labeled examples seen random training set classification noise learn target concept 
requirements views compatible uncorrelated crucial process 
views correlated training set random 
views incompatible target concepts views updated version blum mitchell shows theoretical guarantees hold partially incompatible views provided uncorrelated :10.1.1.114.9164
practice ignore view incompatibility rarely encounters real world problems uncorrelated views 
label differently large number examples consequently may examples learning target concept impossible 
introduce intuition view incompatibility correlation consider courses problem blum mitchell web pages classified course homepages pages views consist words hyperlinks pointing pages words web pages respectively :10.1.1.114.9164
shows illustrative examples domain 
lines represents example example depicted line connects descriptions views 
bottom examples lines course homepages consequently keep simple show examples labels 
note page may referred hyperlinks hyperlinks contain text may point different pages 
real world problems views partially incompatible variety reasons corrupted features insufficient attributes instance shown hyperlinks contain text neural nets point homepages neural nets classes third points publications page 
web pages different labels description 
consequently neural nets mit cs neural nets doe papers incompatible require neural nets simultaneously different labels 
practice views partially correlated domain best introduced example 
consider instance multi view examples ai homepages depicted lines ai clump rectangle 
group examples called clump bi partite subgraph vertices hyperlinks web pages respectively heavily connected edges representing examples 
note clumps class sufficient violate uncorrelated views assumption example itis highly descriptions views come clump 
intuitively view words hyperlinks related theory classes core theory classes algorithms cs related ai classes statistical models neural nets publications theory clump ai clump view words web pages cmu cs finite automata 
cmu cs intro algorithms 
uci cs theory algorithms 
usc cs artificial intelligence 
usc cs statistical learning 
usc cs neural networks 
mit cs intro neural nets 
doe papers neural networks 
illustrative positive clumps course courses domain ai theory clumps consist course ai theory classes respectively 
note knowing example description view provides information actual clump knowing example label example class consists clumps 
means examples cs uci cs theory algorithms connects theory ai clumps see 
summary section introduced basic terminology notation dissertation 
discussed main concepts ideas semi supervised learning 
introduced multi view learning discussed main assumptions multi view learning view independence compatibility 
chapter testing family active learning algorithms true genius lies capacity evaluation 
conflicting information winston churchill order learn classifier supervised learning algorithms need labeled training examples 
applications labeling training data expensive process requires human expertise tedious error prone time consuming task 
selective sampling reduces number training examples need labeled examining pool unlabeled examples selecting informative ones human label 
chapter introduces testing approach multi view active learning 
selective sampling techniques asking user label examples maximize information conveyed learner 
standard single view learning scenario generally translates finding example best splits version space half eliminating half hypotheses consistent current training set 
multi view domains better 
testing trains classifier view applies pool unlabeled examples selects query degree disagreement learners 
target concepts view agree testing reduce hypothesis space faster possible 
illustrate consider learning problem views imagine extreme scenario unlabeled example classified positive single hypothesis version space furthermore assume example classified positive hypotheses version space 
system queries particular example version space example positive case example negative collapses single hypothesis learning process 
testing vs single view selective sampling consider illustrative task classifying employees cs department categories faculty non faculty 
assume classification done person salary faculty salaries office number faculty office numbers 
case domain views uses salary uses office number 
views target concept threshold value salary office number 
learn target concept view base learner identifies pair labeled examples belong different classes closest attribute values 
sets threshold mean values 
testing works follows initially user provides labeled examples pool unlabeled ones 
unlabeled examples denoted points labeled ones appear denotes faculty represents non faculty 
testing uses base learner create classifier view classifiers geometrically represented dotted dashed lines respectively 
testing applies classifiers unlabeled examples determines contention points examples labeled differently classifiers 
contention points lay picture gray areas extremely informative salary office step initial training set testing learns hypotheses threshold values views 
contention points lay dark grey areas testing queries example hypotheses confident farthest away threshold values 
salary step adding training set testing learns new hypotheses queries example farthest away threshold values 
salary office office step adding training set learning new hypotheses testing stops contention points 
classifiers disagree wrong 
testing selects labeling contention points adds training set repeats process 
base learner evaluate confidence classification testing query contention point confident means query maximally improves hypotheses query remove half version space 
example confidence level predictions view proportional distance point corresponding threshold value larger distance higher confidence classification 
testing asks label example con point confident smallest distances thresholds maximal 
example labeled user training learns new hypothesis view finds new set contention points see query re trains time 
shown new classifiers agree unlabeled examples testing stops 
mentioned single view active learning best hope remove half version space query 
illustrate idea consider uncertainty sampling algorithm lewis gale uses labeled data learn classifier queries points classifier confident 
just views example lowest confidence points ones closest learned threshold value 
query uncertainty sampling removes approximately half version space follows single view algorithm requires queries testing learn target concept 
comparison single view active learners testing major advantages 
combining evidence views allows queries lead maximal improvements views 
second querying contention points testing guaranteed ask label example classifiers wrong 
detecting mistakes current hypotheses utmost importance base learners decision trees improve mistakes 
testing family algorithms provides formal description testing family algorithms 
base learner labeled examples set unlabeled ones testing algorithm works follows learns classifiers applying algorithm projection examples views 
applies unlabeled examples creates set contention points consists unlabeled examples predict different label 
queries contention points repeats process 
making allowed number queries testing uses hypotheses learned view create final output hypothesis 
various members testing differ re strategy select query manner output hypothesis constructed 
words testing algorithm uniquely de fined choice functions 
functions depend properties application domain base learner consider types query selection strategies naive choose random contention points 
strategy appropriate base learners lack capability reliably estimating confidence predictions 
aggressive choose contention point con prediction 
aggressive testing designed high accuracy domains little noise 
problems discovering unlabeled examples base learner learning problem features views sets labeled unlabeled examples respectively queries loop iterations create classifiers remove ask label add testing family algorithms repeatedly learn classifier view query contention points unlabeled example views different prediction 
misclassified high confidence translates queries remove significantly half version space 
conservative choose contention point confidence predictions close possible equal confidence predict different label 
conservative testing appropriate noisy domains aggressive strategy may querying noisy examples 
creating output hypothesis allows user choose variety alter natives winner takes output hypothesis learned view smallest number mistakes queries 
obvious solution view learning problems base learner estimate confidence predictions 
majority vote testing predicts label predicted hy learned various views 
strategy appropriate views available base learner estimate confidence predictions 
weighted vote combines vote hypothesis weighted confidence respective predictions 
learning strong weak views multi view setting assumes view sufficient learn target concept 
practice views learn concept strictly general specific concept interest 
terms strong weak views discriminate views describe actual target concept ones learns general specific concept 
example consider wrapper induction task described 
phone number extracted forward rule backward rule see follows forward backward views strong views 
contrast content view weak view grammar number number number describes concept general interest discriminate various types numbers may appear document home cellular fax numbers 
despite limitations content view extremely informative testing 
example grammar number number number detect informative contention points unlabeled examples strong rules extract different strings inconsistent content grammar 
scenario query represents mistake strong views leading faster convergence 
formally weak views exploited query selection strategy 
context learning strong weak views redefine contention points unlabeled examples strong views predict different label 
choose query contention points weak view confidently skipto phone backto fax backto name phone fax 
number number number forward rule backward rule detect restaurant phone number 
rule consists grammar describes content item extracted 
contradicts strong views 
queries highly represent mistake strong views implies large cuts strong version spaces 
section describe aggressive testing algorithm wrapper induction uses strong weak views 
idea combining strong weak views clearly appears applications wrapper induction formalized active learning 
example kushmerick johnston mcguinness authors discuss problem classifying various lines text card person name affiliation address phone number fax application strong view consists words appear line naive bayes text classifier learned 
weak view kushmerick exploit relative order lines card learn hidden markov model predicts probability particular ordering lines card name followed address followed phone number 
weak view defines class concepts general target concept line orderings possible equally probable 
order text lines accurately classify lines 
combined strong view ordering information leads classifier clearly outperforms stand strong view kushmerick johnston mcguinness 
idea combining strong weak views appears discotex sys tem nahm mooney combines information extraction system strong view text mining weak view 
case task consists extracting relevant information computer science job postings newsgroup austin jobs discotex extract job title salary location programming languages development platforms required degree nahm mooney propose approach problem rapier algorithm califf mooney learn extraction rules item interest 
second apply learned rules large unlabeled corpus job post ings create database populated extracted information 
third applying text mining algorithm database learn rules predict value particular item values extracted fields 
example text mining algorithm may discover pattern job requirements include knowledge corba development platforms include windows 
fi nally information extraction system deployed rapier rules fail extract item interest rules mined text predict content particular item 
scenario rapier rules represent strong view rules sufficient extracting data interest 
contrast mined rules represent weak view learned 
furthermore dis discards accurate mined rules highly specific follows weak view learn concepts specific target concept 
nahm mooney show overly specific mined rules improve extraction accuracy capturing information complements rapier extraction rules 
testing 
order better understand testing works compares algorithms analyze behavior high low learning problem past study convergence query committee active learner ritter freund 
precisely high low problem compare contrast convergence properties types learning strategies active learning testing muslea minton knoblock uncertainty sam pling lewis gale query committee seung opper ski semi supervised learning training blum mitchell random sampling randomly choose examples labeled :10.1.1.114.9164
analysis focus variants high low problem dhl dhl 
seen formalization multi view faculty non faculty learning problem discussed section represents single view version dhl discriminate faculty non faculty solely person salary 
dhl dhl illustrate convergence properties single view multi view learning algorithms respectively 
high low learning problems view discretized high low problem dhl goal learn target function form wtc wtc wtc andl 
words goal learn threshold value wtc divides interval sub intervals examples label furthermore learner identify labels denotes positive negative examples respectively andf 
illustrates learning task wtc andl 
dhl assumptions illustrative dhl task wtc andl positive negative examples 
real valued variable uniform distribution interval target concept perfectly learnable noise domain 
view discretized high low learning problem dhl dimensional version dhl 
dhl target function takes form tc tc tc tc tc tc tc tc tc tc andl 
shown translates dimensional instance space di vided rectangular regions 
top right bottom left quadrants populated positive negatives examples class occupy quadrant quadrant consists examples having label quadrants remain domain restriction tc tc tc tc 
dhl assumptions dhl real valued variables uniformly distributed rectangles tc tc tc tc target concept perfectly learnable 
full professor associate professor assistant professor post doc grad student illustrative dhl target concept 
domain classes clumps 
leftmost image shows dhl target concept splits instance space quadrants domain views independent label light dark grey rectangles depict uniform distribution examples negative positive regions instance space respectively 
contrast rightmost picture shows uniform distribution examples clumps dhl domain views independent clump 
note construction dhl multi view learning problem restriction domain tc tc tc tc guarantees thresholds tc tc correctly classify example 
resulting views consist single attributes respectively 
keeping multi view setting dhl decomposed solving dhl problem view 
corresponding target functions tc tc tc tc perfect learnability target concept implies perfectly learnable 
turn guarantees compatibility views definition pair target concepts label examples identically compatible see chapter 
terms view correlation consider main scenarios example label views independent 
original multi view assumption blum mitchell example label values independent 
intuitively means guessing example description description difficult guessing example description label 
words terms guessing example description description label equally un informative 
similar statement holds guessing example description 
example clump views independent 
relaxed version assumption explained chapter domain corresponds having sub classes concept interest violates original view independence assumption 
example depicted faculty non faculty domain faculty class seen having clumps assistant associate full professors 
similarly non faculty class clumps graduate students post docs 
analysis consider simplest form domain domain target concept clumps form intuitively corresponds diagonal rectangular clumps touch single point furthermore clumps overlapping domains see 
easy see independent clump assumption imposes weaker domain constraints independent label allows clump class 
intuitively means terms guessing example description example description informative label example description determines clump belongs reducing range possible descriptions ones specific particular clump 
contrast knowing example label restricts set possible values larger set covers clumps class 
base learner 
base learner dhl views dhl gibbs algorithm mitchell proceeds follows searches labeled examples detects borders min max version space 
min smallest integer greater equal values negative examples see 
similarly max largest integer lower bound positive examples 
sets threshold randomly chosen integer range min max 
note gibbs algorithm possible base learned dhl 
example solve dhl deterministic base learner sets min max 
chosen gibbs algorithm straightforward reason query committee seung opper existing active learner theoretical proof convergence freund requires base learner randomly sample hypotheses version space 
gibbs algorithms simplest base learner fulfills requirement 
considered algorithms uncertainty sampling training sive testing rely ability hypothesis evaluate confidence predictions 
base learner prediction confidence measured version space min max positive negative examples determine min max borders version space dhl learning problem 
follows closer value unlabeled example threshold lower confidence prediction 
instance dhl task depicted predictions confident negative positive predictions re spectively 
confident predictions near decision threshold small positive real number 
convergence properties single view algorithms section comment convergence single view algorithms query committee uncertainty sampling random sampling 
proofs results chapter appendix proposition dhl problem uncertainty sampling algorithm requires log queries learn target concept 
proposition dhl problem arbitrarily high probability query committee algorithm requires log queries learn target concept 
proposition dhl problem probability random sampling gorithm correctly learns target concept randomly chosen examples propositions summarized follows dhl problem active learners converge number queries logarithmic size version space 
contrast regardless number queries random sampling third algorithm converges asymptotically target concept larger number examples larger probability converging 
note dhl uncertainty sampling query committee near optimal number queries 
dhl equivalent finding particular value sorted array follows general case better binary search requires log tests queries 
show section multi view setting converge faster 
convergence properties multi view algorithms views independent label results show multi view setting needs just examples learn target concept 
training set consists randomly chosen positive randomly chosen negative example training learns target concept labeled unlabeled examples 
testing examples initial training set additional queries learn target concepts views 
contrast optimal domain specific strategy requires just randomly chosen la example populated quadrants consists examples label follows examples quadrant share label examples quadrant label 
proposition domain specific knowledge solve dhl problem single randomly chosen query 
proposition dhl problem training algorithm requires ran dom positive random negative examples learn target concept 
proposition dhl problem provided random positive random negative examples aggressive testing requires queries learn target concepts views 
views independent clump results proved extremely strong unrealistic assumption views independent label 
relax condition assuming views independent clump allows faster converge single view algorithms 
theoretical results reinforced controlled text classification experiment described chapter 
section denote number clumps domain 
assume number clumps relatively small compared size domain min 
proposition domain specific knowledge solve dhl problem log queries 
proposition depending distribution examples initial training set training may may learn target concept dhl problem 
proposition dhl problem arbitrarily high probability aggressive testing learns target concept views making queries 
intuition results order discover clumps label correctly aggressive testing requires number queries linear 
min means aggressive testing faster query committee uncertainty sampling random sam pling 
contrast training guaranteed converge randomly chosen training set contains positive negative example decision border clumps decision border clumps ones corresponding post docs assistant professors 
optimal domain specific solution converges log queries performing binary search space clumps 
degenerate scenario views totally correlated equivalent log queries query committee uncertainty sampling 
discussion results require comments 
contrast single view learning scenario multi view setting imposes powerful constraints distribution examples domain 
exploiting constraints multi view learner converge target concept faster single view counterparts 
training testing implicitly exploit multi view assumption examples label views bootstrapping views asks user label examples label 
second analysis assumes domain noise free turn implies views compatible 
extending results noisy domains extremely difficult task single view framework 
straightforward observa tion noisy domains active learner queries querying mislabeled example uninformative misleading 
quantify ing exact effect noise tightly related distribution noisy examples instance space turn varies learning task 
analysis considered ideal scenario views independent label realistic views independent clump 
problems clumps class training guaranteed properly testing converges number queries linear number clumps 
relatively small number clumps implies faster convergence single view learners 
views correlated number clumps increases advantages multi view learning tend disappear 
testing wrapper induction wrapper induction item interest described strings variable length item content prefix suffix document 
typical machine learning representation example description view consists fixed number feature describe detail testing applied wrapper induction 
step introduce basic ideas stalker muslea minton knoblock state art wrapper induction algorithm base learner 
consider illustrative task extracting phone numbers documents similar web page fragment shown 
stalker rule consists start rule rule identify item respectively 
start rules extremely similar time describe 
instance order find phone number start rule skipto phone rule applied forward page ignores finds string phone 
slightly complicated extraction task toll free numbers appear italics disjunctive start rule skipto phone rule skipto phone alternative way detect phone number start backto fax backto number applied backward document 
ignores finds fax skips back number parentheses 
described muslea minton knoblock rules learned user provided examples items extracted 
note represent descriptions concept start phone number learned different views 
views forward view andv backward view consist sequences characters precede follow item respectively 
naive testing stalker extraction rules mentioned order extract item interest stalker detect item starts ends 
words item stalker learns target concepts start item start rule item rule 
start rules testing learns forward backward rule obtain types extraction rules simply various combinations forward backward start rules 
possible combinations turned practical importance muslea minton knoblock ff extraction rules forward start rule forward rule fb extraction rules forward start rule backward rule bb extraction rules backward start rule backward rule 
forward forward rule ff name phone cuisine 
skipto phone forward backward rule fb skipto number name phone cuisine 
skipto phone backto cuisine backward backward rule ff name phone cuisine 
backto backto cuisine types extraction rules ff fb 
illustrates ff fb rules 
example ff rule detects start item applying forward start rule forward rule applied 
bb rule works similar manner detects item backward rule start applying backward start rule point rule matched 
fb rule detects start item independently simply applying start rules start document respectively 
forward backward views applying testing wrapper induction straightforward process 
stalker uses labeled examples learn ward backward start rules 
rules create ff fb bb extraction rules 
contention points unlabeled examples extraction rules extract string 
stalker provide estimate confidence extraction testing algorithm forward backward views naive testing winner takes output hypothesis 
query randomly chosen contention points naive testing output hypothesis ff fb rules fewest mistakes queries winner takes 
aggressive testing strong weak views forward backward stalker views lead extraction rules rely context item extracted text surrounding item document 
described earlier addition strong views third content weak view describes actual item extracted 
example extracting phone numbers may able exploit fact described simple grammar number number number 
similarly extracting urls take advantage fact typical url starts string www ends string html contains html tags 
features describe content item extracted length range tokens seen examples 
instance phone number format number number number consist tokens numbers dash parentheses 
token types appear seen examples 
feature consists set specific wildcards number match tokens tered item extracted 
example phone number case list consists wildcards number punctuation 
complete hierarchy wildcards described 
alphabetic capitalized non html alphanumeric punctuation number html hierarchy wildcards stalker wrapper induction algorithm 
parent child relationship tree denotes relationship 
example general wildcard matches possible tokens 
wildcard child denotes tokens html tags alphanumeric tokens punctuation signs 
start pattern www number describes template item interest 
pattern html number number describes template item interest 
order learn content description item base learner seen simplified version algorithm lerman minton knoblock 
tokenizing user provided examples item extracted weak view learner proceeds follows length range determined finding examples contain largest smallest number tokens token types obtained going tokens appears labeled examples adding set seen types specific wildcard covers 
start pattern length consists specific wildcard covers token labeled examples note case examples start token phone number example actual token specific wildcard 
start pattern length generated repeating procedure second third 
th position 
pattern learned manner start pattern tokens item 
forward backward content views implement ag version testing wrapper induction 
stalker uses labeled examples learn forward backward start rules create ff fb extraction rules 
examples weak view learner generate corresponding content rule 
con points unlabeled examples extraction rules extract string 
views sophisticated version testing query contention point ff fb rules violate possible constraints learned weak view 
extracted strings longer shorter seen examples contain types tokens encountered training set start patterns match 
query selection strategy violating possible constraints learned weak views means content hypothesis maximally confident stalker rules extracting correct string 
output hypothesis obtained majority voting 
precisely new unseen document ff fb rules applied document remember query selection strategy mean querying contention point hypotheses confident prediction 
winner stalker rule violates smallest number constraints learned weak view 
note extremely flexible approach allows testing appropriate type rule ff fb individual document 
empirical evaluation section describes set experiments compare testing active learning algorithms 
results wrapper induction main motivating problem 
discuss experiments conducted additional real world domains features naturally partitioned views 
wrapper induction experiments algorithms comparison practice difficult find algorithms compare performance testing despite importance learning high accuracy wrappers minimal number labeled examples reported results active learning wrapper induction 
furthermore existing active learners applied straightforward manner base learners stalker wrapper induction algorithm uncertainty sampling lewis gale stalker unable evaluate confidence predictions query committee seung opper applied stalker randomly sample hypotheses version space related approaches thompson califf mooney soderland designed systems learn extraction rules free text 
active learners similar uncertainty sampling lewis gale crafted heuristics specific respective base learners rapier whisk 
sg net cohn atlas ladner stalker gen erate specific general extraction rules query boosting abe applied stalker rarely mistakes training set annihilating ability boost ing algorithm schapire bauer kohavi generate diverse com :10.1.1.119.2797:10.1.1.153.7626
query bagging abe existing active learning algorithm applied manner stalker generally wrapper induction 
query bagging works generating committee extraction rules querying unlabeled examples committee split rules committee extract largest number distinct strings 
committee extraction rules created repeatedly re sampling substitution examples original training set empirical evaluation compare naive aggressive testing random sampling query bagging 
random sampling straw man identical naive testing winner takes randomly queries unlabeled examples working set 
query bagging cre ate committee extraction rules obtained running stalker training set generated re sampling output hypothesis query bagging works majority voting extraction rules 
stalker generate types extraction rules ff fb run query bagging type rule report sets results query bagging ff query bagging fb query bagging bb 
query bagging relatively small committee rule committee scarcity training data wrapper induction algorithms expected learn extraction rules handful examples sampling replacement small original training set leads possible training sets members committee 
experimental setup order empirically compare algorithms wrapper induction testbed introduced kushmerick 
consists extraction tasks web information sources shown muslea minton knoblock tasks stalker learns accurate extraction rule just randomly chosen labeled examples 
empirical evaluation consider difficult extraction tasks testbed tasks random examples stalker fails learn accurate rules types ff fb additional tasks stalker requires larger usual number randomly chosen examples learn accurate rules types examples 
tasks table provides information task identifier example designates task source original source name kushmerick name item extracted total number examples domain table provides information performance stand stalker randomly chosen examples 
columns show number examples required reach accuracy ff fb rules respectively 
accurate rule learned table shows accuracy reached random examples 
learning tasks fold cross validation compare formance testing randomized counterpart versions datasets detailed description extraction task obtained rise repository located www isi edu muslea rise index html 
task source item stalker id name name exs ff fb bb price computer esp url item url cnn time source title date url name film com size search date time university internet time travel network availability internet email address update finder organization ej name shops net score item name democratic score party online file type foreign language languages url travelers translation tax code url price cd club artist web server album url cycling www relevance congress person name table extraction tasks empirical evaluation 
query bagging learn ff fb rules respectively 
algorithms start randomly chosen examples successive queries 
reported error rate averaged folds 
empirical results shows illustrative learning curves obtained learning tasks 
graphs correspond main scenarios encountered practice testing algorithms learn accurate rules algo rithms fail 
scenario depicted top graph occurs tasks 
testing algorithms algorithm learn accurate rule testing requires fewer queries 
scenario depicted middle graph occurs tasks 
considered algorithms learns accurate rule tasks 
summarizes performance algorithms extraction tasks 
graphs axis shows number queries algorithm axis shows number tasks accurate rule learned exactly queries 
algorithms start random examples additional queries convention queries data point corresponds tasks algorithm learn accurate rule labeled examples 
shown 
testing algorithms clearly outperform single view counterparts aggressive testing doing significantly better naive testing 
aggressive testing learns accurate rule tasks extraction rules learned queries 
note third tasks single aggressively chosen query sufficient learn correct extraction rule 
contrast naive testing succeeds error rate error rate error rate aggressive testing naive testing fb ff bb random labeled examples aggressive testing naive testing fb ff bb random labeled examples aggressive testing naive testing fb ff random labeled examples illustrative results wrapper induction tasks 
clarity bottom graph include results bb reaches error rate 
extraction task converged extraction task converged extraction task converged aggressive testing random sampling queries queries query bagging ff queries extraction task converged extraction task converged extraction task converged naive testing queries query bagging fb queries query bagging bb queries convergence results wrapper induction tasks 
converging single query just tasks single view algorithms able single task 
naive testing learns accurate rules tasks 
tasks extraction rules learned queries 
contrast random sampling leads rules accurate query bagging slightly outperforming learning ff fb extraction rules query bagging obtains rules accurate respectively 
words testing algorithms learn correct target concept twice tasks query bagging 
remember tasks aggressive testing fails learn accurate rule 
fact query bagging ff random sampling obtain accurate rules aggressive testing error rates opposed 
furthermore single view algorithms outperforms naive testing 
situation due fact extraction tasks backward view significantly accurate forward see table 
circumstances lead large number contention points mislabeled bad view learn correct rule provided available examples 
consequently distribution queries skewed mistakes bad view informative view view correct prediction bad view inadequate learn target concept 
order cope problem chapter introduce view validation algorithm predicts views appropriate particular task 
conclude discussion wrapper induction briefly compare results ones obtained wien kushmerick wrap induction system published empirical results extraction tasks testbed 
experimental setups identical wien evaluated cross validation randomly available examples training test sets various sizes 
just informal comparison 
comparison puts results perspective contrasting testing approach wrapper induction 
results summarized follows wien uses random sampling fails learn extraction rule task stalker wien return extraction rule works perfectly training set 
set tasks includes tasks aggressive learn accurate rule tasks naive testing failed learn perfect rules 
remaining tasks wien requires examples learn correct rule 
tasks aggressive naive testing learn accurate rules examples random plus queries 
wrapper induction order investigate testing performance applied additional real world domains natural intuitive way create views ad kushmerick classification problem classes attributes examples 
ad images appear web pages classified ads non ads 
view consists textual features describe image grams grams url page contains image url page image points turn describes properties image length width aspect ratio origin image page contains coming web server 
courses blum mitchell domain classes features examples :10.1.1.114.9164
learning task consists classifying web pages course homepages pages 
courses views consist words wien framework example consists document items interest labeled 
example page contains list names labeled represents single labeled example 
contrast stalker labeled document represents labeled examples 
order compare wien stalker results convert wien data stalker data multiplying number labeled wien pages average number item occurences page 
appear page words appear hyperlinks pointing respectively 
tf marcu carlson watanabe classification problem classes features examples 
context machine translation system uses shift reduce parsing paradigm learn rewrite japanese discourse trees english discourse trees 
case uses features specific shift reduce parsing paradigm elements input list partial trees stack 
consists features specific japanese tree input 
table shows learning algorithms empirical comparison 
domain base learner obtains best performance entire data set fold cross validation 
ib aha ad naive bayes blum mitchell courses mc mlc kohavi sommerfield dougherty implementation :10.1.1.114.9164
single view algorithms table available features learn target concept 
domains random sampling rnd strawman 
mc provide estimate confidence predictions uncertainty sampling lewis gale short courses 
query bagging boosting abe denoted run domains query committee qbc applied courses 
query committee typical hypothesis committee committees query bagging boosting consist hypotheses 
ib mc reliably estimate confidence predicted label ad tf naive testing takes output hypothesis query query committee ad tf known method sampling ib mc version spaces 
naive bayes idea mccallum nigam committee created sampling hypotheses gamma distribution naive bayes parameters estimated training set query bagging boosting relatively small hypothesis committees cpu constraints running time increases linearly number learned hypotheses domains takes cpu hours complete experiments 
testing single view algorithms domain query output ad tf ib mc selection naive naive hypothesis winner winner qbc rnd naive naive weighted courses bayes conservative vote table algorithms empirical comparison ad courses 
qbc denote query committee query bagging query boosting uncertainty sampling random sampling respectively 
randomly selected contention points output hypothesis learned view fewest mistakes queries 
contrast courses follow methodology blum mitchell output hypothesis consists weighted vote classifiers learned view :10.1.1.114.9164:10.1.1.114.9164
courses investigate testing query selection strategies naive conservative 
performance algorithms evaluated fold stratified cross vali dation 
ad algorithm starts randomly chosen examples queries learning episodes 
courses algorithms start randomly chosen examples query learning episodes 
tf algorithms start randomly chosen examples queries learning episodes 
figures display learning curves various algorithms ad tf course 
domains testing reaches highest accuracy smallest error rate 
table summarizes statistical results test confidence obtained pair wise comparison various algorithms 
comparisons performed right half learning curve convergence 
best way explain results table examples results comparing naive testing random sampling ad appear columns row 
numbers mean naive testing conservative testing algorithm ad tf courses loss tie win loss tie win loss tie win random sampling uncertainty sampling query committee query bagging query boosting naive testing table statistical significance results empirical pair wise comparison various algorithms domains 
comparison points naive testing outperforms random sampling statistically significant manner 
similarly comparing naive conservative testing courses columns row leads results com parison points conservative testing outperforms naive testing statistically significant manner points differences statistically insignificant comparison point naive testing outperforms conservative counterpart 
results table summarized follows 
single view algorithm outperforms testing statistically significant manner com parison points 
furthermore comparison query bagging boosting ad difference accuracy statistically insignificant comparison points testing clearly outperform algorithms domains 
discussion testing inspired original training blum mitchell authors formalized time idea multi view learning :10.1.1.114.9164
previously topic largely ignored idea clearly shows applications word sense disambiguation yarowsky speech recognition de sa ballard 
considering active learning methods blum error rate error rate error rate ad naive testing uncertainty sampling rnd labeled examples ad naive testing rnd labeled examples tf naive testing rnd labeled examples empirical results ad tf problems error rate error rate error rate courses conservative testing uncertainty sampling qbc rnd labeled examples courses conservative testing rnd labeled examples courses conservative testing naive testing labeled examples empirical results courses problem mitchell views learn hypotheses feed unlabeled examples classification confident 
empirical results show testing powerful approach active learning 
experiments described extremely different base learners stalker ib naive bayes mc different types domains wrapper induction text classification courses ad removal ad discourse tree parsing tf 
scenarios testing clearly outperforms single view state art active learning algorithms 
furthermore query bagging testing algorithm applied problems considered empirical evaluation 
contrast query bagging poor performance courses wrapper induction testing obtains highest accuracy considered algorithms 
conjecture testing works ability discover mis takes view 
contention point mislabeled views follows query extremely informative view misclassi fied 
mistakes informative correctly labeled examples 
particularly true base learners stalker mc improve current hypothesis provided examples misclassified instances 
main requirements successfully applying testing 
views sufficiently uncorrelated lead non empty set contention points 
views independent label long hypotheses disagree unlabeled examples testing new queries 
second views sufficiently compatible allow learning mistakes 
words long target concept learned high accuracy view testing queries informative represent mistakes fixed 
limitation testing applied multi view tasks user provide views testing 
researchers shown problems multiple views exist variety real world problems named entity classification collins singer statistical parsing sarkar speech recognition de sa ballard web page classification blum mitchell word sense disambiguation yarowsky base noun phrase bracketing pierce cardie :10.1.1.114.9164:10.1.1.114.3629
concern testing related potential violations multi view assumptions views uncorrelated compatible 
example case correlated views hypotheses learned view may similar contention points select query 
terms view incompatibility remember wrapper induction tasks views testing outperform random sampling 
chapters empirically investigate issues show fact testing compensates view introduce view validation algorithm predicts views sufficiently compatible performing multi view learning new unseen task 
summary section introduced testing novel approach active learning 
testing multi view algorithm learns hypothesis view queries unlabeled examples hypotheses predict different label 
queries extremely informative hypotheses disagree wrong allowing testing identify mistakes views 
testing family algorithms differ criteria query selection strategy output hypothesis 
empirical evaluation shows testing learns high accuracy classifiers small number labeled examples 
testing clearly outperforms single view state art sampling algorithms variety domains 
furthermore contrast single view approaches testing base learners considered experimental comparison 
chapter active semi supervised robust multi view learning ill think land see sea 
sir francis bacon theoretical foundation multi view learning blum mitchell assumptions views compatible uncorrelated :10.1.1.114.9164
intuitively problem compatible views examples labeled identically target con cepts view 
hand views uncorrelated label example descriptions view independent 
real world problems assumptions violated variety reasons correlated insufficiently informative features 
chapter study robustness multi view algorithms respect view incompatibility correlation 
practice difficult measure factors parameterized family text classification problems ptcp con trol view incompatibility correlation 
describe motivating experiment shows lack robustness existing multi view algorithms 
order cope problem introduce new algorithm emt outperforms algo rithms motivating experiment robust behavior entire spectrum considered problems 
new algorithm interleaves active semi supervised learn ing precisely uses testing select labeled examples multi view semi supervised em nigam ghani 
motivating experiment section describe experiment motivates emt 
em show semi supervised em nigam ghani training blum mitchell em nigam ghani extremely sensitive view compatibility correlation :10.1.1.114.9164
experiment demonstrates settings testing semi supervised learning number labeled examples extremely small choosing active learning effective large number unlabeled examples 
describing actual results provide high level description semi supervised algorithms experiment 
semi supervised algorithms comparison training algorithm training blum mitchell semi supervised multi view algorithm uses initial training set learn weak classifier view :10.1.1.114.9164
classifier applied unlabeled examples training detects examples classifier confident predictions 
high confidence examples labeled estimated class labels added training set see 
new training set new classifier learned view process repeated iterations 
final hypothesis created voting scheme combines prediction classifiers learned view 
base learner learning problem views labeled unlabeled examples number iterations performed training class ci number examples labeled iteration loop iterations create classifiers class ci ni examples confident predictions ci ni examples confident predictions ci pl pl pl pl combine prediction weighted vote semi supervised em leth classifier obtained training loop iterations new lmax posteriori new em leth classifier obtained training loop iterations new lmax posteriori new new lmax posteriori new combine prediction weighted vote high level description training semi supervised em em 
semi supervised em algorithm semi supervised em nigam ghani single view algorithm considered empirical comparison baseline known ability combine labeled unlabeled data 
shown semi supervised em nigam ghani applies probabilistic learning algorithm small set labeled examples large set unlabeled ones 
semi supervised em creates initial classifier solely labeled examples 
repeatedly performs step procedure probabilistically label unlabeled examples learn new maximum posteriori map hypothesis examples labeled previous step 
intuitively em tries find hypothesis generate distribution unlabeled data 
semi supervised em seen clustering unlabeled data examples original training set 
em algorithm em nigam ghani ghani semi supervised multi view algorithm uses hypothesis learned view probabilistically label examples see 
intuitively em runs em view new em iteration inter changes probabilistic labels generated view 
em seen probabilistic version training 
fact algorithms underlying idea knowledge acquired view probable labels examples train view 
major difference algorithms em commit label unlabeled examples uses probabilistic labels may change iteration 
contrast training commitment high confidence predictions may add nigam ghani em training contrasted iterative incremental respectively 
description equivalent em iteratively uses unlabeled data commit labels previous iteration 
contrast training incrementally uses unlabeled data committing labels iteration 
training set large number mislabeled examples especially iterations hypotheses may little predictive power 
empirical results order study influence view incompatibility correlation performance multi view learners ptcp parameterized family learning problems muslea minton knoblock 
ptcp consists text classification tasks control amount view correlation incompatibility 
precisely ptcp contains learning problems clumps class view incompatibility examples incompatible 
learning task ptcp binary classification problem instance space features 
empirical study apply semi supervised em training em testing tasks ptcp 
semi supervised algorithms trained randomly chosen labeled examples unlabeled ones 
contrast testing starts random examples queries total labeled examples uses unlabeled data training 
results experiments shown 
graphs displays learning curves obtained problems fixed number clumps class various levels domain incompatibility 
axis shows percentage incompatible examples problems axis represents error rates 
results lead important observations 
labeled data scarce instance space high dimensional labeled examples learning features large set unlabeled discussed sections learning problem said clumps class class consists distinct sub classes 
example courses problem course homepage class consists clumps theory classes ai classes classes 
similarly faculty non faculty problem previous chapter faculty class consists clumps assistant associate full professor 
keep presentation succinct discuss information critical making case 
experimental framework complete results detail section 
ptcp parameterized family problems described detail appendix error rate error rate error rate clump class test em train em incompatibility level clumps class test em train em incompatibility level clumps class test em train em incompatibility level controlled experiment testing training em semisupervised em 
learning tasks graph number clumps class various levels views incompatibility examples labeled differently views 
scarcity labeled examples examples high dimensionality learning tasks features testing exploit unlabeled examples obtains worst results 
algorithms non robust behavior perform tasks poorly ones 
examples dramatically boost classification accuracy 
illustrated semi supervised algorithms outperforming testing testing selects uses informative training set exploit unlabeled data learning hypotheses view undermines performance 
second semi supervised algorithms extremely sensitive view compatibility correlation 
example training em outperform semi supervised em problems uncorrelated views clump class 
con trast views incompatible correlated clumps class incompatibility multi view algorithms semi supervised em em doing clearly worse training 
results motivate need new algorithm robust behavior entire correlation incompatibility space 
section introduce emt reaches goal combining active semi supervised learning testing em respectively 
testing em emt shown emt novel algorithm combines strengths active semi supervised learning interleaving em testing 
opposed typical testing algorithm learns solely labeled examples emt induces hypotheses running em labeled unlabeled examples 
depending type testing emt naive conservative aggressive query selection strategy combined winner takes majority vote weighted vote output hypothesis obtain variety emt algorithms 
chosen combine testing em training difficulties encountered fine tuning sensitive changes number examples added iteration 
order put emt larger context shows emt relationship algorithms considered chapter 
side emt semi supervised variant testing turn inspired training 
side emt builds em state art semi supervised algorithm combines basic ideas training em 
note interleaving em testing leads interesting synergy 
hand testing boosts accuracy em selecting highly informative set labeled examples stand em chooses random 
hand hypotheses learned em accurate ones learned just labeled data compared stand testing emt uses accurate hypotheses select queries 
empirical evaluation experimental setup order evaluate emt apply ptcp parameterized family text classi fication problems compare results ones obtained semi supervised em training em testing 
algorithms base learner naive bayes classifier text classification nigam ghani 
naive bayes clas evaluate confidence prediction stand testing emt conservative testing weighted vote algorithm previous chapter courses problem 
accuracy algorithms estimated runs fold cross validation consequently training test set consist examples respectively 
semi supervised algorithms training examples split randomly groups labeled examples remaining unlabeled hide labels 
keep comparison fair emt testing start randomly chosen labeled examples query base learner learning problem views sets labeled unlabeled examples queries testing loop iterations create classifiers letx remove ask label ad emt number em iterations emt repeat times em iters learn letx remove ask label ad testing emt algorithms differ respect technique learn hypotheses view 
testing uses supervised base learner emt uses semi supervised em algorithm 
testing active learning training emt em probabilistic multiview learning probabilistic multi view active learning em multi view learning probabilistic learning lineage emt algorithm 
line training testing denotes change learning paradigm semi supervised active learning 
error rate clumps class clumps class clumps class labeled examples illustrative learning curves emt tasks incompatibility clumps class 
emt starts randomly chosen labeled examples queries total labeled examples 
unlabeled ones total labeled examples 
depicts illustrative learning curves show emt error rate decreases algorithm larger fraction allowed queries 
semi supervised em training em implemented versions described nigam ghani 
em em run iterations respectively 
training requires significant fine tuning labels examples iterations 
avoid prohibitive running time emt perform em iterations testing query problems emt runs em queries runs folds queries fold 
mentioned ptcp covers points correlation incompatibility space level levels view incompatibility points correlation incompatibility space ptcp contains text classification problems total problems see appendix details 
point correlation incompatibility space reported error rate averaged corresponding text classification problems 
shows performance emt testing em training em parameterized family problems 
graphs correspond levels views incompatibility 
graph axes show number clumps class error rate respectively 
points correlation incompatibility space emt obtains lowest error rates 
pairwise comparison testing training em em results statistically significant confidence points respectively 
remaining points represent extreme situations training em conditional independent views clump class em highly correlated incompatible views clumps class 
error rate error rate error rate incompatibility clumps class incompatibility clumps class incompatibility clumps class error rate error rate incompatibility clumps class incompatibility clumps class emt test em train empirical results ptct family problems 
graph shows results learning tasks fixed level view incompatibility various degrees domain 
em discussion empirical results deserve comments 
emt combines testing em clearly outperforms components 
intuitively emt power comes testing em compensating weaknesses 
hand exploiting unlabeled data em boosts accuracy classifiers learned testing 
hand testing improves em accuracy providing highly informative set labeled examples 
emt algorithm combines semi supervised active learn ing mccallum nigam various combinations semi supervised em query committee qbc shown outperform em qbc 
expect active learning algorithms select labeled examples em training em improve accuracy 
finding best combination active semi supervised learning scope chapter 
main contribution show interleaving active semi supervised learning leads robust performance entire spectrum problems 
second em training highly sensitive domain 
prob lems uncorrelated views clump class em training clearly outperform em 
fact em accurate emt barely outperform 
behavior consistent theoretical argument blum mitchell uncorrelated views presence view incompatibility concept learned labeled unlabeled examples :10.1.1.114.9164:10.1.1.114.9164
contrast problems clumps class em clearly outperforms em training 
multi view algorithms perform poorly domains disseminated entire instance space information best em qbc combinations appropriate multi view problems uses sophisticated heuristic estimates density various regions single view instance space density multi view instance space function local densities view 
implemented single view algorithm mccallum nigam similarly testing interleaves qbc em 
algorithm barely improved em accuracy parameterized problems decided show corresponding learning curves crowded 
exchanged views remains localized clump 
fact emt insensitive suggests testing compensates domain 
third performance algorithms degrades views compatible 
multi view algorithms sensitive view incompatibility information exchanged views misleading examples labeled differently views 
order cope problem chapter introduce view validation technique muslea minton knoblock detects views sufficiently compatible multi view learning 
note glance emt perform poorly problems highly incompatible views domains looks emt query incompatible examples convey little information misleading em 
understand emt avoids making queries reconsider illustrative courses domain introduced chapter repeated convenience 
remember hyperlinks containing text neural nets ilar fragments text artificial neural nets artificial neural networks labels 
ambiguity examples hypotheses learned hyperlink view low confidence predicting labels 
emt uses conservative query selection strategy queries con points views equally confident predictions follows incompatible example queried view equally low confidence prediction 
summary expect emt perform domains 
areas correlation incompatibility space clearly outperform algorithms uncorrelated views clump class correlated incompatible views clumps class incompatibility 
remember emt simply em labeled examples chosen testing queries 
view words hyperlinks related theory classes core theory classes algorithms cs related ai classes statistical models neural nets publications theory clump ai clump view words web pages cmu cs finite automata 
cmu cs intro algorithms 
uci cs theory algorithms 
usc cs artificial intelligence 
usc cs statistical learning 
usc cs neural networks 
mit cs intro neural nets 
doe papers neural networks 
illustrative clumps courses domain 
barely outperforms em domains occur practice 
barely outperforms em may expect em outperform emt higher incompatibility levels 
cope problem chapter introduce view validation algorithm muslea minton knoblock predicts views sufficiently compatible multi view learning 
results real world problems believe real world multi view problems display low level view incompatibility correlation 
spectrum problems emt clearly outperforms algorithms conjecture emt best potential algorithms discussed 
support conjecture additional experiment apply algorithms real world domains section courses ad 
third domain tf experiment text classification problem emt em em experiments implementations specific text classification 
courses text classification problem views words appear pages hyperlinks pointing respectively 
contrast ad task redefine views text classification problems 
originally see section view consisted textual features described geometric properties image length width aspect ratio 
experiment ignore features geometric view define new views follows 
view describes image words image url view characterizes related pages words urls pages contain image pointed image 
features ad boolean presence absence word document wor counts naive bayes multi variate bernoulli model mccallum nigam 
algorithm courses ad emt conservative testing em em training table error rates additional real world problems 
domains perform runs fold cross validation 
courses em training em labeled examples emt testing start labeled examples queries 
ad semi supervised algorithms labeled examples emt testing start labeled examples queries 
em em training run iterations respectively training adds examples iteration 
emt perform em iterations testing query 
table shows emt obtains best accuracy algorithms 
emt outperforms algorithms pair wise com results statistically significant confidence 
result statistically significant consists emt outperforming conservative testing courses domain 
summary chapter family parameterized problems analyze influence view correlation incompatibility performance multi view algorithms 
shown existing algorithms robust correlation incompatibility space 
cope problem introduced new multi view gorithm emt interleaves active semi supervised learning 
shown emt clearly outperforms algorithms parameterized prob lems additional real world domains 
experimental results suggest robustness emt comes active learning compensating view correlation 
chapter view validation things learn learn doing 
aristotle chapter concludes study influence view correlation multi view learning 
previous chapter shown testing compensates domain view incompatibility 
consequently focus view incompatibility issue closely related accuracy hypotheses learned views accurate views fewer examples incompatible labeled differently views 
illustrates relationship incompatibility views applicability multi view algorithms difference accuracy ses learned views increases views incompatible single view algorithm outperforms multi view counterpart 
observation imme raises question new unseen learning task multi view single view learning algorithm 
question restated follows views set learning tasks identify tasks views sufficiently compatible multi view learning 
order answer question introduce view validation algorithm pair views discriminates tasks error rate multi view algorithm single view algorithm difference accuracy views difference accuracy views increases views incompatible single view algorithm outperforms multi view counterpart 
views sufficiently insufficiently compatible multi view learning 
words view validation judges usefulness views particular learning task validates views task interest 
view validation suitable applications wrapper induction muslea minton knoblock web page classification blum mitchell views repeatedly solve variety unrelated learning tasks :10.1.1.114.9164
consider instance web page classification problem views consist words appear web pages words hyperlinks pointing 
note prin views learning tasks diverse distinguishing homepages professors students distinguishing articles economics terrorism 
learning tasks may happen text hyperlinks short uninformative better just words web pages 
cope problem view validation predict multi view learning appropriate task interest 
chapter presents general meta learning approach view validation 
framework user provides exemplar learning tasks solved views 
solved learning task algorithm generates view validation ex ample analyzing hypotheses learned view 
uses algorithm quinlan identify common patterns discriminate learning tasks views sufficiently insufficiently compatible multi view learning 
illustrative example pattern task difference training errors views larger views agree unlabeled examples views insufficiently compatible applying multi view learn ing consider application domains text classification wrapper induction commercially important multi view problem 
domains view validation algorithm high accuracy predictions modest amount training data 
view validation represents step long term goal automatic view detection dramatically widen practical applicability multi view gorithms 
having rely user provided views view detection search adequate views possible partitions domain features 
context view validation algorithm key component verifies views generated view detection sufficiently compatible applying multi view learning learning task 
view validation algorithm introducing view validation briefly terminology chapter 
definition multi view problem collection learning tasks views learning task called instance multi view problem problem instance 
example consider multi view problem consists web page classification tasks views words web pages words hyperlinks pointing pages views learn classifier distinguishes homepages professors students classifier distinguishes articles gun control terrorism forth 
consequently learning tasks represent instances multi view problem 
note practice expect pair views sufficiently compatible learning tasks 
instance problem may encounter tasks text hyperlinks short uninformative text classification task 
generally corrupted insufficient features unrealistic ex views sufficiently compatible applying multi view learning problem instances 
way address problem view validation algorithm problem instance predicts views sufficiently compatible multi view learning particular task 
practice level acceptable view incompatibility depends main features base learner learn hypotheses view 
consequently apply view validation multi view problem pair views learning algorithm note natural scenario multi view problems text classification wrapper induction views wide variety learning tasks 
view validation algorithm see implements step process 
user provides pairs ik lk ik problem instance lk label specifies views sufficiently compatible multi view learning solve ik 
label lk generated automatically comparing accuracy single multi view algorithm test set 
second instance ik generate view validation example feature vector describes properties hypotheses learned views 
apply view validation examples learned decision tree discriminate learning tasks views sufficiently insufficiently compatible multi view learning keeping multi view setting assume instance ik user provides small set lk labeled examples large set uk unlabeled examples 
multi view problem views ln ik instances labels ik having views sufficiently compatible multi view learning instance ik uk labeled unlabeled examples ik lk lk learn classifiers lk uk lk view validation examples learned classifier discriminates problem instances views sufficiently insufficiently compatible multi view learning view validation algorithm 
instance ik labeled examples lk learn hypothesis view 
generate view validation example labeled lk consists feature vector describes hypotheses 
section actual features view validation 
features view validation ideally label lk validation example consist single feature percentage examples labeled differently views 
unique feature learn threshold value discriminates prob lem instances views sufficiently insufficiently compatible multi view learning 
threshold corresponds point learning curves intersect 
practice unique feature requires knowing labels examples domain 
unrealistic scenario chosen features potential indicators incompatible views 
view validation example described features percentage unlabeled examples uk classified identically min max min complexity complexity max complexity complexity 
note features measured straightforward manner regardless algorithm learn 
precisely computed definition 
measuring andf count number labeled training examples mislabeled training errors apply formulas 
contrast features dependent representation describe hypotheses 
instance complexity boolean formula may expressed terms number disjuncts literals disjunctive conjunctive normal form decision tree complexity measure may take account depth breadth number leaves tree 
intuition view validation features fewer unlabeled examples uk labeled identically larger number potentially incompatible examples larger difference training error views equally accurate larger difference complexity complex hypotheses overfits small training set lk 
turn may indicate corresponding view significantly accurate 
practice features measured straightforward manner consequently view validation process 
contrast measuring com plexity hypothesis may possible meaningful consider instance case nearest neighbor classifier 
situations simply ignore features rely remaining features 
empirical results multi view test problems evaluate view validation algorithm multi view problems wrapper induction wi consists extraction tasks described section ptct family parameterized text classification tasks chapter 
wrapper induction base learner stalker 
consequently view validation features measured follows represents percentage unlabeled documents extraction rules extract string count labeled documents extraction rules extract correct string 
measure define complexity extraction rule maximum number disjuncts appear start rule 
ptct base learner naive bayes algorithm nigam ghani 
obvious way measure complexity naive bayes classifier ptct features 
features measured straightforward manner represents percentage unlabeled examples naive preferred second real world multi view problem ptct 
unfortunately multi view learning represents relatively new field study multi view algorithms applied just couple problem instances 
bayes classifiers agree obtained counting training errors views 
generating wi ptct datasets label problem instances wrapper induction wi compare performance naive testing stand stalker stalker learning ff rules randomly chosen labeled examples 
extraction tasks difference accuracy rules learned views larger single view stalker multi view counterpart 
label problem instances having views insufficiently compatible multi view learning 
order label instances ptct compare single view semi supervised em training widely semi supervised multi view algorithm collins singer pierce cardie sarkar :10.1.1.114.3629
empirical results previous chapter identify instances semi supervised em performs training 
label instances having views insufficiently compatible multi view learning 
wi ptct chosen number examples lk size lk experimental setups described muslea minton knoblock muslea minton knoblock wi ptct introduced 
wi instance ik may examples size lk uk consists remaining examples 
ptct instance consists examples size lk uk respectively 
setup contrast approach described single view validation example generated problem instance experiments create view validation examples instance 
instance ik generate view validation examples repeatedly partitioning examples ik randomly chosen error rate wi baseline wi ptct baseline ptct problem instances training view validation clearly outperforms baseline algorithm 
sets lk uk appropriate sizes 
motivation decision fold 
empirical results reflect particularly un fortunate choice sets lk uk 
second generate single view validation example instance wi ptct obtain number view validation examples small rigorous empirical evaluation respectively 
conclude generating view validation examples problem instance obtain larger number view validation examples respectively problem instance ik representative wide variety possible sets lk uk 
evaluate view validation performance wi ptct partition problem instances training test instances 
partition create training test sets follows view validation examples created training instance training set similarly view validation examples created test instance test set 
words view validation examples created problem instance belong training set test set split sets 
experiments train instances test remaining ones 
ratios average error rates obtained random partitions instances training test instances 
shows view validation results wi ptct datasets 
empirical results excellent trained available instances view validation algorithm reaches accuracy wi ptct datasets 
furthermore trained just instances instances wi ptct respectively view validation obtains accuracy 
wi ptct view validation clearly outperforms baseline algorithm simply predicts frequent label corresponding dataset 
influence size lk results raise interesting practical question reduce user effort harming performance view validation 
words label fraction view validation examples problem instance subset lk obtain high accuracy prediction 
answer question designed additional experiments vary parameters atime 
study influence parameter keep size lk constant wi ptct respectively consider values 
including view validation examples gen erate instance ik training sets consist randomly chosen subsets view validation examples training instance 
corresponding test sets continue view validation examples available test instance 
displays learning curves obtained experiment 
cal results suggest benefits increasing quickly wi ptct difference learning curves corresponding error rate error rate wi problem instances training ptct problem instances training keeping size lk constant varying value 
statistically significant twice view validation examples 
implies relatively small number view validation examples sufficient high accuracy view validation 
example view validation algorithm reaches accuracy trained problem instances training instances wi ptct respectively 
means trained just view validation examples respectively 
order study influence size lk parameter designed experiment hypotheses learned fraction examples original set lk 
specifically wi examples lk ptct examples lk 
wi ptct keep constant 
shows learning curves obtained experiment 
results extremely encouraging wi ptct reach accuracy examples lk 
example difference size lk wi lk ptct statistically significant 
experiments suggest main 
wi ptct view validation algorithm high accuracy predictions 
second approach requires modest effort user part number view validation examples size training sets lk reasonably small 
distribution errors order study errors view validation algorithm designed addi tional experiment 
wi ptct training problem instances test learned decision tree remaining instance 
leave instance experiment test learned tree labeled problem instance entire training set lk view validation examples 
error rate error rate wi size size size problem instances training ptct size problem instances training consider values size lk wi ptct 
examples left problem instance 
setup allows study view validation performance individual problem instance 
graphs display results wi ptct datasets respectively 
axis show number view validation examples misclassified view validation remember test set consists view validation examples generated problem instance testing 
axis number problem instances algorithm misclassifies particular number view validation examples 
consider example graph shows results problem instances wi see 
leftmost bar graph meaning problem instances algorithm zero errors view validation examples corresponding test sets view validation correctly predicts labels examples test set 
similarly second bar graph means problem instances view validation misclassifies just examples test set 
results require comments 
half problem instances wi ptct algorithm labels correctly view validation ex amples regardless particular choice sets lk uk generate view validation example algorithm predicts correct label 
second instances wi ptct instances respectively view validation accuracy misclassifies view validation examples 
problem instance algorithm labels correctly view validation examples generated problem instance 
depth perspective results split view tion errors classes false positives false negatives 
errors algorithm predicts apply multi view algorithm views problem instances wi misclassified view validation examples problem instances ptct misclassified view validation examples distribution errors wi top ptct bottom 
insufficiently compatible multi view learning errors algo rithms predicts don apply multi view algorithm views sufficiently compatible multi view learning 
results excellent wi ptcp wi default frequent label prediction multi view learning false positives little concern default negative examples false positives 
problem instances view validation potentially predicted false negatives 
furthermore instances error rate examples negatives 
ptcp default frequent label prediction multi view learning false negatives little concern default positive examples false negatives 
problem instances view validation potentially predicted false positives 
furthermore instances error rates examples positives 
problem instances problem instances wi false positives false positives tc false positives false positives problem instances problem instances wi false negatives false negatives tc false negatives false negatives distribution false positives negatives wi top ptct bottom 
understanding predictions practice important provide users intuition view validation prediction 
decision trees learned extremely useful respect 
shows illustrative pruned decision trees domain learned problem instances 
node trees show information view validation feature decision features described section error rate test set number test examples classified node descendents 
consider instance ptct decision tree misclassifies test examples see tree root 
decision tree reads follows hypotheses agree unlabeled examples uk error sufficiently compatible error sufficiently compatible error error error insufficiently compatible error error insufficiently compatible error error insufficiently compatible error sufficiently compatible error insufficiently compatible error error sufficiently compatible error illustrative trees wi top ptct bottom 
node labels view validation features described section 
agreement level hypotheses learned views absolute value difference training errors views largest complexities hypotheses learned views 
problem instance views sufficiently compatible multi view learning 
criterion examples labeled sufficiently compatible error rate examples misclassified 
hypotheses agree unlabeled examples views insufficiently compatible learning 
agreement level decision taken feature views sufficiently compatible difference training error views larger examples lk 
counter intuitive decision due overfitting produces half errors entire test set misclassified examples 
summary chapter described approach view validation 
view validation algorithm uses solved problem instances train classifier discriminates instances views sufficiently insufficiently compatible multi view learning 
test domains wrapper induction text classification view validation requires modest amount training data high accuracy predictions 
view validation represents step long term goal creating view detection algorithm automatically partitions domain features views adequate multi view learning 
chapter related conceive strange implausible said philosopher 
rene descartes chapter review research efforts related dissertation 
discuss existing various types active learners 
continue presenting main approaches semi supervised learning meta learning 
active learning algorithms idea active learning seen natural development earlier optimum experimental design fedorov 
early machine learning community started recognizing advantages inductive systems capable querying instructors 
example order detect errors prolog programs algorithmic debugging system shapiro shapiro allowed ask user types queries 
similarly concept learning systems marvin sammut banerji cat gross queries integral part respective learning strategies 
review existing approaches active learning structured follows 
discuss early theoretical results query construction 
focus selective sampling algorithms constructing query select query unlabeled examples working set 
active learning query construction earliest approaches formalizing active learning appeared seminal papers angluin valiant focused exact concept induction learning pac framework respectively 
theoretic focused learning classes concepts regular sets monotone dnf expressions expressions 
membership queries example target concept angluin sophisticated types queries equivalence queries concept equivalent target concept superset queries concept superset target concept 
early active learners took constructive approach query generation sense query artificially constructed setting values attributes query informative possible 
practice may raise serious problems example discussed lang baum consider hand writing recognizer discriminate digits 
scenario informative query may consist image represents fusion similarly looking digits image user label properly represent recognizable digit 
consequently query wasted totally irrelevant image 
similar situations appear real world tasks text classification information extraction speech recognition active learner artificially builds query domain highly newly created object meaning human user 
despite practical applicability issue constructive approach active learning leads interesting theoretical insights merits various types queries 
example researchers considered learning incomplete queries query answer may don know angluin slonim goldman mathias sloan turan blum malicious queries answer queries may erroneous angluin angluin angluin 
new learning problems considered unrestricted dnf expression jack son blum unions boxes goldberg goldman mathias tree patterns cull tadepalli cull tadepalli horn clauses reddy tadepalli 
researchers reported results applying active learning neural networks hwang baum rau ritter combining declarative bias prior knowledge active learning tadepalli tadepalli russell 
selective sampling selective sampling represents alternative active learning approach 
typically applies classification tasks learner access large number unlabeled examples 
scenario constructing informative query active learner asks user label existing unlabeled examples 
depending source unlabeled examples main types sampling algorithms stream pool 
assumes active learner access infinite stream unlabeled examples freund argamon engelson dagan dagan engelson successive examples active learner decide labeled user 
contrast pool scenario lewis gale lewis catlett mccallum nigam muslea minton knoblock muslea minton knoblock learner working set unlabeled examples order query active learner goes entire pool selects example labeled 
criterion select query selective sampling algorithms fall main categories uncertainty reduction system queries example current hypothesis confident prediction expected error minimization system queries example maximizes ex pected reduction classification error version space reduction system queries example labeled removes possible version space 
uncertainty reduction approach selective sampling works follows uses labeled examples learn classifier system queries unlabeled example classifier confident prediction 
straightforward idea applied base learner estimate confidence predictions 
confidence estimation heuristics proposed variety base learners logistic regression lewis gale lewis catlett partially hidden markov models scheffer wrobel support vector machines schohn cohn campbell cristianini smola inductive logic programming thompson califf mooney 
second sophisticated approach selective sampling expected error mini mization statistically optimal solution active learning problem 
scenario intuition query unlabeled example minimizes error rate classifier test set 
extremely simple base learners find optimal queries cohn ghahramani jordan true inductive learners 
consequently researchers proposed methods estimate error reduction various types base learners 
example roy mccallum sample estimation method naive bayes classifier similar approaches described parameter learning bayesian nets tong koller nearest neighbor classifiers lindenbaum markovitch 
heuristic approach expected error minimization summarized follows 
chooses loss function estimate error rate see roy mccallum description log loss functions 
unlabeled example working set considered possible query system estimates expected reduction error rate possible label may take 
system queries unlabeled example leads largest estimated reduction error rate 
typical version space reduction active learner works follows generates committee hypotheses queries unlabeled examples predictions committee members split 
class learning problem strategy translates making queries remove approximately half version space 
depending method generate committee distinguish types active learners query committee selects committee randomly sampling hypotheses ver sion space 
query committee applied variety base learners perceptrons freund naive bayes mccallum nigam winnow liere tadepalli 
furthermore argamon engelson dagan introduce extension query committee bayesian learning mitchell 
bayesian framework create committee sampling classifiers posterior distributions better hy explains training data sampled 
main limitation query committee applied base learners feasible sample hypotheses version space 
sg net cohn atlas ladner creates hypothesis committee con sists general anda specific classifier :10.1.1.119.2797
hypotheses generated modifying base learner learns classifier labels possible unlabeled examples working set positive tive respectively 
approach obvious drawback requires user modify base learner generate general specific classifiers 
query bagging query boosting abe create com known bagging breiman boosting schapire algorithms respectively :10.1.1.153.7626
algorithms introduced base learner bagging boosting known extremely 
general committee sampling tends associated version space reduction approach 
base learners support vector machines single hypothesis queries remove approximately half version space tong koller tong koller 
conversely committee sampling seen relying uncertainty reduction principle unlabeled example committee split seen example certain classification 
testing vs existing active learners main differences testing approaches selective sampling 
testing multi view active learner active learning algorithms single view framework 
second testing takes problem oriented approach selective sampling testing applied multi view problem regardless base learner choice 
contrast single view algorithm designed particular class base learner 
example query committee applies learners sample hypotheses version space uncertainty sampling applies base learners evaluate confidence predictions 
testing problem oriented approach active learning advantages disadvantages 
hand testing applied problems views 
hand multi view problem testing straightforward manner base learner works best particular type task 
contrast single view framework create new active learning method accommodate particular base learner worse modify existing base learner conjunction existing sampling algorithm 
observation contrast testing active learners 
testing seen committee approach selective sampling testing generates committee consists hypothesis view queries examples committee predictions split contention points 
opposed single view approaches testing generate committee properties inherent base learner properties pertaining problem solved multiple views 
second testing combined virtually single view active learn ers 
contention points testing algorithm choose query heuristics single view selective samplers 
exam ple aggressive testing queries contention point views confident prediction seen borrowing heuristic uncertainty sampling 
novel members testing family created similar manner relying heuristics expected error minimization version space reduction 
semi supervised concept learning section discuss main classes algorithms combine labeled unlabeled data single view multi view semi supervised learners 
single view classifiers represent traditional approach semi supervised learning 
focus developments multi view semi supervised learning 
single view semi supervised classification way unlabeled examples major approaches single view semi supervised classification transduction expectation max background knowledge injection transduction maximizes classi fication accuracy particular test set working set unlabeled examples actual test set 
contrast approaches aim improving classifiers accuracy entire instance space 
order achieve goal supplement training set unlabeled examples working set distinct test set 
expectation maximization working set create generative model data model generated seen data 
contrast background knowledge injection approach uses unlabeled data synthesize sort knowledge improve accuracy supervised learner 
transductive approaches best way introduce intuition transductive learning framework vapnik contrast inductive learning 
inductive learning searches hypothesis smallest error rate entire instance space 
contrast transductive learning generates classifiers accurate possible particular test set set labeled examples transductive framework learns distinct maximally accurate classifier test set interest 
practice translates combining labeled examples training set unlabeled ones test set 
research transductive learning lead interesting contradictory results 
hand zhang oles provide theoretical empirical evidence general transductive support vector machines tsvm improve classification accuracy 
hand papers joachims bennett demiriz bennett demiriz contradict results zhang oles showing reduce need labeled data 
szummer jaakkola authors describe transductive learning algo rithm kernel density estimation 
scenario labeled unlabeled data evaluate density instance space 
instance density subsequently estimate importance individual labeled example improving classification accuracy 
transductive classification applied learning probabilistic relation models prms taskar segal koller 
prms exploit relational structure data crucial access unlabeled data test set absence test data misses relational information pertaining highly informative relational information connects labeled unlabeled examples 
expectation maximization statistics community problem learning generative models labeled unlabeled data received significant attention hartley rao day decade seminal expectation maximization em dempster laird rubin 
em tremendous influence machine learning community formalizes idea iterative approach likelihood maximization presence missing data iterative approach finding generative model generated seen examples 
concept learning framework translates searching classifier explains best data training working set 
em algorithm stimulated impressive amount theoretical practical 
theoretical side researchers focused mainly answering ques tion unlabeled examples labeled example worth cover thomas venkatesh 
strong assumptions knowing para metric form target function having local optimum points search space convergence results proved various types mixtures gaussians mclachlan neill venkatesh 
intuitive best known results summarized follows certain assumptions infinite amount unlabeled data available labeled examples reduce classi fication error exponentially fast castelli cover finite amount labeled unlabeled data available labeled examples exponentially informative unlabeled ones castelli cover 
semi supervised em algorithm applied variety real world domains face orientation discrimination baluja text classification nigam english text tagging merialdo 
em implementations created base learners naive bayes nigam baluja dependency trees baluja hidden markov models merialdo 
known drawback merialdo nigam cozman cohen approaches data conform generative model base learner perfectly learn target concept unlabeled examples may decrease classification accuracy :10.1.1.1.5684
order cope problem researchers proposed main approaches 
sophisticated base learners multiple mixture components domain class nigam shahshahani landgrebe miller uyar :10.1.1.1.5684
second labeled examples assigned importance unlabeled ones nigam mitigating effect ideal base learner :10.1.1.1.5684
unlabeled data background knowledge third approach single view semi supervised classification characterized unlabeled examples sort background knowledge 
example ze hirsh introduce novel strategy boost accuracy nearest neighbor classifier 
directly measuring similar sets test train ing examples new algorithm compares relative similarities group unlabeled examples working set 
intuition hirsh straightforward relying imperfect metric similarity examples authors stronger evidence examples similar entire group unlabeled examples 
approach unlabeled examples background knowledge pre sented raskutti kowalczyk 
authors unlabeled ex amples enrich original set features additional highly informative attributes 
step creating new features clustering algorithm applied examples training working sets largest clusters discarded 
second phase example remaining clus ter algorithm adds novel features binary attribute answers question closest cluster numeric attribute measures similarity centroid cluster raskutti 
show enriched set features significantly improve classification accuracy 
assemble algorithm bennett demiriz maclin uses un labeled examples create diverse committee consists hypotheses highly consistent predictions hypotheses predict label unlabeled examples 
construction committee prevents overfitting assemble generalization power 
assemble iteratively creates committee manner uses current committee label unlabeled data working set 
second assemble learns new hypothesis training newly labeled working sets 
new hypothesis added committee process repeated number iterations 
note assemble com similar consists hypotheses learned em iteration 
main difference approaches 
expectation maximization assemble simply trains base learner labeled examples 
consequently assemble generative models 
second aiming incrementally learn better hypothesis em manner assemble focuses creating committee members label identically examples working set 
multi view semi supervised learning mentioned blum mitchell provided formalization learning multi view framework 
proved independent compatible views pac learn valiant concept labeled unlabeled examples 
blum mitchell introduced training general purpose multi view algorithm 
collins singer proposed version training biased learning hypotheses predict label unlabeled examples 
introduce explicit objective function measures compatibility learned hypotheses boosting algorithm optimize objective function 
related dasgupta littman mcallester authors provide pac guarantees novel training algorithm assumption views independent compatible 
intuitively dasgupta show ratio contention points unlabeled examples upper bound error rate classifiers learned views 
development abney extends dasgupta relaxing view independence assumption 
precisely abney shows views weakly dependent ratio contention points unlabeled examples represents upper bound view error rate 
unfortunately abney introduces just theoretical definition weak dependence views providing intuitive explanation practical consequences weak dependence 
researchers proposed main types extensions original training algo rithm modifications actual algorithm changes aiming extend practical applicability 
cover wide variety scenarios em nigam ghani uses expectation maximization dempster laird rubin multi view learning 
em seen closest imple mentation theoretical framework proposed blum mitchell :10.1.1.114.9164:10.1.1.114.9164
ghani uses error correcting output codes allow training em scale problems large number classes 
corrected training pierce cardie asks user manually correct labels bootstrapped examples 
approach motivated observation quality bootstrapped data key factor convergence training 
boost collins singer greedy agreement algorithm abney training algorithms explicitly minimize number contention points :10.1.1.114.3629
second group extensions training motivated fact practice encounters problems straightforward way split features views 
order cope problem nigam ghani remember contention point unlabeled example hypotheses learned views predict different label 
show bag words text classification create views arbitrarily splitting original set features sub sets 
approach fits text classification domain features abundant types problems 
alternative solution proposed raskutti kowalczyk authors create second view consists variety features measure examples similarity largest clusters domain 
fact raskutti kowalczyk tightly related raskutti kowalczyk discussed section papers show clusters features highly informative multi single view framework respectively 
goldman zhou advocates multiple biases mul tiple views 
authors introduce algorithm similar training bootstraps hypotheses learned different base learners 
assumption base learners generate hypotheses partition instance space equivalence classes 
emt vs existing approaches approach similar emt proposed mccallum nigam introduced family algorithms combine active semi supervised learning 
precisely highly informative labeled examples chosen active learner seung opper training set semi supervised em algorithm 
main distinction algorithms mccallum nigam emt muslea minton knoblock 
algo rithms introduced mccallum nigam single view emt multi view 
second experiments mccallum nigam show interleaving active semi supervised learning lead higher accuracy applying algorithms 
contrast results showed multi view setting interleaving algorithms dramatically outperforms applying sequence 
meta learning model selection section discuss learning learn thrun pratt paradigm closely related view validation algorithm muslea minton knoblock 
breadth learning learn topic discuss larger context illustrative examples existing approaches focus meta learning model selection algorithms view validation example 
seminal free lunch theorems schaffer schaffer wolpert wolpert macready showed learning algorithm outperform random guessing possible classifications instance space 
results lead main directions research model combination model selection 
learning task aims combining predictive power learners 
algorithms bagging breiman boosting schapire stacked generalization wolpert represent highly successful approaches model combination :10.1.1.153.7626
main focus section model selection methods 
typical model selection algorithm learning task number learning algorithms ln required predict learners obtains best accuracy task main approaches model selection experimental knowledge driven transfer learning meta learning 
experimental model selection main idea experimental model selection assumption algorithm trained subset training data accurate predictions high accuracy predictions trained entire dataset 
typical approach experimental model selection cross validation schaffer estimate accuracy learner task system solves task applying learner lw obtains highest accuracy cross validation 
related approach author introduces subsampling algorithm error estimation 
methodology motivated data mining extremely large datasets cross validation impractical 
shows estimating error rate single subsample large dataset obtains estimate algorithm performance 
results indicate error estimation important large test set large training set 
wrapper method kohavi john find optimal value parameters learning algorithm 
authors best search cross validation explore space parameters settings 
wrapper method seen applying cross validation different levels parameter estimation actual error estimation 
knowledge driven model selection knowledge driven approach model selection idea extracting meta knowledge user select appropriate algorithm particular task 
meta knowledge seen set heuristics model selection 
example shavlik 
perform extensive empirical evaluation id perceptron back propagation algorithms datasets analyzed effect factors classification noise type features accuracy learner 
authors interesting heuristics back propagation outperforms id datasets numerical features similarly king feng authors perform larger scale experiment compare algorithms datasets 
dataset measure statistical characteristics homogeneity covariances tributes skew kurtosis define set heuristics model selection 
example heuristic states domains extreme distributions skew kurtosis binary discrete attributes favor symbolic learners similar approach engels finding heuristics pre processing dataset eliminate redundant uninformative attributes 
brodley author takes idea higher level 
introduces model class selection mcs system creates tree structure hybrid classifier applies different classifiers linear discriminant functions decision trees instance learning various regions instance space 
intuitively mcs seen step process user proposes heuristics model selec tion similar described 
heuristics mcs recursively builds hybrid tree classifier splits instance space regions suited particular learner 
second step datasets iteratively debug heuristics mcs builds hybrid classifier performance compared individual learners hybrid classifier perform best learners user finds repairs faulty heuristics process repeated 
system deployed hybrid tree classifier apply appropriate classifier region instance space 
main disadvantages experimental knowledge driven model selec tion 
represent time consuming processes scale plethora learning algorithms number parameters tuned 
second ignore powerful source knowledge experience acquired solving related learning tasks 
drawbacks addressed approaches model selection transfer learning meta learning 
transfer learning transfer learning refers finding model appropriate group related tasks 
example baxter introduces bayesian framework learning predict appropriate model environment similar tasks 
main intuition solving tasks environment exploit information tasks find model appropriate entire class problems 
baxter provides theoretical ical evidence approach reduces amount data required training particular task 
multitask learning caruana takes different approach transfer learning 
multitask learning simultaneously learns concept interest main concept set related concepts auxiliary concepts 
instance consider task predicting prior hospitalization patient risk people diagnosed 
explained caruana typical single task approach problem set basic measurements age sex pulse prediction 
contrast multitask learning considers additional set lab tests blood cells counts blood gases available patients past 
features directly predictions prior hospitalization multitask learning uses auxiliary learn ing tasks available attributes multitask learning simultaneously learns predict patient risk additional measurements 
caruana shows multitask learning neural networks caruana decision trees caruana nearest neighbor caruana outperform respective single task counterparts 
main problem transfer learning approaches applied new unseen tasks 
words set related task transfer learning finds model appropriate 
new unseen learning task transfer learning predict learner task 
issue central meta learning approaches model selection discussed section 
meta learning model selection meta learning process learning guide user applying machine learning techniques 
meta learning captures valuable knowledge meta data particular learner different factors influence success failure knowledge increase efficiency learning process 
words meta learning refers learning learn meta learning variety tasks feature selection discriminating base learner correct incorrect predictions bay pazzani finding best way deal missing attributes feng detecting concept drift online learning widmer selecting best classifier example domain wolpert chan stolfo todorovski dzeroski ting witten gama brazdil alpaydin learning prune decision tree 
focus meta learning model selection learn predict appropriate learner new unseen dataset 
sake simplicity remainder section term meta learning denote meta learning model selection system rendell predicts best learning algorithm solve task represents approach meta learning model selection 
seen proof concept system meta features number examples attributes domain chooses best algorithms 
criterion algorithm preferred execution time algorithms reach similar accuracy considered tasks 
typical meta learning process consists main steps choose meta features 
second set training tasks create meta examples meta example created training task 
meta example described values meta features label des appropriate learner corresponding training task machine learning algorithm learn classifier predicts learner applied new unseen task 
selection algorithm applied meta data subject meta learning meta meta learning best way discriminate various approaches meta learning analyzing type meta features system 
highest level distinguish main types meta features application related constraints dataset measurements 
related defining scope meta learner meta learner search space dra matically reduced account user requirements learners meta learner choose 
requirements may consist constraints running time accuracy learner understandability learned classifiers learners ability cope noise uncertainty redundant data 
second type meta features created dataset measurements 
meta features fall main categories general dataset characteristics classifier features landmarking features 
general dataset characteristics divided categories simple features number classes attributes examples domain number symbolic binary numeric attributes 
features discriminative analysis number discriminant func tions relative importance largest eigenvalue canonical correlation significant discriminant function class distribution 
statistical features default accuracy relative size populated class amount classification noise frequency missing values standard deviation skewness kurtosis class 
information features class attribute joint entropy mutual information entropy information gain 
subsets meta features researchers created meta learners cn rule generating algorithm aha case reasoning lindner studer nearest neighbor gama brazdil decision tree learner brazdil gama gama brazdil inductive logic programming todorovski dzeroski regression taylor keller gama brazdil predict appropriate learner new unseen task 
zoomed ranking algorithm soares brazdil uses type meta features takes sophisticated approach meta learning 
uses nearest neighbor algorithm detect similar training domains prediction 
uses candidate algorithms performance domains rank predicted performance new domain 
classifier meta features created applying learner dataset measuring various properties learned hypothesis 
example system learns decision tree dataset uses meta features descriptors number tree nodes domain attribute average strength support leaf tree maximum depth tree shape decision tree 
related giraud carrier kennedy authors take idea step farther extract classifier meta features tree higher order inductive algorithm learns directly decision trees 
landmarking pfahringer giraud carrier giraud carrier pfahringer giraud carrier creates meta features consist accuracies reached simple efficient learners dataset 
meta features meta learner learns rules predict winner pair wise comparison algorithms applied new unseen dataset 
landmarking seen extending classifier meta features type classifier variety simple classifiers 
contrast measuring dataset characteristics landmarking extremely efficient dataset characteristics meta features computed complexity number examples domain 
adaptive view validation model selection adaptive view validation algorithm muslea minton knoblock meta learning approach deciding multi view learning appropriate new unseen tasks 
furthermore view validation meta learner designed domains examples labeled 
consequently view validation requires meta features appropriate multi view scenario learns labeled unlabeled examples 
meta features view validation fall broad categories 
meta features measure training error view seen landmarking features hypotheses learned view represent sense described 
second features describe agreement complexity hypotheses learned view seen classifier meta features measure properties learned classifiers 
chapter middle 
aristotle machine learning algorithms start collections data extract knowledge subsequently improve system performance 
human perspective labeling large amounts data tedious time consuming error prone activity 
thesis introduce suite algorithms aim reducing amount data required learning concept interest 
particular focus solving multi view learning problems domain features split disjoint subsets sufficient learning 
dissertation spans major areas research active learning semi supervised learning meta learning 
active learning minimizes amount labeled data asking user label informative examples domain 
contrast semi supervised learner compensates scarcity labeled data exploiting large set unlabeled examples 
meta learning algorithms predict appropriate learner particular learning task implicitly minimizing amount data labeled learner solve task equally require data 
thesis main contributions 
introduce testing multi view approach active learning 
show testing clearly outperforms existing single view active learners 

show existing multi view learners robust respect violation multi view assumptions 
order cope problem introduce robust multi view learner emt interleaves active semi supervised multi view learning 

introduce approach deciding multi view learning appro priate new unseen learning task 
adaptive view validation algorithm meta learner uses past experiences learn classifier predicts multi view learner outperform single view 
contributions discussed detail section provide evidence thesis dissertation correct multi view active learning maximizes accuracy learned hypotheses minimizing amount labeled training data 
main contributions multi view approach active learning dissertation introduce testing multi view approach active learn ing 
testing family active learners select query contention points unlabeled examples hypotheses learned various views predict different label 
querying strategy fol lowing intuition view sufficient learning target concept existence contention points shows views mistakes 
consequently labeling contention point helps fixing mistakes views 
extend idea multi view learning learning strong weak views 
typical views sufficient learn concept interest 
views learn concepts strictly gen eral specific target concept 
empirically show learning strong weak views outperforms single view learning learning strong views 
thesis provide formal analysis testing works 
precisely prove certain assumptions testing converges significantly faster single view learners 
furthermore show true semi supervised multi view learners training 
provide extensive empirical evidence testing outperforms state art single view active learners 
empirical results cover variety base learners stalker naive bayes instance learning real world domains wrapper induction web page classification advertisement removal discourse tree parsing 
robust multi view learning part second main contribution provide empirical evidence existing multi view learners robust violation multi view assumptions views compatible uncorrelated 
precisely show depending assumption violated existing multi view learners form outperformed various regions incompatibility correlation space 
behavior clearly undesirable user solve new unseen task unclear existing algorithms learning 
introduce emt new multi view learner robust assumption viola tions 
emt described interleaving active semi supervised learning testing em respectively 
words emt combines best worlds 
hand labeled training set consists informative exam ples domain selected active learning testing 
hand small training set exploits large set unlabeled examples em 
empirically show emt clearly outperforms existing multi view learners 
furthermore provide evidence emt robustness comes testing ability query informative examples compensate view correlation 
multi view vs single view model selection third main contribution consists formalizing view validation problem tries predict multi view learning appropriate solving new unseen tasks 
introduce meta learning view validation algorithm uses experi ences acquired solving past learning tasks learn classifier predicts views sufficiently compatible multi view learning 
view validation departs typical approach meta learning assumes datasets consist large sets labeled examples 
precisely view validation meta learner designed domains access small set labeled data large set unlabeled ones 
consequently order cope difficulty introduce new set meta features appropriate multi view learning labeled unlabeled data 
limitations despite advantages algorithms introduced dissertation limitations multi view learning framework assumes domain features split views sufficient learning target concept 
words user provide views multi view learning applied 
attempts address issue raskutti kowalczyk nigam ghani specific text classification unclear applied types domains 
testing family algorithms consists large number active learners unclear testing algorithms appropriate particular learning task 
provided rules thumb decide algorithm particular scenario clearly required area 
existing approaches active learning including testing take myopic approach querying select informative query immediately re induce classifier 
extremely time consuming approach appropriate scenarios base learner slow relatively time constraints application may unacceptable user wait minutes consecutive queries 
current version view validation algorithm applied separately multi view problem interest 
interested wide variety multi view problems individually collecting view validation examples problem puts serious burden user 
intend continue main directions am interested creating view detection algorithm partitions main features views adequate multi view learning 
partition created starting labeled unlabeled exam ples extremely difficult problem 
possible step extend view generation approach raskutti kowalczyk domains text classification 
alternatively start creating view detection algorithm relational domains getoor jensen neville search space possible feature partitions guided domain structure hyperlinks hubs authorities web domains getoor abstracts keywords citing cited papers bibliographic domain taskar segal koller 
plan providing better understanding scenarios various testing algorithms best suited 
possible approach modify view validation algorithm predicts appropriate testing algorithm new unseen learning task 
intend extend testing framework directions 
order reduce computational costs am interested testing algorithms look ahead approach making highly informative diverse queries 
second plan investigate applicability testing regression problems learner predicts value continuous variable 
scenario extremely appropriate aggressive testing largest difference values predicted views biggest mistake 
intend apply testing semi supervised clustering basu banerjee mooney 
clustering goal unlabeled examples detect domain structure semi supervised clustering algorithms exploit availability labeled examples guide search structure space 
testing select highly informative set labeled examples expect maximize benefits labeled data 
intend continue view validation directions 
find meta features remember view validation currently uses meta features 
second plan reduce number view validation ex amples required training active semi supervised learning 
view validation scenario assumes large number prob lem instances solved perfect sense ask user label informative instances allowing view validation algorithm exploit remaining unlabeled view validation examples 
am interested cre ating new general purpose view validation algorithm trained covers variety multi view learning problems 
abe naoki hiroshi 

query learning boosting bagging 
proceedings th international conference machine learning icml pages 
abney stephen 

bootstrapping 
proceedings th annual meeting association computational linguistics pages 
aha david 

generalizing case studies case study 
proceedings th international conference machine learning icml pages 
aha david 

tolerating noisy irrelevant novel attributes instance learning algorithms 
international journal man machine studies 
thomas paul cull prasad tadepalli 

exact learning tree patterns queries counterexamples 
proceedings conference computational theory colt pages 
thomas paul cull prasad tadepalli 

exact learning unordered tree patterns queries 
proceedings conference computational theory colt pages 
angluin dana 

note number queries needed identify regular languages 
information control 
angluin dana 

queries concept learning 
machine learning 
angluin dana 

exact learning dnf formulas malicious membership queries 
technical report yaleu dcs tr yale university 
angluin dana martins 

malicious membership queries exceptions 
technical report yaleu dcs tr yale university 
angluin dana martins robert sloan turan 

malicious omissions errors answers membership queries 
machine learning 
angluin dana donna slonim 

randomly fallible teachers learning monotone dnf incomplete membership oracle 
machine learning 
argamon engelson shlomo ido dagan 

committee sample selection probabilistic classifiers 
journal artificial intelligence research 
baluja 

probabilistic modeling face orientation discrimination learning labeled unlabeled data 
advances neural information processing systems volume pages 
basu banerjee raymond mooney 

semi supervised clustering seeding 
proceedings th international conference machine learning icml pages 
bauer eric ron kohavi 

empirical comparison boosting bagging variants 
machine learning 
baum 
neural net algorithms learn polynomial time examples queries 
ieee transactions neural networks 
baxter jonathan 

learning model bias 
advances neural information processing systems volume pages 
baxter jonathan 

bayesian information theoretic model learning learn multiple task sampling 
machine learning 
bay stephen michael pazzani 

characterizing model errors differences 
proceedings th international conference machine learning icml pages 
bennett kristin demiriz 

semi supervised support vector machines 
advances neural information processing systems volume pages 
bennett kristin demiriz 

optimization approaches semi supervised learning 
ferris mangasarian pang editors applications algorithms complementarity 
kluwer academic publishers 
bennett kristin demiriz rich maclin 

exploiting unlabeled data ensemble methods 
proceedings sigkdd international conference knowledge discovery data mining 


god doesn shave occam razor learning prune 
th european conference machine learning pages berlin germany 
springer 


automatic bias learning inquiry inductive basis induction 
ph thesis school cognitive computing sciences university sussex 
christophe giraud carrier 

discovering task neighbourhoods landmark learning performances 
komorowski zytkow editors proceedings th european conference principles practice knowledge discovery databases pages heidelberg 
springer 
christophe giraud carrier claire kennedy 

higher order approach meta learning 
proceedings ecml workshop meta learning building automatic advice strategies model selection method combination 
christophe giraud carrier bernhard pfahringer 

works tells works better 
proceedings icml workshop works pages 
blum avrim prasad chalasani sally goldman donna slonim 

learning unreliable boundary queries 
journal computer system sciences 
blum avrim furst jeffrey jackson michael kearns mansour steven rudich 

weakly learning dnf characterizing statistical query learning fourier analysis 
proceedings th acm symposium theory computing pages 
blum avrim tom mitchell 

combining labeled unlabeled data cotraining 
proceedings conference computational learning theory colt pages 
brazdil pavel joao gama 

characterizing applicability classification algorithms meta level learning 
bergadano de raedt editors machine learning ecml lnai 
springer 
breiman leo 

bagging predictors 
machine learning 
brodley carla 

recursive automatic bias selection classifier construction 
machine learning 
califf mary raymond mooney 

relational learning pattern match rules information extraction 
proceedings sixteenth national conference artificial intelligence aaai pages 
campbell colin nello cristianini alex smola 

query learning large margin classifiers 
proceedings th international conference machine learning icml pages 
caruana rich 

learning related tasks time backpropagation 
advances neural information processing systems volume pages 
caruana rich 

algorithms applications multitask learning 
proceedings th international conference machine learning icml pages 
caruana rich 

multitask learning 
machine learning 
castelli thomas cover 

exponential value labeled examples 
pattern recognition letters 
castelli thomas cover 

relative value labeled unlabeled samples pattern recognition unknown mixing parameter 
ieee transactions information theory 
chan philip salvatore stolfo 

accuracy meta learning scalable data mining 
journal intelligent information systems 
cohen william 

web information system reasons structured collections text 
proceedings second international conference autonomous agents aa pages 
cohn david les atlas richard ladner 

improving generalization active learning 
machine learning 
cohn david zoubin ghahramani michael jordan 

active learning statistical models 
advances neural information processing systems volume pages 
collins michael yoram singer 

unsupervised models named entity classification 
proceedings empirical nlp large corpora conference pages 
cover thomas joy thomas 

elements information theory 
john wiley sons 
cozman fabio ira cohen 

unlabeled data degrade classification performance generative classifiers 
proceedings th international flairs conference 
dagan ido sean engelson 

committee sampling training probabilistic classifiers 
proceedings th international conference machine learning pages 
dasgupta sanjoy michael littman david mcallester 

pac generalization bounds training 
neural information processing systems 
day 
estimating components mixture normal distributions 
biometrika 
de sa virginia dana ballard 

category learning multi modality 
neural computation 
dempster laird rubin 

maximum likelihood incomplete data vie em algorithm 
journal royal statistical society 
engels robert 

data metric preprocessing advice data mining applications 
proceedings european conference artificial intelligence ecai pages 
evans fisher 

overcoming process delays trees induction 
ieee expert 
fayyad usama padhraic smyth weir 

automated analysis exploration image databases results progress challenges 
journal intelligent information systems 
fedorov 
theory optimal experiment 
academic press 
feng 
meta cn unknown values processing combiner stacked generalization 
editors kdd workshop postprocessing machine learning data mining 
freund yoav seung eli shamir naftali tishby 

selective sampling query committee algorithm 
machine learning 
gama joao pavel brazdil 

characterization classification algorithms 
pinto ferreira editors progress artificial intelligence lnai 
springer 
gama joao pavel brazdil 

cascade generalization 
machine learning 
geoff mclachlan 

efficiency linear discriminant function onn unclassified initial examples 
biometrika 
getoor lise nir friedman daphne koller avi pfeffer 

learning probabilistic relational models 
saso dzeroski nada lavrac editors relational data mining 
springer 
getoor lise eran segal ben taskar daphne koller 

probabilistic models text link structure hypertext classification 
proceedings ijcai workshop text learning supervision 
ghahramani zoubin michael jordan 

supervised learning incomplete data em approach 
advances neural information processing systems volume pages 
ghani 

combining labeled unlabeled data text classification large number categories 
proceedings ieee conference data mining icdm 
ghani 

combining labeled unlabeled data multiclass text classification 
proceedings th international conference machine learning icml pages 
goldberg paul sally goldman david mathias 

learning unions boxes membership equivalence queries 
proceedings conference computational theory colt pages 
goldman sally david mathias 

learning term dnf formulas incomplete membership oracle 
proceedings conference computational theory colt pages 
goldman sally yan zhou 

enhancing supervised learning unlabeled data 
proceedings th international conference machine learning icml pages 
gross klaus 

concept acquisition attribute evolution experiment selection 
ph thesis school computer science carnegie mellon university 

minutes lay foundations 
expert systems user august 
hartley rao 

classification estimation analysis variance problems 
review international statistical institute 


active data selection supervised unsupervised learning 
ph thesis faculty technology university bielefeld germany 
ritter 

active learning generalized high 
proceedings international conference artificial neural networks icann volume lecture notes computer science pages 
ritter 

active learning local models 
neural processing letters 
hsu chun nan ming dung 

generating finite state transducers semi structured data extraction web 
journal information systems 
hwang choi oh marks 

query learning applied partially trained multilayer perceptrons 
ieee transactions neural networks 
jackson jeffrey 

efficient membership query algorithm learning dnf respect uniform distribution 
proceedings ieee symposium foundations computer science pages 
jensen david jennifer neville 

schemas models 
proceedings sigkdd workshop multi relational learning 
joachims thorsten 

probabilistic analysis rocchio algorithm tfidf text categorization 
computer science tech 
report cmu cs 
joachims thorsten 

transductive inference text classification support vector machines 
proceedings th international conference machine learning icml pages 


property feature engineering selection 
master thesis department computer sciences university texas austin 
alpaydin 

multistage cascading multiple classifiers man noise man data 
proceedings th international conference machine learning icml pages 
king feng 

statlog comparison classification algorithms large real world problems 
applied artificial intelligence 
kirk levy sagiv srivastava 

information manifold 
proceedings aaai spring symposium information gathering heterogeneous distributed environments pages 
knoblock craig kristina lerman steven minton ion muslea 

accurately reliably extracting data web machine learning approach 
editor intelligent exploration web 
springer 
knoblock craig steven minton jose luis ambite naveen ashish ion muslea andrew 

ariadne approach web information integration 
international journal cooperative information sources 
taylor keller 

meta analysis data characterisation meta learning meta regression 
brazdil jorge editors proceedings pkdd workshop data mining decision support meta learning ilp 
kohavi ron george john 

automatic parameter selection minimizing estimated error 
proceedings th international conference machine learning icml pages 
kohavi ron dan sommerfield james dougherty 

data mining mlc machine learning library 
international journal ai tools 
kushmerick nicholas 

learning remove internet 
proceedings third international conference autonomous agents agents pages 
kushmerick nicholas 

wrapper induction efficiency expressiveness 
artificial intelligence journal 
kushmerick nicholas edward johnston stephen mcguinness 

information extraction text classification 
ijcai workshop adaptive text extraction mining 
lang baum 

query learning poorly human oracle 
proceedings ieee international joint conference neural networks 
lerman kristina steven minton 

learning common structure data 
th national conference artificial intelligence aaai pages 
lewis david jason catlett 

heterogeneous uncertainty sampling supervised learning 
proceedings th international conference machine learning icml pages 
lewis david william gale 

sequential algorithm training text classifiers 
proceedings research development information retrieval pages 
liere ray prasad tadepalli 

active learning committees text categorization 
th national conference artificial intelligence aaai pages 
lindenbaum michael shaul markovitch dmitry 

selective sampling nearest neighbor classifiers 
proceedings th national conference artificial intelligence aaai pages 
lindner guido rudi studer 

ast support algorithm selection cbr approach 
principles data mining knowledge discovery pages 
geoff 

iterative reclassification procedure constructing asymptotically optimal rule allocation discriminant analysis 
journal american statistical association 
marcu daniel lynn carlson watanabe 

automatic translation discourse structures 
proceedings st annual meeting north american chapter association computational linguistics naacl 
mccallum andrew kamal nigam 

comparison event models naive bayes text classification 
aaai workshop learning text categorization 
mccallum andrew kamal nigam 

employing em pool active learning text classification 
proceedings th international conference machine learning pages 
merialdo bernardo 

tagging english text probabilistic model 
computational linguistics 
michie donald 

problems computer aided concept formation 
quinlan editor applications expert systems vol 

addison wesley 
miller david hasan uyar 

generalized gaussian mixture classifier learning labeled unlabeled data 
proceedings conference information science systems 
miller david hasan uyar 

mixture experts classifier learning labelled unlabelled data 
advances neural information processing volume pages 
mitchell tom 

machine learning 
mcgraw hill 
muslea ion steven minton craig knoblock 

selective sampling naive testing 
ecai workshop machine learning information extraction 
muslea ion steven minton craig knoblock 

selective sampling redundant views 
proceedings national conference artificial intelligence aaai pages 
muslea ion steven minton craig knoblock 

hierarchical wrapper induction semistructured sources 
journal autonomous agents multi agent systems 
muslea ion steven minton craig knoblock 

active semi supervised learning robust multi view learning 
th international conference machine learning icml pages 
muslea ion steven minton craig knoblock 

adaptive view validation step automatic view detection 
th international conference machine learning icml pages 
nahm un yong raymond mooney 

mutually beneficial integration data mining information extraction 
th national conference artificial intelligence aaai pages 
nigam kamal ghani 

analyzing effectiveness applicability training 
proceedings information knowledge management pages 
nigam kamal andrew mccallum sebastian thrun tom mitchell 

learning classify text labeled unlabeled documents 
proceedings th national conference artificial intelligence aaai pages 
nigam kamal andrew mccallum sebastian thrun tom mitchell 

text classification labeled unlabeled documents em 
machine learning 
neill 
normal discrimination unclassified observations 
journal american statistical association 

fast subsampling performance estimates classification algorithms selection 
proceedings ecml workshop meta learning building automatic advice strategies model selection method combination 
pfahringer bernhard christophe giraud carrier 

metalearning landmarking various learning algorithms 
proceedings th international conference machine learning icml pages 
pierce david claire cardie 

limitations training natural language learning large datasets 
proceedings empirical methods natural language processing emnlp pages 
quinlan ross 

programs machine learning 
morgan kaufmann publishers 
raskutti herman adam kowalczyk 

combining clustering training enhance text classification unlabeled data 
proceedings sigkdd international conference knowledge discovery data mining 
raskutti herman adam kowalczyk 

unlabeled data text classification addition cluster parameters 
proceedings th international machine learning icml pages 
joel santosh venkatesh 

learning mixture labeled unlabeled examples parametric side information 
proceedings th annual conference computational learning theory pages 
reddy prasad tadepalli 

learning horn definitions equivalence membership queries 
zeroski lavra editors proceedings th international workshop inductive logic programming volume pages 
springer 
rendell 

layered concept learning dynamically variable bias management 
proceedings th international joint conference artificial intelligence ijcai pages 
roy nicholas andrew mccallum 

optimal active learning sampling estimation error reduction 
proceedings th international conference machine learning icml pages 
sammut claude banerji 

learning concepts asking questions 
michalski carbonell carbonell mitchell vol 
editors machine learning artificial intelligence approach pages 
morgan kaufmann 
sarkar anoop 

applying training methods statistical parsing 
proceedings nd annual meeting north american chapter association computational linguistics naacl pages 
schaffer cullen 

overfitting avoidance bias 
machine learning 
schaffer cullen 

selecting classification method cross validation 
machine learning 
schaffer cullen 

conservation law generalization performance 
proceedings th international conference machine learning icml pages 
schapire robert 

strength weak learnability 
machine learning 
scheffer tobias stefan wrobel 

active learning partially hidden markov models 
proceedings ecml pkdd workshop active learning database sampling experimental design views instance selection 
schohn greg david cohn 

active learning support vector machines 
proceedings th international conference machine learning icml pages 
seung sebastian manfred opper haim 

query committee 
proceedings conference computational learning theory colt pages 
shahshahani david landgrebe 

effect unlabeled samples reducing small sample size problem mitigating hughes phenomenon 
ieee transactions geoscience remote sensing 
shapiro 
general incremental algorithm infers theories facts 
proceedings th international joint conference artificial intelligence pages 
shapiro 
algorithmic program diagnosis 
proceedings th acm symposium principles programming languages pages 
shavlik jude raymond mooney george towell 

symbolic neural learning experimental comparison 
machine learning 
sloan robert turan 

learning queries incomplete information extended 
proceedings conference computational theory colt pages 
soares carlos pavel brazdil 

zoomed ranking selection classification algorithms relevant performance information 
proceedings th conference principles practice knowledge discovery databases pkdd 
soderland stephen 

learning extraction rules semi structured free text 
machine learning 
szummer martin tommi jaakkola 

kernel expansions unlabeled examples 
leen dietterich tresp editors neural information processing systems volume pages 
tadepalli prasad 

learning queries examples tree structured bias 
proceedings th international conference machine learning icml pages 
tadepalli prasad stuart russell 

learning queries examples structured determinations 
machine learning pages 
taskar ben eran segal daphne koller 

probabilistic classification clustering relational data 
proceedings th international joint conference artificial intelligence ijcai pages 
thompson cynthia mary elaine califf raymond mooney 

active learning natural language parsing information extraction 
proceedings th international conference machine learning icml pages 
thrun sebastian pratt editors 

learning learn 
kluwer academic publishers 
ting kai ming ian witten 

issues stacked generalization 
journal artificial intelligence research 
todorovski saso dzeroski 

experiments meta level learning ilp 
zytkow rauch editors proceedings rd european conference principles data mining knowledge discovery pkdd pages 
springer 
todorovski saso dzeroski 

combining multiple models meta decision trees 
proceedings th european conference principles data mining knowledge discovery pages 
springer 
tong simon daphne koller 

active learning parameter estimation bayesian networks 
advances neural information processing systems volume pages 
tong simon daphne koller 

support vector machine active learning applications text classification 
proceedings th international conference machine learning icml pages 
tong simon daphne koller 

support vector machine active learning applications text classification 
journal machine learning research 
valiant leslie 

theory learnable 
communications acm 
vapnik vladimir 

statistical learning theory 
john wiley sons 
rau 

selecting examples perceptrons 
journal physics mathematical general 
widmer gerhard 

tracking context changes meta learning 
machine learning 
wolpert david 

stacked generalization 
neural networks 
wolpert david 

lack priori distinctions learning algorithms 
neural computation 
wolpert david william macready 

free lunch theorems search 
ieee transactions evolutionary computation 
yarowsky david 

unsupervised word sense disambiguation rivaling supervised methods 
proceedings rd annual meeting association computational linguistics pages 
sara haym hirsh 

improving short text classification unlabeled background knowledge 
proceedings th international conference machine learning icml pages 
zhang tong frank oles 

probability analysis value unlabeled data classification problems 
proceedings th international conference machine learning icml pages 
appendix proofs convergence take hand volume school metaphysics instance ask contain reasoning concerning quantity number 
contain experimental reasoning concerning matter fact existence 
commit flames contain illusion 
david hume appendix prove propositions section 
remember dhl dhl target concepts integer threshold values real valued attributes uniformly distributed interval 
proofs assume algorithms access sufficiently labeled unlabeled examples unambiguously learn target concepts 
intuitively means intervals training working set include example takes value interval 
convergence properties single view algorithms studying ability single view algorithms learn target concepts form wtc wtc wtc andl 
words goal learn threshold value wtc divides interval sub intervals examples label furthermore learner identify labels denotes positive negative examples respectively andf 
note restriction wtc problem hypotheses space finite 
furthermore training set problem version space consists subset min min min max hypotheses space 
keep notation simple appendix convention version space consists hypotheses min min min min represented set denotes hypothesis version space min denotes second min 
proposition dhl problem uncertainty sampling algorithm requires log queries learn target concept 
proof mentioned uncertainty sampling step iterative process learns hypothesis training set queries unlabeled example hypothesis confident prediction 
gibbs algorithm base learner learned hypothesis randomly chosen current version space decision threshold set value randomly chosen set 
confident prediction hypothesis example closest current decision border fact decision border 
consequently uncertainty sampling seen randomly querying example belongs current version space 
note depending label example query removes hypotheses version space 
notation wtc wtc denote possible cuts version space 
compute expected cut particular query version space cut wtc wtc wtc wtc compute expected cut actual query version space averaging expected cuts possible query cut cut words query uncertainty sampling expected remove approximately current version space 
consequently uncertainty sampling con target concept log queries size initial version space 
proposition dhl problem arbitrarily high probability query committee algorithm requires log queries learn target concept 
proof order prove proposition main result fre und theorem shows arbitrarily high probabil ity query committee error rate reduced exponentially number queries 
theorem hold main requirements 
learning concept perfectly learnable construction true dhl 
second learning problem finite vc dimension dhl finite version space follows vc dimension finite see mitchell page details 
expected information gain query query committee finite lower bound 
words query qi log log probability label example qi structure dhl problem target concept threshold values uniformly distributed initial version space follows example ensuring expected information gain lower bounded finite positive value logn log log log requirements theorem freund fulfilled follows query committee solves dhl learning problem log queries size initial version space 
proposition dhl problem probability random sampling correctly learns target concept randomly chosen examples proof gibbs learner randomly chooses hypothesis version space random sampling correctly learns target concept version space consists single hypothesis true threshold value wtc 
happen randomly chosen training set contain examples wtc wtc andx wtc wtc 
consequently probability random sampling correctly learns target concept equal probability having randomly chosen training set contain examples 
proof notation represents algorithm randomly chosen training set denotes number examples represents size initial version space denotes statement wtc wtc denotes statement wtc wtc andb denote expressions respectively 
probability random sampling correctly learns target concept randomly chosen labeled examples convergence properties multi view algorithms section analyze ability multi view learners correctly learn target concept arbitrary dhl problem 
consider scenario views independent label relax initial assumption analyze situation views independent clump section depict dimensional instance space orthogonal system coordinates 
view described values ox axis view corresponds oy dimension 
figures section color coding regions instance space drawn light dark grey denote positive negative examples respectively areas depicted intermediate shade grey represent contention points 
views independent label analysis studying ability multi view algorithms learn target concepts form tc tc tc tc tc tc tc tc tc tc andl 
view setting translates solving dhl problem view 
consequently target concepts views respectively 
tc tc tc tc proposition domain specific knowledge solve dhl problem single randomly chosen query 
proof construction properties examples dhl instance space occupy bottom left top right quad quadrant consists examples label see scenario 
scenario 
possible scenarios dhl views independent label negative examples lie bottom left top right quadrant 
positive examples occupy populated quadrant 
furthermore view independence assumption populated quad consist examples having different labels 
consequently querying ran chosen example sufficient learning target concept examples quadrant query share label examples opposite label 
proposition dhl problem training algorithm requires random positive random negative examples learn target concept 
proof described earlier training blum mitchell boot views iteratively adding training set examples hypotheses learned views confident predictions :10.1.1.114.9164
dhl problem high confidence predictions correspond examples farthest away decision threshold view 
degenerate scenarios examples positive negative views independent knowing example description view unambiguously identifies example quadrant knowing example label allows example lie quadrants vs vs training examples 
confident predictions 
applying training dhl task views independent label clump class 
consider scenario described training provided randomly chosen examples remember labels denote positive negative example respectively 
step training learns hypothesis view running gibbs learner randomly returns hypothesis version space 
version spaces vs vs denoted black rectangles axes coordinates consist integers intervals respectively 
dashed lines represent hypotheses returned gibbs sampler view 
hypotheses learned training applies unlabeled examples adds training set confident predictions 
depicts unlabeled examples hypothesis learned vertical view confident negative positive predictions respectively 
located axis located top border image 
newly labeled examples highly informative examples denoted adding examples training set version space horizontal view collapses true target concept 
similar situation occurs vertical view adding training set high confidence predictions hypothesis learned horizontal view proposition dhl problem provided random positive random negative examples aggressive testing requires queries learn target concepts views 
proof proposition particular case proposition shows aggressive testing requires queries learn target concepts views 
dhl views independent label clump class total domain clumps 
consequently queries aggressive testing collapses version spaces views respective target concepts 
views independent clump section relax views independent label assumption con scenario views independent clump having just clump class consider problems clumps class precisely assume total number clumps domain 
illustrates scenario negative positive clumps positive negative clump denoted dark light grey rectangle respectively 
formally study convergence properties multi view algorithms learning target concepts form tc tc tc tc tc tc tc tc view setting translates solving dhl problem view 
conse quently target concepts views respectively 
tc tc tc tc vs vs queries 
removes half clumps version space 
domain specific knowledge perform binary search space domain clumps 
proposition domain specific knowledge solve dhl problem log queries 
proof explicitly advantage domain structure dhl solve learning task manner similar binary search 
step algorithm queries andq randomly chosen examples clumps shown andq reveal labels examples left right middle clump respectively 
labels clumps known algorithm keeps halving interval querying randomly chosen example clump middle current version space example corresponds query continuing procedure discovering neighboring clumps labeled differently algorithm guaranteed find correct target concept 
keeping results binary search entire process requires log queries 
proposition depending distribution examples initial training set training may may learn target concept dhl problem 
vs vs proof mentioned earlier training works follows uses labeled examples learn hypothesis view 
applies learned hypotheses unlabeled examples adds training set examples confident prediction 
repeats process number iterations 
consider applying training domain labeled examples determine version spaces vs vs gibbs learner randomly chooses hypotheses dashed lines picture 
confident positive negative predictions hypothesis learned view unlabeled examples farthest away decision border examples lie left border left clump right border right clump respectively 
examples depicted thin white rectangles labeled respectively 
similarly thin black rectangle bottom left clump top right clump represent confident predictions horizontal hypothesis learned 
number iterations training adds training set examples left right clump 
point new confident predictions ones borders second clumps left right respectively see 
iterations examples new clumps added training set training starts making confident predictions third clump left right respectively see 
note clumps ones guaranteed correctly labeled training training starts labeling clumps information proximity previously labeled clumps 
illustrative domain chosen training happens correctly label fourth clump left right respectively see 
reaching remaining unlabeled clump fifth left right vs vs vs labeling left right clumps 
labeling second clump left right 
vs vs vs vs labeling third group clumps 
labeling fourth group clumps 
vs vs vs inconsistently labeling clump 
necessary condition convergence 
training bootstraps views adding confident predictions training set 
initial randomly chosen training set favorable distribution training converge target concept 
views label clump inconsistently see 
example view labels left right border clump negative positive respectively impossible examples clump label 
similar situation appears view predicts positive negative labels examples top bottom borders clump respectively 
practice problem conflicting labels way training may fail learn target concept 
example training labeled fourth clump left right see pure chance clumps labeled correctly 
different target concept clumps different label implied views provided mislabeled examples turn prevented learning correct target concepts 
problems described easy see training guaranteed correctly learn target concept initial training set contains positive negative example clumps define border classes see 
words guarantee arbitrary training set training converges target concept 
proposition dhl problem arbitrarily high probability aggressive testing learns target concept views making queries number clumps domain 
order show proposition true prove auxiliary results proof proposition statement version spaces view collapsed single hypothesis converge respective target concepts arbitrarily high probability testing set contention points empty 
vs vs illustrative scenarios contention points 
scenarios clumps entirely dimensional version space 
statement aggressive testing queries examples clump domain 
proof statement construction hypotheses learned dif ferent views fail generate contention points intersect points neighboring clumps touch see 
gibbs algorithm randomly selects hypotheses uniformly distributed version spaces follows probability learning hypotheses contention points size vs vs size vs vs vs represent version spaces view denotes number clumps entirely lie current dimensional version space rectangular area defined version spaces view 
depicts possible scenarios contention points 
vs min max contention points max min min max max min contention points left entire clump consists contention points 
left hypotheses intersect clump splitting quadrants clump top left bottom right quadrants consist contention points 
assume version spaces collapse single hypothesis hypotheses returned gibbs algorithm contention points 
testing re run gibbs learner generates hypotheses non empty set contention points 
probability having non empty set contention points re runs gibbs learner view size vs size vs consequently choosing appropriately large value guarantee arbitrarily high probability testing obtains non empty set contention points 
proof statement order prove statement proceed follows 
show aggressive testing queries examples particular clump queries examples top left bottom right corners rectangle borders clump show queries example clump contention points making impossible query examples consider arbitrary pair hypotheses learned views 
denote decision thresholds corresponding re spectively 
hypotheses divide instance space quadrants 
contention points lie top left bottom right quadrants respectively hypotheses predict different label 
depicts illustrative scenarios examples clump contention points 
denote xmin ymax xmax ymin top left bottom right corner clump respectively 
properties true property xmin ymax xmax ymin contention points examples contention points 
proof xmin ymax xmax ymin contention points follows xmin xmax ymin ymax xmin xmax ymin ymax 
follows arbitrary example clump xmin xmax andy ymin ymax 
consequently labeled identically decision thresholds views making impossible contention points 
property clump includes contention points located top left quadrant xmin ymax 
top left contention points clump xmin ymax confident prediction hypotheses 
proof consider arbitrary example clump xmin xmax ymin ymax 
assume contention point located top left quadrant 
xmin ymax follows xmin ymax 
consequently xmin ymax contention point located top left quadrant 
furthermore examples lie quadrant xmin ymax farthest away decision borders maximizes 
property clump includes contention points located bottom right quadrant xmax ymin 
furthermore bottom right contention points clump xmax ymin confident prediction hypotheses 
proof consider arbitrary example clump xmin xmax ymin ymax 
assume contention point located bottom right quadrant 
asx xmax ymin follows xmax ymin 
consequently xmax ymin contention point located bottom right quadrant 
furthermore examples lie quadrant xmax ymin farthest away decision borders maximizes properties follows aggressive testing queries examples clump query xmin ymax xmax ymin loss generality assume aggressive testing queries example xmin ymax argument similar holds testing queries xmax ymin query xmin ymax labeled testing re trains new hy correctly classify example xmin ymax remember sumed perfect learning views 
means example xmin ymax contention point turn property implies contention points top left quadrant 
argument implies querying xmin ymax re training possibilities contention points clump contention points lie bottom right quadrant 
scenario testing ends making just single query clump scenario testing may may query clump depending confident predictions contention points various clumps 
testing query clump property query guaranteed xmax ymin second scenario new query xmax ymin labeled remember examples clump label 
adding xmax ymin training set re training time new hypotheses label correctly xmax ymin xmin ymax means xmax ymin xmin ymax contention points consequently property examples clump contention points 
turn means aggressive testing queries clump proof proposition statements proof proposition straightforward 
aggressive testing starts ran chosen examples positive negative learns hypothesis view 
statement guarantees learning process converged target concepts views arbitrarily high probability learned ses lead non empty set contention points allowing testing new queries 
keeping statement aggressive testing queries clump total queries 
number queries label clump unambiguously determined collapsing version spaces single hypothesis represents target concept 
appendix semi artificial problems man knowledge go experience 
john locke create parameterized family problems control view correlation incompatibility start idea nigam ghani 
create semi artificial domain compatible uncorrelated views unrelated binary classification problems considering problem individual view 
multi view examples created randomly pairing examples label original problems 
procedure easily modified introduce clumps ible examples 
instance consider creating binary classification problem positive examples consist clumps 
unrelated problems sets positive examples andd respectively 
newly created view problem positive examples views consist respectively 
shown left graph multi view examples created randomly pairing example obtain uncorrelated views 
contrast allow examples paired ones ones ones obtain view view view view clump class clumps class generating clumps class 
problem clumps positive examples 
similarly unrelated problems create clumps class respectively 
adding incompatible examples straightforward task randomly pick positive negative multi view example say advanced os class john doe homepage 
replace examples recom advanced os homepage joe doe class positive view negative 
order generate problems clumps class newsgroups postings mini newsgroups dataset subset known newsgroups domain joachims 
newsgroup consists articles randomly chosen postings included original dataset 
divided newsgroups groups see table 
examples group positive negative examples views newsgroups comp os ms win comp sys ibm comp windows comp sys mac play roles andd sets examples 
www cs cmu edu afs cs project theo www naive bayes mini newsgroups tar gz comp os ms win misc comp windows pos comp sys ibm pc comp sys mac rec autos rec motorcycles rec sport baseball rec sport hockey sci crypt sci electronics neg sci space sci med talk politics guns talk politics mideast talk politics misc talk religion misc table newsgroups included domain 
creating compatible views levels clumps class 
shows levels created positive examples 
clump class positive example paired positive example 
clumps class allow pairing comp examples view rec examples 
clumps class pair examples comp os ms win comp windows comp sys ibm comp sys mac level consider levels view incompatibility examples incompatible respectively 
corresponds total points correlation incompatibility space mentioned point generate random problems total problems problem consists examples 
documents tokenized usenet headers discarded words stoplist removed stemming performed words appear single document removed 
resulting views features words respectively 
comp os ms win comp sys ibm rec autos rec sport baseball comp windows comp sys mac rec motorcycles rec sport hockey comp os ms win comp sys ibm rec autos rec sport baseball comp windows comp sys mac rec motorcycles rec sport hockey comp os ms win comp sys ibm rec autos rec sport baseball comp windows comp sys mac rec motorcycles rec sport hockey clump class clumps class clumps class generating clumps class 

