neural methods non standard data barbara hammer jain ag lnm dept math comp science university germany hammer informatik uni de methods artificial intelligence faculty iv tu berlin germany cs tu berlin de 
standard pattern recognition provides effective noise tolerant tools machine learning tasks approaches deal real vectors finite fixed dimensionality 
tutorial give overview extensions pattern recognition non standard data contained finite dimensional space strings sequences trees graphs functions 
major directions distinguished neural networks literature models similarity measure adapted non standard data including kernel methods structures prominent approach alternative metric algorithms functional networks alternatively non standard data processed recursively supervised unsupervised recurrent recursive networks fully recurrent systems 
pattern recognition tools statistical classifiers feed forward neural networks support vector machines svms self organizing maps soms deal real life noisy data efficient way constitute successful models various areas applications 
neural methods restricted real vectors finite fixed dimensionality input 
consequence extensive preprocessing data usually necessary typical applications neural methods real life scenarios 
inputs represented finite dimensional vector problem dependent real valued features categorical variables encoded encoding time series embedded finite dimensional vector space time windows preprocessing images includes edge detection various filters sound signals utterances represented cepstrum vectors chemical data characterized topological indices attributes mention examples 
alternative data formats data representations exist sets specified order describe objects scene set measurements contact points gripper functions evaluated specific points constitute natural description time series spectral data sequences arbitrary length represent time series spatial data natural language text documents dna sequences tree structures describe terms logical formulas parse trees phylogenetic trees graph structures encode chemical formulas scenes images objects built various primitives 
feature encoding type data yields compact vectors encoding problem specific time consuming 
information usually lost complex data structures sequences trees graphs possibly arbitrary size encoded fixed dimensional vectors 
extension neural methods directly deal complex data desirable 
article give overview extensions neural methods data 
distinguish main directions similarity approaches recursive models 
similarity approaches similarity measure constitutes interface process complex data 
structures processed output similarity measure adapted non standard data 
recursive models hand decompose structures recursively process basic constituents context processed related constituents 
similarity approaches variety neural methods processes data similarity measure metric input vector feed forward neural networks compute dot product 
input weights neurons support vector machine substitutes standard euclidean dot product kernel support vector interpreted dot product implicit feature space radial basis function networks self organizing maps euclidean metric jx wj denoting weight vector neuron 
input element finite dimensional real vector space dot product kernel similarity measure substituted generalization measures similarity complex objects 
depending respective model issues adapt weight vector specified 
give example approach suggests structural perceptron adaptive processing graphs supervised unsupervised setting 
facilitate adaptive processing neuron associated attributed weight graph concept inner product vectors replaced schur hadamard inner product graphs 
despite name schur hadamard inner product inner product shares useful properties inner product extend supervised unsupervised neural learning machines attributed graphs 
training networks composed structural units minimizing suitable error function function adjustable weights 
tackle different approaches context similarity methods 
functional networks functional networks fall framework functional data analysis processing functions data points 
exact input functions usually available practice 
vector input output pairs 
examples type data time series seen evaluation function different time steps length time series sampling frequency positions function evaluation vary 
data provide alternative application area interpreted signal frequency function evaluated different ranges 
vector input functional data models function fitted values 
standard approximation techniques spline approximation 
space square integrable functions infinite dimensional possesses dot product 
dx techniques standard vector algebra transferred case 
linear techniques principal component analysis linear discriminants non parametric models transferred functional data 
proposals extend nonlinear feedforward networks functional inputs investigated 
commonly functional data layer network models differ way input functions internally evaluated 
shown specific hidden layer functional network provides universal approximation nonlinear continuous operators 
input function evaluated network points weights network contained vector space 
approach extends result multiple nonlinear operators 
multiple nonlinear operators provide important tool simulate systems specific parameter choices show fundamentally different dynamical behavior system 
contribution investigates alternative formulation functional networks base layer dot products input functions functional weights computed 
practice dot products evaluated numerically 
extended version approximation completeness model consistency numerical integration universal function approximators proved 
rossi guez volume application model data tackling problem possibly missing data 
contributions rossi guez verleysen volume rossi guez volume extend idea alternative neural network models radial basis function networks self organizing map 
unsupervised models multidimensional scaling isomap isodata related tools constitute popular unsupervised techniques data visualization clustering 
data visualization methods aim projecting data points low dimensions pairwise distances preserved far possible 
data clustering partitions set data clusters similarity 
data indirectly characterized pairwise proximity values methods directly utilized non standard data provided appropriate similarity measure defined 
specific mathematical properties symmetry fulfilled apply algorithms 
reasonable similarity measures provided kernels described section 
pairwise clustering mean field methods iteratively compute cluster membership weights 
self organizing map constitutes popular unsupervised method data visualization clustering 
apart appropriate notion similarity nonstandard data som training requires concept adapt prototypes non standard domain 
elegant general solution proposed kohonen batch som algorithm applied type data setting prototypes generalized median point training set minimizes generalized quantization error 
approach visualize proteins similarity measure punishes mismatches pairwise aligned sequences 
time gunter bunke extended som algorithm attributed graphs means edit distance generalization weighted mean set graphs 
simple competitive learning algorithms clustering weighted graphs proposed 
kernel methods training classification support vector machine formulated terms support vector kernel 
modification kernel complex data allows transfer svm complex domains 
resulting classification model interpreted linear classifier high dimensional feature space kernel decomposes 

valid positive semi definite kernels 
analogously kernel methods kernel principal component analysis rely solely appropriate choice task reduces design kernels structured data 
various different methods extend kernels non standard data proposed 
gives overview kernels structures 
slightly different taxonomy distinguish types kernels kernels common substructures kernels statistical model kernels local transformations data 
note decomposition fully disjoint string kernel data structure interpreted kernel derived specific generative model 
kernels common substructures articles basic principle composite kernels introduced 
simple kernels defined subparts structures extended generic operations complex convolutional kernels 
particular strong closure properties positive definite kernels hold allow easily construct problem specific versions 
consequence general proposal kernels comparison primitives structures proposed different data types 
sequences string kernel variants count number occurrences common substrings limited length approaches differ respect weighting matches partial matches allowed substrings need contiguous 
direct computation kernels complex effort put efficient computation schemes 
dynamic programming suffix trees alternative techniques context 
improvement efficiency accuracy approaches obtained words single symbols document classification extending methods transduction tasks 
approach introduces locality improved kernel takes local correlations neighbored sequence entries account string kernel proposed fixed structures 
general data structure directed acyclic graphs addressed similar way counting number matching partially matching subtrees structures proposed micheli sperduti volume 
approach adapts general idea matching subtrees kernel compares specific labeled acyclic graphs come limited description language 
alternative string kernels directly applied prefix representation trees proposed 
graphs situation difficult determining matching substructures complex problem 
jain wysotzki volume graphs compared schur hadamard inner product measures similarity connection structure labels graphs 
np hard problem finding optimum matching approximated heuristic need yield valid kernel 
alternative graph kernel proposed labels randomly generated paths infinite length compared 
efficient computation possible means fixed point equation 
kernels statistical model alternative point view define kernels non standard data relies semantic information data represents data feature vectors derived generative models 
fisher kernel constitutes early prominent approach line 
probabilistic model fitted data input structures represented finite dimensional gradients log likelihood model respective data point 
generation process data captured model compared approach 
usually fisher information metric dot product feature space describes riemannian metric space models 
shown fisher kernel class information contained latent variable 
fisher kernel combination hidden markov models context sequential data 
alternative stochastic models appropriate alternative domains mixture probabilistic principal components proposed 
approach proposes tangent vector log odds top kernel similar fisher kernel directly derived classification model 
class information contained class variable top kernel compares favorably fisher kernel application biological sequences 
alternatives fisher kernel derived general model marginalized kernels described 
approaches fit separate probabilistic model data point compare probabilistic models proposed 
gaussian model fitted data point distributions compared leibler divergence 
method audio image data 
similar procedure sets vectors 
gaussian distributions fitted sets affinity serves kernel 
kernels local transformations basic idea diffusion kernel introduced extend known local similarity objects neighborhood structure valid local transformation steps global kernel imitating diffusion process 
main algebraic tool matrix exponentiation iterate generator square matrix describes local neighborhood structure data 
approach proposes negative laplacian generator generic setting undirected graph local neighborhood structure 
extends diffusion kernel introduced discrete neighborhood structures general riemannian manifolds 
diffusion kernel applied document processing generator induced occurrence information bioinformatics data generator links genes participate successive reactions metabolic pathways 
recursive models recursive models decompose structures constituents recursively process basic parts 
processed data sets context computation single parts integrated structure 
basically different directions recursive processing distinguished partially recurrent system dynamic driven data structure fully recurrent systems seen complex discrete continuous time dynamic systems 
partially recurrent systems simple recurrent networks constitute established tool time series data 
assume denotes sequence entry time point dynamic equation function computed network denotes network state time point detailed overview recurrent network models 
dynamic immediately generalized complex recursive structures 
recursive networks process tree structures inputs 
binary tree root label subtrees state network processing defined 
recurrent recursive models investigated mainly supervised learning 
supervised models supervised recurrent network training faces problems complex dynamic behavior dealt 
tutorial overview various aspects concerning learnability dynamical properties training algorithms 
prime application recurrent networks language learning clear discussion possibilities restrictions learn languages 
prototypical training schemes analysis 
mentioned recursive networks enlarge dynamic recurrent models tree structures trained adaptation back propagation 
share dynamic properties difficulties simple recurrent networks 
various alternative training schemes adapted recursive networks widespread successful applications recursive networks literature theorem proving discourse representation theory picture processing document image classification connectivity prediction molecules natural language parsing protein structure prediction chemistry 
recursive networks compete kernel methods see micheli sperduti volume 
dynamic introduced far mirrors causality time series data tree structures 
spatial data acyclic graphs constitute generalizations thereof 
encoded time series tree structures specifying order vertices 
potential loss information dependencies vertices introduced procedure 
generalizations basic recursive models better fit type data proposed recursive networks acyclic graphs volume networks protein secondary structure prediction extension recursive networks lattices applied protein contact map prediction contextual models graph structures 
adaptations extend scope information available recursive processing step data structure yield improved accuracy 
unsupervised models increasing interest unsupervised recursive processing structured data observed see overviews topic 
aim approaches obtain visualization clustering tools temporal signals spatial data complex structures 
principle dynamics unsupervised models borrowed supervised case sequences trees 
supervised case concrete choice function network activation obvious 
unsupervised models compute explicit output 
activation interpreted different ways best matching neuron distance profile computed map 
unsupervised recursive models proposed temporal data obey simple dynamics leaky integrators traveling waves 
recursive som constitutes powerful computationally quite complex model relies map activation 
efficient compression schemes characteristics winner neuron proposed achieve comparable results recursive som computationally efficient 
som structured data constitutes recursive som proposed tree structured data 
general dynamics recursive models subsumes approaches proposed 
general framework important mathematical properties comparisons models investigated 
fully recurrent systems section focuses recurrent systems solving graph matching problems gmp 
gmp refers finding structure preserving correspondence vertices different graphs similarity function maximized 
finding correspondences np hard combinatorial problem 
due wide applicability approximate solutions gmp proposed 
multitude methods originate neural network community 
considerable interest solving combinatorial optimization problems cop means neural networks initiated seminal hopfield tank 
general approach solve cops maps objective function optimization problem energy function network 
constraints problem included energy function penalty terms global minima energy function correspond optimal solutions cop 
context graph matching constituents solution match hypotheses pairs vertices 
recurrent network dynamic aims converging stable coalition active neurons representing maximal set compatible matches 
optimizing networks roughly divided major groups quite intuitive direction poses graph matching problem recovering structure preserving permutation matrix 
alternative direction transforms matching problem maximum clique problem association graph 
approaches fall realms example dynamic link architecture extensions associative memories storing retrieving graphs selforganizing winner takes classifiers structures 
recovering permutation matrices permutation matrix matrix representation injective mapping vertices graphs 
graphs matched order resp permutation matrix matrix rows columns summing zero 
entries permutation matrix determine correspondences vertices graphs 
early uses binary threshold units fixed penalty terms express constraints 
approaches suffer infeasible solutions instable convergence properties 
graph matching problem casted principled statistical physics setting terms mean field theory combined self amplification softmax penalty terms improve solution quality convergence properties 
approaches concerned determining similarity graphs means minimizing energy function quadratic assignment variables subject way constraint 
conceptual extensions issue noteworthy mention relaxed way constraints imposed permutation matrix way constraint retrieving occurrences model scene parallel 
extension due finch non quadratic energy function graph matching compute similarity graphs rectify structural errors time 
association graph techniques second strand activities neural graph matching idea originating computer vision 
ambler barrow burstall levi suggested transform graph matching problem maximum clique problem mcp called association graph product structure derived graphs 
association graph techniques applied graph matching problems :10.1.1.157.6789:10.1.1.15.4278
meet requirements practical applications weights annotated vertices edges association graph express similarities pairs items graphs matched 
graph matching problem maximum weighted clique problem 
wysotzki applied hopfield style network approximately solving mcp association graph 
approach applied learn structural prototypes chemical compounds predict mutagenicity similarity recognition segmented images 
neural solutions solely focus mcp 
jain wysotzki volume proposed hopfield clique network global local minima energy function correspondence maximum weighted maximal cliques respectively 
pelillo replicator dynamics solving mcp framework 
replicator dynamics derived evolutionary game theory 
uses motzkin strauss formulation maximum clique problem spurious free extensions 
formulation allows transform maximum clique problem problem quadratic form 
method successfully applied match articulated deformed shapes described shock trees 
contribution provides brief overview neural network techniques applied non standard data data represented terms static feature vectors 
non vectorial representations trees graphs better suited capture functional structural complex informations inherent real world data 
standard vectorial feature representation usually problem specific prone information loss alternatively curse dimensionality 
structured representations hand allow store data structures different sizes complexity natural way information loss prohibited time number parameters limited 
reported successful applications structure networks various different areas applications chemistry bioinformatics natural language processing developed 
structure approaches suffer analytical poverty computational intractability standard analytical methods easily transferred complex structures discrete optimization problems arise subproblems training 
apparently reasons neural networks non standard data despite importance potential applicability widely unexplored 
emerging interest structure models observed years particular context kernel methods 
comparisons different structure methods conducted literature micheli sperduti volume quite interesting approaches combine best different structure methods jain wysotzki volume 
ambler barrow brown burstall 
versatile computer controlled assembly system 
ijcai 
araujo barreto 
context temporal sequence processing self organizing approach application robotics 
ieee transactions neural networks 
back chen 
universal approximation multiple nonlinear operators neural networks 
neural computation 
baldi brunak frasconi pollastri soda 
bidirectional dynamics protein secondary structure prediction 
sun giles eds sequence learning paradigms algorithms applications pp 
springer 
barreto araujo kremer 
taxonomy spatiotemporal connectionist networks revisited unsupervised case 
neural computation 
barrow burstall 
subgraph isomorphism matching relational structures maximal cliques 
information processing letters 
gori 
processing directed acyclic graphs recursive neural networks 
ieee transactions neural networks 
micheli sperduti 
application cascade correlation networks structures chemistry 
journal applied intelligence 
bischoff wysotzki 
applied connectionist methods computer vision compare segmented images 
ki advances artificial intelligence 
lnai pp 

springer 
boden wiles 
learning context free context sensitive languages 
ieee transactions neural networks 
bolles horaud 
dpo dimensional part orientation system 
international journal robotic research 
bomze 
evolution maximum clique 
journal global optimization 
gori santini 
recursive neural networks applied discourse representation theory 
icann 
gaussier goutte 
renders 
word sequence kernels 
journal machine learning research 

functional linear model 
statist 
prob 
letters 
chappell taylor 
temporal kohonen map 
neural networks 
chen chen 
universal approximation nonlinear operators neural networks application dynamic systems 
ieee transactions neural networks 

cho chi 
siu tsoi 
improved algorithm learning long term dependency problems adaptive processing data structures 
ieee transactions neural networks 
collins duffy 
convolution kernels natural languages 
nips 
roth 
kernel methods relational learning 
icml 
diligenti frasconi gori 
hidden tree markov models document image classification 
ieee transactions pattern analysis machine intelligence 
vieu 
functional nonparametric model applications data 
computational statistics 
finch wilson hancock 
energy function continuous edit process graph matching 
neural computation 
frasconi gori sperduti 
general framework adaptive processing data structures 
ieee transactions neural networks 
takefuji lee 
comparisons energy descent optimization algorithms maximum clique 
ieice trans 
fundamentals 
gartner 
survey kernels structured data 
sigkdd explorations 
garey johnson 
computers intractability guide theory np completeness 
freeman new york 
gibbons hearn pardalos ramana 
continuous characterizations maximum clique problem 
mathematics operations research 
gold rangarajan mjolsness 
learning clustering point graph matching distance measures 
nips 
connectionist approach learning search control heuristics automated deduction systems 
phd thesis technische universitat munchen 
gunter bunke 
self organizing map clustering graph domain 
pattern recognition letters 
tsoi 
self organizing map adaptive processing structured data 
ieee transactions neural networks 
hammer 
learning recurrent neural networks 
springer 
hammer micheli sperduti 
general framework unsupervised processing structured data 
appear neurocomputing 
hammer micheli sperduti 
recursive self organizing network models 
submitted neural networks invited 
hammer 
perspectives learning recurrent networks 
esann 
haussler 
convolutional kernels discrete structures 
technical report department computer science university santa cruz 
hofbauer sigmund 
evolutionary games population dynamics 
cambridge university press uk 
hofmann buhmann pairwise data clustering deterministic annealing 
ieee transactions pattern analysis machine intelligence 
hopfield tank 
neural computation decisions optimization problems 
biological cybernetics 
jaakkola haussler 
discriminative framework detecting remote protein homologies 
journal computational biology 
james hastie 
functional linear discriminant analysis irregularly sampled curves 
journal royal statistical society series 
jagota 
approximating maximum clique hopfield network 
ieee trans 
neural networks 
jain wysotzki 
maximum clique problem hopfield clique model 
submitted neural computation 
jain wysotzki 
fast winner takes networks maximum clique problem 
ki advances artificial intelligence 
lnai springer 
jain wysotzki 
competitive winner takes architecture classification pattern recognition structures 
th iapr international workshop 
lncs springer 
jain wysotzki 
structural perceptrons attributed graphs 

submitted publication 
jain wysotzki 
central clustering domain graphs 
machine learning special issue theoretical advances data clustering 
accepted publication 
jiang bunke 
median graphs properties algorithms applications 
ieee transactions pattern analysis machine intelligence 
kandola shawe taylor cristianini 
learning semantic similarity 
nips 
tsuda inokuchi 
marginalized kernels labeled graphs 
icml 
kohonen 
large self organizing maps data 
neural networks 
kondor lafferty 
diffusion kernels graphs discrete input spaces 
icml 
kondor jebara 
kernel sets vectors 
icml 

recognition topological features graphs 
journal physics mathematical general 
kremer 
spatiotemporal connectionist networks taxonomy review 
neural computation 
lades buhmann lange von der malsburg wurtz 
distortion invariant object 
ieee transactions computers 
lafferty lebanon 
information diffusion kernels 
nips 
leslie eskin weston noble 
mismatch string kernels svm protein classification 
nips 
levi 
note derivation maximal common subgraphs directed undirected graphs 

li 
object recognition graph matching implemented hopfield style neural network 
ijcnn 
lin liao tsao 
hierarchical view approach dimensional object recognition 
ieee transaction neural networks 
lodhi shawe taylor cristianini watkins 
text classification string kernels 
journal machine research 
malsburg 
pattern recognition labeled graph matching 
neural networks 
micheli sperduti 
contextual processing structured data recursive cascade correlation 
submitted ieee transactions neural networks 
moreno ho vasconcelos 
kullback leibler divergence kernel svm classification multimedia applications 
nips 
motzkin strauss 
maxima graphs new proof theorem turan 
canadian journal mathematics 
li 
object recognition hopfield neural network 
ieee transactions systems man cybernetics 
pelillo 
replicator equations maximal cliques graph isomorphism 
neural computation 
pelillo jagota 
feasible infeasible maxima quadratic program maximum clique 
journal artificial neural networks 
pelillo siddiqi zucker 
matching hierarchical structures association graphs 
ieee transactions pattern analysis machine intelligence 
peterson 
new method mapping optimisation problems 
international journal neural systems 
pollastri baldi frasconi 
prediction protein topologies 
nips 
principe 
principles networks self organization space time 
neural networks 
silverman 
functional data analysis 
springer series statistica 
rangarajan mjolsness 
lagrangian relaxation network graph matching 
ieee transactions neural networks 
raymond gardiner willett 
heuristics similarity searching chemical graphs maximum common edge subgraph algorithm 
journal chemical information computer sciences 
rodriguez 
simple recurrent networks learn context free context sensitive languages counting neural computation 
rossi guez 
functional layer perceptrons nonlinear tool functional data analysis 
ceremade preprint www ceremade dauphine fr rossi guez 
theoretical properties functional multi layer perceptrons 
esann 
fu 
distance measure attributed relational graphs pattern recognition 
ieee transactions systems man cybernetics 
saunders shawe taylor 
string kernels fisher kernels finite state automata 
nips 
wysotzki 
application neural net classification knowledge discovery 
esann 
wysotzki 
comparing structures hopfield style neural network 
applied intelligence 
schmidhuber gers eck 
learning nonregular languages comparison simple recurrent networks lstm 
neural computation 
shapiro haralick 
metric comparing relational descriptions 
ieee transaction pattern analysis machine intelligence 

constrained nets graph matching quadratic problems 
neural computation 
buc 
mixtures probabilistic pcas fisher kernels word document modeling 
icann 
sonnenburg ratsch jagota 
muller 
new methods splice site recognition 
icann 
sperduti 
supervised neural networks classification structures 
ieee transactions neural networks 
hammer 
neural gas sequences 

costa frasconi 
learning pass structural attachment preferences dynamic grammars recursive neural networks 
cognition 

pattern recognition graph matching potts mft networks 
pattern recognition 
suzuki sasaki maeda 
kernels structured natural language data 
nips 
hancock 
efficiently computing weighted tree edit distance relaxation labeling 

lncs springer 
tsuda ratsch sonnenburg 
muller 
new discriminative kernel probabilistic models 
neural computation 

vert 
graph driven features extraction microarray data diffusion kernels kernel cca 
nips 
vishwanathan smola 
fast kernels string tree matching 
nips 

recursive self organizing maps 
neural networks 
frasconi 
connectivity prediction recursive neural networks multiple alignments 
appear bioinformatics 
wang tang cao 
efficient approximation algorithm finding maximum clique hopfield network learning 
neural computation 
watkins 
dynamic alignment kernels 
technical report department computer science royal holloway university london 
weston leslie zhou elisseeff noble 
semi supervised protein classification cluster kernels 
nips 
wiemer 
time organized map algorithm extending self organizing map spatiotemporal signals 
neural computation 
wysotzki 
artifical intelligence artifical neural nets 
neural informatics akademie der wissenschaften der ddr berlin gdr 
yao pontil frasconi roli 
combining flat structured representations fingerprint classification recursive neural networks support vector machines 
pattern recognition 
yuille kosowsky 
statistical physics algorithms converge 
neural computation 
aone 
kernel methods relational extraction 
journal machine learning research 
