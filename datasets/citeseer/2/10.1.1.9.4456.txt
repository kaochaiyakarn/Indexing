text augmentation inserting xml tags natural language text ppm models viterbi search 
thesis submitted partial fulfilment requirements degree higher deeper university waikato stuart yeates department computer science hamilton new zealand september thesis develops hidden markov models insert tags natural language text 
taxonomy tags developed unifying fields text segmentation tagging part speech tagging proper noun extraction hierarchical entity extraction 
search spaces inserting tags examined theoretical experimental point view taxonomy corpora 
analysis different correctness measures different types tag insertion problem undertaken technique determine tag insertion errors result modelling failure searching failure discovered 
draft september contents table contents list figures list tables list algorithms thesis statement 
plan thesis 
attribution 
original contributions 
data mining text augmentation algorithms 
rule learners 
probabilistic models 
training testing 
supervised unsupervised learning 
time series ordered data 
text mining 
types text mining 
data mining segmented text 
template filling 
text augmentation 
metadata 
tag insertion 
segmentation 
classification 
entity extraction 
attributes 
models text hidden markov models 
applications hidden markov models 
higher order models 
searching models 
prediction partial matching 
linguistic models 
draft september granularity models 
corpora computists corpus 
previous approaches 
bibliography corpus 
previous approaches 
segmentation corpus 
previous approaches 
reuters corpus 
previous approaches 
xml handling 
evaluation techniques recall precision 
edit distance 
confusion matrices 
type confusion matrices 
entropy 
hybrid measures 
efficiency 
granularity 
optimisations heuristics viterbi optimisation 
best optimisation 
automatic tokenisation heuristic 
alphabet reduction 
maximum lookahead heuristic 
heuristic 
state tying 
segmentation 
classification 
entity extraction 
summary 
results effectiveness optimisations heuristics 
best 
automatic tokenisation 
alphabet reduction 
maximum lookahead heuristic 
heuristic 
state tying 
correctness 
computists corpus 
segmentation corpus 
draft september bibliography corpus 
reuters corpus 
baum welch re estimation 
summary 

open questions 
bibliography draft september list figures decision tree play golf 
simple markov model 
linear sequence sequence relation 
segmentation ambiguity chinese japanese 
data mining segmented text 
template filling action 
text augmentation operation 
schema structures segmentation classification problems 
schema structure bibliography entity extraction problem 
tagging line sentence boundaries 
tagging overlapping structures 
limerick shown secondary structure 
particle moving 
particle observed 
representations ppm model 
model built 
model built 
expansion step viterbi search 
corrections computists 
schema computists 
data flow diagram creating bibliography collection 
schema bibliography corpus tags 
schema bibliography corpus tags thesis 
schema bibliography corpus tag tying 
schema structure chinese text segmentation problem 
schema structure reuters corpus 
short quote hamlet 
inter dependencies small entity extraction problem 
viterbi search large search space 
viterbi search fails 
schema state tying 
best bibliography corpus hierarchical 
best bibliography corpus non hierarchical 
best varying model orders 
effect best number training documents varied effect tokenisation group hierarchical tags 
draft september effect tokenisation group non hierarchical tags 
interaction best tokenisation 
effects alphabet reduction finding single tag 
effects alphabet reduction finding multiple tags 
lookahead name tag 
lookahead pages tag 
lookahead word tag 
heuristic bibliography corpus hierarchical 
heuristic bibliography corpus non hierarchical entropy dropping increased training data 
correctness documents reuters corpus 
correctness reuters corpus 
baum welch re estimation 
baum welch re estimation 
draft september list tables metadata different granularities 
classes metadata 
variety problems tackled hmms 
gram models models order 
types optimisations heuristics 
search space size 
occurrence tables reuters corpus 
occurrence tables bibliography corpus 
occurrence tables computists corpus 
occurrence tables segmentation corpus 
folders alphabet reduction 
lookahead word tag 
type confusion matrices state tying tags type confusion matrices state tying tags confusion matrices computists corpus 
accuracy computists corpus 
segmentation chinese 
confusion matrix bibliography corpus note 
confusion matrix bibliography corpus note 
type confusion matrix bibliography corpus 
draft september list algorithms complete search algorithm 
viterbi search algorithm 
teahan search algorithm 
baum welch algorithm 
draft september chapter thousands millions peer review scientific papers available internet bibliographic entries linking papers materials example donald knuth 
semantics context free languages 
mathematical system theory 
competent researcher readily separate entry parts necessary find document refers 
collections thousands electronic documents separating manually huge tedious error prone task 
useful system took entry automatically augmented donald knuth 
semantics context free languages 
mathematical system theory 
draft september system allow number operations including copy document reformatting inclusion document citation analysis querying date 
thesis describes method automating augmentations large class problems 
thesis statement ppm models viterbi search baum welch re estimation solve effectively range text augmentation problems variety optimisations heuristics computationally tractable 
text augmentation partitioned separate classes problem segmentation classification entity extraction amenable different range algorithms needs evaluated differently differences failure modes 
plan thesis chapter introduces data mining text mining text augmentation outlines classes problems tackled thesis 
chapter discusses statistical models text covering markov models hidden markov models ppm models viterbi search worked examples chapter introduces corpora thesis 
chapter examines challenging problem evaluating correctness solutions different classes text augmentation problems previously outlined 
chapter presents number optimisations heuristics applicable tag insertion models search spaces different classes problems respect optimisations heuristics 
chapter sets experimental results optimisations heuristics corpora introduced chapter chapter concludes thesis overview summary unanswered september tions 
appendices contain sample documents corpora schemas 
scope thesis thesis concerned operations written text natural languages principally english chinese operation computer languages java scope thesis 
complexity searching scope thesis complexity data structures algorithms models considered thesis suffix trees separate parallel consideration 
thesis subset xml 
subset free attributes name value pairs stored elements compose character sequences sequences build characters representable single unicode character xml comments discarded standard xml entities cdata nodes handled transparently 
note terminology thesis touches fields research define key words radically differently 
particular information digital library field signal processing field linguistic denote communication languages theories languages 
problems resolved term meaning part compound term clear meaning information retrieval information processing 
attribution working thesis published papers search space viterbi search built earlier bill september han :10.1.1.16.432
bill left arrived waikato communication limited dozen email messages brief conversations dcc respective published works 
worked alongside wen methodologies independent 
wen publish bibliography corpus created 
final stages thesis worked lin yi chou 
wen approached material quite differently 
identifying acronyms text compression done largely ideas generated summer 
examining ppm models high order markov models ian witten question fit aided htk matt jones :10.1.1.17.8190
usability done collaboration coauthors dave nichols kirsten thomson members digital library research group particularly stephan david bainbridge john 
student conference proceedings edited collaboration david bainbridge materials previous conferences series 
contributed code principally acronym extraction code bug fixes greenstone built software package called cem major collaborations ideas wen principally ideas discussed writing search methods points discussed clarifying ideas write 
early research papers credited ph completed enrolled 
followed undergrad masters thesis 
draft september original contributions key novel aspects thesis 
exploration relationship ppm models markov models chapter previously published 
detailed analysis search space size tag insertion sections earlier versions published 
best section optimisation automatic tokenisation section alphabet reduction section section heuristics 
partitioning tag insertion problems coherent taxonomy taxa section 
detailed analysis correctness measures different types tag insertion problem chapter 
development entropy technique determine errors result ppm modelling failure searching failure section 
new extension confusion matrices suitable evaluating hierarchical class classification problems section 
draft september chapter data mining text augmentation data mining techniques applied text mining text augmentation problems 
provide summary main techniques relate field text augmentation aid subsequent chapters 
years field data mining received attention commercial applied computing worlds 
field concerned extracting knowledge large data sources particularly relational databases 
widely discussed example may urban legend supermarket examined sales records discovered new fathers buy beer knowledge boost beer sales particular demographic 
example shows number features data mining interesting facts previously unknown extracted exploited examining existing data 
kinds facts data mining 
microsoft tutorial gives examples data mining actions attempted simple table customer database identifying customers leave demographic facts finding heterogeneous subgroups customers targeted marketing recommending additional products products purchased classifying customers homogeneous groups customer profile products purchased 
remain challenges data mining including specifying draft september outlook play play don play don play play true false overcast raining humidity sunny decision tree play golf facts interesting ii facts exploitable iii data analysed iv analysis proceed 
degree interest facts components strength explain facet data degree novelty surprising facts person familiar domain 
easily measured entropy techniques established way measure second human input :10.1.1.40.180
algorithms fundamental operation data mining classification placing instance classes 
classes known priori built dynamically instances known clusters 
classification algorithms fall main groups learn rules train probabilistic models 
rule learners rule learning algorithms identify rules don play golf sunny humidity 
rules draft september transition matrix transition diagram simple markov model boolean valued true false combined decision trees shown 
diamond internal node tree represents decision point oval leaf node outcome determination play golf 
case golf played sunny humidity raining 
probabilistic models probabilistic algorithms baum welch algorithm build probabilistic models :10.1.1.131.2084
typically robust face noise rule learners stochastic models nearly concise rules need training data 
shows state transition matrix example hidden markov model toolkit model htk 
row represents state model column probability moving current state state 
second column row means transition draft september state state occurs chance 
row mean transition state state occurs chance 
state start state transitions state final state transitions 
state probabilities going transitions sum 
transition diagram model 
strongly sequential nature model indicated strong diagonal transition matrix linear connectivity transition diagram 
training testing rule learning probabilistic algorithms phase algorithms 
training initialisation algorithm exposed instances builds model rules probabilistic model 
testing algorithm exposed instances assertions 
problems assertions tested independently algorithm know play golf raining confidently reject flawed algorithm suggests 
algorithms tested data trained trivial look algorithms perform 
contrast perform poorly tested fresh data seen training 
problem called fitting overcome selecting algorithms perform best training testing data disjoint 
practice normally achieved partitioning single dataset disjoint training testing sets 
variation called cross validation involves randomly partitioning single dataset partitions testing partition model built remaining partitions 
effectively increasing size testing set technique dramatically lower variance evaluation results 
special case number documents dataset called leave september cross validation optimal testing approach small datasets 
involves building models inefficient large values models particularly probabilistic models built part training process initialisation part re estimation part 
baum welch algorithm performs best data initialisation data re estimation disjoint 
supervised unsupervised learning supervised learning learning goals pre determined 
goals normally set classes play golf versus don play golf instance falls 
golf example assumed priori goal decide days play golf core task find express pertinent features days golf played versus 
typical supervised learning tasks involve indicating hand instance dataset class instance required evaluate algorithm check instances algorithmically placed correct class 
unsupervised learning learning goals pre determined 
example page involved classifying customers homogeneous groups customer profile products purchased example number groups properties group members shared predetermined 
lack pre determined goals evaluation unsupervised learning particularly difficult 
hybrid learning occurs goals pre determined goals pre determined instances 
example baum welch algorithm voice recognition 
example models initialised segments voice transitions marked draft september 

id previous previous current linear sequence sequence relation manually slow labour intensive task iteratively refined segments order transitions known example voice training learn document operations microsoft word microsoft xp 
time series ordered data data mining performed time series sequentially ordered data simple cases classical statistical modelling linear regression performs better 
algorithms expect sequential data algorithms lack concept sequence data segmented 
sequence segmented relation shown 
segmentation suitable estimate sequence instances side 
relational model order rows order columns irrelevant ordering lost implicit actual data 
data mining toolkit provides tools shuffle rows columns avoid inadvertent exploitation data 
september ii iii chinese ii iii japanese examples segmentation ambiguity east asian languages sequence conversion multiple rows identical duplicates removed unique field added 
unique field counter leftmost column unique random value avoids encoding order 
choice granularity scope segmentation sampling known typically extra algorithmic design choice system builder 
text mining text mining subset data mining data mining applied written natural language text 
written natural language text widely available rich structure full interesting facts making suitable target data mining 
task text mining chinese text segmentation problem task segmenting stream chinese characters words 
task step chinese information processing systems chinese normally written explicit word delimiters 
task challenging fact line delimiters may occur including letters word digits number 
unfortunately task harder appears chinese text ambiguous 
text shown taken segmented shown ii shown iii meaning new zealand flowers draft september fresh respectively 
similarly japanese title shown taken segmented shown ii shown iii meaning president business general manager president subsidiary business proper name general manager 
sequences nouns identical point view part speech system particularly ambiguous situation 
structural ambiguity confined asian languages 
widely circulated joke featuring sentence segmentation ambiguity english dear john want man knows love 
generous kind thoughtful 
people admit useless inferior 
men 

feelings whatsoever re apart 
forever happy 
dear john want man knows love generous kind thoughtful people 
admit useless inferior 
men 
feelings whatsoever 
re apart forever happy 

entire class english expression double exploits ambiguity meaning 
ambiguity resolved context style genre piece text 
sentence possible meanings meaning appears script appears reuters dispatch 
forms text ambiguity resolution possible known example lewis carroll poem 
draft september ambiguity resolution context example known artificial intelligence common sense reasoning 
known difficult computers resolve ambiguity difficulty lying wide range world knowledge subtle reasoning humans solve class problems 
partly reduce need ambiguity resolution overwhelming majority text mining performed collections text similar style genre 
uniformity linguistic style highlights patterns structures text uniformity genre ensures patterns meanings 
types text mining computation consideration natural language documents focus attention need standard test corpus identified 
text hypertext systems widespread large volumes text systems widely 
simple kinds data concerning text calculating statistics document lengths sentence lengths forth 
built simple statistics complex calculations numeric heuristics documents finding vocabulary size reading age 
data traditional libraries long time incorporated infrastructure modern digital libraries calculating usually considered text mining simple straight forward algorithm available 
approaches extracting complex data text traditional data mining template filling draws heavily traditional data mining text augmentation 
draws heavily fields voice recognition draft september documents constellation attributes data mining relation positives relation instances instance generation data mining segmented text statistical modelling 
data mining segmented text data mining segmented text converts text relation see performs conventional data mining relation 
conversion relation involves just immediately adjacent words entire constellation word properties position text may include offsets parts speech capitalisation punctuation hyphenation 
shows way documents converted relation instances constellation associated attributes conventional machine learning run find positive instances 
second table smaller data mining algorithm run properties discarded 
template filling example template filling shown template slots filled snippets text symbols 
snippet contains semantically atomic substring original item typically noun verb phrase 
templates normally handcrafted filled converted relational rows allow additional data cleaning conventional database draft september documents template filling filled template relational table template filling action 
tools 
template filling differs text mining evaluation quality quality relation performed context surrounding text context relation 
template filling data mining referred information extraction 
template filling flexible include non local pointers thesauri glossaries indexes proper nouns part speech markers great deal domain specific ad hoc information 
successful extracting wide range facts text ranging recovering requirements job advertisements finding names locations news articles 
generalised template filling systems 
text augmentation data mining segmented text template filling result relation separated text 
alternative approach separating inferred knowledge text text augmentation inferred knowledge annotate text shown 
widely form automated text augmentation part speech tagging 
part speech tagging attempts determine grammatical syntactical role played word sentence 
problem old century september documents augmented documents tag insertion text augmentation operation concerned grammar determining role individual words sentences 
part speech tagging widely preprocessing step template filling text mining allowing reasoning classes words 
algorithms text augmentation discussed chapter 
standardisation representing augmented text xml currently underway lead architecture tools linguistic analysis systems atlas 
standardisation includes content independent method specifying regions anchors linear linguistic signals query language regions anchors 
similar greater implemented functionality done linguistic data consortium 
insufficiently developed began 
chinese english text segmentation examples seen earlier posed text augmentation problems 
text augmentation limited segmentation problems covers wide variety metadata 
metadata metadata means set data describes gives data data 
usually granularity document catalogue entry book title author data webpage metadata character level cover www nist gov speech atlas www ldc upenn edu draft september granularity relevant metadata document collection scope purpose coverage copyright maintenance status maintainer contact details document author title date publication subject classification section topics cross sentence semantic meanings word part speech glossary links dictionary links details reading direction details character character encoding table metadata different granularities metadata type classification segmentation applicative test schema segmentation linguistic units metadata adjacent units metadata merged loss information 
root tag child tag 
classification linguistic units metadata adjacent units metadata merged loss 
root tag immediate children 
entity linguistic units metadata adjacent units metadata merged loss 
root tag descendant tags 
table classes metadata entire collections documents table 
metadata implementations metadata stored document level may apply collection section character level level majority processing storage retrieval transmission operations take place 
thesis introduces new taxonomy metadata fine granularities metadata segmentation metadata classification metadata entity metadata table 
classes metadata involves classification segmentation shown 
entity metadata combination classification segmentation metadata 
segmentation metadata indicates boundaries fall schema consists tags root tag contains entire document child tag shown 
child tag instance starts boundary finishes boundary 
draft september document word document dt nnp vbd jj 
cd issue name location email source date money phone fax url organisation schema structures segmentation classification problems 
chinese text segmentation problem 
part speech tagging classification problem 
computists classification problem 
classification metadata places document word character class 
schema consists root tag child tags shown 
examples include document language identification part speech tagging subject classification reading direction 
entity metadata segments classifies says bounded part document property 
schema entity metadata consists root tag tree structure descendant tags shown features diagram discussed section 
assigning metadata hand arduous task done document collection level done lower level challenging non trivial collections 
possible build computer systems assign metadata 
technique proven useful past tag insertion statistical models 
draft september title editor address publisher date month bibliography author journal jr year name jr name schema structure bibliography entity extraction problem 
tag insertion general tag insertion problem stated sequence symbols 
set tags 
tags inserted sequence tags express metadata implicit sequence 
representation coincides neatly xml standard uses nested tags encode particular kinds data 
example bibliography name author represented author tag contains single name tag composed tag tag containing names author respectively 
sequences assumed bound constraints 
half tags opening tags half closing tags 
opened tag may closed 
draft september quick brown fox jumps 
lazy dog 
quick brown fox jumps lazy dog 
quick brown fox jumps 
lazy dog 
quick brown fox jumps lazy dog 
tagging line sentence boundaries 
opening tag separated corresponding closing tag data point underlying sequence 
constraint restatement constraint xml interchange format 
strict better known wellformedness constraint root document tree multiple children 
key practical difference constraints fragment subtree formed xml document balanced entire document formed 
allows independent constraint checking processing xml fragments 
constraint xml representation rule proliferation arbitrary numbers empty tags 
shows overlapping tag problem 
text logical structure physical structure 
draft september quick brown fox jumps 
lazy dog 
quick brown fox jumps 
lazy dog 
quick brown fox type continued jumps lazy dog 
id quick brown fox id jumps lazy dog 
tagging overlapping structures draft september general logical physical structures document distinct trees 
xml constraint prevents straight forward tagging sentence tag ends open line tag 
ways tagging situation meet constraint shown 
inserts empty tag pairs relies post processing ranges explicit 
equivalent somewhat xml allows empty tags pairs merged style atlas project 
second shown trees primary attributes post processing second tree accessible 
style similar way html tags implicit close tags operate 
third shown identify tag fragments explicitly state relationship tag 
difficulties tagging overlapping structures standard ways overcoming described detail 
xml provide concur feature sgml allows parallel parsing documents separate parse trees structure multiple data schemas 
key abstraction tag insertion shares natural language processing approaches linearisation language 
written language wide range cultures laid rectangular regions read left right top bottom bottom top right left digitised language written spoken linear detriment secondary rectangular structure 
example limerick shown shown twice secondary rectangular structure 
second form limerick rhymes cadence lose explicit rectangular structure harder recognise 
data dealt thesis strong secondary rectangular structure 
draft september limerick packs anatomical space quite economical 
ones seen seldom clean clean ones seldom 
limerick packs anatomical space quite economical 
ones seen seldom clean clean ones seldom 
limerick shown secondary structure segmentation tag insertion segmentation problems stated sequence symbols 
tag pairs symbols instance tag 
segmentation problems involve finding internal boundaries documents 
boundaries linguistic boundaries word boundaries sentence boundaries semantic boundaries topic boundaries boundaries index bibliography entries 
segmentation problems include finding line page boundaries considered detail physical linguistic structures text text secondary rectangular structure 
segmentation metadata destroyed tag merging 
adjacent tags merged segmentation information lost information lies solely tags start 
classification tag insertion classification problems involves creating pair tags class stated sequence symbols 
set draft september classes 
class symbol placed 
classification metadata immune tag merging 
adjacent tags class merged knowledge lost extracted information lies solely symbols tag 
muc named entity problems classification problems wrapper induction problem 
examples include proper names news press articles part speech tagging :10.1.1.41.4658
classification problems 
schema single root node representing document classes node directly connected root node 
entity extraction entity extraction tag insertion problem stated sequence symbols 
set tags 
tags inserted sequence tags express metadata implicit 
superset segmentation classification entity extraction finds bounded sections text belong particular class aims mark semantic facts text 
adjacent tags merged information may lost information lies symbols class tag individual tags start finish 
examples entities include author names article titles conference names bibliography entries 
shows schema structure bibliography corpus current research 
part speech tagging unsegmented entity extraction problem 
attributes important feature problem statements involve inserting tags tag attributes 
attributes name value pairs attached tag associating metadata tag 
attributes syntactic sugar xml draft september document attributes transformed attributes back lossless fashion 
example tag verb jump easily transformed jump transforms lead combinatorial explosion tags large number attributes attributes contain numeric data 
draft september chapter models text hidden markov models ppm models common models text text augmentation algorithms provide brief review modelling techniques discussion related issues 
computer science models systems built generate streams data 
models built finite state machines fsms 
fsms consist finite number states 
state associated probability density function pdf state pdf generating predicting symbol alphabet symbols 
fsm set start states set states 
stream data generated fsm starting start states moving succession states current state pdf determine state reaches state 
markov models stochastic statistical models originally created study brownian motion apparently random jerky movement small rigid particles liquid suspension caused short term non uniformities number momentum molecules liquid hitting particles 
shows particle moving dimensions 
short term nature non uniformities causing brownian motion viscosity fluids low mass particle inertia irrelevant shown experimentally movement particle depends current position previous positions previous movements positions 
concept come called markov assumption value state draft september particle moving influenced value state directly preceded 
terms random walk walk describe models behave 
markov assumption useful gives bound context system needs modelled 
markov models produce pdfs estimate likelihood possible value state 
markov models finite state machines fsms 
model defines set states set transitions states 
transition probabilistic allowable probabilistic action associated 
need transitions pair states equivalently transitions may zero probability 
action emission symbol coordinate 
models sequences nearly linear shown 
hidden markov models unfortunately interesting things directly measurable 
consider example case particle observed shadows casts shown 
shadows movements particles dimensional movement projected dimensional surface 
particle observe position shadow cast light source dimensions position shadow cast light source 
draft september light source light source flat surface shadow shadow particle observed hidden markov models model hidden sequence observable sequence 
relationship hidden observable sequences typically case modelled statistically 
notions observable hidden similar plato notions shadows forms allegory cave 
allegory claims perceived reality shadow thrown world experience true reality inaccessible direct sensory experience 
forms true reality contain essence class object experienced incompletely perceived reality 
example singular dog form true reality dogs encounter perceived reality shadows true dog hint true essence 
philosophy seen identification documentation forms 
analogy particularly strong modelling parts speech sentences entities strongly defined semantic meaning independent myriad possible representations observable sequence 
draft september problem observable sequence hidden sequence observable alphabet size hidden alphabet size type ref 
brownian motion infinite infinite chinese word segmentation characters words large segmentation english sentence segmentation words sentences large segmentation part speech tagging words word classes large classification name finding words names large large classification rain forecasting satellite weather observations precipitation large classification phone identification digitised audio waveforms phones large large entity extraction handwriting recognition directed pen strokes characters large large entity extraction finding protein binding sites nucleotides binding sites small entity extraction finding functional groups amino acids functional groups small entity extraction table hidden observable sequences variety problems tackled hidden markov models draft september applications hidden markov models table shows wide variety uses hidden markov models observable hidden sequences alphabet sizes sequences kind metadata extracted see page 
observable alphabet range possible observations hidden alphabet range possible hidden states 
handwriting recognition problem converted series marks tablet sequence characters represent 
chinese english text segmentation problems discussed finding names 
rain forecasting context taken task predicting location relevant satellite images 
classes problems computational biology hmms applied finding protein binding sites nucleotide sequences finding points nucleotide sequences transcription starts stops finding parts nucleotide sequences markers proteins built finding functional groups amino acid sequences :10.1.1.148.3886
summary hmm computational biology 
higher order models higher order markov models involve relaxation markov assumption allowing multiple states taken account values state influenced values states directly preceded 
markov model order isomorphic family markov models order 

transformation straightforward comes cost multiplying number states observable alphabet size lower model 
transformations allow high order models software tools htk designed order models 
computational linguistics uses terms gram uni gram bi gram september gram order meaning symbols equal probability uni gram symbol probability frequency training data bi gram symbol probability frequency training data previous symbol tri gram symbol probability frequency training data previous symbols quad gram symbol probability frequency training data previous symbols 
gram order symbol probability frequency training data previous symbols gram order symbol probability frequency training data previous symbols table gram models models order gram denote order models information sciences refer order models 
table shows relationship terminologies 
markov models represented array shown grow large high order models size alphabet observable symbols 
training data need train models grows linearly size meaning high order models require large amounts training data 
obtaining training data difficult 
large amounts training data state transition high order model visited initialisation 
leaving transitions zero probability means model may generate zero probabilities fail transition travelled testing 
problem called zero frequency problem solved smoothing transitions taken small non zero probability probability calculated similar transitions typically transitions lower order model 
markov model systems shrinkage smoothers escape methods ppm models 
studies effectiveness draft september different smoothing strategies 
advantage escape methods implemented current shrinkage escape methods may changed model built allowing run time selection escape method 
searching models built models find sequence hidden states sequence observed states 
done search tree transition labelled entropy markov model node sum probabilities root node 
entropy inversely related likelihood sequence corresponds leaf node lowest entropy 
root leaf leaves leaf leaves leaves result algorithm complete search algorithm exhaustive complete search sequence involves search space deep sequence long 
algorithm shown algorithm 
interesting sequences search space computationally infeasible exists algorithm called viterbi search 
search guaranteed find sequence provided model determines entropy node bounded local knowledge global knowledge required exhaustive search 
fortunately markov models high order markov draft september models meet criterion 
length sequence modelled local knowledge called lookahead 
root leaf leaves leaf leaves leaves result algorithm viterbi search algorithm viterbi search beam search shown algorithm moving incrementally portion complete search space pruning search space increment lines 
details search spaces chapter 
root leaf leaves leaf leaves leaves result algorithm teahan search algorithm teahan algorithm shown algorithm viterbi inspired algorithm effective 
search fixed distance ahead search space increment expands lowest entropy nodes level tree line 
common problems limited amounts data correlated hidden observable sequences available large amounts data draft september observable sequences available 
algorithm utilise un correlated observable sequences developed baum known baum welch algorithm :10.1.1.131.2084
algorithm algorithm similar viterbi search algorithm addition step line updates model branch 
root leaf leaves leaf leaves leaves result algorithm baum welch algorithm algorithm specialisation expectation maximisation em widely machine learning statistics 
mclachlan krishnan contains description em relationship baum welch algorithm contains mathematical view 
baum welch algorithm primary training mechanism information extraction projects learning transition probabilities model structure :10.1.1.37.3740
current baum welch algorithm learning transition probabilities model structure 
variant baum welch algorithm known batch mode baum welch algorithm performed tag insertion model re estimation closely linked manner entire document group documents tags inserted update model 
approach precludes possibility intra document learning lowering entropy sequence symbols tag seen 
draft september research field markov modelling viterbi search performed context voice recognition observable sequence sequence discretised representation continuous signal :10.1.1.131.2084
symbols discretised representation ordered possible say db db db 
observable sequence text modelling characters ordered meaningful manner research applied text 
baum welch algorithm normally training 
sequence modelled changing slowly time insufficient training data sufficiently characterise sequence testing 
prediction partial matching prediction partial matching ppm world class incremental compression algorithm variant statistical model thesis 
variant text augmentation 
ppm model order examines previous characters calculate probability density function character 
calculate function ppm keeps record sequences characters seen character followed 
sequence characters seen seen ppm escapes back sequences characters 
match ppm escapes back sequences eventually escaping back order characters observable alphabet probability 
ppm model keeps sequences characters suffix tree node labelled number times sequence seen 
suffix tree converted single state markov model order 
suffix tree efficient representation sparse model possible draft september states observed unused branches expanded 
equivalent markov model array leaves seen training appearing small probabilities 
ppm model deterministic subsequential transition output symbol 
regard differs done mccallum built non deterministic hmms similar tasks seen non deterministic condition random fields 
ppm models may far removed way humans deal natural language text story reveals may closer way humans deal natural language text linguistic information working greek text oxford university press 
announced mistake text 
couldn read greek colleagues superiors dismissed claim 
man insisted 
editor came compositing room 
dismissed idea checking closely error 
asked knew said hand picking letters greek texts professional life sure physical move pick letters order 
implies built implicit model characters followed characters sufficient confidence model risk peers 
ppm model store probabilities counts occurrences 
counts converted probabilities dynamically escape method allocates probability seen unseen symbols observable alphabet 
number different escape methods including 
escape method thesis stated 
draft september representations ppm model 
draft september shows representations adaptive order model built string 
represents start string 
suffix tree representation 
tree complete example node marked leading string 
contains sub string ac 
shows occurrence tables order order order correspond root node suffix tree row suffix tree leaves suffix tree respectively 
non zero entry order table corresponds leaf tree 
zero entry order table corresponds leaf missing tree 
shows markov models order order order 
structure occurrence tables occurrences converted probabilities escape method count order tables divided total counts table get probability 
non zero count order table divided total counts row plus 
probability corresponding extra plus count distributed zero counts 
page seen sections text marked pair xml tags type xml tag corresponding hidden state having separate model built 
observable sequence tags mapped single character symbols 
string mapped different symbol corresponding pair tags seen earlier indicating start string entire string xml refers document element entire string represented 
distinct ppm model built tag case models built string shown figures similar structure 
model built sub strings ab ba ba ab 
model built draft september model built draft september model built draft september expansion step viterbi search 
sub strings cb bc seen model transition occurs model model 
seen model transition occurs model previous model case model 
pair models viterbi search find sequence tags sequence 
step shown look ahead 
symbols observed sequence algorithm calculates probability transition hidden state right branch node probability transition hidden state left branch node 
probability left branch taken right hand tables states model states model 
probability right branch product probabilities transition model second probability seeing observed character 
possibly lead leaf current leaf non leaf node probability smaller leaf need expanded 
reason nodes right side draft september search space expanded 
expansion step shown pruning step 
node node pruned search tree children 
node leaf highest probability descendant pruned 
discussed section 
viterbi search says demonstration example look ahead insufficient guarantee optimal tagging look ahead sum order model longest tag length 
short look ahead clarity 
linguistic models linguistic models text assumptions particular school linguistics 
assumptions linguistic models usually stronger markov assumption typically assumptions semantics 
additional assumptions allow interpretation documents light prior knowledge terms kinds structures contents knowledge bases dictionaries roget thesaurus multilingual agricultural thesaurus 
prior knowledge gives tremendous leverage terms accuracy terms details may modelled leverage applied texts language genre topics prior knowledge applies 
enable cem collections possible truly diverse digital libraries uses solely markov models linguistic models 
unicode character classes assumptions symbol punctuation letter arguably linguistic assumptions tokenisation alphabet reduction heuristics 
techniques optional system character classes equally applicable known september guages scripts 
granularity models text mining systems model text words 
prior segmentation words leads separate problems 
contexts clear word 
english areas ambiguity contractions abbreviations example joined words example real time variously realtime real time real time 
appear great deal research effects different word definitions 

words seen testing production seen training raise unknown word problem 
problem zero frequency problem see page 
system evaluation contexts problem solved leaking information testing set training set form perfect lexicon containing word system 
production systems approach possible constraint placed vocabulary system called controlled vocabularies unbounded number words may seen life system 
approaches solving unknown word problem include merging unseen words single class treating unknown words works surprisingly news articles unknown words proper nouns escaping back character level model requiring redundant models word level character level 
draft september modelling text sequence characters 
glance problems discussed affect character models similar problems arise different level granularity 

unicode allows compound characters characters built base character modifiers 
characters languages including english mandarin representable compose characters system see input handling problematic 

unicode character set bounded sufficiently large tens thousands characters characters hyper geometrically distributed expected natural languages rare circumstances system see instance character 
character set expanding characters added theory production system see characters undefined system built 
problems normal usage character system word system may see problems particularly unknown word problem 
draft september chapter corpora chapter introduce corpora thesis describe nature problems posed corpora previous solving problems similar corpora 
information retrieval paradigm collection documents called corpus assumed commonality documents source covering topic representative sample larger population documents 
building corpora especially rich metadata documents expensive timing consuming 
number methods acquiring corpora research including 
manual determination metadata documents 
non trivial corpora extremely expensive terms human effort generally resulting small collections 

manual determination metadata sample documents extrapolated remaining documents 
sample large gives results 
sample size increases cost marking documents advantage previous method lost 

pooling metadata assignments peer systems 
system great effect trec conferences works provided systems diverse reflects notion collective understanding documents metadata 
draft september 
acquisition documents creators users metadata associated 
researcher point view best way acquire corpora metadata free effort invested third party assign relevance data documents implicit assumption documents metadata way meaningful research task hand 
research community corpora serve pools data exploratory research benchmarks comparative research thesis uses purposes 
corpora computists corpus bibliography corpus chinese text segmentation corpus reuters corpus 
samples appendix 
computists corpus computists corpus issues magazine called computists converted ascii text xml 
issues approximately words length consists number short articles usually followed job openings 
previous workers marked features name location organisation email source date money phone fax url hand corrections results statistical modelling interface smi system renamed text mining toolkit tmt 
receiving data converted xml format smi formed xml number systemic errors corrected 
shows lines corpus appears original text 
shows text teahan bray wen tags added phone number url source date 
unfortunately insertion url email address shown tags done automatically inserted extra url detection failed url line wrapped 
text contains draft september 
proc htm 
cbd jul 

web fie com fed afr wri proc htm 
cbd jul 

lt web fie com fed afr wri proc htm gt 
cbd jul 
corrections computists original text text smi experiments text thesis un escaped shown characters non balanced xml 
shows shows text thesis 
corpus number endemic ambiguity issues mailing list names listed sources derived mailing list creation mailing list announced words marked coincidentally 
example discussion computers ibm sun computers sun microsystems ibm sun microsystems marked organisations expected sun marked organisation pc refer computers organisation names particularly apple marked intermittently place names newton ma wash dc product names apple newton coined personal names 
similarly source names washington post organisational names washington coined place names 
taken account errors previously reported 
number corrections corpus attempt resolve draft september issue name location email source date money phone fax url organisation schema structure computists 

passes corpus marking organisations lesser extent sources marked marked 
corpus thesis section 
best knowledge material public domain 
inserting features computists corpus non hierarchical entity extraction problem 
shows schema structure problem 
previous approaches computists corpus number studies tag insertion word level approaches similar described 
muc named entity problems muc conferences strong correspondences name location organisation source date money tags 
muc information extraction systems problems variety centred template filling markov models rule learning 
bibliography corpus bibliography corpus created specifically thesis bibliography records known metadata 
collection publicly available bibliographic databases maintained expanded number years 
samples bibliographic entries taken sources collection split ira uka de bibliography index html draft september bibtex bibtex sty sty txt bbl ps bbl ps txt xml bib merge data flow diagram creating bibliography collection bibliographies entries formatted text formatting systems standard bibliography styles alpha plain siam different page layout techniques article book report avoid secondary rectangular effects see section 
addition metadata tags bibliographies changed layout entries avoid bibliography processed twice standard style file modified style file inserted metadata tags parts entries 
merged formatting layout taken standard style metadata taken modified style 
process shown upper half showing processing bibliography bib unmodified style file sty produce bibliography bbl processing laid bibliography postscript ps document xand processing postscript document text file txt ps txt 
lower half shows processing bibliography modified style file insert escaped xml tags 
resulting text files merged xml document whitespace punctuation text derived unmodified style file un escaping escaped xml tags text derived modified style file 
resulting bibliographies processed xml xsl style preserve whitespace 
draft september unfortunately bibliographies successfully converted failure bibliography led entire bibliography excluded corpus 
failures due non ascii alphabetic mathematical characters resulting consistent bias non english publications authors 
unfortunate handling non ascii characters tools obscure resolving problems taken considerable effort 
approximately documents discarded manner 
researchers thrown data higher rate 
large collections postscript documents stand benefit tools developed corpus including technical report collection new zealand digital library arxiv 
corpus public domain 
modified style files available licence original style files 
corpus contains xml tag metadata type format tags decompose group names 
structure schema shown 
tags level indicate bibliographies marked certain bibliography styles document styles respectively 
combinations creating corpus 
tags level correspond tags different types documents referenced 
tags shown thesis 
shows tags corpus thesis note particular tags levels missing 
variant schema structure shown experiments state tying see sections variant distinguished fact node schema zero parents 
draft september bibliography 
name article book techreport manual author title journal editor address publisher date abbrev alpha siam acm plain year month jr schema bibliography corpus tags 
draft september 
name title editor address publisher date year month jr bibliography author journal schema bibliography corpus tags thesis 
title editor address publisher date month bibliography author journal jr year name jr name schema bibliography corpus tag tying 
draft september previous approaches bray showed small sample hierarchical tagging personal names parts hindered identification names hierarchical tagging email addresses username host parts aided identification email addresses 
failure hierarchical tagging names appears part due small number names 
wen tags early version corpus achieve measure 
time corpus doubled size systematic errors corrected 
freitag mccallum report similar nonhierarchical corpus hand crafted automatically shrunk hidden markov models giving results :10.1.1.26.3665
segmentation corpus segmentation corpus derived standard segmentation corpus contains pre segmented words represented big coding scheme 
corpus converted big encoding wen kindly lent author data 
corpus converted encoding unicode 
inserting word tags whitespace punctuation removed text split documents 
xml output ascii unicode escapes ensure correct transmission systems 
sentence tags regular punctuation appears phrase sentence 
resulting corpus character word looks 
corpus includes western terms example proper nouns currency symbols 
thorough review chinese text segmentation teahan wen 
author thesis reads speaks draft september document word schema structure chinese text segmentation problem 
chinese unfortunately unable give detailed analysis 
segmentation corpus appears suffer overly optimistic segmentation described wu fung 
inserting word tags segmentation corpus segmentation problem 
shows schema structure problem 
previous approaches wide variety approaches segment text 
early systems simple lookup tables works surprisingly text novel characters seen training 
systems gram methods specialised handling novel characters 
differences approach current highlighted handling known character pair novel characters 

current unknown characters modelled escaping back order model known character seen context seen order model 
synthetic novel character enable probability encountering sequence 

estimated 



escaping back order model 
chinese text segmentation systems gram models markov models solutions broadly similar part speech discussed earlier 
specific results section 
draft september document dt nnp vbd jj cd schema structure reuters corpus 
reuters corpus reuters corpus collection news articles taken reuters news wire referred reuters reuters corpus volume english language 
articles range paragraph summaries financial information depth articles political literary topics 
corpus widely studied number purposes including text categorisation clustering information extraction part speech tagging :10.1.1.26.3665
corpus prepared articles full reuters corpus removing document level metadata title author topic copyright information passing brill tagger widely part speech tagger tags word label indicates role plays speech 
taggers notion constitutes word unusual don regarded words dollar yen word tagger box accepted practice :10.1.1.26.3665
duplicates removed duplicates near duplicates occur collections documents containing urls confused tagger removed 
complete explanation meanings tags contained :10.1.1.14.9706
text reuters corpus copyright reuters redistribution 
copies corpus reuters 
inserting part speech tags reuters corpus classification problem 
shows schema structure problem 
draft september previous approaches considerable done part speech tagging problem regarded solved problem 
xerox tagger uses hidden markov models viterbi search achieves results handles unseen words novel contexts poorly 
brill tagger trains rule tagger learns transformations errors rule tagger 
rules allow higher level reasoning word suffix prefixes finding bast tags word 
applying rules fast system runs quickly 
xml handling corpora share features incidental second carefully planned 
corpora 
xml involves normalisation whitespace 
xml tools ignore whitespace normally problem 
cem ignore whitespace treats whitespace characters characters 
combination lead serious trouble documents mixed particularly training testing data differ 
corpora xml attributes 
attributes name value pairs attached xml start tag denote metadata related branch tree 
ensures xml fits requirement tags attributes see page 
draft september chapter seen corpora described nature problems posed corpora previous solving problems problems 
chapter examine determine solution solves problem theses domains 
draft september chapter evaluation techniques ultimate test computer system terms interactions users system correctly 
errors minor catastrophic 
fast 
easy 
users 
questions hard phrase terms allow answers compared systems versions system software packages time face changing requirements user expectations groups users operating environments 
questions hard ask sub systems provide subset functionality required full system 
features performance widely comparing systems correctness efficiency 
chapter examines applied text augmentation 
approaches measuring correctness examined come respectively fields information retrieval string processing machine learning compression 
recall precision information retrieval paradigm assumes query single operation retrieves set items relevant query 
evaluation question item relevant returned 
answer question puts item distinct classes true positive relevant draft september retrieved true negative relevant retrieved false positive relevant retrieved false negative relevant retrieved 
accumulating counts classes large number independent experiments allows calculation higher level measures 
recall proportion relevant items retrieved recall number relevant items retrieved total number items collection true positives true positives false negatives precision proportion retrieved items relevant recision number relevant items retrieved total number items retrieved true positives true positives false positives recall precision represent trade 
system return items high recall low precision items low recall high precision expressed harmonic mean measure recall precision recall precision number false negatives unknown retrieving documents world wide web exact size unknown large 
number false negatives known reliably estimated measure called fallout measure result result negated query number non relevant items retrieved total number non items collection false positives false positives true negatives fallout measures effectively non relevant items query results 
fallout rarely sensitive size collection addition clearly irrelevant items collection 
recall precision combination measure primary means evaluating correctness information retrieval systems definition draft september constitutes document varies type text augmentation problem 
segmentation segmentation problems evaluation question segment symbol segment 
recall precision measures evaluating segmentation problems operate binary distinction 
recall precision standard methodology measuring correctness fields chinese text segmentation japanese text segmentation widely studied segmentation problems 
classification classification problems evaluation question class predicted symbol correct symbols characters words sentences documents placed classes recall precision standard methodology measuring correctness fields part speech tagging genre classification probably widely studied textual classification problems 
short quote hamlet part speech tags shows short quote hamlet quote marked tags lancaster oslo bergen part speech corpus 
teahan example taken word approach uses word evaluation mechanisms words sample draft september correctly tagged giving true positives 
character approaches see characters words characters including spaces correctly tagged giving true positives 
solution problem evaluate output character system word evaluation 
works mistakes mis classification entire word fails part word non word character mis classified 
similar problems evaluating optical character recognition ocr word level word boundaries incorrectly identified 
core problem character approaches expressive wrong ways represented conventional word approaches 
reverse case output word system compared character system character level 
expressiveness character approaches definitely advantages corpora 
example dates computists corpora section expressed single word form jan word approaches see single word customised word boundaries heuristics unable better identifying date jan 
character approaches capable breaking date component parts jan 
difference expressiveness applies types text augmentation problem standard measurement technique word obvious classification problems part speech tagging 
entity extraction measuring entity extraction information retrieval problem challenging 
basic classes accumulated successive independent trials xml constraint page introduces inter dependencies trials 
draft september smolensky fox king lewis computer aided reasoned discourse 
smolensky fox king lewis computer aided reasoned discourse 
smolensky fox king lewis computer aided reasoned discourse 
inter dependencies small entity extraction problem shows inter dependencies small entity extraction problem 
untagged input text shown 
task insert tags text shown 
shows error boundary names inserted incorrect place tag smolensky fox false positive 
independence criteria broken seeing false positive just preclude possibility seeing tag smolensky precludes possibility seeing tag fox possibility smolensky fox smolensky fox names precluded data segmented relation processing see page 
segmented results merged back xml tags names included 
breaking independence criteria matters unclear 
certainly means recall precision results entity extraction problems way different segmentation classification results directly draft september comparable 
recall precision primary means comparison trec text retrieval conference series conferences primary focus entity extraction 
muc message understand conferences conferences recall precision primary measures correctness 
edit distance related information retrieval metrics edit distance terms individual tags tag pairs 
false negatives inserts false positives deletes counted summed get edit distance 
edit distance standard technique string processing field measure spelling correction transposes common due mechanics typing ocr swaps common due mis recognition character 
fields measure edit distance data text augmentation edit distance combined data metadata expectation errors closely linked metadata 
edit distance solely concerned mistakes text augmentation true negatives true positives impact edit distance 
edit distance explicitly recognises sequential nature text true positives ignored independence problems discussed relation recall precision occur edit distance calculation 
edit distances current normalised document length give edits character 
correctness kinds metadata text augmentation measured edit distance 
teahan uses edit distance evaluate text augmentation nahm uses edit distance input segmented text mining system 
draft september confusion matrices recall precision assume underlying binary classification confusion matrices tool evaluating class classification tasks widely machine learning evaluating tasks 
confusion matrix classification problem classes 



matrix square row column class 
column row number symbols classified class classified class correct classification indicated leading diagonal matrix 
non zero numbers leading diagonal indicate misclassification symmetry diagonal 
non zero numbers indicate symbols class mistaken symbols class symbols class mistaken symbols class ability highlight confusion tags confusion matrix excellent tool fine tuning tagsets finding markup errors 
example bray confusion matrix find errors strong correlation name tags place tags computists corpora 
confusion matrices conventionally normalised converting rows percentages 
confusion matrix classes synonymous xml tags domains considered thesis 
class xml root tag usually document issue thought background text corpora low tag density 
draft september segmentation confusion matrices segmentation problems represent degenerate case classes matrix contains basic measures information retrieval paradigm called contingency table true positives false positives false negatives true negatives reason evaluating segmentation confusion matrix information retrieval metrics produces results information retrieval metrics higher level metrics recall precision built 
classification confusion matrices standard method evaluating classification tasks 
disadvantage somewhat verbose especially problems part speech tagging large number classes 
entity extraction confusion matrices identical independence problems recall precision extract entities text 
confusion matrices assume underlying class classification task entity extraction general form general hierarchical class classification task 
hierarchy depth bounded way possible re define problem possible state hierarchy new class 
solution suffers problems combinatoric explosion leading large sparse matrices normalised leads division zero 
draft september type confusion matrices type confusion matrices new extension confusion matrices suitable application hierarchical class classification tasks 
node hierarchy assigned type class opened class 
type confusion matrix hierarchical classification problem classes 



column row number symbols node class classified node class type confusion matrices similar confusion matrices noted information thrown away 
example sequence 
kraus subrahmanian 
marked 
kraus subrahmanian 

kraus subrahmanian 
author editor confusion apparent sub sequence 
sub sequences kraus erroneous tag immediately enclosing tag 
situation worse dealing classes content classes tag contains single tag 
type confusion matrices applicable tag insertion problems applied classification problem degenerate confusion matrix immediately enclosing tag tag 
applied segmentation problems draft september type confusion matrices degenerate contingency table 
entropy entropy measure widely signal processing error correction compression fields computer science 
inversely related probability 
augmentation text high probability low entropy measured bits character 
types text augmentation measured entropy 
measures correctness entropy measure results predefined answer measures closely set results match model 
effective situations perfect answers unobtainable obtainable great expense 
entropy measures effective measurement accuracy augmentation text model measure entropy independent testing training data 
problem closely related fitting problem machine learning avoided training models separate training data augment text measure entropy 
independently trained model unavailable untrained model adaptive algorithm 
standard methodology measuring strength lossless compression algorithms 
unfortunately entropy measurement conveys little clear knowledge absolute quality augmentation user augmented text unable infer entropy measurement recall precision pair edit distance 
compare relative merit different augmentations text provided model captures pertinent details 
tag insertion viterbi algorithm produces incorrect result entropy measurements determine fault lies draft september model searching algorithm 
result produced tag insertion lower entropy baseline text model flawed seen training data sufficient order attempting linguistically model nonlinguistic features experimental result higher entropy baseline searching algorithm flawed heuristics making assumption hold text 
technique section examine effectiveness alphabet reduction heuristic 
hybrid measures reports text augmentation combination measures report results 
example bray decomposed tag insertion evaluation computists corpus pair operations firstly segmenting characters tokens secondly classifying tokens respective types 
segmentation operation measured terms error count false negatives classification measured confusion matrices 
systems measures expressed terms interaction larger information systems extraction acronyms bibliographies 
efficiency computer programs written wide variety computer languages run wide variety platforms 
efficiency languages platforms varies widely useful compare algorithms independent language platform 
methodology allows time complexity analysis big notation 
function simplified remove constant factors called time complexity analysis defined terms characteristic operation case tag insertion visiting node search space counting draft september times operation performed expressed function parameters input size algorithm 
case tag insertion methodology parameters numbers tags lookahead size input length text prior augmentation 
complexity reflection tagging action complexity underlying intellectual syntactic complexity 
size search space normalised document length give measurement terms search space character 
special cases searching start documents corpora thesis initial final characters documents lower entropy effect normalisation 
constant unbounded positive variables 
algorithms greater referred intractable run non polynomial time conventional computer equipment 
thesis examine efficiency text augmentation tag insertion building models prerequisite activity 
area building models efficiently outside scope thesis 
granularity evaluating systems performance tension evaluating performance fine level granularity course level granularity 
text compression systems evaluated corpora calgary canterbury corpora contain wide variety texts different characteristics 
systems expected perform individual documents corpus taken 
poor performance single document corpus draft september sign system perform real world 
fortunately text mining systems type examined thesis assumption text seen training text seen testing 
sense general purpose system way bzip gzip variety texts encountered testing corpora described chapter chinese text segmentation corpus built pre data distinguishable variation documents 
computists corpus contains documents structure variation subject matter 
bibliography corpus contains relatively homogenous documents exceptions documents generated bibliographies containing publications individual documents generated forum bibliographies containing publications appearing journal conference book series 
non homogenous documents entirely artifact way data prepared insignificant number peer review articles published computer science contain single author source 
reuters corpus contrast contains genuinely heterogenous articles ranging short market report articles columns figures long depth articles political commentary 
reuters corpus evaluated corpus level document level see section corpora evaluated corpus level 
draft september chapter optimisations heuristics tag insertion intractable problem general case tractable variety optimisations heuristics 
optimisations techniques improve efficiency problem solving altering correctness 
heuristics techniques improve efficiency problem solving may potentially reduce correctness 
chapter looks techniques effect search spaces different classes text augmentation 
viterbi optimisation viterbi search algorithm page optimisation complete search algorithm page viterbi proved impact correctness provided lookahead large encoding scheme right properties 
text augmentation problems large maximum possible length tag plus order ppm model plus 
relating search space size maximum length tags inserted means tags require smaller search spaces 
inserting short tags personal names parts speech gains advantage viterbi search large tags tags xhtml contain entirely document text 
shows example viterbi search space small black triangle search space current increment loop algorithm draft september search space full search search space viterbi search viterbi search large search space draft september page large triangle full search space loop algorithm page 
shows initial search space depth pruning search space full search space depth shows second search space depth pruning shows search half way shows completed search 
obvious natural language text meets preconditions viterbi proof 
shows markov model hidden states alphabet symbols 
hidden model models contents matched braces 
hidden model models contents matched parentheses 
columns zeros models indicates transitions possible final state 
aaa gf 
gf 
gf gf gfx aaaa gf gf gf gf gaa set models sequences viterbi search hold 
class difficult sequences single sequence top level markov model model 
model 

shows class sequences problematic respect model parentheses brackets ways match 
repeating chain parentheses brackets extend ambiguity indefinitely symbols seen 
shows string draft september viterbi search yield equally hidden sequences 
floating point operations modern computers means likelihood sequence chosen pseudo random manner 
model may changed prefer changing adjusting probabilities row sum 
solution requires search sees chain pruning search tree start chain 
fortunately situations rare datasets appear contains sequences reported literature 
experience shown practise viterbi search natural language text 
situation exactly kind situation teahan search algorithm performs 
teahan search expands fixed number nodes level search tree quite capable exploring equal entropy branches search tree arbitrary depth long level node branch expanded 
branch higher entropy example raised probably get pruned lowest global entropy lies branch search tree 
best optimisation best optimisation observation candidate augmentation entropy calculated nodes search space higher entropy pruned immediately 
candidate augmentation cheaply probability distribution function steep search space reduced considerably 
consider node entropy node entropy child lower entropy node node need expanded 
draft september argued best optimisation implementation detail true optimisation 
absent previous similar systems teahan statistical modelling interface smi mentioned prior literature 
savings best difficult model depend probability distribution function state model exact sequence symbols seen 
general savings larger sequence lower entropy lower entropy implies branches search tree ultimately correct highest probability leaves 
cem implementation finds best candidate calculating entropy left leaf leaf reachable inserting tags 
automatic tokenisation heuristic automatic tokenisation heuristic observation problems classes characters tag occurs 
example computists bibliography corpora tag occurs pair lower case letters pair spaces 
tag seen situation training sufficient amount training data seen reasonable consider inserting tags positions testing 
assumption may prove false automatic tokenisation heuristic optimisation 
saving search space depends structure text text uniform words letters starting capital letter separated space 
abcd 
automatic tokenisation meant search consider inserting tags pairs lower case letters nodes search space need expanded 
draft september approximation assumed chapter 
types contraction abbreviation direct impact automatic tokenisation 
example string john anthony smith may search space smith differ markedly length 
cem implementation keeps table possible pairs unicode character classes counts tags seen pair 
augmentation node search tree checked see threshold number tags seen current pair character classes considering expand search tree 
common threshold values include 
unicode character classes set classes unicode characters divided 
common classes seen corpora thesis lowercase letter uppercase letter space separator line separator decimal digit number various classes punctuation 
classes particularly convenient java language uses unicode 
ansi functions isspace certainly performed role 
proposals sophisticated character level metadata systems unicode considered 
unicode character class private class reserved software developers users need special set characters applications 
characters reserved private defined interpretable semantics private agreement 
cem uses represent tags character level models 
alphabet reduction alphabet reduction heuristic character classes automatic tokenisation 
bibliography corpus repeating patterns punctuation september surrounding names bibliographies noticed 
names commonly unique strings remain problem ppm model typically sees characters context 
alphabet reduction merges class characters single character model 
example merging upper case letters lower case letters means john smith jill jones yong xiong merge aaaa aaaaa aaa 
throwing away information characters produces significantly worse model point view names 
alphabet reduction reduces size alphabet drastically memory training data needed produce high order models 
empirically alphabet reduction raised maximum order model see 
method related finding acronyms patterns case generating candidate acronyms techniques 
benefits alphabet reduction hard model depend gains modelling higher order compared loss information character 
performance alphabet reduction practice examined detail section 
maximum lookahead heuristic lookahead required viterbi proof required previous suggests results tag insertion commonly converge lookaheads lower maximum lookahead heuristic select lower lookahead represents trade correctness efficiency 
lower lookahead denoted set low lowest entropy tagging may detected evaluation described section 
cem implementation collects statistics maximum size tag draft september leaves selection lower lookahead user 
performance maximum lookahead practise examined detail chapter 
heuristic xml provides mechanism called schemas specify tags may occur nested tags 
structure simple schemas tree shown figures 
complex schemas considered 
transitions considered insertion characters sequence determined schema current position schema 
node schema reached node inserting closing tags moving child node parent node opening tags moving parent node child node pairs nodes reached combination tags 
depending shape schema number combinations tags considered characters increases linearly 
bibliography corpus combinations observed relatively small subset combinations 
heuristic developed try fact 
training set kept combinations tags seen seen training considered insertion testing 
heuristic effect segmentation problems states limited effect classification schema number combinations increases linearly number nodes 
cem implementation builds implicit schema markov model created documents seen training 
performance discussed section 
draft september schema state tying 
state tying state tying widely heuristic speech recognition appears text modelling 
insight state tying built states large model similar chance model similar concepts 
speech recognition system models second half words hair pair similar certain dialects words different represent different parts speech 
state tying uses single underlying statistical distribution model states model 
states merged higher level model tracks difference models states share training data require significantly training data 
shows simple schema root node child nodes single child 
shows schema child nodes tied single state real benefit state tying ability share training data relative common relatively rare tags achieve better performance amount training data 
state tying works entity extraction problems requires levels document root order 
default cem performs state tying states tag name 
effect tying name tag examined section 
draft september segmentation segmentation tractable class text augmentation problems 
sequence symbols places segment may may symbols segment segment symbol giving total different ways segmenting sequence 
viterbi search reduces search space may may sufficient depending size lookahead reduced automatic tokenisation term represents leftmost branches tree involve insertion tag 
represents insertion tag need considered nodes search space 
search space reduced maximum lookahead amounting substantial reduction 
draft september classification segmentation classification represents tractable class text augmentation problems 
sequence symbols classes classed different ways classifying sequence 
viterbi search applied multiple tag situation requires lookahead related largest maximum tag length possible tags giving max 
max 
may may large reduction depending sizes 
reduced automatic tokenisation max 
max 
segmentation term represents straight forward case tags inserted term represents tags considered nodes 
search space reduced maximum lookahead amounting substantial reduction 
draft september entity extraction entity extraction tractable class text augmentation problems 
ways select zero tags vocabulary tags 

places tags occur sequence symbols tags occurring symbol inferred known state constraint prohibition empty tags closing tags correct order occur 
gives approximately tn possible sequence 
classification longest maximum tag length viterbi search giving max 
max 
max 
automatic tokenisation reduces search space max 
max 
max 
term represents straight forward case tags inserted term represents tags considered nodes 
maximum lookahead reduces size search space draft september summary section technique type assumption viterbi optimisation markov best optimisation markov maximum lookahead heuristic markov automatic tokenisation heuristic unicode data alphabet reduction heuristic unicode data maximum lookahead heuristic markov heuristic markov state tying heuristic markov table types optimisations heuristics assumptions table shows technique optimisation heuristic assumption permits technique 
techniques markov model automatic tokenisation alphabet reduction rely features unicode character classes 
lat rely structure hidden states markov model 
algorithm segmentation classification entity extraction complete tn viterbi max 
max 
automatic tokenisation max 
max 
maximum lookahead table search space size table shows size search spaces improvements expressed big notation 
table show general segmentation efficient classification turn efficient entity extraction 
chapter looked number optimisations heuristics 
chapter examines experimental performance corpora seen chapter 
draft september chapter results chapter techniques described previous chapter applied corpora described chapter 
correctness results possible compared experimental results literature 
re estimation examined bibliography corpus 
effectiveness optimisations heuristics bibliography corpus useful dataset evaluating effectiveness optimisations heuristics wide variety tags corpus allows selection tags examined 
segmentation corpus represents widely studied problem sharp contrast bibliography corpus 
best best section optimisation exploits nature viterbi search linking discrimination models search space required find lowest entropy tagging sequence respect model 
shows effect best optimisation hierarchical nested tags author editor name bibliography corpus 
cases lookahead search space significantly reduced 
effect greatest largest number tags number tags increases chances particular sequence low entropy relative particular model increases 
draft september lookahead best best optimisation hierarchical tag insertion 
steepest lines author editor name name name name 
runs order model training documents single testing document 
draft september search space nodes character lookahead best best optimisation non hierarchical tag insertion 
steepest lines name pages date volume number name pages date volume name pages date name pages name 
runs order model training documents single testing document 
draft september lookahead best effect best word varying model orders 
nearly incident quadruple line representing search spaces orders best order best order best order best order best 
runs training documents single testing document 
shows effect best optimisation non hierarchical tags name pages date volume number bibliography corpus 
considerably noisy relative sparseness pages volume number tags 
shows effect best optimisation word tag segmentation corpus 
best order model impact search space best reduces search space progressively reduces search space rising order increases discrimination model 
documents segmentation corpus significantly homogenous bibliography corpus resulting noise smoother graph 
shows little effectiveness best increases draft september search space nodes character entropy bits character number training files best effect best number training documents varied 
search space entropy 
runs order models lookahead single testing document segmentation corpus 
amount training segmentation corpus 
best search space independent number documents trained best search space drops 
drop occurred training documents relatively little drop remaining documents document withheld testing 
findings consistent expectations section 
trained high order models allow probability distribution function distinguish accurately branches models tags branches prune 
performance relatively simple implementation fact extra state required model best optimisation valuable tag insertion problems 
draft september character second character sum symbol unassigned uppercase letter lowercase letter decimal digit number space separator control private dash punctuation start punctuation punctuation connector punctuation punctuation math symbol currency symbol modifier symbol sum character second character sum symbol unassigned uppercase letter lowercase letter decimal digit number space separator control private dash punctuation start punctuation punctuation connector punctuation punctuation math symbol currency symbol modifier symbol sum table occurrence tables reuters corpus 
table pairs characters 
table pairs characters side tag 
automatic tokenisation automatic tokenisation see section evaluated occurrence tables tables corpora 
table shows counts pairs characters reuters corpus grouped unicode character class 
indicate units respectively 
table shows pairs tags 
differences reflect opportunities tokenisation improvements particular upper left corner table counts letters digits followed letters digits high zero indicating tag occurs combination letters digits 
distinctive cross shape table due fact opening tags usually follow space character followed upright draft september search space nodes character lookahead tokenisation effect tokenisation group hierarchical tags 
steepest lines name name name name editor author 
run performed training documents testing document order models 
closing tags proceeded followed space nn character crossbar 
control character class includes nn nr 
figures show effect tokenisation hierarchical nonhierarchical tags bibliography corpus 
shows gains gains tokenisation significant smaller variation documents 
reason differences hierarchical non hierarchical tags shown table 
table shows pairs characters shows side name tag sparseness indicating procedure tokenisation potential improvement 
hierarchical tags shown table similar non hierarchical tags shown table standard method writing names unicode characters character classes capitals 
draft september lookahead best effect tokenisation group non hierarchical tags 
steepest lines name name pages name pages date name pages date volume name pages date volume number 
run performed training documents testing document order 
draft september hierarchical sequences case sensitive characters delimited spaces commas full stops 
comparison nonhierarchical tags shown table comparison significantly diverse context date tag sequence digits case sensitive characters volume number tags strings digits commonly delimited brackets semicolons resultant occurrence table sparse previous table 
table show tables computists corpus tags 
table non zero counts situations table non zero counts meaning heuristic applied pairs 
frequently occurring alpha numeric pairs upper left corner mainly zero heuristic benefit 
table occurrence table segmentation corpus indicates letter far common character class expected chinese characters fall class 
nature corpus means frequently occurring pairs appear table non zeros indicating automatic tokenisation going little effect search space corpus 
shows interaction best tokenisation name tag 
addition tokenisation best reduces search space effect noticeable low lookaheads best effective 
automatic tokenisation prunes branches search tree having expand node branch calculate entropy 
consistent expectations section results show automatic tokenisation improves performance datasets 
perform consistent datasets number corpora noise occurrence tables 
noise occurs curated corpora suggests generally digital library collections heterogenous documents diverse origin draft september character second character sum symbol unassigned uppercase letter lowercase letter decimal digit number space separator control private dash punctuation start punctuation punctuation connector punctuation punctuation math symbol currency symbol modifier symbol sum character second character sum symbol unassigned uppercase letter lowercase letter decimal digit number space separator control private dash punctuation start punctuation punctuation connector punctuation punctuation math symbol currency symbol modifier symbol sum character second character sum symbol unassigned uppercase letter lowercase letter decimal digit number space separator control private dash punctuation start punctuation punctuation connector punctuation punctuation math symbol currency symbol modifier symbol sum character second character sum symbol unassigned uppercase letter lowercase letter decimal digit number space separator control private dash punctuation start punctuation punctuation connector punctuation punctuation math symbol currency symbol modifier symbol table occurrence tables bibliography corpus 
table pairs characters 
table pairs characters side name tag 
table pairs characters side name editor author tags 
table pairs characters side name pages date volume number tags draft september character second character sum symbol unassigned uppercase letter lowercase letter decimal digit number space separator control private dash punctuation start punctuation punctuation connector punctuation punctuation math symbol currency symbol sum character second character sum symbol unassigned uppercase letter lowercase letter decimal digit number space separator control private dash punctuation start punctuation punctuation connector punctuation punctuation math symbol currency symbol sum table occurrence tables computists corpus 
table pairs characters 
table pairs characters side tag 
character second character sum symbol unassigned uppercase letter lowercase letter letter decimal digit number number private dash punctuation start punctuation punctuation punctuation math symbol currency symbol symbol sum character second character sum symbol unassigned uppercase letter lowercase letter letter decimal digit number number private dash punctuation start punctuation punctuation punctuation math symbol currency symbol symbol sum table occurrence tables segmentation corpus 
table pairs characters 
table pairs characters side tag 
draft september lookahead tokenisation best tokenisation best tokenisation best tokenisation best effect best automatic tokenisation name tag 
run performed training documents testing document order models 
significantly worse point degrades heuristic ability determine insert tag 
anecdotal evidence html xhtml documents form internet suggest tags occur significantly wider variety places collections 
automatic tokenisation needs requires small tightly bounded amount extra state model form occurrence table 
best automatic tokenisation linked discrimination model 
means perform poorly trained model 
reason automatic tokenisation doesn perform occurrence tables suggest ppm model discriminates situations best ensures branches get pruned automatic tokenisation explored anyway 
draft september name symbol example null folder jones jill capitals folder jones jill case folder aaaaa aaaa aaa unicode folder vowel folder vowel case folder vc table folders alphabet reduction 
alphabet reduction table shows folders alphabet reduction experiment 
fold alphabet model effects sample string show 
null folder process alphabet 
capitals folder removes distinction upper lower case 
case folder folds uppercase letters single letter lowercase letters single letter 
unicode folder folds unicode character classes see section single character class 
vowel folder folds vowels single letter non vowels single letter 
vowel case folder folds uppercase vowels single letter lowercase vowels single letter uppercase non vowels single letter lowercase non vowels single letter 
shows results folders name bibliography corpus 
shows measure order model folders 
experiment done megabytes heap memory data shown models built memory 
folder performed best models built order large alphabet 
models performed build order 
increasing order increase performance probably useful information thrown away folder 
cv models performed similarly poorly built orders range 
models performed badly measure draft september model order vc measure model order vc ratio baseline entropy experimental entropy model order vc ratio baseline entropy experimental entropy detail effects alphabet reduction finding name tag bibliography corpus 
lookahead trained documents tested documents 
draft september despite able built order 
particularly surprising folder close relationship folder performed 
reason difference appears important delimiting names features bibliographies models unable distinguish 
shows ratio baseline experimental entropy experiments shows detail relationship ratio approaches 
discussed previously see page entropy determine model search responsible mis tagging 
data points ratio indicate search deficient lookahead needed increased optimal performance data points ratio greater indicate model deficient regard ideal situation ratio 
ways model deficient may seen insufficient training data may insufficient order may failing capture important features data 
training bibliographies approximate bibliographic entries appear sufficient training data models smaller alphabets generally require training data 
increasing order cv models clearly moves ratio 
problem models capturing important features data 
upward trend entropy ratio models higher consistent behaviour ppm models order increased optimal 
species fitting discussed page 
increase noise ratio entropies particularly model order increases due sampling effects 
shows details tags name pages date volume number lower lookahead lower lookahead necessary draft september model order vc measure model order vc ratio baseline entropy experimental entropy model order vc ratio baseline entropy experimental entropy detail effects alphabet reduction finding multiple tags bibliography corpus 
lookahead trained documents tested documents 
draft september greatly increased search space caused additional tags 
performance consistently poorer relative performance folders similar 
deviation folder measure similar vc folders clearly superior 
pages date volume number tags number centric text centric loss capitalisation effect badly 
large reductions correctness shown figures strongly suggest alphabet reduction production systems 
maximum lookahead heuristic majority tag insertion problems maximum lookahead problematic lookahead accuracy asymptotic computationally infeasible 
problems small number tags maximum lookahead obtainable 
shown great deal noise may clear asymptote reached 
pages tag noisy bibliography corpus representation page ranges homogenous representation names 
primary sources errors inserting pages tag digit page numbers looked years features common format citation taken electronic copy document length known location larger journal collection 
sources noise compounded variability length bibliographies may short single entry pages tag name 
problems resolved increasing lookahead 
shows analysis word tag segmentation corpus requires lower order model straight line 
data draft september lookahead search space recall precision graph recall precision search space lookahead single name tag 
models trained documents tested document 
lookahead search space recall precision graph recall precision search space lookahead single pages tag 
models trained documents tested document 
draft september search space nodes character recall precision lookahead search space recall precision graph recall precision search space lookahead word tag 
models trained documents tested document 
graph shown table show search space increased orders magnitude recall precision increased percent 
results show maximum lookahead heuristic effective 
increasing lookahead obvious benefit recall precision great detriment search space cases 
heuristic heuristic section limits number tags considered inserting character document 
shows effect heuristic hierarchical nested tags author editor name bibliography corpus 
cases search space reduced 
shows effect heuristic non hierarchical tags name pages date volume number bibliography corpus 
results heuristic consistent fantastic partly draft september lookahead search space nodes character recall precision table table recall precision search space lookahead word tag 
data plotted 
lookahead heuristic hierarchical tag insertion 
steepest lines author editor name name name name 
runs order model training documents single testing document 
draft september search space nodes character lookahead optimisation non hierarchical tag insertion 
steepest lines name pages date volume number name pages date volume name pages date name pages name 
runs order model training documents single testing document 
draft september best optimisation reaps savings tag ruled heuristic seen model meaning ppm model escape back order see section implying high entropy 
structure ppm models means order transition followed transition order start sequence symbol order transition followed order transition available entropy effects felt transitions 
tags tag sequence ruled heuristic mean order transitions rapid pruning best optimisation normal circumstances 
set observed tag combinations smaller bibliography corpus may real world corpora integrating tagged tagged bibliographies placement tags respect inter word whitespace performed automatically see consistently 
diverse realworld sources display degree consistency 
state tying state tying heuristic see section corpora studied name tag may occur editor author tag bibliography corpus 
schema structures bibliography dataset state tying shown respectively 
differs name subtree cloned copy appears parent 
examine effect duplication performance model 
table shows type confusion matrices state tying bibliography corpus 
surprisingly key leaf tags perform similarly models evidence models built tags tying 
slightly higher level tying performed noticeably better identifying name tags draft september bibliography editor author name pages date volume number title journal booktitle publisher address table type confusion matrices bibliography corpus 
matrix left state tying matrix left state tying 
values percent indicates lower 
order models trained documents tested documents lookahead 
draft september training files tying tying entropy dropping increased training data state tying 
order models tested documents lookahead 
tying performed noticeably better identifying editor tags improvement appears due fact proceedings editors name bibliography entries modelling editor tags separately author tags allowed information captured 
tags directly related names state tying results slightly better state tying results having higher number results leading diagonal eleven cases 
state tying consistent model concepts names rest model 
features type confusion matrices bibliography corpus explained section 
shows entropy drops increased training data state tying 
clear pattern divergence difference 
somewhat surprising motivation state tying achieve better performance amount training data section appears happening significant effect 
draft september bibliography name editor author table type confusion matrices bibliography corpus 
matrix left state tying matrix left state tying 
values percent indicates lower 
order models trained documents tested documents lookahead 
table shows type confusion matrices state tying bibliography corpus greatly reduced set tags 
results show clear pattern similarity shown larger set tags suggesting results generally applicable 
unanticipated benefit state tying models significantly smaller 
memory consumption ppm model increases linearly extra training data tags tied ppm model memory saved 
cem implementation uses memory naively detailed analysis optimised implementation teahan 
state tying optimisation gives best marginal improvement results expected lead smaller models 
occam razor variously called principle parsimony principle simplicity asserts simpler smaller model phenomenon preferred complex larger 
draft september correctness having evaluated optimisations heuristics look look correctness 
correctness studied corpus corpus basis 
computists corpus computists corpus previously studied bray wen 
bray evaluates extraction confusion matrix see section reproduced table confusion matrix derived current cem data corrected data 
values measured words values characters 
tags cem results comparable slightly worse results bray 
bray results percentages words correctly classified cem results percentages characters correctly classified direct comparison results difficult 
despite corrections described section mistakes shown table systems appear due inconsistencies 
tags best performance url email money deserve close attention described regular expression uniquely exclusively identified single character 
properties tag insertion consistent modelling tags easier certain kinds models 
systemic confusion name source location organisation discussed chapter clear confusion tables cem clearly performing worse bray results 
situation cem performs worse bray analysis fax tag 
common type error fax phone tag systems fax numbers mistaken phone numbers draft september ate ame rg 
rl mail hone ax ate ame rg 
rl mail hone ax ate ame rg rl mail hone ax table confusion matrices computists corpus bray page cem data bray cem corrected data 
character counts characters values percent indicates lower 
draft september author recall precision measure documents wen cem wen data cem corrected table accuracy computists corpus wen page cem 
documents number documents testing set 
fax 
cem small number fax tags seen model fax tag closest untrained model biased apparently random sequences 
results errors pp 
unix ht dig search 
happen bray analysis normal word approaches words seen testing seen training handled separately effectively second tier escape methodology 
handling effectively learns probability unseen word appearing particular tag 
bray results url email tags high cem results noticeably lower 
partly definition word word bray results allowed urls email addresses seen single word seen letters 
tagging regular expression extremely consistent 
wen expresses accuracy terms recall precision error rates type tag shown table 
documents number documents testing set 
wen model trained documents thesis uses leave cross validation 
values table bear direct relationship table results word character level recall precision tags 
draft september author corpus recall precision fmeasure perfect ref 
peng people daily chinese treebank ponte people daily palmer trec teahan ponte people daily cem table performance chinese text 
perfect indicates system uses perfect lexicon 
segmentation corpus segmentation chinese text archetypical segmentation task large number published recall precision figures task 
table shows selection best case results obtained study cem corpus described section 
systems perfect lexicon list words may seen testing effectively solves zero frequency problem prevents results transfered real world problems 
taken face value results cem clearly better segmentation systems systems appear assessing recall precision words word boundaries doubles perceived number false positives false negatives isolated errors 
issue data sorted sentence level clear case reported results 
cem differs teahan smi system internal character handling 
cem treats character unicode character fixed number determined unicode specification smi treats characters words new word handled specially added model 
substantially changes performance model escape method 
noted earlier priori reason preferring escape method see section results generalisable chinese draft september text segmentation 
shows trade offs critical chinese text segmentation order model 
large alphabet chinese models modest orders large making problem significantly difficult smaller alphabet language english 
attempt optimise memory usage cem models meaning build large models teahan smi 
bibliography corpus bibliography corpus developed study wide range results systems compare results cem 
wen gives results tags publisher date pages early version corpus results sufficient detail comparison 
table shows confusion matrix large number tags bibliography corpus 
bibliography tag background default tag containing characters document tag 
significant number errors caused note field field allows arbitrary text inserted entry 
extra text abbreviated published version tech 
report information ideally fields lecture notes computer science series number fields citation erratum jpl pp 

extra text trained model adding noise implicit model text testing data sequences page ranges dates pages date tags placed viterbi search 
table shows confusion matrix note tag added 
performance substantially different performance number drops draft september name pages date volume number title journal booktitle publisher address bibliography character count table confusion matrix bibliography corpus note 
counts characters values percent indicates percent lower 
order models train documents tested documents lookahead 
draft september name pages date volume number title journal booktitle publisher address note bibliography character count table confusion matrix bibliography corpus note 
counts characters values percent indicates percent lower 
order models train documents tested documents lookahead 
draft september considerably 
appears note tags contained numeric sequences see examples 
table shows type confusion matrix bibliography corpus 
bibliography tag document tag content tag contains body leading key bibliography styles 
characters mistakenly marked punctuation note tag explained errors title column mainly represent words title confused preceeding author tag 
tables confusion title booktitle booktitle place title titles document chapter title book title article title collection title 
confusion publisher address tags publisher tags address publisher included especially entries proceedings inproceedings address tag reserved address conference publisher 
name table split separate tags editor author name considerable confusion various tags surprisingly little difference editor name tags probably name immediately start tag editor tag middle tag 
results appear higher figures systems direct comparison certainly misleading different granularity results measured different number tags 
informal comparison results uncorrected results citeseer website suggest significantly better determination non name structures cem similar determination names 
citeseer nj nec com cs draft september editor author name pages date volume number title journal booktitle publisher address bibliography character count table type confusion matrix bibliography corpus 
character counts characters values percent indicates lower 
order models train documents tested documents lookahead 
draft september recall precision lookahead order order order order graph recall precision lookahead various orders models documents reuters corpus 
reuters corpus figures show recall precision curves entity extraction task reuters corpus training documents testing documents 
explained section difference graphs average recall precision documents corpus recall precision testing set 
difference percent greatest low lookaheads caused number shorter market report articles columns figures easier tag longer articles literary nature 
fortunately results different trends clearly 
performance cem poor state art taggers routinely recall precision measures high range 
results particularly disappointing baseline data generated finite state machine brill tagger word level taggers able emulate september lookahead order order order order graph recall precision lookahead various orders models reuters corpus taken 
tively easily 
baum welch re estimation baum welch algorithm see section allows testing data boost models performance 
section look application re estimation bibliography corpus pertinent pointed previously see sections bibliography corpus significantly diverse bibliography corpus digital library beneficial able generalise models build bibliography corpus diverse corpora 
shows attempt generalise bibliography format acm bibliography format 
format abbreviated form author initialised acm format standard style includes draft september edit distance edits character re estimation files incremental re estimation cumulative average document average graph edit distance increasing re estimation 
trained documents re estimated acm documents tags order lookahead 
full author known 
tags considered 
expected model built format tested acm format errors 
line edits character average number edits entire acm documents re estimation 
common error tagging tag tag seen edit distance metric separate errors removing opening closing tag adding opening closing tag 
common errors included tagging eds tagging word words title 
increment re estimation points edit distances acm documents tagged model formed documents previous acm documents tagged model 
points fall outside viewport graph 
great deal noise reflecting draft september batch size files pass csv graph edit distance increasing re estimation trained documents re estimated acm documents tested acm documents tags order lookahead 
diverse content individual bibliographies 
document average running average previous points 
individual points shows great deal noise obvious pattern increase decrease noise 
cumulative average reaches edits character entire documents significant drop edits character re estimation 
re estimation clearly reduces edit distance case lowering average edit distance acm documents 
em theory predicts true convergence higher higher proportion data estimated true data fidelity model slowly falls insufficient re estimation data apparent 
explained section cem implementation uses variant baum welch algorithm 
shows effect batch size edit distance draft september single batch 
batch size represents trade cost repeatedly retraining model times small batch size cost reinforcing mistakes tagging large batch size 
clearly small batch sizes give correct results large batch sizes case 
summary best optimisation produced large reductions search space 
automatic tokenisation heuristic reduces search space slightly significant impact accuracy alphabet reduction causes considerable reduction accuracy maximum lookahead heuristic significantly reduces search space 
corpora bibliography corpus segmentation corpus character level tag insertion works 
results entity extraction reuters corpus poor mixed computists corpus 
draft september chapter introduced data mining text augmentation taxonomy types augmentation introduced examined 
models text algorithms operate examined particular markov model ppm models viterbi teahan search 
corpora discussed including bibliography corpus build current 
evaluation methods text augmentation examined relation classes augmentation independence problems arise 
number novel optimisations heuristics text augmentation introduced evaluated relevant corpora 
best optimisation clearly great improvement maximum lookahead heuristic reduced search space feasible sizes 
automatic tokenisation heuristics successful reducing search space state tying little effect search space reduced size models 
compared systems current produced competitive results simply structured chinese text segmentation corpus complex bibliography corpus part speech tagging reuters corpus 
results small computists corpus mediocre 
number directions current system draft september integration cem larger system probably greenstone removal constraint see page 
empty tags high entropy constraint unnecessary current system ease implementation 
creation user interface user feedback 
open questions number open questions examined thesis conceptualisation context optimal 
alternative method computing context current character character stream 
discovered explored experimental thesis 
context 

collapsed 

approach successful tag densities highest part speech tagging 
adding default tag untrained model accessible context remove tendency place high entropy sequences model training data 
different escape methods reduce tendency place high entropy sequences model training data 
universal similarity metric kolmogorov complexity appropriate measure comparing sequences moving evaluation theoretical framework independent particular approach solving problem may resolve complexities evaluating performance 
www greenstone org draft september certain textual strings line synchronisation points finite automata sense 
draft september glossary acm acronym association computing www acm org multilingual structured controlled vocabulary agriculture 
www fao org baum welch algorithm refines model unclassified data 
see page 
big encoding chinese language documents 
see 
cem dcc acronym data compression conference 
annual conference data compression held year snowbird salt lake city usa 
www cs brandeis edu dcc dtd acronym document type definition 
description grammar class sgml xml documents 
see schema 
www org tr rec xml em acronym entropy minimisation algorithm 
generalisation re estimation 
fsm see finite state machine 
ftp acronym file transfer protocol 
widely implemented protocol transfering file network 
largely superseded 
finite state machine computer consisting finite number states transitions 
gb encoding see 
gpl acronym gnu public licence 
software licence cem 
www gnu org gpl acronym greenstone digital library 
gpl digital library suite 
nzdl org abbreviated gb 
national standard chinese 
official encoding china 
draft september hmm see hidden markov model 
htk acronym hmm 
suite tools voice recognition markov models 
html acronym hypertext markup langauge 
widely known instance sgml default format www documents 
www org markup acronym hypertext transfer protocol 
widely implemented protocol transfering documents particularly html documents network 
advanced ftp allowing caching metadata 
hidden markov model see page markov model see page mesh medical ontology 
www nlm nih gov mesh nist acronym national institute standards technology usa 
www nist gov ocr acronym optical character recognition 
process converting scanned image text ascii unicode 
pdf portable document format 
document format adobe systems 
www adobe com products acrobat html ppm algorithm escape method ppm text compression algorithm 
see page 
escape method approach overcoming zero frequency problem 
see page 
sgml acronym standard generalized markup language 
standard specifying markup family markup specified standard including html tei 
superseded xml 
www org markup sgml schema description grammar xml class xml documents 
prefered dtd automated settings schema may parsed manipulated communicated form xml 
www org xml schema tcc computists 
see page 
www computists com tei acronym text encoding initiative 
collaborative project encoding texts humanities 
markup languages documents encoded languages 
www 
org draft september url acronym uniform resource locator 
string uniquely identifies resource standard form 
www ietf org rfc rfc txt unicode standard character encoding attempting assign single character code character independant platform program language 
www unicode org viterbi search see page 
www acronym world wide web 
set hosts serving predominately html pages 
www org formedness constraint constraint tags may occur stream xml differences xml sgml 
xhtml joining names xml html 
xml schema closely approximates html documents conforming schema 
www org tr xhtml xsl fo acronym extensible stylesheet language formatting objects 
expressed xml laying textual representations xml dimensional rectangles 
www org style xsl xsl see xslt 
xslt acronym extensible stylesheet language transformations 
expressed xml manipulating xml trees 
www org tr xslt xsl acronym extensible stylesheet language 
manipulating xml 
split xslt xsl fo 
pdf acronym probability density function 
function returns probability distribution 
smi acronym statistical modelling interface 
text augmentation system written bill teahan renamed text mining toolkit 
tmt acronym text mining toolkit 
text augmentation system written bill teahan previous known statistical modelling interface draft september bibliography eugene agichtein luis gravano 
snowball extracting relations large plain text collections 
proceedings fifth acm conference digital libraries pages san antonio texas united states 
rie ando lillian lee 
unsupervised statistical segmentation japanese sequences 
journal natural language engineering 
scheduled appear volume number 

hidden markov models text recognition 
international journal pattern recognition artificial intelligence 
paul carl craig stuart yeates 
interaction networks teaching 
technical report tr department computer science university canterbury christchurch new zealand september 
steven atkin ryan 
generalised mechanism unicode metadata 
th internation unicode conference san jose california 
steven atkin ryan 
generalized mechanism unicode metadata 
nineteenth international unicode conference san jose california usa september 
ricardo baeza yates berthier ribeiro neto 
modern information retrieval 
acm press addison wesley 
david bainbridge dana mckay ian witten stefan 
greenstone digital library developer guide 
digital library laboratory university waikato 
alex bateman lorenzo richard durbin laurence sean eddy sam griffiths jones kevin howe marshall erik 
protein families database 
nucleic acids research 
leonard baum 
inequality associated maximisation technique statistical estimation probabilistic functions markov process 
inequalities 
sighted 
draft september leonard baum ted petrie george soules norman weiss 
maximisation techniques occurring statistical analysis probabilistic functions markov chains 
annals mathematical statistics 
doug beeferman adam berger john lafferty 
statistical models text segmentation 
machine learning 
timothy bell john cleary ian witten 
text compression 
prentice hall 
timothy bell ian witten john cleary 
modeling text compression 
computing surveys december 
tim berners lee daniel connolly 
hypertext markup language html specification 
request comments network working group 
november 
alex berson kurt stephen smith 
building data mining applications crm 
osborne mcgraw hill 
alan biermann amit bagga 
analyzing complexity domain respect information extraction task 
fifth workshop large corpora 
daniel bikel richard schwartz ralph weischedel 
algorithm learns name 
machine learning 
jeff bilmes 
gentle tutorial em algorithm application parameter estimation gaussian mixture hidden markov models 
technical report icsi tr university berkeley massachusetts usa 
gentle thorough sound mathematical background field 
steven bird peter buneman wang tan 
query language annotation graphs 
second international conference language resources evaluation pages paris france 
european language resources association 
steven bird maeda ma lee beth randall salim 
diverse tools built annotation graph toolkit 
third international conference language resources evaluation paris france 
kurt bollacker steve lawrence lee giles 
citeseer autonomous web agent automatic retrieval identification interesting publications 
katia sycara michael wooldridge editors proceedings second international conference autonomous agents pages new york new york usa 
acm press 
draft september editors 
multilingual agricultural thesaurus 
fao rome italy edition 
matthew brand 
learning behavioral manifolds recognition synthesis 
international workshop statistical computational theories vision fort collins colorado usa june 
tim bray jean paoli sperberg mcqueen 
extensible markup language xml 
recommendation world wide web consortium february 
bray 
compression models text mining 
master thesis department computer science university waikato hamilton new zealand july 
david gilbert 
approaches automatic discovery patterns 
journal computational biology 
christopher le 
heard data mining science october 
eric brill 
simple rule part speech tagger 
rd conference applied natural language processing pages trento italy 
eric brill 
advances transformation part speech tagging 
proceedings national conference artificial intelligence pages 
john seely brown paul duguid 
social life information 
harvard business school press boston massachusetts usa march 
published monday april www firstmonday org issues issue brown contents html 

relationship recall precision 
journal american society information science 
jeffrey chang hinrich schutze russ altman 
creating online dictionary abbreviations medline 

appear 
eugene charniak 
statistical language learning 
mit press 
stanley chen joshua goodman 
empirical study smoothing techniques language modeling 
joshi martha palmer editors proceedings fourth annual meeting association computational linguistics pages san francisco 
morgan kaufmann publishers 
nancy chinchor 
overview muc met 
proceedings message understanding conference muc april 
www muc saic com proceedings muc proceedings overview html 
draft september richard curtis ben elton john lloyd 

michael joseph 
doug cutting julian kupiec jan pedersen penelope sibun 
practical part speech tagger 
proceedings third conference applied natural language processing 
doug cutting jan pedersen 
xerox part speech tagger 
xerox palo alto research center palo alto california usa version edition april 
hugh davis hey 
automatic extraction hypermedia bundles digital library 
second annual conference theory practice digital libraries digital libraries austin texas usa june 
acm 

markov processes 
springer 
translated english fabius greenberg 
line 
information extraction world wide web survey 
technical report computing center 
tom emerson 
segmentation chinese text 
multilingual computing technology february 
david fallside 
xml schema 
world wide web consortium may 
ian frank 
football times learn newspapers 
robocup pages 
freitag mccallum 
information extraction hmm structures learned stochastic optimization 
american association artificial intelligence aaai conference 
dayne freitag 
multistrategy learning information extraction 
proceedings th international conference machine learning pages san francisco ca 
morgan kaufmann 
dayne freitag andrew mccallum 
information extraction hmms shrinkage 
proceedings aaai workshop machine learning extraction 
edward fry 
elementary reading instruction 
mcgraw hill 
robert gaizauskas alexander robertson 
coupling information retrieval information extraction new text technology gathering information web 
th riao computer assisted information searching internet conference pages montreal canada june 
draft september ge pratt padhraic smyth 
discovering chinese words unsegmented text poster 
research development information retrieval pages 
james gosling bill joy guy steele 
java language specification 
addison wesley 
paul grosso daniel 
xml fragment interchange 
world wide web consortium february 
www org tr xml fragment 
donna harman 
overview text retrieval conference 
text retrieval conference pages gaithersburg maryland usa november 
national institute standards technology 
donna harman 
overview second text retrieval conference 
second text retrieval conference pages gaithersburg maryland usa august september 
national institute standards technology 
donna harman 
overview third text retrieval conference 
third text retrieval conference pages gaithersburg maryland usa november 
national institute standards technology 
donna harman 
overview fourth text retrieval conference 
fourth text retrieval conference pages gaithersburg maryland usa november 
national institute standards technology 
hearst 
text data mining 
proceedings th annual meeting association computational linguistics 
paul howard 
design analysis efficient lossless data compression systems 
phd thesis department computer science brown university june 
ronald howard 
dynamic probabilistic systems 
john wiley sons 
james hughes peter guttorp stephen charles 
nonhomogeneous hidden markov model precipitation occurrence 
applied statistics 


iso standard programming language 
frederick jelinek 
statistical methods speech recognition 
mit press boston massachusetts usa 
thorsten joachims 
probabilistic analysis rocchio algorithm tfidf text categorization 
douglas fisher editor proceedings icml th international conference machine learning pages nashville 
morgan kaufmann publishers san francisco 
draft september thorsten joachims 
text categorization support vector machines learning relevant features 
claire nedellec rouveirol editors proceedings ecml th european conference machine learning pages chemnitz de 
springer heidelberg de 
johansson leech 
manual information accompany lancaster oslo bergen corpus british english digital computers 
technical report bergen norwegian computing centre humanities 
karen sparck jones van 
report need provision ideal information retrieval test collection 
technical report december cambridge university computer laboratory 
jussi karlgren douglass cutting 
recognizing text genres simple metrics discriminant analysis 
th international conference computational linguistics volume ii pages kyoto japan 
jeffrey kingston 
algorithms data structures design correctness analysis 
addison wesley 
anders krogh michael brown mian david haussler 
hidden markov models computational biology applications protein modeling 
technical report ucsc crl university california santa cruz 
karen kukich 
techniques automatically correcting words text 
acm computing surveys december 
nicholas kushmerick 
wrapper induction 
artificial intelligence 
john lafferty andrew mccallum fernando pereira 
conditional random fields probabilistic models segmenting labeling sequence data 
th international conference machine learning pages 
morgan kaufmann san francisco ca 

part speech tagging statistical parsing 
michael andre renaud tim wright editors new zealand computer science research students conference pages christchurch new zealand april 
university canterbury 
leslie lamport 
document preparation system user guide manual 
addison wesley 
christophe jonathan fiscus sylvain john garofolo 
practical atlas 
human language technology san diego california usa march 
draft september steve lawrence lee giles 
accessibility information web 
nature 
leek 
information extraction hidden markov models 
master thesis uc san diego 
lewis 
evaluating text categorization 
proceedings speech natural language workshop pages 
morgan kaufmann 
lewis 
trec filtering track 
fifth text retrieval conference pages 
ming li xin chen xin li bin ma paul vitanyi 
similarity metric 
proceedings th annual acm siam symposium discrete algorithms pages baltimore md january 
acm siam 
ming li paul vitanyi 
kolmogorov complexity applications 
springer verlag berlin 
jean 
gzip 
unix manual page 
claudio lucchesi tomasz kowaltowski 
applications finite automata representing large vocabularies 
software practice experience january 
helmut 
stochastic models allow baum welch training 
ieee transactions signal processing november 
hans peter luhn 
statistical approach mechanised encoding searching literary information 
ibm journal pages october 
american chemical society meeting miami april 
hans peter luhn 
modern trends documentation chapter auto encoding documents information retrieval systems pages 
pergamon press london england 
mitchell marcus beatrice santorini mary ann marcinkiewicz :10.1.1.14.9706
building large annotated corpus english penn treebank 
computational linguistics 
andrew mccallum dayne freitag fernando pereira 
maximum entropy markov models information extraction segmentation 
proc 
th international conference machine learning pages 
morgan kaufmann san francisco ca 
katherine 
efficient phrase hierarchy inference 
master thesis university waikato hamilton new zealand 
gerry 
arxiv org los alamos national laboratory print server 
international journal grey literature 
draft september geoffrey mclachlan krishnan 
em algorithm extensions 
probability statistics 
wiley 
mclaughlin 
grading new readability formula 
journal reading 
john mcmahon francis smith 
review statistical language processing techniques 
ai review appear 
microsoft 
speech recognition office xp 
web page may 
www microsoft com office evaluation indepth speech asp 
alistair moffat timothy bell ian witten 
lossless compression text images 
international journal high speed electronics 
special issue signal compression 
moffat 
lossless compression 
computer journal 
special issue lossless compression editorial 
mehryar mohri michael riley 
weighted determinization minimization large vocabulary speech recognition 
proc 
eurospeech pages rhodes greece 
rao 
natural language versus controlled vocabulary information retrieval case study soil mechanics 
journal american society information science 
un yong nahm mikhail bilenko raymond mooney 
approaches handling noisy variation text mining 
international conference machine learning text learning workshop pages sydney australia july 
nelson 
computer lib 
microsoft press redmond washington 
dream machines author volume 
craig nevill manning geoffrey holmes ian witten 
development holte classifier 
proceedings artificial neural networks expert systems pages new zealand 
david nichols kirsten thomson stuart yeates 
usability open source software development 
elizabeth kemp chris phillips john haynes editors symposium computer human interaction pages north new zealand july 
acm sigchi nz 
joseph 
model intellectual foundations library information science 
published williams texas woman university 
david palmer john burger 
chinese word segmentation information retrieval 
aaai spring symposium cross language text speech retrieval 
draft september park roy byrd 
hybrid text mining finding abbreviations definitions 
proceedings conference empirical methods natural language processing pittsburgh pa june 
steven pemberton daniel austin axelsson doug herman beth ishikawa shin ichi matsui ann navarro subramanian rob sebastian peter stark 
xhtml extensible hypertext markup language reformulation html xml 
world wide web consortium edition august 
peng dale schuurmans 
self supervised chinese word segmentation 
lecture notes computer science 
plato 
republic 
penguin 
jay ponte bruce croft 
retargetable word segmentation procedure information retrieval 
symposium document analysis information retrieval 
john ross quinlan 
programs machine learning 
morgan kaufmann san mateo california usa 
lawrence rabiner 
tutorial hidden markov models selected applications speech recognition 
proceedings ieee february 
martin rajman 
text mining knowledge extraction unstructured textual data 
th conference international federation classification societies rome italy 
peter mark roget 
thesaurus english words 
gould lincoln boston 
rosenfeld 
maximum entropy approach adaptive statistical language modeling 
computer speech language 
ryan 
viterbi algorithm 
warwick research report rr computer science university warwick coventry england february 
gerard salton 
automatic text processing transformation analysis retrieval information computer 
addison wesley 
schindler 
fast block sorting algorithm lossless data compression 
technical report carnegie mellon university 
www com 

automatic taxonomy building 
julian seward 
bzip 
unix manual page 
draft september seymore andrew mccallum ronald rosenfeld 
learning hidden markov model structure information extraction 
proceedings sixteenth national conference articial intelligence workshop machine learning information extraction pages orlando fl 
claude shannon warren weaver 
mathematical theory communication 
university illinois press urbana illinois usa 
john simpson editor 
oxford dictionary online edition 
oxford university press oxford england 
tony smith 
gram models agreement language 
phd thesis computer science department university waikato hamilton new zealand 
sanjay zhaohui tang jim yang 
performance study microsoft data mining algorithms 
technical report microsoft 
sperberg mcqueen lou 
guidelines electronic text encoding interchange 
association computers humanities association computational linguistics association literary linguistic computing 

definition data mining text mining applications new customer economy 
question answer www crm day com 
james storer martin cohn editors 
data compression conference snowbird utah usa march 
ieee 
james storer martin cohn editors 
data compression conference dcc snowbird utah usa march 
ieee computer society ieee 
teahan harper 
combining ppm models text mining approach 
storer cohn pages 
william teahan 
modelling english text 
phd thesis department computer science university waikato hamilton new zealand may 
william teahan john cleary 
tag models english text 
storer cohn page 
william teahan wen roger mcnab ian witten 
compression algorithm chinese word segmentation 
computational linguistics september 
unicode consortium 
unicode standard worldwide character encoding 
addison wesley 
draft september andrew viterbi 
error bounds convolutional codes asymptotically optimal decoding algorithm 
ieee transactions information theory 
andrew viterbi 
principles digital communication coding 
mcgraw hill 
ellen voorhees donna harman 
overview fifth text retrieval conference 
fifth text retrieval conference pages gaithersburg maryland usa november 
national institute standards technology 
ellen voorhees donna harman 
overview sixth text retrieval conference 
sixth text retrieval conference pages gaithersburg maryland usa november 
national institute standards technology 
ellen voorhees donna harman 
overview seventh text retrieval conference 
seventh text retrieval conference pages gaithersburg maryland usa november 
national institute standards technology 
ellen voorhees donna harman 
overview eighth text retrieval conference 
eighth text retrieval conference pages gaithersburg maryland usa november 
national institute standards technology 
ellen voorhees donna harman 
overview ninth text retrieval conference 
ninth text retrieval conference pages gaithersburg maryland usa november 
national institute standards technology 
ellen voorhees donna harman 
overview tenth text retrieval conference 
tenth text retrieval conference pages gaithersburg maryland usa november 
national institute standards technology 
wen 
text mining hmm ppm 
master thesis computer science university waikato hamilton new zealand july 
ian witten neal john cleary 
arithmetic coding data compression 
communications acm 
ian witten 
applications lossless compression adaptive text mining 
proceedings conference information science systems princeton university march 
ian witten 
applications lossless compression adaptive text mining 
proc conference information sciences systems pages princeton usa march 
draft september ian witten timothy bell 
zero frequency problem estimating novel events adaptive text compression 
ieee transaction information theory 
ian witten stefan 
greenstone digital library guide 
digital library laboratory university waikato 
ian witten stefan 
greenstone digital library users guide 
digital library laboratory university waikato 
ian witten bray william teahan 
language models generic entity extraction 
international conference machine learning workshop text mining 
ian witten eibe frank 
data mining practical machine learning tools techniques java implementations chapter weka waikato environment knowledge analysis 
morgan kaufmann san francisco 
ian witten alistair moffat timothy bell 
managing gigabytes compressing indexing documents images 
morgan kaufmann nd edition 
ian witten neal john 
cleary 
arithmetic coding data compression 
cacm june 
ian witten craig nevill manning sally jo cunningham 
building digital library computer science research technical issues 
australasian computer science conference proceedings pages melbourne australia 
ian witten craig nevill manning mcnab sally jo cunningham 
public library full text retrieval 
communications association computing machinery april 
wu pascale fung 
improving chinese tokenization linguistic filters statistical lexical acquisition 
proceedings fourth acl conference applied natural language processing stuttgart germany october 
stuart yeates 
design patterns garbage collection 
master thesis university canterbury christchurch new zealand june 
stuart yeates 
automatic extraction acronyms text 
third new zealand computer science research students conference pages 
stuart yeates editor 
third new zealand computer science research students conference hamilton new zealand april 
university waikato 
draft september stuart yeates 
colloquial entropy markup cem documentation 
university waikato javadoc package edition 
stuart yeates david bainbridge ian witten 
compression identify acronyms text 
storer cohn page 
longer version appears 
stuart yeates david bainbridge ian witten 
compression identify acronyms text 
working department computer science university waikato hamilton new zealand january 
short version appears 
stuart yeates kirsten thomson 
applications machine learning agricultural datasets 
third new zealand conference postgraduate students engineering technology pages christchurch new zealand july 
school engineering university canterbury 
post graduate research new zealand industry 
stuart yeates ian witten 
tag insertion complexity 
tan philip yu editors international workshop text web mining pacific rim conference artificial intelligence pages melbourne australia august 
stuart yeates ian witten david bainbridge 
tag insertion complexity 
storer cohn pages 
stuart yeates 
relationship hidden markov models prediction partial matching models 
th annual new zealand engineering technology postgraduate conference hamilton new zealand august 
university waikato 
stuart yeates michel de 
design garbage collector design patterns 
christine roger duke bertrand meyer editors th conference technology object oriented languages systems pacific pages melbourne australia november 
interactive software engineering 
stuart yeates michel de 
design patterns garbage collection 
robert don roberts editors th annual conference pattern languages programs volume general techniques monticello illinois usa september 
yi sundaresan 
mining web acronyms duality patterns relations 
proceedings second international workshop web information data management part cikm conference information knowledge management pages kansas city missouri usa november 
acm 
steve young 
htk hidden markov model toolkit design philosophy 
technical report cued infeng tr department engineering cambridge university september 
draft september oren zamir oren etzioni 
web document clustering feasibility demonstration 
proceedings sigir melbourne australia 
george zipf 
human behavior principle effort human ecology 
addison wesley press cambridge massachusetts usa 
republished 
draft september 
