approximate medians quantiles pass limited memory singh manku ibm almaden research center manku almaden ibm com sridhar rajagopalan ibm almaden research center sridhar almaden ibm com bruce lindsay ibm almaden research center bruce almaden ibm com new algorithms computing approximate quantiles large datasets single pass 
approximation guarantees explicit apply regard value distribution arrival distributions dataset 
main memory requirements smaller reported earlier order magnitude 
discuss methods couple approximation algorithms random sampling reduce memory requirements 
sampling approximation guarantees explicit probabilistic apply respect user controlled confidence parameter 
algorithms theoretical analysis simulation results 
article studies problem computing order statistics large sequences online disk resident data little main memory possible 
focus computing quantiles elements specific positions sorted order input 
oe quantile oe defined element position sorted sequence input 
rest denotes number elements input 
oe quantile called median 
element said ffl approximate oe quantile rank oe gamma ffl oe ffl clearly elements dataset qualify 
database applications quantiles interest database implementers database users 
characterize distributions real world data sets sensitive outliers moments mean variance 
business intelligence applications distill summary information huge data sets 
obtaining accurate estimate predicate selectivity valuable query optimization 
better estimate cardinality query result sets quantiles characterize distribution stored data 
equidepth histograms instance simply quantiles gamma computed column values database tables suitable parallel database systems employ value range data partitioning requires generation splitters divide data approximately equal parts 
distributed parallel sorting splitter values assign data elements nodes sorted 
approximate quantiles substituted exact quantiles applications statistical data analysis database query optimization value range data partitioning 
guarantee error number elements true quantile approximate quantile practitioners reluctant algorithms produce 
algorithm provides explicit priori guarantees accuracy output quantiles understood trusted 
challenges meet efficiency correctness algorithm data independent 
datasets originate sources stored tables intermediate query results 
sequence values coming stored table influenced insert order data value clustering 
sequence values coming intermediate result depends query plan example merge join produce table ordered join column 
stored intermediate table clustered sorted column different ones quantile computation correlations columns 
arrival orders value distributions hard characterize 
important algorithms depend assumptions efficiency correctness 
note different applications demand different levels accuracy 
amount error quantiles produced affects performance application uses 
cost quantified 
example equi depth histogram errors lead cardinality estimation errors query optimization 
cost partition imbalance distributed sorting proportional difference completion times smallest largest partitions 
quantile finding algorithm tunable level accuracy required application performance degrade gracefully accuracy requirements increased 
require single pass data 
multiple passes large data sets unattractive performance reasons incompatible dbms group implementations 
address problem main memory usage 
clearly entire input stream buffered memory 
degree accuracy algorithm little main memory possible 
especially important query optimization desirable compute histograms multiple columns table single pass table 
group algorithms compute multiple aggregation results concurrently 
propose desiderata algorithm require prior knowledge arrival value distribution inputs provide explicit tunable approximation guarantees compute results single pass parallelizable scale smp mpp configurations produce multiple quantiles extra cost little memory possible simple code understand 
shall see algorithms clearly meet requirements 
improve previously described algorithms memory usage impose non trivial memory costs 
reader judge simplicity understandability algorithms 
antecedents theory literature theory literature primarily focused counting number comparisons needed find exact median quantile 
celebrated blum floyd pratt rivest tarjan shows selection kth largest element done comparisons 
shows comparisons required computation exact median 
account progress see survey mike paterson 
current best bounds tighter product sophisticated deep analysis see 
upper bound comparisons lower bound ff ff order gamma extremely small number standards 
frances yao showed computing approximate median requires omega gamma comparisons deterministic algorithm 
curiously lower bound easily beaten resorting randomization 
naive randomized algorithm outputs median random sample size ffl log ffi gamma uses number comparisons independent comprehensive survey aspect literature see survey paterson 
ira pohl established deterministic algorithm computes exact median pass needs store data elements 
munro paterson generalized showed memory store elements necessary sufficient finding exact median passes 
bound holds oe quantile constant oe 
result motivates search algorithms produce approximate quantiles single pass memory 
database literature jain chlamtac proposed simple algorithm computing quantiles single pass constant amount memory 
priori guarantees error 
agrawal swami proposed pass algorithm 
idea adjust equi depth histogram boundaries fly appear balance 
strong priori guarantees error 
ranka singh propose data independent single pass algorithm guaranteed error bounds 
describe algorithm detail section 
random sampling useful tool context 
dewitt distributed sorting 
discuss idea various applications detail section 
bridging gap ideas munro paterson applied develop pass algorithm approximate quantiles 
original appeared early fact appears missed database community 
describe general uniform setting includes munro paterson algorithm special case 
doing improve munro paterson algorithm terms space required 
show algorithms coupled sampling obtain reduction space 
statement problem tackle sections oe ffl design single pass algorithm computes ffl approximate oe quantile dataset size little main memory possible 
uniform framework algorithm framework parameterized integers algorithm buffers store elements 
small amount memory required book keeping purposes memory footprint bk elements 
associate buffer positive integer denotes weight 
intuitively weight buffer number input elements represented element buffer 
buffers labeled empty full 
initially buffers labeled empty 
values calculated enforce approximation guarantee optimize bk constraint 
various algorithms composed interleaved sequence operations new collapse output describe 
new operation new takes input empty buffer 
invoked empty buffer outstanding element input sequence 
operation simply populates input buffer elements input sequence labels buffer full assigns weight 
buffer filled completely remaining elements input sequence equal number gamma elements added deficit 
size augmented dataset consisting original dataset plus gamma elements added buffer fin fi 
oe oe fi gamma fi output weight 
sorted sequence offset input weight weight weight 
collapse illustrated 
clear oe quantile original dataset size corresponds oe quantile augmented dataset size fin collapse operation collapse takes full input buffers xc outputs buffer size input buffer marked empty 
output stored buffer marked full 
logically different xc physically occupies space corresponding 
weight output buffer sum weights input buffers 
describe elements stored illustrates collapse operation 
consider making copies element sorting input buffers account multiple copies 
elements simply equally spaced elements sorted sequence 
odd elements positions jw gamma 
call quantity offset collapse 
choices choose elements positions jw positions jw gamma 
collapse operator alternates choices successive invocations 
short denote offset output buffer offset contents described consisting elements positions jw offset gamma 
easy see multiple copies elements need materialized 
outputs stored identified follows sort input buffers individually start merging 
merging element just selected originates buffer counter initialized zero gets incremented times 
counter hits value corresponds position populated selected element marked left unmarked 
marked elements collected input buffers labeled full remaining input buffers labeled empty 
denote total number collapse operations carried course algorithm 
denote sum weights output buffers produced operations 
lemma sum offsets collapse operations gamma proof codd codd number collapse operations weight output buffer odd respectively 
number collapse operations offset output buffer number collapse operations offset output buffer clearly sum offsets odd collapse alternates choices offsets weights output buffer gamma sum offsets gamma output operation output performed exactly just termination 
takes full input buffers xc size outputs single element corresponding approximate oe quantile augmented dataset 
recall oe quantile original dataset corresponds oe quantile augmented dataset consists original elements plus gamma elements added buffer 
similar collapse operator copies element sorts input buffers multiple copies element account 
output element position doe delta delta delta xc 
algorithm computing approximate quantiles consists series invocations new collapse terminating output 
new populates empty buffers input collapse reclaims collapsing chosen subset full buffers 
output invoked final set full buffers 
different buffer collapsing policies correspond different algorithms 
describe interesting policies 
collapse policies munro paterson empty buffer invoke new invoke collapse buffers having weight 
ranka singh fill empty buffers invoking new invoke collapse 
repeat times invoke output resulting buffers 
new algorithm associate buffer integer denotes level 
smallest levels currently full buffers 
exactly empty buffer invoke new assign level 
empty buffers invoke new assign level 
empty buffers invoke collapse set buffers level 
assign output buffer level 
analysis section see sequence operations carried algorithm looked tree buffers 
analyze tree show error bounds quality output 
show compute values minimize memory different collapsing policies 
tree representation sequence operations carried algorithm represented tree 
vertex set tree root set logical buffers initial intermediate final produced computation 
clearly number physical buffers algorithm 
leaves tree correspond initial buffers get populated incoming 
edge drawn input buffer output buffer collapse operation 
root corresponds final output operation 
children root final buffers produced 
draw broken edges children root 
see figures trees resulting munro paterson algorithm ranka singh algorithm new collapsing policy proposed 
labels nodes correspond weights 
figures leaves get populated left right 
collapse operation corresponding non leaf node invoked soon operands corresponding children node ready 
tree munro paterson algorithm buffers 
node labeled weight 
tree ranka singh algorithm buffers 
node labeled weight 
tree new collapsing scheme buffers 
node labeled weight 
possible collapsing policies representable trees 
possible vary buffer sizes 
schemes scope 
approximation guarantees denote number leaves tree 
denote number collapse operations number non leaf non root nodes 
denote sum weights collapse operations 
wmax denote weight heaviest child root 
see quick list symbols analysis 
section prove difference rank true oe quantile original dataset output produced algorithm gammac gamma wmax require simple results claim re state lemma 
reader wishes skip proof jump section loss continuity noting claim holds tree leaves weight non leaves children 
leaves need level 
lemma sum weights top buffers children root number leaves 
output algorithm 
say element input sequence definitely small assert smaller similarly say element definitely large evidence larger analysis proceeds phases describe procedure identify definitely small elements mark 
describe counting technique establish fairly large number elements 
identification procedure starts top buffers children root 
mark elements buffers definitely small definitely large depending smaller larger element belongs categories 
children root leaves ignore 
children children outputs collapse operations 
consider output buffer children 
elements children smaller definitely small element output marked definitely small 
similarly elements children larger definitely large element output marked definitely large 
see example 
continue fashion leaves processed 
user specified size dataset oe quantile computed ffl approximation guarantee number buffers size buffer oe quantile augmented dataset consisting gamma elements number collapses sum weights collapses wmax weight heaviest collapse number leaves tree height tree list important symbols analysis 
consider sets definitely small definitely large elements children root 
lemma infer output selects element position doe kle sorted sequence copies elements 
place interesting bound number definitely small elements buffers certainly place weighted sum weight element weight buffer originates 
holds definitely large elements 
denote weighted sum definitely small elements top buffers children root 
denote weighted sum definitely large elements buffers 
lemma doe kle gamma wmax doe kle gamma kl gamma doe kle gamma wmax kl gamma doe kle consider node tree corresponding collapse operation 
definitely small elements 
weighted sum elements sw 
consider largest element set definitely small elements 
element position gamma offset sorted sequence elements children element having duplicated times weight child originates 
weighted sum definitely small elements children smaller largest definitely small element gamma offset written sw gamma offset 
see figures illustration argument 
similarly argue definitely large elements weighted sum weighted sum definitely large elements children gamma gamma offset 
shown weighted sum definitely large elements children node smaller gamma offset weighted sum definitely small definitely large elements 
suggests counting technique maintain set buffers weighted sums definitely small definitely large elements buffers 
initial set set top buffers weighted output weight definitely small definitely large sorted sequence offset input weight weight weight definitely small definitely large identification definitely small definitely large elements illustrated intermediate node tree corresponding input output buffers 
sums respectively 
repeatedly replace non leaf set children update weighted sum definitely small definitely large elements 
process stops traveled leaves non leaf remains set 
denote weighted sum definitely small definitely small elements set leaf buffers 
weight leaf fact number definitely small definitely large elements augmented dataset exactly values interest 
lemma gamma gamma gamma gamma proof starting top buffers children root initial weighted sums definitely small elements respectively 
know collapse operation corresponding node diminishes weighted sum definitely small elements gamma offset 
travel leaves hit node get diminished gamma offset 
total amount diminished sum weights collapse operations minus sum offsets collapse operations 
quantity exactly lemma second quantity gamma gives desired bounds lemma difference rank true oe quantile original dataset output produced algorithm gammac gamma wmax munro paterson algorithm number buffers size buffer total memory bk ffl ranka singh algorithm number buffers size buffer total memory bk ffl new algorithm number buffers size buffer total memory bk ffl sampling followed new algorithm confidence number buffers size buffer total memory bk ffl table number buffers size buffer total memory bk 
proof leaves leaf buffer worth elements total kl elements augmented dataset 
true oe quantile augmented dataset lies position doe kle 
output element position small large kl gamma difference true oe quantile output algorithm large doe kle gamma gamma kl gamma gamma doe kle 
lemma deduce sigma oe kl upsilon gamma gamma sigma oe kl upsilon gamma gamma gamma substituting doe kle gamma wmax lemma obtain sigma oe kl upsilon gamma gamma gamma gamma wmax exactly bound established quantity kl kle similar argument 
difference ranks element output root true oe quantile augmented dataset gammac gamma wmax true oe quantile augmented dataset true oe quantile original dataset get desired result 
munro paterson algorithm munro paterson algorithm requires buffers leaf level buffer level tree root 
height tree including root children root inputs final output operation 
collapsing scheme described munro paterson original stipulates exactly gamma leaves final output operation carried buffers weight gamma assume restrictions analyzing algorithm 
munro paterson tree height sum weights collapse operations gamma gamma total number collapse operations gamma gamma 
heaviest collapse operation wmax gamma plugging values lemma obtain difference rank output algorithm true oe quantile gammac gamma wmax gamma gamma number ffln output ffl approximate quantile 
optimal values 
objective minimize bk amount memory needed subject constraints gamma gamma ffln gamma constraint ensures approximation error ffl 
second constraint ensures number elements leaf buffers combined gamma leaves worth elements 
practice optimal values calculated computing maximum integral satisfies gamma gamma ffln lie log ffln binary search 
compute smallest integral satisfies gamma values total memory required listed practical values ffl table 
ranka singh algorithm ranka singh algorithm assume 
weighted sum collapse operations total number collapse operations weight heaviest collapse operation wmax number leaves plugging values lemma obtain difference ranks output algorithm true oe quantile original dataset gammac gamma wmax simplifies gamma number ffln optimal values obtained minimizing bk subject constraints gamma ffln practice optimal value obtained computing largest integral satisfies constraint computing smallest integral satisfies second 
values total memory required practical values ffl listed table 
new algorithm new collapsing policy values wmax functions height tree denote munro paterson tree height ranka singh tree height 
height new tree restricted height number leaves tree gamma gamma gamma delta number collapse operations gamma gamma gamma delta gamma 
weighted sum collapse operations gamma gamma gamma gamma delta gamma gamma gamma gamma delta weight heaviest collapse wmax gamma gamma gamma delta objective minimize bk subject constraints 
constraint gammac gamma wmax ffln equivalent gamma gamma gamma gamma delta gamma gamma gamma gamma delta gamma gamma gamma delta ffln second constraint kl equivalent gamma gamma gamma delta practice optimal values computed trying different values range 
compute largest integral satisfies constraint 
compute smallest integral satisfies second constraint 
identify value minimizes bk 
values memory requirements new algorithm listed table practical values ffl 
performance comparison table deduced new algorithm better terms space required 
shows amount memory varies increasing ffl held constant 
new algorithm clear winner 
log base comparison algorithms epsilon ranka singh munro paterson new algorithm memory requirements ffl 
curve munro paterson algorithm merit explanation 
algorithm stipulates exactly gamma leaves tree 
recall section minimize bk total memory requirement subject constraints gamma gamma ffln gamma grows largest satisfies inequality increases 
increases successive values smallest value satisfies second constraint diminishes roughly half resulting similar reduction product bk total memory required 
multiple quantiles analysis culminating lemma holds number quantiles simultaneously 
algorithm framework computes multiple quantiles approximation guarantees extra cost 
space complexity space complexity new algorithm determined restricting constraint gammac gamma wmax ffln weakened gamma delta ffln yielding log ffln 
second constraint obtain ffl log ffln space complexity ffl log ffln 
asymptotically algorithm space complexity 
theorem possible compute ffl approximate oe quantile dataset size single pass ffl log ffln memory oe 
curves new algorithm munro paterson algorithm parabolic appear straight lines limited range log shows constant new algorithm clearly better 
ranka singh algorithm ffln ffl total memory requirement ffl 
explains exponential curve algorithm 
parallel version new algorithm easily parallelized partitioning input stream statically dynamically processors 
root nodes partition concatenated form input stream final output phase outputs different quantiles 
approach scales linearly degree parallelism final sampling followed new algorithm sample size number buffers size buffer total memory bk ffl ffi gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma table memory required sampling running new approximate quantile finding algorithm different ffl ffi 
phase 
moderate degrees parallelism nodes final phase insignificant large data sets 
higher degrees parallelism 
outputs root gates partitioned arbitrarily smaller number processors 
new roots combined final step single processor 
sampling algorithm section show deterministic algorithm section coupled sampling obtain remarkable reductions space large size dataset 
interestingly space required independent tackle problem oe ffl ffi design single pass algorithm compute ffl approximate oe quantile dataset size little main memory possible output guaranteed correct probability gamma ffi 
require inequality due hoeffding lemma hoeffding inequality xn independent random variables ex denote expectation pr gamma ex exp gamma big picture 
ffl ffl ffl describe ffl ffl fixed 
assume possible choose sample say size total elements guaranteed probability gamma ffi set elements pair positions oe sigma ffl se sorted sequence sample subset set elements pair positions oe sigma ffl sorted sequence original dataset 
run new deterministic algorithm section samples stipulating accuracy ffl algorithm guarantees outputs quantile ffl elements away true quantile sample 
coupled guarantee element ffl elements away original dataset probability gamma ffi scheme works 
crucial question ffl ffl ffi big sample require 
lemma ffl ffl ffl total ffl log ffi gamma samples drawn population elements guarantee set elements pair positions oe sigma ffl se sorted sequence samples subset set elements pair positions oe sigma ffl sorted sequence elements 
proof say sample bad satisfy property mentioned lemma 

sets oe gammaffl oe ffl denote set elements preceding oe gammaffl quantile succeeding oe ffl quantile elements respectively 
sample size bad oe gamma ffl se elements drawn oe gammaffl gamma oe ffl se elements drawn oe ffl probability oe gamma ffl se elements drawn oe gammaffl bounded follows 
process drawing sample size population elements corresponds independent bernoulli trials coin tosses probability oe gamma ffl 
expected number successful trials oe gamma ffl number successful trials oe gamma ffl se sample bad 
probability occurs gamma ffl hoeffding inequality 
symmetric argument shows probability gamma oe ffl se elements drawn oe ffl gamma ffl probability ffi sample bad gamma ffl solving obtain ffl log ffi gamma 
interestingly number samples independent fixing ffl ffl ffl ff 
ffl gamma ff ffl 
ff approaches number samples increases 
ff approaches zero approximation guarantee required deterministic algorithm increases 
case memory requirements blow 
clearly optimal value ff minimizes memory 
compute optimal value ff 
practical values ffl ffi compute memory requirements different values ff increments minimum value lies 
see table memory requirements different ffl ffi 
theoretically complexity determined fixing ff constant say 
number samples ffl gamma log ffi gamma 
section new deterministic algorithm requires ffl gamma log ffln space elements space requirements running samples ffl gamma log ffl gamma log ffi gamma 
theorem possible compute ffl approximate oe quantile probability success ffi arbitrary sized dataset single pass ffl gamma log ffl gamma ffl gamma log log ffi gamma space 
sample sample idea sample new quantile finding algorithm 
fixed value ffl ffi threshold value better sampling 
threshold value obtained computing minimum memory required fixed value ffl ffi technique outlined earlier section computing maximum ffl approximate quantile computed amount memory 
see threshold values ffl 
epsilon threshold value confidence threshold threshold value confidence 
multiple quantiles want compute different quantiles error bound ffl confidence gamma ffi quantiles ffl approximate approach works ffl ffl ffl ffl gamma log gamma 
choose samples feed deterministic algorithm stipulating accuracy ffl read quantiles single quantile final collapse operation 
quantiles guaranteed probability gamma ffi ffl approximate 
optimal values ffl ffl calculated technique outlined earlier section 
proof correctness approach simple ffi ffi lemma argue probability particular quantile fails ffl approximate ffi follows probability quantile fails ffl approximate simply ffi 
theorem deduce dependence total amount memory required number quantiles log log 
cost computing quantiles great 
note multiple quantiles require extra memory run deterministic algorithm section random sampling probabilistic guarantees error bounds multiple quantiles necessitates slightly larger sized sample turn increases memory requirements small log log factor 
simulation results analysis new deterministic algorithm worst case scenario 
practice approximate quantile output root gate really deviates exact value ffl 
claim experimental results datasets different sequences ranks elements 
note exact values data elements consequence 
permutation ranks sorted order matters 
study kinds permutations sorted random 
fix ffl gamma compute quantiles positions 
results tabulated table 
observed ffl sorted random table final error obtained running new algorithm different sized datasets ffl 
clear actual error obtained better ffl started 
described algorithms computing approximate quantiles guaranteed error bounds single pass large online disk resident datasets 
algorithms require substantially memory previously published results 
shown reduction memory achieved coupling sampling approximate quantile computing algorithm 
interestingly certain dataset sizes memory requirement independent size dataset cost probabilistic confidence approximation guarantee 
derived important parameters algorithms varying input sizes error bounds quantiles needed 
memory requirements accuracy guarantees experimental results new algorithms show practical safe deliver order statistics aggregation database users exploit query optimization data partitioning 
clearly delineated tradeoff accuracy quantile memory requirements poses challenging choice users algorithm 
cases analysis may able quantify cost benefit accuracy particular applications 
cases user judgment may required choose appropriate error bound 
practical implementations real relational database management systems challenged need support additional parameters oe ffl ffi sql column functions single parameter point 
require ingenuity handle multiple quantiles efficiently column select quantile col quantile col 
addition non trivial memory requirements probably require tricky extensions group execution environment system 
selinger astrahan price access path selection relational database management system acm sigmod june 
piatetsky shapiro accurate estimation number tuples satisfying condition acm sigmod boston june 
poosala ioannidis haas shekita improved histograms selectivity estimation range predicates acm sigmod pp 
montreal june 
db mvs informix dewitt naughton schneider parallel sorting shared architecture probabilistic splitting proc 
intl 
conf 
parallel distributed inf 
sys pp 
miami beach 
blum floyd pratt rivest tarjan time bounds selection comput 
syst 
sci vol 
pp 

paterson progress selection 
computer science university warwick coventry uk 
dor selection algorithms phd thesis tel aviv university 
dor zwick selecting median proc 
th annual acm siam symp 
discrete algorithms pp 

dor zwick finding ffn th largest element combinatorica vol 
pp 

dor zwick median selection requires ffl comparisons technical report department computer science tel aviv university apr 
yao lower bounds selection problems technical report mac tr massachusetts institute technology 
pohl minimum storage algorithm computing median technical report ibm research report rc ibm watson center nov 
munro paterson selection sorting limited storage theoretical computer science vol 
pp 

jain chlamtac algorithm dynamic calculation quantiles histograms storing observations cacm vol 
pp 

agrawal swami pass space efficient algorithm finding quantiles proc 
th intl 
conf 
management data india 
ranka singh pass algorithm accurately estimating quantiles data proc 
rd vldb conference athens greece 
hoeffding probability inequalities sums bounded random variables american statistical association pp 
mar 
