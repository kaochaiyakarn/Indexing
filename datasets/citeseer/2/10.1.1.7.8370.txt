modeling inverse covariance matrices basis expansion olsen ramesh gopinath ibm watson research center parkway yorktown heights ny ibm com proposes new covariance modeling technique gaussian mixture models 
specifically inverse covariance precision matrix gaussian expanded rank basis aka ak generalized em algorithm proposed obtain maximum likelihood parameter estimates basis set expansion coefficients model called extended maximum likelihood linear transform emllt model extremely flexible varying number basis elements gradually moves maximum likelihood linear transform mllt model full covariance model 
experimental results speech recognition tasks show emllt model give relative gains word error rate standard diagonal covariance model 

state art speech recognition systems continuous parameter hidden markov models hmms state represented gaussian mixture model gmm 
computational storage robust estimation considerations typically diagonal covariance gmms practical systems 
significant improvement mllt model data transformed non singular linear matrix prior modeling diagonal covariance gmm 
mllt global semi tied covariances 
key idea view mllt expansion precision matrices gaussians tied basis exactly elements row determining basis element 
viewpoint suggests natural generalization basis elements leads extended mllt emllt model 
precision matrix contains exactly free parameters follows basis need basis elements 
controlling number nature basis elements emllt gradually moves diagonal covariance mllt full covariance model 

emllt model standard gmm parameters form xj parameters satisfy requirements positive definite matrix 
precision matrix diagonal covariance gmm model diagonal say diag 
case note precision matrix form eke ek th coordinate vector mllt model linear transformation precision matrix form diagonal matrix inverse covariance entries say diag 
case form aka th row expansion coefficients inverse variance interpretation positive positive definite 
diagonal covariance model mllt model approximate precision matrix subspace spanned basis basis shared gaussians 
leads emllt model set vectors generates basis precision matrices represented aka parameters emllt model emllt model trivial generalization mllt model significant differences mllt case coefficients required positive 
set chosen positive definite 
mllt case estimation trivial ak sample covariance th gaussian 
general emllt case provide algorithms iterative update parameters 
algorithms nice property initial set values associated positive definite updated values automatically satisfy property 

relationship similar models papers past modeling covariance matrices gaussian mixture models 
single gaussian density exponential family precision matrix canonical parameter natural try model inverse covariances tied fashion 
precisely emllt model 
alternative generalization mllt model called mlt multiple linear transformations model proposed 
fundamental idea mlt method similar 
precise relationships follows mllt mlt index set dg ji full covariance ak ek ak form em en dg 
parameter estimation parameters emllt model estimated generalized expectation maximization em algorithm 
hmm context main aspect algorithm distinct diagonal covariance gmm case estimation idea cycle alternating estimations keeping fixed 
estimation fixed done numerical optimization 
estimation fixed hand elegant iterative algorithm 
mathematical theory algorithm omitted page limitations details 
outline main points 
training data fx step em algorithm full covariance gmm gives estimate ij ij ij ij ij soft count ij posteriori probability gaussian vector ij depend previous estimate parameters ij kn emllt model update means mixture weights remain 
update methods proposed multiplicative additive update formula 
updates guarantee likelihood training data decrease 
discussion update formulas consider fixed 
multiplicative formula assumes entries non negative 
trivially ensures estimates positive definite 
update rule ak ak 
update rule scales ratio previous model variance empirical variance measured direction ak yields conservative update preserves non negativity guaranteed positive definite consequently optimization problem occurring parameter unconstrained fixed 
additive update formula assumes initial value positive definite 
multiplicative update simultaneously re estimates values entries additive update changes variable time formula 
ak ak update unique maximum step generalized em algorithm variables fixed 
recomputed variable changed 
contrast prescribes updated re estimated 
fortunately change rapidly accounted sherman morrison woodbury formula 
ak 
aka 
ak requires arithmetic operations compared general matrix inversion 
additive update may allow negative positive definiteness unclear 
proved matrix stays positive definite iteration initial value positive definite 
update fixed step requires maximization increase value function log det trace function maximized subject constraint positive definite 
numerical optimization package may 
note constraining positive definite easily enforced comes considerable computational cost 
contrast multiplicative update rule matrix yield positive definite multiplicative case yields simpler robust estimation procedure additive update applied estimated example iterating multiplicative updates updates interesting note updating gave gains multiplicative update best performance achieved additive update applying change matrix 
parameter interpretation projection direction compute histogram projected training data fy similarly gaussian mixture model probability density distribution corresponding projection gaussian mixture model 
variance gaussian component projection estimation formulas previous section seen convergence reached model variance gaussians match empirical data variance projections ak strictly speaking multiplicative update convergence reached ak ak words emllt model histogram matches gmm density projection directions rows matrix rows get better model projection demonstrates graphically 
diagonal covariance model large emllt model trained data 
shows histogram gmm plotted graph random projection acoustic models 
clear mismatch histogram gmm diagonal covariance model dramatic improvement emllt model 

experimental results experiments comparing emllt mllt model performed speech recognition tasks 
speech recognition tasks ibm internal databases car database telephony database respectively 
emllt models built additive update multiplicative update 
matrix initialized follows hmm states split groups similarity american english phonemes fricatives stops 
emllt matrix initialized stacking mllt matrices built group hmm states top 

car test set speech recognition system test set experiments described 
test set recorded car environment consisted total words 
test set divided tasks addresses command control digits radio control 
tasks recorded car different velocities mph mph diagonal mllt emllt wer wer wer table 
speech recognition word error rates percentages car test set 
mph 
test set contains total words subtasks contains roughly words subtasks contains roughly words 
baseline system dimensional feature vectors consisting dimensional cepstral vectors corresponding second order derivatives 
baseline system grammars medium size vocabulary 
acoustic model phonemes word specific digit task 
total hmm states necessarily digit specific 
system total gaussian components 
detailed breakdown results see 

experimental results car test set table describes experimental results car test set 
notice emllt systems gradually improve performance yielding best system relative gain baseline diagonal covariance system baseline mllt system 
baseline diagonal mllt models substantially fewer parameters compared emllt models 
built diagonal covariance models emllt models gaussians match number parameters emllt systems 
table shows performance emllt systems substantially better 
performance full covariance system emllt model gaussians gave error rate 

telephone test set acoustic models built hours training data speakers 
acoustic features standard dimensional lda mllt features built mfcc cepstral ms frame rate 
baseline diagonal covariance acoustic model hmm states gaussians 
test suite grammar tasks stocks mutual funds directory names digits yellow pages 
script words 
histogram vs emllt histogram pdf random projection diag gmm histogram vs diagonal covariance gmm histogram pdf random projection fig 

histogram gaussian mixture comparison emllt diagonal covariance model random projection additive multiplicative table 
speech recognition word error rates percentages telephony test set emllt systems different sizes mllt system 

experimental results telephone test set emllt models built additive multiplicative update rules matrix initialized exactly car test set 
table shows results 
relative improvement mllt model obtained additive emllt model 

emllt model allows flexibly model covariances 
emllt model generalizes known covariance modeling techniques 
compared mllt model flexibility emllt model exploited give excellent performance improvements 
approaches covariance modeling investigated mlt multiple mllt transforms 
emllt gaussians modeled subspace 
emllt model discriminative yields better performance approaches 
acknowledgments authors scott axelrod goel jiri michael harry insightful comments helpful discussions 

gopinath maximum likelihood modeling gaussian distributions classification proceedings icassp seattle usa vol 
ii pp 

gales semi tied covariance matrices hidden markov models ieee transactions speech audio processing 
goel gopinath multiple linear transforms proceedings icassp salt lake city usa vol 
gales factored semi tied covariance matrices proceedings nips denver usa 
dempster laird rubin maximum likelihood incomplete data em algorithm journal royal statistical society 
maximum likelihood estimation multivariate observation markov sources ieee transactions information theory 
olsen gopinath extended mllt gaussian mixture models transactions speech audio processing submitted www research ibm com people olsen trans sap ps 
golub van loan matrix computations johns hopkins university press baltimore 
course phonetics harcourt brace jovanovich 
deligne eide gopinath olsen low resource speech recognition word vocabularies proceedings sixth european conference speech communication technology aarhus denmark september 
