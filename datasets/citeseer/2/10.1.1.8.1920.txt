cs self tuned congestion control multiprocessor networks alvin lebeck mukherjee department computer science duke university durham nc 
cs duke edu alpha development group compaq computer ma 
mukherjee compaq com department computer science duke university durham north carolina november self tuned congestion control multiprocessor networks alvin lebeck mukherjee department computer science duke university durham nc 
cs duke edu alpha development group compaq computer ma 
mukherjee compaq com network performance tightly coupled multiprocessors typically degrades rapidly network saturation 
consequently designers keep network saturation point reducing load network 
congestion control source throttling common technique reduce network load prevents new packets entering network presence congestion 
unfortunately prior schemes implement source throttling lack vital global information network correct decision throttle depend specific network parameters network topology communication patterns 
presents global knowledge self tuned congestion control technique prevents saturation high loads different network configurations communication patterns 
design composed key components 
global information network obtain timely estimate network congestion 
compare estimate threshold value determine throttle packet injection 
second component self tuning mechanism automatically determines appropriate threshold values throughput feedback 
combination techniques provides high performance heavy load penalize performance light load gracefully adapts changes communication patterns 
tightly coupled multiprocessors provide performance ease programming necessary commercial scientific applications 
interconnection networks provide low latency high bandwidth communication required variety workloads 
advent multiprocessor systems built highly aggressive order speculative microprocessors simultaneous multithreaded processors chip multiprocessors promises dramatically increase offered load multiprocessor networks 
unfortunately multiprocessor networks suffer tree saturation heavy load key performance bottleneck 
tree saturation occurs multiple packets contend single resource link nodes creating hot spot 
packet resource packets wait 
waiting packets occupy buffers delay packets may destined completely different node share link paths respective destinations 
process continues waiting packets delay packets producing tree waiting packets fans original hot spot 
performance degradation caused network saturation severe illustrated 
axis corresponds delivered bandwidth flits node cycle axis shows offered load terms packet injection rate packets node cycle 
lines correspond different communication patterns randomly selecting destination node random node number significant significant bits switched destination butterfly 
important observations 
communication patterns incur dramatic reductions throughput network reaches saturation 
second observation network saturates different points different communication patterns 
normalized accepted traffic packets node cycle packet injection rate packets node cycle random butterfly 
performance breakdown network saturation network adaptive routing deadlock recovery way prevent network saturation source throttling prevents source node packet injection congestion detected 
oracle achieve knowing communication pattern packet injection rate maximizes performance 
challenge develop realistic implementation prevent network saturation adapt variations communication patterns 
presents self tuned source throttling mechanism multiprocessor interconnection networks 
solution comprised key components technique obtain global knowledge network state self tuning mechanism automatically determine network saturation occurs 
global knowledge number full network buffers estimate network congestion 
global information allows detect congestion earlier alternative approaches wait network backpressure create locally observable indicators congestion local buffer occupancy timeouts 
global estimate compared threshold control packet injection 
estimate higher threshold packet injection stopped 
estimate drops threshold packet injection resumed 
second key aspect source throttling implementation self tuning mechanism monitors network throughput automatically determines appropriate threshold value 
eliminates manual tuning allows scheme adjust variations communication patterns 
believe congestion control mechanism generally applicable broad range packet switched multiprocessor networks including virtual cut networks wormhole networks 
evaluate technique context wormhole switched ary cube networks 
simulation results ary cube node network show congestion control technique prevents severe performance degradation caused network saturation 
limiting packet injection scheme sustains high throughput low latency 
compared alternative approach uses local estimates congestion scheme superior global congestion estimation enables technique detect congestion early stages 
show single static threshold accommodate communication patterns single threshold workloads prevent saturation ones 
contrast simulations reveal self tuning technique automatically adapts various communication patterns including bursts different patterns 
remainder organized follows 
section provides background information discusses related 
section section section section discuss key innovations 
section presents proposed global information gathering scheme 
section describes self tuned congestion control scheme 
section presents experimental methodology simulation results 
section summarizes 
background related high performance interconnection networks tightly coupled multiprocessors achieved wormhole cut switching adaptive routing multiple virtual channels 
cray sgi origin machines combination techniques interconnection networks 
systems communication occurs sending packets information routed independently network 
packet composed flits flow control units transferred network nodes 
wormhole routing cut switching suffer network saturation 
wormhole switching node receives header flit typically contains routing information immediately selects route forwards flit node 
provide low latency compared store forward routing entire packet received node forwarding 
packet blocks wormhole network flits occupy buffer space network nodes exacerbate tree saturation 
contrast routers cut switching buffer blocked packets router 
cut switching suffer tree saturation router buffers fill 
adaptive routing dynamically chooses multiple potential routes current local network state 
help alleviate effects tree saturation experienced deterministic routing algorithms heavy load provide higher performance 
unfortunately full adaptive routing cause potential deadlock cycles exacerbate network saturation 
adaptive routing helps alleviate light moderate congestion focus source throttling congestion control technique prevent network saturation 
virtual channels allow multiple packets share single physical link reducing effects tree saturation eliminate deadlocks 
deadlock avoidance schemes preventing cyclic dependencies storage resources 
particular consider scheme reserves small set virtual channels deadlock free routing remaining virtual channels fully adaptive routing 
technique guarantees forward progress packets routed special channels deadlock eventually free resources fully adaptive channels 
deadlock recovery alternative deadlock avoidance potentially achieve higher performance 
deadlock recovery uses full adaptive routing virtual channels detects deadlocks occur typically timeouts recovers routing packets deadlock free path uses central node buffer 
approach imagined containing virtual networks suffer deadlock guaranteed deadlock free 
main difference approach uses node buffer deadlock avoidance scheme requires buffers physical channel 
deadlock avoidance recovery frequency deadlocks adaptive channels increases dramatically network reaches saturation 
occurs packets delivered relatively limited escape bandwidth available deadlock free paths 
causes sudden severe drop throughput corresponding increase packet latency 
crucial avoid network saturation systems 
keep network saturation avoid resulting performance degradation necessary implement congestion control mechanism 
mechanism self tuning eliminating need system designer administrator application programmer tune various parameters allowing system adapt changes communication patterns load levels network topologies 
self tuned system may require timely information global network state correctly tune congestion control algorithm 
remainder section examines prior congestion control mechanisms tightly coupled multiprocessors context desirable properties 
examine congestion control mechanisms lans wans discuss applicability techniques tightly coupled multiprocessors 
related previous congestion control multiprocessor networks relies estimating network congestion independently node limiting packet injection network predicted near saturation 
reduces problem finding local heuristic node estimate network congestion 
lopez number busy output virtual channels node estimate congestion 
propose approach counts subset free useful virtual channel buffers decide throttle 
schemes rely local symptoms congestion lack knowledge global network state unable take corrective action timely manner 
reduces effectiveness different network load levels communication patterns 
describe form global congestion control 
node detects congestion time outs signals nodes network limit packet injection 
approach requires tuning appropriate timeouts timeouts tuned robustness higher loads performance penalty light loads 
scott sohi describe explicit feedback inform nodes tree saturation imminent multistage interconnection networks 
approach requires tuning thresholds 
ease exposition assume network node contains processor memory network router 
technique proposed kim allows sender kill packet experienced delays threshold 
approach pads shorter packets ensure sender kill packet time flit reaches destination 
cause larger overheads short messages sent distant nodes 
techniques congestion control multiprocessor networks attempt prevent network saturation heavy loads 
unfortunately techniques require tuning lack necessary information network global state take preventive actions timely fashion provide high performance traffic patterns offered load levels 
flit reservation flow control alternative flow control technique improves network utilization saturation occurs 
uses control flits schedule bandwidth buffers ahead arrival data flits 
results better re buffers waiting feedback neighboring nodes free buffers 
panda demonstrate consumption channels bottleneck exacerbate tree saturation 
show saturation bandwidth increased having appropriate number consumption channels 
lans local area networks wans wide area networks self tuned congestion control techniques 
various flavors self tuning congestion avoidance control techniques tcp protocol 
tcp congestion control mechanism uses time outs dropped unacknowledged packets locally estimate global congestion throughput 
congestion detected size sliding window controls number unacknowledged packets flight reduced 
floyd jacobson proposed scheme tcp packets dropped router feels congestion imminent 
dropped packets give early indication hosts take corrective action scale back offered load 
floyd proposed modification tcp packets explicitly sent hosts 
ramakrishnan jain describe similar mechanism decbit explicitly notify congestion gateways set ecn explicit congestion notification bit depending average queue size 
congestion control atm uses explicit packets called resource management rm cells propagate congestion information 
switches packet path modify bits rm cells indicate highest data rate handle 
hosts limited maximum data rate indicated switches overwhelm network switches 
congestion control mechanisms lans wans directly applicable multiprocessor networks 
lans wans drop packets higher network layers retransmit dropped packets reliable communication 
dropped packets serve implicit hints network congestion 
multiprocessor networks typically expected guarantee reliable communication 
additional complexity built store retransmit dropped packets 
alternative idea propagating congestion information explicitly 
challenge determining appropriate set mechanisms policies required provide self tuned congestion control implementation preventing saturation multiprocessor networks 
solution regular interconnection networks adaptive routing wormhole switching deadlock recovery deadlock avoidance 
solution key innovations collectively overcome limitations previous congestion control techniques 
global knowledge congestion estimation enables timely estimate network congestion 
second component self tuning mechanism automatically determines saturation occurs allowing throttle packet injection 
sections elaborate key components 
global congestion estimation congestion control implementation requires timely way detect network congestion 
previous techniques estimate network congestion locally observable quantity local virtual buffer occupancy packet timeouts 
estimates correlated network congestion claim waiting local symptoms network congestion useful primarily time network overloaded 
consider case network congestion develops distance node 
schemes local heuristics estimate congestion rely back pressure propagate symptoms congestion node filling buffers increase queue delays 
node takes corrective action congestion symptoms observed locally 
possible detect network congestion early stages global conditions account 
achieve fraction full virtual channel buffers nodes network metric estimate network congestion 
ensures far away congestion accounted early take corrective action 
additional cost hardware latency propagate global information 
scheme counts full buffers estimate congestion take distribution full buffers nodes account 
glance appears serious limitation scheme unable distinguish case localized congestion large fraction full buffers relatively nodes network benign case number full buffers distributed evenly nodes network 
adaptivity self tuning mechanism reduces impact problem setting threshold differently cases 
mechanism set higher threshold benign case case localized congestion 
section show global information gathered reasonable cost achieve robust self tuned congestion control implementation 
implementing global information gather technique requires node network aware aggregate number full buffers throughput entire network 
explain relationship full buffers offered load delivered bandwidth section 
variety ways implement communication 
section discuss alternatives piggybacking meta packets dedicated side band 
approach distribute information network piggy back extra information normal packets 
approach disadvantage difficult guarantee communication 
nodes involved communication see piggy backed information possible nodes see information extended period time 
reduce accuracy congestion estimate reducing effectiveness congestion control scheme 
alternative approach send special meta packets containing congestion throughput information 
required communication guaranteed approach 
guaranteeing delay bounds may involve additional complexity 
meta packets flooding network consume bandwidth may add congestion 
adding high priority virtual channel reserved meta packets may way addressing concerns 
exclusive side band reserved communicating congestion throughput information 
implementation terms additional hardware complexity 
easy guarantee delay bounds communication affect performance main data network 
extra bandwidth available side band general packet routing postpone network saturation short time provide complete solution congestion control scheme 
discussion see issues surrounding global information gathering mechanism 
includes thorough examination issues implementations 
side band incurs neighbor neighbor communication delay cycles 
dimension wise aggregation scheme 
node communicates number full buffers throughput directions lowest dimension network 
node receives information computes aggregate aggregate information neighbors zeroth dimension hops cycles 
nodes communicate aggregates neighbors higher dimension 
continuing procedure dimension global aggregation full duplex ary cube network completes cycles 
assuming network configuration takes cycles 
refer time communication gather duration 
mechanism described provides cycle delayed snapshots network congestion cycles 
congestion control policy requires compare cycle current estimated congestion threshold 
re currently time observed previous network snapshots estimate network congestion time previous snap shots global network congestion 
simplest solution state observed immediately previous network snapshot snapshot available 
slightly sophisticated method estimate network congestion computes linear extrapolation previous network snapshots 
general prediction mechanism previously observed network states predict network congestion 
leave evaluation alternative prediction techniques 
average linear extrapolation technique yields improvement throughput deadlock avoidance configuration deadlock recovery configuration 
communicate congestion information nodes exchange full buffer counts 
number bits needed represent information depends number buffers network 
specify network configuration number bits needed represent congestion information configuration section 
summary global measurement virtual buffer occupancy provides early estimate network congestion 
estimate compared threshold determine packet injection resume 
obtaining information global state network part solution 
translate congestion estimate congestion control properly choose threshold 
self tuning mechanism described section dynamically tunes full buffers 
throughput vs full buffers drop bandwidth 
currently throttling 
decrement decrement increment change table 
tuning decision table threshold appropriate values 
self tuning mechanism proper threshold selection crucial component congestion control implementation 
inappropriate threshold values produce unstable behavior high loads unnecessarily limit performance light loads 
furthermore single threshold works communication patterns 
section presents technique automatically determine proper threshold value 
goal self tuning mechanism maximize delivered throughput dramatic increases packet latency 
view task optimization problem delivered bandwidth objective function dependent number full virtual buffers 
consider relationship offered load full buffers delivered bandwidth see 
offered load increases zero number full virtual buffers delivered bandwidth increase 
saturation occurs delivered bandwidth decreases number full virtual buffers continues increase 
self tuning technique attempting find number full virtual buffers threshold value maximizes delivered throughput 
achieve hill climbing algorithm including technique avoid local maxima 
obtain measure global network throughput objective function manner similar way obtain global count full virtual buffers see section 
nodes exchange number flits delivered past cycles measure throughput 
consider maximum possible delivered bandwidth flit node cycle count exceed 
hill climbing automatically tune threshold initial value network parameters buffers 
intuition relationship number full buffers delivered bandwidth specify tuning decision table indicates threshold value increased decreased 
low value lower prevents reaching peak throttling packet injection 
contrast high value pushes peak higher causing saturation just network congestion control 
table illustrates tuning decision table 
dimensions table correspond observed network throughput network currently throttled 
tuning decision tuning period 
say drop bandwidth throughput tuning period drops specified fraction throughput previous tuning period 
leave complex schemes adaptively modify frequency tuning network conditions 
tuning period exact multiple gather duration 
tuning period large slow inefficient tuning leading network underutilization network saturation 
small short lived troughs throughput alter estimate 
experiments reasonable range values cycles cycles performance alter significantly 
experiments cycle tuning period 
tuning process proceeds follows 
observe decrease throughput upper row decrease threshold value 
decreased throughput result network saturation decrease offered load 
cause saturation reduce threshold value bring network saturation 
offered load decreased safe reduce threshold system throttling 
system throttling drop throughput optimistically increase threshold 
drop throughput increase optimism justified lower threshold value throttling 
exceed saturation point increase threshold observed bandwidth decreases reduce threshold value 
throttling occurring decrease throughput change threshold value 
constant additive increments decrements update threshold value 
sophisticated algorithms tune threshold improves tuning mechanism reducing time reach sweet spot 
find constant additive tuning adequate effective self tuning explore complicated methods 
reasonable range values buffers performance insensitive variations increment decrement values 
marginally better performance decrement higher increment 
increment buffers decrement buffers 
ary cube network corresponds increment decrement 
re comparing throughput observed tuning period throughput observed previous tuning period possible bandwidth drop due saturation happens gradually treat sufficient trigger decrease threshold value 
network saturation hits local maximum 
hill climbing technique currently proposed fails move back local maximum 
increasing threshold keeps network saturation drop bandwidth 
section describe method scale back threshold away local maximum 
avoiding local maxima avoid settling local maxima remember conditions existed maximum throughput achieved 
keep track maximum throughput max achieved single tuning period remember corresponding number full buffers nmax threshold max 
throughput tune period drops significantly maximum throughput technique tries recreate conditions existed maximum throughput achieved 
setting threshold min tmax nmax 
nmax higher tmax means network throttling threshold value tmax achieved maximum observed throughput 
case set threshold tmax network throttle new packets drain existing packets till reaches desired load level 
hand nmax smaller tmax setting threshold nmax better choice possible tmax low prevent saturation 
guarantees re stuck local maximum network saturates 
possible threshold value sustains high throughput communication pattern low prevent saturation communication pattern 
congestion control mechanism detects adapts threshold changes 
find reset threshold min tmax nmax consecutive tuning periods means min tmax nmax value high prevent saturation recompute max value 
case reset max zero start maximum locating 
ensures threshold adapts changing communication patterns 
experiments 
summary discussion provides general overview technique believe provide robust self tuned congestion control 
scheme gathers full buffer counts throughput measurements cycles 
full buffer counts estimate current congestion linear extrapolation 
estimate compared threshold decide throttle new packets 
hill climbing algorithm update threshold cycles increments decrements total buffer count respectively 
hill climbing algorithm susceptible settling local maxima network saturation 
scheme includes mechanism prevent happening remembering maximum max observed throughput 
recompute maximum max reset threshold consecutive tuning periods 
high level scheme somewhat analogous tcp self tuning congestion control 
idea network performance 
expected round trip time rtt case tcp max throughput case 
schemes allow offered load incrementally increase long network performance penalized 
sliding window size increases long packets dropped case tcp threshold increases long decrease throughput case 
techniques take corrective action network performance suffers 
tcp reduces window size scheme decrements threshold resets min nmax tmax 
schemes periodically refresh estimate network performance 
tcp recomputes expected round trip time packets dropped scheme recomputes max nmax tmax max stale consecutive corrective actions 
evaluation section uses simulation evaluate congestion control technique 
describing evaluation methodology 
followed simulation results 
methodology evaluate congestion control scheme simulator 
simulate ary cube nodes full duplex physical links 
node injection channel packets sent node enter network delivery channel packets sent node exit network 
virtual channels physical channel edge buffers buffers associated virtual channels hold flits 
router arbiter central resource packet time cycle routing delay packet header 
packets obtain control router arbiter demand slotted round robin distribution 
bottleneck routing occurs header flit flit packet 
remaining flits simply stream header flit switch path 
takes cycle flit traverse cross bar switch cycle flit traverse physical link 
evaluate congestion control mechanism deadlock avoidance deadlock recovery mechanisms 
deadlock avoidance uses method proposed escape virtual channel oblivious dimension order routing 
progressive deadlock recovery scheme time cycles 
simulations execute cycles 
ignore cycles eliminate warm transients 
results parts normalized delivered throughput accepted flits node cycle average packet latency versus offered load terms packet injection rate 
default load consists node generating flit packets fixed rate 
consider different communication patterns uniform random bit reversal perfect shuffle butterfly 
communication patterns differ way destination node chosen source node bit ordinates gamma gamma 
bit coordinates destination nodes gamma gamma gamma perfect shuffle gamma gamma butterfly gamma gamma bit reversal 
results steady loads uniform random communication pattern 
results bursty load various communication patterns 
results steady loads bit reversal perfect shuffle butterfly communication patterns shown appendix synthetic workload full blown multiprocessor workloads reasons 
simulation environment handle full blown multiprocessor workloads 
second packet generation frequency corresponds realistic rates databases scientific applications gives confidence results 
third synthetic workloads nicely demonstrate problem network saturation avoids interactions application specific features 
network buffers bits count buffers network 
configuration needs bits represent maximum possible aggregate throughput maxt flits 
need total bits signals 
section show send bits bit channels little performance degradation 
comparison simulate alo congestion control scheme 
alo estimates global network congestion locally node 
virtual channel free useful physical channel useful output channel violating minimal routing constraint 
useful physical channel virtual channels free packet injection allowed 
new packets throttled 
simulation results primary simulations ffl technique provides high performance consistently different communication patterns offered load levels 
ffl technique outperforms alternative congestion control technique uses local estimates congestion 
ffl self tuning technique adapts threshold dynamically varying workloads bursty traffic 
remainder section elaborates items 
performance examining performance complete implementation described sections 
shows bandwidth latency uniform random traffic pattern deadlock recovery deadlock avoidance 
note logarithmic scale axis latency graphs 
curve base case illustrates network saturation problem 
load increases network throughput increases certain extent 
saturation sudden drop throughput escape channels available drain deadlocks 
configuration deadlock recovery lower bandwidth saturation deadlock recovery requires packet obtain exclusive access deadlock free path 
contrast deadlock avoidance schemes break multiple deadlock cycles concurrently 
results clearly show key point congestion control technique une stable high loads 
alo congestion control scheme improves performance early stages congestion deadlock avoidance case exhibit severe performance degradation eventually 
scheme maintains latency throughput close peak values 
effect delay consider effect varying delay time neighbor neighbor communication side band gather global information performance 
corresponds global aggregation time cycles 

note tuning period remains cycles 
note increasing side band communication delay viewed equivalent decreasing width factor 
example increasing hop delay factor alternately viewed decreasing side band width factor bits wide bits wide 
bits information sent units cycles transmission unit cycles 
intuitively know stale information useful fresh information 
case stale information directly 
linear extrapolation possible estimate current information stale information accuracy 
fact noisy curves linear extrapolation may reflect trends better increased sampling 
shows quantitatively performance losses due delays gathering global information 
see points tuning scheme works better cycle delay cycle delay 
points question linear extrapolation gives average increase throughput previous snapshot approach delay average increase throughput delay 
see delay cycles shows performance degradation due stale information 
self tuning section demonstrate important aspects self tuning technique 
show importance having congestion control mechanism adapts congestion characteristics different communication patterns 
followed examination hill climbing algorithm scheme avoid local maxima 
recall saturation occurs different levels offered load random butterfly communication patterns 
different levels offered load correspond different buffer occupancies network 
saturation occurring buffer occupancies different workloads chosen single static threshold prevent network deadlock recovery normalized accepted traffic packets node cycle packet injection rate packets node cycle uniform random tune base alo average latency cycles packet injection rate packets node cycle uniform random tune base alo delivered throughput vs offered load average latency vs offered load deadlock avoidance normalized accepted traffic packets node cycle packet injection rate packets node cycle uniform random tune base alo average latency cycles packet injection rate packets node cycle uniform random tune base alo delivered throughput vs offered load average latency vs offered load 
performance random traffic saturation 
show compares performance deadlock recovery network configuration congestion control mechanism static thresholds scheme 
consider uniform random solid lines butterfly dashed lines communication patterns 
see static threshold buffer occupancy works random traffic threshold unable prevent saturation butterfly communication pattern 
contrast static threshold buffer occupancy works butterfly communication pattern random traffic 
indicates buffer occupancy network saturates uniform communication patterns 
necessary self tuning mechanism adapts threshold communication patterns change 
understand behavior self tuning technique analyze operation specific configuration 
stated section gather period cycles tuning period cycles increment virtual channel buffers decrement virtual channel buffers 
load uniform random distribution packet regeneration interval cycles deadlock avoidance configuration 
parameters shows tuning threshold time duration simulation 
recall cycles ignored eliminate start transients 
shows throughput achieved interval 
hill climbing mechanism tries increase threshold long decrease bandwidth tries scale back bandwidth decreases 
settle local maximum decrease bandwidth happens gradually 
occurs network saturation throughput falls 
mechanism avoid local maxima hill climbing algorithm settle local maximum corresponding deep saturation 
solid line shows behavior 
gradual drop throughput begins approximately deadlock recovery normalized accepted traffic flits node cycle packet regeneration interval cycles latency cycles packet regeneration interval cycles delivered throughput vs offered load average latency vs offered load deadlock avoidance normalized accepted traffic flits node cycle packet regeneration interval cycles latency cycles packet regeneration interval cycles delivered throughput vs offered load average latency vs offered load 
effect global information gathering delays deadlock recovery deadlock avoidance 
cycles 
recall decrement threshold throughput drop tuning period 
see decrements gradual nature decrease throughput results rise threshold eventually saturating network 
dashed line shows behavior scheme avoid local maxima 
sharp dip threshold value specifically approximately cycles illustrates corrective action taken network saturation 
result avoid saturation sustain higher throughput 
bursty traffic confirm self tuning mechanism works varying load bursty load created alternating low loads high loads 
addition change communication pattern high load burst 
offered bursty load shown 
low load phase communication pattern uniform random node tries generate packet cycle period corresponding packet injection rate packets node cycle 
high load phase node tries generate packet cycles corresponding packet injection rate packets node cycle 
communication pattern high load bursts different indicated 
show delivered throughput bursty load deadlock recovery deadlock avoidance configurations respectively 
deadlock recovery average packet latency base alo tune configurations cycles cycles cycles respectively 
deadlock avoidance average packet threshold buffer occupancy percentage time cycles hill climbing hill climbing avoid local maxima time cycles hill climbing hill climbing avoid local maxima threshold vs time throughput vs time 
self tuning operation example packet injection rate packets node cycle static threshold static threshold tune base uniform random butterfly 
static threshold vs tuning 
latency base alo tune configurations cycles cycles cycles respectively 
high load phase congestion control consistently delivers sustained throughput predictable latencies 
alo scheme base scheme initially ramp throughput throughput collapses soon due network saturation 
deadlock recovery results exhibit interesting phenomenon base alo schemes 
small bursts throughput long offered load reduced 
network absorbs heavy offered load goes deep saturation deadlock cycles 
observe happening approximately cycles 
period network packets draining limited escape bandwidth available approximately cycles 
deadlock cycles break full adaptive routing begins 
network drains quickly showing spurt throughput approximately cycles 
interconnection network saturation commensurate decrease performance widely known problem multiprocessor networks 
limiting packet injection network near saturation form congestion control prevent severe performance degradation 
ideal congestion control implementations provide robust performance offered loads require manual tuning 
primary contribution development robust self tuned congestion control technique preventing network saturation 
key components form basis proposed design 
global knowledge time cycles uniform random bit reversal perfect shuffle butterfly 
offered bursty load normalized throughput packets node cycle time cycles base alo tune normalized throughput packets node cycle time cycles base alo tune deadlock recovery deadlock avoidance 
performance bursty load delivered throughput buffer occupancy estimate network congestion control packet injection 
number full buffers exceeds tunable threshold packet injection stopped 
congestion full buffer count drops threshold packet injection restarts 
second piece solution self tuning mechanism observes delivered network throughput automatically determine appropriate threshold values 
inappropriate thresholds throttle network unnecessarily limiting throughput throttle prevent saturation 
self tuning mechanism important single threshold value provides best performance communication patterns 
simulation show design prevents network saturation limiting packet injection 
results show technique superior alternative implementation uses local estimates congestion global information detect congestion early stages 
show different communication patterns require different threshold values prevent saturation unnecessarily limiting performance self tuning mechanism automatically adjusts changes communication patterns 
acknowledgments amin vahdat jeffrey chase gershon kedem kenneth joel emer mark hill anonymous referees feedback suggestions improve 
timothy choi yong ho song providing network simulator helping debug simulation code 
jose giving pointers network saturation 
supported part darpa dabt nsf cda cda eia career award mip duke university equipment donation intel technology education program 
views contained authors interpreted representing official policies endorsements expressed implied darpa government 
panda 
alleviating consumption channel bottleneck wormhole routed ary cube systems 
ieee transactions parallel distributed systems may 
lopez 
simple efficient mechanism prevent saturation wormhole networks 
proceedings 
th international parallel distributed processing symposium pages 
brakmo peterson 
tcp vegas congestion avoidance global internet 
journal selected areas communications october 
dally 
virtual channel flow control 
ieee transactions parallel distributed systems march 
dally seitz 
torus routing chip 
journal distributed computing october 
dally seitz 
deadlock free message routing multiprocessor interconnection networks 
ieee transactions computers may 

power focuses memory bandwidth 
microprocessor report october 

new theory deadlock free adaptive routing wormhole networks 
ieee transactions parallel distributed systems december 
emer 
simultaneous multithreading multiplying alpha performance 
microprocessor forum october 
floyd 
tcp explicit congestion notification 
acm computer communications review october 
floyd jacobson 
random early detection gateways congestion avoidance 
ieee acm transactions networking august 

adaptive routing protocols hypercube interconnection networks 
ieee computer pages may 
jacobson 
congestion avoidance control 
proceedings acm sigcomm symposium pages august 
jain 
congestion control traffic management atm networks advances survey 
computer networks isdn systems october 
kleinrock 
virtual cut new computer communication switching technique 
computer networks 
kim liu chien 
routing framework adaptive fault tolerant routing 
proceedings st international symposium computer architecture april 

efficient fully adaptive deadlock recovery scheme 
proceedings nd annual international symposium computer architecture pages june 
laudon lenoski 
sgi origin ccnuma highly scalable server 
proceedings th international symposium computer architecture pages june 
lopez martinez 
dynamically reduced message injection limitation mechanism wormhole networks 
international conference parallel processing pages august 
lopez martinez 
reduction deadlock frequency limiting message injection wormhole networks 
proceedings parallel computer routing communication workshop june 

dally 
flit reservation flow control 
proceedings sixth internation symposium high computer architecture pages january 
pfister norton 
hot spot contention combining multistage interconnection networks 
ieee transactions computers october 
ramakrishnan jain 
binary feedback scheme congestion avoidance computer networks 
acm transactions computer systems 
scott sohi 
feedback multiprocessors application tree saturation control 
ieee transactions parallel distributed systems october 
scott 
synchronization communication multiprocessor 
proceedings seventh internation conference architectural support programming languages operating systems pages october 

global reactive congestion control multicomputer networks 
th international conference high performance computing pages 
superior multiprocessor architecture smart interconnects group electrical engineering systems department university southern california 

www usc edu dept tools html 

characterization deadlocks interconnection networks 
proceedings th international parallel processing symposium april 
performance communication patterns deadlock recovery normalized accepted traffic packets node cycle packet injection rate packets node cycle bit reversal tune base alo average latency cycles packet injection rate packets node cycle bit reversal tune base alo delivered throughput vs offered load average latency vs offered load deadlock avoidance normalized accepted traffic packets node cycle packet injection rate packets node cycle bit reversal tune base alo average latency cycles packet injection rate packets node cycle bit reversal tune base alo delivered throughput vs offered load average latency vs offered load 
performance bit reversal traffic pattern deadlock recovery normalized accepted traffic packets node cycle packet injection rate packets node cycle perfect shuffle tune base alo average latency cycles packet injection rate packets node cycle perfect shuffle tune base alo delivered throughput vs offered load average latency vs offered load deadlock avoidance normalized accepted traffic packets node cycle packet injection rate packets node cycle perfect shuffle tune base alo average latency cycles packet injection rate packets node cycle perfect shuffle tune base alo delivered throughput vs offered load average latency vs offered load 
performance perfect shuffle traffic pattern deadlock recovery normalized accepted traffic packets node cycle packet injection rate packets node cycle butterfly tune base alo average latency cycles packet injection rate packets node cycle butterfly tune base alo delivered throughput vs offered load average latency vs offered load deadlock avoidance normalized accepted traffic packets node cycle packet injection rate packets node cycle butterfly tune base alo average latency cycles packet injection rate packets node cycle butterfly tune base alo delivered throughput vs offered load average latency vs offered load 
performance butterfly traffic pattern 
