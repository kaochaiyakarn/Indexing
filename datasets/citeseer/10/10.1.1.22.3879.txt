workload parallel supercomputers modeling characteristics rigid jobs uri dror feitelson school computer science engineering hebrew university jerusalem israel analysis workloads important understanding systems 
addition workload models needed input evaluation new system designs comparison system designs 
especially important costly large scale parallel systems 
luckily workload data available form accounting logs 
logs di erent sites analyze model job level workloads emphasis aspects universal sites 
distributions turn span large range typically rst apply logarithmic transformation data novel hyper gamma distribution special cases 
generalization distributions proposed previously leads goodness scores 
parameters distribution iterative em algorithm 
results analysis codi ed modeling program creates synthetic workload results analysis 
study design computer systems requires models workload systems subjected 
data necessary build models observations production installations available especially parallel computers 
models assumptions mathematical attributes facilitate analysis 
number supercomputer sites accounting data available possible build realistic workload models 
clear generalize speci observations model workload 
addresses analysis real workloads creation realistic workload models analysis special emphasis placed tradeo complexity model resulting predictive power 
models lead substantial improvements experimental procedures higher con dence results 
current systems scope involves rigid parallel jobs 
reason focusing parallel jobs lead intricate workloads job parallelism runtime may interact extensive modeling ort needed trac models packets prede ned size arrival process known 
rigid jobs jobs change parallelism runtime 
chose address malleable dynamic jobs stage due complexities involved lack data described 
model 
common ways recorded workload analyze evaluate system design logged workload directly drive simulation create model log model analysis simulation 
example trace driven simulations large address traces evaluate cache designs 
models applications traverse address space proposed provide interesting insights program behavior 
advantage trace directly real test system workload re ects real workload precisely complexities known person performing analysis 
drawback trace re ects speci workload question results generalize systems load conditions 
particular cases workload depends system con guration workload necessarily representative workloads systems con gurations 
obviously comparison di erent con gurations problematic 
addition traces misleading incomplete information circumstances collected 
example workload traces contain intervals machine part dedicated speci project information may available 
workload models number advantages traces 
modeler full knowledge workload characteristics 
example easy know workload parameters correlated information part model 
possible change model parameters time order investigate uence keeping parameters constant 
possible select model parameters expected match speci workload site 
manipulations problematic logs 
example common practice increase modeled load system reducing average interarrival time 
practice undesirable consequence shrinking daily load cycle 
workload model control load independent daily cycle 
example ability create long workloads jobs available log 
model ected policies constraints particular site trace recorded 
example site con gures queues maximum allowed duration hours forces users break long jobs multiple short jobs 
observed distribution durations di erent natural distribution users generated di erent policy 
logs may polluted bogus data 
example trace may include records jobs killed exceeded resource bounds 
jobs impose transient load system uence arrival process 
may replicated number times completing successfully successful run represents real 
model jobs avoided modeled explicitly desired 
modeling increases understanding lead new designs understanding 
example identifying repetitive nature job learning job requirements history 
design resource management policy parameterized workload model measured values local workload tune policy 
model main problem models logs representativeness 
degree model represent workload system encounter practice 
answer depends part degree detail included 
job composed procedures built instructions interact computer di erent levels 
option model levels explicitly creating hierarchy interlocked models di erent levels 
obvious advantage conveying full detailed picture structure workload 
example sizes sequence jobs need modeled independently 
derived lower level model jobs structures 
combined model useful evaluating systems jobs executed prede ned partitions evaluating systems partition size de ned runtime re ect current load speci requirements jobs 
drawback approach detailed levels added complexity model increases 
detrimental reasons 
detailed traces needed order create lower levels model 
second commonly case wider diversity lower levels 
example may jobs nodes ner detail coded data parallel serial parallel phases written mpi spmd style 
creating representative model captures diversity hard possibly arbitrary decisions regarding relative weight various options 
concentrate single level models may viewed top level hierarchical set models 
common approach workload modeling create statistical summary observed workload 
typically assumed longer observation period size large small denote degree parallelism job 
duration short long denote runtimes 
better 
summarize year workload analyzing record jobs ran system year 
simplest widely statistics rely moments especially mean variance sample data 
example statistics indicate distribution job runtimes wide dispersion leading preference hyperexponential model exponential 
summaries may misleading may represent shape distribution correctly 
years ago lazowska showed models hyperexponential distribution matching moments lead incorrect results 
addition calculation moments unduly uenced extreme values necessarily representative 
prefer calculation percentiles attempt match cdf target distribution 
section techniques modeling cdf distribution 
chosen model hyper gamma distribution combination gamma distributions 
parameters distributions discovered em algorithm 
apply methodology characterization distributions parallelism runtimes interarrival times di erent workload logs 
comparing logs identify features parameter values representative include nal workload model 
workload logs analysis workload logs locations 
log contains tens thousands jobs spans months activity 
logs typically available ascii les job ran system represented single line space separated elds providing data di erent job attributes 
logs available line parallel workloads archive 
rst log san diego supercomputer center intel paragon machine 
machine nodes constitute batch partition interactive partition 
scheduling special handling partitions node con gurations 
log spans thirds jobs rst year total successful jobs 
log originally available separate logs years appears analysis sdsc sdsc 
second log node connection machine cm installed los alamos national lab lanl 
machine scheduled djm minimal partition size nodes 
log spans period january september contains jobs completed successfully full log longer part 
third nal log node ibm sp machine installed swedish royal institute technology stockholm kth 
machine scheduled easy back lling scheduler 
log contains jobs completed successfully period october august 
statistical techniques section covers statistical distributions techniques nd workload model 
idea statistical modeling characterize workload distributions workload consistent sampling distributions 
done phases 
decide distribution model 

find values distribution parameters provide samples 

check goodness speci distribution sample data 
candidate distributions rst phase typically considered distributions described 
phase uniform distribution generalization uniform distribution 
parameters required order de ne low medium high proportion 
cumulative distribution function constructed straight lines passing points 
exponential distribution known distribution modeling due availability estimators nice mathematical properties memoryless 
pdf hyper exponential distribution mixture exponential distributions 
stage version mixture exponentials parameters parameters exponential distributions proportion rst 
population comes exponential distribution parameter distribution parameter gamma distribution distribution de ned pdf dt member exponential family distributions estimators 
gamma distribution general exible exponential distribution special case 
examples ect parameters shown fig 

shape parameter 
seen distribution bell shaped right tail 
smaller alpha beta beta beta alpha beta beta beta alpha beta beta beta beta alpha alpha alpha beta alpha alpha alpha beta alpha alpha alpha examples gamma distributions 
heavier tail 
called scale parameter determines spread distribution see scale bottom graphs 
mean distribution equal product parameters variance noted important distributions special cases gamma distribution 
exponential distribution obtained setting 
erlang distribution obtained setting integer 
cases parameter resulting distribution 
note gamma distribution represented parameters mean variance notation employed matlab analysis 
hyper gamma distribution mixture gamma distributions generalization hyper exponential hyper erlang distributions 
version mixture gamma distributions parameters fitting distribution data sample functional form certain distribution need nd values distribution parameters 
values de ne exactly distribution example function form ax need nd values parameter values judged degree resulting distribution matches sample data 
methods nd parameter values 
moments estimation method way characterize distribution moments mean variance typically expressed function parameters mean gamma distribution product parameters 
inverting functions obtains formula expresses parameters function moments 
moments sample calculated plugged formula giving desired parameters 
problem method deal distributions samples fat tails 
number equations needed number unknown parameters distribution 
number parameters large high order moments required 
sensitive sample outliers leading situations data ectively ignored 
example exponential distribution parameter estimated rst moment mean 
hyper gamma distribution fth moment required 
consider sample outlier 
fth moment de ned due outlier 
resulting parameters dominated rare samples necessarily representative 
maximum likelihood estimation method idea maximum likelihood derive parameter values lead highest probability sampling data values 
log monotonic function maximum likelihood function maximum log likelihood function 
easier calculate maximum log likelihood function log product sum exponent product 
example consider exponential distribution 
likelihood sampling values parameter product likelihoods individual values log developing equation leads ln ln ln ln nd maximizes expression di erentiate equate zero leading solution equal mean sample 
procedure assumption random variables sample independent 
finding parameters mixture mixture sample comes distributions forming mixture 
don know making harder assess parameters individual distributions 
missing data iterative em expectation maximization algorithm 
algorithm assumption number distributions mixture functional form distribution distribution estimating parameters hard usually produces near optimal results 
algorithm proceeds follows 
initialize parameters distributions 

expectation step observation distribution decide part observation belongs distribution 
currently parameters distribution set nd distribution probability getting observation speci distribution 
probability relative part observed value assigned distribution 

maximization step distribution estimate parameters maximum likelihood estimation method 
estimation done part observations belong distribution 

repeat expectation maximization steps sample likelihood converges 
case number distributions functional form gamma exponential 
steps easy calculate 
em heuristic iterative algorithm results convergence depend initialized 
developed medium minimum estimation method purpose 
method fact easy distinguish distributions mixture just looking histogram samples bimodal bimodal applying logarithmic transformation 
simply divide sample minimum point modes estimate parameters subsample 
likewise estimate probability belonging distribution initialized fraction samples fall subsample 
assessing goodness fit nding parameters de ning speci distribution want know models original sample data 
words want ensure best model managed nd model absolute terms 
kolmogorov smirnov goodness test purpose 
distributions considering known conservative test 
kolmogorov smirnov method kolmogorov smirnov calculates maximal distance cumulative distribution function theoretical distribution sample empirical distribution points 

sort sample observations 
de ne sample empirical cumulative distribution function empirical cdf estimator theoretical distribution 
furthermore samples theoretical distribution pr lim jf 
de ne sup jg 
step function steps height equivalent max 
value large reject hypothesis theoretical empirical distributions 
small reject hypothesis 
actual threshold depends sample size con dence level wanted statistical tables 
method available form simple equation alternative create random samples distribution check reasonable say original data samples come distribution 
done test 
number samples generated equal number original data observations 
test range values partitioned certain number subranges 
number observations fall range expected number observations fall range tabulated case formula created random samples 
metric compared statistics tables ascertain small warrant distributions probably 
degree parallelism rigid jobs thought rectangles processors time space 
important aspects modeling modeling dimensions terms processors terms runtime section 
direct modeling degree parallelism possible input parameter provided user request submit job execution accompanied speci cation processors 
considering jobs necessary model total speedup function order derive runtime allocated number processors 
handling power jobs experience shows distribution job sizes typically dominated sizes powers 
obvious early machines allowed powers hypercubes connection machines 
persists systems architectural preference powers 
raises question source phenomenon included workload model 
downey chose include special treatment powers models 
belief emphasis powers intrinsic workload 
thought stem habit uence queue con guration choices system administrators de ne queues di erent job sizes typically delimited power nodes 
disagree point believe jobs sizes powers emphasized observed logs 
argument approach powers habitual intrinsic part workload users today expected 
argument continue see strong powers logs come machines queues con gured powers machines running easy maui schedulers 
note power jobs shown strong impact performance evaluation results departing empirical observations justi ed carefully retaining observed characteristics safer :10.1.1.23.3197
modeling procedure apart power jobs note high fraction serial jobs typically observed 
motivates partition jobs classes serial power rest 
modeling procedure combination distinction general distribution parallel jobs 
procedure shown graphically fig 

probability job selected serial 
log size selected appropriate distribution 
probability value rounded nearest integer represent power job note fraction power jobs total round size round probability power distribution choose parallel job size serial job probability start size algorithm modeling size job 
stage uniform gamma sdsc sdsc kth lanl model min max max table parameter values logs model job sizes 
parallel jobs 
job size raised selected value rounded necessary case power 
distribution parameters complete model specify parameters distribution 
evaluation parameters exclude lanl cm log machine allows partitions powers nodes 
values logs shown table 
lead choice model 
nd tting distribution rst apply logarithmic transformation regard result continuous distribution 
checked ts gamma distribution uniform distribution stage uniform distribution hyper exponential distribution 
parameters estimated evaluated kolmogorov smirnov method 
best results obtained gamma stage uniform distributions shown table 
chose stage uniform distribution model reasons rst slightly better 
second parameter values obtained consistent di erent machines relatively straightforward relate log runtime cdf log runtime sdsc sdsc kth lanl average log runtime pdf log runtime distributions runtimes logarithmic transformation derived model distributions 
machine size 
model de ne minimal possible value correct fact uniform distribution rounding probability get value reduced maximal value maximal possible value log set arithmetic mean 
job runtimes noted runtime second major characteristic rigid job 
distribution runtimes di erent distribution sizes continuous discrete spans larger range values 
modeling technique completely di erent 
start describing modeling single system show models di erent systems combined single representative model 
modeling individual systems case job sizes start applying logarithmic transformation data 
reduces range reduces uence extreme values may representative general ect quality results 
candidate distributions checked gamma distribution hyper exponential distribution hyper gamma distribution generalization previous hyper erlang distribution 
hyper gamma distribution especially appealing distributions bimodal log space shown fig 

parameters hyper gamma distribution estimated method starting point application em algorithm explained section 
goodness evaluated kolmogorov smirnov method 
results shown table 
cases hyper gamma model close original data provides better match distributions 
sdsc sdsc kth lanl average model search model table parameter values model job runtimes 
pass statistical goodness test 
reasons samples necessarily independent dealing extremely large numbers samples statistical standards jobs log 
order check conjecture chose random subsample jobs data set checked models subsamples 
cases models passed test con dence level 
creating representative model order create representative model need reduce models shown table 
considered ways doing 
rst method calculates average value parameters distribution values parameter models 
salient features gamma distribution depend products parameters geometrical mean chosen arithmetic mean 
resulting parameter values shown table resulting distribution compared originals fig 

seen shape plausible representative data 
second method tabulate range values parameter systematically check di erent combinations 
speci cally parameter selected values divide range equal parts checked distributions resulting combinations values 
distributions turned desired characteristics bimodal maxima minima right places eliminated 
remaining ones pdf lay closest middle pdf data sets chosen model 
resulting parameter values shown bottom row table 
close values calculated previous method leading greater belief values representative 
model compromise representing di erent systems possible consider minor modi cations interest ecient computability 
example possible round nearest integer modify compensate change mean derive hyper erlang model place hyper gamma model note modeling phase done accurate hyper gamma distribution 
experience cuts time required compute samples model 
sdsc sdsc kth lanl average model search model table parameter values model total job 
modeling total techniques described applied total area job rectangle number processors multiplied runtime 
results doing shown table 
obviously combined model speedup function parallel jobs proposed sevcik downey 
validity model debatable jobs ran di erent numbers processors 
akin assumption ideal speedup 
direct data available models 
correlation parallelism runtime idea parallelism reduce completion time task dates back times 
terms workload parallel supercomputers may expected lead inverse correlation parallelism runtime large jobs processors complete faster 
implicit assumption total amount remains 
alternative scalability models assert added parallelism solve problem faster solve larger problems 
may lead increase total processing time 
establishing existence correlation simplest way check correlation parallelism runtime calculate correlation coecient variables 
doing logs yields small positive correlation ranging kth sdsc 
alternative divide jobs log groups degree parallelism plot cdf runtimes distribution group fig 

fact larger jobs generally longer runtime evident fact cdf smaller jobs 
clearly seen sdsc logs 
kth lanl logs mixture small jobs rst groups large jobs third group 
sdsc log runtime sdsc log runtime kth log runtime lanl log runtime distributions runtimes di erent job sizes systems :10.1.1.23.3197
modeling approaches connection parallelism runtime question incorporate workload model 
straightforward approach adopted divide jobs groups degree parallelism create distinct runtime model group 
model runtimes modeled hyper erlang distribution parameters 
model deals jobs processors dividing jobs groups powers yields groups total parameter values 
statistics resulting model similar original data log sp machine ctc 
risk tting data price resembling logs 
alternative approach focus parameters runtime distribution change job size 
words having parameter assigned values jobs groups respectively assign value individual job size 
function completely arbitrary endeavor nd simple function gives data 
suggested approach vein 
start modeling runtimes group hyper gamma distribution previous section fig 
sizes sdsc sdsc kth lanl table parameters runtime model di erent size groups :10.1.1.23.3197
log consume time sample model log runtime sample model log consume time sample model log runtime sample model log consume time sample model log runtime sample model comparison runtime model original distributions di erent size groups sdsc log :10.1.1.23.3197
table 
yields measured kolmogorov smirnov method 
leads observation shapes distributions change similar manner composed pair gamma distributions similar means relative weights distributions changes range sizes 
small jobs distribution runtimes modeled lower gamma 
middle size jobs low gamma dominant higher gamma 
large jobs runtime distribution composed gammas roughly equal weights 
observation devised model runtimes represented hyper gamma distribution 
parameters describing constituent gamma distributions xed 
parameter determines probability sampling gamma distributions correlated job size 
ect replaced pair parameters specify depends job size 
total number parameters model 
procedure sampling runtime distribution select job size fig 
calculate size constant parameters select runtime algorithm modeling runtime job 
sdsc sdsc kth lanl model table parameter values linear dependence job size 
model pictured fig 

results obtained method shown fig 

model track exact di erences shapes distributions di erent sizes accurate model sizes 
calculating model runtimes involves xed gamma distributions parameter represents proportion rst population 
point function job size 
simplest approach linear relationship 
job size 
relationship previously employed feitelson context hyper exponential distribution 
decrease increases negative 
danger negative large larger forcing useful range 
way solve problem log odds transformation equation log 
ensures remains changes shape dependence checked needs expressing dependence resulting distributions data 
alternative set turns negative higher 
ect divides spectrum job sizes segments 
get rst gamma 
get second gamma 
linear relationship 
nd suitable values divided data set roughly equal groups jobs job size splitting single size groups sample model model sample model model sample model model sample model model sample model model sample model model sample model model sample model model resulting runtime distribution di erent job sizes :10.1.1.23.3197
model linear dependence compared model constant sdsc data sample 
lanl sizes 
group best value gamma distributions 
value associated median number processors jobs group 
obtained hs pi pairs input linear regression yielded results logs shown table 
nal model created arithmetic average logs 
arrival process arrival process received relatively little attention past modelers content poisson process 
particular modeling eliminates daily cycle arrivals day night 
unfortunate distribution runtimes includes long jobs may interact daily cycle 
addition shown details arrival process impact results evaluations 
exception created detailed model interarrival times di erent job size ranges par model runtimes 
modeling arrival process dicult need distribution interarrival times distribution hours day daily cycle 
sdsc hours sdsc hours kth hours number jobs arrived lanl hours histograms job arrivals time day 
approach rst model relatively stationary arrival process peak hours characterize daily cycle nally combine 
modeling arrivals peak hours start modeling arrival process peak hours 
isolation combined daily model described 
histograms job arrivals day fig 
de ne peak hours am pm 
interarrival times jobs submitted times tabulated compared distributions exponential hyperexponential gamma hyper gamma 
goodness evaluated kolmogorov smirnov method 
results exponential distribution gave ts 
distribution marginally better gamma distributions expense parameters 
chose gamma distribution model 
parameter values shown table 
model geometrical mean systems 
sdsc sdsc kth lanl model table parameter values model interarrival times peak hours 
sdsc sdsc kth lanl model table parameter values model daily cycle :10.1.1.23.3197
modeling daily cycle workloads expected cycles levels daily people night weekly people weekend yearly people holidays 
important ect daily cycle weekly cycle may ect scheduling long jobs 
shall deal daily cycle 
daily cycle di erent systems shown fig 

removal large peak appears am sdsc logs probably due automatic invocation routine administrative script 
model daily cycle rst note minimum am 
perform cyclic shift range leading distribution essentially unimodal ignoring slight dip 
modeled gamma distribution parameters shown table 
note parameters depend cyclic shift hours minute slots histogram 
calculate fraction jobs arrive half hour interval time rst multiply change hours half hour slots add result account hour shift nally evaluate cdf model gamma distribution 
combined model goal derive workload model interarrival times satisfy distinct constraints interarrivals taken match correct distribution interarrival times time fraction jobs arriving hour day match daily cycle 
way go achieving distribution interarrivals peak hours basis modify order achieve correct number jobs hour day 
order get correct arrival rate modify peak distribution multiplying mean constant call arrive rush ratio 
simply de ned ratio mean complete distribution mean peak distribution close logs partly explained fact distributions logarithmic transformation 
approach achieving goal modify parameters interarrival time distribution time day order match desired arrival rate time 
order reduce complexity model strive nd functional relationship parameters desired arrival rate similar context correlation parallelism runtime 
approach keep underlying distribution modify interpretation sampled interarrival times time day 
see examples types 
check quality approach need compare results original data 
assessing interarrival distribution done kolmogorov smirnov method distributions 
assessing daily cycle done metric 
case calculated number observations model data respectively half hour slots day 
expected interarrival time method rst method tried modify interarrival time distribution desired arrival rate certain time slot 
pre compute di erent values parameter gamma distribution slot denoted 
values computing interarrival time job arrived time done sampled gamma distribution parameters recall model log space 
computed follows 
average slots values representing fraction jobs arrive time ratio gives ratio average number jobs arrive time divided expected number jobs arrive time inverse ratio interarrival times 
leads log method simple led poor match daily cycle 
reason number jobs arriving slot depend distribution interarrival times slot previous slots 
method resulted distribution desired shifted times 
expected time slots method second method tries amend rst calculating values take values subsequent slots account 
done iteratively starting values converge 
iteration calculation proceeds follows 
slot calculate expected jump slot arrival occur account fraction jobs arrive slot 
arrival rate target slot high increase probability jump probability low decrease mod pr mod pr number slots pr probability sampling interarrival distribution lead value slots away 
goal adjust distribution interarrival times holds 
compute weighted average jumps desired current iteration values interarrival distribution parameters adjust parameters closer 
speci cally calculate new parameter value subscript denotes iteration number 
understood follows time new value related weighted average way time related weighted average es 
mean interarrival time proportional distribution similar desired distribution es 
method produced better results chose simpler third method 
slot weight method method interarrival times chosen original distribution modi ed 
slots di erent weights time passes faster slots jobs supposed arrive 
idea simple slot considered having virtual seconds original real seconds half hour 
calculating job arrivals sample gamma distribution peak interarrival times regard result virtual real seconds 
arrival larger chance trapped slot high 
naturally care taken account progress slot 
example assume certain slot duration virtual seconds value seconds sampled 
case arrival way slot 
sample seconds complete current slot progress 
sdsc time intervals sample model model sdsc time intervals sample model model kth time intervals sample model model lanl time intervals sample model model comparison daily arrival cycle nal model model smooth gamma model model original data sample 
noted method selected model 
performance shown fig 

remarkably just parameters daily cycle gamma suce create values provide decent workload consistency important question creating workload models logs data logs consistent 
facets 
distinction di erent job classes interactive batch jobs 
possibility workload evolves time 
distinction interactive batch jobs sdsc sdsc logs include distinction interactive jobs submitted directly machine scheduler batch jobs handled batch queueing system 
enables repeat analysis previous sections subset jobs separately 
log consume time pdf sdsc batch interactive log runtime pdf sdsc batch interactive log consume time pdf sdsc batch interactive log runtime sdsc batch interactive comparison runtime distribution interactive batch jobs sdsc logs 
results signi cant di erences seen job classes 
starting distribution job sizes nd batch jobs nodes interactive jobs rarely result system administration policies 
general batch jobs larger somewhat surprisingly twice batch serial jobs interactive serial jobs 
batch jobs slightly power sizes log 
comparing runtimes nd batch jobs general ran longer 
fact runtimes interactive jobs dominated lower gamma hyper gamma distribution runtimes batch jobs decidedly bimodal log space see fig 

may conjectured runtimes logs result di erent job classes 
considering correlation size runtime correlation coecient calculated batch jobs signi cantly higher interactive jobs sdsc sdsc respectively vs 
parameters dependence model di erent 
batch jobs absolute value smaller range values larger 
arrival process job classes somewhat di erent 
distributions interarrival times peak hours similar curve batch jobs shifted slightly higher values relative curve interactive jobs 
daily cycle similar di erences daytime lows smaller batch jobs 
results imply may important model interactive batch jobs separately especially model evaluate scheduler may provide di erent levels service di erent job types 
workload evolution analysis long logs assumes characteristics workload stable 
fact known workload changes users learn new machine migrate machine current dated 
hard assess processes logs 
check degree workloads change compared sdsc sdsc logs consecutive years machine 
results logs similar certainly signi cant di erences 
main change reduction number interactive jobs log jobs jobs number batch jobs remained bit :10.1.1.23.3197
characteristics interactive batch jobs quite di erent led noticeable changes workload average jobs processors ran longer arrived larger intervals 
summary summary model nal model somewhat involved includes components model job sizes stage uniform distribution parameters including specifying minimal maximal sizes desired 
additional parameters account fractions serial power jobs 
model job runtimes hyper gamma distribution 
parameters parameter replaced linear model depends job size 
model arrivals gamma distributions peak interarrival times daily arrivals cycle 
additional parameters shift model daily cycle value match peak arrivals arrivals 
replicated times full workload interactive batch jobs separately 
program implements model available line parallel workloads archive 
comparison models models parallel workloads proposed literature 
probably rst detailed model precursor current model proposed feitelson 
model stage hyperexponential distribution runtimes choosing parameters cdf looked right similar various logs 
subsequent version stage hyperexponential 
accommodate slight correlation observed runtime degree parallelism probability exponential depended degree parallelism 
arrival process modeled assumed poisson process 
hyper erlang distribution runtimes interarrival times parameters matching rst moments data log 
addition divided jobs submitted parallel machine degree parallelism created separate model range degrees parallelism 
ignores extra weight powers appears original log 
result model large number parameters closely mimics original data 
downey proposed log uniform distribution total observation sdsc paragon log 
uses smallest number parameters multiple segments 
distributions upper bound values produce 
total model speedup function derive runtime number processors allocated 
model jobs rigid jobs 
current model improves models respects 
employs rigorous statistical procedures previously eld 
uses matching cdf distributions relying moments may unduly uenced outliers 
logs di erent locations 
thorough modeling parallelism runtimes correlation arrival process including daily cycles 
analysis compared models logs current model closest average metrics checked 
metrics include mean variance runtimes total interarrival times degree parallelism 
said model representative available general sense albeit completely match di erent logs creation 
acknowledgments research supported part israel science foundation 
workload logs available line parallel workloads archive 
workload log sdsc paragon graciously provided reagan moore allen downey 
workload log kth sp graciously provided lars 
workload log lanl cm graciously provided canada 
making data available help background information interpretation 
prof ya ritov statistics advice 
merlo hierarchical approach workload characterization parallel systems 
high performance computing networking pp 
springer verlag may 
lect 
notes comput 
sci 
vol 

workload characterization survey 
proc 
ieee pp 
aug 
downey parallel workload model implications processor allocation 
th intl 
symp 
high performance distributed comput aug 
downey feitelson elusive goal workload characterization 
performance evaluation rev pp 
mar 
feitelson packing schemes gang scheduling 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

feitelson improved utilization responsiveness gang scheduling 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

feitelson rudolph metrics benchmarking parallel job scheduling 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

feitelson rudolph convergence job schedulers parallel supercomputers 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

gustafson reevaluating amdahl law 
comm 
acm pp 
may 
see comm 
acm pp 
feb comm 
acm pp 
aug 
workload evolution cornell theory center ibm sp 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

franke wang modeling workload 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

kessler hill wood comparison trace sampling techniques multi megabyte caches 
ieee trans 
comput 
pp 
jun 
eggers levy validity trace driven simulation multiprocessors 
th ann 
intl 
symp 
computer architecture conf 
proc pp 
may 
law simulation modeling analysis 
mcgraw hill rd ed 
lazowska percentiles modeling cpu service time distributions 
computer performance chandy reiser eds pp 
north holland 
anl ibm sp scheduling system 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

lo comparative study real workload traces synthetic workload models parallel job scheduling :10.1.1.23.3197
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

mclachlan em algorithm extensions 
wiley 
parallel workloads archive 
url www cs huji ac il labs parallel workload 
sevcik application scheduling processor allocation multiprogrammed parallel processing systems 
performance evaluation pp 
mar 
yao zhang impact job arrival patterns parallel scheduling 
performance evaluation rev pp 
mar 

sun ni scalable problems memory bounded speedup 
parallel distributed comput 
pp 
sep 
feitelson comparing logs models parallel workloads plot method 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springer verlag 
lect 
notes comput 
sci 
vol 

thi fractal dimension computer programs application prediction cache ratio 
ieee trans 
comput 
pp 
jul 
thi wolf stone synthetic traces trace driven simulation cache memories 
ieee trans 
comput 
pp 
apr 
corrected ieee trans 
comput 
may 
wan moore batch scheduler intel paragon non contiguous node allocation algorithm 
job scheduling strategies parallel processing feitelson rudolph eds pp 
springerverlag 
lect 
notes comput 
sci 
vol 


