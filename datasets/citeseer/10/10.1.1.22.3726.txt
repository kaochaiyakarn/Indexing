broadcast disks data management asymmetric communication environments swarup acharya rafael alonso michael franklin stanley zdonik october proposes repetitive broadcast way augmenting memory hierarchy clients asymmetric communication environment 
describe new technique called broadcast disks structuring broadcast way provides improved performance non uniformly accessed data 
broadcast disk multiple disks spinning different speeds single broadcast channel effect creating arbitrarily fine grained memory hierarchy 
addition proposing defining mechanism main result exploiting potential broadcast structure requires re evaluation basic cache management policies 
examine pure cache management policies develop measure implementable approximations policies 
results set simulation studies basic idea develops intuitions required design particular broadcast program 
asymmetric communication environments existing emerging application domains downstream communication capacity servers clients greater upstream communication capacity clients back servers 
example wireless mobile network servers may relatively high bandwidth broadcast capability clients transmit lower bandwidth cellular link 
systems characteristics proposed application domains including traffic information systems hospital information systems public safety applications wireless classrooms katz 
refer environments asymmetric communications environments 
communications asymmetry arise ways bandwidth limitations physical communications medium 
example physical asymmetry wireless environment described stationary servers powerful broadcast transmitters mobile clients little transmission capability 
obviously communications asymmetry arise patterns information flow application 
example information retrieval system number available brown university dept computer science technical report cs university maryland department computer science technical report cs tr dept computer science brown university providence ri sa cs brown edu matsushita information technology labs princeton nj alonso mitl research panasonic com dept computer science university maryland college park md franklin cs umd edu dept computer science brown university providence ri cs brown edu clients far greater number servers asymmetric insufficient capacity network servers handle simultaneous requests generated multiple clients 
asymmetry arise due physical devices workload characteristics class asymmetric communications environments spans wide range important systems applications encompassing wired wireless networks 
examples include ffl wireless networks stationary base stations mobile clients 
ffl information dispersal systems volatile time sensitive information stock prices weather information traffic updates factory floor information ffl cable television networks set top boxes allow viewers communicate broadcasting home office video demand servers 
ffl information retrieval systems large client populations mail order catalog services mutual fund information services software help desks broadcast disks traditional client server information systems clients initiate data transfers sending requests server 
refer systems pull clients pull data server order provide data locally running applications 
pull systems poor match asymmetric communications environments require substantial upstream communications capabilities 
address incompatibility proposed new information system architecture exploits relative abundance downstream communication capacity asymmetric environments 
new architecture called broadcast disks 
central idea servers exploit advantage bandwidth broadcasting data multiple clients 
refer arrangement push architecture data pushed server clients 
approach server continuously repeatedly broadcasts data client community 
effect broadcast channel disk clients retrieve data goes 
broadcasting data addressed previously researchers herm 
technique differs superimpose multiple disks different sizes speeds broadcast medium 
broadcast created multiplexing chunks data different disks broadcast channel 
chunks disk evenly interspersed 
chunks fast disks repeated chunks slow disks 
relative speeds disks adjusted parameter configuration broadcast 
channel effectively puts fast disks closer client time pushing slower disks away 
presents opportunity closely match broadcast workload clients 
assuming server indication client access patterns watching previous activity description intended client hot pages pages interest larger part client community brought closer cold pages pushed away 
effect creates arbitrarily fine grained memory hierarchy expected delay obtaining item depends item broadcast 
scope organizing data multi disk broadcast medium raises number new research problems 
server side issues involve designing broadcast program satisfy number conflicting criteria 
client side challenges relate developing new caching strategies take account serial nature broadcast medium 
described assumptions restrict scope environment order initial study feasible 
assumptions include ffl client population access patterns change 
implies broadcast program determined statically 
ffl data read updates clients servers 
ffl clients retrieve data items broadcast item time prefetching 
ffl clients upstream communications capability provide feedback servers 
environment main interrelated issues addressed 
client population specification access probabilities data items client server construct broadcast program satisfy needs clients 

server chosen particular broadcast program client manage local data cache maximize performance 
describe important results regards issues obtained simulation study environment 
results include ffl significant performance benefits gained broadcasting data items frequently 
broadcasting advantage scalability additional clients monitor broadcast impacting performance existing clients 
ffl broadcast disk fundamentally changes nature cache memory management clients 
caching locally hottest pages clients local resources remove local idiosyncrasies access stream broadcast disk 
ffl looked idealized broadcast caching policies serve upper bounds analysis 
developed easily implementable cache replacement policies idealized case 
remainder organized follows 
section discusses way structure broadcast program section shows client cache management policy designed complement choice 
section describes simulation model section develops main experimental results derived model 
section compares previous repetitive broadcast 
section summarizes results describes 
structuring broadcast disk properties broadcast programs push information system server construct broadcast program meet needs client population 
simplest scenario indication data items desired client listening broadcast server simply take union requests broadcast resulting set data items 
broadcast depicted 
application running server flat broadcast program client needs data item attempts retrieve item local memory disk 
desired item client monitors broadcast waits desired item arrive 
flat broadcast expected delay required prior obtaining item items broadcast half broadcast period regardless relative importance clients 
flat approach adopted earlier broadcast database systems 
alternatively server broadcast different items differing frequency important items broadcast 
assuming server knowledge access probability data item client server determine broadcast program emphasize popular items de emphasize popular ones 
theoretically broadcast program generation addressed bandwidth allocation problem client access probabilities server determines optimal percentage broadcast bandwidth allocated item 
broadcast program generated randomly bandwidth allocations average inter arrival time instances discussion assumes broadcast items self identifying 
option provide index discussed 
item matches needs client population 
random broadcast optimal terms minimizing expected delay due variance inter arrival times 
simple example demonstrating points shown 
shows different broadcast programs data set containing equal length items pages 
program flat broadcast disks broadcast page twice pages program skewed broadcast subsequent broadcasts page clustered 
contrast program regular variance inter arrival time page 
performance characteristics program page stored disk spinning twice fast disk pages stored 
reason refer program multi disk broadcast 
example broadcast programs access probability expected delay broadcast units flat skewed multi disk table expected delay various access probabilities table shows expected delay page accesses different broadcast programs varying skew access probabilities pages 
expected delay calculated multiplying probability access page times expected delay page summing results 
major points demonstrated table 
point uniform page access probabilities flat disk best expected performance 
fact demonstrates fundamental constraint broadcast disk paradigm due fixed bandwidth increasing broadcast rate item necessarily decrease broadcast rate items 
second point access probabilities increasingly skewed non flat programs perform increasingly better 
third point demonstrated table multi disk program performs better skewed program 
behavior result called bus paradox 
inter arrival rate broadcast rate page fixed expected delay request arriving random time half gap successive broadcasts page 
contrast variance inter arrival rate gaps broadcasts different lengths 
case probability request arriving large gap greater probability request arriving short gap 
expected delay greater variance inter arrival rate increases 
addition performance benefits multi disk broadcast advantages random skewed broadcast program 
randomness arrivals reduce effectiveness prefetching techniques require knowledge exactly particular item broadcast 
second randomness broadcast disallows sleeping reduce power consumption 
notion period broadcast 
periodicity may important providing correct semantics updates done herm introducing changes structure broadcast program 
reasons argue broadcast program features ffl inter arrival times subsequent copies data item fixed 
ffl defined unit broadcast broadcast repeats periodic 
ffl furthermore subject constraints available broadcast bandwidth possible 
broadcast program generation section model describing structure broadcast programs describe algorithm generates broadcast programs desired features listed previous section 
algorithm imposes multi disk structure broadcast medium way allows substantial flexibility fitting relative broadcast frequencies data items access probabilities client population 
algorithm steps simplicity assume data items pages uniform fixed length 
order pages hottest popular 

partition list pages multiple ranges pages range contains pages similar access probabilities 
ranges referred disks 

choose relative frequency broadcast disks 
restriction relative frequencies integers 
example disks disk broadcast times times disk broadcast rel freq rel freq 

split disk number smaller units 
units called chunks ij refers th chunk disk 
calculate max chunks common multiple lcm relative frequencies 
split disk num chunks max chunks rel freq chunks 
previous example num chunks num chunks 
create broadcast program interleaving chunks disk manner max chunks gamma num disks broadcast chunk mod num chunks endfor endfor shows example broadcast program generation 
assume list pages partitioned disks pages disk broadcast twice frequently pages disk times frequently pages disk 
rel freq rel freq rel freq 
disks split chunks step algorithm 
max chunks num chunks num chunks num chunks 
note chunks different disks differing sizes 
resulting broadcast consists minor cycles containing chunk disk lcm relative frequencies 
resulting broadcast period pages 
broadcast produces level memory hierarchy disk smallest fastest level disk largest slowest level 
multi level broadcast corresponds traditional notion memory hierarchy 
chunks hot cold database pages disks minor cycle major cycle period deriving server broadcast program algorithm produces periodic broadcast program fixed inter arrival times page 
broadcast slots may unused possible evenly divide disk required number chunks step algorithm 
course extra slots need wasted broadcast additional information indexes updates invalidations extra broadcasts extremely important pages 
furthermore anticipated number disks small order number pages broadcast substantially larger unused slots small fraction total number slots relative frequencies adjusted slightly reduce number unused slots necessary 
disk model fairly simple allows creation broadcast programs support particular access probability distribution 
inter related types knobs turned vary shape broadcast 
number disks num disks determines number different frequencies pages broadcast 
disk number pages disk relative frequency broadcast rel freq determine size broadcast arrival rate real relative time pages disk 
example adding page fast disk significantly increase delay pages slower disks 
intuitively expect fast disks configured fewer pages slower disks model enforce constraint 
recall constraint relative broadcast frequencies disks expressed positive integers 
possible arbitrarily fine distinctions broadcasts disk rotates times times slower disk rotates 
ratio results broadcast long period nearly rotations fast disk 
furthermore requires slower disk size split fairly equal chunks 
addition fine tuning produce significant performance benefit compared ratio 
practice relative frequencies chosen care possible approximated simpler ratios 
algorithm specified generates broadcast programs properties desire help selection various parameter values shape broadcast 
automatic determination parameters access probability distribution interesting optimization problem focus going 
issue scope current 
focus examining basic properties new paradigm broadcast disks 
broadcast disk changes basic assumptions traditional pull memory hierarchies founded 
result imperative develop understanding fundamental tradeoffs affect performance broadcast system 
performance study described section presents initial investigation issues 
client cache management shared nature broadcast disk principle allowing nearly unlimited scalability fact gives rise fundamental tradeoff tuning performance broadcast zero sum game improving broadcast access probability distribution hurt performance clients different access distributions 
way dilemma exploit local memory disk client machines cache pages obtained broadcast 
observation leads novel important result broadcast fundamentally changes role client caching client server information system 
traditional pull systems arch care wang fran clients cache hottest data items access 
push environment cache lead poor performance server broadcast poorly matched client page access distribution 
difference arises serial nature broadcast disk non cache resident pages equidistant client 
server tailor broadcast program needs particular client client simply cache hottest pages 
client loaded hottest pages cache server place pages slower spinning disk 
frees valuable space fastest spinning disks additional pages 
general factors cause server broadcast sub optimal particular client ffl access distribution client gives server may inaccurate 
ffl client access distribution may change time 
ffl server may give higher priority needs clients different access distributions 
ffl server may average broadcast needs large client population 
broadcast program sub optimal point view client 
reasons push system clients cache store simply hottest pages store pages local probability access significantly greater page frequency broadcast 
example page accessed frequently client clients page broadcast slow disk 
avoid long waits page client keep page cached locally 
contrast page accessed frequently clients including client broadcast fast disk reducing value caching 
argument leads need cost page replacement 
cost obtaining page cache accounted page replacement decisions 
standard page replacement policy tries replace cache resident page lowest probability access lru tries approximate 
shown certain assumptions optimal replacement strategy replaces cache resident page having lowest ratio probability access frequency broadcast 
refer ratio pix inverse 
example pix consider pages 
page accessed time particular client broadcast time 
second page accessed time client broadcast time 
example page lower pix value 
result page replacement policy pix replace page favor second page accessed twice frequently 
pix shown optimal policy certain conditions practical policy implement requires perfect knowledge access probabilities comparison pix values cache resident pages page replacement time 
reason investigated implementable cost algorithms intended approximate performance pix algorithm adds frequency broadcast lru style policy 
new policy called lix described analyzed section 
modeling broadcast environment order better understand properties broadcast program generation client cache management constructed simulation model broadcast disk environment 
simulator implemented csim models single server continuously broadcasts pages single client continuously accesses pages broadcast cache 
simulator client generates requests logical pages 
logical pages mapped physical pages broadcast server 
mapping logical pages physical pages allows server broadcast varied respect client workload 
flexibility allows simulator model impact large client population performance single client having model clients 
example having client access subset pages models fact server broadcasting pages clients 
furthermore systematically perturbing client page access probabilities respect server expectation probabilities able vary degree server broadcast favors particular client modeling 
simulation model described sections 
client execution model parameters describe operation client shown table 
simulator measures performance logical time units called broadcast units 
broadcast unit time required broadcast single page 
general results obtained simulator valid possible broadcast media 
actual response times experienced medium depend amount real time required broadcast page 
parameter meaning client cache size pages thinktime time client page accesses broadcast units pages range accessed client zipf distribution parameter pages region zipf distribution table client parameter description client runs continuous loop randomly requests page specified distribution 
client cache hold pages 
requested page cache resident client waits page arrive broadcast brings requested page cache 
client cache management done similarly buffer management traditional system cache slots parameter meaning number distinct pages broadcast number disks size disk pages delta broadcast shape parameter offset offset default client access noise workload deviation table server parameter description occupied page replacement policy choose victim replacement 
requested page cache resident client waits thinktime broadcast units time request 
thinktime parameter allows cost client processing relative page broadcast time adjusted model workload processing relative speeds cpu broadcast medium 
client chooses pages access range gamma subset pages broadcast 
pages outside range zero probability access client 
range page access probabilities follow zipf distribution knut gray page frequently accessed page gamma frequently accessed 
zipf distribution typically model non uniform access patterns 
produces access patterns increasingly skewed increases probability accessing page numbered total number pages 
similar earlier models skewed access dan partition pages regions pages probability accessing page region uniform zipf distribution applied regions 
regions overlap regions 
server execution model parameters describe operation server shown table 
server broadcasts pages range 
pages interleaved broadcast program algorithm described section 
program broadcast repeatedly server 
structure broadcast program described parameters 
number levels disks multi disk program 
convention disks numbered fastest slowest 
number pages assigned disk page broadcast exactly disk sum equal 
addition size number disks model capture relative speeds 
described section relative speeds various disks positive integers 
order experimentation tractable introduce parameter called delta determines relative frequencies disks restricted manner 
delta broadcast frequency disk computed relative broadcast frequency slowest disk disk follows discuss performance various replacement policies section 
offset offset disk disk offset access probability offset vary client access broadcast frequency broadcast gamma delta delta zero broadcast flat disks spin speed 
delta increased speed differentials disks increase 
example disk broadcast delta disk spins times fast disk disk spins twice fast disk 
delta relative speeds disks respectively 
important note delta performance study organize space disk configurations examine 
part disk model described section 
remaining parameters offset noise modify mapping logical pages requested client physical pages broadcast server 
offset noise set zero logical physical mapping simply identity function 
case hottest pages client perspective gamma placed disk hottest pages placed disk discussed section mapping may sub optimal due client caching 
client cache management policies tend fix certain pages client buffer pages need broadcast frequently 
cases best broadcast obtained shifting hottest pages fastest disk slowest 
offset number pages shifted manner 
offset shifts access pattern pages pushing hottest pages slowest disk bringing pages faster disks 
offset demonstrated 
contrast offset provide better broadcast client parameter noise introduce disagreement needs client broadcast program generated server 
described section disagreement arise ways including dynamic client access patterns conflicting access requirements population clients 
noise determines percentage pages may mismatch client server 
probability noise mapping page may switched different page 
generation server broadcast program works follows 
mapping logical physical pages generated identity function 
second mapping shifted offset pages described 
third page mapping coin weighted noise tossed 
coin toss page selected swapped disk uniformly chosen new destination way existing page chosen exchange mappings 
experiments results parameter settings overview experiments section simulation model explore performance characteristics broadcast disk 
examine performance number different disk configurations case clients perform caching 
experiments provide insight basic properties broadcast program simple environment 
performance cache case relatively straightforward client caching raises number new issues study 
set cache experiments described section investigate performance standard caching techniques multiple disks 
results highlight drawbacks standard page replacement techniques broadcast disk motivate need cost cache management studied section section 
primary performance metric employed study response time client measured broadcast units 
server database size pages client access range pages 
studied different configurations broadcast programs including disk disk cases experiments 
results obtained client performance reached steady state 
cache warm effects eliminated measurements cache full 
parameter values experiments summarized table 
noted results described section small subset results obtained 
results chosen demonstrate unique performance aspects tradeoffs broadcast disk environment identify important areas study 
experimental results non caching case experiment caching noise set results examine case client performs caching cache size page 
shows client response time vs delta number disk configurations 
graph noise set meaning server providing preferential treatment client giving highest priority client pages 
delta increased axis skew relative speeds disks increased described section 
shown note page may swapped page disk 
swap affect performance steady state noise represents upper limit number changes 
thinktime delta offset noise table parameter settings general trend cases response time improves increasing disk skew 
delta broadcast flat disks rotate speed 
case expected disks result response time pages half 
delta increased disk configurations shown provide improvement flat disk 
degree improvement begins flatten configurations delta value 
delta client performance cache size noise turning various disk configurations examine disk configurations 
pages fit fastest disk 
noise offset zero hottest half client access range fast disk half slower disk 
note delta increased performance improves delta hotter pages brought closer 
point degradation caused access slow pages get pushed away begins lower performance 
contrast places client access range pages fast disk improves increasing delta values delta experiment 
accessed pages fast disk increasing delta pushes unused pages away allowing accessed pages arrive frequently 
point penalty slowing great curve turn previous case 
final disk configuration equal sized disks 
accessed data fits fast disk fast disk includes pages 
size fast disk causes effective frequencies pages disk lower frequencies pages fast disks corresponding values delta 
result worst performance disk configurations delta values shown 
turning disk configurations seen configuration fast disk pages best performance entire range 
delta response time third flat disk response time 
simply disk disk split disks performs better disk counterpart 
extra level disk easier match broadcast program client needs 
note response time typically higher disk extra disk level necessarily ensure better performance 
experiment noise caching previous experiment broadcast program generation done giving client access pattern highest priority 
experiment examine performance broadcast disk server shifts priority away client noise increased 
results shown figures show client performs presence increasing noise configurations disks disks respectively 
expected performance suffers configurations noise increased mismatch broadcast client needs increases skew disk speeds starts hurt performance 
ultimately mismatch great multi disk approach worse performance flat disk 
shown performance disk 
susceptibility broadcast mismatch expected client accesses data broadcast channel 
clear client cache broadcast suited client access demands order gain benefits multi disk approach 
response time broadcast units delta noise response time broadcast units delta noise sensitivity noise disk 
disk 
experiments results caching case results previous section demonstrated absence caching multi level disk scheme improve performance cache performance suffer broadcast program poorly suited client access demands 
section introduce client cache increase client tolerance mismatches broadcast program 
initially idealized page replacement policy called keeps pages highest probability access cache 
implementable policy requires perfect knowledge access probabilities great deal local computation order gain understanding performance simplified setting point implementable policies 
experiment caching offset caching case client performs best perfect match broadcast server fills disks fastest slowest client pages decreasing order probability access 
alternatively said best broadcast client cache offset zero 
client cache changes 
page replacement policy tends favor subset pages steady state pages cache resident 
hot pages obtained broadcast disk broadcast frequently 
assuming clients choose cache pages probability access best broadcast obtained non zero offset 
non zero offset implies server broadcasts portion client hottest pages slowest disk fills faster disks remainder client access range 
figures show response time client varying offset disk disk case delta respectively 
graph shows results different cache sizes page replacement policy 
disk see shows sensitivity offset 
best response time occurs offset equal client cache size 
policy retains hottest pages pages pushed slower disk exactly offset size 
offset small server wastes significant portion fastest disk pages client cache 
large hot pages fit client cache pushed slowest disk resulting huge penalties cache misses pages 
disk configuration sensitive offset middle disk provides buffer fast slow disks pages fast disk 
sensitive oversized offset differential fast slow disks greater making cache misses slow disk expensive 
trivial implement simulator probability page known client access distribution 
response time broadcast units offset delta noise response time broadcast units offset delta noise offset sensitivity disk disk broadcast response time broadcast units delta cache offset noise noise noise noise noise noise response time broadcast units delta cache offset noise noise noise noise noise noise noise sensitivity disk broadcast pix experiment caching noise offset provides best broadcast client examine effectiveness cache idealized replacement policy allowing client tolerate noise broadcast 
shows impact increasing noise performance disk configuration delta varied 
case shown offset set pages 
comparing results results obtained caching case see see expected cache greatly improves performance absolute sense surprisingly cache numbers somewhat sensitive degree noise non caching numbers 
example caching case delta greater higher degrees noise multi disk performance worse flat disk performance crossover occur similar delta values case 
reason additional sensitivity noise low offset exactly caches hot pages placed slowest disk obtains remainder hottest pages fastest disk 
noise increases caches pages regardless disk stored 
caching page stored fastest disk cache pages broadcast frequently 
noise increases cache hit rate remains cache misses expensive retrieve pages slower disks 
expensive cache misses cause sensitivity noise 
cost replacement algorithms previous section shown standard caching help improve performance broadcast environment increase client sensitivity noise 
recall noise represents degree server broadcast deviates best particular client 
type noise application multiple clients access broadcast disk 
sensitivity noise prime consideration performance systems 
discussed previous section replacement policy sensitive noise ignored cost obtaining page choosing victim replacement 
address deficiency examine second idealized algorithm called pix extends notion cost 
stated section pix replaces page lowest ratio access probability broadcast frequency 
cost re accessing replaced page factored replacement decision 
experiment pix noise shows response time client pix case previous experiment showed see 
comparing figures seen pix successful insulating client response time effects noise 
course increase noise results degradation performance expected 
case pix performance client remains better corresponding flat disk performance values noise delta experiment 
pix performance client noise value remains stable delta increased certain point 
contrast presence noise performance client degrades delta increased certain point 
experiment demonstrates potential cost replacement making broadcast disk practical wider range applications 
figures show results set experiments slightly different light 
shows relative performance pix set conditions noise fixed 
delta increases response time begins increase quickly pix falls half value flat disk delta rising 
shows relative response algorithms delta delta increasing noise 
performance flat disk delta baseline 
note degrades faster pix eventually worse flat disk noise 
pix rises gradually manages perform better flat disk parameters 
notice performance degrades delta pix fails adapt cache note delta flat disk pix identical pages broadcast frequency 
contents increasing differences disk speeds 
performance differences algorithms result differences places obtain pages shown case noise 
interesting note pix lower cache hit rate lower cache hit rate mean lower response times broadcast environments key reduce expected latency caching important pages reside slower disks 
pix gets fewer pages slowest disk gets pages second disks results net performance win 
response time broadcast units delta cache offset noise pix response time broadcast units noise cache offset delta delta delta pix delta delta delta vs pix varying delta varying noise pages accessed cache disk disk disk pix cache noise delta access locations vs pix noise implementing cost policies previous sections shown multi disk broadcast environments special characteristics correctly exploited result significant performance gains 
demonstrated need cost page replacement examined cost algorithm pix 
unfortunately policy pix implementable algorithm 
insight gained examining pix designed implemented approximation pix call lix victim disk disk lix lix new page new page disk disk page replacement lix lix modification lru takes account broadcast frequency 
lru maintains cache single linked list pages 
page cache accessed moved top list 
cache page chain chosen replacement 
contrast lix maintains number smaller chains corresponding disk broadcast lix reduces lru broadcast uses single flat disk 
page enters chain corresponding disk broadcast 
lru page hit moved top chain 
new page enters cache lix evaluates lix value see paragraph page bottom chain 
page smallest lix value ejected new page inserted appropriate queue 
queue different queue slot recovered chains fixed sizes 
dynamically shrink grow depending access pattern time 
lix performs constant number operations page replacement proportional number disks order lru 
shows example lix disk broadcast 
pages bottom chain 
lower lix value chosen victim 
new page picked second disk joins disk 
note relative changes sizes queues 
order compute lix value algorithm maintains data items cached page running probability estimate rob time access page 
page enters chain rob initially set zero set current time 
hit new probability calculated formula rob actor currenttime gamma gamma actor rob subsequently updated current time 
constant appropriately weigh access respect cumulative probability experiments set 
formula evaluated pages chains estimate current probability access 
value divided frequency page known exactly get lix value 
page lowest lix value ejected cache 
lix simple approximation pix spite performs surprisingly shown 
better approximations pix developed proposed improvements lru john lru 
experiment lix vs lru set experiments similar pix compare lix lru 
best performance lru isn offset equal cache size 
approximation lru isn able retain hot pages stored slowest disk performs poorly offset 
similar reasons lix perform best offset 
result compared performance lix lru modified version lix called behaves exactly lix assumes value frequency pages 
difference performance lru indicates better worse approximation probability provides lru performance difference lix shows role broadcast frequency plays performance caching strategies 
figures show performance algorithms different values delta large medium cache size respectively 
shows sensitivity algorithms changing delta case offset noise 
experiment lru performs worst consistently degrades delta increased 
better delta degrades 
benefits frequency apparent difference response time lix response time lix similar observation medium size cache fig 
absolute numbers lower due smaller cache relative ratios hold 
solid lines bottom graphs show ideal policy pix performs better lix small margin 
factors underlying results seen figures show distribution page access locations figures respectively delta set 
cases lix obtains smaller proportion pages slowest disk algorithms 
algorithms roughly similar cache hit rates differences distributions access different disks drives performance results case 
figures show performance algorithms varying noise large medium cache sizes respectively 
large cache pages case delta seen performs slightly better lru 
performance lix degrades noise expected outperforms lru entire region noise values 
graph medium cache similar lix significantly better lru doesn provide additional benefit 
results demonstrate lix effective isolating clients effects noise 
response time broadcast units delta cache offset noise lru lix pix response time broadcast units delta cache offset noise lru lix pix sensitivity delta large cache pages medium cache pages pages accessed cache disk disk disk lru lix cache noise delta pages accessed cache disk disk disk lru lix cache noise delta access locations large cache medium cache previous previous addressed multilevel broadcast disks related cache management techniques described projects mobile databases areas performed related 
stated previously notion repetitive broadcast medium database storage query processing investigated project bellcore herm 
intended exploit high bandwidth optical communication technology employed custom vlsi data filters performing associative searches continuous queries broadcast data 
broadcast data flat disk approach project address multi level disk issues addressed 
project provide optimistic form transaction management employed upstream network allowed clients communicate host 
intend investigate issues raised allowing upstream communication low bandwidth links part ongoing 
mobile computing group rutgers investigated techniques indexing broadcast response time broadcast units noise cache offset delta lru lix response time broadcast units noise cache offset delta lru lix noise sensitivity large cache medium cache data 
main thrust investigate ways reduce power consumption clients order preserve battery life 
indexing techniques described involve interleaving index information data forms restricted type multilevel disk 
investigate notion replicating actual data support non uniform access patterns investigate impact caching 
current assumed fixed broadcast program indexing needed 
currently investigating ways integrate indexes multilevel disk order support broadcast program changes due client population changes updates 
caching mobile environment considered barb 
model different considered volatile data clients inactive disconnected long periods time 
focus broadcasting caching efficiently detect avoid access stale data cache 
approach broadcasting data video demand taken 
technique called pyramid broadcasting splits object video clip number segments increasing sizes 
minimize latency segment broadcast frequently rest 
similar spirit key difference data needed client known priori segment choice movie decided need address issues related caching dealt 
issues arise due broadcast medium multi level device arise traditional types complex memory hierarchies 
need cost caching page replacement recognized domains wide variation cost obtaining data different levels storage hierarchy 
example describes need considering cost acquisition page replacement deep store file systems involving tertiary mass storage 
issue addressed client server database systems global memory hierarchy created allowing clients obtain data clients data cached fran 
server page replacement policies modified favor pages cached clients obtained disk expensive 
technique called disk directed proposed high performance computing applications kotz 
disk directed sends large requests devices allows devices fulfill requests piecemeal fashion order improves disk bandwidth 
tradeoff replication support access hot data making cold data expensive access investigated magnetic disks 
summary described design multilevel broadcast disk cache management policies style memory 
believe approach data management highly applicable asymmetric network environments naturally occur nii modern data delivery systems 
demonstrated designing disks broadcast program caching policy considered 
shown cases performance level disks outperform flat broadcast caching 
argued scheme interleaving data desirable provides uniform expected latency 
shown introducing cache provide advantage smoothing disagreement broadcast client access patterns 
cache gives clients way hoard hottest pages regardless frequently broadcast 
doing page replacement solely probability access increase client sensitivity server broadcast 
introduced caching policy took account broadcast frequency replacement 
showed improves client performance shields vagaries server broadcast 
clients cache items relatively hot reside slow disk avoid paying high cache penalties 
demonstrated straightforward implementation technique approximates ideal caching scheme 
technique modification lru accounts differences broadcast frequency data 
believe study interesting useful right just tip iceberg 
opportunities exploited 
considered static read case 
results change allowed broadcast data change cycle cycle 
kinds changes allowed order keep scheme manageable kinds indexing needed allow client intelligent decisions cost retrieving data item broadcast 
currently investigating prefetching introduced scheme 
client cache manager broadcast way opportunistically increase temperature cache 
exploring new cache management metrics deciding prefetch page 
provide guidance user wants configure broadcast 
experimental results show things happen workload concrete design principles deciding disks best relative spinning speeds segment client access range disks 
pursuing analytic model address 
basic design parameters broadcast disks kind understood needed develop query processing strategies exploit type media 
authors ranganathan providing number important insights properties broadcast programs 
franklin research supported part university maryland general research board number iri nsf gift intel 
acharya zdonik supported part onr number arpa order number gift intel 
salem placing replicated data reduce seek delays proc 
usenix file system conference may 
tech 
rep cs tr university maryland college park 
honeyman integrating mass storage file systems proc 
th ieee symposium mass storage systems 
arch archibald baer cache coherence protocols evaluation multiprocessor simulation model acm tocs november 
barb barbara imielinski caching strategies mobile environments proc 
acm sigmod conf minneapolis minnesota 
bowen gopal herman hickey lee mansfield architecture cacm december 
care carey franklin livny shekita data caching tradeoffs client server dbms architectures proc 
acm sigmod conf denver june 
dan dan dias yu effect skewed access buffer hits data contention data sharing environment proc 
th vldb conf brisbane australia august 
fran franklin carey client server caching revisited proc 
international workshop distributed object management edmonton alberta canada august published distributed object management ozsu dayal valduriez eds morgan kaufmann san mateo ca 
fran franklin carey livny global memory management client server dbms architectures proc 
th vldb conf vancouver canada august 
gray gray sundaresan weinberger quickly generating record synthetic databases proc 
acm sigmod conf 
herm herman gopal lee architecture high throughput database systems proc 
acm sigmod conf san francisco ca may 
howard kazar menees nichols satyanarayanan sidebotham west scale performance distributed file system acm tocs february 
imielinski badrinath mobile wireless computing challenges data management communications acm vol 
october 
imielinski viswanathan badrinath energy efficient indexing air proc 
acm sigmod conf minneapolis mn may 
john johnson shasha low overhead high performance buffer management replacement algorithm proc 
th vldb conf santiago chile 
katz katz adaption mobility wireless information systems ieee personal communications quarter 
knut knuth art computer programming vol ii addison wesley 
kotz kotz disk directed mimd multiprocessors st symposium os design implementation usenix monterey ca november 
neil neil weikum lru page replacement algorithm database disk buffering proc 
acm sigmod conf pp 

csim process oriented simulation language proceedings winter simulation conference pp 

wang wang rowe cache consistency concurrency control client server dbms architecture proc 
acm sigmod conf denver june 
wilkinson neimat maintaining consistency client cached data proc 
th vldb conf brisbane australia august 
imielinski pyramid broadcasting video demand service rutgers univ tech 
report dcs tr 
zdonik franklin alonso acharya disks air just pie sky ieee workshop mobile computing systems applications santa cruz ca december appear 

