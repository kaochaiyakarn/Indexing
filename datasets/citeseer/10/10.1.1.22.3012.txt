simple fast scalable non blocking concurrent fifo queue shared memory multiprocessor systems yi zhang department computing science chalmers university technology cs chalmers se non blocking fifo queue algorithm multiprocessor shared memory systems 
algorithm simple fast scales symmetric non symmetric multiprocessor shared memory systems 
experiments node sun enterprise gamma symmetric multiprocessor system gamma node sgi origin gamma cache coherent non uniform memory access multiprocessor system gamma indicate algorithm considerably outperforms best known alternatives multiprocessors level multiprogramming 
introduces new simple algorithmic mechanisms 
rst lowers contention key variables concurrent enqueue dequeue operations consequently results performance algorithm second deals pointer recycling problem inconsistency problem non blocking algorithms compare swap synchronisation primitive address 
construction selected compare swap compare swap atomic primitive scales contention supported modern multiprocessors implemented eoeciently 
concurrent fifo queue data structures fundamental data structures applications algorithms operating systems multiprocessor systems 
protect integrity shared queue concurrent operations created parallel application operating system partially supported national swedish real time systems research initiative www uu se supported swedish foundation strategic research ii swedish research council engineering sciences 
synchronised 
typically algorithms concurrent data structures including fifo queues form mutual exclusion locking synchronise concurrent operations 
mutual exclusion protects consistency concurrent data structure allowing process holder lock data structure time access data structure blocking processes try access concurrent data structure time 
mutual exclusion general solutions introduce blocking penalised locking introduces priority inversion deadlock scenarios performance bottlenecks 
time process spend blocked waiting get access critical section form substantial part algorithm execution time 
main reasons locking expensive 
rst reason eoeect blocking synchronisation process holding lock preempted process waiting lock unable perform useful process hold locks scheduled 
account multiprocessor running program multiprogramming environment serious 
second locking tends produce large amount memory interconnection network contention locks hot memory spots 
researchers eld rst designed dioeerent lock implementations lower contention system high congestion situation give dioeerent execution times dioeerent contention instances 
hand overhead due blocking remained 
address problems arise blocking researchers proposed non blocking implementations shared data structures 
non blocking implementation shared data objects new alternative approach problem designing scalable shared data objects multiprocessor systems 
non blocking implementations allow multiple tasks access shared object time enforcing mutual exclusion accomplish 
non blocking implementations shared data structures process allowed block process non blocking shared data structures signicant advantages lock ones 
avoid lock contention points locks 

provide high fault tolerance processor failures corrupt shared data objects eliminates deadlock scenarios tasks waiting locks held 

give priority inversion scenarios 
innovative architectures multiprocessor systems proposed years shared memory multiprocessor architectures gaining central place high performance computing 
decade shared memory multiprocessors built major computer vendors develop shared memory multiprocessor systems nowadays 
main classes shared memory multiprocessors cache coherent nonuniform memory access multiprocessors ccnuma architecture sun enterprise architecture origin architectures symmetric uniform memory access uma multiprocessors dioeerences coming architectural philosophy 
symmetric shared memory multiprocessors processor cache processors memory modules attach interconnect shared bus 
ccnuma relatively new system topology foundation generation shared memory multiprocessor systems 
uma systems ccnuma systems maintain global coherent memory resources managed single copy operating system 
cache coherency scheme ensures data held memory consistent system wide basis 
contrast symmetric shared memory multiprocessor systems memory accesses equal latency ccnuma systems memory latencies equal uniform name non uniform memory access 
accesses memory addresses located far modules take longer local memory 
addresses problem designing scalable practical fifo queues shared memory multiprocessor systems 
nonblocking fifo queue algorithm 
algorithm simple algorithmically implements fifo queue circular array introduces new algorithmic mechanisms believe general design eoecient non blocking algorithms multiprocessor systems 
rst mechanism restricts contention key variables generated concurrent enqueue dequeue operations low levels contention shared variables degrades performance memory tanks variables located processor memory interconnection network 
second algorithmic mechanism introduces mechanism deals pointer recycling known aba problem problem non blocking algorithms compare swap primitive address 
performance improvements due mechanisms simplicity comes simplicity richness structure circular arrays 
selected compare swap primitive scales contention supported modern multiprocessors implemented eoeciently 
evaluate performance algorithm node sun enterprise multiprocessor node sgi origin 
sun system uniform memory access uma multiprocessor system sgi system cache coherent nonuniform memory access ccnuma sun enterprise supports compare swap sgi origin 
experiments clearly indicate algorithm considerably outperforms best known alternatives uma ccnuma machines respect dedicated multiprogramming workloads 
second experimental results give better insight performance scalability non blocking algorithms uma ccnuma large scale multiprocessors respect dedicated multiprogramming workloads non blocking algorithms perform better blocking uma ccnuma large scale multiprocessors performance scalability increases multiprogramming increases 
concurrent fifo queue data structures fundamental data structures multiprocessor programs algorithms expected researchers proposed non blocking implementations 
lamport introduced wait free queue allow enqueue operation dequeue operation time 
herlihy wing algorithm non blocking linear fifo queue requires innite array 
prakash lee johnson non blocking queue algorithm singly linked list 
stone describes non blocking algorithm circular queue 
massalin pu non blocking array queue requires double compare swap atomic primitive available members motorola family processors :10.1.1.39.8065
valois presents non blocking queue algorithm non blocking data structures queue array 
michael scott nonblocking queue singly link list eoecient scalable non blocking algorithm compared algorithms mentioned 
remainder organised follows 
section give brief shared memory multiprocessors 
section presents algorithm proof sketch 
section performance evaluation algorithm 
concludes section 
shared memory multiprocessors architecture synchronization main classes shared memory multiprocessors nonuniform memory access ccnuma multiprocessors symmetric multiprocessors 
familiar design shared memory multiprocessor systems xed bus shared bus multiprocessor system 
bus path shared processors usable time handle transfers cpu memory 
communicating bus cpus share memory requests synchronise local cache memories 
systems include silicon graphics challenge onyx systems octane sun enterprise digital server vendors systems 
central crossbar mainframes supercomputers crossbar switch build shared multiprocessor systems higher bandwidth feasible busses switch supports multiple concurrent paths active 
systems include mainframes cray sun new enterprise graphically describes architecture new sun enterprise 
shared bus central crossbar systems usually called uniform memory access systems cpu equally distant time memory locations 
uniform memory access shared memory multiprocessors dominate server market common desktop 
price systems rise quite fast number processors increases 
ll set set fp return value sc set value pset return true return false load linked store conditional primitive ccnuma relatively new system topology foundation generation shared memory multiprocessor systems 
commodity processing modules distributed coherent memory ccnuma extends power performance shared memory multiprocessor systems preserving shared memory programming model 
uma systems ccnuma systems maintain global coherent memory resources managed single copy operating system 
hardware cache coherency scheme ensures data held memory consistent systemwide basis 
memory scale linearly processing modules added single backplane bus 
nodes connected interconnect speed nature varies widely 
normally memory near cpu accessed faster memory locations away 
attribute leads non non uniform 
ccnuma systems include convex exemplar sequent numa silicon graphics cray mp origin onyx 
silicon graphics origin system dual processor node connected router 
routers connected fat hypercube interconnect graphically describes architecture 
ccnuma systems expected dominant systems large high performance systems years 
reasons scale processors needed 
support cache coherent globally addressable memory model entry level incremental costs relatively low 
widely available hardware synchronisation primitive common architectures compare swap 
compare swap primitive takes arguments pointer memory location old new values 
seen describes specication compare swap primitive automatically checks contents memory location pointer points equal old value updates pointer new value 
case returns boolean value indicates succeeded 
ibm system rst computer system introduced compare swap 
sun enterprise systems support hardware primitive 
newer architectures sgi origin included introduce load linked store conditional instruction implemented compare swap primitive 
load linked store conditional comprised simpler operations load linked store conditional 
load linked loads word memory register 
matching store conditional stores back possibly new value memory word value memory word modied process 
word modied store succeeds returned 
store conditional fails memory modied returned 
specication operation shown 
information sgi origin sun enterprise reader referred respectively 
compare swap int mem register old new temp mem temp old mem new new old new mem compare swap primitive compare swap primitive gives rise pointer recycling known aba problem 
aba problem arises process reads value shared memory location computes new value compare swap updates memory location checking value memory location mistakenly concluding operation changed value memory location 
read compare swap operation processes may changed context memory location back 
scenario compare swap primitive fails detect existence operations changed value memory location non blocking implementations shared data structures able detect having operation high latency creates high contention 
common solution aba problem split shared memory location parts part counter part data 
way process updates memory location increments counter atomic operation 
drawbacks solution 
rst real word length decreases counter occupies part word 
second counter rounds possibility aba scenario occur especially systems fast processors systems studying 
new simple eoecient technique overcome aba problem technique described section algorithm 
compare swap int mem register old new temp ll mem temp old return false sc mem new return true emulating compare swap load linked store conditional algorithm design phase eoecient non blocking data structure large spent guaranteeing consistency data structure generating interconnection transactions 
reason performance synchronisation protocol multiprocessor systems heavily depends interconnection transactions generate 
high number transactions causes degradation performance memory banks processor memory interconnection network 
rst step designing algorithm tried simple synchronisation instructions primitives low latency generate lot coherent traoec powerful support high level synchronisation needed non blocking implementation fifo queue 
construction described selected compare swap atomic primitive meets important goals looking 
quite powerful primitive simple read write registers suoecient building non blocking implementation interesting shared data structure :10.1.1.164.8106
second supported modern multiprocessors implemented eoeciently 
generate lot coherent traoec 
problem compare swap primitive gives rise pointer recycling known aba problem 
second step tried designing algorithm compare swap operation little possible 
compare swap operation eoecient synchronisation operation latency increases linearly number processors concurrently transactional generates coherent traoec 
hand read update operations require single message interconnection network generate coherent traoec 
third step propose simple new solution overcomes aba problem generate lot coherent traoec restrict size queue 
commented pseudo code new nonblocking queue algorithm 
algorithm simple practical surprised nd literature 
non blocking queue algorithmically implemented circular array head tail pointer ghost copy null introduced order help avoid aba problem going see section 
design phase algorithm realised structural properties circular array reduce number compare swap operations algorithm uses overcome eoeciently aba problem ii previous non blocking implementations trying guarantee tail head pointers show real head tail queue allowing tail head pointers lag reduce number compare swap asymptotically close optimal 
assume enqueue operations inserts data tail queue dequeue operations remove data head queue queue empty 
algorithm allow head tail pointers lag actual head tail queue way operations consistently adjust tail head pointer performing compare swap operation 
implement queue circular array queue operation successfully enqueues dequeues data knows index array data placed taken respectively index divided operation try update head tail queue skip step updating head tail head tail lag actual head tail 
way amortised number compare swap operations enqueue dequeue operation compare swap operation enqueue dequeue operation necessary 
drawback technique introduces operation average need read operations nd actual head tail queue latency gamma compare swap operations larger latency read operations performance gain algorithm performance gains increase number processes increases 
true array queues inferior link queues require maximum queue size 
hand require memory management schemes link queue implementations need spatial locality link queues 
account having simple fast practical implementation mind decided cyclical array construction 
compare swap primitive atomically swing head tail pointers current value new 
sgi origin system emulate compare swap atomic primitive load linked store conditional instruction implementation shown 
compare swap manner susceptible aba problem 
past researchers proposed attach counter pointer reducing way size memory pointers point eoeciently 
observe circular array works counter mod length cyclical array arbitrary large 
way designing queue circular array overcome aba problem way counters having attach expensive counters pointers restrict pointer size 
henceforth enqueue operation takes place tail changes direction goes back zero reaches array 
henceforth tail change back old value shared object nishes enqueue operations successive operations exactly counter mod 
holds dequeue operations 
length cyclical structure queue head unsigned integer nodes array pointer tail unsigned integer pointer queue queue temp temp queue malloc sizeof queue temp head temp tail define null null means empty temp nodes null temp nodes null return temp initialisation atomic operations array potential places aba problem take place giving rise scenarios array empty 

array location actual tail queue content null 
processes nd actual tail 
process enqueues data updates content location compare swap 
contents null succeeds 
process dequeues data updates content location null changing pointer head 
process enqueues data updates contents location compare swap 
content null incorrectly succeeds enqueue non active cell queue 
array full 

array location actual head queue content 
processes nd actual head read content location 

process dequeues data updates content location null compare swap 
contents succeeds 

process comes enqueues data updates content location changing pointer tail 

process dequeues data updates contents location null compare swap 
content succeeds dequeue data fifo order 
order overcome specic aba instances counter negative side introduce new simple mechanism surprised nd literature 
idea simple value describe entry array empty null null 
processor dequeues item swap cell nulls way consecutive dequeue operations cell give dioeerent null values cell 
returning aba scenario described scenario look cell empty 
array location actual tail content null 
processes nd actual tail 
location 
process enqueues data updates content location compare swap operation 
content null succeeds 
process dequeues data updates content location null 
process enqueues data updates content location compare swap 
content null fails turn 
variable help dequeue operations determine null time 
mechanism aba scenario place process preempted process changes aba ba scenario 
aba scenario pointer recycling problem order take place dequeue operations needed take system subsequently dequeue operations needed order take system operations take place process experience pointer recycling preempted 
account arbitrary large number probability aba scenario happen go close want sketches proof theorem theorem algorithm give rise pointer recycling problem dequeue operation preempted operations arbitrary large number 
rest assume selected large give rise pointer recycling problem system 
accessing shared object modelled history history nite sequence operation invocation response events 
response event preceded corresponding invocation event 
case dioeerent operations invoked enqueue operation dequeue operation 
operation called complete response event history said pending 
history called complete operations complete 
global time model operation time interval linear time axis think starting nishing time instants time interval operation said pending 
exists precedence relation operations history denoted strict partial order means ends starts operations incomparable point technique dioeerent null values extended dioeerent values requiring dequeue operations preempt operation inorder cause pointer recycling problem 
think scheme ull values simple suoecient systems looking 
called overlapping 
complete history partial order operations extended total order respects specication object 
possible history produced implementation mapped history operations auxiliary array bounded right side 
order simplify proof new auxiliary array 
algorithm guarantees enqueue operations enqueue data consecutive array entries left right array dequeue operations dequeue items left right 
way sure operations dequeued order enqueued 
previous theorem enqueue operation nishes writing entry array head pointer implementation guides dequeue operations pass entry making sure enqueued item going lost 
sketches proof theorem theorem complete history enqueue enqueue dequeue dequeue dequeue dequeue overlap 
dequeue operation dequeues succeeds read empty array entry written atomic compare swap operation making way sure operation dequeues item 
array entry written enqueue operation dequeue operations dequeue items really enqueued 
sketches proof theorem theorem dequeued enqueued enqueue dequeue theorems guarantee linearizable behaviour fifo queue implementation 
due space constraints sketched proof theorems 
performance evaluation implemented algorithm conducted experiments sun enterprise mhz ultrasparc processors sgi origin mhz mips processors 
sun multiprocessor symmetric multiprocessor sgi multiprocessor ccnuma 
ensure accuracy results exclusive access multiprocessors conducting experiments 
tests compared performance algorithm new performance algorithm michael scott ms algorithm appears best non blocking fifo queue algorithm 
experiments included solution locks ordinary lock demonstrate superiority non blocking solutions blocking ones 
experiments sun enterprise conducted experiments sun multiprocessor exclusive 
rst experiment measured average time taken processors perform pairs enqueue dequeue operations 
experiment process enqueues item dequeues item repeats 
second experiment processes stay idle random time consecutive queue operations 
third experiment parallel quick sort uses queue data structure evaluate performance queue implementations 
parallel quick sort sort randomly generated keys 
results experiment shown 
horizontal axis gures represent number processors vertical represents execution time normalised michael scott algorithm 
rst experiments processors show new algorithm outperforms ms algorithm spin lock algorithm 
third experiment shows new queue implementation better response time sorting algorithm 
experiments sgi multiprocessor sgi machine rst experiments basically experiments performed sun multiprocessor 
dioeerence sgi machine select system dedicated system multiprogramming level multiprogrammed system processes processor multiprogramming level respectively 
sun multiprocessor possible 
figures show graphically performance results 
interesting algorithm gives performance improvements machines 
sgi multiprocessor possible radiosity splash shared address space parallel applications 
shows performance improvement compared original splash implementation 
vertical axis represents execution time normalised splash implementation 
new bounded non blocking concurrent fifo queue algorithm shared memory multiprocessor systems 
algorithm simple introduces new simple algorithmic mechanisms general design eoecient non blocking algorithms 
experiments clearly indicate algorithm considerably outperforms best known alternatives uma ccnuma machines respect dedicated multiprogramming workloads 
experimental results give better insight performance scalability non blocking algorithms uma ccnuma large scale multiprocessors respect dedicated multiprogramming workloads non blocking algorithms perform better blocking uma ccnuma large scale multiprocessors 
david great help writing phase 
grateful carl andy paul impossible possible exclusive access heavily physics department loaded parallel machines 
agarwal adaptive synchronization techniques proceedings th annual international symposium computer architectures pp 

extending smp envelope ieee micro pp 
jan feb 
origin onyx performance tuning optimization guide sgi com library tpl cgi bin browse cgi coll db bks cmd toc pth 
culler singh gupta parallel computer architecture hardware software approach morgan kaufmann publishers herlihy wait free synchronization acm transactions programming languages systems pp 
january 
herlihy wing linearizability correctness condition atomic objects toplas pp 
july 
karlin li manasse owicki empirical studies competitive spinning shared memory multiprocessor proceedings th acm symposium operating systems principles pp 
october 
lamport specifying concurrent program modulus acm transaction programming languages systems pp 
april 
laudon lenoski sgi origin ccnuma highly scalable server proceedings th annual international symposium computer architecture isca computer architecture news vol 
pp 
acm press june 
massalin pu lock free multiprocessor os kernel technical report cucs computer science department columbia university :10.1.1.39.8065
mellor crummey scott algorithms scalable synchronization shared memory multiprocessors acm trans 
computer systems february 
michael scott nonblocking algorithms locking multiprogrammed shared memory multiprocessors journal parallel distributed computing pp 

prakash lee johnson nonblocking algorithm shared queues compare swap ieee transactions computers pp 

shavit elimination trees construction pools stacks proc 
th annual acm symposium parallel algorithms architectures pp 
july 
stone nonblocking compare swap algorithm shared circular queue parallel distributed computing engineering systems pp 
elsevier science 
valois lock free data structures phd thesis rensselaer polytechnic institute department computer science 
woo singh gupta splash programs characterization methodological considerations proceedings nd international symposium computer architectures pp 
june 
zahorjan lazowska eager eoeect scheduling discipline spin overhead shared memory parallel systems ieee transactions parallel distributed systems pp 
april 
enqueue pointer queue newnode pointer data type boolean loop te tail read tail ate te tt nodes ate slot tail temp ate want find actual tail tt null tt null check tail consistency te tail break tail meet head possible queue full temp head break check cell tt nodes temp ate temp temp ate check tail consistency te tail continue check queue full temp head ate temp tt nodes ate cell head occupied tt null tt null return failure queue full help dequeue update head cas head temp ate try enqueue continue tt null tnew newnode tnew newnode check tail consistency te tail continue get actual tail try enqueue data cas nodes ate tt tnew temp enqueue cas tail te temp return success endloop enqueue operation dequeue pointer queue pointer pointer data type loop th head read head want dequeue temp th tt nodes temp find actual head loop tt null tt null check head consistency th head break consecutive null means empty return temp tail return temp temp cell tt nodes temp check head th head continue check queue empty temp tail help enqueue update cas tail temp temp continue try dequeue tt null null check head consistency th head continue get actual head null value means empty cas nodes temp tt temp cas head th temp tt return value return endloop dequeue operation number processors new non blocking ms non blocking ordinary lock sun full contention number processors new non blocking ms non blocking ordinary lock sun random waiting contention number processors new non blocking ms non blocking ordinary lock quick sort sun results sun multiprocessor normalized time number processors new non ms non blocking ordinary lock level normalized time number processors new non ms non blocking ordinary lock level normalized time number processors new non ms non blocking ordinary lock level results sgi multiprocessor dioeerent multiprogramming levels full contention normalized time number processors new non ms non blocking ordinary lock level normalized time number processors new non ms non blocking ordinary lock level normalized time number processors new non ms non blocking ordinary lock level results sgi multiprocessor dioeerent multiprogramming levels random waiting contention number processors new non blocking ms non blocking ordinary lock quick sort number processors non queue spinlock radiosity applications sgi 
