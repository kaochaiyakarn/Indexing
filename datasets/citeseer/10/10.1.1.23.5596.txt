journal artificial intelligence research submitted published exploiting causal independence bayesian network inference nevin zhang cs ust hk department computer science university science technology hong kong david poole poole cs ubc ca department computer science university british columbia main mall vancouver canada new method proposed exploiting causal independencies exact bayesian network inference 
bayesian network viewed representing factorization joint probability multiplication set conditional probabilities 
notion causal independence enables factorize conditional probabilities combination smaller factors consequently obtain finer grain factorization joint probability 
new formulation causal independence lets specify conditional probability variable parents terms associative commutative operator sum max contribution parent 
start simple algorithm bayesian network inference evidence query variable uses factorization find posterior distribution query 
show algorithm extended exploit causal independence 
empirical studies cpcs networks medical diagnosis show method efficient previous methods allows inference larger networks previous algorithms 

reasoning uncertain knowledge beliefs long recognized important research issue ai shortliffe buchanan duda 
methodologies proposed including certainty factors fuzzy sets dempster shafer theory probability theory 
probabilistic approach far popular alternatives mainly due knowledge representation framework called bayesian networks belief networks pearl howard matheson 
bayesian networks graphical representation dependencies random variables 
bayesian network bn dag nodes representing random variables arcs representing direct influence 
independence encoded bayesian network variable independent non descendents parents 
bayesian networks aid knowledge acquisition specifying probabilities needed 
network structure sparse number probabilities required number required independencies 
structure exploited computationally inference faster pearl lauritzen spiegelhalter jensen shafer shenoy 
definition bayesian network constrain variable depends parents 
exploited knowledge acquisition inference 
case dependencies depend particular values variables dependencies stated rules poole trees boutilier ai access foundation morgan kaufmann publishers 
rights reserved 
zhang poole multinets geiger heckerman 
function described binary operator applied values parent variables 
known causal independencies seek exploit 
causal independence refers situation multiple causes contribute independently common effect 
known example noisy gate model 
knowledge engineers specific causal independence models simplifying knowledge acquisition henrion olesen olesen 
heckerman formalize general concept causal independence 
formalization refined heckerman breese 
kim pearl showed noisy gate speed inference special kind bns known polytrees ambrosio showed level bns binary variables 
general bns olesen 
heckerman proposed ways causal independencies transform network structures 
inference transformed networks efficient original networks see section 
proposes new method exploiting special type causal independence see section covers common causal independence models noisy gates noisy noisy gates noisy adders special cases 
method observation 
bn viewed representing factorization joint probability multiplication list conditional probabilities shachter zhang poole li ambrosio 
type causal independence studied leads factorization conditional probabilities section 
finer grain factorization joint probability obtained result 
propose extend exact inference algorithms exploit conditional independencies finer grain factorization provided causal independence 
state art exact inference algorithm called clique tree propagation ctp lauritzen spiegelhalter jensen shafer shenoy 
proposes algorithm called variable elimination section related spi shachter li ambrosio extends finer grain factorization see sections 
compiling secondary structure finding posterior probability variable query oriented needs part network relevant query observations necessary answer query 
chose ctp simplicity carry inference large networks ctp deal 
experiments section performed cpcs networks provided pradhan 
networks consist nodes respectively contain abundant causal independencies 
best terms exact inference transform networks jensen heckerman technique apply ctp 
experiments computer ran memory constructing clique trees transformed networks 
occurs answer query 
extended algorithm able answer randomly generated queries observations findings networks 
propose perform jensen heckerman transformation apply 
experiments show significantly efficient extended algorithm 
brief review concept bayesian network issue inference 
exploiting causal independence bayesian network inference 
bayesian networks assume problem domain characterized set random variables 
beliefs represented bayesian network bn annotated directed acyclic graph nodes represent random variables arcs represent probabilistic dependencies variables 
terms node variable interchangeably 
associated node conditional probability variable parents 
addition explicitly represented conditional probabilities bn implicitly represents conditional independence assertions 
letx xn enumeration nodes bn node appears children xi set parents 
bayesian network represents independence assertion variables fx xi values parents 
assertions entail joint probability variables 
chain rule xn ny ny xi xij xi second equation true conditional independence assertions 
conditional xij xi specification bn 
consequently theory arbitrary probabilistic reasoning bn 
inference inference refers process computing posterior xjy setx query variables obtaining list observed variables corresponding list observed values 
consists query variable 
theory xjy obtained marginal turn computed joint xn summing variables outside 
practice viable summing variable joint probability requires exponential number additions 
key efficient inference lies concept factorization 
joint probability list factors functions construct joint probability 
factor function set variables number 
say factor contains avariable factor function variable say factor variables depends 
andf factors wheref factor contains xi yj write asf xi yj andf factor yj zk yj variables common tof andf 
product andf factor function union variables xi yj zk defined xi yj zk xi yj yj zk zhang poole bayesian network 
letf xi function xi 
setting inf xi particular value xi function xi 
iff xi factor sum variable resulting factor variables xi defined xi xi xi possible values 
equation bn viewed representing factorization joint probability 
example bayesian network factorizes joint list factors ja ja je multiplying factors yields joint probability 
suppose joint zm factorized multiplication list fm 
zm summing zm requires exponential number additions obtaining factorization ofp zm done computation 
consider procedure inputs list factors avariable 
output list factors 

remove factors fk 
add new factor return theorem suppose joint zm factorized multiplication list factors 
returns list factors zm 
exploiting causal independence bayesian network inference proof suppose consists fm appears factors fk 
zm zm fi ky fi theorem follows 
variables appear fk participated small portion variables 
inference bn tractable cases general problem np hard cooper 

variable elimination algorithm previous section simple xjy 
algorithm intuitions underlying ambrosio symbolic probabilistic inference spi shachter li ambrosio appeared zhang poole 
essentially dechter bucket elimination algorithm belief assessment 
algorithm called variable elimination sums variables list factors 
ordering variables summed required input 
called elimination ordering 
procedure fi inputs list conditional probabilities bn list query variables list observed variables corresponding list observed values elimination ordering variables output xjy 

set observed variables factors corresponding observed values 

empty remove 
endwhile 
seth multiplication factors function variables inx 

xh 
renormalization theorem output xjy 
proof consider modifications procedure 
remove step 
factor produced step function variables inx andy 
add new step step sets observed variables observed values 
zhang poole letf function variables ina 
jy denote 
letf andh functions ofy variables 
evident jy jy jy jy jy consequently modifications change output procedure 
theorem modifications factor produced step simply marginal 
consequently output xjy 
complexity measured number numerical multiplications numerical summations performs 
optimal elimination ordering results complexity 
problem finding optimal elimination ordering np complete arnborg 
commonly heuristics include minimum deficiency search maximum cardinality search tarjan yannakakis 
kj empirically shown minimum deficiency search best existing heuristic 
minimum deficiency search experiments better maximum cardinality search 
versus clique tree propagation clique tree propagation lauritzen spiegelhalter jensen shafer shenoy compilation step transforms bn secondary structure called clique tree junction tree 
secondary structure allows ctp compute answers queries query variable fixed set observations twice time needed answer query clique tree 
applications desirable property user want compare posterior probabilities different variables 
ctp takes build secondary structure observations received 
bayesian network reused cost building secondary structure amortized cases 
observation entails propagation network 
observations processes query time 
user wants posterior probabilities variables sequence observations needs run variables observation sets 
cost terms number summations multiplications answering single query observations order magnitude ctp 
particular clique tree propagation sequence encodes elimination ordering elimination ordering results approximately summations multiplications factors ctp discrepancy form marginals cliques works conditional probabilities directly 
observations simpler observed variables eliminated start algorithm observation ctp requires propagation evidence 
query oriented prune nodes irrelevant specific queries geiger lauritzen baker boult 
ctp hand clique tree structure kept static run time allow pruning irrelevant nodes 
ctp encodes particular space time tradeoff 
ctp particularly suited case observations arrive incrementally want posterior probability node exploiting causal independence bayesian network inference cost building clique tree amortized cases 
suited queries single query variable observations 
unfortunately large real world networks ctp deal due time space complexities see section examples 
networks answer possible queries permits pruning irrelevant variables 

causal independence bayesian networks place restriction node depends parents 
unfortunately means general case need specify exponential number parents number conditional probabilities node 
cases structure probability tables exploited acquisition inference 
case investigate known causal independence 
interpretation arcs bn represent causal relationships cm viewed causes jointly bear 
causal independence refers situation cm contribute independently 
precisely cm said causally independent exist random variables frame set possible values ase 
probabilistically depends conditionally independent 
exists commutative associative binary operator frame independence notion pearl jz mean independent ofy condition fc cm similarly variables 
andi jjc 
refer contribution toe 
technical terms causes causally independent common effect individual contributions different causes independent total influence effect combination individual contributions 
call variable independent contributions different sources collected combined lack better name 
non convergent variables simply called regular variables 
call base combination operator ofe 
definition causal independence slightly different heckerman breese srinivas 
covers common causal independence models noisy gates pearl noisy max gates ez noisy gates noisy adders dagum special cases 
see examples 
example lottery buying lotteries affects wealth 
amounts money spend buying different kinds lotteries affect wealth independently 
words causally zhang poole independent change wealth 
ck denote amounts money spend types lottery tickets 
changes wealth due buying different types lottery tickets respectively 
depends probabilistically conditionally independent 
lete total change wealth due lottery buying 
ck causally independent base combination operator ofe numerical addition 
example instance causal independence model called noisy adders 
ifc ck amounts money spend buying lottery tickets lottery ck causally independent winning ticket reduces chance winning 

represent expected change wealth buying tickets lottery causally independent arcs 
example alarm consider scenario 
different motion sensors connected burglary alarm 
sensor activates alarm rings 
different sensors different reliability 
treat activation random variable 
reliability sensor reflected assume sensors fail independently assume alarm caused sensor activation base combination operator logical operator 
example instance causal independence model called noisy gate 
example instance causal independence models know example contract renewal faculty members university evaluated teaching research service purpose contract renewal 
faculty member contract renewed renewed pay raise renewed pay raise renewed double pay raise depending performance evaluated unacceptable areas acceptable areas excellent area excellent areas 
andc fractions time faculty member spends teaching research service respectively 
represent evaluation gets area 
take values depending evaluation unacceptable acceptable excellent 
variable depends probabilistically 
reasonable assume conditionally independent 
contract renewal result 
variable take values depending contract renewed renewed pay raise renewed pay raise renewed double pay raise 
base combination operator table 
called exception independence assumption pearl 

called accountability assumption pearl 
assumption satisfied introducing node represent causes henrion 
exploiting causal independence bayesian network inference fractions time faculty member spends areas causally independent contract renewal result 
traditional formulation bayesian network need specify exponential number parents number conditional probabilities variable 
causal independence number conditional linear inm 
causal independence reduce complexity knowledge acquisition henrion pearl olesen olesen 
sections show causal independence exploited computational gain 
conditional probabilities convergent variables allows exploit structure bayesian network providing factorization joint probability distribution 
section show causal independence factorize joint 
algorithm cm 
want break simpler factors need table exponential inm 
proposition shows causal independence proposition lete node bn cm parents ofe 
ifc cm causally independent conditional cm obtained conditional jc cm jc value ofe 
base combination operator ofe 
proof definition causal independence entails independence assertions fc andi jc axiom weak union pearl jfc cmg 
mutually independent fc cmg 
definition causal fc jc cm jc cm jfc cmg jc cm jc cm jc cm cm jc jc sections develop algorithm exploiting causal independence inference 

anonymous reviewer helping simplify proof 
zhang poole 
causal independence heterogeneous factorizations section shall introduce operator combining factors contain convergent variables 
operator basic ingredient algorithm developed sections 
operator shall rewrite equation form convenient inference introduce concept heterogeneous factorization 
consider andg 
lete ek convergent variables appear leta list regular variables appear andg letb list variables appear inf list variables appear ing 
andc contain convergent variables regular variables 
suppose base combination operator ei 
function ek variables ina andc 
defined fg ek ek ek value 
shall asf ek ek explicit arguments andg 
note base combination operators different convergent variables different 
proposition exhibits basic properties combination operator proposition 
iff andg share convergent variables simply multiplication andg 

operator commutative associative 
proof item obvious 
commutativity follows readily commutativity multiplication base combination operators 
shall prove associativity special case 
general case proved line reasoning 
andh factors contain variable convergent 
need show fg gh 
base combination operator ofe 
associativity value ofe fg fg 
note base combination operators summations indexed 
associated operator binary operator associated corresponding convergent variable 
examples ease exposition base combination operator 
type base combination operator may sum max different variables network keep track operators associated convergent variables 
complicate description 
exploiting causal independence bayesian network inference gh gh proposition proved propositions give properties correspond operations exploited algorithm 
proofs straight forward omitted 
proposition factors appears inf ing fg fg proposition factors share convergent variables rewriting equation fh gf noticing contribution variable possible values ase define functions fi ci fi ci jci value ofe 
shall refer contributing factor toe 
operator rewrite equation follows cm fi ci interesting notice similarity equation equation 
equation conditional independence allows factorize joint probability factors involve variables equation causal independence allows factorize conditional probability factors involve variables 
ways factors combined different equations 
heterogeneous factorizations consider bayesian network 
factorizes joint list factors ja ja je say factorization homogeneous factors combined way multiplication 
suppose convergent variables 
conditional probabilities factorized follows ja ja je zhang poole instance contributing factor ofa toe 
say list factors andp constitute heterogeneous factorization ofp joint probability obtained combining factors proper order multiplication operator word heterogeneous signify fact different factor pairs combined different ways 
call heterogeneous factor needs combined fik operator combined factors multiplication 
contrast call andp homogeneous factors 
shall refer heterogeneous factorization heterogeneous factorization represented bn 
obvious heterogeneous factorization finer grain homogeneous factorization represented bn 

flexible heterogeneous factorizations deputation extends exploit finer grain factorization 
compute answer query summing variables factorization just 
correctness guaranteed fact factors homogeneous factorization combined multiplication order distributivity multiplication summations see proof theorem 
proposition operator distributive summations 
factors heterogeneous factorization combined arbitrary order 
example consider heterogeneous factorization 
correct andf andf correct andf want combine multiplication combined sibling heterogeneous factors 
overcome difficulty transformation called deputation performed bn 
transformation change answers queries 
heterogeneous factorization represented transformed bn flexible sense heterogeneous factorization joint probability flexible joint probability multiplication homogeneous factors combination heterogeneous factors property allows carry multiplication homogeneous factors arbitrary order associative commutative combination heterogeneous factors arbitrary order 
conditions proposition satisfied exchange multiplication combination guarantee conditions proposition elimination ordering needs constrained sections 
heterogeneous factorization ofp previous section flexible 
consider combining heterogeneous factors 
operator commutative exploiting causal independence bayesian network inference bn deputation convergent variables 
associative combine obtaining conditional probability combine resulting conditional probabilities 
combination multiplication ja ja je ja ja je convergent ande appear factor 
consequently equation hold factorization flexible 
problem arises convergent variable shared factors siblings 
example want combine andf order tackle problem introduce new deputation variable heterogeneous factor contains single convergent variable 
deputation transformation apply bn heterogeneous factorization represented bn flexible 
convergent variable 
copy ofe parents parents ofe contributing factors ofe parent ofe set conditional eje follows eje ife shall deputy ofe 
deputy convergent variable definition 
convergent deputation regular variable deputation 
shall refer new regular variable 
contrast shall refer variables regular deputation old regular variables 
conditional je homogeneous factor definition 
called function written asi ensures take value 
deputation bn obtained bn convergent variables 
deputation bn deputy variables convergent variables deputy variables convergent variables 
zhang poole shows deputation bn 
factorizes joint probability homogeneous factors heterogeneous factors factorization important properties 

heterogeneous factor contains convergent variable 
recall longer convergent variables 

convergent appears homogeneous factor 

functions homogeneous factors contain convergent variables 
properties shared factorization represented deputation bn 
proposition heterogeneous factorization represented deputation bn flexible 
proof consider combination heterogeneous factors deputation bn 
combination operator commutative associative carry combination steps 
convergent deputy combine heterogeneous factors yielding conditional ofe combine resulting conditional probabilities 
follows property mentioned different convergent ande andp share convergent variables 
combination just multiplication 
consequently combination heterogeneous factors deputation bn just multiplication conditional probabilities convergent variables 
joint probability variables deputation bn multiplication conditional probabilities variables multiplication conditional probabilities regular variables multiplication conditional probabilities convergent variables multiplication homogeneous factors combination heterogeneous factors proposition proved 
deputation change answer query 
precisely proposition posterior xjy bn deputation 
exploiting causal independence bayesian network inference proof letr ande lists old regular new regular deputy variables deputation bn respectively 
suffices show thatp original bn deputation bn 
new regular lete deputy 
easy see quantity deputation bn asp ej original bn 
proposition proved 
deputation bn rj rj rj 
tidy heterogeneous factorizations ej ej original bn far encountered heterogeneous factorizations correspond bayesian networks 
algorithm intermediate heterogeneous factorizations necessarily correspond bns 
property combine form appropriate marginal probabilities 
general intuition heterogeneous factors combine sibling heterogeneous factors multiplied factors containing original convergent variable 
previous section mentioned properties heterogeneous factorization represented deputation bn property show factorization flexible 
properties qualify factorization tidy heterogeneous factorization defined 
letz zk list variables deputation bn convergent deputy fz corresponding new regular 
flexible heterogeneous factorization ofp zk said tidy 
convergent deputy fz factorization contains homogeneous factor 
functions homogeneous factors contain convergent variables 
stated earlier heterogeneous factorization represented deputation bn tidy 
certain conditions theorem obtain tidy factorization ofp zk summing tidy factorization ofp zk procedure 
inputs list homogeneous factors list heterogeneous factors avariable 
zhang poole output list heterogeneous factors list homogeneous factors 

remove factors multiply resulting say factors setf nil 

remove factors combine resulting say factors nil 

nil add new homogeneous factor zf 

add new heterogeneous factor 

return 
theorem suppose list homogeneous factors list heterogeneous factors constitute tidy factorization ofp zk 
ifz convergent variable old regular variable new regular variable deputy list fz procedure sum returns tidy heterogeneous factorization ofp zk 
proof theorem quite long appendix 

causal independence inference task xjy bn 
proposition deputation bn 
elimination ordering consisting variables legitimate deputy appears corresponding new regular 
ordering minor adaptations minimum deficiency search maximum cardinality search 
algorithm xjy deputation bn 
called extension 
procedure inputs list homogeneous factors deputation bn list heterogeneous factors deputation bn list query variables list observed variables corresponding list observed values legitimate elimination ordering 
output xjy 

set observed variables factors observed values 

empty remove 
sum 
endwhile exploiting causal independence bayesian network inference 
seth multiplication factors combination factors 
function variables inx 

xh 
renormalization theorem output xjy 
proof consider modifications algorithm 
remove step 
factor produced step function variables inx andy add new step step sets observed variables inh observed values 
shall show modifications change output algorithm show output modified algorithm xjy 
letf andh functions ofy variables 
evident jy jy jy regular variable jy jy jy jy jy consequently modifications change output procedure 
elimination ordering legitimate case deputy summed corresponding new regular 
letz zk remaining variables time execution algorithm 
fz fz 
fact factorization represented deputation bn tidy enable repeatedly apply theorem conclude modifications factor created step simply marginal 
consequently output isp xjy 
example subsection illustrates walking example 
je deputation bayesian network shown 
suppose elimination ordering ande 
step fp ff procedure enters loop sums variables 
summing outa fp ff 
summing outb fp ff 
zhang poole summing fi ff 
summing fi ff 
summing fi ff 
summing fi ff 
summing 
procedure enters step example 
procedure returns whichis je required probability 
comparing comparing notice summing variable combine factors contain variable 
factorization works finer grain factorization 
running example works factorization initially consists factors contain variables factorization uses initially include factors contain variables 
hand uses operator expensive multiplication 
consider instance calculating 
convergent variable variables binary 
operation requires numerical multiplications numerical summations 
hand andg requires numerical multiplications 
despite operator efficient 
shall provide empirical evidence support claim section 
see simple example true consider bn convergent variable 
suppose variables binary 
elimination andc requires numerical multiplications numerical additions 
hand deputation bn shown elimination ande requires numerical multiplications numerical additions 
note summing requires numerical multiplications summing ci heterogeneous factors containing combining exploiting causal independence bayesian network inference bn deputation transformations 
pairwise requires multiplications 
resultant factor needs multiplied requires numerical multiplications 

previous methods methods proposed previously exploiting causal independence speed inference general bns olesen heckerman 
causal independence transform topology bn 
transformation conventional algorithms ctp inference 
shall illustrate methods bn 
base combination operator ofe denote contribution toe ci contributing factor toe 
parent method olesen transforms bn 
transformation variables regular new ande possible values ase 
conditional probabilities ofe ande conditional probability ofe jc jc je value ofe ofe ofe 
shall pd refer algorithm performs parent transformation uses inference 
zhang poole temporal transformation heckerman converts bn 
variables regular transformation newly introduced variables possible values ase 
conditional probability ofe jc value ofe fori conditional probability stands fore ei ci fi ci possible value 
shall tt refer algorithm performs temporal transformation uses inference 
factorization represented original bn includes factor contain variables factors transformed bns contain variables 
general transformations lead finer grain factorizations joint probabilities 
pd tt efficient pd tt efficient shall provide empirical evidence support claim section 
illustrate considering 
doing elimination ande require numerical multiplications numerical additions 
doing elimination require numerical multiplications numerical additions 
cases numerical multiplications additions performed differences drastic complex networks shown section 
saving example may marginal 
may reasonable conjecture method produces families elements marginal saving hope producing factors elements cliques elements 
interacting causal variables difference extreme 
example method bn produce network 
triangulation network clique elements produce factor elements 
note far networks shown concerned efficient pd pd efficient tt tt efficient 
experiments show true general 

exactly number operations required determine clique tree propagation network 
clique tree cliques containing fc containing fc containing fe 
clique contains elements construct requires multiplications 
message needs sent third clique marginal obtained summing 
similarly second clique 
third clique elements requires multiplications construct 
order extract clique need sum 
shown reason efficient ctp constructs factor variables example 
note advantage ctp cost building cliques amortized queries 

note need produce variables represent noisy need variables noise applied case independent 
note noise network need create variable variable perfectly correlated 
case need complicated example show point 

experiments exploiting causal independence bayesian network inference result applying method bn 
cpcs networks multi level multi valued bns medicine 
created pradhan 
computer patient case simulation system cpcs pm developed parker miller 
cpcs networks experiments 
consists nodes arcs contains nodes 
largest bns time 
cpcs networks contain abundant causal independencies 
matter fact non root variable convergent variable base combination operator max 
test cases inference algorithms exploit causal independencies 
ctp approaches versus approaches seen previous section kind approach exploiting causal independencies transform bns 
inference algorithms including ctp inference 
coupling network transformation techniques ctp able carry inference cpcs networks experiments 
computer ran memory constructing clique trees transformed networks 
reported subsection combination network transformation techniques able answer queries 
proposed new method exploiting causal independencies 
observed causal independencies lead factorization joint probability finer grain factorization entailed conditional independencies 
extend inference algorithms including ctp exploit finer grain factorization 
extended obtained algorithm called able answer queries cpcs networks 
conjecture extension ctp able carry inference cpcs networks 
resources takes answer query bn extension ctp take construct clique tree 
obtained ftp stanford edu pub pradhan 
file names cpcs lm sm txt networks std 
number queries pd tt cpu time seconds number queries zhang poole number queries pd tt cpu time seconds comparisons node bn 
pd tt cpu time seconds bn seen subsection queries cpcs networks able answer 
summary ctp approaches able deal cpcs networks approaches different extents 
comparisons approaches subsection provides experimental data compare approaches pd tt compare approaches determine gained exploiting causal independencies 
node network types queries query variable fifteen observations respectively considered 
queries randomly generated query type 
query passed algorithms nodes irrelevant pruned 
general observations mean irrelevant nodes greater difficulty answer query 
cpu times algorithms spent answering queries recorded 
order get statistics algorithms cpu time consumption limited seconds memory consumption limited megabytes 
statistics shown 
charts curve instance displays time statistics queries observations 
points axis represent cpu times number queries exploiting causal independence bayesian network inference pd tt cpu time seconds number queries comparisons node bn 
pd tt cpu time seconds seconds 
time point corresponding point axis represents number queries answered time see able answer queries pd tt able answer observation fifteen observation queries 
able answer majority queries 
get feeling average performances algorithms regard curves representing functions ofy ofx 
integration axis curve pd instance roughly total amount time pd took answer observation queries pd able answer 
dividing total number queries answered gets average time pd took answer observation query 
clear average performed significantly better pd tt turn performed better 
average performance pd observation queries roughly tt slightly better fifteen observation queries 
node network types queries observations considered queries generated type 
space time limits imposed node networks 
approximations real numbers smaller regarded zero 
approximations algorithms comparisons fair 
statistics shown 
curves hardly visible close axis 
see average performed significantly better pd pd performed significantly better tt tt performed better 
notice tt able answer observation queries pd able 
due limit memory consumption 
see subsection memory consumption limit increased megabytes able answer observation queries exactly seconds 
effectiveness established efficient algorithm exploiting causal independencies 
section investigate effective number queries node bn cpu time seconds zhang poole number queries time statistics node bn cpu time seconds experiments carried cpcs networks answer question 
node network types queries query variable fifteen observations respectively considered 
queries randomly generated query type 
statistics times took answer queries left chart 
collecting statistics mb memory limit second cpu time limit imposed guide excessive resource demands 
see observation queries network answered half second 
observation queries fifteen observation queries observation queries answered second 
observation query able answer time memory limits 
node network types queries query variable fifteen observations respectively considered 
queries randomly generated query type 
previous section approximations 
mb memory limit second cpu time limit imposed 
time statistics shown right hand side chart 
see able answer queries majority queries answered little time 
fifteen observation queries able answer 

concerned exploit causal independence exact bn inference 
previous approaches olesen heckerman causal independencies transform bns 
efficiency gained inference easier transformed bns original bns 
new method proposed 
basic idea 
bayesian network viewed representing factorization joint probability multiplication list 
studied notion causal enables factorize conditional probabilities combination smaller factors consequently obtain finer grain factorization joint probability 
propose extend inference algorithms finer grain factorization 
extended algorithm called 
experiments shown extended algo exploiting causal independence bayesian network inference rithm significantly efficient performs olesen heckerman transformation apply 
choice widely known ctp algorithm due ability networks ctp deal 
matter fact ctp able deal networks experiments olesen heckerman transformation 
hand able answer randomly generated queries majority queries answered little time 
interesting extend ctp finer grain factorization mentioned 
seen previous section queries especially node network took long time answer 
queries able answer 
queries approximation 
employed approximation technique comparing algorithms node network 
extent ignoring minor distinctions 
developing way bound error technique anytime algorithm technique 
grateful malcolm pradhan gregory provan sharing cpcs networks 
jack breese bruce ambrosio mike qi glenn shafer valuable discussions ronen brafman chris geib mike anonymous reviewers helpful comments 
tak yin chan great help experimentations 
research supported nserc institute robotics intelligent systems hong kong research council software research center ssrc 
appendix proof theorem theorem suppose list homogeneous factors list heterogeneous factors constitute tidy factorization ofp zk 
ifz convergent variable old regular variable new regular variable deputy list fz procedure sum returns tidy heterogeneous factorization ofp zk 
proof fr heterogeneous factors andg gs homogeneous factors 
fl gm factors zk zk fj sy gi fj fj fj gi gi fj sy sy gi gi zhang poole fj gi fj sy gi equation due proposition 
equation follows proposition 
matter fact ifz convergent variable convergent variable gi due condition 
condition proposition satisfied appear infl fr 
hand ifz old regular variable new regular variable deputy appear zk gi contains convergent variables due second condition 
condition proposition satisfied 
proved yields flexible heterogeneous factorization ofp zk 
lete convergent variable zk 
regular 
touched 
consequently show new factor created heterogeneous factor homogeneous factor contain convergent variable factorization returned tidy 
create new homogeneous factor 
heterogeneous factors ifz convergent variable homogeneous factor new factor contain convergent variables 
ifz old regular variable new regular variable deputy zk factors contain convergent variables 
new factor contain convergent variables 
theorem proved 
arnborg corneil 

complexity finding embedding tree 
siam alg 
disc 
meth 
baker boult 

pruning bayesian networks efficient computation 
proc 
sixth conf 
uncertainty artificial intelligence pp 
cambridge mass 

dynamic programming vol science engineering 
academic press 
boutilier friedman goldszmidt koller 

context specific independence bayesian networks 
horvitz jensen ed proc 
conf 
uncertainty artificial intelligence pp 
portland oregon 
cooper 

computational complexity bayesian belief networks 
artificial intelligence 
dagum 

network models 
heckerman mamdani ed proc 
ninth conf 
uncertainty artificial intelligence pp 
washington ambrosio 
local expression languages probabilistic dependence 
international journal approximate reasoning 
ambrosio 

symbolic probabilistic inference large bn networks 
lopez de mantaras poole ed proc 
tenth conf 
uncertainty artificial intelligence pp 
seattle 
exploiting causal independence bayesian network inference dechter 

bucket elimination unifying framework probabilistic inference 
jensen ed proc 
conf 
uncertainty artificial intelligence pp 
portland oregon 
ez 

parameter adjustment bayes networks 
generalized noisy gate 
heckerman mamdani ed proc 
ninth conf 
uncertainty artificial intelligence pp 
washington duda hart nilsson 

subjective bayesian methods rule inference systems 
proc 
afips nat 
comp 
conf pp 

geiger heckerman 

inference similarity networks bayesian multinets 
artificial intelligence 
geiger verma pearl 

separation theorems algorithms 
henrion 
ed uncertainty artificial intelligence pp 

north holland new york 


causal calculus 
british journal philosophy science 
heckerman 

causal independence knowledge acquisition inference 
proc 
ninth conference uncertainty artificial intelligence pp 

heckerman breese 

new look causal independence 
proc 
tenth conference uncertainty artificial pp 

henrion 

practical issues constructing belief networks 
kanal levitt lemmer ed uncertainty artificial intelligence pp 

north holland 
howard matheson 

influence diagrams 
howard matheson 
eds principles applications decision analysis pp 

strategic decisions group ca 
jensen lauritzen olesen 

bayesian updating causal probabilistic networks local computations 
computational statistics 
kim pearl 

computational model causal diagnostic reasoning inference engines 
proc 
eighth international joint conference artificial intelligence pp 
karlsruhe germany 
kj 

triangulation graphs algorithms giving small total state space 
tech 
rep department mathematics computer science dk aalborg denmark 
lauritzen dawid larsen 

independence properties directed markov fields 
networks 
lauritzen spiegelhalter 

local computations probabilities graphical structures application expert systems 
journal royal statistical society series 
zhang poole li ambrosio 

efficient inference bayes networks combinatorial optimization problem 
international journal approximate reasoning 
olesen 

specification models large expert systems causal probabilistic networks 
artificial intelligence medicine 
olesen kj jensen andersen 

munin network median nerve case study loops 
applied artificial intelligence 
parker miller 

causal knowledge creat simulated patient cases cpsc project extension internist 
proc 
th symp 
comp 
appl 
medical care pp 
los alamitos ca 
ieee comp soc press 
pearl 

probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann san mateo ca 
poole 

abduction bayesian networks 
artificial intelligence 
pradhan provan middleton henrion 

knowledge engineering large belief networks 
lopez de mantaras poole ed proc 
tenth conf 
uncertainty artificial intelligence pp 
seattle 
shachter ambrosio del 

symbolic probabilistic inference belief networks 
proc 
th national conference artificial intelligence pp 
boston 
mit press 
shafer shenoy 

probability propagation 
annals mathematics artificial intelligence 
shortliffe buchanan 

model inexact reasoning medicine 
math 
biosci 
srinivas 

generalization noisy model 
proc 
ninth conference uncertainty artificial intelligence pp 

tarjan yannakakis 

simple linear time algorithm test graphs test acyclicity hypergraphs selectively reduce acyclic hypergraphs 
siam comput 
zhang poole 

simple approach bayesian network computations 
proc 
tenth canadian conference artificial intelligence pp 


