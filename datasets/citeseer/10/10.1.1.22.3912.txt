university california los angeles competitive execution distributed environment dissertation submitted partial satisfaction requirements degree doctor philosophy computer science sung cho fl copyright sung cho dissertation sung cho approved 
bruce rothschild andrew kahng mario gerla david jefferson committee chair university california los angeles ii table contents background speedup sequential process competition variable speed processors competition variable speed processors speedup communicating processes differences related research contributions organization dissertation related idle processors distributed parallel computing snow replication replication improve performance replication improve fault tolerance competition protocols variable speed processors iii model snow distributed program critical processes detect critical processes runtime 
measure progress definition speedup competition maximum progress peer clones propagating competition protocol performance comparison competition protocols comparison competition migration advantage competition migration advantage migration competition competition 
competition mechanisms system architecture internal representation process clone competition mechanisms implementation competition mechanism message counters state propagation communication process clones iv group communication correctness competition protocols analytic study competition sequential process assumptions terminology stretching ratio performance variable speed processor competition protocol ideal competition protocol speedup ideal competition protocol effect load balancing competition migration sequential process migration policy competition policy migration protocols competition protocols migration protocols competition protocols inherent differences competition migration performance comparison mig comp mig protocol comp protocol simulation results performance comparison mig comp mig protocol comp protocol simulation results competition migration distributed programs application layer issues simulation static dynamic boundary migration migration policy competition policy assumptions simulation speedup competition protocols programs full connectivity programs mesh connectivity programs ring connectivity vi list figures execution variable speed processors execution variable speed processors static choices executing communicating processes competition migration communicating processes execution speed processors progress clones sp sp state propagation clones sp sp performance comparison competition protocols system software layers message process process message communication competition mechanism communication multicasting peer clones communication state model processor execution time variable speed processor number clones diminishing return queue state diagram queue vii skeletons protocols mig protocol comp protocol simulation results processors simulation results processors mig protocol comp protocol speedup processors speedup processors speedup processors speedup processors speedup processors static boundary dynamic boundary processes full connectivity processes full connectivity speedup competition processors speedup migration processors comparison competition migration effect number processes speedup effect granularity speedup effect load imbalance speedup viii processes mesh connectivity processes mesh connectivity processes ring connectivity speedup different topologies ix list tables acknowledgments wish express gratitude people helped going research finishing difficult tasks life 
am grateful advisor professor david jefferson patient advice final stage research 
am thankful professors bruce rothschild andrew kahng mario gerla serving committee 
especially professor andrew kahng allowing workstations laboratory department computing environment stable 
cavendish jr reading dissertation helping simulation 
past colleagues art goldberg ravi liao chen kong li adam king jha yi ro moon 
morgan valerie aylett help dealing ucla administration appreciated 
am especially grateful helping stay ucla 
mother wife soon daughters 
constant loving support gotten point 
appreciation goes korean government provided fellowship years 
xi vita seoul national university korea seoul national university korea instructor korea military academy korea korean government fellowship research assistant computer science department ucla research assistant radiology department ucla research assistant computer science department ucla xii dissertation competitive execution distributed environment sung cho doctor philosophy computer science university california los angeles professor david jefferson chair propose alternative process migration called competition speed distributed programs background network variable speed processors 
competition protocols transparent operating system facilities involve creating multiple instances called clones process different variable speed processors making clones compete attempting guarantee output clone farthest ahead fed rest computation entire application performance tracks clone farthest ahead 
clone may ahead depending current foreground loads 
reason variation progress clones clone ahead times ahead times set competing clones may outperform single copy 
issues mechanisms competition show competition protocols offer performance benefits better migration xiii protocols sequential distributed programs comparable assumptions 
claim supported analytical results simulation results sequential programs 
simulation results distributed programs show competition protocols offer speedup distributed programs sequential programs 
xiv chapter background cost performance ratio workstations shown dramatic improvement past trend probably continue near 
accordingly networks workstations acp increasingly prevalent computing environment 
computing capacity typical workstation gone unused presents large available source computing power 
middle researchers tried harness idle workstations example system tlc nest ae butler nic condor llm benevolent bandit rem sho stealth kc utopia 
goal systems execute processes remote idle workstations maximizing utilization workstations 
study goal execute distributed programs quickly possible 
may dedicate subset workstations execute distributed programs may share workstations interactive foreground processes 
environments called dedicated dnow shared snow respectively 
progress rate processes dnow constant snow may unpredictably vary due processor shar ing 
dnow variable speed processors identical snow background execution points view study 
focus methods able execute distributed programs snow background quickly possible 
characteristics snow available computing capacity background processes changes dynamically probably fast drastically 
unpredictable variability may drastically degrade performance background programs entire program perform poorly processes executing heavily loaded workstation 
key issues snow intrusive background program foreground processes vice versa 
owners may tolerant interference background programs 
workstation operating systems wos guarantee foreground processes preemptive priority background programs interfere 
additionally cpu scheduling memory management file access prioritized insulate foreground processes background programs kc 
assume wos manages resources background programs interfere foreground processes foreground processes interfere performance background programs 
refer workstations scheduled way variable speed processors background programs 
terms workstations processors interchangeably study 
speedup sequential process competition variable speed processors suppose non interactive sequential process sp want run background 
addition variable speed processors run sp 
know foreground activities going 

statically choose execute sp 
wrong choose slower variable speed processor 
choose correctly may able better static choice migrating sp back forth basis load averages speed variable speed processors change dynamically 
alternatively execute sp parallel 
instances sp called clones sp 
monitor clone ahead time time 
clone sufficiently far ahead pause propagate state clone ahead 
clone uses propagated state continue execution 
state propagation allows clone jump forward state clone ahead executing instructions sp 
essence competition clones compete execute quickly possible 
circumstances migration protocols get speedup show competition protocols get better speedup making cpu cycles 
competition protocols idle cpu cycles really higher cost 
presumably communication bandwidth 
example showing competition protocol execute sp quicker migration protocol 
example assume simple policy migration protocol sp preempted due foreground processes migration protocol migrates sp immediately idle processor available 
migration protocol migrates sp soon idle processor available 
migration protocol called mig protocol 
hand competition protocol propagates states clone ahead preempted 
competition protocol called comp protocol 
assume migration decision state propagation decision instantly 
consider variable speed processors 
shaded rectangles represent foreground activities 
foreground activities identical 
thick vertical arrows represent fastest execution trace sp dotted horizontal arrows represent process migration state propagation 
numbers left side represent real time 
assume latency process migration state propagation unit time physically identical 
assume takes units time run sequential process sp dedicated processor 
statically choose processor takes units time respectively shown 
migrate sp back forth shown mig protocol completes sp units time process migration occurs times 
example shows mig protocol completes sp quicker static choices 
assume sp clones scheduled period state propagation prevent state modification 
shows periods static choices migration competition execution variable speed processors dashed rectangles execution traces sp clones 
faster trace execution shown thick vertical arrows slower shown thin vertical arrows 
real time consider clone ahead executing stops execution 
similarly clone considered ahead real time 
comp protocol need propagate states real time 
comp protocol completes sp units time state propagation occurs times 
competition protocol easily simulate behavior mig protocol mig protocol migrates sp processor competition protocol propagates state clone clone ahead competition protocol easily suppress state propagation 
shows comp protocol suppresses state propagation twice real time sp migrated 
comp protocol completes sp quicker mig protocol units time number state propagation smaller process migration 
chance comp protocol suppresses state propagation comp protocol performs mig protocol assumption overhead state propagation equal migration 
case possible comp protocol suppresses state propagation comp protocol performs better mig protocol 
comp protocol may perform significantly better mig protocol state propagation suppressed times mig protocol process migration occur 
competition speeds sp executing clones sp processors 
competition increase parallelism sp sp sequential process parallelism 
show reason competition protocols preferable migration protocols subsection 
competition variable speed processors consider example variable speed processors 
assume physically identical 
fact foreground activities identical 
want execute sp background 
dashed horizontal arrows show optimal migration paths migration completes sp units time 
migration completes sp units time sp migrated dotted horizontal arrows 
migration competition execution variable speed processors necessary migrate sp real time obtain shortest execution time 
migration decision real time known better choice complete knowledge foreground activities 
general information available 
impossible achieve optimal performance migration 
competition completes sp units time shown thick vertical arrows show execution trace fastest clone time 
migration competition need know foreground activities real time finish sp shortest time 
competition easily obtains benefit cost redundant execution clones 
redundant execution may cost snow competition exploits processors idle 
far implicitly assume competition propagate states clone ahead vice versa 
assumption easily satisfied number instructions clones executed cpu times clones determine clone ahead time 
heuristic decision occasionally wrong propagating states clone ahead won violate correctness may degrade performance competition 
speedup communicating processes want execute distributed program set workstations snow background 
consider simple distributed program consists communicating processes shows behavior run physically identical processors 
assume message communication instantaneous 
dashed arrows represent message communication message shown dashed arrow 
numbers thick vertical arrows represent time execute messages 
produces message unit time sends executes produces message unit time sends executes produces message units time sends 
distributed program completes units time dedicated processors 
assume variable speed processors dedicated processor 
assume physically iden dedicated processors static choices executing communicating processes tical message communication instantaneous 
execute distributed program background 
consider static choices foreground activities identical 
possible configuration shown run respectively 
message arrives real time execute real time foreground activities 
distributed program completes units time configuration 
shows configuration run respectively 
distributed program completes units time 
consider speedup comp protocol achieve competition migration migration competition migration communicating processes shown process represented clones respectively process represented single clone dedicated processor 
foreground activities identical shown previously 
simply assume process sends message clone sends instances instantaneously 
instances message mi called message clones shown 
dashed horizontal arrows represent communication message clones 
discuss issue detail chapter 
shows sends message clones instantaneously real time respectively 
clone execute immediately send message clone execute real time due foreground activities 
delayed execution represented message clone parenthesis thin vertical arrow 
produces comp protocol suppresses sending sent earlier shows thick vertical arrows trace fastest execution distributed program 
produces real time produced shown 
discuss issue chapter 
comp protocol completes distributed program units time 
consider speedup mig protocol achieve shown 
shows initially start run respectively shows migrated real time 
assume latency migration unit time 
mig protocol completes distributed program units time 
comp protocol completes distributed program quicker mig protocol unit time process migration 
differences related researchers studied set homogeneous heterogeneous processors load sharing load balancing 
considered fixed performance environment execution speed processors change 
positive local change architecture speeding processor example lead negative global effect distributed program 
phenomenon called paradoxical performance behavior 
chen che considered changing performance environment execute distributed program different architectures paradoxical performance behavior 
study consider problem executing distributed program snow background performance environment change dynamically executing program 
idea replication investigated intensively improving fault tolerance ak bir propose process replication improving performance distributed program snow 
previous process replication increasing performance attempted increase parallelism reduce communication distance aj 
asymmetric strategies employed managing clones process primary clone primary clone send message aj 
competition protocols employ symmetrical strategy clone process fastest time 
competition protocols improve performance distributed program speeding processes making clones compete increasing parallelism 
research contributions investigate competition protocols snow execution speed processors may change due foreground processes 
study issues mechanisms performance benefits competition protocols sequential distributed programs 
main contributions research summarized ffl characterization competition may improve performance cost 
ffl qualitative study competition mechanisms 
ffl performance analysis competition protocols sequential process 
ffl performance comparison migration competition 
ffl performance analysis competition protocols distributed programs simulation 
show competition value snow 
identify competition protocols exploited dnow general distributed parallel computing platforms 
investigate competition sequential processes thoroughly mathematical analysis simulation 
means finished subject competition distributed context 
organization dissertation study competition sequential programs primarily chapter 
extend competition distributed programs chapter 
dissertation organized follows 
chapter related current literature discussed 
chapter introduce formal definitions variable speed processors speedup metric competition 
introduce model snow distributed program 
discuss processes cloned detect 
introduce competition protocols 
chapter competition mechanism issues including correctness 
study performance competition protocols sequential programs chapter 
compare performance competition performance migration sequential programs chapter 
study performance benefit competition distributed programs different topologies ring full connection dimensional mesh chapter 
chapter summarize contributions related open problems 
chapter related order minimize completion time parallel distributed applications researchers taken different approaches different circumstances 
considerable amount theoretical assignment problem parallel distributed computing 
addresses problems mapping tasks processors assumption resource requirements distributed parallel applications known priori dnow 
static approaches utilize knowledge problem characteristics reach global optimal near optimal solution load 
load balancing research operating systems focuses mapping problems 
assumed resource requirements applications known priori heuristics play important role 
eager compare heuristics task placement migration various system loads 
show simple heuristics scheduling independent processes homogeneous distributed systems 
review remote execution facilities distributed computing snow replication techniques performance fault tolerance 
idle processors researchers tried harness idle underutilized workstations remote execution facilities include system tlc nest ae butler nic condor llm benevolent bandit rem sho stealth kc utopia 
important issues workstation determined available background processes handle background processes workstations reclaimed 
earlier systems tlc hag ae nic availability defined absolutely idle workstation 
refer kc ml study available capacity workstations 
processor reclaimed foreground process take approaches migrate background processes tlc ae llm priority driven local scheduler preempts background processes schedules foreground process background processes foreground process finishes kc sho 
advantage priority driven local scheduler utilize fully available cpu cycles 
process distributed program running heavily loaded processor processes may wait process communication synchronization 
priority driven local scheduler appropriate execute distributed programs snow 
process migration alternative approaches employed snow 
process migration mechanism load balancing shar ing lm pw kl af kk 
refer survey process object migration smi nut 
distributed parallel computing snow order execute distributed programs snow researchers studied areas developing software tools increasing communication performance studying feasibility distributed computing snow 
software tools developed support snow environments pvm sun gei boy express fkb linda cg isis bm mpi gls 
tools allow programmers treat heterogeneous collection processors snow large virtual machine 
virtual machine composed set identical workstations 
networked computers users running variety jobs machine load vary dramatically moment moment 
result effective background computational power identical workstations vary enormously 
performance distributed programs network workstations partly determined speed underlying communication network 
network speeds increasing rapidly communication latency application level improved overhead preparing send receive message 
researchers tried eliminate network bottleneck cha ebb demonstrated executing communication intensive distributed programs local atm networks appears promising 
goal berkeley project harness computers building satisfy needs desktop computing applications require computing resources single machine provide 
improve communication performance orders magnitude atm network reducing communication overhead lean communication layers ebb 
reported overlay typical processor parallel workload workstation cluster interactive foreground jobs significantly sacrificing performance 
lewis advanced cluster environment nasa lewis research center machines connected ethernet networks public file server activities private multiprocessing fat 
underlying communication network snow bottleneck executing communication intensive distributed programs 
alternatives networks processors performance competition protocols may heavily depend foreground message traffic network 
environment ideal competition protocols alternatives networks 
kk investigated performance distributed program snow assumption workload program divided evenly available processors 
ignored overheads occur real system communication delay 
model provides lower bound time completion 
study investigate methods speed distributed program snow performance benefits 
leutenegger sun ls studied distributed programs run snow 
demonstrated may possible significant impact distributed programs 
replication replication improve performance goldberg aj proposed process replication reduce communication distance increase parallelism 
distinguished read messages write messages minimize redundant execution message communication bandwidth read messages executed clones message clones delivered 
clone receiving original read messages executes heavily loaded slow processor slow execution clone slow distributed program 
competition protocols clones compete execute read write messages performance program tracks performance clone farthest ahead cost message traffic redundant computation 
research replication performance goals reduce communication cost applying read operations local copy object phi increase parallelism reading local copy avoid sequential bottleneck aj bkt 
important factor ratio read write operations useful primarily shared object read relatively overhead maintain consistency multiple copies 
alternative methods computing result smith sg proposed concurrent execution alternative methods get result quickly 
programmers provide alternatives solve problem 
competition protocols share similar philosophy exploiting multiple alternative processors clones processes executed parallel 
order competition protocols users need provide alternatives need change programs competition protocols transparent 
replication improve fault tolerance replicated process group deterministic processes called proposed building block replicated distributed programs transparent fault tolerance coo 
processes assumed communicate remote procedure calls transformed replicated procedure calls operating system 
replicated procedure call sends message member calling member receiving message cost quadratic number clones 
process replication proposed fault tolerance performance improvement cc 
major concern fault tolerance tried improve performance allowing replica generating message multicast message reduce communication traffic 
destination replica need identify possibly redundant messages 
replica generating message check see message sent replicas 
outcome negative request permission send coordinator 
replica generating message needs get permission coordinator delay message delivery latency get permission 
snow ideally frequency clones process send message clone concurrently rare competition protocols allow process clones send message clones destination clones concept coordinator 
clone sends message clone competition protocols may multicast message clone destination clones peer clones sender 
clones sender generate message clone message clone broadcast arrived competition protocols suppress multicasting message clone 
motivation process replication totally different communication message clones competition protocols differs protocols 
aware previous study similar competition protocols consequently systematic study competition protocols 
chapter competition protocols define variable speed processor discuss model distributed program 
define speedup competition competition protocols 
discuss appropriate competition protocols 
variable speed processors foreground load processors snow vary unpredictably time available execute background processes vary 
snow processors referred variable speed processors point view background processes 
ambiguity variable speed processor simply called processor 
progress background process measured number instructions executed far 
practice operating system ordinarily access number instructions executed access cpu time 
simplicity assume processors physically identical cpu time second linearly proportional number instructions processor executes second 
progress rate background process goes processor foreground load increases 
execution speed processor background process continuous step function fine scale average execution speed larger scale considered continuous function coarser time scale 
chapter assume execution speed processor background process changes continuously 
model snow assume snow consists processors variable delay communication network connecting processors 
processor memory processors communicates messages 
execution speeds background processes change unpredictably execution speed processor uncorrelated processors 
study assumption execution speeds processors background processes average execution speed 
distributed program assume distributed program written form set cooperating sequential processes communicate asynchronous messages shared memory 
simplicity assume processes created destroyed dynamically 
process may execute send receive primitives communication synchronization 
message sent received executing send message receiver name receive message sender name 
model assume direct naming messages addressed directly processes name 
multicasting broadcasting primitives 
process running faster processor communication partner reach communication statement earlier 
synchronous message passing called rendezvous occam delays process sending message process ready receive message 
degrade completion time programs significantly snow 
assume asynchronous message passing send primitive non blocking cause process block 
sending receiving processes execute independently message received arbitrarily long sent 
asynchronous message passing requires message buffering queueing 
assume communication traffic background processes lower priority communication subsystems foreground processes 
consequently communication delay variable speed processor 
study model communication delay constant 
assume messages reliably delivered message order preserved communicating processes 
require runtime behavior process deterministic sequence states passes sequence messages sends depends process initial state sequence messages received 
nondeterministic programming constructs allowed model 
clones process execute instructions order send receive messages sequence go sequence states 
critical processes competition reduce completion time distributed program making processes program compete 
general processes program probably need compete subset processes critical completion time program need 
set critical processes change execution program 
formally define critical process distributed program follows definition process distributed program critical real time completion time entire program longer deltat pause process short period deltat 
accordingly process sequential program critical 
distributed program process non critical process critical system deadlocked 
exist critical process program 
goal competition critical processes non critical ones speed critical processes doing speed completion time program 
detect critical processes runtime 
definition critical processes described theoretic detect critical processes definition runtime 
runtime scheduling algorithms utilize knowledge application programs sw 
heuristic detect critical processes knowledge 
consider distributed program consists sequential processes assume process composed instructions process composed instructions 
assume illustrative purposes communication 
executed fully parallel application complete terminated 
execute processes dedicated processors different execution speeds 
know longer process execute faster processor slower processor 
terminates earlier may migrate faster processor depending migration delay remaining time finish slower processor 
known long process 
operating systems reasonable guess longer process 
operating systems execute better average 
assume execute variable speed processors 
sufficient know longer process 
critical execute faster variable speed processor migrating back forth 
point time may progress ahead critical 
way detect critical 
order reduce completion time distributed program snow able detect process critical time 
information know process critical time may clone processes include critical processes 
get competition benefit just knew critical process 
price pay just need excess background resources get benefit 
measure progress study looking case excess resources clone processes 
clone processes critical 
heuristics determining processes critical time operating systems get away cloning cloning critical processes 
heuristics deciding processes critical scope study 
examples chapters symmetric processes equally critical 
part research investigate detect critical processes discuss issues related critical processes 
distributed computation general just complex sequential computation due new concepts communication synchronization load balancing 
analogs sequential computation 
new concepts appear competition distributed computation 
measure progress 
easy measure progress sequential programs 
just cpu time number instructions 
number remaining instructions complete sequential program total number instructions program minus current progress terms number instructions 
program consisting processes discussed need know total number instructions process order know number remaining instructions executed 
possible know critical 
difficult define measure progress distributed program 
consider communication primitive block sequential instructions process event lamport logical clock lam measure progress detect critical process 
virtual time chen che proposed measure progress concurrent program event process assigned virtual time event occur executed imaginary architecture called virtual architecture 
general need knowledge distributed program assign virtual time values events 
issue way scope study 
virtual time compilers may insert codes process maintain virtual times che 
progress processes quantified compared virtual times 
context virtual time define critical process process smallest virtual time time 
competition protocols adequate time warp jef virtual time available processes deterministic time warp 
competition mechanisms apply directly time warp difference programming model time warp model optimistic synchronization time warp 
modify deal replication 
issue scope study 
required progress indicator perfect 
approximate progress indicators may degrade performance competition protocols violate correctness 
tolerate setting clone ahead back pace clone rarely 
net result speedup 
parallel context may just guessing process ahead 
guessing critical processes clones ahead 
definition speedup competition various kinds speedup metrics speedup amdahl law amd gustafson scaled speedup gus memory bounded speedup sn 
definitions competition protocols need processors cases competition protocols execute distributed program condition cases 
going statistical definition speedup consider set physically identical processors arrival foreground processes processors forms poisson process rate execution times distribution parameter 
mean foreground processor utilization ae identical processors mean background execution speed processors identical 
background execution speeds may fluctuate differently processors time 
sake analysis assume underlying statistics foreground processes processors change duration entire background computation 
assume run distributed program processors background competition run program background competition processors mean foreground processor utilization ae 
nc denote mean completion time program competition competition respectively 
define speedup competition sp ae sp ae nc ae ae speedup competition sp ae ratio mean completion time competition processors competition processors assumption behavior foreground processes processors statistically identical 
new speedup metric shows performance benefit competition 
foreground processes processors start go idle real time entire computation distributed program competition protocols reduce completion time application 
case execution speed processors background processes changes lock step 
background applications achieve speedup competition idle periods processors occur different times processors faster times faster times 
performance competition depends extent idle periods processors disjoint 
maximum progress peer clones consider shows execution speed processors respectively 
dotted line shows maximum possible execution speed processors completely idle 
shown greater execution speed period reverse true times 
assume clones sp sp process sp run processors change dynamically smaller execution speed instr sec time maximum speed execution speed processors competition offers advantage sp ahead sp difference sufficiently small useful keep clones sp sp 
study focus snow environment change dynamically times 
dx 
represents progress total number instructions executed clone sp real time progress sp sp shown drawn 
equal smaller larger competition offers advantage 
means cross time order competition benefit 
time competition benefit increases jg gamma increases 
total progress instructions executed time progress clones sp sp assume ideal conditions delay process switching communication latency state propagation latency 
assume competition protocols detect processor fastest processors 
ideal conditions competition protocols achieve times maximum execution speed processors max maximum progress clones max max 
propagating competition protocol desirable competition protocols exploit execution speed shown 
state propagation shows competition protocols may exploit faster execution speed real time sp needs real time gamma go ahead sp time gamma called catching latency 
total progress instructions executed time state propagation state propagation state propagation clones sp sp reduce catching latency propagating state sp sp state propagation takes time catching latency 
refer competition protocol state propagation state propagation propagating competition protocol competition protocol respectively 
consider propagating competition protocol standard competition protocol study 
assuming state propagation done instantaneously shows sp jumps forward sp state sp go ahead sp real time ideal situation propagating competition protocol progress process times maximum progress clones max max 
optimal points state propagation shows 
general optimal points time fastest processor changes processors 
processors determined idle cpu utilization foreground processes smaller threshold way know optimal points time 
clone far ahead running slow processor clone far running fast processor desirable propagate state clone ahead 
purpose state propagation minimize catching latency clone ahead run fastest processor 
state propagation latency larger catching latency state propagation gives advantage 
competition protocols propagate states infrequently state propagation latency sufficiently large 
case processor may faster currently fastest processor state propagation 
heuristic decisions competition protocols processes critical cloned 
second clones process ahead purpose state propagation 
overhead competition protocols small cost keeping multiple clones offset advantage competition protocols worth doing 
performance comparison competition protocols shows performance curves competition protocols assuming zero overhead state propagation max propagating competition pro total progress instructions executed time max max max performance comparison competition protocols tocol optimal state propagation max propagating competition protocol suboptimal state propagation max competition protocol 
max max redrawn max max redrawn max drawn assuming state propagations done optimal points overhead state propagation 
performance propagating competition protocol suboptimal state propagation max competition protocol max 
furthermore max outperform max tremendously gaps max max increases time 
obviously max outperforms max max propagates states optimal points 
concept state propagation plays key role competition protocols overhead state propagation justified small compared total processing time 
special cases state process change processes messages process receives message calculates function message return result state propagation optimized 
comparison competition migration advantage competition migration migration requires predict know processor faster near 
requires measuring actual processor speed period time 
decide time quantum measurement measurement causes delay quantum 
implicit assumption near performance similar past measurement taken 
competition require knowledge 
requires measuring clone ahead instruction counter cpu time clock 
instantaneous measurement delay injected 
importantly need assumption resembles past time scale 
advantage migration competition performance predictable migration processor competition extreme case perfect knowl edge processor fastest times zero overhead migration optimal uses processor competition protocol zero overhead state propagation faster takes processor 
message communication simpler migrating processes cloned processes 
competition 
decisions scheduling resource allocation incomplete information precedence constraints execution times resource demands large excess resources competition protocols may improve performance 
may get significant benefits competition performance clones varies widely reason 
envision informal scenarios satisfying conditions favoring competition 

interference foreground applications process distributed program critical snow foreground processes 
competition protocols speed critical processes cloning executing clones different processors parallel 
competition protocols speed single sequential program 

excessive parallel capacity number available processors snow larger number processes distributed program 
way additional processors competition 

heterogeneous performance systems processors binary compatibility system may different processing power memory space disk storage 
general difficult find best configuration execute distributed program heterogeneous performance system 
competition protocols try multiple alternative configurations concurrently 
summary multiple alternative processors execute process processor fastest time processor fastest reason competition protocols try alternative processors parallel exploiting fastest result 
competition protocols exploit excess resources wasted 
known advance processor faster competition protocols due competition overheads 
believe information won usually available runtime distributed computing platforms especially 
competition protocols useful operating system technique applicable different cases improve performance background distributed applications 
competition protocols applicable dnow snow statically dynamically depending goal system 
chapter competition mechanisms issues implementation competition protocols competition policy competition mechanism 
study study competing policy issues optimal number competing clones process increase decrease number competing clones 
consider simple policies necessary 
focus competition mechanisms competition mechanism deals message multicasting state propagation peer clones addition message communication clones communicating processes 
competition mechanism creates destroys clones process depending requests competition policy 
assume competition mechanism interacts competition policy defined interface 
system architecture snow system competition consists runtime software layers application layer competition layer kernel layer 
application layer consists user defined processes communicate messages achieve common task 
competition layer consists components competition policy layer functions application communicating processes application messages competition message multicast state propagation clone creation destruction kernel clone scheduling message communication progress measurement system software layers competition mechanism 
competition policy component collects performance measurement data decisions state propagation peer clones number clones processes placement clones processors 
study focus competition mechanisms 
process represented positive number process clones competition layer 
similarly message represented positive number message clones runtime 
assume process clones run processor snow 
competition mechanism responsible message multicast peer clones communicating processes state propagation peer clones process addition message communication clones processes 
process clones communicate messages competition mechanisms primarily contained implementation send receive primitives addition state propagation 
creation destruction clones implemented layer consider dynamic cloning study 
lowest level kernel schedules foreground processes back ground process clones provides basic message communication services competition mechanisms 
assume kernel schedules foreground processes high priority background process clones preempted immediately foreground processes ready execute 
background process clones exploits idle cpu cycles 
assume underlying message passing system provides asynchronous communication communication delays finite unpredictable 
assume messages received reliably order sent processors lost duplicated kernel layer 
internal representation process clone assume process clone represented components message queues state 
message queues consists input message queue hold incoming messages output message queue hold copies outgoing messages process clone peer clones may send 
state includes operating system structure keeps track current activities system holds pointers code necessary run process clone 
competition mechanisms consider message communication process clones communicating processes section 
assumptions competition mechanisms 
processor communicates messages message communication processors fifo reliable 
message process process message communication competition mechanism 
process deterministic process clones deterministic 

peer process clones run processor run processor snow 
consider processes application layer shown sends message assume processes represented clones clones respectively competition layer 
clones peer clones clones peer clones solid arrow represents message delivery clones communicating processes dotted arrows represent message delivery called multicast peer clones 
process clones process execute code 
competition mechanisms implement send receive primitives collective behavior process clones process logically identical behavior single clone process executing process clones detect cloning process 
implementation competition mechanism pseudocode implementation competition mechanism 
assume message clone competition layer fields addition message application layer shown content message clone competition layer msg message application layer sender sender message receiver receiver message type unicast multicast direction input output message queue send message receiver receive message sender executed process clone pseudocode executed competition layer procedure send msg receiver 
msg msg msg 
msg sender sender assume sender known 
msg receiver receiver 
msg output queue sender 
message sending suppressed 

msg type unicast 
msg direction input 
unicast msg clone receiver 
msg type multicast 
msg direction output 
multicast msg peer clones sender 
procedure receive msg sender 
message msg sender input queue 
msg msg msg 

block receiver procedure msg message arrives 
msg msg msg 
msg direction input 
msg input queue msg receiver 
peer msg clone arrived 

enqueue msg input queue msg receiver 
msg type unicast 
msg type multicast 
msg direction input 
multicast msg peer clones msg receiver 


output queue 
msg output queue msg sender 
peer message clone sent 

enqueue msg output queue msg sender 
explain competition mechanism works 
assume clone requests send message clone message process earlier clones requests send competition mechanism checks peer clones sent line procedure send 
just ignores request said message sending suppressed 
unicasts say clones line procedure send multicasts peer clones line procedure send 
arrives competition mechanism enqueues input message queue line procedure message arrival assuming peer message clone arrived multicasts peer clones line procedure message arrival unicast message clone 
multicast message clone arrives peer clones enqueued output message queue sent 
done lines procedure message arrival 
peer clone say requests send concurrently requests send broadcast enqueued output message queue competition mechanism deliver clones 
multiple peer message clones may delivered receiving process clones detected message clone received processed receiving process clone preserve exactly semantics distributed programs 
order detect arrival redundant peer message clones receiving clone message clone removed input message queue immediately process clone received processed 
order detect sending redundant peer message clones sending process clones copies message clones saved output queues sending process clones message clone sent sending process clones 
line procedure send checks message clone sent 
process clones produced message clone removed input message queues receiving process clones output message queues sending process clones 
message counters order remove message clones input message queue immediately received maintain counters pair sending process say receiving processes say called sent clone record message clones sent called arrived clone record message clones arrived 
message clone arrived received receiving clone time 
initially sent arrived 
values sent clones values arrived clones differ time 
clone sends message clone clone earlier clones sent clone increased 
message clone carries sending sequence number receiving clones detect message clone arrived arrived receiving clone smaller sending sequence number arrived past enqueued input message queue 
ignored 
difference sent sending clone arrived receiving clone time shows number message clones sent point view sending clone arrived point view receiving clone 
message clone arrives corresponding counter arrived receiving clone increased message clone arrived 
need maintain real output message queue 
just need maintain counter local sent addition sent sending clone sent represents message clones sent process clones local sent represents message clone produced local clone 
relation satisfied sent local sent 
sent local sent process clone clone peer clone 
need modify pseudocode described order include concept message counters 
add asterisks line numbers pseudocode lines new modified 
content message clone competition layer msg message application layer seq message sending sequence number sender sender message receiver receiver message type unicast multicast direction input output message queue procedure send msg receiver 

msg msg msg 
msg sender sender sender known 
msg receiver receiver 
sent 
message sending suppressed 

sent 
msg type unicast 
msg direction input 
msg seq 
unicast msg clone receiver 
msg type multicast 
msg direction output 
multicast msg peer clones sender 
procedure msg message arrives 
msg msg msg 
seq msg seq 
msg direction input 
seq arrived 
peer msg clone arrived 

arrived arrived 
enqueue msg input queue msg receiver 
msg type unicast 
msg type multicast 
msg direction input 
multicast msg peer clones msg receiver 


output queue 
seq sent 
peer message clone sent 

sent seq 
state propagation assume set message counters communicating processes part state sending sequence number message clone input message queue accessible 
propagate state process clone ahead may remove message clones input message queue destination sending sequence number message clone equal smaller corresponding arrived propagated state 
propagate state process clone may recover messages clones may received clone ahead 
consider different competition mechanisms depending deliver message clone receiving process clones state propagation allowed 
mechanism delivers message clone single receiving clone 
mechanism may deliver message clone receiving clones message multicasting receiving clones necessary 
sending clone may multicast message clone peer clones suppressing sending redundant message clones 
peer clones process snow environment distinguished may known clone ahead time 
reason message clone delivered clones receiving process 
snow environment multicasting capability multicast sufficient deliver message clone process clone receiver sender 
clone process time peer clones competition protocols kill clone create clone processor 
case competition protocols may degenerate form migration consider killed clone processor 
communication process clones group communication number protocols related group communication proposed researchers 
major issues order messages receiving clones maintaining consistency 
protocols provide total ordering cm bss protocols causal ordering bss 
protocols coordinator sequence messages receiving clones cm kt ez cc 
competition protocols concept coordinator communicating process names model distributed programs chapter 
easily employ concept coordinator competition protocols sequence messages models distributed programs 
assume number clones sending process receiving process respectively 
consider methods message communication ffl coo clone sending process sends message clone receiving clones shown 
circus system method improving fault tolerance coo 
method requires quadratic delta number messages point point network linear number messages broadcasting network 
ffl coordinator cc clone sending process sends message clone receiving clones get permission sending coordinator 
process clone request permission faster peer clones allowed send message clone 
method requires best case messages worst case point point network requires messages best case messages worst case broadcasting network 
ffl multicasting peer clones clone sending process sends unicasts message clone receiving clones peer process clone sent message clone 
clone multicasts message clone peer process clones 
message sending suppressed 
unicast message clone arrive receiving clone receiving clone multicasts message clone peer process clones message clone arrived 
point point network method requires gamma messages best case gamma gamma worst case 
method proposed competition protocols shown 
method requires messages broadcasting network concurrent sending occurs 
ffl clone sending process multicasts message clone receiving process clones peer process clones 
point point network method requires gamma messages best case gamma worst case 
broadcasting network method requires message concurrent sending occurs worst case 
shown 
message clone arrives process clone distinguish process clone sending process clone receiving process clone straight forward pseudocode implementation competition mechanism 
communication multicasting peer clones communication correctness competition protocols replication algorithm correct ensures process clones process receive execute sequence messages sch 
competition mechanism guarantees process clones process receive message clones sequence omission duplication sending sequence number message clones fifo assumption communicating processors 
competition protocols correct 
consider propagating competition protocols 
state process clone ahead propagated process clone message clones received input message queue destination may message clones received process clone ahead 
competition mechanism easily detect case checking sending sequence number message clone greater corresponding received 
state process clone propagated process clone ahead message clones omitted process clone destination received message clones received process clone 
competition mechanism detect case checking sending sequence number message clone greater corresponding received 
case message clones recovered process clones chapter analytic study competition sequential process chapter consider sequential process called sp special case distributed program 
study extreme competition protocols competition protocol propagating competition protocol propagates states instantaneously optimal times 
called ideal competition protocol 
performance competition protocols fall competition protocol ideal competition protocol 
goal competition protocols execute sp quickly possible snow environment interfering foreground processes 
going derive closed form solution performance ideal competition protocol 
best performance achieve competition ideal conditions state propagation decision overhead instantaneous state propagation 
assumptions terminology idle busy state model processor processor executes foreground process say busy 
idle 
assume processors alternate busy idle states constant rates 
processor busy fraction time idle remaining fraction time 
probability processors idle time gammak binomial density 
clones sp progress depending arrival foreground processes hosting processors 
assume lengths busy periods processors independent identically distributed random variables exponential distribution mean corresponding density 
respectively gamma gammat gammat likewise lengths idle periods processors random variables exponential distribution mean density 
assume time execution time variable speed processor processors physically identical 
sp denote constant amount time finish sp dedicated processor stretching ratio time line execution sp variable speed processor shown 
shadowed regions indicate busy periods white regions indicate idle periods sp executed 
sp starts run idle period shown middle sp finish time sp sp sp additional time sp spends processor preempting periods 
sp sum busy periods occur sp runs ambiguity sp sp denoted respectively simplicity 
analyze total length busy periods time examining arrival process periods sp finishes idle period busy periods truncated 
arrival process busy periods stops busy periods state model processor 
lengths busy periods affect rate arrive may take busy periods zero length 
number real busy periods arriving number zero length busy periods arriving kor 
probability density zero length busy periods arrive assume length idle periods exponentially distributed busy periods arrive poisson process rate 
gamma delta delta delta mean variance equal completion time sp stretched preempting foreground processes 
define stretching ratio variable speed processor follows definition finishing time sequential process dedicated processor denote finishing time process variable speed processor 
stretching ratio sr variable speed processor defined sr stretching ratio sr shows times completion time sp variable speed processor stretched due foreground processes 
sr may depend time sp starts execute ignore factors consider long running applications 
assume mean stretching ratio sr change entire computation applications 
stretching ratio sr non negative real number greater shown sr ratio cpu cycles foreground processes background process 
call ratio busy ratio denoted sr processor smaller busy ratio complete background process faster larger busy ratio 
operating system measure runtime portion cpu cycles foreground processes portion cpu cycles available background processes 
ae busy periods arrive variable speed processor executes background process sp 
assume delta delta delta random variables common mean finite variance oe delta delta delta known oe noe coefficient variation cx oe oe lim cx means probability density sum random variables tight mean regardless distribution 
means sr independent ae study interested case ae omit sp sr sp ambiguity 
sr known completion time background process estimated sr delta foreground processes arrive frequently demand resources sr increases turn increases sr delta mathematical model stretching ratio near independent past 
practical snow may predict stretching ratio near stretching ratio past 
clear competition protocols execute program faster sr small may room competition protocols improve performance program sr sufficiently large competition protocols may potential improve performance applications 
performance variable speed processor mean stretching ratio srq expressed terms follows proposition mean length busy periods idle periods processor respectively 
srq proof processor busy fraction time idle remaining fraction time 
average amount time execute background process second equal fraction time idle 
assuming background process runs dedicated processor srq mean stretching ratio srq characterizes performance background process sp delta srq measurable runtime srq calculated 
predict mean finishing time variable speed processor known 
oe mean variance equation 
random sum busy period durations mean time finish sp sum constant plus random variables representing lengths busy periods kle tri 
average number zero length busy periods average interarrival time seconds arrive variance oe tq poe oe equation shows mean stretching ratio srq proposition 
goal competition protocols snow minimize mean stretching factor applications executing multiple clones different variable speed processors improve performance applications 
competition protocol random variables delta delta delta denote finishing times clones 
min minimum finishing time clones 
speedup competition protocol defined sp busy periods arrive poisson process rate equation reduces oe tq note mean variance poisson process identical 
coefficient variation tq tq oe tq consider tq approaches competition protocol speed sp 
ffl lim tq sufficiently large finishing time distribution tends impulse mean finishing time sp goes 
ffl fixed lim tq 
small busy periods occur sp finishes 
law large numbers ensures finishing time density tight mean busy periods 
sp goes 
ffl lim tq ae busy periods negligible variable speed processors idle time 
finishing time density tight mean busy periods add little variability finishing time 
case competition protocols offer advantage 
summary finishing time variable speed processor relatively small variance sp goes competition protocol speed sp 
second cases finishing time small variance busy periods occur sp finishes 
hand finishing time case small variance busy periods occur sp finishes 
competition protocol useful significantly larger finishing times may sufficient variation case 
ae situation occur processors underlying statistics 
ideal competition protocol showed competition protocol limited performance benefit 
limitation apply family propagating competition protocols 
section consider performance benefit ideal competition protocol 
works overhead follows processor executes clone idle preempts clone immediately foreground processes arrive 
ahead clones ideal competition protocol propagates state clones instantaneously 
note ideal competition protocol belongs family propagating competition protocols 
speedup ideal competition protocol assume ideal competition protocol replicates sp clones times allocates different processors arrival foreground processes forms poisson process rate processors service time foreground process exponentially distributed parameter processors modeled independent queues utilization foreground processes ae 
foreground processes create certain pattern activities background processes fit 
queueing analysis simply probability processors idle 
probability processor idle gamma ae 
finishing time sp finish dedicated processor 
take gamma ae single processor mean stretching ratio processor gamma ae mean stretching ratio increases decreases ae increases decreases 
analyze best speedup ideal competition protocol considering independent queues 
consider speedup ideal competition protocol processors foreground activities modeled independent queues 
long processors idle ideal competition protocol allows sp progress instantaneous state propagation 
probability processors idle gamma gamma ae mean stretching ratio ideal competition protocol processors gamma ae 
speedup ideal competition protocol queues single queue gamma ae gamma ae ae 
fact result independent underlying exponential distributions 
generalize result theorem theorem assume processors alternate idle periods busy periods 
mean length idle periods busy periods respectively 
foreground utilization processors ae 
speedup ideal competition protocol independent processors processor ae delta delta delta ae gamma gamma ae gamma ae 
proof ideal competition protocol allows sp progress long processors idle 
probability independent processors gamma ae stretching ratio processors ideal competition protocol ae stretching ratio processor ae 
speedup ideal competition protocol gamma ae gamma ae ae delta delta delta ae gamma theorem true independent processors underlying distributions long ae 
fact best possible performance dynamic methods including migration executing sequential process parallelism background 
theorem shows ideal competition protocol diminishing return adding processor returns quantitatively 
ae may point adding processor ae 
theorem shows processors maximum possible speedup minimum 
ideal competition protocol get slow minimum speedup get fold speedup maximum best speedup competition background occurs ae high 
exactly time takes longest 
tradeoff finish soon ae low lots spare cycles competition probably won help 
ae high high degree competition efficiency finish soon cloning 
assume ideal competition protocol increases number clones diminishing return clones clones additional clone offer speedup 
order find number clones foreground utilization diminishing return diminishing return diminishing return number clones diminishing return formance benefit adding clone solve inequality ae gamma 
log log ae 
curve middle shows clones need function ae diminishing return 
ae clones diminishing return 
ae increases number clones sharply increases diminishing return 
shows cases need clones diminishing return diminishing return 
theorem shows foreground load processors gets high clone foreground load gets low worth having clones 
ideal case hurt system performance 
non ideal case degrades system performance ideal competition protocol coordinate 
ideal competition protocol measure busy processors runtime clone process sp theorem improve performance sp 
general competition valuable worst case ae increases counter intuitive 
arrival rate foreground processes service times processors theorem won applied exactly 
non zero propagation delay theorem won applied 
theorem shows limit achieved competition protocols 
competition protocols better 
statistics foreground processes processors different formula similar shape ideal competition protocol better 
benefit get additional processor exponentially trails 
shape exponential slightly different 
upper bound speedup ideal competition protocol processors single processor approaches ae approaches ae approaches 
shown speedup competition protocol approaches goes infinity 
speedup ideal competition protocol competition protocol approaching ae approaches 
absolute execution time competition approaches infinity ae approaches 
achieve best speedup finishing time worst 
queue effect load balancing order see load balancing effect ideal competition protocol consider queue foreground processes arrive rate service rate foreground process servers foreground processes wait queue order arrival 
interested probability servers idle 
state system defined tuple denotes number foreground processes queue including specific server denotes number foreground processes server 
foreground process arrives servers idle scheduled service servers randomly 
obviously probability server idle foreground processes waiting server zero queue 
clearly queue load balanced independent queues 
consider speedup ideal competition protocol processors foreground activity characterized queue 
state diagram system 
balance equations steady state state diagram queue written equating rate flow state rate flow state gp gp gp fp gp gamma traffic intensity system ae 
applying concept local balance kle balance equation gamma equation easily seen satisfy equation 
repeated equation aep gamma ae gamma equations obtain aep aep ae observing ae ae ae gamma ae ae gamma ae get gamma ae ae gamma ae ae gamma ae ae gamma ae execute sp processor processors background probability processor idle gamma ae ae ae gamma ae mean stretching ratio processor processors ae gamma ae gamma ae ae 
note mean stretching ratio single queue gamma ae 
gamma ae 
ae gamma ae gamma ae ae finish sp faster processor queue processor queue 
queue balanced fraction idle times processor queue processor queue statistics 
consequently take shorter finish processor queue processor queue 
ideal competition protocol processors allows sp progress long idle probability gamma ae ae ae gamma ae 
mean stretching ratio ae gamma ae gamma ae ae speedup ideal competition protocol processors processor queue ae gamma ae gamma ae ae ae gamma ae gamma ae ae ae ae best speedup ideal competition protocol approaches processors ae goes 
note best speedup ideal competition protocol independent queues goes ae goes 
speedup queue smaller independent queues 
reason queue balanced independent queues load processors balanced idle periods processors overlap effectiveness competition decreases 
conclude speedup ideal competition protocol decreases load processors balanced 
widely observed usage computing resources distributed environment usually bursty time uneven processors 
believe ideal competition protocol may get performance benefit queue real snow processors burstiness uneven load 
chapter competition migration sequential process migration competition speed distributed programs snow 
order compare performance competition migration consider sequential process sp parallelism 
assume processors alternate busy periods idle periods lengths busy periods processors random variables exponential distribution mean lengths idle periods random variables exponential distribution mean mean stretching ratio processors migration delay state propagation delay larger mean length busy periods migration protocols competition protocols generally improve performance sp 
focus case mean delay migration state propagation smaller mean length busy periods 
chapter compare performance competition migration 
goal develop efficient migration protocols competition protocols develop migration protocols competition protocols fairly comparable 
show migration beneficial competition may beneficial migration comparable assumptions 
consider migration protocols competition protocols different performance characteristics 
assume competition protocols replicate sequential process sp statically put clones sp sp delta delta delta sp different variable speed processors delta delta delta processors number clones fixed changes 
assume migration protocols migrate sp variable speed processors processors 
time sp executed called hosting processor 
compare performance competition migration assuming processors participating competition participating migration 
simplicity assume migration delay state propagation delay constant 
assumption unrealistic ways states large states small may congestion network 
going ignore assume migration delay state propagation delay independent factors system 
migration policy competition policy choices migration protocols deciding migrate migrate migrate 
chapter focus sequential process sp need consider migrate 
consider specific migration policy sp preempted migration protocols migrate sp randomly idle processor gamma processors immediately idle processor available 
migration protocols migrate sp idle processor processor goes idle processors 
current hosting processor goes idle earlier processors migration protocols need migrate sp 
choices competition protocols deciding clone degree folds folds clone clone 
consider sequential process sp assume number clones sp fixed just need consider propagate states clone clones 
competition protocols ideally propagate states clone ahead clones vice versa 
determine clone ahead number instructions executed cpu cycles 
consider specific competition policy clone ahead preempted competition protocols propagate state clones 
competition protocols propagate state clone preempted 
summary foreground processes arrive sp preempted migrated idle processor gamma processors immediately idle processor processor goes idle 
clone sp preempted competition protocols propagate state clones ahead 
practice delay choosing migration target determining clone ahead assume migration decision state propagation decision instantaneously migration competition protocols study 
amount information transfer competition protocols larger migration protocols general network topology clones sp 
difference network multicasting capability ethernets token rings 
competition protocols deliver message clone message process clone receiver communication requirement competition higher migration 
difference disappears network multicasting capability 
chapter assume overheads migration competition identical independent number clones consider snow environments multicasting capability 
migration protocols competition protocols section describe migration protocols competition protocols explain differences protocols 
assume decision making part protocols migration competition done high priority process migration state propagation done low priority order minimize interference foreground processes 
migration delay state propagation delay vary practice assume delays constant sake analysis 
decision making may interfere foreground processes delay won long migration state propagation 
migration protocols mig mig comp comp migration decision state propagation decision process consists packets state consists packets transmit packet target multicast packet targets skeletons protocols migration protocols considered chapter specific migration policy described subsection 
show skeletons mig mig protocols 
sp preempted migration decision instantaneously 
assume packets transferred source target 
difference mig mig migration delay mig protocol mig protocol constant 
migration mig protocol successful target idle migration completed 
hand migration mig protocol may successful due migration delay target may busy sp migrating 
note migration decision right assume migration decision instantaneous 
probability migration success decreases migration delay increases 
migration unsuccessful assume target treats sp way preempts sp 
possible sp migrate having chance run 
focus mig mig migration protocols chapter 
competition protocols competition protocols considered chapter specific competition policy described subsection 
competition protocols propagate state clone ahead freeze execution clones instantaneously 
start propagate state clones reset state clones state propagated 
assume state propagation decision freezing clones instantaneous 
consider comp protocol state propagation instantaneous similarly mig protocol 
skeleton comp protocol shown 
consider competition protocol called comp protocol delay state propagation constant fair comparison mig protocol comp protocol 
comp comp protocols identical state propagation delay 
competition protocols replaces clone ahead clone freezing 
clones frozen states may partly modified states propagating 
practice necessary freeze clones period time 
clone ahead needs frozen state locally copied clones need frozen switching state maintaining states 
inherent differences competition migration critical process distributed program executing heavily loaded processor may migrate heavily loaded processor lightly load processor 
processes program may wait critical process due synchronization message communication migration 
critical process slowest program migration delay degrade completion time entire program 
furthermore migration delay snow large migration background process lower priority foreground message traffic 
fundamental limitation migration comes fact instance process executing time 
migration protocols choose targets start migration 
target may busy process migrating targets idle 
migration delay large workload foreground processes processors changes fast drastically migration may unsuccessful 
migration successful idle period target may smaller targets 
migration protocols may choose idle periods including minimum maximum 
average idle period chosen mean length idle periods independently number participating processors 
idle period competition protocols typical idle period maximum idle periods clone start execute time state propagation progress preempted earliest 
assume clone preempted propagate state competition protocols 
processors busy sp preempted sp dormant hosting processor migration protocols 
non hosting processor idle virtual node busy idle busy idle initial placement time migration push migration pull mig protocol earlier hosting processor non hosting processor migrate sp current hosting processor order execute sp migration protocols 
migration called migration pull 
competition guarantees clone ahead clones fastest processor processors competition protocols propagate state clones clone ahead preempted 
performance comparison mig comp mig protocol comp protocol similar skeletons unicasting migration multicasting competition 
mig protocol shows case processors process sp initially starts 
shaded periods indicate processors busy white periods indicate processors idle 
solid horizontal arrow indicates process migration called migration push idle period dotted horizontal arrow indicate migration pull idle period 
need distinguish migration push migration pull migration delay zero 
mig protocol sp migrated processor instantaneously matter sp starts 
migrates sp 
sp migrated 
preempts sp migrate sp busy 
sp stays dormant idle sp migrated 
execution trace sp shown thick vertical arrows 
order analyze performance mig protocol project idle periods horizontally imaginary processor called virtual node 
busy time virtual node called busy possible execute sp processor 
virtual node called idle moment 
period continuously busy called busy period period continuously idle called idle period 
shows sp starts busy 
initial busy periods processors fact residual busy periods sp starts 
distribution time remaining exponentially distributed random variable independent acquired age random variable kle 
length busy period virtual node simply minimum lengths busy periods 
second minimum lengths residual busy periods 
busy period starts distribution residual busy period memoryless property exponential distributions 
general length busy period minimum lengths busy periods 
lengths busy periods exponentially distributed parameters respectively minimum lengths distributed parameter kle tri 
idle period virtual node may consist segment shown segment indicates sp executes processor period 
mig protocol checks idle processors segment preemption occurs 
note segment may part idle period processor 
idle period consists segments 
idle period residual idle period residual idle period exponential distribution idle period 
migration stops busy idle period ends busy period starts 
busy periods idle periods virtual node alternate 
form renewal process alternating states virtual node letting renewal period busy period followed idle period 
analyze performance mig protocol virtual node renewal period cox 
know means busy periods idle periods easily find stretching ratio virtual node performance mig protocol 
renewal period indicated thick horizontal dotted line 
observe lengths busy periods virtual node shortened lengths idle periods lengthened reason virtual node mig protocol processors renders better performance single processor 
denote busy period idle period respectively virtual node participating processors 
exponentially distributed mean minimum exponentially distributed random variables mean mean consider mean idle period 
probability processor delta delta delta busy time ae 
sp starts initially start execute sp migration pull case called proper processor number migration idle period 
sp positioned initially migrate sp 
note migration pull occur idle period virtual node 
migration pull different migration push migration pull occurs idle period migrations occur idle period 
furthermore migration pull may may necessary depending sp positioned proper processor 
probability sp positioned proper processor idle period assuming processors 
focus processors 
segment idle period hosting processor busy checks processor 
probability processor idle random point time gamma ae probability processor idle segment moment preemption gamma ae validated simulation theoretic upper bound derived chapter 
denote number migration excluding migration pull idle period 
mig protocol number segments idle period migration stops segment 
probability mass function modified geometric distribution tri px fs delta delta delta probability processor idle preemption occurs processor gamma gamma 
idle period consists random sum segments segment exponentially distributed idle period due memoryless property exponential distributions 
denote length idle period processors participating migration 
mean tri gamma mean stretching ratio mig protocol processors delta gamma speedup mig protocol processors single processor gamma theorem assume processors participating migration 
preemption occurs processor probability processor idle mig protocol equal gamma ae 
proof assume probability processor idle equal gamma ae 
show equation larger optimal speedup derived theorem 
replacing equation gamma ae get optimal speedup processors ae theorem 
ae multiplying numerator denominator get ae numerator equation larger equation denominator equation larger equation 
equation larger equation 
means larger optimal speedup contradictory 
implies probability smaller gamma ae 
equation shows performance ideal case migration decision migration overheads 
result optimal speedup ae 
setting ae probability idleness preemption occurs virtual node busy idle busy idle time state propagation comp protocol easily seen smaller gamma ae 
going probability approximate probability idleness migration delay instantaneous section 
comp protocol shows clones sp sp start respectively activities foreground processes 
solid arrow indicates state propagation 
clone sp starts execute sp starts execute 
sp may start sp state 
necessary going propagate sp state anyway 
similarly clone sp may resume execution sp state moment 
necessary preempts sp propagates state 
replaces sp state sp state 
preempts sp propagates state busy replaces sp state sp state 
differs migration protocols migration stops busy 
resumes execute sp 
competition protocols need worry initial placement idle period virtual node clone ahead guaranteed proper processor 
order analyze performance comp protocol project idle periods virtual node horizontally shown migration pull 
similarly mig protocol form renewal process alternating states virtual node letting renewal period busy period followed idle period 
analyze performance comp protocol inspecting mean lengths idle periods busy periods 
length busy period minimum lengths busy periods mig protocol 
idle period may consist segment shown segment traces performance profile clone ahead time 
idle period consists segments traces sp performance second traces sp performance third traces sp performance 
focus processors 
processor propagates state busy 
idle period virtual node ends processor busy 
need know probability processor busy idle state propagation 
state propagation instantaneous probability probability processor idle moment preemption processor 
probability equation 
denote number state propagations idle period 
comp protocol number segments idle period state propagations occur segment including 
probability mass function geometric distribution tri fs delta delta delta gamma clones start execution time segment idle period comp protocol state propagation instantaneous 
starts earlier segment clone progress preempted 
mig protocol 
idle period consists random sum segments segment exponentially distributed idle period due memoryless property 
denote length idle period processors participating competition 
mean mean stretching ratio comp protocol processors speedup comp protocol processors single processor ae performance comp protocol optimal speedup 
participating processors processor executes clone ahead comp protocol hosting processor sp mig protocol migration competition starts independent identical snow environments 
execution trace sp mig protocol execution trace faster clone comp protocol 
true participating processors 
migration pull mig protocol instantaneous appears sp stays proper processor idle period 
furthermore comp protocol mig protocol completely exploit idle periods processors 
waste idle periods processors achieve optimal speedup 
simulation results simulated mig comp protocols validate analysis 
simulations set simulated times period simulation results mean simulation results 
axis mean length busy periods shown multiples shows simulation results curves labeled competition migration speedup mean length busy periods optimal speedup competition migration simulation results processors simulation results mig protocol comp protocol respectively 
curve labeled optimal speedup ae optimal speedup processors derived chapter 
analytic results agree optimal speedup find probability idleness setting analytic speedup equal optimal speedup 
shows analytic results simulation results perfectly matched validate simulation code delay migration state propagation section 
going approximate probability idleness delay migration state propagation zero section 
shows optimal speedup simulation results mig comp protocols processors 
axis mean length busy speedup mean length busy periods optimal speedup competition migration simulation results processors periods shown multiples find probability idleness processor case omit analytic result optimal speedup 
correctness simulation codes validated 
performance comparison mig comp mig protocol shows activities foreground processes shows idle period consists black periods white periods 
solid arrow indicates migration pull dotted arrow indicates migration pull 
shaded periods white periods denote black period denotes migration delay shown virtual node idle busy busy idle initial placement time mig protocol rectangular band 
white periods effectively available execute sp black periods represent migration delay 
denote sum white periods black periods idle period virtual node respectively number participating processors called available time 
idle period start white black period depending sp positioned proper processor idle period 
denote number migration migration pull idle period 
random variable distributed equation 
section going approximate probability idleness preemption occurs 
show approximation analytic results simulations close 
busy periods idle periods alternate virtual node busy period idle period form renewal period 
available time renewal period execute sp stretching ratio note 
migration may successful migration delay 
migration successful sp run migration may migrate having chance run 
need know probability migration success 
interested case idle period highly available locally migration target may busy migration completes 
hosting processor preempts sp time checks processor idle 
idle period started random variable represents residual idle period time memoryless property exponential distribution probability migration success gammad mean available time idle period xp term accounts case sp positioned proper processor idle period probability processor case 
second accounts case sp positioned improper processor 
mean number migration push including migration pull gamma term accounts accumulated periods idle period 
second third terms multiplied sp chance run migrations successful 
gammad mig protocol mean sum migration delays idle period xd term accounts migration pull second term accounts migration delay migration push regardless success failure 
stretching ratio mig protocol processors gammad lim approaches performance mig approaches mig expected 
speedup mig protocol processors single processor gammad comp protocol assumed clones frozen state propagation freezing shown rectangular band 
start execute sp 
fact state propagation harms performance process virtual node idle busy busy idle time freezing comp protocol sp 
sp sp resume execution time progress preempts sp assume competition protocols break tie sp sp making progress sp stops making progress 
competition protocols allow propagate sp state sp sp progress freezing 
competition protocols idle period starts white period long state propagation finished idle periods participating processors start 
reason clone positioned proper processor idle period 
competition protocols delay similar migration pull migration protocols 
say state propagation successful state propagation completed idle period processors sp progress interruption propagation delay 
occurs period propagating processor smaller processor idle state propagation completed 
going probability processor idle state propagation completed 
probability state propagation succeeds gamma gammad gammad probability state propagation fails gamma number state propagation idle period number white periods idle period state propagation 
probability mass function geometric distribution equation focus processors 
state propagation completed clones may start execution time example 
clone longer idle period propagate state 
corresponding segment typical idle period maximum idle periods 
clone starts earlier corresponding segment distributed typical idle period 
clones start time busy period state propagator smaller processor idle state propagation completed 
probability gamma gammad probability clone starts earlier gammad gamma gammad order find mean sum available time idle period need know probability segment idle period maximum idle periods probability segment simply typical idle period 
gamma gammad need normalize 
gamma gammad gamma gammad gammad gamma gammad gamma gammad note clone starts earlier segment idle period 
mean maximum lengths exponentially distributed idle periods abn 
mean sum available time idle period gamma replacing equation get gamma gamma gammad gammad gamma gammad comp protocol dy speedup mean length busy periods delay mean length idle periods optimal speedup simulation analysis simulation analysis speedup processors lim approaches performance comp approaches comp expected 
simulation results simulated mig comp protocols validate analysis 
simulations set mean busy periods speedup mean length busy periods delay mean length idle periods optimal speedup simulation analysis simulation analysis speedup processors delay migration state propagation represented multiples simulated times period simulation results means simulation results 
show simulation results processors delay migration state propagation respectively 
figures curves labeled simulation simulation simulation results mig comp protocols respectively 
curves labeled analysis analysis analytic results assuming probability migration probability success state propagation 
curve labeled optimal speedup ae processors 
delay migration state propagation migration state propagation deteriorate completion time applications small mean length busy periods idle periods may locally available migration state propagation completed 
shows mig comp protocols improve performance region 
shows speedups mig comp protocols larger respectively 
interested cases delay migration state propagation smaller mean busy periods 
regions simulation results analytic results close 
significant discrepancy simulation results analytic results region mean busy periods smaller delay migration state propagation especially mig protocol occurs approximate probability migration 
equation approaches error approximate probability migration magnified discrepancy comp protocol smaller mig protocol term comp protocol sensitive errors mig protocol gammad approaches approaches 
increases shown performance difference mig protocol comp protocol increases reason frequency migration pulls mig protocol increases increases overhead migration pulls dominating comp protocol overhead 
increases overhead migration pulls increases speedup mean length busy periods delay mean length idle periods optimal speedup competition migration speedup processors probability migration success decreases 
process migration fails process may migrate chance running mig protocol 
probability state propagation success decreases state propagation guaranteed improve performance applications comp protocol propagates state clone ahead clones 
performance difference mig protocol comp protocol larger 
show simulation results processors delay migration state propagation respectively 
shape curves figures similar respectively 
shows simulation results ae 
speedup mean length busy periods delay mean length idle periods optimal speedup competition migration speedup processors speedup delay mean length busy periods mean length idle periods migration migration competition competition speedup processors delay migration state propagation increases performance mig protocol deteriorates faster comp protocol overhead migration pull dominates probability migration success decreases 
sufficiently large shows competition processors may perform better migration processors migration processors may perform better migration processors large delay migration 
chapter competition migration distributed programs chapter consider performance competition protocols distributed programs 
consider question maximum speedup competition protocols achieve simulating completion time distributed programs 
simulation results show competition protocols achieve speedups distributed programs sequential programs 
compare performance competition protocols performance migration protocols distributed programs 
consider effect load imbalance granularity performance competition protocols 
simulator built order evaluate performance competition protocols migration protocols 
simulates snow environment competition protocols migration protocols sequential processor 
simulator written language bl 
simulator composed layers described chapter application layer competition layer kernel layer 
application layer consists set processes communicate messages 
application layer fact processes may cloned snow hidden 
competition layer implements competition protocols including detecting clone process ahead making decision state propagation 
kernel layer simulates variable speed processors snow environment message communication processors 
application layer different kinds distributed programs consider limited set distributed programs full connectivity mesh connectivity ring connectivity 
assume distributed program consists processes 
numbers neighbors topologies gamma respectively 
assume process distributed program alternates computation phases communication phases processes exchange messages neighbors process starts computation phase 
process sends messages neighbors waits messages neighbors 
process resumes execution receive messages neighbors 
assume message communication bidirectional case consider unidirectional ring see effect number neighbors performance competition protocols 
time process needs complete computation phase dedicated processor called granularity process denoted assume granularity processes distributed program identical case consider case granularity process larger processes order see effect load imbalance processes performance competition protocols 
pk 
static boundary pk 
dynamic boundary assume latency message communication zero latency relatively small compared latency state propagation 
issues simulation simulation model distributed programs similar simulation model sequential programs message communication 
consider cases delay migration state propagation zero delay positive constant 
static dynamic boundary migration processes distributed program may allocated different processors parallel execution allocation called configuration pro gram 
assume distributed program consists processes variable speed processors available execute program 
consider ways execute program processors 
allocate processors process process allowed migrate processors migration protocols 
shows static boundary migration 
squares represent processors circles represent processes rectangles round corners represent boundaries processes migrate 
second allocate processor process migration protocols remaining processors pool processors process migrate 
shows dynamic boundary migration 
process migrates configuration program pool processors change 
competition protocols change configuration process dynamically clones cloning processors especially peer clones process offer competition advantage processor faster processors execution speeds identical 
general dynamic strategy offers better performance static strategy migration competition communication delay pair processors identical 
dynamic strategy requires complicated policies process migration decision migration protocols cloning decision competition 
scope study consider static strategy chapter 
migration policy competition policy sequential processes states running preempted 
addition states processes distributed program state waiting messages 
message clone arrives processor process clone waiting state migration policy migrates process clone message clone idle processor available 
processor idle earlier processor migrates process execute 
competition policy propagates state process clone process clone ahead 
positive latency state propagation propagate states process clone sufficiently ahead peer process clones 
optimize competition protocols direction optimize competition protocols kind optimization available migration protocols 
assumptions simulation denote mean length idle periods mean length busy periods respectively 
chapter interchangeably interchangeably 
simulations set delays granularity mean length busy periods delay migration state propagation represented multiples simulated times processes distributed program exchange messages neighbors times simulation results means simulation results 
assumed latency message communication zero configuration program performance effect study 
assumed clone runs processor 
speedup competition protocols performance measures ideally obtained observing implementation competition protocols running actual snow building system scope study 
consider simple distributed programs connectivities full connectivity mesh connectivity ring connectivity 
simulated execution programs snow 
performance measure speedup achieved competition protocols program 
speedup ratio program completion time competition program completion time competition snow 
assume processors available execute clone processor 
programs full connectivity consider distributed program consisting fully connected processes 
assume processes uniformly cloned times granularity mean execution time communication phases processes 
parameters describe system 
mean length busy periods processors speedup mean length busy periods balanced processes full connectivity comp comp comp seq 
optimal speedup processes full connectivity speedup mean length busy periods balanced processes full connectivity comp comp comp seq 
optimal speedup processes full connectivity number clones processes delay process migration state propagation performance competition protocols 
curve labeled comp represents speedup competition processes cloned times curve labeled seq 
optimal speedup represents optimal speedup sequential programs processors ae 
speedup curves increases monotonically mean length busy periods increases shown sequential processes chapter 
shows achieve speedups distributed program fully connected processes sequential programs optimal speedup sequential programs lower bound distributed program 
speedup curves 
observe speedup smaller speedup delay state propagation 
region axis speedup competition distributed program fully connected processes processors larger optimal speedup sequential programs processors 
shows speedups competition protocols migration protocols processors respectively 
shown competition protocols migration protocols achieve speedup expected 
increases speedups migration protocols deteriorate quicker competition protocols 
phenomena observed sequential processes 
shows speedups competition protocols migration pro speedup mean length busy periods comp balanced processes full connectivity delay delay delay speedup competition processors speedup mean length busy periods mig balanced processes full connectivity delay delay delay speedup migration processors speedup mean length busy periods balanced processes full connectivity comp mig comp mig comp mig comparison competition migration different number processors speedups competition protocols consistently greater migration protocols number participating processors 
shows effect number processes full connectivity speedup competition protocols achieve 
number processes increases competition protocols achieve speedups probability executes slow processor competition increases 
consider effect granularity performance competition protocols 
shows speedup competition protocols decreases granularity increases 
granularity sufficiently large speedup curves approaches optimal speedup sequential processes 
reason processes tend fully parallel processes communication execution time program approaches speedup 
processes balanced processes full connectivity comp comp comp effect number processes speedup single process 
consider effect load imbalance processes process curve labeled uniform comp shows performance competition protocols degree competition processes identical 
curve labeled selective comp shows performance competition protocols process granularity cloned 
shows may need clone processes distributed program critical processes 
programs mesh connectivity consider distributed program consisting processes mesh connectivity 
shows performance competition protocols fully connected processes region axis speedup competition processes mesh connectivity speedup granularity balanced processes full connectivity comp comp comp effect granularity speedup speedup degree competition unbalanced processes full connectivity uniform comp selective comp effect load imbalance speedup speedup mean length busy periods processes mesh connectivity comp comp comp seq 
optimal speedup processes mesh connectivity larger optimal speedup sequential programs processors 
shapes speedup curves similar fully connected processes shown 
observe speedups fully connected processes greater processes mesh connectivity 
reason processes program stronger dependency processes neighbors processes program 
simulation results processes mesh connectivity consistently show shapes speedup curves similar fully connected processes 
simulation results processes mesh connectivity 
consider distributed programs consisting processes processes mesh connectivity respectively 
speedups speedup degree competition processes mesh connectivity mesh mesh mesh processes mesh connectivity shown 
processes number neighbors processes program processes indirectly dependent number processes 
competition protocols achieve speedup program processes program processes mesh connectivity 
programs ring connectivity consider distributed program processes ring connectivity 
shows performance competition protocols different degrees competition number neighbors processes undirected ring directed ring 
competition speed program undirected ring connectivity directed ring connectivity 
speedup degree competition processes ring connectivity undirected ring directed ring processes ring connectivity order understand speedups competition protocols obtain distributed programs different topologies different number processes simulation results cases processes full connectivity processes mesh connectivity processes mesh connectivity processes undirected ring connectivity processes directed ring connectivity processes full connectivity 
processes fully connected program strongest dependency processes cases 
processes directed ring connectivity number direct neighbors fully connected processes processes depends indirectly 
competition protocols achieve speedup 
processes distributed program stronger depen speedup degree competition different topologies full mesh mesh undirected ring directed ring full speedup different topologies dency directly indirectly progress hindered processes competition 
competition protocols achieve speedup distributed program stronger dependency 
chapter research studied competitive execution distributed environment network workstations 
analytic results simulation results illustrate ability competitive execution speed execution distributed programs 
showed migration achieve optimal performance complete knowledge foreground activities 
competition need know foreground activities achieve optimal performance 
competition easily obtains benefit cost redundant execution 
competition protocols state propagation state propagation showed competition protocols limited performance benefit 
competition mechanisms deals message multicasting state propagation peer process clones addition message communication clones communicating processes 
showed competitive execution finish distributed programs significantly faster execution especially foreground load processor sufficiently high 
derived closed form solution performance ideal competition protocol extensively studied performance competition protocols sequential process mathematical analysis simulation 
shown competition protocols offer performance benefits better migration protocols sequential distributed programs comparable assumptions 
supported analytic results simulation results sequential programs 
performance competition protocols distributed programs simulation 
simulation results showed competition protocols offer speedups distributed programs sequential programs 
means finished subject competition distributed context 
order better understand performance competition distributed programs intend implement simulate distributed programs different synchronization communication requirement 
study competition policy issues 
understood real competitive systems designed 
need study competitive mechanisms policies dynamic cloning 
study implementation issues consider processor idle minimize interference background programs preemptive scheduling foreground processes may insu late foreground processes background programs 
memory management file access network access redesigned support competition 
abn barry arnold balakrishnan 
course order statistics 
john wiley sons 
acp thomas anderson david culler david patterson team 
case networks workstations 
ieee micro pp 
february 
ae agrawal 
location independent remote execution nest 
ieee transactions software engineering 
af finkel 
designing process migration facility charlotte experience 
computer september 
aj goldberg jefferson 
transparent process cloning tool load management distributed programs 
int conf 
parallel processing pp 

ak avizienis john kelly 
fault tolerance design diversity concepts experiments 
computer august 
amd amdahl 
validity single processor approach achieving large scale computer capacities 
afips conference proceedings volume pp 

bir birman 
replication fault tolerance isis system 
proc 
th acm symp 
operating systems principles pp 

bkt henri bal frans kaashoek andrew tanenbaum jack jansen 
replication techniques speeding parallel applications distributed systems 
concurrency practice experience august 
bl bagrodia wen toh liao 
user manual 

bm kenneth birman keith marzullo 
isis meta project 
sun technology pp 
summer 

assignment problems parallel distributed computing 
kluwer academic publishers 
boy boyle portable programs parallel processors 
holt rinehart winston 
bss birman schiper stephenson 
lightweight casual atomic group multicast 
acm transactions computer systems august 
cc jane chiu ge ming chiu 
process replication technique fault tolerance performance improvement distributed computing systems 
proceedings third international symp 
high performance distributed computing pp 
san francisco california august 
cg nicholas carriero david gelernter 
write parallel programs guide 
acm computing surveys pp 
september 
cha ham chang high performance tcp ip udp ip networking dec osf alpha axp 
high performance distributed computing pp 
san francisco california august 
che li wen chen 
model distributed dynamic progress management 
phd thesis university california los angeles 
cm jo mei chang maxemchuk 
reliable broadcast protocols 
acm transactions computer systems august 
coo cooper 
replicated distributed programs 
proc 
th acm symposium operating systems principles pp 
december 
cox cox 
renewal theory 
methuen london 
fred douglis john ousterhout 
transparent process migration design alternatives sprite implementation 
software practice experience august 
ebb thorsten von eicken anindya basu vineet 
low latency communication atm networks active messages 
ieee micro pp 
february 
el lewis ali 
task scheduling parallel distributed systems 
prentice hall 
eager lazowska zahorjan 
adaptive load sharing homogeneous distributed systems 
ieee transactions software engineering may 
eager lazowska zahorjan 
comparison receiver initiated sender initiated dynamic load sharing 
performance evaluation april 
derek eager edward john zahorjan 
limited performance benefits migrating active processes load sharing 
proceedings acm sigmetrics conference measurement modeling computer systems pp 
santa fe new mexico may 
ez elnozahy willy zwaenepoel 
replicated distributed processes manetho 
proc 
conf 
fault tolerant computing systems pp 
july 
fat rod 
performance evaluation communication networks distributed computing 
technical report nas nasa ames research center march 
fkb flower bharadwaj 
express way distributed processing 
supercomputing review pp 
may 
robert eve schooler leonard kleinrock 
benevolent bandit laboratory testbed distributed algorithms 
ieee journal selected areas communications february 
gei geist pvm parallel virtual machine users guide tutorial networked parallel computing 
mit press cambridge massachusetts 
gls gropp lusk skjellum 
mpi 
mit press 
gus john gustafson 
reevaluating amdahl law 
communications acm may 
hag robert hagmann 
process server sharing processing power workstation environment 
th international conf 
distributed computing systems pp 
cambridge massachusetts may 
jef david jefferson 
virtual time 
acm trans 
programming languages systems july 
ju xu jie tao 
parallel computing idle workstations 
operating systems review july 
kc phillip krueger rohit chawla 
stealth distributed scheduler 
th int conf 
distributed computing systems pp 
arlington texas may 
kk leonard kleinrock willard korfhage 
collecting unused processing capacity analysis transient distributed systems 
th int conf 
distributed computing systems pp 

kk jeff kramer 
methodical analysis adaptive load sharing algorithms 
ieee transactions parallel distributed systems november 
kl phillip krueger miron 
comparison preemptive non preemptive load distributing 
th int conf 
distributed computing systems pp 
san jose california june 
kle leonard kleinrock 
queueing systems theory 
john wiley sons 
kor willard robert 
distributed systems transient processors 
phd thesis university california los angeles 
kt kaashoek tanenbaum 
group communication amoeba distributed operating system 
int conf 
distributed computing systems pp 

lam lamport 
time 
clock ordering events distributed system 
commun 
acm july 
lin hsieh david du joseph thomas 
distributed network computing local atm networks 
proc 
supercomputing pp 
washington november 
llm litzkow mutka 
condor hunter idle workstations 
th int conf 
distributed computing systems pp 
san jose california june 
lm 
load balancing homogeneous broadcast distributed systems 
proc 
acm computer network performance symposium pp 
april 
ls scott leutenegger sun 
distributed computing feasibility non dedicated homogeneous distributed system 
proc 
supercomputing pp 
portland oregon november 
ml matt mutka miron 
availability capacity privately owned workstation environment 
performance evaluation pp 

nic david 
idle workstations shared computing environment 
operating systems review november 
nut mark 
brief survey systems providing process object migration facilities 
operating system review october 
ni xu gendreau 
drafting algorithm dynamic process migration protocol distributed system 
proc 
th int conf 
distributed computing systems pp 
may 
phi chr etienne philippe 
task scheduling distributed memory machines pp 

elsevier science publishers north holland 
pw popek walker 
locus distributed system 
mit press 
sch fred schneider 
implementing fault tolerant services state machine approaches tutorial 
acm computing surveys december 
sg jonathan smith jr gerald 
exploring multiple worlds parallel 
int conf 
parallel processing pp 
ii 
sho 
distributed facility load sharing parallel processing workstations 
journal systems software 
smi jonathan smith 
survey process migration mechanisms 
operating system review july 
sn sun lionel ni 
scalable problems speedup 
journal parallel distributed computing 
sun sunderam 
pvm framework parallel distributed computing 
concurrency practice experience december 
sw wei shu min wu 
runtime incremental parallel scheduling rips large scale parallel computers 
proc 
frontiers pp 
mclean virginia february 
zhu 
implementation process migration amoeba 
proc 
th int 
conf 
distributed computing systems june 
tlc theimer cheriton 
preemptable remote execution facilities system 
proc 
th acm symp 
operating systems principles pp 

tri trivedi 
probability statistics reliability queueing computer science applications 
prentice hall 
john wexler 
concurrent programming occam 
john wiley sons 
zhou utopia load sharing facility large heterogeneous distributed computer systems 
software practice experience december 

