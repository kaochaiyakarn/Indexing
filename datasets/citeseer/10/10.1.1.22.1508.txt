scalable content addressable network sylvia ratnasamy paul francis mark handley richard karp scott shenker aciri dept 
electrical eng 
comp 
sci 
university california berkeley berkeley ca usa center internet research icsi berkeley ca usa hash tables map keys values essential building block modern software systems 
believe similar functionality equally valuable large distributed systems 
introduce concept content addressable network distributed infrastructure provides hash table functionality internet scales 
scalable fault tolerant completely self organizing demonstrate scalability robustness low latency properties simulation 

hash table data structure efficiently maps keys values serves core building block implementation software systems 
conjecture large scale distributed systems likewise benefit hash table functionality 
term content addressable network describe distributed internet scale hash table 
best example current internet systems potentially improved introduced peerto peer file sharing systems napster gnutella 
systems files stored user machines peers central server opposed traditional client server model files transferred directly peers 
peer peer systems quite popular 
napster introduced mid december software loaded users making fastest growing application web 
new file sharing systems freenet jungle monkey introduced year 
remains quite justified skepticism business potential file sharing systems believe rapid wide spread deployment suggests important advantages peer peer systems 
peer peer designs harness huge amounts resources content advertised napster observed exceed tb storage single day requiring centralized planning huge investments private communication yin zhang vern paxson permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigcomm august san diego california usa 
copyright acm 
hardware bandwidth rack space 
peer peer file sharing may lead new content distribution models applications software distribution file sharing static web content delivery 
unfortunately current peer peer designs scalable 
example napster central server stores index files available napster user community 
retrieve file user queries central server desired file known name obtains ip address user machine storing requested file 
file loaded directly user machine 
napster uses peerto peer communication model actual file transfer process locating file centralized 
expensive scale central directory vulnerable single point failure 
gnutella goes step de file location process 
users gnutella network self organize application level mesh requests file flooded certain scope 
flooding request clearly scalable flooding curtailed point may fail find content system 
started investigation question scalable peer peer file distribution system 
soon recognized central peer peer system indexing scheme map file names known discovered external mechanism location system 
peer peer file transfer process inherently scalable hard part finding peer retrieve file 
scalable peer peer system requires scalable indexing mechanism 
call indexing systems content addressable networks propose particular design 
applicability cans limited peer topeer systems 
cans large scale storage management systems oceanstore farsite publius :10.1.1.125.3017:10.1.1.115.4299
systems require efficient insertion retrieval content large distributed storage infrastructure scalable indexing mechanism essential component infrastructure 
fact discuss section oceanstore system includes core design oceanstore plaxton algorithm somewhat different propose :10.1.1.38.1850
potential application cans construction wide area name resolution services dns decouple naming scheme name resolution process enabling arbitrary location independent naming schemes 
interest cans belief hash abstraction give internet system developers powerful design tool enable new applications communication models 
focus cans design 
describe detail possible application call grass roots content distribution system leverages 
said cans resemble hash table basic operations performed insertion lookup deletion key value pairs 
design composed individual nodes 
node stores chunk called zone entire hash table 
addition node holds information small number adjacent zones table 
requests insert lookup delete particular key routed intermediate nodes node zone contains key 
design completely distributed requires form centralized control coordination configuration scalable nodes maintain small amount control state independent number nodes system fault tolerant nodes route failures 
systems dns ip routing design impose form rigid hierarchical naming structure achieve scalability 
design implemented entirely application level 
follows describe basic design section describe evaluate design detail section discuss results section 
discuss related section directions section 
design describe content addressable network basic form section additional design features greatly improve performance robustness 
design centers virtual dimensional cartesian coordinate space torus 
coordinate space completely logical bears relation physical coordinate system 
point time entire coordinate space dynamically partitioned nodes system node owns individual distinct zone space 
example shows dimensional coordinate space partitioned nodes 
virtual coordinate space store key value pairs follows store pair key deterministically mapped point coordinate space uniform hash function 
corresponding key value pair stored node owns zone point lies 
retrieve entry corresponding key node apply deterministic hash function map point retrieve corresponding value point point owned requesting node immediate neighbors request routed infrastructure reaches node zone lies 
efficient routing critical aspect 
nodes self organize overlay network represents virtual coordinate space 
node learns maintains ip addresses nodes hold coordinate zones adjoining zone 
set immediate neighbors coordinate space serves coordinate routing table enables routing arbitrary points space 
describe basic pieces design routing construction coordinate overlay maintenance overlay 
routing simplicity illustrations show torus reader remember coordinate space wraps 
intuitively routing content addressable network works straight line path cartesian space source destination coordinates 
node maintains coordinate routing table holds ip address virtual coordinate zone immediate neighbors coordinate space 
dimensional coordinate space nodes neighbors coordinate spans overlap dimensions abut dimension 
example node neighbor node coordinate zone overlaps axis axis 
hand node neighbor coordinate zones abut axes 
purely local neighbor state sufficient route arbitrary points space message includes destination coordinates 
neighbor coordinate set node routes message destination simple greedy forwarding neighbor coordinates closest destination coordinates 
shows sample routing path 
dimensional space partitioned equal zones average routing path length hops individual nodes maintain neighbors scaling results mean ddimensional space grow number nodes zones increasing node state average path length grows 
note different paths exist points space node neighbors crash node automatically route best available path 
node loses neighbors certain direction repair mechanisms described section rebuilt void coordinate space greedy forwarding may temporarily fail 
case node may expanding ring search stateless controlled flooding unicast overlay mesh locate node closer destination 
message forwarded closer node greedy forwarding resumed 
construction described entire space divided nodes currently system 
allow grow incrementally new node joins system allocated portion coordinate space 
done existing node splitting allocated zone half retaining half handing half new node 
process takes steps 
new node find node 

routing mechanisms find node zone split 

neighbors split zone notified routing include new node 
bootstrap new node discovers ip address node currently system 
functioning depend proposed routing algorithms location services route log hops node maintaining log neighbors :10.1.1.105.3673:10.1.1.38.1850
notice select number dimensions log achieve scaling properties choose hold fixed independent envision applying cans large systems frequent topology changes 
systems important keep number neighbors independent system size node virtual coordinate zone example space nodes details done bootstrap mechanism yoid 
assume associated dns domain name resolves ip address bootstrap nodes 
bootstrap node maintains partial list nodes believes currently system 
simple techniques keep list reasonably current described 
join new node looks domain name dns retrieve bootstrap node ip address 
bootstrap node supplies ip addresses randomly chosen nodes currently system 
coordinate neighbor set coordinate neighbor set finding zone new node randomly chooses point space sends join request destined point message sent existing node 
node uses routing mechanism forward message reaches node zone lies 
current occupant node splits zone half assigns half new node 
split done assuming certain ordering dimensions deciding dimension zone split zones re merged nodes leave 
space zone split dimension 
key value pairs half zone handed transfered new node 
joining routing having obtained zone new node learns ip addresses coordinate neighbor set previous occupant 
set subset previous occupant neighbors plus occupant 
similarly previous occupant updates neighbor set eliminate nodes longer neighbors 
new old nodes neighbors informed reallocation space 
node system sends immediate update message followed periodic refreshes currently assigned zone neighbors 
soft state style updates ensure neighbors quickly learn change update neighbor sets accordingly 
figures show example new node node joining dimensional 
addition new node affects small number existing nodes small locality coordinate space 
number neighbors node maintains depends dimensionality coordinate space independent total sample routing path node point example space node joins coordinate neighbor set coordinate neighbor set example space node joins number nodes system 
node insertion affects number dimensions existing nodes important cans huge numbers nodes 
node departure recovery maintenance nodes leave need ensure zones occupied taken remaining nodes 
normal procedure doing node explicitly hand zone associated key value database neighbors 
zone neighbors merged departing node zone produce valid single zone done 
zone handed neighbor current zone smallest node temporarily handle zones 
needs robust node network failures nodes simply unreachable 
handled immediate takeover algorithm ensures failed node neighbors takes zone 
case key value pairs held departing node lost state refreshed holders data normal conditions node sends periodic update messages neighbors giving zone coordinates list neighbors zone coordinates 
prolonged absence update message neighbor signals failure 
node decided neighbor died initiates takeover mechanism starts takeover timer running 
neighbor failed node independently timer initialized proportion volume node zone 
timer expires node sends takeover message conveying zone volume failed node neighbors 
receipt takeover message node cancels timer zone volume message smaller zone volume replies takeover message 
way neighboring node efficiently chosen alive small zone volume certain failure scenarios involving simultaneous failure multiple adjacent nodes possible node detects prevent stale entries refresh lost entries nodes insert key value pairs periodically refresh entries additional metrics load quality connectivity taken account interests simplicity won discuss 
failure half failed node neighbors reachable 
node takes zone circumstances possible state inconsistent 
cases prior triggering repair mechanism node performs expanding ring search nodes residing failure region eventually rebuilds sufficient neighbor state initiate takeover safely 
normal leaving procedure immediate takeover algorithm result node holding zone 
prevent repeated fragmentation space background zone reassignment algorithm describe appendix runs ensure tends back zone node 

design improvements basic algorithm described previous section provides balance low node state dimensional space short path lengths dn hops dimensions nodes 
bound applies number hops path 
application level hops hops latency hop substantial recall nodes adjacent miles ip hops away 
average total latency lookup average number hops times average latency hop 
achieve lookup latency comparable small factor underlying ip path latencies requester node holding key 
section describe number design techniques primary goal reduce latency routing 
unintentionally techniques offer additional advantage improved robustness terms routing data availability 
nutshell strategy attempting reduce path latency reduce path length hop latency 
final improvement basic design add simple load balancing mechanisms described sections 
describe evaluate design feature individually section discuss affect performance 
added features yield significant improvements come cost increased node state node state remains independent number nodes system somewhat increased complexity 
extent techniques applied involves trade improved routing performance system robustness hand increased node state system complexity 
greater deployment experience know application requirements better prepared decide tradeoffs 
simulated design transit stub ts topologies gt itm topology generator 
ts topologies model networks level hierarchy routing domains transit domains interconnect lower level stub domains 
multi dimensioned coordinate spaces observation design restrict dimensionality coordinate space 
increasing dimensions coordinate space reduces routing path length path latency small increase size coordinate routing table 
measures effect increasing dimensions routing path length 
plot path length increasing numbers nodes coordinate spaces different dimensions 
system nodes dimensions see path length scales keeping analytical results perfectly partitioned coordinate spaces 
increasing number dimensions implies node neighbors routing fault tolerance improves node potential hop nodes messages routed event neighboring nodes crash 
realities multiple coordinate spaces second observation maintain multiple independent coordinate spaces node system assigned different zone coordinate space 
call coordinate space reality 
realities single node assigned coordinate zones reality holds independent neighbor sets 
contents hash table replicated reality 
replication improves data availability 
example say pointer particular file stored coordinate location 
independent realities pointer stored different nodes corresponding coordinates reality unavailable nodes unavailable 
multiple realities improve routing fault tolerance case routing breakdown reality messages continue routed remaining realities 
contents hash table replicated reality routing location translates reaching reality 
node owns zone reality distinct possibly distant location coordinate space 
individual node ability reach distant portions coordinate space single hop greatly reducing average path length 
forward message node checks neighbors reality forwards message neighbor coordinates closest destination 
plots path length increasing numbers nodes different numbers realities 
graph see realities greatly reduce path length 
multiple realities reduces path length path latency 
multiple dimensions versus multiple realities increasing number dimensions realities results shorter path lengths higher node neighbor state maintenance traffic 
compare relative improvements caused features 
plots path length versus average number neighbors maintained node increasing dimensions realities 
see number neighbors increasing dimensions space yields shorter path lengths increasing number realities 
conclude tests multiple dimensions valuable multiple realities multiple realities offer benefits improved data availability fault tolerance 
point take away willing incur increase average node neighbor state primary purpose improving routing efficiency right way increase dimensionality coordinate space number realities better routing metrics routing metric described section progress terms cartesian distance destination 
improve metric better reflect underlying ip topology having node measure network level round trip time rtt neighbors 
destination message number hops realities number nodes dimensions dimensions dimensions dimensions effect dimensions path length forwarded neighbor maximum ratio progress rtt 
favors lower latency paths helps application level routing avoid unnecessarily long hops 
increasing number dimensions realities routing aims reducing latency individual hops path reducing path length 
metric evaluating efficacy rtt weighted routing hop latency obtained dividing path latency path length 
quantify effect routing metric transit stub topologies link latencies ms intra transit domain links ms stub transit links ms intra stub domain links 
simulated topology average latency underlying ip network path randomly selected source destination nodes approximately ms 
table compares average hop latency rtt weighting 
latencies averaged test runs number nodes ranging seen hop latency rtt weighted routing matches underlying average ip network latency routing lowers hop latency depending number dimensions 
higher dimensions give hop forwarding choices greater improvements 
overloading coordinate zones far design assumes zone point time assigned single node system 
modify allow multiple nodes share zone 
nodes share zone termed peers 
define system parameter maximum number allowable peers zone imagine value typically low example 
zone overloading node maintains list peers addition neighbor list 
node know peers zone need track peers neighboring zones 
node selects neighbor peers neighboring zones 
zone overloading increase amount neighbor information individual node hold require hold additional state peer nodes 
overloading zone achieved follows new node joins system discovers existent node zone meant occupy 
directly splitting zone number hops dimensions reality realities realities realities number nodes effect multiple realities path length number hops number nodes increasing dimensions realities increasing realities dimensions number neighbors path length increasing neighbor state described earlier node checks fewer peer nodes 
new node merely joins zone space splitting 
node obtains peer list list coordinate neighbors periodic soft state updates serve inform peers neighbors entry system 
zone full nodes zone split half 
node informs nodes peer list space split 
deterministic rule example ordering ip addresses nodes peer list new node divide equally halves split zone 
obtains initial list peers neighbors periodically node sends coordinate neighbor request list peers measures rtt nodes neighboring zone retains node lowest rtt neighbor zone 
node time measure round trip time nodes neighboring zone retain closest lowest latency nodes coordinate neighbor set 
initial bootstrap system node perform rtt measurement operation infrequent intervals unnecessarily generate large amounts control traffic 
contents hash table may divided replicated nodes zone 
replication provides higher availability increases size data stored node factor space partitioned fewer larger zones data consistency maintained peer nodes 
hand partitioning data set peer nodes require consistency mechanisms increased data storage improve availability 
overloading zones offers advantages reduced path length number hops reduced path latency placing multiple nodes zone effect reducing number nodes system 
reduced hop latency node multiple choices selection neighboring nodes select neighbors closer terms latency 
table lists average hop latency increasing system sizes ranging nodes transit stub simulation topologies section 
see placing nodes zone reduce hop latency 
improved fault tolerance zone vacant number non rtt weighted rtt weighted dimensions routing ms routing ms table hop latency rtt weighted routing nodes zone crash simultaneously case repair process section required 
negative side overloading zones adds somewhat system complexity nodes additionally track set peers 
multiple hash functions improved data availability different hash functions map single key points coordinate space accordingly replicate single key value pair distinct nodes system 
key value pair unavailable replicas simultaneously unavailable 
addition queries particular hash table entry sent nodes parallel reducing average query latency 
plots query latency time fetch key value pair increasing number nodes different numbers hash functions 
course advantages come cost increasing size key value database query traffic case parallel queries factor querying nodes node choose retrieve entry node closest coordinate space 
topologically sensitive construction overlay network construction mechanism described section allocates nodes zones random node neighbors need topologically nearby underlying ip network 
lead seemingly strange routing scenarios example node berkeley neighbor nodes europe path node nearby stanford may traverse distant nodes europe 
design mechanisms described previous sections try improve selection paths existing overlay network try improve overlay network structure 
section initial results current trying construct topologies congruent underlying ip topology 
initial scheme assumes existence known set machines example dns root name servers act landmarks internet 
achieve form distributed binning nodes relative distances set landmarks 
node measures round trip time landmarks orders landmarks order increasing rtt 
delay measurements different landmarks node associated ordering 
landmarks 
orderings possible 
accordingly partition coordinate space 
equal sized portions corresponding single ordering 
current somewhat naive scheme partition space 
portions works follows assuming fixed cyclical ordering dimensions divide space dimension portions portion sub divided second dimension portions divided por number nodes zone hop latency ms table hop latencies multiple nodes zone tions 
previously new node joined random point entire coordinate space 
new node joins random point portion coordinate space associated landmark ordering 
rationale scheme topologically close nodes ordering consequently reside portion coordinate space neighbors coordinate space topologically close internet 
metric evaluate binning scheme ratio latency network average latency ip network 
call latency stretch 
compares stretch cans constructed landmark ordering scheme 
transit stub topologies section landmarks placed random restriction hops away 
seen landmark ordering greatly improves path latency 
consequence binning strategy coordinate space longer uniformly populated 
orderings bins occur corresponding portions coordinate space densely occupied leading slightly uneven distribution load nodes 
background load balancing techniques described appendix overloaded node hands portion space lightly loaded alleviate problem 
results encouraging continuing study effect topology link delay distribution number landmarks factors scheme 
landmark ordering progress 
discuss 
uniform partitioning new node joins join message sent owner random point space 
existing node knows zone coordinates neighbors 
directly splitting zone existing occupant node compares volume zone immediate neighbors coordinate space 
zone split accommodate new node largest volume 
volume balancing check tries achieve uniform partitioning space nodes landmark ordering scheme section 
key value pairs spread coordinate space uniform hash function volume node zone indicative size key value database node store indicative load placed node 
uniform partitioning space desirable achieve load balancing 
note sufficient true load balancing key value pairs popular putting higher load nodes hosting pairs 
similar user perceived query latency dimensions realities hash function hash functions hash functions number nodes reduction user perceived query latency multiple hash functions hot spot problem web 
section discuss caching replication techniques ease hot spot problem cans 
total volume entire coordinate space vt total number nodes system perfect partitioning space nodes assign zone volume vt node 
denote vt ran simulations nodes uniform partitioning feature 
run compute volume zone assigned node 
plots different possible volumes terms axis shows percentage total number nodes axis assigned zones particular volume 
plot see uniform partitioning feature little nodes assigned zones volume compared feature largest zone volume drops surprisingly partitioning space improves increasing dimensions 
caching replication techniques hot spot management files web certain key value pairs far frequently accessed overloading nodes hold popular data keys 
popular data keys widely available borrow caching replication techniques commonly applied web 
caching addition primary data store data keys hash coordinate zone node maintains cache data keys accessed 
forwarding request data key destination node checks requested data key cache satisfy request forwarding 
number caches data key served grows direct proportion popularity act requesting data key widely available 
replication node finds overloaded requests particular data key replicate data key neighboring nodes 
replication active pushing popular data keys opposed caching natural consequence requesting data key 
latency stretch landmarks realities landmark ordering landmark ordering landmark ordering landmark ordering number nodes latency savings due landmark ordering construction percentage nodes uniform partitioning feature uniform partitioning feature volume effect uniform partitioning feature nodes dimensions reality popular data key eventually replicated region surrounding original storage node 
node holding replica requested data key certain probability choose satisfy request forward way causing load spread entire region just periphery 
schemes cached replicated data keys associated time live field eventually expired cache 

design review sections described evaluated individual design components 
evaluation recovery algorithms large scale smaller scale ns simulations :10.1.1.140.3129
briefly recap design parameters metrics summarize effect parameter different metrics quantify performance gains achieved cumulative effect features 
metrics evaluate system performance path length number application level hops required route points coordinate space 
neighbor state number nodes individual node retain state 
latency consider latency total routing path points coordinate space hop latency latency individual application level hops obtained dividing latency path length 
volume volume zone node assigned indicative request storage load node handle 
routing fault tolerance availability multiple paths points 
hash table availability adequate replication key value entry withstand loss replicas 
key design parameters affecting system performance dimensionality virtual coordinate space number realities number peer nodes zone parameter bare bones knobs full rtt weighted routing metric uniform partitioning landmark ordering table parameters number hash functions number points reality key value pair stored rtt weighted routing metric uniform partitioning feature described section cases effect design parameter certain metrics directly inferred algorithm cases resorted simulation 
table summarizes relationship different parameters metrics 
table entry marked indicates parameter significant effect metric indicate increase decrease respectively measure caused increase corresponding parameter 
numbers included certain table entries refer corresponding simulation results 
measure cumulative effect features selected system size nodes compared algorithms 
bare bones utilize additional design features 
knobs full making full added features landmark ordering feature section topology test transit stub topology delay ms intra transit links ms stub transit links ms intra stub links ms links connect transit nodes ms links connect transit node stub node forth 
tables list values parameters metrics test 
find results encouraging demonstrate system nodes route latency factor underlying network latency 
number neighbors node maintain achieve approximately definitely high side necessarily unreasonable 
biggest gain comes increasing number dimensions lowers path length approximately hops 
see latency reduction heuristics play important role latency heuristics latency close ms hops latency hop 
repeated knobs full simulation varied system size scaling system scaled topology scaling number nodes added reason ip latency ms knobs full test ms average latency physical network lower algorithm zone overloading rtt weighted routing automatically retrieves entry closest replica 
ms represents average ip network level latency retrieving node closest replica 
metric bare bones knobs full path length neighbors peers ip latency ms ms path latency ms ms latency stretch table performance results xh number nodes effect link delay distribution latency edges topology scaling backbone topology 
effectively grows density edges topology 
grows total path latency grows slowly case path length grows slowly hops nodes hops latency additional hops lower average latency added hops low latency links edges network 
extrapolating scaling trend making pessimistic assumption total latency grows increase path length asn potentially scale size system reaching system size close nodes seeing path latency increase factor underlying network latency 
better understand effect link delay distributions results repeated knobs full test different delay distributions transit stub topologies 
topologies transit stub topology hierarchical link delay assignment ms intra transit links ms transit stub links ms intra stub links 
topology knobs full test 
transit stub topology hierarchical link delay assignment ms intra transit links ms links ms intra stub links 
table effect design parameters performance metrics hops dimensions dn due reduced path fig length realities fig due reduced path length number peer nodes due reduced path table replicated data store repli due backup replicated data store zone length reduced partitioned data neighbors partitioned data hop latency store store number hash functions fig rtt weighted routing due reduced hop table metric latency uniform partitioning reduced reduced reduced variance fig feature variance variance design parameters path length neighbor state total path latency hop latency size data store routing fault tolerance data store availability transit stub topology delay link set random value ms ms 
xh topology backbone topology scaled factor implies density nodes resultant topology times lower 
topologies measure latency stretch ratio latency ip latency different system sizes 
results shown 
see delay distribution affects absolute value latency stretch cases latency stretch grows slowly system size 
case see latency stretch system sizes nodes 
fastest growth case random delay distributions 
case grow system size new links added edges network need low latency links hierarchical delay distributions 
see latency stretch topology slightly lower topology xh 
due higher density nodes case higher densities allow latency heuristics yield higher gains 

related categorize related related algorithms literature relevant data location related systems involve data location component 
related algorithms distance vector dv link state ls algorithms ip routing require router level knowledge exact link structure case ls distance hops dv topology entire network 
routing algorithm dv ls require widespread dissemination local topology information 
suited ip networks topology changes infrequent networks frequent topology changes dv ls result frequent propagation routing updates 
wanted design scale large numbers potentially nodes chose routing schemes dv ls 
goal designing cans truly distributed routing algorithm stress small set nodes avoids single point failure 
avoided traditional hierarchical routing algorithms 
closest spirit routing scheme plaxton algorithm 
plaxton algorithm node assigned unique bit label 
bit label divided levels level having bits 
node label say xyz bit digits routing table entries form xx entries form entries form notation denote digit denote digit 
routing state packet forwarded destination label node incrementally resolving destination label left right node forwards packet neighbor label matches left right destination label digit label 
system nodes plaxton algorithm routes log hops requires routing table size log 
routing comparison routes dn hops dimensions routing table size dr independent mentioned earlier setting log allows algorithm match plaxton scaling properties 
plaxton algorithm addresses issues 
natural candidate cans early seriously considered 
studying details algorithm decided suited application 
primarily plaxton algorithm originally proposed web caching environments typically administratively configured fairly stable hosts maximal scales order thousands 
plaxton algorithm suited environments peer peer contexts address quite different 
require self configuring system capable dealing large set hosts millions potentially quite 
targeted application web caching plaxton algorithm provide solution nodes independently discover neighbors decentralized manner 
fact algorithm requires global knowledge topology achieve consistent mapping data objects plaxton nodes holding objects 
additionally node arrival departure affects logarithmic number nodes large systems high arrival departure rates appears high side nodes constantly reacting changes system membership 
algorithms built concept geographic routing similar routing algorithm build notion forwarding messages coordinate space 
key difference space refers true physical space neighbor discovery problem node neighbors lie radio range 
algorithms suited targeted applications routing location services ad hoc networks 
applying algorithms problem require construct maintain neighbor relationships correctly mimic geographic space appears non trivial example gpsr performs certain planarity checks hard achieve physical radio medium 
additionally geographic routing algorithms obviously extensible multidimensional spaces 
related systems domain name system dns system sense provides functionality hash table stores key value pairs form domain name ip address 
potentially provide distributed dns service systems quite different 
terms functionality cans general dns 
current design dns closely ties naming scheme manner name resolved ip address name resolution truly independent naming scheme 
terms design systems different 
oceanstore oceanstore project berkeley building utility infrastructure designed span globe provide continuous access persistent information :10.1.1.115.4299
servers self organize large scale storage system 
data oceanstore reside server oceanstore system data location algorithm needed route requests data object appro priate server 
oceanstore uses plaxton algorithm basis data location scheme 
plaxton algorithm described 
publius publius web publishing system highly resistant censorship provides publishers high degree anonymity :10.1.1.125.3017
system consists publishers post publius content web servers host random looking content browse publius content web 
current publius design assumes existence static system wide list available servers 
self organizing aspects design potentially incorporated publius design allowing scale large numbers servers 
view complementary publius project 
peer peer file sharing systems section described basic operation widely deployed peer peer file sharing systems napster gnutella 
describe systems space novel indexing schemes 
systems address additional related problems security anonymity keyword searching focus solutions indexing problem 
freenet file sharing application additionally protects anonymity authors readers :10.1.1.10.4919
freenet nodes hold types information keys analogous web urls addresses freenet nodes know similar keys optionally data corresponding keys 
node receives request key know exact location forwards request freenet node know keys closer requested key 
results successful failed searches backtrack path request travelled 
node fails locate desired content returns failure message back upstream node try alternate downstream node best choice 
way request operates steepest ascent hillclimbing search backtracking 
authors hypothesize quality routing improve time reasons 
nodes come specialize locating sets similar keys node listed routing tables particular key tend receive requests similar keys 
backtracking better informed routing tables nodes carry keys 
second nodes similarly specialized storing clusters files having similar keys 
forwarding request successfully result node gaining copy requested file requests similar keys node acquire files similar keys 
scalability algorithm fully studied 
ongoing ucb looks developing peer peer file sharing application location algorithm similar plaxton algorithm developed independently plaxton 
novel aspect randomization path selection improved robustness 
description evaluation file sharing applications 
key difference algorithm file sharing systems normal operating conditions content exists located node clear home point content node knows home reach 
systems private communication adam costello quite possible node system behaving correctly content may content horizon particular node different nodes different inconsistent views network :10.1.1.10.4919
important distinguishing factor depends course nature application goals 

discussion far addresses key problems design content addressable networks scalable routing indexing 
simulation results validate scalability design nodes route latency twice ip path latency 
certain additional problems remain addressed realizing comprehensive system 
important open problem designing secure resistant denial service attacks 
particularly hard problem web malicious node act malicious client malicious server router 
number ongoing projects research industry looking problem building large scale distributed systems secure resistant denial service attacks 
additional related problems topics include extension algorithms handle mutable content design search techniques keyword searching built indexing mechanism 
interest exploring scalability design difficulty conducting truly large scale experiments hundreds thousands nodes led initially evaluate design simulation 
simulation understanding scaling properties design collaboration embarking implementation project build file sharing application uses distributed indexing 

acknowledgments authors steve mccanne jitendra padhye brad karp vern paxson randy katz petros maniatis anonymous reviewers useful comments 

bolosky douceur ely theimer 
feasibility serverless distributed file system deployed existing set desktop pcs 
proceedings sigmetrics santa clara ca june 
clarke sandberg wiley hong 
freenet distributed anonymous information storage retrieval system 
icsi workshop design issues anonymity unobservability july 
czerwinski zhao hodes joseph katz 
architecture secure service discovery service 
proceedings fifth acm conf 
mobile computing networking mobicom seattle wa 
acm 
francis 
yoid extending internet multicast architecture 
unpublished available www aciri org yoid docs index html apr 
freenet 
freenet sourceforge net 
gnutella 
gnutella wego com 

gnutella rescue fast napster 
link article gnutella wego com sept 

www com 
karp kung 
greedy perimeter stateless routing 
proceedings acm conf 
mobile computing networking mobicom boston ma 
acm 
kubiatowicz bindel chen czerwinski eaton geels gummadi rhea weatherspoon weimer wells zhao :10.1.1.115.4299
oceanstore architecture global scale persistent storage 
proceedings asplos cambridge massachusetts nov 
kumar alaettinoglu estrin 
scout scalable object tracking unattended techniques 
proceedings ieee international conference network protocols osaka japan nov 
li jannotti couto karger morris 
scalable location service geographic ad hoc routing 
proceedings acm conf 
mobile computing networking mobicom boston ma 
acm 
marc waldman cranor :10.1.1.125.3017
publius robust tamper evident censorship resistant web publishing system 
proceedings th usenix security symposium pages august 
napster 
www napster com 
plaxton richa 
accessing nearby copies replicated objects distributed environment 
proceedings ninth annual acm symposium parallel algorithms architectures spaa june 
postel 
internet protocol specification 
arpanet working group requests comment ddn network information center sri international menlo park ca sept 
rfc 
ratnasamy francis handley karp padhye shenker 
grass roots content distribution raid meets web 
jan 
unpublished document available www aciri org sylvia 
ratnasamy francis handley karp shenker :10.1.1.140.3129
scalable content addressable network 
icsi technical report jan 
rekhter li 
border gateway protocol bgp 
arpanet working group requests comment ddn network information center mar 
rfc 
stoica morris karger kaashoek balakrishnan 
chord scalable peer peer lookup service internet applications 
proceedings acm sigcomm san diego ca aug 
welsh hill von behren woo 
querying large collections music similarity 
technical report university california berkeley ca nov 
zegura calvert bhattacharjee 
model internetwork 
proceedings ieee infocom san francisco ca may 
com 
file sharing portal www com 
example depth search replacement node appendix maintenance background zone reassignment immediate takeover algorithm described section may result single node assigned multiple zones 
ideally retain assignment nodes zones prevents coordinate space highly fragmented 
achieve node zone assignment simple algorithm aims maintaining face node failures dissection coordinate space created solely nodes joining system 
general step think existing zone leaf binary partition tree internal vertices tree represent zones longer exist split previous time 
children tree vertex zones split 
course don maintain partition tree data structure useful conceptually 
abuse notation name leaf vertex zone corresponding leaf vertex node responsible zone 
partition tree binary partition tree property subtree rooted internal vertex leaves siblings 
suppose node wants hand leaf sibling leaf leaf call hand easy simply coalesce leaves making parent vertex leaf assign node leaf 
zones merge single zone assigned node sibling leaf perform depth search subtree partition tree rooted sibling leaves 
call leaves combine making parent leaf 
zones merged single zone assigned node node takes zone illustrates reassignment process 
say node fails immediate takeover algorithm node takes node place 
background reassignment process node discovers sibling nodes 
say takes combined zones takes zone 
partition tree data structure helps explain required transformations global nature unsuitable actual implementation 
effect required transformations purely local operations 
individual node coordinate routing table captures adjacency structure current zones leaves deletion tree 
adjacency structure sufficient emulation operations partition tree 
node performs equivalent described depthfirst search partition follows number dimensions avg hops max hops table background zone reassignment dk dimension node zone halved easily detected merely searching highest ordered dimension shortest coordinate span 
coordinate routing table node selects neighbor node dimension dk belongs zone forms half zone split dimension dk 
volume zone equals volume pair sibling leaf nodes zones combined 
zone smaller forwards depth search request node repeats steps 
process repeats pair sibling nodes 
simulation measure number steps depth search request travel sibling leaf nodes 
table lists number hops away node search order find node hand extra zone 
uniform partitioning space due uniform partitioning feature section pair sibling nodes typically available close requesting node dissection tree balanced 
