streaming multi threaded model caspi university california berkeley cs berkeley edu score stream computations organized reconfigurable execution multi threaded model relies streams expose thread parallelism enable efficient scheduling low overhead communication scalability 
date score scalable reconfigurable logic implementation ideas score processor architectures 
demonstrate streams exposed clean architectural feature supports forward compatibility larger parallel hardware 

overview past decades predominant architectural abstraction programmable computation systems instruction set architecture isa 
isa defines instruction set semantics executing 
key benefit isa model semantics decouple software hardware development 
piece software written compiled guaranteed run isa compatible device 
guarantee allows hardware evolve time growing larger faster process generation 
existing software base preserved performance automatically improves hardware generation 
isa abstraction instrumental protecting investment software allowing ride moore law better performance 
examples ibm intel architectures survived commercially decades 
years existence seen clock speeds increase nearly transistor counts grow nearly 
increasingly isa uniprocessors running performance improvement due primarily increasing costs extracting exploiting instruction level parallelism ilp 
today state comparing intel mhz transistors introduced june ghz transistors introduced august 
appear third workshop media stream processors conjunction micro austin texas dec 
andr dehon california institute technology andre acm org john wawrzynek university california berkeley cs berkeley edu art processors expend area power hardware features enhance ilp tolerate latency including caches branch prediction units instruction reorder buffers 
new architectures emerged exploit forms parallelism including explicit instruction parallelism vliw data level parallelism vector mmx thread level parallelism chip multiprocessors multi threaded processors 
architectures typically sacrifice desirable properties single threaded isa model ease programming compiler analyzability obscured inter thread communication patterns forward compatibility larger hardware vliw 
score scalable multi threaded computation model associated architectural abstraction maintain best properties isa model 
model highly parallel efficient supports forward compatibility executable programs larger hardware 
heart score premise streams inter thread communication channels fifo discipline fundamental abstraction exposed programming model architectural model 
rely streams streams expose inter thread communication dependencies data flow allowing efficient scheduling streams admit data batching data blocking amortize cost context swaps inter thread communication particular message cost communication negligible setting reusing stream reuse fully automated part thread scheduling streams exposed clean architectural feature resembling memory interface admits hardware acceleration protection forward compatibility 
remainder organized follows 
section related cites prior data flow streaming architecture inspired score 
section score model discusses basic primitives properties score model 
section score reconfigurable architectures presents binding score reconfigurable logic including hardware model programming model scheduler simulation results media processing application 
section discusses ideas binding score processor architectures 

related score draws heavily prior numerous parallel models architectures 
section highlights works 
refer reader complete treatment 
hoare communicating sequential processes csp strong models parallel computation 
score shares csp general notion computation collection communicating independent processes local control 
score model stylized making amenable virtualization strong hardware software interface 
score emphasizes design preserves deterministic behavior regardless target hardware size scheduling 
data flow processing dennis arvind introduced parallel models architectures flexible scheduling 
culler threaded machine tam active messages am important attempt capture essence parallel programming model software hardware boundary communication lightweight 
score persistent streaming data flow significant overcoming overheads tam expensive implement 
mosaic machines early multicomputers pioneering tight integration communication processor isa 
dynamic messages required tens cycles send message 
streaming score enables pipelined communication reducing time required send receive message little machine cycle proper hardware support 
wide range shared memory machines including dash alewife flash showed memory abstraction useful communication 
observed relying solely shared memory cache coherence communication sufficient broadly deliver high performance 
shared memory programming remains difficult single threaded programming owing primarily fact determinism synchronization entirely burden programmer 
streaming data flow heavily digital signal processing dsp 
lee synchronous dataflow sdf heavy influence score 
lee sdf restricted static rates static flow graphs suitable systems modeled completely compile time 
buck boolean controlled dataflow supports dynamic programming constructs compile time focus 
score expands models handle dynamic characteristics dynamic flow rates graph evolution variable hardware resource availability 
score heterogeneous systems streaming data flow tie arbitrary processors conventional special purpose reconfigurable 
examples include mit berkeley 
systems provide interesting performance point mix processing elements 
score hybrid reconfigurable hardware section builds models defining common programming model processing elements microprocessor reconfigurable case virtualizing number type elements 

score model score program collection threads communicate streams 
thread usual meaning process local state global state shared threads shared memory 
mechanism inter thread communication synchronization stream inter thread communication channel fifo order blocking reads non blocking writes conceptually unbounded capacity 
respect score closely resembles kahn process networks specifically dataflow process networks 
processor basic hardware unit executes threads time time multiplexed manner threads processors 
threads interact streams possible execute order allowed stream data flow deterministic results 
data flow graph induced stream connections exposes inter thread dependencies reflect actual inter thread parallelism 
dependencies construct schedules efficient particular hardware target minimize idle cycles pre computed 
contrast threading models tend obscure inter thread dependencies pointer aliasing shared memory threads restrict scheduling explicit synchronization semaphores barriers 
restricted schedules may able take full advantage larger hardware undermine forward compatibility 
threads time sliced batch process large sequence inputs 
batching useful amortizing run time costs context swapping setting stream connections buffers 
batching mechanism similar spirit traditional data blocking better cache behavior case blocking factor determined scheduling tailored available hardware available buffer sizes late run time 
late binding blocking factor contributes forward compatibility performance scaling larger hardware 
contrast data blocking non streaming models fixed compile time improve performance larger hardware 

score reconfigurable architectures target score model scalable reconfigurable systems 
reconfigurable blocking read fifo order streams guarantee determinism schedule 
non determinism added model allowing non blocking stream reads case thread execution sensitive scheduling communication timing 
cmb cp cache icache dcache mmu hypothetical single chip score system logic field programmable gate arrays fpgas promising performance platform combines massive fine grained spatial parallelism programmability 
programmability particular dynamic reconfiguration aids performance improve hardware utilization giving idle logic meaningful task allows specializing computation data compile time 
reconfigurable systems fpgas available commercially time isa abstraction decouple hardware software 
resource types capacities lut count exposed programmer forcing bind algorithmic decisions reconfiguration times particular devices possibility forward compatibility larger hardware 
score hides size hardware programmer executable notion hardware paging 
programs hardware sliced fixed size compute pages analogy virtual memory pages automatically swapped available hardware run time operating system support 
paged computation run number compute pages re compilation see performance improvement pages 
inter page communication uses streaming discipline natural abstraction synchronous wire communication independent wire timing page stalls absence stream input allows data batching 
batching critical amortizing typically high cost reconfiguration 
respect score model compute page serves role processor page configuration serves role thread 
transform quantize rle encode temporal spatial swap tran rle enc tran swap swap rle swap enc hypothetical executions jpeg encode large small device microarchitecture 
basic score hardware model shown 
compute page cp fixed size slice reconfigurable fabric typically logic registers stream network interface 
fabric kind size number channels streams architecturally defined identical pages presently target page boolean input lookup tables luts 
number pages vary architecturally compatible devices 
page network interface includes stream flow control data presence back pressure stall page buffer words stream reducing stalls draining flight communication 
configurable memory block cmb memory block stream network interface sequential address generator 
cmb memory capacity architecturally defined presently target cmb mbit 
cmb holds stream buffers user data page configurations os controlled memory management 
conventional microprocessor page scheduling os support 
common streaming protocol linking components allows page thread completely oblivious streams connected page buffer cmb microprocessor 
actual network transport important ideally high bandwidth 
presently assume scalable interconnect modeled berkeley circuit switched fat tree structured pipelined high frequency operation 
execution 
illustrates possible executions jpeg encode application instances microarchitecture described 
application described data flow graph stream connected page threads page configurations 
spatial execution may target hardware large simultaneously execute page threads 
case thread loaded compute page stream mapped chip interconnect 
primary inputs outputs may mapped buffers chip may periodically flushed microprocessor 
hand time multiplexed execution may select input boolean input signed input signed output signed state goto goto state goto state goto tdf code select operator selectively passes input output select input target hardware small 
case threads clustered groups loaded turn available compute pages 
stream outputs non loaded thread routed cmb buffering similarly inputs non loaded thread routed cmb buffer 
cluster pages may run exhausts input buffers fills output buffers point cluster pages loaded 
actual page loading order determined automatic scheduler microprocessor described 
compilation 
designed language tdf task description format associated compiler specifying page threads inter page data flow 
thread tdf streaming finite state machine essentially extended fsm streaming describes cycle cycle behavior compute page 
tdf execution semantics specify entry state issues blocking reads streams specified state input signature 
input available streams fires executing state specific action described syntax 
firing action straight line code looping accomplished re entering state re evaluating input signature 
shows example tdf thread implement select operation 
tdf includes syntax composing persistent data flow graphs stream connected page threads supports hierarchy sub graphs 
tdf thread compiled forms 
thread compiled compute page logic implementation evaluated device simulator 
alternatively thread compiled microprocessor posix thread stream api 
api allows stream communication threads microprocessor threads compute pages 
allows threads microprocessor spawn connect new threads 
tdf threads explicitly written match hardware constraints area timing compute page 
fit compute page execute state action device cycle 
general device details exposed programmer tie program device undermine forward compatibility 
presently working automatic synthesis partitioning transform arbitrarily large complex groups stream connected page size 
primary challenge page partitioning inter page communication delay stream latency known compile time 
communication delay depends device size page placement page scheduling 
communication delay may arbitrarily large threads simultaneously executing hardware 
basic partitioning approach follows 
attempt hoist code pipelines shrink size delay cyclic state machine cores 
resulting larger page decomposed clustering states pages minimize frequency inter page state transitions 
state transition frequencies profiled execution pure microprocessor threads 
area timing estimated lut area time model data path components 
page scheduling 
developed tested page schedulers 
scheduler privileged microprocessor task responsible time multiplexing collection page threads available physical hardware 
time sliced model time slice scheduler chooses set page threads execute hardware manages stream buffers communicate suspended pages 
scheduler responsible reconfiguring hardware cps interconnect including data transfer primary memory 
general policy scheduler execute communicating pages reduce communication latency especially inter page feedback reduce number buffered streams reduce reconfiguration frequency 
initial scheduler completely dynamic making decisions time slice intervals 
advantage dynamic scheduler versus static dynamic information stream buffer fullness page stalls construct efficient reactive schedules 
list scheduling policy select execution pages buffered input available intent pages run longest requiring reconfiguration 
practice performance suffered high scheduling overhead occasional stalling page loading order violated page graph dependence order 
reduce run time overhead improve analysis subsequently designed static schedulers compute single repeated page loading order page graph 
topological scheduler chooses loading order need resize thread match page artifact reconfigurable hardware target 
may unnecessary optional hardware targets 
example partitioning compute pages somewhat analogous restructuring microprocessor code better locality virtual memory pages 
score allows dynamic spawning page threads page graphs 
static schedule generated separately graph 
actual implementation compute optimized graph specific schedules line profile information collected previous unoptimized execution 
makespan cycles jpeg encode run time quasi static scheduling hardware size cps exhaustive topological min cut run times jpeg encode quasi static scheduling makespan cycles jpeg encode run time hardware size cps dynamic static quasi static run times jpeg encode different schedulers exhaustive static quasi static satisfy page precedence constraints topologically sorting page graph 
min cut scheduler chooses loading order minimize number stream buffers required time slice min cutting page graph 
exhaustive scheduler chooses loading order minimize stalled cycles loaded pages exhaustively searching space orderings profiled rates estimate input availability 
analysis discussed shows heuristic schedulers topological min cut perform surprisingly yielding application run times exhaustive search 
interestingly best performance demonstrated dynamic static schedulers class hybrid quasi static schedulers 
quasi static schedulers extend static schedulers dynamic ability detect compute pages blocked stream access due empty full stream buffers immediately advance time slice 
policies apply topological min cut exhaustive astute reader notice small disparity figures makespan cycles jpeg decode run time quasi static scheduling hardware size cps exhaustive topological min cut run times jpeg decode quasi static scheduling makespan cycles jpeg decode run time hardware size cps dynamic static quasi static run times jpeg decode different schedulers exhaustive static quasi static analysis 
written tested media processing applications score including wavelet encode decode jpeg encode decode mpeg encode 
figures show performance results running jpeg encode decode having page threads simulated hardware varying page counts different schedulers 
device model scales number number pages 
device simulation model page placement routing 
models page capacity fixed network delay pages 
refer reader details simulation scheduling application results 
figures demonstrate interesting properties score quasi static schedulers 
results demonstrate application performance scales predictably hardware sizes 
hardware means shorter run times 
second results demonstrate performance exhaustive quasi static scheduler 
disparity due different accounting overheads negligible smallest device sizes 
time multiplexing highly efficient applications sense application run substantially fewer compute pages page threads negligible performance loss analogous efficiency virtual memory allows programs run smaller memory negligible performance loss 
application implemented limited parallelism requires threads idle time time multiplexed schedule avoid loading threads idle hardware 
third results show simple heuristic schedulers stream data flow topology topological min cut perform exhaustive search directly minimize idle cycles exhaustive 
figures compare application run times dynamic static quasi static scheduling approaches 
find static scheduling generally outperforms dynamic scheduling owing part better analysis part lower run time overhead computing schedules line 
find quasi static scheduling outperforms pure static dynamic approaches typically factor 
performance improvement owes entirely addition single dynamic feature ability advance static schedule compute pages blocked 
quasi static schedulers presently attain hardware utilization non idle page cycles 
limit due rate mismatches scheduled threads leading input starvation buffer overflows 
includes scheduling run rate matched threads rate mismatched threads different time slices 
compiler transformations may intentionally change thread rates serial arithmetic 

score processor architectures score architecture developed easily extended additional processor types 
defined processor types cp cmb microprocessor 
extended architecture specialized function units alus fft units dsps additional microprocessors 
processor stream network interface ability stall processor 
network fabric completely abstracted stream network interface 
streams added microprocessor clean architectural feature resembling memory interface 
instruction set extended load store operations stream read register index stream write register index index enumerates space streams memory address register denotes value register 
stream reads able stall processor memory wait states stream writes resume immediately memory stores write buffer 
features handled stream access units resembling memory load store units order issue 
units transparently route stream accesses network interface memory buffers 
stream state live buffered memory dma ctrl external memory sid pid location array control hypothetical microprocessor stream support controlling reconfigurable array buffer locations stored stream table analogous vm page table cached tlb stream look aside buffer 
enables single cycle access common streams handles uncommon streams trapping updated 
access protection added process id stream table 
stalled stream accesses time allowing scheduler swap blocked threads 
illustrates hardware components microprocessor stream support 
note necessary features emulated conventional microprocessor memory mapping processor interface plus external controller route stream accesses network buffer memory 
scheduling policies reconfigurable hardware easily adapted multi processor multi threaded processor architectures provided operations fast memory operations 
chip multi processor scheduled score architecture microprocessors 
multi threaded processor scheduled similarly treating hardware thread context separate score processor 
communication threads loaded hardware live registers communication threads swapped memory buffered memory 
case scheduler prefers schedule communicating threads 

summary score multi threaded compute model built ground communication mind support software scalability longevity high capacity hardware 
model uses streams fifo channels blocking read method inter thread communication synchronization 
exposing inter thread dependencies allows highly flexible efficient thread scheduling tailored available hardware separately thread compilation 
exposing streams architectural abstraction allows compiled programs automatically benefit additional compute communication resources devices 
demonstrated score reconfigurable hardware decouples logic design target device size enables binary compatibility performance scaling larger devices 
framework developed schedulers demonstrated heuristics perform nearly exhaustive search scheduling 
proposed architectural support score streams microprocessors 
note score extends naturally large heterogeneous systems provided component compatible stream interface 

research part berkeley reconfigurable architectures software systems brass effort supported defense advanced research projects agency darpa contract dabt california micro program st microelectronics 

additional authors randy huang joseph yeh 
arthur jan rabaey 
ultra low power domain specific multimedia processors 
proceedings ieee vlsi signal processing workshop october 
anant agarwal ricardo david kirk johnson david kranz john kubiatowicz beng hong lim kenneth mackenzie donald yeung 
mit alewife machine architecture performance 
proceedings nd international symposium computer architecture 
arvind 
fundamental issues multiprocessing 
proceedings conference parallel processing science engineering pages west germany june 
bhattacharyya praveen murthy edward lee 
software synthesis dataflow graphs chapter synchronous dataflow 
kluwer academic publishers 
vincent michael bove jr john 
reconfigurable data flow system video processing 
ieee transactions circuits systems video technology april 
wad www media mit edu people wad html 
joseph buck 
scheduling dynamic dataflow graphs bounded memory token flow model 
phd thesis university california berkeley 
erl technical report 
caspi michael chu randy huang nicholas weaver joseph yeh john wawrzynek andr dehon 
stream computations organized reconfigurable execution score tutorial 
www cs berkeley edu projects brass documents score tutorial html short version appears fpl lncs 
david culler seth goldstein klaus schauser thorsten von eicken 
tam compiler controlled threaded machine 
journal parallel distributed computing june 
william dally message driven processor multicomputer processing node efficient mechanisms 
ieee micro pages april 
jack dennis 
data flow supercomputers 
computer november 
thorsten von eicken active messages mechanism integrated communication computation 
proceedings th annual symposium computer architecture queensland australia may 
marco stephen william dally nicholas carter gurevich andrew chang lee 
machine multicomputer 
proceedings th annual international symposium microarchitecture ann arbor mi 
hoare 
communicating sequential processes 
international series computer science 
prentice hall 
intel microprocessor quick guide 
www intel com kits htm 
kahn 
semantics simple language parallel programming 
info 
proc pages august 
jeffrey david mark heinrich john richard simoni kourosh gharachorloo john chapin david joel baxter mark horowitz anoop gupta mendel rosenblum john hennessy 
stanford flash multiprocessor 
proceedings st international symposium computer architecture pages april 
lee parks 
dataflow process networks 
proc 
ieee may 
sing lee william dally stephen nicholas carter andrew chang 
efficient protected message interface mit machine 
ieee computer november 
daniel lenoski james laudon kourosh gharachorloo wolf dietrich weber anoop gupta john hennessy 
overview status stanford dash multiprocessor 
suzuki editor proceedings international symposium shared memory multiprocessing pages 
information processing society japan april 
caspi randy huang joseph yeh michael chu andr dehon john wawrzynek 
analysis quasi static scheduling techniques virtualized reconfigurable machine 
proceedings tenth international symposium field programmable gate arrays fpga february 
charles seitz 
mosaic experimental fine grain multicomputer 

editors tendencies computer science control applied mathematics conference occasion th anniversary inria pages 
verlag december 
william tsu kip atul joshi randy huang norman walker tony tung varghese george john wawrzynek andr dehon 
high speed hierarchical synchronous reconfigurable array 
proceedings international symposium field programmable gate arrays pages february 
john 
architecture media processing implementation 
thesis proposal mit media laboratory january 
wad www media mit edu people wad tp 
