dependable computing virtual laboratories alonso kahn dept computer science swiss federal institute technology eth eth zentrum ch zurich switzerland kahng inf ethz ch mcgill centre bioinformatics mcgill university montreal canada cs mcgill ca scientific disciplines shifting vitro silico research physical processes natural phenomena examined computer silico observed vitro 
virtual laboratories computations involved complex long lived 
currently users required manually handle aspects computations including dependability 
surprisingly major bottleneck significant source inefficiencies 
address issue developed bioopera extensible process support management system virtual laboratories 
briefly discuss architecture functionality bioopera show efficiently manage long lived computations 

virtual laboratories increasingly pervasive cost storing observations lower cost making 
environments typically associated massive amounts data initial experiences shown data processing critical data storage 
better illustrate problem consider example 
goals bioopera project able build software system capable automatically predict secondary structure protein primary sequence 
idea construct tower information depicted 
tower information represents sequence derived data sets higher information content predecessors 
step consists locating genes raw dna translating coding regions amino acid sequences 
amino acid sequences aligned compared known proteins various statistics calculated 
intermediate results turn build phylogenetic evolutionary tree 
trees multiple sequence alignment provide historical perspective evolutionary events occurred accepted genomes organisms vast periods time 
evolutionary history provides important clues prediction secondary structure 
turn secondary structural units provide avenues prediction structure shape protein knowledge dimensional configuration dna rna sequences pairwise alignments phylogenetic trees secondary structure prediction probabilistic ancestral sequences multiple sequence alignments 
tower information computational biology may lead accurate assignments function protein 
existing virtual laboratories storing manipulating keeping track computations tower information done manually ad hoc pieces code 
data processing logic typically written conventional programming languages fortran basic algorithms collections operating system scripts mainly perl scripts glue different components 
approach leads logic extremely difficult modify primitive methods driving monitoring computations 
considering studies tower information built times clear better software support needed organized way store manage information entire procedure critical success virtual experiment 
concentrate provide basic functionality 
core efforts bioopera process support system virtual laboratories bioinformatics 
bioopera opera workflow middleware tool evolved programming runtime environment cluster computing capability define execute monitor manage broad range large scale complex scientific computations 
organized follows 
section presents typical virtual experiment 
section briefly describes bioopera 
section shows virtual experiment represented bioopera notation 
section discusses experimental results 
section concludes 

motivation problem statement focus sequence alignment 
typical data set swiss prot vers 
sp starting point amino acid sequences 
aligning entry sp entries dataset self comparison vs requires approximately delta individual pairwise alignments certain optimizations reduce 
indication implies past years computational biochemistry research group eth zurich updated public vs comparison swiss prot vers 

current updates typically involve new sequences require months computation cluster dual processor nodes 
computations datasets software workstations involved need maintained nodes fail algorithms fail data entries need discarded jobs restarted results coalesced 
today done manually due lack appropriate tools 
experiments tower information orders magnitude complex vs 
clearly adequate tools needed efforts viable 
basic aspect tools able run computations months time minimal user intervention 
requires automatically transparently handle issues efficient scheduling jobs load balancing tracking progress results computation recovery system errors machine crashes access intermediate results computed automatic accounting statistics concerning computing time systematic method storing necessary meta data 
step providing functionality involves finding appropriate representation computation 
chosen notion process similar workflow management systems final implementation different workflow tools entirely adequate virtual laboratories 
process annotated directed graph nodes represent tasks arcs represent control data flow tasks 
notion process allows capture sequences invocations computer programs distributed heterogeneous environment corresponding data exchanges programs 
process encoded way allow efficient storage database 
database information persistent allowing automatically manage computation increase dependability 

bioopera virtual laboratory bioinformatics 
process design computation bioopera represented process 
bioopera uses language called opera canonical representation ocr describe processes 
ocr process consists set tasks set data objects 
tasks activities blocks subprocesses allowing modular design reuse tower information built process step subprocess 
data objects store input output data tasks pass information process 
example depicts simplified version vs process implemented bioopera 
activities rectangles basic execution steps 
correspond stand programs systems relied complete computational steps process 
activity external binding specifies program invoked shown 
information runtime system launch external applications 
control flow inside process control connectors formally annotated arcs act source task target task act activation condition bold connecting lines shows activation condition control connector queue file tasks user input queue generation 
activation condition activator defines execution order tasks capable restricting execution target task state data objects allowing conditional branching parallel execution 
data flow tasks processes represented help connectors shown thin connecting lines 
simplest form process consists activities control data flow dependencies 
task input data structure storing input parameters output data structure storing return values represented cylinders 
input parameters task bound data items global data area process whiteboard output structures tasks 
task starts bindings analyzed necessary values passed task 
successful execution task mapping phase transfers data output structure global data area tasks 
larger processes structured blocks subprocesses 
block named group tasks 
scope block name process defined 
blocks modular process design implement specialized parallel processing language constructs alignment block 
particular blocks implement unconventional branching flow control executing algorithm section grid resulting activity applied parallel section grid 
subprocesses processes components processes 
subprocess seen process inside process 
blocks allow hierarchical structuring complex processes 
late binding subprocess instantiated started allows dynamic modification running process offering ability change subprocesses 
addition primitives ocr supports exception handling event handling spheres atomicity 
combination features allows process designer define sophisticated failure handlers part process undo actions alternative executions various forms exception handling 

architecture basic functionality bioopera seen high level distributed operating system managing resources computer cluster 
bioopera server 
bioopera client 
architecture opera runtime component development environment 
development environment allows users specify bioopera processes eventually library processes activities provided users run predefined processes having define 
development environment encompasses elements process creation library management configuration management 
configuration management allows users specify hardware software execution process ip addresses type os cpu specifications 
information runtime component job placement decisions load balancing deal failed nodes 
library management element allows definition runtime aspects activities program invoked input output runs pass arguments 
library management element designed allow users computer knowledge prepare pre packaged activities users computer knowledge 
idea eventually form library activities distributed bioopera 
process creation element allow users create processes simply selecting activities library management element combining individual activities part blocks specifying flow control data 
process creation graphical compiler charge translating graph proper ocr code 
information stored corresponding data spaces bioopera template space contains process templates processes defined user instance space contains processes currently executing configuration space contains information related system configuration data space contains historical information processes executed external datasets created 
execution process instance persistent terms data state execution 
allows bioopera resume execution processes failures occur losing completed 
fact process state persistently stored database offers significant advantages monitoring querying purposes 
instance space process execution controlled navigator 
sense ocr acts persistent scripting language interpreted navigator 
navigator decides step execute information passed dispatcher turn schedules task associates processing node cluster particular application 
choice assignment unique node determined scheduling load balancing policy 
dispatcher contacts program execution client pec small software component node responsible running application programs behalf bioopera server 
written java platform independent allowing bioopera heterogeneous nodes 
client performs additional activities monitoring load node reporting failures bioopera server 
applications complete task results returned pec activity queue server 
recovery module reads data updates database keep track events occurred 
navigator control looks activities execute 
interaction external applications takes place specific interfaces wrappers 
computational purposes currently working exclusively software tool darwin system 

monitoring scheduling load sharing monitoring important aspect long lived computations allows keep track state computation influence outcome necessary 
information pertaining process execution environment stored persistently bioopera 
task start times task finish times task failures system stores information regarding load node node availability node failure node capacity relevant information regarding state computing environment 
information allows creation awareness model turn allows bioopera react changes computing environment provides complete view computation 
information share load different nodes schedule computation machine usage availability resume execution computation smoothly failures occur avoid inconsistencies output data failures 

planning dealing outages bioopera designed tool help managing long lived computations 
implies addition functionality discussed needs provide support planning ahead 
key feature running virtual experiments may months encounter different situations addition failures need upgrade software hardware replacement nodes changes storage devices forth 
regard bioopera advantages 
computation outlined process possible determine happen node taken line 
gives system administrators powerful tool perform upgrades changes system computation proceeds minimizing impact outages 
dynamic scheduling load balancing mechanisms bioopera capable working system shrinks grows size dynamically 
possible late binding approach replace activities initially intended run node alternative activities running different node different os 
experiments bioopera successfully coped failures entire cluster complete network outages hardware upgrades nodes cluster processors user driven interruptions computation users utilize cluster 
cases computation successfully resumed minimal human intervention 
fact necessary information organized stored database opens opportunity create sophisticated automatic tools system computation administration go available today 
instance processes run system administrator ask system processes affected node set nodes taken line 
bioopera configuration information process structure determine alternatives exist re schedule processes accordingly 

vs bioopera order better understand experiments carried illustrate processes bioopera section vs process 
recall vs self comparison entries certain dataset 
result computation set sequence pairs similarity scores reach user defined threshold information characteristics pairs 
call sequence pair match 
exact details activity computed data structures scope 
suffice say darwin system bioinformatics application 
software offers dynamic programming local alignment algorithm uses scoring matrices affine gap penalty 
initial tasks process tasks executed darwin programs 
task needs executed bioopera contacts darwin appropriate machine instructs execute particular algorithm particular set inputs 
tasks vs process depicted follows 
task user input queries user input parameters vs process 
parameters consist dataset called queue file location results stored 
dataset swissprot queue file contains list entry indexes dataset delta sp 
purpose queue file twofold 
indexing provided queue file allows bioopera discard ill behaving sequences smoothly re start computation failures occur dataset entries listed queue file take part comparison 
second succeeding tasks control degree parallelism execution 
queue file optional input parameter absence presence determines possible successor tasks executed task finished 
task queue generation produces queue file consisting complete list entries sp queue file provided user 
task preprocessing responsible preparing data parallel execution creating partition fp png entries queue file 
input task parallel task 
block alignment parallel task internal activity corresponds subprocess 
started subprocesses run subprocess computes alignment entry sp fixed pam alignment performs pairwise alignment fast inaccurate algorithm set matches second match refined task pam param refinement recalculating corresponding alignment computationally expensive informative algorithm 
call resulting set matches subprocesses running parallel task finish datasets assembled fr rng forms result parallel task 
care taken rule different subprocesses 

vs process implemented bioopera task merge entry merges set files output alignment block master file 
contents file sorted entry number original database 
task merge pam distance sorts matches various files pam distance estimations 

experimental results performed different experiments 
aimed finding optimal granularity level parallelization 
consisted versions vs process smaller database entries different granularity levels 
experiments computation vs sp 
run cluster shared users performed cluster exclusively managed bioopera 
objectives measure effectiveness bioopera managing large scale computations test system long term stability ability cope changes hardware configuration various failures 
failures observed injected part everyday operation systems 

hardware environment experiments performed combination pcs unix workstations linked ordinary ethernet mbit network 
main cluster comprised processor pcs mhz mb main memory running red hat linux sun sparcstation cpus mhz mb main memory running solaris 
refer cluster cluster 
cluster set sun ultra mhz mb main memory running solaris 
refer cluster ik sun cluster 
ik linux cluster group processor pcs mhz mb main memory running red hat linux 

measurements evaluate results experiments criteria 
activity measured time took complete looking long active cpu cpu time cpu 
denote activity executed process omega fa denote entire process 
cpu time process cpu time took execute activities 
seconds cpu wall 
effects granularity level 
cpu omega gamma omega cpu wall time measures absolute time takes process complete difference starting finishing times 
wall time depends heavily amount parallelism achieved 
addition measurement provides indicator effectiveness bioopera basic tool virtual laboratories 
relation cpu time respect number activities process omega gives rough approximation time needed activity provides intuition average recovery time 
cpu cpu omega gamma omega measured bioopera ability recover failures time manual interventions required keep computation going 

determining optimal granularity level determine optimal granularity levels vs computation analyzed performance cpu wall times varying numbers task execution units 
dataset purpose consisted entries sp 
experiments run ik sun cluster users jobs cluster 
number experiments varied parallelization vs alls parallelized 
shows results 
results indicate key points 
surprisingly scenario gives best cpu time worst wall times due lack parallelism 
chart shows left right cpu time increases wall time decreases increases 
extreme number cpu time doubled 
due overhead incurred darwin initialization stages repeated times 
increased wall time reflects extra overhead due bioopera scheduling executing increased number activities 
results indicate optimal choice granularity 
somewhat counter intuitive tempted conclude optimal coincide number available cpus case 
explain split chart segments 
explanation downward curve wall time straightforward added parallelism achieved 
cpu time increases slightly difference overhead marginal 
explanation straightforward 
granularity exceedingly fine number alignments exceedingly small 
overhead bioopera darwin significantly increases cpu wall times 
explanation somewhat difficult 
expect optimal granularity level coincide number processors observed 
clearly overhead starting stopping darwin dominant factor discrepancy 
explanation observed behavior lies known scheduling phenomenon 
may differ size slightly cpu time differ tasks require previous tasks complete final merging task vs process executed longest completed 
wall time significantly affected 
granularity coarse phenomenon quite large 
granularity level implies performs approximately total number individual pairwise alignments gamma delta extrapolate results full vs sp granularity level 
dataset larger containing entries initialization cost larger 
set level granularity multiple number processors available 
lies equivalent segment vs entries close optimal 

vs shared cluster run vs experiment tried test ability bioopera cope everyday changes take place shared cluster 
nodes clusters machines dedicated certain tasks 
particular slower ik sun cluster responsible refinement stages 
stated clusters shared storage device part experiment 
due problems device switch storage device accessible cluster implying ik sun machines disabled computation 
activities run lowest priority 
computation lasted th december th january 
note final days computation represented 
performance figures shown shared cluster column table 
point view virtual laboratory relevant re time days dec jan cluster failure unavailable shortage server maintenance 
lifecycle vs run 
shared cluster non shared cluster max 
cpus cpu omega wall omega cpu table 
results experiments sults entire process required days wall time processors run days processors second run see details section 
previous manual efforts required significantly time order months computed significantly mere updates earlier version swissprot 
proves benefits system bioopera 
regarding ability bioopera automate procedure history computation summarized 
bioopera jobs run nice mode giving priority users 
contains number event indicators refer particular phases execution 
flat line dark area indicates processors available point time ranges 
variation due network failures system maintenance software upgrades 
rugged line light area indicates number processors computing bioopera jobs 
indicated actual computing time small fraction total wall time 
due heavy utilization cluster users events problems execution event process ran storage space 
events indicate bioopera server caused running process terminate 
restart bioopera automatically resumed computation stopped server shutdown 
believe results accurately reflect happens typical shared computational environment 
stress major goal experiment test ability bioopera sustain computation long period time spite problems require little manual attention 
bioopera quite successful manual intervention necessary deal system activity failures 

vs non shared cluster experiment proved bioopera run longlived computations coping heterogeneity continuous changes shared clusters 
second experiment wanted test stability bioopera system running computation nonshared cluster 
second experiment run cluster th may th july 
shown operating system configuration changed day second processor added node 
results show bioopera quite stable effectively available resources 
run events interest 
planned network outages required suspend execution process 
third event upgrade cluster extra processor available machine 
clearly shows number processors doubled bioopera immediately took advantage available cpu power 

experimental results demonstrate bioopera able run month long computations minimal user intervention 
significant step providing software infrastructure needed virtual laboratories 
bioopera additional functionality important virtual laboratories 
instance lineage tracking done automatically dependencies persistently recorded 
possible system may jul time days change 
lifecycle vs second run 
recompute processes data algorithms change 
ability suspend resume process check intermediate results correct intermediate data 
results feedback obtained feel bioopera potential tool virtual laboratories opens interesting challenging research directions 
alonso hagen 
flexible exception handling opera process support system 
th international conference distributed computing systems icdcs amsterdam netherlands 
alonso hagen 
black box eventbased inter process communication process support systems 
th international conference distributed computing systems icdcs austin texas usa 
alonso hagen 
schek 
distributed processing stand systems applications 
proceedings rd international conference large data bases athens greece august pages 
available www inf ethz ch department publications html 
bairoch 
swiss prot protein sequence data bank supplement trembl 
nucleic acids research 
baker georgakopoulos schuster cassandra cichocki 
providing customized process situation awareness collaboration management infrastructure 
coopis pages 
barclay gray 
microsoft spatial data warehouse 
proceedings acm sigmod international conferenceon management data may dallas texas 
bonner 
database benchmark high throughput workflow management 
proceedingsof th int 
conferenceon extending database technology edbt avignon france 
buyya 
high performance cluster computing volume 
prentice hall 
zhou 
large gene dataset 
bioinformatics 

comparison complete protein sets worm yeast divergence 
science 
mining digital skies 
economist 
gonnet cohen benner 
exhaustive matching entire protein sequence database 
science 
gonnet 
darwin version interpreted computer language biosciences 
bioinformatics 
hagen 
generic kernel reliable process support 
phd thesis dissertation eth nr 

ioannidis livny gupta 
zoo desktop experiment management environment 
proceedings nd international conference bases september mumbai bombay india pages 
vossen weske 
workflow management dna sequencing 
proceedings st international conference cooperative information systems coopis brussels belgium 
rost sander 
rd generation prediction secondary structure 
webster editor predicting secondary structure 
press 
smith waterman 
identification common molecular subsequences 
mol 
biol 
szalay gray brunner 
designing mining multi terabyte astronomy archives sloan digital sky survey 
proceedings acm sigmod international conference management data may dallas texas volume 
wang zhang shasha 
pattern matching pattern discovery scientific program document databases 
proceedings acm sigmod international conference management data may san jose california volume 
ioannidis 
scientific databases state art directions 
th international conference large data bases september santiago chile pages 
