optimizing direct threaded code selective inlining ian fabio riccardi inria rocquencourt le chesnay cedex france email ian inria fr fabio riccardi inria fr achieving performance language interpreters difficult sacrificing simplicity portability 
due complexity dynamic translation just time compilation bytecodes native code mechanism employed universally highperformance interpreters 
demonstrate simple techniques possible create highly portable dynamic translators attain performance optimized certain numerical computations 
translators techniques offer respectable performance sacrificing simplicity portability slower pure bytecode interpreters 
keywords bytecode interpretation threaded code inlining dynamic translation just time compilation 
languages smalltalk gol caml ler java arn lin offer significant engineering advantages conventional languages higher levels abstraction dynamic execution environments incremental debugging code modification compact representation executable code cases platform independence 
success java due largely promise platform independence compactness code 
compactness bytecodes important advantages network computing code downloaded demand execution arbitrary platform operating system keeping bandwidth requirements minimum 
disadvantage bytecode interpreters typically offer lower performance compiled code consume significantly resources 
modern virtual machines perform degree dynamic translation improve program performance deu 
techniques significantly increase complexity virtual machine tailored permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigplan montreal canada fl acm hardware architecture way conventional compiler back 
increases development costs requiring specific knowledge target architecture time writing specific code reduces reliability introducing code debug support 
languages caml example traditional compilers produce high performance native code defeats advantages come platform independence compactness 
propose novel dynamic technique applied certain class virtual machines 
technique delivers high performance optimized easy retrofit existing virtual machines requires effort port new architecture 
continues follows 
section gives brief survey bytecode interpretation mechanisms providing context remainder 
novel dynamic technique explained section 
section presents results applying technique interpreters small risc interpreter inspired production virtual machine objective caml 
sections contrast technique related concluding remarks 
background interpreter performance depend heavily representation chosen executable code mechanism dispatch opcodes 
section describes common techniques 
pure bytecode interpreters inner loop pure bytecode interpreter simple fetch bytecode dispatch implementation switch statement 
shows typical pure bytecode interpreter loop array bytecodes calculate running example 
interpreter infinite loop containing switch statement dispatch successive bytecodes 
case body switch implements bytecode passes control bytecode breaking switch pass control back start infinite loop 
assuming compiler optimizes jump chains breaks implicit jump body back overheads associated approach follows compiled code unsigned char code 
bytecode implementations unsigned char code unsigned char bytecode switch bytecode 
case break case break case break 
pure bytecode interpreter 
ffl increment ffl fetch bytecode memory ffl redundant range check argument switch ffl fetch address destination case label table ffl jump address bytecode ffl jump back start body fetch bytecode 
eleven machine instructions executed powerpc perform push bytecode 
instructions dedicated dispatch mechanism including memory jumps expensive instructions modern architectures 
pure interpreters easy write understand highly portable slow 
case bytecodes perform simple operations push example majority execution time wasted performing dispatch 
threaded code interpreters threaded code bel popularized forth programming language moo 
various kinds threaded code efficient generally direct threading ert 
bytecodes simply integers dispatch involves fetching opcode bytecode looking address associated implementation explicit table implicitly switch transferring control address 
direct threaded code improves performance eliminating table lookup executable code represented sequence opcode implementation addresses dispatch involves fetching opcode implementation address jumping directly address 
additional optimization eliminates centralized dispatch 
returning central dispatch loop compiled code void code 
opcode implementations dispatch instruction define goto void code start execution dispatch opcode opcode implementations 

direct threaded code 
direct threaded opcode implementation ends code required dispatch opcode 
direct threaded version example shown 
execution begins fetching address opcode implementation compiled code jumping address 
opcode performs dispatches opcode implied compiled code 
name control flow threads way opcodes order implied compiled code returning central dispatch loop 
overheads associated threaded code lower associated pure bytecode interpreter 
opcode executed additional overhead dispatching opcode ffl increment ffl fetch opcode address memory ffl jump address 
machine instructions required implement push powerpc 
associated opcode dispatch memory jump 
saved instructions pure bytecode approach 
importantly saved memory jump instruction expensive dynamic translation threaded code benefits direct threaded code easily obtained language translating bytecodes threaded code examples written class labels provided gnu expression void addr label assigns address type void statement attached label addr 
control transferred location goto dereferences address goto addr 
note gcc class labels required implement techniques effects achieved couple macros containing lines asm 
translation table void opcodes 
opcodes opcodes opcodes 
dynamic translator unsigned char void opcodes dynamic translation bytecodes threaded code 
direct threaded code execution 
illustrated 
translation loop reads bytecode looks address implementation table writes address direct threaded code 
complication bytecode sets extension bytes 
provide additional information encoded bytecode branch offsets indices literal tables environments 
extension bytes normally placed inline translated threaded code translator immediately threaded opcode corresponding bytecode 
translation threaded code permits kinds optimization 
example smalltalk provides bytecodes pushing implicit integer constant stack 
translator loop easily translate single opcode followed constant pushed inline operand 
treatment applied kinds literal quantity relative branch offsets 
possibility partial decoding translator loop examines overloaded bytecode translation time translates threaded opcodes 
translator loop aware kind operand copying 
relative offset example require modification scaling translation loop 
possible approximate evaluation approach realistic system 
squeak ing portable pure bytecode implementation smalltalk performs numerical computations approximately speed optimized mir portable smalltalk virtual machine similar squeak vm dynamically translates bytecodes direct threaded code execution mir 
performs numerical computations speed optimized implementations carefully hand tuned performance essential difference dynamic translation direct threaded code 
optimizing common bytecode sequences bytecodes typically represent operations 
threaded opcodes represent encoded pointers 
translating bytecodes threaded code gives opportunity arbitrary transformations executable code 
transformation detect common sequences bytecodes translate single threaded macro opcode macro opcode performs entire sequence original bytecodes 
example bytecodes push literal push variable add store variable translated single add literal variable opcode threaded code 
optimizations effective avoid overhead multiple dispatches implied original bytecodes elided macro opcode 
single macro opcode translated sequence original bytecodes avoids gamma opcode dispatches execution time 
technique particularly important cases bytecodes simple example implementation bytecode short single register register machine instruction 
cost threading significantly larger cost useful execution 
instructions executed dispatch opcode overhead threading useful instructions executed instructions dispatching threaded opcodes 
overhead drops operation optimized single macro opcode useful instructions instructions threading 
dispatching opcode implementations non contiguous addresses undermines code locality causing unnecessary processor pipeline stalls inefficient utilization instruction cache tlbs 
combining common sequences bytecodes single macro opcode considerably reduces effects 
compiler chance inter bytecode optimizations implementation single macro opcode impossible implementations individual bytecodes 
determining appropriate set common bytecode sequences difficult 
virtual machine instrumented record execution traces simple offline analysis reveal candidates 
corresponding pattern matching macro opcode implementations incorporated manually vm 
example analysis applied earlier version objective caml bytecode set resulting new set bytecodes includes macro style operations 
problems static optimization significant problem static approach number possible permutations shortest common sequences consecutive bytecodes prohibitive 
example smalltalk provides bytecodes push popular integer constants minus bytecodes load store temporary receiver variables 
manually optimizing possible permutations incrementing decrementing variable small constant require translator implement explicit special cases 
clearly unreasonable 
problem acute different applications running virtual machine favor different sequences bytecodes 
statically chosing single optimal set common sequences impossible 
technique focuses making choice runtime allows set common sequences nearly optimal particular application run 
instruction counting accurate way estimate savings instructions avoid expensive execute 
push add goto equivalent macro opcode push push add 
int nfibs int return nfibs nfibs benchmark function dynamically rewriting opcode sequences generate implementations common bytecode sequences dynamically 
implementations available new macro opcodes single macro opcode replaces threaded opcodes generated original common bytecode sequence 
dynamically generated macro opcodes executed precisely manner interpreter predefined opcodes original execution mechanism direct threading requires modification 
transformation performed bytecode threaded code translation separate pass threaded code 
shows equivalent dynamically generated threaded opcode sequence bytecodes needed evaluate example 
translator concatenates compiled implementations intrinsic threaded opcodes corresponding bytecode sequence optimized 
involves relocating code safe perform concatenation threaded opcodes implementation position independent 
general cases consider concatenating opcode implementations ffl threaded opcode inlined implementation contains call function destination address relative processor pc 
destination addresses invalidated copied form new macro opcode implementation 
ffl threaded opcode changes flow control threaded code appear translated sequence 
different paths sequence consume different numbers inline arguments 
ffl threaded opcode branch destination appear macro opcode incorporating middle macro opcode delete branch destination final threaded code 
simplified rule consider basic blocks inlining basic block begins jump destination ends jump nfibs push saved call move arg cont pop restore return return cont move arg 
sub call nfibs arg call nfibs swap nfibs arg 
arg 
sub call nfibs arg call nfibs add nfibs arg 
add nfibs arg nfibs arg 
pop restore return return nfibs arg nfibs arg start move call nfibs call nfibs print print result halt threaded code nfibs benchmark inlining 
destination change control flow 
inlining purposes opcodes contain function call considered single opcode basic blocks 
restriction relaxed target architecture compiler build vm uses absolute addresses function call destinations 
technique designed works best fine grained opcodes implementations short typically machine instructions cost opcode dispatch dominates 
section presents example context 
simple example illustrate technique applying simple risc virtual machine executing nfibs function shown 
example interpreter implements register execution model 
handful registers performing arithmetic stack saving return addresses contents clobbered registers subroutine calls 
direct threaded code kinds inline operand instruction pointer relative offsets branch destinations absolute addresses function call destinations 
interpreter translates bytecodes threaded code passes 
pass bytecodes expanding threaded opcodes inlining exactly explained section 
shows symbolic listing nfibs function implemented example interpreter opcode set initial translation threaded code 
bytecode operands placed inline threaded code translation 
example offset opcode call destinations placed directly opcode stream immediately associated opcode 
represented pseudo operand fig doubly recursive function interesting property result number function calls required calculate result 
nfibs push move thr 
cont pop return thr 
cont move sub call thr 
nfibs swap sub call thr 
nfibs add add pop return thr 
threaded code nfibs benchmark inlining 
implementations new macro opcodes shown right 
ure appear separate line code prefixed 
initial translation threaded code second pass performs inlining threaded code basic blocks identified dynamically generate new threaded macro opcodes corresponding original sequences threaded opcodes replaced single macro opcodes 
rewriting threaded code performed situ optimizing opcode sequence result shorter sequence optimized code possibility overwriting opcode considered inlining 
shows code nfibs function inlining taken place 
function reduced threaded macro opcodes shown replacing basic block original code 
implementation new macro opcode concatenation implementations opcodes replaces 
new implementations written separate area memory called macro cache 
implementations required nfibs shown curly braces 
ends copy implementation pseudo opcode thr threading operation dispatch opcode 
inline arguments copied verbatim cont jump offset adjusted appropriately translator 
inline arguments macro opcode implementations points marked 
help identification basic blocks divide threaded opcodes classes follows inline opcode implementation inlined macro opcode restriction arithmetic opcodes belong class protect implementation contains function call inlined print opcode belongs class final opcode changes flow control defines basic block call opcode relative opcode changes flow control defines basic block conditional branch 
difference final relative way opcode inline operand treated 
case operand absolute copied directly final translated code 
second case operand relative current threaded program counter adjusted appropriately final translated code 
shows translator code initializes threaded opcode table representative implementations threaded opcodes classes threaded opcode represented 
define push sp long define pop sp define get long ip read inline operand define goto ip dispatch opcode define protect expanded define inline expanded define final expanded ends basic block define relative expanded ends basic block offset follows define op name nargs flags case name info op nargs nargs info op flags flags info op addr start name info op name info op size int name int start name break start name opcode body define name name initialize execute see macro op int op op op switch op op add inline add op inline op relative register long offset get ip offset op call final register long dest get push ip ip void dest call op final ip void pop op protect printf ld default fprintf stderr panic op undefined op abort opcode table initialization 
translator inlining loop shown 
complex appear 
code pointer translated threaded code rewritten situ 
indices code pointing opcode copied inlined location copied respectively times 
loop considers opcode inlining inlining loop entered current opcode opcode inlined 
case opcode copied inline arguments directly 
pointer unused location macro cache 
inlining loop writes address represents threaded opcode macro implementation generated copies compiled implementations opcodes macro cache 
inlined threaded opcodes copied inline arguments encountered copied directly 
inlining loop continues copies implementation opcode explicitly ends basic block final relative opcode non int code int info nargs long code relocations info flags inline info flags protect destination inline create new macro opcode void ep code long ep new macro opcode info flags protect info addr ep info size ep info size skip opcode info flags relative offset code code original int info nargs code code info flags final info flags relative destination break basic block code copy threading operation info thr addr ep info thr size ep info thr size ep inline copy opcode inline arguments code long info addr skip opcode info flags relative code code copy literal arguments int info nargs code code dynamic translator loop 
protected branch destination implicitly current basic block 
translator appends implementation pseudo opcode thr threading operation 
location updated ready inlining operation 
translator loop uses array flags destination identify branch destinations threaded code 
array easily constructed translator pass bytecodes expanded non inlined threaded code 
loop creates arrays relocations recalculate relative branch offsets 
inlining loop concatenates opcode implementations function shown 
function similar bcopy synchronizes processor instruction data caches ensure new macro opcode implementation executable 
contains line platform dependent code interpreter 
branch destination identification relative offset recalculation shown 
seen full source code example interpreter see appendix 
static inline void void source void dest size bcopy source dest size size defined ppc asm sync elif defined sparc asm flush elif defined op elif defined 
endif dest size function containing single line platform dependent code 
saving space translating multiple copies opcode sequences waste space 
keep cache dynamically generated macro opcodes keyed hash value computed incoming unoptimized opcodes translation 
case cache hit reuse existing macro opcode translated code immediately reclaim macro cache space occupied newly translated version 
case cache newly generated macro opcode translated code hash table updated include new opcode 
ensures macro opcode corresponding sequence unoptimized opcodes 
experimental results particularly interested performance benefits dynamic inlining applied interpreters finegrain instruction sets 
curious see technique perform applied interpreter having coarse grained bytecode set 
took measurements contexts risc interpreter widely suited interpreter objective caml language 
fine grained opcodes risc interpreter opcode set similar section 
configured compile time bytecodes direct threaded code direct threaded code dynamically generated macro opcodes 
performance benchmarks measured interpreter function call intensive fibonacci benchmark earlier nfibs memory intensive function call free prime number generator sieve 
table shows number seconds required execute benchmarks architectures mhz pentium sparcstation mhz powerpc ev 
figures shown simple bytecode interpreter interpreter performing translation direct threaded code direct threaded code dynamic inlining common opcode sequences benchmark written compiled optimization options interpreter 
final column shows performance inlined threaded code compared optimized nfibs machine bytecode threaded inlined inlined pentium sparc powerpc sieve machine bytecode threaded inlined inlined pentium sparc powerpc table nfibs sieve benchmark results architectures tested 
final column shows speed inlined threaded code relative optimized nfibs 
pentium 
sparc 
powerpc 
sieve 
pentium 
sparc 
powerpc 
bytecode direct threaded inlined benchmark performance relative optimized nfibs spends time performing arithmetic registers 
memory stack operations performed function call return 
interpreter allocates vm registers physical machine registers possible 
opcodes perform arithmetic typically compiled single machine instruction sparc powerpc 
architectures show marked improvement performance common sequences inlined single macro opcodes due significantly reduced ratio opcode dispatch real 
effect pronounced pentium machine registers vm registers kept memory 
arithmetic opcode compiles pentium instructions ratio dispatch overhead real lower risc architectures 
observe marked improvement approximately factor successive versions interpreter nfibs 
sieve shows pronounced improvement spends majority time performing memory operations 
contribution opcode dispatch execution time smaller nfibs 
interesting observe performance version interpreter relative optimized shows nfibs gains approximately speed optimized moving representation threaded code 
gain moving threaded inlined threaded code dependent architecture approximately pentium sparc 
gains sieve smaller dependent architecture approximately step architectures 
objective caml applied technique objective caml bytecode interpreter order obtain realistic measurements performance overheads favorable environment 
objective caml chosen design implementation interpreter core clean simple understanding making required modifications significant challenge 
furthermore fully fledged system includes bytecode compiler benchmark suite large applications 
easier collect meaningful statistics 
interpreter equipped mechanism bulk translate bytecodes threaded code startup platforms support 
needed extend initial translation phase perform analysis opcode sequences generate macro opcode implementations rewrite threaded code situ dynamically generated macro opcodes 
implementing technique caml virtual machine took day 
small details required careful attention 
presence switch opcode 
performs multi way branch followed threaded code inline table mapping values branch offsets 
added special case translator loop handle opcode 
second existence handful opcodes consume inline arguments literal relative offset 
introduced new opcode class relative differs relative copying additional inline literal argument offset translator loop 
translation algorithm identical respects section 
ran standard objective caml benchmark suite modified vm see table 
vm instrumented gather statistics relating execution speed uses gcc class labels portably 
ftp ftp inria fr inria projects xavier leroy benchmarks tar gz boyer 
fib 

kb 
qsort 
qsort 
sieve 



taku 
speed inlined non inlined pentium sparc powerpc objective caml benchmark results architectures tested 
vertical axis shows performance relative original non inlining interpreter 
asterisks indicate versions benchmarks compiled array bounds checking disabled 
boyer term processing function calls fib integer arithmetic function calls arg lexing parsing symbolic processing kb term processing function calls functionals qsort integer arrays loops sieve integer arithmetic list processing functionals puzzle solving arrays loops integer arithmetic function calls args curried taku integer arithmetic function calls args table objective caml benchmarks 
memory usage characteristics dynamically generated macro opcodes 
shows performance benchmarks inlining relative original performance inlining 
important note objective caml bytecode set optimized statically described section ler 
improvements due mainly elimination dispatch overhead common sequences particular application 
virtual machines bytecode sets statically optimized way benefit technique 
see majority benchmarks benefit significant performance advantage inlining 
cases inlined version runs faster original benchmarks running twice fast original non inlined version sparc 
clear improvements related processor architecture 
probably due differences cost threading operation 
sparc example avoiding pipeline stalls associated threading significant difference 
shows final size macro cache benchmark sparc plotted factor size original unoptimized code 
final macro cache cache size original code size original code size kbytes macro cache size diamonds optimized threaded code size crosses plotted factor original code size 
sizes vary slightly architecture depend size bytecode implementations 
shape case 
average ratios original bytecode size macro cache size show cost times size original code sparc 
ratio identical powerpc slightly smaller pentium 
observe ratio decreases gradually original code size increases 
expected larger bodies code tend reuse macro opcodes generating new ones 
tested translating version objective caml compiler bytes original code generated bytes macro opcode implementation sparc 
approximately times size original code shown rightmost point graph 
inlined threaded code smaller original code generated 
shows final optimized code size benchmark 
observe ratio independent size benchmark 
expected reduction size dependent average number opcodes common sequence density corresponding macro opcodes final code 
depend mainly characteristics language opcode set 
systems long lived object memory generate new executable code runtime 
realistic implementation systems recycle macro cache space possibly profiling optimize popular areas program 
example lc emulator macintosh systems performs dynamic translation powerpc code normally requires kb cache commonly translated code sequences stored tho 
similar fixed cache size effective smalltalk system mir 
translation speed important factor 
measure ran object caml bytecode compiler larger program benchmarks modified interpreter 
opcodes objective caml compiler translated seconds sparc rate opcodes second 
inlining interpreter executes compiler rate opcodes second 
translation approximately times slower execution 
related objective caml demonstrated benefits creating specialized macro opcodes perform sequence common opcodes 
objective caml led new bytecode set 
standard smalltalk bytecodes translated threaded code execution detection limited number pre determined common bytecode sequences performed translation specialized opcode substituted executable code 
contribution extension technique dynamically analyze generate implementations new macro opcodes runtime 
systems concatenation pre compiled sequences code runtime aus noe completely different context 
precompiled code sequences generic templates parameterized runtime particular constant values 
template approach commercial smalltalk virtual machines perform dynamic compilation native code mir 
technique complex requires significant effort implement templates new architecture 
interesting system portable dynamic code generation vcode eng architecture neutral runtime assembler 
generates code approaches performance architectures 
main disadvantage retrofitting existing virtual machine requires significant amount effort certainly single day required implement technique production virtual machine 
simple nfibs benchmark runs faster vcode compared risc inlined threaded code virtual machine 
superoperators pro technique specializing interpreter program execute 
possible specialized translation performed opcode break point passed program executes times number opcodes contains 
interpreter generated time compiled representation program 
compile time analysis program chooses candidates superoperators implemented new interpreter bytecodes 
superoperators similar macro opcodes 
advantage corresponding synthesized bytecodes benefit inter opcode optimizations simple concatenation implementations fails exploit 
superoperators require bytecodes corresponding precisely nodes build parse trees best choice bytecode set 
tricky superoperators incremental system smalltalk new executable code generated runtime 
investigation merging techniques superoperators dynamically generated macro opcodes worthwhile 
inspired need create interpreter fine grain risc opcode set general tied particular high level language amenable traditional compiler optimizations 
cost opcode dispatch significant context compared interpreters bytecodes carefully matched language semantics 
expected benefits technique related average semantic content bytecode 
expect languages tcl perl relatively highlevel opcodes benefit 
interpreters risc opcode set benefit cost dispatch significant compared cost executing body bytecode 
objective caml bytecode set positioned extremes containing simple complex opcodes 
vcode better performance technique instruction set matches closely underlying architecture 
exert fine control code generated performing degree reordering better instruction scheduling 
believe similar results achieved risc inlining threaded code interpreter portable manner 
performance macro opcodes limited inability compiler perform inter opcode optimizations possible static analysis performed new macro opcodes implemented manually interpreter 
believe limitations important fine grain opcode set corresponding closely traditional risc architecture 
opcodes implemented single machine instruction new opportunities inter opcode optimization available translator code generator 
technique portable simple implement orthogonal implementation virtual machine opcodes 
reducing overhead opcode dispatch helps bring performance fine grained bytecodes level language dependent opcode sets 
significant overheads associated technique check stack overflow pending signals objective caml discussion scope 
speed seconds space bytes pentium sparc powerpc sparc benchmark original inlined original inlined original inlined original inlined cache boyer fib kb qsort qsort sieve taku table raw results objective caml benchmarks 
authors xavier leroy john maloney eliot miranda dave ungar mario wolczko anonymous referees helpful comments draft 
arn arnold gosling java programming language addison wesley 
isbn aus joel auslander philipose craig chambers susan eggers brian bershad fast effective dynamic compilation proc 
pldi 
published sigplan notices 
bel james bell threaded code communications acm 
deu peter deutsch alan schiffman efficient implementation smalltalk system proc 
popl pages 
eng dawson engler vcode retargetable extensible fast dynamic code generation system proc 
pldi 
published sigplan notices 
www 
pdos lcs mit edu engler vcode html ert anton ertl portable forth engine proc 
pages 
www tuwien 
ac forth threaded code html gol adele goldberg david robson smalltalk language implementation addison wesley 
isbn ing dan ingalls ted john maloney scott wallace alan kay back story squeak usable smalltalk written proc 
oopsla 
published sigplan notices 
ler xavier leroy objective caml system release inria 
ler xavier leroy personal communication 
lin tim lindholm frank yellin java virtual machine specification addison wesley 
isbn mir eliot miranda portable smalltalk interpreter proc 
oopsla 
published sigplan notices 
mir eliot miranda portable fast direct threaded code posted comp compilers 
unige ch osg people compilers year msg html mir eliot miranda personal communication 
moo charles moore geoffrey leach forth language interactive computing technical report industries 
www com post zip noe francois noel luke hornof charles consel julia lawall automatic template run time specialization implementation experimental study proc 
iccl 
www irisa fr compose papers ps gz pro todd proebsting optimizing ansi interpreter superoperators proc 
popl pages 
tho tom thompson building better virtual cpu byte magazine august 
appendix table shows raw results objective caml benchmarks 
execution speed seconds shown architectures original interpreter inlined interpreter 
inlined interpreter speed shown absolute percentage relative original interpreter speed 
final columns show sizes original threaded code threaded code inlining final size macro cache sparc 
measured bytes 
sources risc interpreter modified objective caml interpreter generate benchmark data available www sor inria fr pldi 

