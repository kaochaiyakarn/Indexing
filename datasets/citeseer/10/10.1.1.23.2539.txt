chapter different spiking neurons 
gerstner center neuromimetic systems swiss federal institute technology epfl di ch lausanne epfl switzerland gerstner epfl ch standard neural network models neurons described terms mean firing rates viz analog signal 
real neurons communicate pulses called action potentials simply spikes 
chapter main di erences spike coding rate coding described 
integrate fire model studied simple model spiking neuron 
fast transients synchrony coincidence detection discussed examples spike coding relevant 
description spikes rates implications learning rules 
show relation spike time dependent learning rule standard hebbian learning 
learning rule temporal coding illustrated example coincidence detecting neuron barn owl auditory system 
keywords temporal coding coincidence detection spikes spiking neurons fire neurons auditory system hebbian learning spike time dependent plasticity 
spikes rates chapters book neuronal activity described rate 
simple rate model output neuron nonlinear transform input ii plausible neural networks biological modeling gain function 
standard rate model neuron 
output rate nonlinear transform total input ij synaptic weights ij nonlinear function sigmoidal shape 
ij ext input arises neurons external stimulation 
weight ij coupling strength neuron neuron called firing rate neuron 
rate 

temporal average spike count neurons cortex areas brain communicate short electrical pulses called action potentials simply spikes 
experiments spikes recorded electrode placed close soma axon neuron 
neurons cortex emit absence external stimulation action potentials 
called spontaneous activity 
spontaneous activity temporal sequence action potentials spike train irregular 
occasional spike events 
neuron visual cortex stimulated appropriate input retina neuron emits spikes 
simple concept rate spike count time window number spikes 
defines temporal average common definition rate 
gain function tells weak stimulation leads average spikes time window strong stimulation spikes see fig 

problem code temporal average intrinsically slow 
order perform sensible average di spiking neurons 
iii spikes inside averaging period 
typical rates cortical neurons time window order ms estimate information flow cortex involves processing steps step neurons average ms read code spikes receive processing slow fact slow account reaction times system 
humans recognize classify complex scenes ms thorpe 
simple reaction time experiment images classified groups show animal responses pressing releasing button 
movement finger takes ms leaves ms decision classify visual scene 
eeg signals show classification fact performed ms thorpe 
short classification time inconsistent idea neuron sequence processing steps needs average ms read code 
spike count temporal average useful tools experimental data analysis code neurons 

spatial average population activity completely di erent definition rate relies averaging group identical similar neurons 
distinguish definition definition rate refer population activity 
may called population rate 
idea 
visual cortex example organized columns neurons similar properties 
short time interval certain fraction neurons column active 
suppose measure fraction 
population rate dividing fraction idea illustrated shows spike trains neurons 
count number spikes neurons time interval divide number neurons get fraction active ones divide get rate 
result population activity total number spikes population size density connections fairly high code population rates natural concept 
consider column neurons visual cortex 
neuron area cortex iv plausible neural networks biological modeling dt temporal average spike count 
local pool activity population average 
definitions firing rate temporal average single neuron spatial average population neurons 
spike count gives number action potentials interval similarly number spikes neuron emits short interval su ciently short neuron emit spike 
neuron fires 
adapted gerstner :10.1.1.36.4685
di spiking neurons 

examples temporal coding schemes 
phase spikes respect periodic background signal carry information contained mean firing rate 
synchrony groups neurons signify special events 
adapted gerstner :10.1.1.36.4685
receives input neurons column consideration measures population activity column 
rate defined population average avoids disadvantage temporally averaged firing rate 
fact see chapter population rate respond rapidly changes input 
problem arrive useful mathematical description population activity 
rate model definition static equation 
capture dynamics population activity 
simple generalization dynamic model form da dt ij 
clear give correct description dynamics population 
gain function introduced defined static situation single neuron 
time constant obvious physiological meaning 
question correct description population activity 
vi plausible neural networks biological modeling 
pulse coding correlations synchrony far discussion focused rate coding 
theoretical coding schemes take temporal structure spike sequence generated neurons seriously 
examples shown fig 

sketch illustration phase coding 
signals auditory nerve occur preferentially certain phase respect sinusoidal sound stimulus 
auditory system uses phase information localize external sound source carr konishi 
similarly phase spikes hippocampus contains information contained firing rate keefe recce 
fig 
gives illustration coding synchrony 
fact neurons fire time signify encode aspect external stimulus 
idea experimental support coming recordings visual cortex eckhorn engel gray singer 
exact temporal correlations spikes millisecond time scale contain information contained firing rate abeles 
want exclude possibility temporal coding plays role take neuronal spike trains seriously study models level spikes 
simple spiking neuron model integrate fire model studied section 

integrate fire model neuron surrounded cell membrane 
ions may pass membrane specific channels may open closed 
simple picture electrical properties cell 
close inactive rest state neuron characterized resistance parallel capacitance factor rc defines membrane time constant neuron 
voltage measured respect neuronal resting potential 
neuron stimulated current voltage rises du dt 
absence current membrane potential approach resting potential 
hand strong current voltage may reach threshold value 
point action potential generated 
action di spiking neurons 
vii potential numerous ion channels membrane open close 
detailed model biochemical processes explain form voltage pulse 
integrate fire model action potential described explicitly 
simply record firing time defined threshold condition 
firing membrane potential immediately reset value reset limit lim reset assumed reset potential resting potential 
case may set reset 
current driving current applies artificially intracellular electrode 
real cortical network driving current synaptic input arises due arrival spikes neurons 
suppose spike presynaptic neuron fired time evokes current ij synapse connecting neuron neuron factor ij determines amplitude current pulse called synaptic cacy 
function describes time course synaptic current 
neuron receives input presynaptic neurons total input current neuron ij sums run neurons firing times put du dt ij 
eqs 
define dynamics network integrate fire neurons 
sketch fig 
corresponds simplified situation input current pulse simple square pulse 
realistically may take exponential pulse exp viii plausible neural networks biological modeling synapse axon output spike voltage response soma neuron neuron 
integrate fire model 
spike neuron arrives synapse neuron leads current input rc circuit dashed circle represents electrical properties soma rc circuit acts leaky integrator 
result current integration voltage response 
presynaptic pulses arrive short interval total voltage may surpass time threshold value 
case output pulse generated 
time circuit voltage reset zero 
time constant characterizes open time synaptic channel 
detailed model change form include rise time synaptic current 
reality amplitude current pulse depend momentary membrane voltage dependence neglected presentation model 

spike response model equations define dynamics integrate fire model 
linear di erential equation easily integrated 
linearity implies term sum right hand side integrated separately 
total voltage simply sum components 
integration di erent methods 
simple approach impulse response function imp called function equation 
order linear di erential equation time constant response membrane potential short current pulse form imp 
current pulse deposits exactly unit charge capacitance proportionality factor response arbitrary input current convolution di spiking neurons 
ix input response function ds imp ds may check di erentiation solution di erential equation 
impulse response function laplace transform directly solution associated initial value problem 
instructive recall alternative impulse response calculated integration unit step current input 
result step rc 
derivative step response yields impulse response function 
return specify input current 
loss generality set 
voltage response synaptic current pulse form ds 
square pulse amplitude voltage response roughly form sketched fig 

specifically find exponential pulse case vanishing synaptic time constant lim voltage response simple exponential pulse 
hand special case get 
plausible neural networks biological modeling ms 
synaptic input current pulse exp shown causes postsynaptic potential shown 
time constants ms ms sketch voltage response defined fig 
voltage response synaptic input called postsynaptic potential psp 
excitatory synapse called epsp inhibitory synapse 
include reset integration model 
reset time corresponds outgoing current pulse removes charge capacitor 
charge just firing pulse reset yields reset zero 
may integrate reset current 
result voltage contribution 
mentioned linear di erential equation 
total voltage sum individual terms 
ij 
firing times threshold condition eqs 
define spike response model srm gerstner gerstner 
term simple interpretation 
function describes reset voltage spike 
response neuron threshold crossing 
due reset neuron fires spikes immediately 
di spiking neurons 
xi input spikes output output input spikes spike reception spike emission epsp reset epsp voltage response spike 
input pulse causes excitatory postsynaptic potential epsp 
added 
threshold reached voltage reset 
reset corresponds adding negative kernel 
reset leads refractoriness 
may call refractory potential 
term describes response neuron incoming spikes 
biological terms excitatory inhibitory postsynaptic potential epsp 
measured experiments form chosen approximate closely possible experimental data 
graphical interpretation spike response approach fig 

purpose mathematical analysis convenient neglect sum preceding spikes neuron keep refractory potential spike 
write spike neuron simplification called short term memory approximation gerstner srm gerstner ij :10.1.1.36.3372
note approximation ects sum right hand side 
sum presynaptic pulses remains 
spike neuron occurs 
may put threshold condition move term xii plausible neural networks biological modeling ms 
neurons state asynchronous firing 
upper part shows population activity network neurons 
lower part spike trains randomly selected neurons marked sequences dots 
neurons fire time population average neurons yields activity apart fluctuations approximately constant 
taken gerstner :10.1.1.36.4685
left hand side 
result ij 
left hand side may interpreted dynamic threshold increased spike 
spike occurs total postsynaptic potential defined right hand side reaches dynamic threshold 
sections discuss results networks spiking neurons 
focus aspects di erence naive rate model obvious 
detailed treatment gerstner gerstner gerstner gerstner :10.1.1.36.3372:10.1.1.36.4685

rapid transients suppose large homogeneous network 
neurons identical described 
order spike trains completely regular add artificially noise 
network large interested spikes individual neuron population activity defined 
fig 
shows example network state 
spike trains di spiking neurons 
xiii selected neurons plotted bottom 
add spikes neurons population get population activity top 
population activity looks noisy fluctuates constant mean 
value activity depends course size input 
fig 
input constant 
may imagine presynaptic spikes drive neuron arrive constant rate 
suppose input rate increases abruptly time ms population activity respond change input 
answer fig 

population activity responds quasi instantaneously step input 
fact shown form transient reflects directly time course postsynaptic potential gerstner gerstner :10.1.1.36.3372:10.1.1.36.4685
write constant mean activity ms immediately switch ms gerstner constant simulation fig :10.1.1.36.4685
defined 
initial phase transient exponentially decaying pulse 
equation form describe instantaneous transition 
general useful description population rate 
shown approximation case population neurons subject white noise input large amplitude gerstner :10.1.1.36.3372
get correct description general case may integral equation motivate 
firing time neuron input arrives neurons calculate neuronal potential 
may calculate firing time threshold condition 
noisy case predict exact firing time probability fires time write probability density neuron fired spike potential fires time large population population activity gerstner gerstner gerstner van hemmen :10.1.1.36.4685
xiv plausible neural networks biological modeling ms 
rapid switching 
ms input current changed higher value 
population activity responds immediately 
solid line simulation network neurons 
dashed line theory 
taken gerstner :10.1.1.36.3372
analysis population activity correctly predicts rapid transients gerstner gerstner :10.1.1.36.3372:10.1.1.36.4685
fact dashed line fig 
theoretical prediction coincides nicely simulation result 
fast switching networks spiking neurons known ect knight knight treves tsodyks sejnowski 
important implications potential coding schemes 
shows signal transmission cortical networks fast limited membrane time constant knight knight treves 
firing rate sense population activity useful concept accordance reaction time experiments thorpe 
thorpe 
necessary condition fast switching population just switch state asynchronous firing 
second shown analysis population activity dynamics asynchronous state unstable su cient amount noise network gerstner van hemmen abbott van vreeswijk 
noise necessary requirement functioning network may explain spike trains cortical neurons look noisy 

perfect synchrony synchrony important neural coding study conditions synchrony network mutually coupled neurons 
di spiking neurons 
xv section essence argument extensively discussed gerstner 
study homogeneous network identical neurons mutually coupled strength ij constant 
words interaction scaled total input neuron order number neurons large 
interested synchrony suppose neurons fired simultaneously 
neurons fire 
neurons identical expect firing time synchronous 
calculate period synchronous pulse 
start 
neurons fired synchronously set 
result condition form postsynaptic potential equation 
graphical solution fig 

crossing point defines time synchronous pulse 
happens synchrony perfect 
assume neurons slightly late compared fig 

receive input right hand side 
left hand side di erent firing zero 
firing time 
linearisation respect yields 
neuron late pulled back synchronized pulse postsynaptic potential rising moment firing 
general condition stable synchrony gerstner 

coincidence detection simple rate model temporal order spikes matter 
presynaptic neurons fire hz total spike arrival rate postsynaptic neuron hz results certain output rate see eq 

spiking neuron model degree synchrony input matters cf 
xvi plausible neural networks biological modeling 
perfect synchrony 
neurons fired 
spike occurs summed postsynaptic potential reaches dynamic threshold 
stability perfect synchrony 
neuron tune 
firing time di erence period firing time di erence reduced threshold reached point rising 
adapted gerstner 
di spiking neurons 
xvii 
coincidence detection 
spike evokes postsynaptic potential epsp denoted 
sum terms yields potential 
spike trains di erent presynaptic neurons phase shifted respect 
total potential reach threshold 
output spikes 
spikes di erent presynaptic neurons arrive synchronously 
summed reach threshold cause generation output spike 
schematic neurons amplitude postsynaptic potential smaller input spikes su cient drive neuron threshold 
fig 

fig 
sketched situation input spikes di erent neurons arrive phase shifted respect 
threshold reached output spike occurs 
number input spikes arrives synchronously output spikes occur 
neuron acts coincidence detector viz 
sensitive inputs arrive short time window 
arguments schematic apply noise free neuron 
may wonder coincidence detection possible input noisy 
answer simulated integrate neuron receives stochastic input presynaptic neurons 
input spike evokes jump membrane potential fixed amount ij 
membrane potential decays exponentially time constant cf 
eq 

synapse spikes arrive time dependent rate cos frequency modulation modulation amplitude 
input spikes arrive constant rate rate periodically modulated zero shown absence threshold mean membrane potential approaches value ij fluctuations due stochastic spike arrival cause membrane potential fluctuations amplitude ij take account firing threshold 
neuron said sub threshold regime see abeles newsome konig miller 
xviii plausible neural networks biological modeling ms ms 
coincidence detection noisy spike input 
synapses spikes arrive stochastically rate hz 
membrane potential fluctuates mean value reaches threshold occasionally mean firing rate hz 
spikes marked vertical lines 
synapses spikes arrive stochastically rate cos mean hz periodic modulation period ms due modulation membrane potential exhibits periodic component reaches threshold frequently 
mean firing rate hz 
parameters integrate fire model ms spike evokes exponentially decaying postsynaptic potential 
amplitude synaptic coupling strength sub threshold regime spikes triggered fluctuations membrane potential 
regime neuron sensitive timing input spikes function coincidence detection 
sensitivity highest mean membrane potential standard deviations threshold kempter 
coincidence detection neurons auditory system discussed 

spike time dependent hebbian learning standard hebbian learning hebb synaptic weight ij presynaptic neuron postsynaptic neuron increased presynaptic postsynaptic neurons simultaneously active 
rate models activity presynaptic postsynaptic neurons defined rates respectively learning rule usually summarized dt ij ij ij ij corr ij seen terms expansion general adaptation rule dw ij dt ij uses information locally available synapses firing rates momentary value synaptic weight ij correlation term di spiking neurons 
xix post ij post pre 
time windows synaptic plasticity 
spikes presynaptic neuron postsynaptic neuron coincide learning window synaptic weight connection neurons changed 
simple coincidence detection window 
asymmetric learning window synapses presynaptic spike arrives slightly postsynaptic 
phase learning window 
presynaptic spike arriving slightly postsynaptic firing leads increase potentiation presynaptic spike arrives postsynaptic firing leads decrease synaptic weight depression 
corr ij sensitive joint activity pre postsynaptic neurons 
correlation term corr ij usually called hebbian learning narrow senses corr ij called anti hebbian learning 
spiking neurons notion simultaneously active leads term corr eq 
defined 
simple notion define time window simultaneity milliseconds change weights presynaptic postsynaptic spikes occur time span set time window cf 
fig 

need time window symmetric rectangular 
generally asymmetric fig 
phases shown fig 

generalized learning windows postulated theoretical grounds spiking neuron models gerstner gerstner rate models herz herz abbott blum gerstner abbott experiments levy stewart tsodyks zhang bi poo 
potential advantages generalized learning window 
asymmetric hebb rules fig 
natural implementation causal notion original statement hebb rules strengthen synapses presynaptic neurons potentially contributed firing postsynaptic neuron xx plausible neural networks biological modeling obviously neuron fired slightly postsynaptic spike influence firing spike 
asymmetric learning rules useful sequence learning herz herz gerstner levy abbott blum gerstner abbott 
example possible store spatio temporal spike patterns network spiking neurons gerstner 
asymmetric time window fig 
synaptic plasticity detect enhance store temporal structure time scale learning window 
auditory system example need resolve temporal structure sub millisecond range learning windows width milliseconds 
possible 
answer phase learning window fig 

combination potentiation inhibition leads ective competition di erent synapses synaptic growth connection ij possible expense decreasing weight synapses gerstner song 
synapses give correct timing enhanced decreased 
mechanism thought playing role tuning delay lines barn owl auditory system gerstner 
understand competitiveness phase learning rule mathematical point view useful study extension eq 
spike learning gerstner gerstner kempter kistler van hemmen dt ij dt dt presynaptic spike train arrives synapse ij learning window sketched fig 
plays role correlation term corr eq 

analogy eq 
coe cients learning window general depend current weight value may depend local variables membrane potential calcium concentration 
drop dependencies assume constant coe cients 
terms direct biological interpretation 
example term implies presynaptic spike neuron induces weight change synapse ij independent presence absence output spike postsynaptic neuron di spiking neurons 
xxi poisson input poisson output correlation term corr eq 
identified integral learning window eq 
kempter 
easy see certain combinations parameters learning rule leads intrinsic stabilization output firing rate 
example model ds eq 
leads poisson input equivalent rate model form dt ij 
constant input rates learning stops output rate approached stable fixed point 
arguments precise order show stabilization output rates occurs generically broad range parameters independent neuron model consideration kempter 

temporal coding auditory system prominent example temporal coding probably auditory system barn owl carr konishi konishi konishi sullivan konishi 
barn owl capable localizing external sound sources horizontal plane precision degrees azimuthal angle 
localization achieved measuring interaural time di erence viz phase di erence sound waves left right ear 
precision degrees angle corresponds temporal precision microseconds 
resolved auditory system 
basic idea sketched fig 

array coincidence detection neurons receives input ears 
spatial position neuron array mirror image position sound source external world je 
circuit properties barn owl auditory system carr konishi 
neurons nucleus barn owl auditory system play role coincidence detectors 
neurons nucleus sensitive interaural time di erence 
phase sound wave ear transmitted coincidence detector neurons phase locked spikes 
basic picture coincidence detection fig 
hundreds spike trains arrive ears just fig 

adapt parameters model fig 
barn owl auditory system check neuron act coincidence detector sensitive interaural plausible neural networks biological modeling left ear right ear 
je model 
activity waves ears meet array coincidence detectors circles 
time di erence stimulating tone gerstner gerstner kempter cf 
fig 
bottom right 
essential component model coincidence detection barn owl auditory system adaption learning rule controls timing transmission delays 
coincidence detecting neuron nucleus barn owl auditory system receives synapses left synapses right ear 
transmission delays di erent synapses side spikes arrive synchronously generated cochlea perfectly synchronous fashion 
case activity wave travels ear coincidence detectors looses information timing external stimulus 
order guarantee nearly perfect timing transmission delays spike time dependent learning rule discussed previous section 
fig 
shows delay lines arrive ears selected 
connections broad distribution delays milliseconds top left 
simulation khz tone small delay di erence range millisecond completely destroy temporal information 
postsynaptic neuron function coincidence detector top right 
learning synapses strengthened decreased middle 
learning synapses delay delay di ers full period ms 
output rate neuron number spikes time window ms depends clearly interaural time di erence itd stimulus left stimulus right ear bottom right 
neuron acts coincidence detector responds maximally itd spikes left right ear arrive average simultaneously 

auditory system specific examples temporal coding generally accepted principle 
related coding schemes di spiking neurons 
xxiii ms itd itd 
development tuning khz tone 
left column shows strength synaptic ij synapses 
synapses indexed delay corresponding transmission line plotted ij 
right show output firing rate function interaural time delay itd 
top 
learning synapses ear di erent delays chosen randomly gaussian distribution mean ms variance ms weights unit value 
output rate shows dependence itd right 
middle 
learning synapses strengthened decreased 
synapses increase delays similar di er multiples period ms stimulating tone 
bottom 
learning synapses ear survive 
output rate shows characteristic dependence itd seen experiments adult owls carr konishi 
neuron maximal response hz itd stimulus learning session model neuron 
taken gerstner 
plausible neural networks biological modeling principle hold areas brain 
final decision temporal codes relevant system come experiments 
want bias model approaches rate coding models level spike events integrate fire spike response model studied 
areas brain rate coding su cient rate coding interpreted temporal average population average 
rate coding sense population activity important concept allows fast temporal coding schemes 
models population activity capable describing fast signal transmission properties 
naive rate model form unable 
get appropriate model population activity keep track spike dynamics 
spikes important rate coding principle 
abbott blum 

functional significance longterm potentiation sequence learning prediction 
cerebral cortex 
abbott van vreeswijk 

asynchronous states network pulse coupled oscillators 
phys 
rev 
abeles 


cambridge university press cambridge 
abeles 

firing rates timed events 
domany schulten van hemmen editors models neural networks chapter pages 
springer new york 
taylor 

role temporal integration fluctuation detection highly irregular firing leaky integrator neuron model partial reset 
neural computation 
carr konishi 

circuit detection interaural time di erences brain stem barn owl 
neurosci 
thompson 

long term synaptic plasticity pairs individual ca pyramidal cells rat hippocampal slice cultures 
physiol 
eckhorn bauer jordan kruse munk 

coherent oscillations mechanism feature linking visual cortex 
biol 
cybern 
engel konig singer 

direct physiological evidence scene segmentation temporal coding 
proc 
natl 
acad 
sci 
usa 
gerstner 

associative memory network biological neurons 
lippmann moody touretzky editors advances neural information processing systems pages san mateo ca 
morgan kaufmann publishers 
gerstner 

time structure activity neural network models 
phys 
rev 
plausible neural networks biological modeling gerstner 

populations spiking neurons 
maass bishop editors pulsed neural networks chapter pages 
mit press 
gerstner 

spiking neurons 
maass bishop editors pulsed neural networks chapter pages 
mit press 
gerstner 

population dynamics spiking neurons fast transients asynchronous states locking 
neural computation appear 
gerstner 

population dynamics spiking neurons fast transients asynchronous states locking 
neural computation 
gerstner abbott 

learning navigational maps potentiation modulation hippocampal place cells 
journal comput 
neurosci 
gerstner kempter van hemmen 

hebbian learning pulse timing barn owl auditory system 
maass bishop editors pulsed neural networks chapter pages 
mit press 
gerstner kempter van hemmen wagner 

neuronal learning rule sub millisecond temporal coding 
nature 
gerstner ritz van hemmen 

spikes 
hebbian learning retrieval time resolved excitation patterns 
biol 
cybern 
gerstner van hemmen 

coherence incoherence globally coupled ensemble pulse emitting units 
phys 
rev lett 
gerstner van hemmen 

coding information processing neural networks 
domany van hemmen schulten editors models neural networks ii pages new york 
springer verlag 
gerstner van hemmen cowan 

matters neuronal locking 
neural comput 
gray singer 

stimulus specific neuronal oscillations orientation columns cat visual cortex 
proc 
natl 
acad 
sci 
usa 
hebb 

organization behavior 
wiley new york 
herz kuhn van hemmen 

hebb rule representation static dynamic objects neural nets 
europhys 
lett 
herz kuhn van hemmen 

hebbian learning reconsidered representation static dynamic objects associative neural nets 
biol 
cybern 
je 

place theory sound localisation 
comp 
physiol 
psychol 
keefe recce 

phase relationship hippocampal place units hippocampal theta rhythm 
hippocampus 
kempter gerstner van hemmen 

hebbian learning spiking neurons 
phys 
rev 
kempter gerstner van hemmen 

intrinsic stabilization output rates spike hebbian learning 
neural computation submitted 
kempter gerstner van hemmen wagner 

extracting oscillations neuronal coincidence detection noisy periodic spike input 
neural comput 
kistler van hemmen 

modeling synaptic plasticity conjunction timing pre postsynaptic potentials 
neural comput 
knight 

dynamics encoding population neurons 
gen physiology 
knight 

relationship firing rate single neuron level activity population neurons 
gen physiology 
konishi 

centrally synthesized maps sensory space 
trends neurosciences 
konishi 

listening ears 
scientific american pages 
konig engel singer 

integrator coincidence detector 
role cortical neuron revisited 
tins 
levy stewart 

temporal contiguity requirements long term associative potentiation depression hippocampus 
neurosci 
tsodyks 

information content action potential trains synaptic basis 
gerstner nicoud editors artificial neural networks icann lecture notes computer science 
springer 
levy 

sequence learning single trial 
inns world congress neural networks ii pages 
intern 
neural network soc 
neural networks biological modeling 

aspects signal processing noisy neurons 
phd thesis georg august universitat 
bi poo 

synaptic modifications hippocampal neurons dependence spike timing synaptic strength postsynaptic cell type 
neurosci 
newsome 

noise neural codes cortical organization 
current neurobiology 
song miller abbott 

competitive hebbian learning spike time dependent synaptic plasticity 
nature neuroscience 
sullivan konishi 

neural map interaural phase di erence owl brainstem 
proc 
natl 
acad 
sci usa 
thorpe 

speed processing human visual system 
nature 
treves 

local neocortical processing time recognition 
int 
neural systems supp 
treves 

mean field analysis neuronal spike dynamics 
network 
miller 

physiological gain leads high isi variability simple model cortical regular spiking cell 
neural computation 
tsodyks sejnowski 

rapid state switching balanced cortical networks 
network 
zhang tao holt harris poo 

critical window cooperation competition developing synapses 
nature 
