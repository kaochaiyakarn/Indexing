software hardware exploiting speculative parallelism multiprocessor jeffrey david heine shih wei liao monica lam olukotun computer systems laboratory stanford university stanford ca thread level speculation tls possible parallelize general purpose programs 
proposes software hardware mechanisms support speculative thread level execution single chip multiprocessor 
detailed analysis programs tls execution model shows bound performance tls machine promising 
particular tls feasible find speculative parallelism outer loops greatly improve performance general purpose applications 
exploiting speculative thread level parallelism multiprocessor requires compiler determine speculate generate spmd single program multi ple data code developed fully automatic compiler system uses profile information determine best loops execute speculatively generate synchronization code improves performance execution 
hardware mechanisms required support speculation simple extensions cache hierar chy single chip multiprocessor 
show proposed mechanisms thread level speculation provides significant performance benefits 
desire higher microprocessor performance general purpose programs increasing gate densities offered semiconductor technology driven hardware designers compiler writers investigate aggressive techniques exploiting program parallelism 
current software hardware techniques focus exploiting instruc tion level parallelism single execution thread multiple instruction issue combination static dynamic instruction scheduling register renaming speculative execution 
techniques successful achieving better program performance simple cpu pipeline studies show amount program parallel ism exploited techniques limited thread control model computation 
overcome limit consider computational model includes multiple flows control 
requires parallel applications 
possible applications perfor mance important parallelized hand automatic parallelization general purpose codes required single chip multiprocessor architectures widespread 
date automatic parallelization suc numeric fortran programs data dependencies analyzed statically 
parallelizing general purpose non numeric programs successful requires pointer disambiguation cally analyze dependencies 
significant amount progress area unsolved problem 
parallelization general purpose programs succeed need hardware software mechanisms eliminate need data dependence analysis ensure correct program execution 
describes model computation called thread level speculation tls uses speculative execu tion multiple threads control overcome current limitations software hardware uncovering exploiting parallelism general purpose programs 
support tls added single chip cessor low interprocessor communication overhead 
support consists hardware keep memory state separate non speculative state mechanism committing speculative state software control method detecting data hazards flushing speculative state mechanism notifying software hazard detected recovery take place 
hardware support tls possible compiler aggressive conservative uncovering parallelism 
tls computation model compiler takes sequential programs automatically generates parallel code ignoring potential data dependencies tls hardware support guarantees correct execution dependencies exist 
tls works best data hazards occur infrequently performance gained increased parallelism greater performance lost recovery overhead 
maximize performance compiler deter mine speculation beneficial insert synchronization processors 
model computation similar multiscalar paradigm proposed sohi 
multiscalar paradigm constructive model processor multiple threads speculation influenced significantly 
results reported applicable proposed system 
primary differ ence multiscalar approach proposed system multiscalar machine operates anno sequential program 
architecture tailored executing relatively fine grain speculative execution machine having single logical register file special mechanisms ensure coherence register files 
contrast approach speculation multiple threads extension multiprocessor supports fine grain sharing 
objective build machine cost effectively execute different programs time single applications statically speculatively parallelized 
interested exploit ing fine grain coarse grain parallelism 
expect compiler fully aware presence multi ple processors generating code keeps separate states respective register files improve performance 
machine intended implemented single chip provides efficient generic support communication processors specialized support speculative execution 
software plays bigger role system versatile lower hardware overheads 
research reported major components 
include defining computa tion model studying model analytically experimentally suite programs developing feedback driven optimizing compiler machine hardware support speculation specifying processor detail run operating system code demonstrating functionality complete simulation rep programs 
speculative execution model 
define machine speculative execution show machine find speculative parallelism iterations loop 
lay ground subse quent discussion describing issues determine performance speculative execution 
analysis speculative parallelism programs 
speculation multiple threads new computation para explored intuitions performance effects speculation lation employed developed 
gain intuition devised experiment designed discover inherent amounts speculative parallelism general purpose programs 
define perfect tion machine chooses best loops execute speculatively issues load instruction optimal time 
simulation perfect speculation machine different previous limit studies models realistic form computation individual iteration executed sequentially relies implementable tion mechanism 
analyze results simulations detail discover characteristics programs executing speculation 
compiler optimizations speculation 
explain minor coding styles greatly affect perfor mance speculation describe simple compiler algorithm eliminates artificial dependencies program 
algorithm fully implemented suif compiler system 
information simulation study compiler key optimization decisions speculate synchronize 
compiler generates speculation code loops perfect speculation machine chooses intro duces synchronizations operations frequently occur simulations 
simulation slow compared normal compilation speeds code optimization process fully automatic time taken compared manual performance tuning time spent software products 
detailed hardware design 
computation model dramatically different existing mul show machine realized modifications existing single chip multiprocessor design 
focus design addressing issues required support system software demonstrate functionality full simulations programs running complete operating system 
determining precise memory system parameter values cache sizes outside scope 
computation model section machine speculation discussions implementation pre sented section 
speculative execution model goal support potentially coarse grain speculative execution unit code speculate contain loops function calls 
fully support coarse grain model processor running independent thread stack 
computation consists speculative regions entered exited processor explicit speculation terminate speculation operations 
speculative computation decomposed sequential tasks numbered consecutively execution order 
speculation proces sors machine sequential tasks execute 
processor completes task pro execute task task state processor executing task lowest id said current state tasks speculative state identical speculative state task memory locations written task replaced latest value written task read write operations executed processor speculation mode directed processor state may current speculative 
flavors write operations normal write operation may trigger raw hazard processor synch write operation synchronization primitives sim ply writes location 
raw hazard occurs read operation speculatively executes write opera tion produce value read 
note value write operation overwritten current task read question original write operation cause raw hazard 
raw hazard detected speculative task containing read tasks need rolled back 
roll back machine passes appropriate task number software handler task restarted 
task issue forms commit statements 
semantics commits requires task issuing commit wait speculative state current 
requires waiting previous tasks commit advance 
simple commit operation effect forcing serialization commit point 
enforce sequentiality operations operating system calls executed speculatively 
task commit advance operation occurs 
waiting previous tasks complete process task id incremented speculative state task current state 
terminate lation operation commit semantics waits previous tasks complete 
waiting speculative states subsequent tasks flushed processors notice operating speculative mode 
primitives computation model summarized table denote processor executing instructions denote task id operations semantics start speculation start speculative mode execution current state state processor task 
read read state 
synch write write state 
write write state 
task previously read data flush speculative states task restart tasks 
commit wait state current state commit advance commit current state speculate state processor executing task terminate speculation commit flush speculative states subsequent tasks signal speculation mode processors table software primitives speculative execution 
clear computation model correctly honors data dependences original sequential execution 
machine ensures reads retrieve value original sequential order rolling back computation dependencies violated 
speculative execution model quite powerful raw hazard occur true dependency violated 
war hazards occur write change state preceding task 
speculation loops focus exploiting parallelism loop iterations 
loops target reasons loops programs spend execution time typically relatively small amount state needs transferred iterations partitioning loop iterations simple way achieve reasonable load balance processors 
interested just finding parallelism requires iterations loop data control independent parallelism may exist loop carried data control dependences iterations 
machine complete multiprocessor support parallelism compiler extract statically 
concentrate subject exploiting speculative parallelism loops 
generating correct code machine straightforward 
compiler generates single program multiple data spmd program master thread responsible executing sequential portions program 
slaves execute infinite loop waiting master order execute 
master thread reaches speculatively parallelized loop signals slave threads participate executing loop 
master passes slaves small loop execution context consists starting location code execute starting iteration number master frame pointer 
variables local master thread accessed master frame pointer thread local pointer 
compiler analyzes code variables privatized includes numerous temporary variables allocated directly slave stacks 
source source compiler current implementation pass frame pointers threads include loop execution context values variables read loop addresses variables may modified 
code modified access master variables loop execution context 
spmd code parameterized processor identification number iterations cyclically dis tributed processors 
machine processors thread executes iterations necessary number iterations known time loop execution started model general handle loops 
code loop independent iterations threads need communicate step assigned iterations independently 
loop thread issues start speculation operation task id starts executing assigned iteration speculatively 
course execution thread executes system call issues commit operation ensure system calls original sequential order 
reaches iteration executes commit advance operation branches back loop 
hand branches loop issues terminate speculation operation 
shows speculative execution loop processors 
master wakes slaves threads proceeds execution 
slaves start executing respective iterations 
diagram shows second slave thread delayed tries issue commit advance statement iteration commit advance statement issued iteration 
example iteration loop executes break statement exits loop 
break statement executed iterations tively completed iteration encountering break statement loop 
commit advance terminate speculation operations allowed proceed thread issued operations current terminate speculation operation issued iteration correctly flushes spec states iterations 
master thread slave threads start speculation iteration commit advance iteration commit advance iteration terminate speculation example thread level speculative execution compiler provides exception handler called hardware detects raw hazard lation mode 
exception handler restores state thread point iteration 
ration requires flushing thread speculative state restoring loop execution context starting iteration set iteration thread speculating 
addition speculative read write operations compiler uses synch write operations enforce synchronization iterations definite data dependence iterations 
dependent task reads synchronization variable proceed preceding task signals data ready synch write operation 
synch write operation dependent task read synchronization variable synch write occurs causing roll back 
start speculation start speculation iteration commit advance iteration terminate speculation iteration commit advance iteration commit advance analyzing speculative parallelism loops section analyze performance speculative parallelism extracted loops executing infinite hardware 
simplify analysis assume machine issue single instruction time takes clock cycle execute loop iteration 
infinite hardware initiate iterations time 
read operation data dependent write operation reads value written definition stricter usual meaning requires read write operations access location 
data dependencies cross iteration boundaries loop said carried loop 
sup pose loop carried data dependency iteration executing instructions writes value read second iteration executing instructions 
difference positive optimal delay read operation cycles 
delay read iteration roll back violation occurs delay read operation cycles 
refer difference number instruc tions executed minimum execution delay dependence 
maximum execution delay loop carried dependences defines total minimum execution delay entire iteration 
loops loop carried data dependencies positive execution delays referred doacross loops 
execution time shorter compounded execution delays consecutive iterations degree parallelism loop estimated ratio average time execute iteration average minimum execution delay iteration 
iteration contain loops recursive function calls total number instructions executed bounded number statements loops functions calls 
regard small minimum execution delay degree parallelism bounded constant inde pendent number iterations loop 
hand iteration contains loops recursive function calls number instructions iteration unbounded degree parallelism quite large minimum execution delay small 
refer doacross loops contain inner loops recursive calls coarse grained fine grained 
presence loop carried dependences necessarily reduce degree parallelism loop 
execution delay negative means write operation taken place read operation iterations initiated time 
dependences negative execution delays slow parallel execution 
unfortunately case occurs rarely practice times possible compilers rearrange code eliminate loop carried data dependences 
loop carried data dependences execution loop loop said speculative doall parallelism degree parallelism exploited simply minimum number iterations loop number processors machine 
classes doall loops 
class doall loops ar loops number iter ations known advance iterations initiated simultaneously knowing definitely execute 
second class doall loops number iterations known advance includes loops loops break statements 
example loop searches element array matches key 
execute loop speculatively initiate iterations proces sors flush speculative state iterations executed loop termination condition met 
maximum degree parallelism program smaller number iterations loop number processors machine 
performance perfect speculation machine model aid understanding speculative execution experiment perfect speculation machine 
machine infinite number processors issues executes single instruction clock cycle 
assuming loop allowed execute speculatively time perfect speculation machine choose optimally instance loop loop speculatively parallelized refrain speculating order allow inner loops speculate 
perfect machine knows iterations speculative loop execute initiates iterations simultaneously 
delays read operation minimum amount time necessary satisfy true data dependences 
performance perfect machine places upper bound performance hardware supporting speculative execution model algorithm simulate perfect machine show results simulating set programs machine 
analyze results experiments extract information programs relevant speculative execution model 
simulation algorithm trace driven simulation algorithm determine performance perfect machine 
basic engine similar previous architecture limit studies record latest instruction write memory location determine earliest time read operation execute 
data user program appear trace order compute accurate limit 
relatively easy modify basic scheme simulate perfect speculative execution single loop 
augment load store address trace start points iteration loop 
deter mine minimum execution speculative loop reset time simulation iteration 
normally simulation time advances clock cycle instruction 
instruction load time location written current time clock advanced minimum time needed satisfy dependence difference times 
iteration clock time recorded completion time iteration 
minimum execution time speculatively executed loop just maximum completion time iterations 
complexity simulation algorithm lies determining best loop speculate point pro gram 
simulation algorithm analyzes sequential trace keeps separate simulation times currently active loop loop speculating 
loop executed instruction nested dynamically algorithm tracks current iteration number simulation time assuming loop executing speculatively 
currently active loop information recorded location stored simulation 
load operation encountered compares current iteration counts write location 
loop carrying dependence common loop nest different iteration counts 
time store loop current time advance simulation time current iteration loop containing load minimum execution delay 
note dependence car loop level affect simulation time loop 
read automatically executed write operations regardless loop current nest choose execute speculatively 
innermost loop terminates passes surrounding loop length computation degree parallelism achieved speculatively executed 
collecting information inner loops outer loop determine profitable speculate suppress tion order allow inner loops speculate 
chooses option providing best performance ter informs surrounding loop best performance available speculation applied inner loops 
eventually information propagates back outermost loop level determines best performance loop speculation provide 
algorithm handles recursion assuming speculation applied outermost execution loop recursively invokes 
addition computation described collect statistics deepen understanding program characteristics 
identify read write operations potentially cause cross iteration raw hazard store information loop affects 
compare iteration number stored current iteration determine iteration distance dependent operations 
simulation results experiments perfect speculation machine chose examine benchmarks 
ben shown significant amounts doall parallelism past 
benchmarks sim small input set serves validate compilation provide data needed understanding pat terns parallelism 
benchmarks summarized table table summary benchmarks number instructions executed application lines code function execution length eqntott equation solver spec mpeg audio compression wc word count utility grep pattern matching utility espresso logic minimization fpppp quantum chemistry benchmark diff file comparison utility compress file compression spec analysis parallel behavior table presents performance perfect speculation machine 
programs sorted reverse order speedups highlight range behavior 
speedup ranges ing potential performance speculation highly sensitive program 
understand behavior program analyze behavior perfect speculation machine classify spends time modes speculative doall loops speculative doall loops potential early exits speculative doacross loops coarse grain parallelism speculative doacross loops fine grain parallelism sequential execution 
breakdown execution time enables understand variation speculative parallelism program correlate performance program characteristics 
shows breakdown program 
program bar components indicating percentages computation different modes 
show table speedup component occupies computation time 
table speedups different modes speculative parallelism program doall doall coarse fine speedup early exits doacross doacross eqntott wc grep espresso fpppp diff compress composition speculative execution modes doall doall exit coarse fine sequential results show programs collection different behaviors 
significant amount fine coarse grain doacross parallelism programs 
programs doall paral 
largest speedup times eqntott achieved exploiting forms parallelism scale data set size doall early exits coarse grain doacross parallelism 
medium speedups observed music wc grep achieved different ways fine grain coarse grain doacross parallelism doall loops early exits 
espresso largest program collection variety different execution modes exhibits reasonable amount parallelism 
fpppp highly unusual program spends time executing loops iterations consists thousands lines straight line code 
small number iterations limit speedup achieved exploiting loop level parallelism 
different techniques partitioning basic block processors may effective program 
program diff compress loop carried dependences program limiting speedup achieved 
examine mode execution carefully 
speculative doall loops 
programs examined programs able speculative doall parallelism 
results indicate collection programs different scientific applications dominated doall parallelism 
program col lection heavy numerical component significant amount parallelism doall loops 
results imply parallelizing compiler find amount doall parallelism program 
com piler may unable find parallelism automatically analysis powerful 
furthermore speculation machine ignores anti dependences possible conventional multiprocessor 
speculative doall loops early exits 
eqntott grep espresso loops form parallelism 
dependencies loops analyzed statically machine speculation support execute loop doacross loop iteration start iteration determines terminate pre 
efficient termination condition calculated relatively early execution loop iteration 
speculative hardware obviates dependence analysis buffering side effects loop iteration certain iteration executed 
coarse grain speculative doacross parallelism 
coarse grain parallelism usually small number loops loops constitute large proportion program execution time 
parallelizing outer loops opposed inner loops advantage operations execute parallel 
hand course grain parallel programs instructions execute simultaneously originally apart sequential program greater potential data dependencies 
perfect speculation machine dis covered significant effective coarse grain parallelism half programs 
furthermore machine chooses speculate outer loop usually achieves reasonable speed 
exception compress case speedup outer loop small speedup speculating inner loops smaller 
results suggest important identify coarse grain doacross loops program 
fine grain speculative doacross parallelism 
presence coarse grain doacross parallelism dependent algorithms program fine grain doacross parallelism universal 
note pro grams coarse grain speculative parallelism may contain fine grain parallelism deemed profitable 
range speedup quite large 
success exploiting form parallelism lies hardware organization support speculation fine grain communication efficiently 
sequential execution 
parallelization overhead perfect speculation machine employ lation loops gain performance small 
result machine speculating time 
observe programs espresso diff compress non negligible sequential component 
reason perfect speculation machine decides profitable exploit speculative par inner loops leaves remaining code outer loops execute sequentially 
example espresso executes speculation mode speculation manages achieve reasonable performance speeding speculative portion times 
frequency roll backs speculative execution hardware serves important functions 
guarantees serial semantics necessary prove absence dependence compile time 
second important function extract parallelism loops dynamically varying dependences non speculative scheme 
example program exception condition speculative execution hardware allows iteration proceed previous iteration determines exception condition holds preceding iteration 
understand speculative hardware breaks computation differ ent components highlighting dependences uniform iterations 
doall loops early exits obviously irregular dependencies requiring hardware squash iterations speculatively ated incorrectly 
partition coarse grain fine grain speculative executions data dependence shows iteration 
clearly programs dynamic depen dences exception eqntott ability hardware roll back plays significant role 
size speculative state perfect machine keep infinite amount speculative state real machine fixed limit amount speculative state 
order show amount speculative state required task keep track maximum volume data written single iteration particular loop 
multiple writes loca tion iteration counted 
table shows degree parallelism obtained small amount state bytes kept 
addition infinite volume possible give maximum volume needed execute loops contributing parallel coverage 
note programs bytes speculative state sufficient obtain desired parallelism 
fpppp thresh old bytes needed significant parallelism attained 
correlates size loop speculated fpppp 
similar amount state required maximum parallel ism 
speculative parallelism static dynamic dependencies table volume data vs parallelism exposed bytes infinite volume parallelism bytes program parallelism required eqntott grep espresso fpppp diff compress compiler optimizations speculation machine easy generate tls code resulting performance highly tive code generated 
show compiler improve speculative code code reorder ing statistics gathered perfect speculation machine choose best loops execute speculatively insert synchronization code reduce frequency roll backs 
doall doall exit coarse static coarse dynamic fine static fine dynamic sequential sensitivity performance code ordering performance speculatively parallelized loop sensitive actual code sequence itera tion 
example operation iteration depends operation previous iteration amount cross processor speculative hardware deliver parallelism code 
loop carried dependences impose limits parallelism available machine 
recurrences create loop carried dependences eliminated 
common form recurrences programs calculations loop induction variables 
implemented aggressive induction variable recognition algorithm elimi recurrences 
loop carried dependences show code participate recurrences 
reduce occurrences heuristic algorithm greedily finds opportunities converting intra iteration depen dences 
shifting loop boundary loops expose parallelism speculative hardware 
speculate perfect machine individual execution loop decide speculate execution 
optimal speedup loop may involve speculating time allowing inner loops speculate times 
annotate program real execution loop static decision speculate speculate uniformly apply dynamic executions loop 
guide compiler augmented simulation perfect speculation machine calculate loop speed loop chosen execute speculatively executions 
information compared speed ups inner loops speculation decision 
modified perfect speculation machine accept static external decisions loops speculate evaluate performance resulting execution 
table shows speculation results static decisions heuristic described 
program speedups largely unchanged apart static loop nest perfect machine chooses speculate different levels different times making static speculation policy clearly suboptimal perfect dynamic 
table performance static speculation program perfect speedup static speculation speedup eqntott wc grep espresso fpppp diff compress insertion synchronization code real speculative execution machine backup costs significant worthwhile introduce synchro program delay read operation executing early cause machine roll back lose performance 
shows frequencies cross iteration dependences 
frequency computed dividing number times dependence observed number iterations loop observed minus loop iteration cross iteration dependences 
note multiple reads single write counted synchronization rollback presumed eliminate hazard subsequent reads data 
frequency dependences observed suggests bimodal frequency distribution dependences close rarely occur 
furthermore examining dependencies reveals loop carried cies detected consecutive iterations 
exception compress dependencies span ning boundaries iterations 
results suggest simple strategy inserting synchronizations operations dependences frequency synchronizing consecutive iterations 
note decide synchronize read write inside conditional control flow structure move synchronization outside control flow consumer waits producer synchronization occurs 
furthermore analyze control flow determine enforcing desired ordering pair depen dent operations may enforce order remove redundant synchronization improve effi ciency spmd code 
reducing commits doall loops commits operations execute order iteration may proceed preceding iteration committed 
iterations high variance execution times serializing commits may waste cycles 
possible improve performance speculative doall loops assigning multiple iterations processor minimize overhead commit operations 
hardware support speculative system performance single chip multiprocessor speculation support 
section describe high performance single chip multiprocessor hardware support thread level speculation 
shows architecture cpu single chip multiprocessor designed exploit fine grained speculative parallelism 
heart system dual issue processors 
processors set tightly coupled primary caches possible achieve single cycle cache access high proces sor clock frequencies 
chip memory system interconnects processor primary cache subsystems pro vides interprocessor communication supplies data lower levels memory hierarchy 
designed high bandwidth extensive pipelining buffering 
key components memory system design pair read write buses 
buses provide connection processors rest levels memory hierarchy 
addition buses primary points synchronization communication processors system 
prevent buses performance bottleneck designed low occupancy 
transaction occupies bus cycle accomplished pipelined centralized bus arbitration mechanism allocates cycles buses cycle cycle bus ally 
maintain cache coherency write invalidate protocol write primary data caches 
write buffer placed processor write bus allow processor continue executing write waits bus 
write bus sees write processors data caches write 
order write bus allocated processors imposes total ordering writes system 
write complete point view processors write transaction completes bus 
write bus key coherency point responsible invalidating caches may sharing cache line 
write bus direct connection secondary cache updated write 
shared secondary cache provides low latency mechanism processors share data 
designed bandwidth accommodate write traffic read traffic processors 
hardware support speculation distributed primary caches secondary cache 
hard ware possible back memory data hazard detected 
describe speculation support detail section 
hardware support speculation hardware support speculation possible processor back memory operations restore memory system previous state 
implies way keeping temporary memory values way detecting necessary back memory operations 
describe ideal model hardware spec ulation describe mechanisms speculation implemented 
ideally memory system hardware support speculation consists fully associative infinite size primary cache attached processor 
cache holds speculative state operates write back mode writes change sequential state secondary cache commit point reached 
speculative mode behavior memory operations processor executing task follows 
processor ing iteration performs read operation speculative hardware returns value data 
data read processor primary cache version data 
processor cache version data read processor executing task data caches processors executing task data read secondary cache 
fact processor read memory address data recorded primary cache 
important note processor separate speculative buffer data hazards detect raw hazards due true data dependencies program 
write read war write write hazards due named dependencies eliminated automatic renaming mem ory locations provided having separate speculative buffer processor 
shows speculation support distributed primary caches set speculation write buffers 
associated processors primary cache set bits tracking raw hazards speculative state 
read bit bit word cache bits modified pre invalidate line cache 
read bit indicate word speculatively read processor 
bit set pro cessor reads word cache 
word bit detect raw hazards writes broadcast ing processor performed write appear write bus 
modified bit indicate line contains speculative write state 
set processor written line reads data written speculatively processor 
pre invalidate bit pending invalidation bit 
write appears write bus associated task causes matching cache lines processors executing tasks set pending invalidate bit 
processor executing tasks greater writes cause invalidations violations 
task commits lines pending invalidate bit set invalidated 
doing ensures processor received pending invalidate reassigned task greater state cache con sistent newly assigned iteration 
implementation speculation support 
ideal speculation support primary caches infinite replacement misses 
finite sized primary caches possibility replacement misses 
maintain correctness replace ment happens processor executing iteration stall processors executing iterations commit 
point processor continue processors sequential program order longer executing speculative mode 
lessen impact replacement misses line replaced speculative tag state kept victim cache 
replacements victim cache occur processor stalls 
design goal support speculation minimize time takes commit discard speculative state ensure order state updated correctly 
set fully associative write buffers hold speculative state attain goal 
twice buffers processors 
speculation mode buffer assigned processor 
processor completes commit operation contents buffer transferred secondary cache 
ensure consistent view order state contents write buffers completely emptied time 
allow processor new iteration data transfer new buffer assigned processor 
double buffering minimizes latency commit operation maximizes parallelism exploited speculative mode 
processor discard speculative state contents current write buffer invalidated lines primary cache modified bit set 
take processor cycles 
cache speculative reads 
shows diagram reads multiprocessor speculative support 
processor labeled cpu shown possible iteration windows 
window cpu speculative pro cessor window non speculative order processor 
assuming iteration window speculative reads way 
read hit fetches data primary cache updates appropriate speculative read bit 
read cause line fetched secondary cache 
data secondary cache merged data write buffers bytes buffer labeled highest priority bytes secondary cache labeled lowest priority 
data merging ensures cpu sees data written cpu cpu cpu 
cache iteration windows possible head cpu cpu speculative writes 
write buffer speculative earlier cpus speculative cpus cpu write buffer iteration windows possible head cpu write bus cpu write buffer cpu cpu write buffer cpu cpu cache write buffer cpu hit cpu write buffer cpu cpu write buffer speculative earlier cpus speculative cpus write buffer invalidations raw detection write buffer cache write buffer write buffer pre invalidations cpu write buffer cpu write buffer cpu write buffer shows diagram writes 
iteration windows possible cpu writes processors cpu cpu cpu cpu cause lines cpu cache invalidated may cause raw hazard detection cpu read word written 
writes processors cpu cpu cpu greater cpu may cause pre invalidations cpu cache 
pre invalidated lines invalidated cpu commits 
simulation model results section collected simulator models idealized hardware 
think single cycle commits flushes possible achieve real implementation course nite primary caches feasible 
results show hardware requirements practical implementation speculation support quite modest 
simulator ideal speculation support implemented simos environment 
simos models hardware multiprocessor detail boot run commercial version unix sgi irix 
possible simulate binaries compiled existing sgi multiprocessor systems 
simos set cpu models differing levels detail simulation speed 
study cpu model models simple stage pipeline id ex mem wb instructions take single cycle execute ex stage 
cpu model coupled memory system model includes ideal speculation support 
memory system model memory accesses take cycle assumes perfect infinite cache consistent description ideal speculation support described section 
perfect memory system primarily interested evaluation performance speculation influenced perfor mance artifacts parts memory system design 
speculation os advantage simos simulation methodology provides realistic environment evaluate speculative parallelism 
environment cpu spends part time kernel mode han system calls request interrupts page faults 
memory system sees memory refer ences occur real machine 
presents extra challenges simulator directly executes user level code 
challenges arise kernel allowed execute spec ulation mode 
reasons 
kernel analyzed compiler guarantee correctly speculation mode 
second kernel interfaces devices disk subsystem facility backing 
control speculation kernel broad classes interrupts need consider 
coerced page faults timer interrupts disk requests user requested syscall user program 
coerced interrupts may may related user process responded processor immediately avoid potential dead lock situation 
speculation mode interrupts han turning speculation reads writes bypass speculation support operate directly tial state 
writes occur processor executing kernel checked raw hazards processors 
hazard detected processor restarted 
simulations observed situation 
user requested interrupts syscall handled immediately interrupts occur order sequential program serialized 
enforce con ditions processor execute commit operation executing syscall 
ensures processor sequential state kernel entered speculative executed 
speculation system performance results demonstrate software hardware speculation working complete system preliminary results 
show performance hardware model running applications wc eqntott grep diff compiled automatically feedback parallelizing compiler 
table shows speedup percentage speculative tasks restart applications 
speedup achieved speculative multiprocessor applications highly correlated number restarts 
wc achieves speedup processors 
consistent single loop fine grain speculative parallelism exploited speculative hardware support 
percentage spec tasks restarted low restarts happen execution proces sors operate pipelined fashion interfering 
performance eqntott wc perfect speculation machine results predict eqntott achieve better performance wc 
reason large fraction tasks speculative parallelism eqntott restarted 
restarts waste time lower performance 
recall perfect speculation machine need restart tasks 
grep contains early exit parallelism fine grain parallelism 
results indicate parallel speedup due parallelism application spends time loop restarting 
result high percentage speculative tasks restarted 
restarts due loop carried dependencies loop iterations result raw hazards 
performance diff speculative parallelism fine grained loops 
loops restart constantly indicates true parallelism application 
important result shown size speculative write state appli cations 
results indicate write state relatively small bytes speculative tasks 
speculative read state bytes majority speculative tasks 
tion results replacements primary cache reasonable size greater kbytes cause significant performance losses speculative mode 
importantly small size write state indicates speculative state placed write buffers constructed modest amount sram 
results closely correlate size speculative read write state measured perfect machine described section program speedup restart wc eqntott grep diff table hardware performance processors related goal exploiting maximum amount parallelism general purpose programs driving force modern processor design 
multiple instruction issue speculative execution dynamic scheduling exploit instruction level parallelism ilp extensively studied 
rau fisher comprehensive overview approaches wall studies suggest ilp limits reasonable window size high 
overcome limitations conventional superscalar approaches ilp franklin sohi pro posed expandable split window approach refined multiscalar paradigm 
multiscalar paradigm combines multiple threads speculative execution 
developers approach arguments paradigm better superscalar approaches exploiting parallelism gen eral purpose programs 
sohi argue speculation enable multiscalar paradigm exploit parallel ism available multiprocessor 
attempts exploit parallelism multiprocessor 
attempts successful due high cost synchronization communica tion latency commercial available multiprocessors 
approach speculation multiple threads combines ideas multiscalar paradigm emphasis compiler technology focus hardware mechanisms lead efficient vlsi implementation 
possible speculative parallelism improve performance addition modest amount hardware support single chip multiprocessor archi tecture 
speculative tasks write state bytes cumulative distribution speculative write state 
describes detailed analysis speculative computation model uses multiple flows control 
results show speculative execution promising technique difficult important prob wc eqntott grep diff lem improving performance general purpose code 
particular results point exploiting parallelism outer loops lead significant performance gain codes 
presents automatic strategy generating efficient speculative software 
speculative hardware generating legal code easy generating efficient code difficult 
developed algorithm reduce loop carried data dependences program 
developed simulation feedback system deter mine best loops speculate synchronizations introduce 
analysis shows having static decisions speculate degrades performance slightly ideal decisions vary choice instance 
furthermore show frequencies dependences bimodal allowing simple highly effective strategy placing explicit synchronizations dependences close frequency 
proposed hardware support speculative parallelism 
investigated ideal hardware support realistic implementation primary cache speculative write buffers 
incorporated model ideal version speculation support simulation environment closely resembles real machine 
realism raised number issues addressed concerning interaction speculation operating system 
results demonstrate complete software hardware system speculation multiprocessors 
far achieved speedups small integer programs 
measurements speculative read write state suggest small speculative write buffers take complete advantage speculative parallelism integer programs 
amarasinghe anderson lam 
tseng overview suif compiler scalable parallel machines proceedings seventh siam conference parallel processing scientific compiler san francisco 
amarasinghe hot compilers hot chips hot chips vii stanford ca 
blume parallel programming polaris computer vol 
pp 
december 
cytron doacross vectorization multiprocessors proceedings int 
conf 
parallel processing pp 

franklin sohi expandable split window paradigm exploiting fine grain parallelism proceedings th annual international symposium computer architecture pp 
gold coast australia may 
hall anderson amarasinghe murphy liao bugnion lam maximizing multiprocessor performance suif compiler computer pp 
december 
hennessy patterson computer architecture quantitative approach nd edition 
san francisco california morgan kaufman publishers 
lam wilson limits control flow parallelism proceedings th annual international symposium computer architecture pp 
gold coast australia may 
rau fisher instruction level parallel processing history overview perspective journal supercomputing vol 
pp 

rosenblum herrod witchel gupta simos approach ieee parallel distributed technology vol 

sohi breach multiscalar processors proceedings nd annual intl 
symp 
computer architecture pp 
ligure italy june 
wall limits instruction level parallelism digital western research laboratory wrl research report november 
wilson lam efficient context sensitive pointer analysis programs proceedings prog 
lang 
design implementation pp 
june 

