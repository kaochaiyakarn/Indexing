submitted presence teleoperators virtual environments motion structure estimation inertial sensors authors computer vision augmented reality lin chai xilinx th st boulder lin chai xilinx com william hoff corresponding author engineering division colorado school mines golden mines edu vincent engineering division colorado school mines golden mines edu submitted presence teleoperators virtual environments motion structure estimation inertial sensors computer vision augmented reality new method registration augmented reality ar developed simultaneously tracks position orientation motion user head estimating dimensional structure scene 
method fuses data head mounted cameras head mounted inertial sensors 
extended kalman filters ekf estimates motion user head estimates locations points scene 
recursive loop 
algorithm tested combination synthetic real data general perform 
test showed system cameras performed better system single camera improving accuracy inertial sensors partially compensate loss camera 
method suitable completely unstructured environments 
previous area method requires priori knowledge scene environments objects interest close user 
index terms augmented reality pose estimation registration kalman filter structure motion computer vision inertial sensors submitted presence teleoperators virtual environments describes new method registration augmented reality ar simultaneously tracks position orientation motion user head estimating dimensional structure scene 
method suitable completely unstructured environments 
previous area method requires priori knowledge scene environments objects interest close user 
term augmented reality refers systems draw visual overlays top user view real world see azuma survey 
accomplished see head mounted displays hmd include hand held devices 
virtual objects displayed registered corresponding real world objects give sense virtual real objects exist space 
preserve illusion virtual objects accurately registered real world user moves scene 
requires accurate sensors measure degree freedom dof position orientation pose user head real time 
particularly interested environments sense pre placed sensors markings objects aid registration 
may priori knowledge environment terms types objects locations 
characteristics potential ar applications maintenance navigation military law enforcement 
example consider scenario maintenance worker wearing ar system enters unfamiliar room fix piece equipment 
ar system automatically track pose worker head room respect arbitrary fixed origin submitted presence teleoperators virtual environments room 
image snapshots sent remote expert annotate piece equipment text graphics 
annotations fixed coordinate system room remained registered object interest 
requirements tele maintenance scenario similar potential applications remote collaboration 
tracking user head unstructured environments precludes sensors require pre placing instruments transponders landmarks scene 
include mechanical magnetic acoustic optical sensors meyer 
possible alternative inertial sensors gyroscopes accelerometers provide rate information absolute pose 
result derived pose drift time 
orientation drift corrected occasional updates absolute sensor compass tilt sensor azuma hoff 
translation information may obtained global positioning system gps sensor azuma hoff 
gps systems may unreliable indoors 
promising alternative head mounted cameras computer vision techniques locate track naturally occurring features scene neumann 
pose camera positions features estimated projections features images 
computer vision may sufficient meet demands accuracy reliability real time operation needed ar systems 
computer vision algorithms computationally intensive may difficult produce results rate needed keep rapid head motion 
features detected due occlusions lighting changes motion blur 
hybrid system incorporating multiple sensors submitted presence teleoperators virtual environments probably necessary neumann 
example inertial sensors complement head mounted cameras 
computer vision provide absolute pose information inertial system provide pose estimates vision updates vision data available 
sensor suite suitable unstructured environments 
main issues address follows simultaneously estimate positions naturally occurring features pose head priori information 
relatively straightforward compute pose visual observations knows true locations observed features see example hoff lyon sharma 
relatively straightforward compute locations observed features knows true motion camera see example hoff shekhar chellappa bhanu das 
don know compute simultaneously 
model dynamics user motion estimate sensor vision inertial data 
motion model needed predict pose head 
greatly improve dynamic accuracy azuma bishop improve efficiency computer vision system predicting locations features images 
fuse vision inertial sensor data may obtained different update rates 
main contribution description method addresses issues described presentation results testing algorithm implementation submitted presence teleoperators virtual environments synthetic real data 
address issues detecting tracking visual features sensor calibration real time implementation issues 
material comes thesis authors chai 
remainder organized follows 
section provides background previous related sets context 
section describes algorithm developed 
section describes experimental augmented reality system test algorithm software design 
section illustrates application method various synthetic real data sets line non real time processing 
section provides discussion 
previous problem estimating self motion self pose studied robotics computer vision research communities ar community 
interested approaches modify environment priori assumptions environment 
mobile robotics mobile robotics field approaches developed support navigation unstructured environments borenstein everett 
robot build local map environment estimate pose respect map 
methods developed fuse sensor data occupancy grids moravec kalman filters kriegman durrant whyte 
approaches sensors unsuitable ar applications due size weight cost 
include high inertial navigation systems ins bhanu das lidar submitted presence teleoperators virtual environments wei larsson odometry sonar millimeter wave radar approaches take advantage fact robot motion constrained example lie plane crowley road dickmanns 
ar user motion unconstrained control ar system 
computer vision computer vision field done estimate motion structure image sequences see example tomasi kanade morita kanade ahuja soatto perona 
term motion usually refers relative pose camera successive images usually refer dynamics camera motion terms explicit velocities accelerations 
term structure refers locations features assumed lie rigid body 
focus methods track discrete set features image opposed optical flow methods compute dense velocity flow field entire image 
problem solved single camera unknown scale factor resulting estimated camera point positions 
additional information necessary recover unknown scale 
data second camera provide absolute point positions stereo triangulation data ins observation initial set landmarks known geometry 
minimum point correspondences perspective images necessary compute motion structure faugeras 
resulting estimates sensitive noise observed image points fang huang 
views larger number image frames improve accuracy 
ar submitted presence teleoperators virtual environments interested recursive techniques kalman filter batch techniques due requirements real time operation 
extended kalman filter ekf brown hwang number computer vision researchers 
ayache faugeras developed number systems compute camera motion positions point line features ayache faugeras ayache faugeras faugeras 
separate state vectors feature tracked motion camera 
motion refers relative pose camera frames 
similar includes matthies shafer matthies shafer 
works explicit representation error feature point form gaussian distribution chellappa developed ekf dynamic motion model includes position orientation angular velocity translational velocity 
single state vector motion positions feature points 
state vector elements number feature points tracked 
single camera unknown scale factor 
authors report algorithm sensitive accuracy initial guess state vector 
azarbayejani pentland azarbayejani pentland extended include estimating camera focal length motion structure include translational velocity acceleration state vector 
parameters point xyz single parameter point depth 
reduces dimensionality problem expense losing explicit representation uncertainty point location 
submitted presence teleoperators virtual environments augmented reality augmented reality field done registration inertial sensors head mounted cameras 
developed system track head orientation combination angular rate sensors 
kalman filter predicting head dynamics approach estimate sensor characteristics 
complementary kalman filter error estimator predict gyroscope biases 
integration euler angles carried outside kalman filter separate step 
harrington combined accelerometers ultrasonic range sensors allow translation measurement orientation 
estimating sensor characteristics kalman filter azuma azuma bishop took approach estimating head dynamics 
developed system track dof head pose angular rate sensors accelerometers optical tracker 
separate linear kalman filters estimate translation velocity acceleration axis head position 
single ekf estimate head orientation angular velocity angular acceleration 
previous works tracking sensors required placing active targets powered emitters transponders environment applications preferable passive targets ambient naturally occurring signals neumann 
researchers begun computer vision sense passive fiducial markings scene mellor kanade hoff lyon state sharma hoff vincent 
positions submitted presence teleoperators virtual environments fiducials known priori pose camera respect features calculated 
requires preparation knowledge environment 
neumann neumann computer vision detect track natural features video images 
point region features automatically adaptively selected tracking positions estimated 
system computed pose camera observed features explicit model head motion 
single camera normally yield results unknown scale factor position 
initial set features known positions compute absolute pose camera set frames 
ekf compute positions new features known poses camera 
positions new features known sufficiently accurately new fiducials compute camera pose 
allowed ar system extend workspace 
azuma azuma lee developed ar system outdoor applications gyroscopes conjunction computer vision achieve accurate orientation registration translation provided gps 
tracked features assumed distant image motion features presumed due orientation changes head 
observed image motion mapped orientation differences provide corrections inertial sensor drift 
simplified filter true ekf motion model 
algorithm design satisfy goal accurate robust head tracking unstructured environments chose develop hybrid system consisting computer vision system locate track submitted presence teleoperators virtual environments natural features scene inertial sensors gyroscopes accelerometers provide pose estimates vision updates vision data available 
chose incorporate explicit model head motion dynamics aid prediction 
designed algorithm accommodate head mounted camera single camera 
cameras yielded improved performance described 
compute structure feature point positions head pose motion simultaneously similar assume 
combining unknowns single large state vector separate motion estimation structure estimation different ekf similar ayache ayache faugeras 
reduces computational cost 
filters coupled provides information 
novel combine motion structure estimation vision ins sensors explicit head motion model 
system uses priori information scene scenes objects close distant 
examine consequences cameras part sensor group 
subsections describe head motion estimation filter 
describe structure estimation filter combined integrated system 
head motion estimation frames shown 
primary frame camera frame location right camera camera apparatus 
assume inertial sensors rigidly mounted respect camera relative pose known 
simplify kinematics model system set submitted presence teleoperators virtual environments frame orientation frame 
world frame arbitrary fixed location scene 
world frame hmd camera frame position orientation frames 
accelerometers frame orientation referenced vector head motion model assumes constant angular velocity constant translational acceleration 
represent head motion state vector head 
orientation camera frame respect world euler angles case quaternions modifications angular velocity 
position velocity acceleration camera respect world 
combining single state vector represent cross coupling different axes motion orientation translation 
states discretized system dynamics follows details chai empirical data curtis suggests adequate 
submitted presence teleoperators virtual environments tw tx 



wk wk wk wk elapsed time previous time update inverse jacobian matrix relating rate change euler angles angular velocity unknown input corresponding disturbance noise 
notice unknown input equal zero position update equations come kinetic relationships position velocity acceleration assumption linear acceleration samples 
equation comes taylor series expansion keep terms 
model dynamic model sense including mass inertia simply relate measurements depend positions velocities accelerations 
noise inputs come unknown motion user linearization error 
grouping signals vectors obvious way notation angle set convention matrix details chai cos sec sin sec sin cos cos tan sin tan data inputs types sensors gyroscopes accelerometers cameras 
type sensor associated output equation maps state sensor output 
output equations sensor defined follows 
submitted presence teleoperators virtual environments gyroscopes produce angular velocity measurements axis units rad related craig mm accelerometers produce acceleration measurements axis units 
dt matrix rotation camera frame frame gravity 
rotation computer vision system measures image position target point world cameras units mm image plane 
cameras separated distance optical axes aligned 
estimated world camera pose transform world point camera coordinates project images perspective projection equations 
focal length camera lenses mm position feature world frame position frame origin px px pz pz pz pz filter feature point positions considered known inputs 
actuality estimates come structure estimation filter described section 
submitted presence teleoperators virtual environments sensor sensor noise associated 
example camera data measurement sample time unknown noise input associated computer vision sensor 
similar relation holds inertial data 
sensor data varies amount sensor noise rate data arrives 
typically data rates inertial sensors greater computer vision 
statistical description unknown inputs sensor noise form mean covariance extended kalman filter determine appropriate update weightings sensor data 
assume zero mean white gaussian sequences covariance ng ng na nv extended kalman filter ekf updates state estimate associated state covariance matrix follows brown hwang 
time update equations measurement update equations kh submitted presence teleoperators virtual environments current observation inertial camera prediction sensor output current state estimate gradient dynamics equation observation equation respectively current state estimate 
block diagram head motion estimation filter shown 
assume sensors asynchronous noise independent sensor incorporated separate measurement update 
filter perform time update step project state current time step time step gyroscope data accelerometer data camera data available 
measurement update step followed update filter state new measurement input 
recursive process run continuously measurement input data available 
time update performed sensor data available head head gyroscope measurement update accelerometer measurement update camera measurement update block diagram head motion filter 
submitted presence teleoperators virtual environments structure estimation scene structure represented single nx state vector structure xi position th feature point respect world number points tracked 
points 
assume points stationary fixed world 
combined points single state vector similar represent cross coupling uncertainty different points 
note represent point positions respect world know actual location world origin 
problem world origin arbitrary interested relative pose user scene structure 
actuality world origin determined initial guesses user pose point positions 
alternative method represent point positions respect user cost complex time update step 
points represented world coordinates time update step easy small values 
measurement inputs observed image feature positions cameras address problem extracting feature points establishing required correspondences 
camera feature points giving nx measurement vector un vn sensor measurement equation non linear function equation 
filter estimates structure head pose considered known input 
actuality estimate comes motion estimation filter described previous section 
submitted presence teleoperators virtual environments measurement update equations equation nx matrix linearization current estimate block diagram structure estimation filter shown 
implementation allows cameras inputs asynchronous sensor incorporated separate measurement update 
filter perform time update step project state current time step time step data camera data available 
measurement update step followed update filter state new measurement input 
time update performed data camera available structure structure left left camera measurement update right right camera measurement update block diagram structure estimation filter 
data cameras available simultaneously alternative method calculate point positions directly stereo triangulation input data image points camera 
feature visible camera due occlusion limited field view 
case method allow data camera 
submitted presence teleoperators virtual environments combined motion structure estimation previous subsections describe separate kalman filter algorithms predict pose user head estimate structure feature points respectively 
predict user head motion inertial sensor data camera image data assume true location feature points respect world known 
estimate structure feature points camera image data assume true camera motion known 
subsection describes combined system simultaneously predicts motion pose head location feature points 
idea take results head motion prediction filter known condition estimation structure 
take results estimation structure filter known condition head motion prediction step 
steps form feedback loop 
shows block diagram data flow entire process 
inertial sensor measurements head motion filter head structure camera image measurements left right structure estimation filter block diagram combined filter algorithm 
submitted presence teleoperators virtual environments basic structure algorithm consists ekf running parallel 
filter contains time update step measurement update step 
system designed accommodate fact camera image data usually obtained slower rate inertial sensors data 
means gyroscope data accelerometer data available head motion prediction filter perform time update step measurement update step new inertial sensors measurement input 
camera image data available head motion prediction filter feature point prediction filter perform time update step measurement update step separately 
experimental system experimental system consists see hmd virtual glasses mounted helmet 
attached helmet small video cameras panasonic gp ks degree field view 
cameras left right 
attached helmet inertial sensor system consisting axis solid state gyroscope watson industries orthogonally mounted single axis accelerometers ic sensors 
data transmitted desktop computer cable tether 
current system sample inertial sensor data ms submitted presence teleoperators virtual environments experimental augmented reality system 
measured standard deviation noise accelerometers average mm gyroscopes approximately rad nguyen 
measured gyroscope biases small compared measurement noise ignored remainder study 
obtain ground truth data northern digital optical position sensor model mounted wall lab tracked set infrared led mounted helmet 
system uses high resolution linear array ccd cameras measure led positions accuracy mm 
optical sensor achieve high accuracy provide ground truth information pose user head compare results algorithm known result 
measurement input algorithm developed research 
submitted presence teleoperators virtual environments high accuracy optical sensor ground truth 
video images head mounted cameras digitized resolution pixels 
manually processed images line extract feature point positions 
estimated error feature point measurements pixels 
conservative estimate automatic feature extraction algorithms accurate 
current system support real time data acquisition processing 
described section recorded measured data file processed line 
kalman filter algorithms written matlab run pentium class personal computer 
results synthetic data examined behavior algorithm purely synthetic data 
motion trajectories described synthetic accelerometer gyro camera data generated 
trajectory simple translation constant velocity world direction user maintaining fixed gaze parallel world axis 
submitted presence teleoperators virtual environments second trajectory constant acceleration 
third trajectory user moves curve constant velocity constant acceleration rotates head constant angular velocity order keep feature points view 
synthetic user motions trajectories axis direction xy plane 
fourth trajectory arbitrary motion xy plane varying accelerations fixed orientation 
plot translation shown 
submitted presence teleoperators virtual environments arbitrary motion xy plane varying acceleration synthetic trajectory 
synthetic computer vision data generated features located points space user 
synthetic white gaussian noise added measurements standard deviation rad gyro data mm accelerometer data mm camera data corresponding pixels image 
data rates sensors ms inertial sensors vision data 
details experiments summarized table 
table summary synthetic motion trajectories 
trajectory translation gaze direction constant velocity mm direction fixed constant acceleration mm direction initial velocity zero fixed constant velocity mm constant acceleration mm constant angular rotation arbitrary motion xy plane varying accelerations fixed submitted presence teleoperators virtual environments filter parameters synthetic experiments 
measurement covariance matrices equation set observed values sensor noise described section 
process noise matrices equation set follows head structure diag diag diag indicates matrix block diagonal listed elements diagonal identity matrix 
small values reflect fact point positions stationary world 
head motion filter values chosen empirically order achieve best performance filter 
note process noise term linear velocity larger compared position acceleration 
usually difficult give simple explanation values obtained tuning clear velocity estimate modified measurements easily 
direct measurement velocity predicted velocity derived past velocity estimates acceleration current time 
inertial sensor suffers drift time velocity estimate accurate 
large value velocity process noise covariance drive velocity state covariance higher position term updated new image measurement filter tend ignore current velocity estimate reset estimate value derived position term 
results summarized table 
look difference predicted actual point positions initially run 
measure error relative user specifically camera frame 
ar applications accuracy image overlays important actual scene structure 
look submitted presence teleoperators virtual environments projected point positions camera image plane see error decreases significantly run 
table synthetic motion results showing initial final feature point errors 
experiment avg 
error mm avg 
error mm initial final initial final evident table initial guesses point positions set fairly large true values test algorithm ability recover poor priori knowledge scene 
fact initial errors comparable distance user points 
shows rapid decrease point errors experiments 
assume errors camera image plane comparable hmd display cameras typically mounted close hmd 
submitted presence teleoperators virtual environments point prediction error function time experiment 
shows top view prediction process frame experiment 
solid lines represent true trajectory feature points markers represent predicted trajectory feature points 
sets lines eventually converge motion 
shows entire process frame viewed top 
represents position right camera frame represents true location feature points 
points fixed frame move process 
represents predicted location feature points 
initial guesses point locations fairly far away true locations move true locations time goes 
note estimated world origin settled arbitrary location 
submitted presence teleoperators virtual environments top view experiment frame frame 
submitted presence teleoperators virtual environments real data tested algorithm real image data real motions 
set feature points placed surface table 
measured location feature point respect sensor mounted wall 
helmet mounted tripod physically translated table 
movement helmet rotated cameras aimed feature points table 
movement quasi static moved tripod collected image data stationary moved sensor tracked led mounted helmet provide ground truth pose 
real motion experimental setup sensor wall 
previously stated current system allow simultaneous recording video imagery inertial sensor data 
generated synthetic inertial sensor data corresponding real motions recorded sensor 
ground truth real motion data shown 
submitted presence teleoperators virtual environments real motion ground truth translation data 
real motion ground truth orientation data 
submitted presence teleoperators virtual environments motion structure estimation algorithm run real image data synthetic inertial sensor data result average point error decreased initial value mm final value mm run average point error decreased initial value mm final value mm 
shows decrease point errors function time 
point prediction error function time real data 
filter converges real image data errors larger synthetic image data 
reason larger error probably due crude calibration done cameras 
roughly measured focal length camera helmet synthetic inertial sensor data measured real motion 
submitted presence teleoperators virtual environments transformation transformation led cameras 
simplifying assumptions lens distortion cameras optical axes cameras aligned 
calibration error sources account larger error saw real data 
comparison camera vs cameras algorithm designed number cameras cameras majority testing 
issue cameras necessary 
principle single head mounted camera inertial sensor data able recover structure motion unknown scale factor 
effectively motion single camera provides baseline separation viewpoints triangulation done recover depth unambiguously 
stereo case baseline separation known accurately single camera case rough estimate motion 
result expect structure estimation accurate single camera system camera system 
performed test see true see accurate inertial sensor data compensate loss camera 
single camera system run synthetic data experiment 
amount noise added inertial sensor data varied different trials 
results shown table 
top row table shows results camera system previously shown table repeated convenience 
remaining rows table show results camera system varying levels noise accelerometers 
submitted presence teleoperators virtual environments table comparison structure estimation errors camera vs cameras 
mm rad avg initial error mm avg final error mm avg initial error mm avg final error mm cameras camera tests confirm single camera system perform camera system terms final prediction errors point positions 
variance inertial sensor noise decreased orders magnitude final prediction errors appear level higher errors camera system 
conclude cameras may required practical tracking ar 
possible area investigation 
discussion developed new method ar registration simultaneously tracks pose motion user head estimating locations naturally occurring features scene 
relying head mounted cameras inertial sensors method applicable portable systems completely unstructured environments 
previous area method requires priori knowledge scene environments objects interest close user 
experimentally convergence testing combination real synthetic data 
submitted presence teleoperators virtual environments method number cameras cameras gave better performance single camera 
method assumes visual features exist scene persist time stationary 
primarily addressed algorithmic issues fuse data possibly asynchronous camera inertial data sensors order estimate structure motion 
address difficult problems detecting tracking features calibration real time operation 
progress issues researchers remain active area research 
possible area investigation tune filter parameters specifically process noise covariance matrices achieve optimum performance 
ideally manually adjusting parameters intuitive understanding process automatic procedure optimum performance system guaranteed 
interesting approach adaptively adjust filter parameters observed motion user 
intuitively person moving slowly smoothly effectively lower level process noise unmodeled disturbances person moving rapidly accelerating quickly done preliminary area developing adaptive estimation approach multiple model estimator chai nguyen 
acknowledge valuable contribution nguyen developed equations head dynamics matlab software implement kalman filter 
experimental augmented reality system built tory lyon nguyen rex 
northern digital provided valuable assistance sensor 
submitted presence teleoperators virtual environments ayache faugeras 
maintaining representations environment mobile robot ieee trans 
robotics automation 
ayache faugeras 
building fusing noisy visual maps international journal robotics research 
azarbayejani pentland 
recursive estimation motion structure focal length ieee trans pattern anal mach intell 
azuma bishop 
improving static dynamic registration optical see hmd 
st international siggraph conference orlando fl usa acm new york ny usa 
azuma hoff 

motion stabilized outdoor augmented reality system 
ieee virtual reality ieee 
azuma lee 

tracking environments augmented reality systems computers graphics pergamon 
azuma 

survey augmented reality presence 
durrant whyte 
inertial navigation systems mobile robots ieee transactions robotics automation 
bhanu das 

system obstacle detection low altitude flight ieee trans electron syst 
borenstein everett 

navigating mobile robots systems techniques 
wellesley ma peters submitted presence teleoperators virtual environments 

recursive motion estimation monocular image sequence ieee trans electron syst 
brown hwang 
random signals applied kalman filtering 
new york wiley 
chai 

motion structure estimation inertial sensors computer vision augmented reality 
engineering division 
golden colorado school mines 
chai nguyen 

adaptive estimator registration augmented reality 
nd int workshop augmented reality san ieee 
craig 

robotics mechanics control 
reading massachusetts addison wesley 
crowley 

mathematical foundations navigation perception autonomous mobile robot 
reasoning uncertainty robotics 
van 
new york springer verlag 
ahuja 
segmentation factorization motion structure estimation long image sequences ieee trans pattern anal mach intell 
dickmanns 
recursive road relative ego state recognition ieee trans 
pattern analysis machine intelligence 
fang huang 
experiments estimating motion parameters sequence image frames ieee trans 
pattern analysis machine intelligence pami 
submitted presence teleoperators virtual environments faugeras 

dimensional computer vision geometric viewpoint 
cambridge massachusetts mit press 
larsson 

mobile robot navigation range weighted hough transform ieee robotics automation magazine 


inertial head tracker sensor fusion complementary separate bias kalman filter 
vrais santa clara california ieee computer society 
harrington 

constellation wide range wireless motion tracking system augmented reality virtual set applications 
siggraph orlando fl 
hoff 
planetary terminal descent hazard avoidance optical flow 
ieee conf 
robotics automation 
hoff lyon 

computer vision registration techniques augmented reality 
intelligent robots computer vision xv boston massachusetts spie 
hoff vincent 
analysis head pose accuracy augmented reality ieee trans 
visualization computer graphics 
kriegman 

stereo vision navigation buildings mobile robots ieee transactions robotics automation 
matthies shafer 
error modeling stereo navigation ieee journal robotics automation ra 
mellor 

realtime camera calibration enhanced reality visualization 
computer vision virtual reality robotics medicine 
international conference med nice france springer verlag berlin germany 
submitted presence teleoperators virtual environments meyer 
survey position trackers presence 
moravec 

sensor fusion certainty grids mobile robots 
ai magazine 
morita kanade 
sequential factorization method recovering shape motion image streams ieee trans pattern anal mach intell 
neumann 
natural feature tracking augmented reality ieee transactions multimedia 
nguyen 

inertial data fusion kalman filter methods augmented reality 
engineering division 
golden colorado colorado school mines 


comparison relative accuracy mechanical optical position tracker image guided neurosurgery journal image guided surgery 


navigational system continuous mining machines 
sensors 
sharma 
computer vision augmented reality guiding manual assembly presence 
shekhar chellappa 
passive ranging moving camera journal robotic systems 
soatto perona 
reducing structure motion general framework dynamic vision part implementation experimental assessment ieee trans pattern anal mach intell 
state 

superior augmented reality registration integrating landmark tracking magnetic tracking 
rd international conference computer submitted presence teleoperators virtual environments graphics interactive techniques siggraph new orleans la usa acm new york ny usa 
tomasi kanade 
shape motion image streams orthography factorization method int comput vision 
kanade 
vision object registration real time image overlay computers biology medicine 
wei 

keeping track position orientation moving indoor systems correlation range finder scans 
international conference intelligent robots systems iros munich germany 
neumann 

hybrid inertial vision tracking augmented reality registration 
ieee virtual reality ieee 
curtis 

note dynamics human head motions predictive filtering head set orientations 
telepresence technologies spie 
submitted presence teleoperators virtual environments captions frames 
block diagram head motion filter 
block diagram structure estimation filter 
block diagram combined filter algorithm 
experimental augmented reality system 
high accuracy optical sensor ground truth 
synthetic user motions trajectories axis direction xy plane 
arbitrary motion xy plane varying acceleration synthetic trajectory 
point prediction error function time experiment 
top view experiment frame frame 
real motion experimental setup sensor wall 
real motion ground truth translation data 
real motion ground truth orientation data 
point prediction error function time real data 

