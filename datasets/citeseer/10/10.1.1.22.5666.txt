robot programming multi modal interaction ph thesis proposal iba robotics institute carnegie mellon university april robots enter human environment come contact inexperienced users need able interact users multi modal fashion keyboard mouse longer acceptable input modalities 
humans able communicate robots methods similar possible concise rich diverse means communicate 
goal proposed thesis comprehensive multi modal human machine interface allows non experts conveniently compose robot programs 
key characteristics novel programming approach system interpret user intent user provide feedback interactively time 
proposed framework takes step approach problem multi modal recognition intention interpretation prioritized task execution 
multi modal recognition module translates hand gestures spontaneous speech structured symbolic data stream abstracting away user intent 
intention interpretation module selects appropriate primitives user input current state robot sensor data 
prioritized task execution module selects executes primitives current state sensor input task previous step 
depending mode operation system provide interactive robot control adjustment creation primitives composition robot programs 
proposed research expected improve significantly state art industrial robot programming interactive personal robotics 
table contents 

motivation 
related 
proposed framework 
multi modal recognition module 
intention interpretation module 
prioritized task execution module 
summary framework 
pre proposal 
gesture control mobile robot 
gesture programming humanoid robot 
gesture control manipulator 
research issues 
expected contributions 
research plan schedule 

motivation important aspect successful robotic system human machine interaction 
robots enter human environment come contact inexperienced users need able interact users multi modal fashion keyboard mouse longer acceptable input modalities 
humans able communicate robots methods similar possible concise rich diverse means communicate 
industrial robotics early years robotics teach common mode interaction 
software capabilities improved ability line programming proved significant step forward 
interfaces manipulator systems progress user friendly programming paradigms sensor manipulation 
current state art manipulator interaction iconic programming programming human demonstration paradigm 
goal paradigms translate burden programming manipulator systems robot experts task experts 
task experts extensive knowledge experience respect task may limited expertise robotics 
enable novice users interact robot interface needs intuitive ability interpret vague specifications user 
example system gesture programming interface developed khosla 
robot system observes operator unobtrusively demonstrating task 
observations vision range sensing data gloves tactile sensing 
personal robotics due growing field personal robotics come contact robots 
examples robots include pet robots tour guiding robots entertainment robots intelligent wheelchairs mobile vacuuming robots 
proposed framework focus robots personal vacuuming robot require interactive control certain degree autonomy 
traditionally mobile robots controlled joystick mouse increasingly voice gestures introduced input modalities 
proposal explore multi modal interaction combined learning approaches leap user friendly robot interfaces 
intention interpretation challenging aspect interactive robot programming interpret intent user simply mimicking actions 
user input vague inaccurate contradicting 
intention interpretation user thought search mapping function user input robot sensory data correct set robot actions 
course interpretation system may need consider factors prior actions habits user different inputs resulting action 
unreasonable assume system designers sufficient data prior system deployment understand factors 
accomplish interpretation user needs intuitive mode interaction robot letting system collect additional data leading correct intention interpretations 
framework provide line line interaction user robot sufficiently general applied manipulators mobile robots 
multi modal interface perspective multi modal interfaces gesture speech interaction user robot systems advantages conventional interaction modes teach joysticks 
compared input modalities hand gestures advantage specifying geometric objects spatial dimensional data intuitive conveying information robots exist dimensional world 
advantage obvious interacting team robots complicated maneuvers grouping commands executed gesturing set points region interest group formation 
hand gestures convenient specifying parametric information symbolic gestures 
symbolic information commands speech input natural choice 
comparison gui personal computers hand gesture superset mouse speech superset keyboard icon screen 
task primitive level programming proposed multi modal interactive programming framework distinct advantages conventional methods 
robot programming perspective line interaction adds new flavor robot programming problem 
enables novice users program robots enables interactive composition primitives create robot programs enables interactive addition primitives accelerates system ability adapt learn continuous interaction 
degree paradigms iconic programming programming demonstration mentioned succeed shifting burden robot programming robot experts task experts 
due current lack understanding intention interpretation robotic task line programming methods fragile 
task expert may demonstrate task robot task expert idea robot interpreted skill robot sufficient set actions perform demonstrated task 
proposed framework allows task expert coach robot adjustments line performs new skill 
ability add primitives closely related example 
robot system may necessary motor primitive sensing primitive compose new skill navigation range sensing develop avoidance skill mobile robot take lot training data learn associations 
interactive supervision system receive direct immediate feedback task expert significantly improving learning speed generate new sensori motor primitive 

related area human robot interaction rich diverse field study 
order understand proposed controlling programming robots multimodal interface chose divide section subsections robot control robot programming multi modal interfaces 
robot control area robot control refers problem efficiently conveying control signals robot system 
robot system device user control behavior robot 
control signal various forms ranging low level joint motor torque high level symbolic skill representations 
mobile robots industrial manipulators basic level control joint space user input comes teach pendant joystick 
higher level abstraction control specifications symbolic come graphical user interface natural user interface eye gaze tracking finger pointing natural language interpretation 
researches implemented variety natural interface control mobile robots 
systems fong provide teleoperation interface symbolic hand gestures force feedback haptic device 
mobile robot interactions systems capable receiving symbolic gesture commands board camera kortenkamp commonly symbolic gestures predefined 
kuno developed wheelchair robot controlled detecting hand gestures camera 
system capable dealing unknown gestures considering periodic hand motions potential gestures 
examples interface modalities shown matsumoto wheelchair robot detect user gaze facial direction navigate hands 
move step closer human human interaction researchers currently exploring multi modal interaction scenarios 
advantage working multi modal input mainly lies redundancy 
example system developed combines natural language hand gestures interpret complete commands 
human robot interaction intuitive level flexibility human interface increase 
order achieve higher level human robot interaction human interface robot programming modules 
robots trainable sets embedded behaviors easier interact robots offer fixed low level primitives 
robot programming addition gesture interaction direct control robots robot programming 
position path applications arc welding machine loading typically employ pendant walk teaching lead teaching 
pendant teaching user specifies intermediate points teach pendant 
lead teaching user performs required motions manually holding device manipulator replica record path 
forms teaching useful non contact applications methods proposed applications involve contact 
kang ikeuchi learning observation system models human behavior transitions contact states observing human demonstration 
system able model high level task specifications sensor feedback contact 
proposed gesture programming paradigm system assumed set basic skills referred priori control policies sensori motor primitives system compose programs 
human demonstration observed gesture recognition interpretation agents correct skills selected votes agents 
similar skill approach telerobotics system combines geometric modeling teaching demonstration virtual environment execution manipulation skills 
achieve robot interaction elevated conceptual levels robot programs composed primitive behaviors 
composition skills prepared advance learned observation 
asada human robot interaction system uses model interaction robot human plan prepared advance programmer 
kimura ikeuchi model human robot cooperation tasks observing parties placing pre post conditions stack compose program 
human humanoid application kawamura architecture captures similar pre post conditions look table 
skills built primitives embody low level policies generate control outputs sensor inputs current state 
current research neuro biologists suggests existence motor primitives identities known 
example categorization human hand grasps differs significantly robotics researchers occupational attempted categorize human hand skills 
possible foresee entire task space prior execution desirable able modify create new primitives 
pioneered motor primitives dexterous utah mit hand 
morrow created categorization possible contacts objects assign primitives take care contact situations 
schaal assigned regulator black box skills interest parameters obtained reinforcement learning 
similarly system implemented sm xu yang learns control strategies examples classifying skills action reaction skills statistically modeling incoming feedback signals control signals hidden markov models 
grupen uses reinforcement learning learn grasps resemble child skill development process :10.1.1.12.4953
multi modal interface multi modal interface combines multiple input modalities natural speech pen input hand gestures facial gestures eye gaze body language tactile input 
past robust multi modal approaches available believed multi modal interface incorporating error prone recognition technologies compound errors yield greater unreliability 
data shows fusing information sources effectively reduce recognition uncertainty improving robustness 
multi modal mobile robot interface example successful multi modal interface system 
proposed am considering hand gestures natural language possible interface modalities mobile robots manipulators 
hand gesture recognition popular field due broad applicability 
successful gesture recognition methods derived algorithms natural language recognition domain 
roughly divided approaches stochastic neural net approaches 
nishimura oka template continuous dynamic time warping dtw spotting continuous visual gestures 
mobile robot interaction system kuno strategy dtw 
starner applied hidden markov models hmm model doubly stochastic processes visual hand recognition dynamic american sign language asl 
lee xu similar hmm method recognize static asl alphabets data glove input device 
kortenkamp developed model method models different parts body set proximity spaces defines pose gestures examining angles links connect proximity spaces 
combined neural net approach static pose gestures temporal template matching approach motion gestures 
differ assumptions implementations vision vs magnetic spatial sensor controlled lighting background condition vs mobile robot board camera capabilities pose vs motion gesture recognition rate important keep mind advantage disadvantage task dependent 

proposed framework goal proposed thesis comprehensive multi modal human machine interface allows non experts conveniently compose robot programs 
robot programming approaches framework offers intuitive interface user ability provide interactive feedback coach robot programming process 
demonstrate generality proposed framework system implemented personal mobile robot manipulator 
specifically consider tasks interactive vacuum cleaning personal robot welding manipulator 
input modalities hand gestures spontaneous speech 
proposed thesis includes gesture speech recognition component focus primarily online adaptation reinforcement gesture models word models interpretations resulting comprehensive interface 
user sensor input acoustic input multi modal recognition module trainer speech db gesture db gesture symbol param word symbol param intention interpretation module trainer semantic db action db framework composed functional modules illustrated 
module multi modal recognition translates hand gestures spontaneous speech structured symbolic data stream abstracting away user intent 
second module intention interpretation selects appropriate primitives user input current state robot sensor data 
third module prioritized task execution selects executes primitives current state sensor input task previous step 
module includes modes operation learning execution mode 
depending mode operation system provide interactive robot control creation adjustment primitives composition robot programs 
subsections describe functions module discuss cooperate solve problems 

multi modal recognition module function multi modal recognition module circled translate hand gestures spontaneous speech structured symbolic data stream abstracting away user intent 
symbols gestures words 
consider sub functions 
module needs translate incoming audio gesture signals structured stream word gesture unit symbols appropriate parameters 
second module needs able adapt new users reinforcing symbols recognition 
module needs able add new vocabulary line 
prioritized task symbol param prioritized execution module trainer task db primitive db motor sensor sensori motor robot parameters sensor reading control vector proposed framework multi modal interface info manager personal robot manipulator sensor reading user sensor input acoustic input multi modal recognition module trainer speech db gesture db gesture symbol param word symbol param intention interpretation module trainer semantic db action db function module translate incoming audio gesture signals structured stream word gesture unit symbols appropriate parameters 
appropriate parameters gestures defined system designer 
examples parameters direction velocity hand gesture designated coordinates floor pointing gesture 
types input modalities discussed proposal human voice parameterization hands sensor 
modalities added substituted current recognition module 
process data translation important away user intent 
parameters structured symbol stream contain valid information recognized symbol module probabilistic recommendation recognition symbols module hard decision 
module considered lower layer multi level decision process 
similar tactic employed speech visual recognition problem final interpretation sensor data probability propagated layers higher level knowledge model 
second function module adapt data new users reinforcing symbols recognition 
multi modal recognition module implemented stochastic method hidden markov models 
domain speech recognition line model adaptation reinforcement common 
domain gesture recognition lee xu implemented american sign language asl recognition system estimates hidden markov model parameters online dataglove baum welch re estimation algorithm 
third function module interactively add new vocabulary 
spoken language gestures standardized listed dictionary 
exist task dependent categorizations gestures exist categorizations generalize task independent implementation 
prioritized task symbol param prioritized execution module trainer task db primitive db motor sensor sensori motor robot parameters sensor reading control vector multi modal recognition module circle info manager personal robot manipulator sensor reading input candidate symbols handed gestures circle point open close turn power grasp precision grasp handed gestures cross speech vocabulary go start turn forward backward right left move go names yellow green robot sweep vacuum remember forget table initial gesture speech recognition candidates reasonable assume system capable recognizing new user gestures provide easy way register additional gestures 
implementation word spotting technique speech recognition limited scope problem hand gestures 
obvious research problems need addressed realizing functionalities module 
issue relates initial vocabulary system 
system trained recognize new gestures words module able recognize basic vocabulary 
table lists initial candidate gestures words basic vocabulary include 
natural language recognition trade generality words recognized recognition accuracy 
fewer words result higher accuracy loss generality 
hand gestures exist domain dependant lists including hand grasp categorization occupational taxonomy hand gestures vocabulary gestures describing spatial relationships structure motion 
taxonomies comprehensive application domain insufficient general gesture vocabulary 
right approach find essential starting gestures build vocabulary 
research issue efficient line addition cross modal vocabulary 
attempts automatically discover gestures kuno 
assumes persistent rhythmic hand motions intentional worth learning 
easier rely redundant input mode manage learning process 
instance speech signal learning process gestures vise versa 
research issue relates feature selection 
example features temporal data model gesture 
features include angles velocities acceleration finger joints dimensional position orientation hand 
order recognize abstracting away user intent module needs look features frequency repetition rhythmic gestures radius circular gestures line sight pointing gestures 
directly related kind parameters intention interpretation module 
type features translate temporal input structured stream symbols may different module needs perform intention interpretation 
user sensor input acoustic input multi modal recognition module trainer speech db gesture db gesture symbol param word symbol param intention interpretation module trainer semantic db action db 
intention interpretation module function intention interpretation module circled select appropriate primitives user input current state robot sensor data 
user input incoming stream structured symbolic data parameters multi modal recognition module 
current state system current working task 
robot sensor data abstracted version robot sensor stream 
mobile robots robot sensor data includes range sensor data distance closest obstacle robot global position velocity mobile robots 
manipulators robot sensor data includes effector position velocity joint space cartesian space contact data force torque tactile sensors available 
output module task symbol configuration robot primitives 
usage definition terms primitive task discussed section 
short primitive encapsulations low level robot behavior policy maps state system environment appropriate action particular task particular time additional parameters 
task robot program composed various primitives 
keep mind task consist sequence primitives single primitive 
fact user inputs mapped single primitive tasks give close interaction robot 
problem intention interpretation considered mapping problem stream user input robot sensor data correct robot task 
words intention interpretation considered selection correct policy 
valid interpretation particular task mapping built needs expandable truly capture intent 
mapping function stored semantics database database expandable adjust new mappings designed user 
prioritized task symbol param prioritized execution module trainer task db primitive db motor sensor sensori motor robot parameters sensor reading control vector intention interpretation module circle info manager personal robot manipulator sensor reading distinguishes proposed framework systems claims intention recognition 
unreasonable assume semantic database designer cover domain 
example intention recognition system yamada human robot cooperation system determines known trajectories human trying take initial trajectory data 
example gesture programming system intention recognition agents vote determine robot human gesture input 
cases system correctly determine intention user mapping exist database 
predefined intention mapping solution automatically discover intentional motion interactively add intentions 
proposed framework semantic database expanded interactive addition mappings 
interactive addition semantic mappings robot tasks done mapping objects names meanings demonstrated robotics researchers roy kawamura developmental psychologists 
common strategy user refer object contains concept wants map input modality give input mapping second input modality 
illustrative example interactive addition semantic mapping user point yellow cube hand gesture say yellow cube 
similar training samples red cube yellow sphere red sphere robot able learn word yellow corresponds chromatic property particular hue value mutual information gain word yellow came examples 
similarly proposed framework attempts line addition semantic database maps user input robot task 
illustrative example follows 
assume voice utterance go home maps mobile robot task primitive navigates home position user wants map hand gesture ok assumed recognizable recognition module task 
user train new mapping repeatedly saying go home making ok sign 
ideally semantic trainer map ok sign gesture behavior navigating home position 
particular example illustrates simple case new behavior created 
interesting mapping performed task primitive database described section 
primitives adjusted configured grouped similar techniques 
important aspect output intention interpretation prioritization tasks 
tasks treated equally 
example gesture word corresponds emergency high priority executed robot engaged task 
similarly high level task navigating point may require assistance user avoid obstacles dead ends 
purpose task needs associated priority 
schultz looked problem multi modal mobile robot interaction low priority task interrupted high priority task 
introduced context predicates act prioritized stack 
implementation gesture control mobile robot similar concept combine moving goal location assisted user move obstacles user sensor input acoustic input multi modal recognition module trainer speech db gesture db gesture symbol param word symbol param intention interpretation module trainer semantic db action db section 
added priorities primitives attributes primitives 
attributes low priority levels allowed change learning execution phases high priority attributes fixed 
strategy useful adapt changes environment 
question determine priority task needs explored 

prioritized task execution module prioritized task execution module circled functions 
arbitrate execute primitives current state sensor input prioritized task previous module 
second generate robot program task configuring primitives 
third generate new primitives copying modifying primitives similar underlying structures 
going function go concepts tasks primitives differ levels abstraction 
primitives encapsulations low level robot behaviors serve building blocks high level behaviors 
consist motor sensor sensori motor sm primitives 
motor primitives generate open loop behaviors depend sensor feedback 
mobile robots motor primitives include sensor independent acceleration turn beep directional motions 
motor primitives manipulators purely kinematic 
sensor primitives provide system observable sensor signals current robot position joint angles range sensor data bumper switch data 
sensori motor primitives generate closed loop behaviors guarded move wall navigation particular destination mobile robots 
sensori motor primitives thought pre tailored configurations motor sensor primitives 
task configuration primitives 
robot program consisting sequence primitives single primitive 
tasks stored database form prioritized task symbol param prioritized execution module trainer task db primitive db motor sensor sensori motor robot parameters sensor reading control vector prioritized task execution module circle info manager personal robot manipulator sensor reading state buffer markov chain fsm 
intention interpretation module requires access task data shares semantic primitive task databases task execution module shown 
important function task execution module task arbitration 
explained section intention interpretation tasks treated equal 
tasks different priority come prioritized task execution module module stack tasks execute priority 
scheme described event driven preemption event request intention interpretation module execute task triggers active switch running task lower priority higher priority 
allows user handle situations making emergency avoiding obstacle engaging task 
second function generate robot program task interaction 
basic approach take coaching strategy redundant input mode 
user sets module learning mode executes primitives sequentially system remembers sequence task 
obvious problems approach 
problem robot programs sequential due conditional branching loops 
desirable force user remember special gesture command system unintuitive 
second problem lack generality 
example user sequentially module register task navigating particular destination pointed gesture 
task useless particular destination 
user module know attribute generalized retaining important features task 
point navigate task goal coordinates set variable sequence primitives navigate needs retained 
similar approach attributes priorities hand coded module 
function generate new primitives copying modifying 
exhaustive clustering approach applying svd entire input output pair robot motion generate task independent primitives infeasible current approaches creating primitives appear task dependent 
feel task dependency causes problems long primitives extensible 
order match need user reasonable system designer prepare essential primitives serves template 
user may copy attach modify configure template primitives adjusting parameters supervisory gesture data 
defining essential primitives grupen pre primitives humanoid hand requires basis set motion sensing primitives robot cover entire configuration space 
simple extensible template primitives demonstrated section 
systematic approach design primitives exist task system designer provide basic set motor sensor primitives 
module input size function output size multi modal recognition intention interpretation prioritized task execution polhemus polhemus acoustic bit khz gesture symbol param gesture symbol param word symbol param robot data robot position robot velocity sensor readings 
knowledge current state robot status 
sensor readings 
task symbol priority param translate incoming audio gesture signals structured stream word gesture unit symbols appropriate parameters 
reinforce models recognition add new vocabulary line 
select appropriate primitives user input current state robot sensor data 
expand semantic database adjust new mappings user comes 
prioritization tasks database arbitrate execute primitives current state sensor input prioritized task previous module 
generate robot program task configuring primitives 
generate new primitives copying modifying template primitives similar underlying structures 
table functional summary proposed research attempt automatically generate primitives aims modify existing primitives interactively 
interactive generation primitive involves composing primitives different configurations adjusting parameters multi modal input 
shown schaal supervised reinforcement learning control policy correct underlying structure requires relatively little training data adaptation parameters interaction provide training data 
approach start primitive similar functionality 
quantitative measures similarity primitives human decision 

summary framework table summarizes functions offered modules proposed framework 
modules works synchronously continuous flow data provide intuitive multi modal interaction programming robots 

pre proposal section pre proposal implementations described show proposed modules partially demonstrated 
gesture control mobile robot demonstrated letting user operate mobile robot handed continuous gestures 
second demonstration gesture programming humanoid robot user transfer high level task descriptions gestures hands 
demonstration gesture control manipulator robot primitives adjusted interactively spotting gestures hands 
gesture symbol param 
gesture symbol param 
word symbol param task symbol priority param control vector 
position tracker gui server geolocation server environment server gesture server joint angle hand position orientation robot pos orientation motion vector destination go turn left wireless ethernet robot controller architecture gesture control camera camera 
gesture control mobile robot particular system experimented handed gestures control single mobile robot 
system capable spotting temporal handed gestures interpreting mode operation navigating mobile robot 
illustrates architecture illustrates demonstration performed single mobile robot handed gestures 
data glove electro magnetic dof position sensor provide reliable measurements position joints 
data glove measures joint angles fingers wrist hz 
polhemus dof positioning system consists transmitter receiver 
receiver placed user hand detects magnetic field emitted fixed transmitter inductively tracks relative position orientation 
due cables attached glove position sensor mobility user constrained 
envision technological advances wearable computing personal localization systems overcome data glove current limitation mobility 
developed gesture spotting recognition algorithm hidden markov model hmm 
hmms commonly model temporally spatially varying signals 
successfully applied field speech handwriting recognition applied gesture recognition 
readers unfamiliar hmms refer rabiner juang excellent tutorial evaluation estimation decoding hmms applied problem speech recognition 
purposely term spotting addition recognition emphasize importance spotting gesture sequence data containing gestures non gestures 
able reject motions correspond predefined gestures important 
stream motion data classified gestures motion fingers result inadvertent robot actions 
including classification allows user perform tasks wearing data glove hmm interpreting hand motions robot commands 
new data point continuous stream gesture control single mobile robot gesture image sequence left right description pointing measurements vector quantizer discretize features codewords hmm recognizer determines gesture currently executed 
preprocessing data gesture spotter takes sequence codewords determines gestures user performing gesture executed 
gestures chose recognize consist described table 
developed gesture spotting recognition algorithm hidden markov model hmm 
hmms commonly model temporally spatially varying signal 
successfully applied field speech handwriting recognition applied gesture recognition 
readers unfamiliar hmms refer rabiner juang excellent tutorial evaluation estimation decoding hmms applied problem speech recognition 
purposely term spotting addition recognition emphasize importance spotting gesture sequence data containing gestures non gestures 
able reject motions correspond gestures important 
stream motion data classified gestures listed motion fingers result inadvertent robot actions 
including classification allows user perform tasks wearing data glove hmm interpreting hand motions robot commands 
new data point continuous stream measurements vector quantizer discretize features codewords hmm recognizer determines gesture currently executed 
preprocessing data gesture spotter takes sequence codewords moving open hand index finger pointing closed fist index finger pointing opening moving closed fist flat open hand opened flat open hand closing waving left waving right table handed gestures moving flat open hand closed fist fingers extended waving left directing left fingers extended waving right gestures policy pointing accelerates robot current direction opening opened maintains current state robot closing eventually stops robot left increases rotational velocity move left right increases rotational velocity move right table local control mode policy determines gestures user performing gesture executed 
gestures chose recognize consist described table 
particular gesture recognized needs interpreted corresponding robot action 
system spots gesture gesture interpreter extracts important parameters palm direction velocity position user pointing 
depending mode operation local global control gestures mapped different robot actions table table 
local control mode user gestures interpreted robot local frame 
instance pointing robot move forward regardless robot facing away user 
purpose local control mode allow user control robot remote operation scenario 
user watches video image transmitted robot camera controls robot sitting 
global control mode hand position hand measured universal coordinate frame allowing interpret gestures respect global frame 
mode supports scenario robot sight user user point finger specify destination robot give additional guidance waving gesture 
board controller takes role prioritized task execution module architecture 
desired velocity vector desired position generated interpreter sent robot converted linear angular velocities 
desired position sent robot board proportional controller servo desired position 
prioritization takes place desired velocity vector sent robot robot navigating desired position 
example case gesture avoid obstacle issuing pointing gesture set destination point 
due prioritization robot continues navigate destination linear angular velocity commands issued 
illustrates pre proposal fits proposed framework 
architecture different appearance underlying flow recognition interpretation execution 
compared proposed framework improve ways gestures policy pointing move position pointed opening opened maintains current state robot closing eventually stops robot left right directs robot direction hand waving 
table global control mode policy bend sensors dof position sensor polhemus multi modal recognition module gesture symbol parameters intention interpretation module multi modal recognition module speech recognition capability line addition adaptation reinforcement vocabularies intention interpretation module additional interpretations current local global control modes prioritized task execution module programming capability addressed 
addition adaptation reinforcement primitives 
gesture programming humanoid robot addition control mobile robots applied gesture spotting aid transferring manipulation tasks humanoid robot 
objective construct human behavior model attention point ap analysis 
ap analysis consists steps illustrated 
step broadly observes human behavior constructs rough human behavior model finds aps time axis require detailed analysis 
second step enhance human behavior model applying time consuming observations aps 
human behavior model highly abstracted able change degree abstraction adapting environment applicable different environment 
am going describe focusing gesture recognition intention interpretation features 
refer full description 
prioritized task symbol parameters prioritized execution module current position velocity sonar ir reading stereo acoustic video info manager sensor readings user robot trainer semantic db primitive db gesture db motor sensor sensori motor control vector gesture control proposed framework overhead camera attention point analysis performance humanoid robot user interaction system multi modal including gestures vision 
rough observation step ap analysis hands spot gestures find aps 
aps provide temporal indexes tend detailed analysis second stage 
detailed analysis second stage robot template matching dtm process uses depth image generated eye system recognizes object handled user 
dtm process run real time aps designate 
list gestures handled gesture spotting system ap analysis described table 
difference gesture spotting system previous system section closely resembles speech recognition 
gesture spotter implemented hidden markov model toolkit htk freely available software development kit speech recognition research 
provides range functionalities necessary speech recognition research data collection model estimation line recognition evaluation 
gesture composition smaller gesture particles similar phonemes speech particle modeled statistically hmm 
improve recognition accuracy simplify training grammatical rules imposed gesture sequence 
aps stage dtm applied recorded depth images aps 
dtm finds details object types locations necessary construct human behavior model 
robot performs task constructed human behavior model environment may differ environment demonstration took place 
task performance differences environment handled system intention interpretation prioritized attributes table 
priorities help system determine user intent letting low priority attributes vary depending environment keeping high priority attributes fixed 
example shown demonstrates robot performance task slightly different environment 
robot performs task pouring water jar opposite hand accommodate difference object locations 
sp network level hmm level observations gesture particles gesture release summary demonstrated novel method construct transfer human behavior model attention point analysis humanoid robot 
method followed basic step framework recognition interpretation execution outlined proposal 
list possible improvements system multi modal recognition module speech recognition capability line addition adaptation reinforcement gesture vocabularies intention interpretation module line adjustment prioritized attributes different interpretations demonstrated task interactively switch demonstration execution mode coach robot mistake interpretation prioritized task execution module adjustable motor primitives start power grasp precision grasp pour hand ok garbage ok release release gesture grammar gestures gesture particles action power grasp cls sp power grasp open position precision grasp prc sp precision grasp open position pour cls roll sp power grasp roll wrist hand prc forw sp precision grasp move forward back release sp open grasp hand ok ok sp circle thumb index finger garbage gb filler model spotting start sil silence start table gesture definitions attributes priority value time stamp low absolute time start time action symbol high power grasp precision grasp release pour hand hand right left position absolute position space object model type manipulated object table attributes hand actions 
gesture control manipulator applied gesture spotting interpretation demonstrate interactive adjustment robot primitives manipulator 
line robot programming demonstration previous section experiment focuses line interaction user robot 
set gestures pointing closing releasing rectangle sign motor primitives generalized ellipse drive manipulator elliptical rectangular trajectories 
module framework demonstration shown 
gesture recognition module implemented hidden markov model toolkit htk spot set gestures pointing closing releasing rectangle sign 
implementation similar previous section 
intention interpretation module takes gestures parameters position hands maps various adjustments described table 
execution module motor primitives follow generalized ellipse trajectory 
generalized ellipse trajectory primitive template trajectory generator takes parameters center position radius angular velocity major minor axis tilt angle 
time gesture interaction manipulator interpretation move center user bend sensors dof position sensor polhemus gesture recognition module trainer gesture db gesture symbol parameters intention interpretation module semantic db intention interpretation module particular interest gesture sequence handed pinch release map different adjustments generalized ellipse trajectory primitive table rows 
module records positions hands pinch gestures occur hands 
positions release gestures occur interpretation 
example move center interpretation table row hands move direction 
move opposite direction result modify radius row modify angular velocity row interpretation depending movements line 
intention interpretation successfully demonstrated expressing interactive functions small set gestures primitives 
possible improvements system summarized list multi modal recognition module speech recognition capability line addition adaptation reinforcement gesture vocabularies intention interpretation module reinforcement correctly mapped intention prioritized task execution module ability sequence primitives turn task primitive symbol parameters prioritized execution module primitive db motor robot parameters sensor readings info manager chimera rtos control vector joint angles torques sensor readings robot gesture control manipulator proposed framework gesture interpretation default circular motion modify angular velocity modify length radius move center tilt major minor axis switch rectangle image sequence left right description table interpretations handed gestures pointing gesture manipulator draw circle default center major minor axis angular velocity 
closed fist gesture stops manipulator motion handed pinch turn release cause manipulator accelerate decelerate angular velocity handed pinch stretch shrink release modify radius circular motion handed pinch translation circular motion handed pinch plane tilt axis circular motion rectangle gesture hands switches circular motion rectangular motion 

research issues providing intuitive means program robot system challenging problem requires improvements user interfaces intention interpretation behavior representations 
proposed research addresses problems combination multi modal user input interactive learning 
group research issues categories multi modal interaction understanding gesture vocabulary spatial interaction interactively extending gesture vocabulary cross modal interaction feature selection interactively assigning meaningful parameters gesture intention recognition representation intentions prioritized attributes semantic database interactively extending range intentions recognized extracting task priorities user intentions prioritized task execution representation task configuration prioritized primitives representation primitive parameterized template control policy 
expected contributions thesis contributions human robot interaction robot programming 
expected contributions improved human robot interaction simultaneous training execution framework novice friendly robot interaction novel approach incrementally register intentions 
implementation demonstration proposed framework control program robot hand gestures speech personal mobile robot manipulator 

research plan schedule order cut implementation time stage designed supplement stage 
development investigation modules move parallel 
time system mobile robot manipulator expected able demonstrate early form final proposed framework 
dates description apr proposal summer fall spring summer multi modal recognition default set speech gesture vocabulary spatial human robot interaction intention interpretation representation intentions prioritized attributes semantic database prioritized execution default set primitives templates span task space representation primitives tasks database multi modal recognition online addition gesture learning cues speech online reinforcement gesture model intention interpretation online association user input action mutual information gain prioritized execution parameter adjustment primitives interaction multi modal recognition interactive assignment meaningful parameters new gestures add cross modal cues interaction intention interpretation interactive specification adjustment task priority prioritized execution creation new primitives copy paste adjust primitive programming task set primitives sequencing means evaluation implemented framework interactive programming control personal mobile robot vacuum cleaning task manipulator arc welding non contact manipulation contact task fall writing buffer january defense nourbakhsh path planning personal robot ieee rsj international conference intelligent robots systems iros japan pp 

gross neural architecture gesture human machine interaction gesture sign language human computer interaction bielefeld germany pp 

coelho grupen developing haptic visual perceptual categories reaching grasping humanoid robot ieee ras international conference humanoid robots cambridge ma usa 
cutkosky grasp choice grasp models design hands manufacturing tasks ieee transactions robotics automation vol pp 

fong conti baur novel remote driving gesture haptic pda spie telepresence technologies vii boston ma 
gertz khosla iconic language reconfigurable sensor control systems annual meeting american nuclear society papers summary form received new orleans la usa pp 

giszter chapin neurobiological approaches control architecture humanoid motor system ieee ras international conference humanoid robots boston ma 
iba paredis khosla architecture gesture control mobile robots ieee rsj international conference intelligent robots systems iros korea pp 

ikeuchi assembly plan observation part iii assembly task recognition general case robot learning 
jelinek statistical methods speech recognition 
cambridge mass london mit press 
te te dai han 
ed 
tokyo 
japanese kang ikeuchi robot task programming human demonstration rd image understanding workshop monterey ca usa pp 

kawamura alford wilkes unified framework human humanoid interaction ieee ras international conference humanoid robots boston ma 
kimura ikeuchi task model human robot cooperation vision ieee rsj international conference intelligent robots systems iros korea pp 

kortenkamp huber bonasso recognizing interpreting gestures mobile robot national conference artificial intelligence portland usa pp 

kuno shimada shirai interactive gesture interface intelligent wheelchairs international conference multimedia expo new york ny usa pp 

lee xu online interactive learning gestures human robot interfaces ieee international conference robotics automation minneapolis mn pp 

lee kim gesture spotting continuous hand motion pattern recognition letters vol 
pp 

asada hand glove human machine interface interactive control task process modeling dual petri nets ieee international conference robotics automation leuven belgium pp 

matsumoto zelinsky algorithm real time stereo vision implementation head pose gaze direction measurement fourth international conference automatic face gesture recognition grenoble france pp 

morrow khosla manipulation task primitives composing robot skills ieee international conference robotics automation albuquerque nm usa pp 

nishimura oka adaptation gesture performers line teaching system spotting recognition gestures time varying image transactions institute electronics information communication engineers ii vol 
ii pp 

japanese iba sato kimura ikeuchi recognition human behaviour stereo vision data gloves vol 
pp 

nakamura telerobotics system planning functions manipulation skills teaching demonstration technique vr journal robotics society japan vol 
pp 

japanese oviatt taming recognition errors multimodal interface communications acm vol 
pp 

schultz adams integrating natural language gesture robotics domain ieee intelligent control computational intelligence robotics automation intelligent systems semiotics isas joint conference gaithersburg md pp 

schultz adams marsh goal tracking natural language interface achieving adjustable autonomy ieee international symposium computational intelligence robotics automation pp 

quek vision hand gesture interface virtual reality system technology conference singapore pp 

rabiner tutorial hidden markov models selected applications speech recognition proceedings ieee vol 
pp 

roy pentland word learning multimodal environment ieee international conference acoustics speech signal processing seattle wa usa pp 

interactive task training mobile robot human gesture recognition ieee international conference robotics automation detroit mi usa pp 

schaal nonlinear dynamical systems movement primitives international conference humanoid robotics cambridge ma 
primitive control utah mit hand ieee international conference robotics automation pp 

starner pentland real time american sign language recognition video ieee international symposium computer vision pp 

virtual infant ed 
japanese todd fundamentals robot technology industrial robots teleoperators robot vehicles 
new york wiley 
khosla bekey cognition interpretation context dependent gestures ieee international conference robotics automation albuquerque nm usa pp 

khosla multi agent system programming robotic agents human demonstration artificial intelligence manufacturing state art state practice workshop albuquerque nm usa pp 

khosla gesture programming preliminary demonstration ieee international conference robotics automation detroit mi usa pp 

morrow khosla gesture programming robotics human augmented software adaptation ieee intelligent systems vol 
pp 

romero thrun gesture interface interaction autonomous robots vol 
pp 

xu yang human robot coordination skill modeling transferring hidden markov model ieee international conference robotics automation pp 

yamada sakai construction human robot coexistence system model human intention desire ieee international conference robotics automation detroit mi usa pp 

young woodland byrne spontaneous speech recognition credit card corpus htk toolkit ieee transactions speech audio processing vol 
pp 


