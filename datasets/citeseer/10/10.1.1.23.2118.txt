master slave computing grid gary shao department computer science engineering university california san diego san diego ca cs ucsd edu berman department computer science engineering university california san diego san diego ca berman cs ucsd edu rich wolski department computer science hall university tennessee knoxville tn rich cs utk edu resource selection fundamental performance master slave applications 
address problem promoting performance distributed master slave applications targeted distributed heterogeneous grid resources 
rate model master slave application performance utilizes system application characteristics select potentially performance efficient hosts master slave processes 
grid allocation strategy performance model demonstrate performance improvement selection options representative set master slave applications simulated actual grid environments 

master slave paradigm fundamental commonly approach parallel distributed applications 
master slave applications single master process controls distribution set identically operating slave processes 
master slave paradigm successfully wide class parallel applications suited programming model supported part nsf asc darpa ito contract npaci award asc supported part nsf asc darpa ito contract npaci award asc applications targeted distributed heterogeneous grid resources 
methods improve performance master slave applications considerable interest people 
researchers application developers previously experimented tuning granularity master slave processes balance computation communication varying parameters number complexity tasks assigned slaves varying number slave processes 
note homogeneous environment processor reasonably chosen master slave resources typically considered equivalent 
heterogeneous grid environment non uniformity peak deliverable capacities computational communication resources produce different application execution times depending processor chosen master processors chosen slaves 
address problem determine performance efficient placement master slave processes running shared distributed heterogeneous environments 
heterogeneous environment choice processor master significant effect total available rate directly impacting application performance 
strategy selecting location master process involves identifying host processor allows largest aggregated system rate define section 
strategy selecting slaves utilizes performance capacity available computation communication resources determine performance efficient collection workers 
organized follows section provides performance model distributed master slave applications 
section describes obtain input parameters calculating resource capacity values performance models 
section describes algorithm selecting resources master slave processes 
section gives representative set performance results experiments section includes short discussion related section provides summary 

master slave performance model consider model master slave applications primary function master process pass collect set slave processes assume communication patterns simple defined requiring communication master process individual slave processes 
define application divisible set tasks task may require input data produces output data 
tasks completed application progressing stages master slave computation stage transmission command initiate task slave processes including data needed slave perform computation 
stage execution task designated slave 
stage transmission results slave back master 
stage immediate processing task results slave done master 
passing stage computation particular system resource employed task period time task move stage 
example consider simple network topology shown 
processor designated master process task intended slave processor stage employ network net transfer required data processor processor stage task utilize processor time run task computations 
stage task utilize network net transfer result data stage task utilize processor time process incoming results prepare initiating additional task transfers straightforward extend case master may perform slave 
net net net 
example network configuration 
constructing performance model master slave applications look rate applications process tasks 
rate application cycles tasks measure application performance faster cycle rates correspond directly reduced application execution times 
consider flow tasks master process slave process definition task completion rate occurring master slave units tasks unit time 
master slave computations communication different slave processes total rate task completions application sum rates arising task completions individual slaves 
define equation rate task completions application master process set slave processes define execution time application master process set slave processes tasks total number tasks application 
tasks application performance derived values 
way solve values consider system resource constraints bound achievable application performance 
illustrate concept go back simple example system observe processor network labeled numerical values 
define numbers diagram represent resource capacities terms tasks unit time 
values network links represent network capacity network link upper number circle represents slave capacity processor lower number circle represents master capacity processor 
consider application uses processor host master process 
solve application performance determine values 
fundamental constraint condition meet total task flow rates resource exceed capacity value resource 
means task flow processor processor passes network net example sum capacity net 
general define resource capacity terms processor network resources 
terms rates units tasks unit time 
maximum master rate supported processor determined processor capacity perform stage computations specified application 
maximum slave rate supported processor determined processor capacity perform stage computations specified application 
wnet maximum communication rate supported network determined network capacity perform stage stage communication specified application 
assuming graph representing network connectivity diagram allows identify network resources shared different task flows resource capacity rates resources system form set upper bounds possible values 
process network connectivity graph capacity rate terms derived resources grid environment discussed section 
aid defining upper bound constraints define helper set constructor function takes input network connectivity graph set slaves processes master process network resource returns set slave processes share network resource communicating master slave applications easily determined network graph master process set slaves network resource single path graph slave process master process recording path passing resource give bounds form constraints application performance shown wnet goal find values meet constraints yield largest value 
solution correspond configuration delivers best achievable application performance 
frame problem determining values yield largest value flow rate problem values flows wish solve sink flows set slave processes sources flows flow constraints correspond wnet capacities target environment 
flows master slave computation form tree rooted master limited investigation considering process hosted processor efficient algorithms maximum flow algorithm exist solving problem 
approach solve flow rate problem candidate processes finding expected deliver maximum flow best expected application performance 
section describes implementation maximum flow algorithm find largest possible flow 

modeling capacity rates grid environment order apply flow performance model real applications running grid environment derive network connectivity graph appropriate values capacity rate terms wnet 
flow rate algorithm determining application performance requires graph represents network connectivity processor resources 
wide area consider cases processors host process application allow process identifier identifier processor hosting inequality expressions 
input description data acquired acquired graph net network connectivity env periodically cpu slave task time benchmark install cpu master task time benchmark install cpu availability nws run time size task data transfer size wnet analysis application logging bw net network bandwidth wnet nws run time table 
inputs constructing performance model 
grid environments difficult get complete physical network configuration data platform system 
reasonable represent target computational resources interconnection logical view captures areas network constraints potential bottlenecks application performance 
derive logical view resource interconnection logical network configuration discovery tool called effective network views env 
systems discovery effective system topology 
output env tool network graph representation processor belongs cluster machines 
machines cluster connected local network capacity local network represents limiting capacity network resource shared machine cluster 
clusters local networks connected logical representation single layer nonlocal network links 
representation suitable graph analysis techniques maximum problem directly translates network graph flow rate solution 
processor capacity rates model determined components application specific component representing maximum performance delivered processor resource unloaded state dynamic component determined run time adjust capacity rates account current loading conditions 
applicationspecific component obtained running benchmark target application code unloaded processor measuring times required compute single task processor type slave master processes respectively 
task computation time variable time data dependencies application take average value task times run application benchmark 
value scaled particular classes data sets run time variation average task run times large different data sets 
benchmark times measured platform type application built run obtaining values computationally efficient 
dynamic component capacity terms processor resources calculated help real time monitoring forecasting services network weather service nws :10.1.1.46.3287
nws provides real time predictions dynamic processor availability percentage cpu time process expect get processor 
describes predicted availability status processor resource generated independently particular application 
enables single nws system provide simultaneous service applications requiring real time information resource behavior 
processor capacity rates calculated application specific dynamic components shown 
input parameters functions summarized table 
network capacity rate wnet model calculated components 
component application specific term size represents amount data transferred master process slave process task application 
task data transfer sizes variable quantity time due data dependencies application calculate average data transfer value represents expected steady state communication behavior time entire application run 
second component calculating network capacities network resource dynamic prediction expected available network bandwidth bw net obtain nws 
network capacity rates calculated application specific dynamic components shown 
input parameters summarized table 
wnet bw net size having constructed set resource constraint values help model performance grid environment discuss obvious limitation approach 
terms derived section generated average value expression steadystate application performance model 
properties modeled reality exhibit considerable variability time due time varying load conditions data dependent behavior application run 
experience despite limitations converting variable terms average steady state values approach yields performance model job estimating application performance provides effective tool helping solve resource selection problem discuss 

selecting master slaves rate performance model described section logical representation capacities grid resources consider strategies selecting processors host master slave processes 
important issues master slave applications running grid environments users may able choose different types resources availability resources may change time 
selection right processor host master process significantly impact application performance section show 
knowing master placement produces best application performance influence important decisions efficiently position input output files application 
selection right set processor resources host slave processes goals selecting resources available set produce best achievable application performance limiting selection resources benefit application performance 
second goal important grid environments resources shared users resources owned managed different organizations 
environments desirable applications resources really need allowing limited pools shared resources satisfy largest number users 
consider issue selecting right host master process 

master selection example heterogeneous system selection location master process strongly depends deliverable capacity candidate resources 
consider logical grid configuration shown back processors connected system networks 
labeled network resources values representing wnet capacity terms 
processor resources shown circles diagram labeled values capacity term top capacity term bottom 
capacity terms units tasks second 
simple example system determine assignment master process processor gives greatest achievable flow 
processor selected host master process processor able provide tasks sec rate slave 
addition maximum tasks sec worth data transferred network net rate supplied processor total expected application rate processor hosting master tasks sec 
consider selecting processor host master process observe processor deliver rate tasks sec working slave 
addition transfer maximum tasks sec worth data network net supplied processor apparent processor constrained achieving higher application rate limitations net capacity capacity processor serve master host tasks sec 
proceed similar manner processors derive expected application rates candidate 
table shows set possible outcomes process 
apparent column table processor best choice yielding potential application rate tasks sec 

selecting master generally developed basic algorithm finding best performing host master process 
known maximum flow algorithm ford fulkerson 
algorithm keep augmenting estimated flow rate master host adding master location table 
rates resulting master placement decision 
contributions slave processors 
additional contributing slaves selected local network master 
continues slaves included slave rates incorporated capacity limitations network resources capacity limitations master processor 
capacity available processors non local networks added accumulated master total additions possible exceeding resource capacities 
illustrates basic algorithm finding best performing master host 
termination algorithm processor highest calculated rate selected master 

complexity deriving complexity algorithm note simplified logical representation network configuration reduces entire system sets processors connected local networks 
local networks connected local networks level remote networking 
logical topology data transfers slaves local network pass level networking encounter network resource constraint 
data transfers slaves located different local networks pass levels networking satisfy networking constraints 
slave rates meet resource constraints master processor 
arrangement tests constraints algorithm checked master slave pairing 
processors system master candidate slaves individual master rate calculation takes time calculate 
calculating maximum rates possible master candidates takes time 
algorithm requires simple compare accumulation operations resource constraint test entire algorithm efficient numbers processors networks currently find grid environments available typical user 

selecting slaves selecting master processor turn selection slave processors 
issue select set processors hosting slave processes deliver aggregate performance 
approach start set slave processors master selection algorithm yielded highest expected application performance 
algorithm keeps track set list list containing slaves algorithm calculate maximum rate application processor master host 
master selection algorithm ensures set processors results flows fall constraints imposed resource capacity limitations 
numerous experimental trials set processors slave hosts observed slave processors delivering maximum rate values expected algorithm 
observations selected slaves showed reduction slave performance due presence unaccounted idle time periods time slave processors doing useful 
explanation observed idle times comes observing manner tasks distributed slave processors master 
master slave application tested maintained queue available tasks master process distributed new tasks individual slave processes request commonly technique contention shared resources networks master processor delays occurred time slave processor finished task time task appeared processing 
delays appeared idle time observations slaves 
minimum set slaves selected achieve desired rate unexpected idle time slaves resulted reduction actual total rate achieved 
flow rate performance model correctly determines possible application performance resource capacity limits 
master selection algorithm uses performance model process identifies set slaves delivers performance assuming slave delivers maximum rate 
experimentation shown slaves deliver predicted maximum rates resulting networks calculate maximum network capacity wnet processors calculate maximum master processor capacity calculate maximum slave processor capacity candidate master processor local network set sum candidate slave rates set set empty networks set network utilization sum til get maximum capacity wnet local network get maximum master processor capacity wnet select new processor local network largest available value get slave processor capacity get fraction cause utilization til exceed wnet add add til add processor set total candidate rate min total local network utilization til wnet select new processor outside local network largest available value get slave processor capacity get fraction cause utilization til exceed wnet network add add til add til network involved communications processors add processor set select processor largest master 
algorithm finding best processor master 
formance resource capacity constraints allow 
way get application performance back predicted levels add additional slave processors originally selected mix raising effective slave rates achieved expected values 
goal compensate lost performance due idle time individual slave processors keeping number additional processors minimum needed accomplish goal 
steady state flow rate performance model useful helping decide slaves add increase effective performance account idle times caused slaves waiting new tasks arrive 
address shortcoming steadystate approaches performance analysis developed master slave application performance simulator provide significant new capabilities 
discuss simulator help solve slave selection problem subsections 

application performance simulator originally developed master slave application performance simulator provide detailed predictions performance resource behavior applications running grid environments 
effective simulator help determine additional slave processors added predicted group master slave processors performance losses due slave idle time 
core simulator set routines model behavior tasks pass system comprised kinds resources processors networks 
resources modeled single servers input queues 
service times processor resources determine long task control processor relinquishing resource task input queue dependent processor availability parameters estimated task execution times developed earlier flow rate model 
service times network resources determine long network resource committed servicing data transfers task dependent network bandwidth parameters bw net size data transfers values size developed flow rate model earlier 
addition parameters adjusted static steady state values performance model dynamic data inputs statistical distributions actual measured trace values application runs 
network connectivity represented graph output env tool flow rate performance model 
simulator written highly portable language code help simulation library package called sim 
simulator easily embedded programs application scheduler provide detailed predictions application performance resource utilization levels 
particularly useful observing performance impact changing application resource parameters 

simulation enhance slave selection algorithm finding correct set slave processors starts master processor set slaves master selection algorithm 
simulator run machines target environment values resource capacities master selection algorithm 
results simulation checked see idle time simulated slaves results significant decrease application performance 
substantial performance decrease resource utilization figures simulation checked see additional processors added exceeding existing resource constraints 
slave processors available added violate known resource constraints added set slaves 
new system configuration additional processors added constructed simulated 
process slave additions testing simulation repeats performance gains realized adding slave processors processors placed exceeding known resource capacity constraints 
illustrates algorithm finding set slave processors 
algorithm simulator results calculate predicted resource utilization values resource system 
values allow quickly identify system slave processors added improve application performance 
practice number times simulation cycle needs run small process quickly converges situation additional performance gains insignificant additions exceeding resource constraint 

experimental results section describe experiments goal test usefulness accuracy rate performance model application performance simulator performance algorithms selecting master slave processors 
run master selection algorithm get master processor set slaves predicted application rate run application performance simulator get simulated rate slave utilization values check slaves large simulated idle times find additional processors idle time exceeding wnet constraints add processors form run simulator processors get new simulated rate slave utilization values return slave solution set equal equal set equal return slave solution 
algorithm finding best processors slaves 
application test suite applications chosen represent spectrum potential master slave distributed applications 
applications selected implemented test sensitivity approach computation communication granularity 
master slave implementation mandelbrot image application expected display relatively high sensitivity communication constraints amount image data transferred execution large compared computation time 
extreme nas parallel benchmarks ep application performs relatively little data transfer compared time spent computing 
povray ray tracing application falls middle transfer fourth amount image data mandelbrot application spread longer computation time 
applications initially benchmarked target processor types produce application specific parameters needed performance analysis tools 
applications summarized table 

experimental design experiments compared predicted execution time resulting performance model simulated execution time application simulator actual execution time determined experimental runs 
comparisons non dedicated environment load traces predicted simulated execution times determined nws load trace actual execution time runs 
identical parameter inputs network configuration resource constraints application characteristics flow analysis performance simulation tools 
way attempted compare set execution times environmental conditions 
target experimental platform heterogeneous mix intel processor machines running linux sun sparc machines running solaris located parallel computation laboratory department computer science engineering university california san diego 
experiments run machines non dedicated mode outside loading name description emphasis mandelbrot parallel fractal image generator communication povray parallel implementation popular ray tracer nbp ep nas parallel benchmark ep variant computation table 
list applications experiments 
ing jobs observed relatively light machines course experimentation 

results set experiments ran test suite applications set workstations shown table 
applications trials run processors selected run master included run slaves 
cases flow rate problem solved configuration master slaves give expected application execution time shown light bars figures 
application performance simulator run cases give predicted application execution time shown middle bars graphs 
real applications run configuration execution times recorded appear dark bars graphs 
shows results running relatively communication heavy mandelbrot application 
shows set execution times balanced povray application shows execution times computation intensive nas parallel benchmarks ep application 
experiments rate performance model done job identifying correct master host produce fastest application execution times 
mandelbrot series experiments machine thing calculated yield lowest execution time confirmed actual application run 
application highest execution time achieved machine named took longer finish best choice 
applications rate performance model estimates execution time showed results correlated closely actual application run times 
applications exhibited lower dependence network constraints differences worst best performers smaller povray nas ep 
rate performance model correctly ordered master performance communication computation constrained applications 
results show application performance simulator job tracking actual application execution times 
experimental results show small number cases execution time significantly underestimated mandelbrot application 
analysis experimental results leads believe discrepancy predicted actual performance communication heavy application due inadequate benchmarking constraint terms 
actual application performance worse predicted flow model simulator tools overestimated capacity single master process process incoming data respond new task requests 
real master process fails keep projected rates application rate reduced execution time relatively larger 
improved methods benchmarking master processor performance currently developed overcome shortcoming 
second set experiments look applications mandelbrot povray 
trials pick specific host master process run application different numbers slave processes 
show measured execution times simulated execution times applications increase number slave processors 
shows results mandelbrot application different choices master host 
results show number slaves beneficially employed varies different conditions heavily constrained network speed master process host 
shows results povray application performance dominated communication costs 
test environment application shows scalable performance mandelbrot eventually reaches point additional processors significantly decrease execution time 
results shown master case data cases produces identical graphs 
results third application npb ep shown similar povray simulation predicted run times actual application run times close numbers processors 
results indicate representative examples performance simulator useful tool help predict points additional slaves added computation increase performance additional slaves cease useful effect 
tandem sojourner thing hosts master selection results mandelbrot analysis simulation application 
execution time communication intensive application varying master host 
tandem sojourner thing hosts master selection results povray analysis simulation application 
execution time application varying master host 
tandem sojourner thing hosts master selection results npb ep analysis simulation application 
execution time computation intensive application varying master host 
name processor network os intel pentium pro mbit ethernet linux sun ultrasparc iii mhz mbit ethernet solaris sun ultrasparc mhz mbit ethernet solaris sun ii mhz mbit ethernet solaris intel pentium pro mbit ethernet linux intel pentium ii mbit ethernet linux sojourner intel pentium ii mbit ethernet linux tandem intel pentium ii mbit ethernet linux thing sun ultrasparc mhz mbit ethernet solaris table 
partial list heterogeneous mix machines experiments 

related different approaches predicting performance parallel applications distributed memory machines appeared literature 
partial summary earlier efforts 
unfortunately approaches suffered limited accuracy real world conditions caused making simplifying assumptions excessive complexity constructing models 
approach performance prediction focuses achieving useful levels prediction accuracy limiting model complexity allowing efficient measurement quantification important model parameters 
application performance prediction problem resource selection addressed weissman zhao :10.1.1.47.2751
weissman zhao heuristics select number candidate configurations employ cost functions derive computation communication times configuration 
select configuration yielding lowest total cost 
approach resource selection efficiently evaluates application performance different configurations simple constraint calculations 
lieu lowekamp looked automatically selecting processor nodes applications running high speed networks 
results lieu lowekamp algorithms allow automatically select nodes different goals maximizing computation capacity maximizing communi number slave processes execution time sec slave selection mandelbrot application sojourner master simulation sojourner master application tandem master simulation tandem master 
application performance varying numbers slaves 
cation capacity balancing computation communication 
explain correct goal selected match specific application characteristics order give optimum performance 
approach automatically determines performance bottlenecks computation communication constraints finds best performing configuration cases 

summary described rate performance model master slave applications running distributed heterogeneous processors networks 
parameterizing steady state performance model dynamic run time information able accurately predict maximum achievable application performance rates cases application characteristics resource behavior steady time 
described application performance simulator accurately simulates dynamic interaction master slave application defined configuration performance constrained resources 
simulator allows detailed analysis performance bottlenecks due resource limitations may occur application 
kind detailed information applications interact resources grid environment valuable resource selection application runtime advanced application platform planning program number slave processes slave selection povray application tandem master simulation tandem master 
application performance varying numbers slaves 
development activities 
key success performance prediction tools identification common set application resource parameters quantified measured captured static dynamic aspects application performance grid environments 
effectiveness performance prediction tools developed algorithms master slave resource selection grid platforms 
algorithms enable selection master processor set slave processors allow maximum application performance occur 
achieving maximum application performance dynamic grid environments may require run time techniques handle issues load balancing fault tolerance 
issues actively researching subject publications 
brief experimental data verify performance prediction tools strategies selecting master slave resources sound 
currently integrating performance tools resource selection strategies apples grid application scheduler goal providing automatic mechanism high quality distributed master slave scheduling heterogeneous dynamic grid environments 
extend performance model common classes paral lel computing grid environments 
study physical resource characteristics available memory beneficial include constraint analyses 
experience shown idea estimating application performance accounting application resource constraints appears promising tool enabling effective application scheduling 
berman 
high performance schedulers 
foster kesselman editors grid blueprint new computing infrastructure chapter 
morgan kaufmann publishers july 
berman wolski 
scheduling perspective application 
proceedings fifth ieee symposium high performance distributed computing pages aug 

performance analysis algorithms heterogeneous systems message passing 
proceedings advances parallel virtual machine message passing interface th european pvm mpi users group meeting sept 
fishwick 
sim version 
department computer information science engineering university florida gainesville fl 
evans minieka 
optimization algorithms networks graphs chapter pages 
marcel dekker second edition 
koren 
coordination parallelize sparse grid methods cfd problems 
parallel computing 
ford fulkerson 
flows networks 
princeton university press princeton new jersey 
gelernter kaminsky 
piranha scheduling strategies implementation 
international journal parallel programming feb 
lowekamp miller sutherland gross steenkiste 
resource query interface network aware applications 
proceedings seventh international symposium high performance distributed computing july 

modeling performance parallel programs 
technical report computer science department university rochester rochester ny june 
persistence vision raytracer 
persistence vision development team 
www povray org 
pruyne livny 
interfacing condor pvm harness cycles workstation clusters 
generation computer systems 
shao berman wolski 
effective network views promote distributed application performance 
proceedings international conference parallel distributed processing techniques applications june 
silva martins soares 
mobile agents parallel processing 
proceedings international symposium distributed objects applications sept 
lieu lowekamp 
automatic node selection high performance applications networks 
appear proceedings seventh acm sigplan symposium principles practice parallel programming may 
wagner 
performance models processor farm paradigm 
ieee transactions parallel distributed systems may 
weissman zhao :10.1.1.47.2751
scheduling parallel applications distributed networks 
journal cluster computing 
white sunderam 
nas parallel benchmark kernels pvm 
www nas nasa gov nas npb oct 
wolski :10.1.1.46.3287
dynamically forecasting network performance network weather service 
proceedings th high performance distributed computing conference pages aug 
gary shao graduate student department computer science engineering university california san diego 
research interests include parallel distributed computing adaptive scheduling application development environments 
received university missouri columbia washington university st louis missouri 
berman professor computer science engineering university california san diego 
senior fellow san diego supercomputer center fellow acm founder parallel computation laboratory ucsd 
research interests decades focused parallel distributed computation particular areas programming environments tools models support high performance computing 
received university california los angeles ph university washington 
rich wolski assistant professor department computer science university tennessee partner national partnership advanced computational infrastructure 
research interests include parallel distributed computing line performance analysis techniques software compiler runtime system dynamic scheduling 
received california polytechnic university san luis ph university california davis livermore campus 
