maximum likelihood approach visual event classification jeffrey mark siskind morris department computer science university toronto toronto ontario canada 
presents novel framework maximum likelihood training models recognise simple spatial motion events described verbs pick put push pull drop throw classifying novel observations previously trained classes 
model employ presuppose prior recognition tracking object pose shape identity 
describe general framework maximum likelihood techniques visual event classification details generative model characterise observations instances event types implemented computational techniques support training classification generative model 
conclude illustrating operation implementation small example 
people describe see 
describe objects see describe events objects participate 
see person pick pen describe event saying person picked pen 
doing classify participant objects person pen respectively 
classify observed event picking event 
recognition machine vision focussed object classification 
contrast attempt address problem event classification 
address problem differs prior approaches badler nagel tsuji okada rourke badler rashid tsotsos mylopoulos zucker abe tsuji neumann novak waltz marr neumann novak yamamoto ohya ishii pinhanez bobick number important ways 
apply methods camera input contrast synthetic input 
second group naturally occurring events classes correspond pre theoretic notions described simple spatial motion verbs pick put push pull drop throw forth 
people may able perceive kinds differences motion sequences current address department electrical engineering technion haifa israel interested detecting differences described ordinary verbs 
approach maximum likelihood 
determine parameters general model empirically training data formulating detailed logical geometric descriptions event classes hand 
vision community done prior processing image sequences particularly sequences involving motion 
examples include optical flow object tracking shape motion name 
bears superficial resemblance wish stress concerned fundamentally different problem orthogonal ones addressed prior 
example interested event classification tracking 
techniques tracking relevant far facilitate facilitated event classification 
fact techniques describe perform detailed shape recovery object classification pose estimation 
siskind proposed technique classifying events recovering changing support contact attachment relations participant objects kinematic simulator driven output tracking 
tacit assumption prior object recognition prerequisite event recognition 
attempting implement aforementioned techniques conducted simple experiment calls question validity assumption 
took movies simple spatial motion events ordinary desk top environments 
events included picking putting pushing pulling boxes dropping various collisions objects 
movies filmed shell system recording image sequences resolution theta frames second compressed sun format 
applied edge detector line finder images movie animated resulting output 
original movie edge detected images correspond movie shown 
frame frame frame frame frame frame fig 

frames movie depicting pick event result applying edge detector line finder movie 
results experiment striking 
edge detection line finding collectively reduce amount information movie bytes frame roughly line segments bytes frame 
corresponds factor lossy data compression 
watching edge detected output isolated frames animated line movies humans reliably recognise objects appear images 
despite lossy data compression humans reliably recognise depicted events viewing animation line drawings 
retrospect results surprising 
line point light studies animate body motion performed johansson 
call question assumption prior event recognition presupposes object recognition 
information required classify objects recover pose time simply available animated line drawings constructed 
information event recognition robust process 
leads conjecture human event perception presuppose object recognition 
conjecture event recognition performed visual pathway separate object recognition 
furthermore conjecture pathway requires far lower information bandwidth object recognition 
true may case event recognition easier problem object recognition amenable short term synthetic engineered implementations 
rest offers precisely possible framework building event recognition engine 
framework linguistic evidence indicates humans characterise events terms characteristic changes properties relations objects participate events 
example pick event typically consists sequence subevents 
subevent hand agent moves patient object picked patient rests source object 
agent comes contact grasps patient 
second subevent agent moves patient away source supporting patient 
similarly throw event typically consists sequence subevents 
subevent patient moves agent agent grasps supports applies force patient 
subevent ends agent releases patient 
second subevent patient continues unsupported motion leaving patient hand trajectory results part force applied agent subevent 
types properties participant objects little importance defining event types 
agent throw patient pick patient source 
objects simply fill roles event type 
event types characterised types term patient denote object affected action 
potentially changing properties participant objects events described simple spatial motion verbs largely characterised changing spatial force dynamic relations objects 
focuses solely event types 
long term goal characterise recognise simple spatial motion events recovering changing force dynamic relations addition changing spatial relations 
mann jepson siskind lines 
describes techniques event recognition solely modelling characteristic motion profiles changing time objects participate different simple spatial motion events 
partition event recognition task independent subtasks 
lower level task performs object tracking image sequences input producing output stream position orientation shape size values participant object observed event 
pose information takes form set parameters ellipses abstractly characterise position orientation shape size participant objects 
lower level tracking done constraint event models 
upper level task takes input pose stream produced lower level processing image information classifies pose stream instance event type 
maximum likelihood approach perform upper level task 
approach supervised learning strategy train model event class set example events class 
classify novel event observations class model best fits new observation 
tracking tracker uses mixture colour motion techniques 
techniques track objects uniform distinctive colour blocks objects motion motion part event 
motion techniques track moving objects hand agent colour objects uniform distinctive detected colour techniques 
tracker operates frame frame basis tracking coloured objects moving objects independently 
track coloured objects determines set coloured pixels frame 
pixels considered coloured saturation value specified thresholds 
shows coloured pixels derived input image 
pixels classified bins histogram clusterer hue 
finding coloured regions frame tracker finds moving regions 
determines set moving pixels frame thresholding absolute value difference grey scale values corresponding pixels adjacent frames 
shows set moving pixels recovered technique image 
hue cluster spread noncontiguous regions image 
multiple moving objects set moving pixels fig 

processing stages tracker 
shows input image 
shows coloured pixels 
shows output region 
shows moving pixels 
shows output region 
shows combination 
shows ellipses fit regions 
spread noncontiguous regions 
apply proximity clustering technique divide hue cluster set moving pixels contiguous subclusters 
employ simple region growing algorithm groups pixels equivalence classes 
pixels placed equivalence class euclidean distance hx yi coordinates pixels specified threshold 
discard equivalence classes fewer specified number pixels 
eliminates small spurious regions appear figures 
shows result applying region hue clusters image 
shows result applying region image shows combined colour motion output tracker 
point movie represented set regions frame region set pixels 
region frame ellipse 
compute mean covariance matrix dimensional hx yi coordinate values pixels region 
take ellipse region centered mean follow contour standard deviation mean 
orientation major axis ellipse primary eigenvector covariance matrix lengths major minor axes ellipse eigenvalues covariance matrix 
shows ellipses generated regions 
subsequent processing ignores underlying image pixel data uses derived ellipse parameters 
operation fitting ellipses image data done independently frame movie 
independent processing suffers limitations 
recover intra frame correspondence ellipses 
require internal correspondence order track object position time 
second different frames contain different numbers ellipses 
may situations case tracker produces spurious ellipses correspond objects participate events movie 
may situations tracker fails produce ellipse represent object participate event 
drop outs happen variety reasons inappropriate settings various threshold parameters 
drop outs spurious ellipses intra frame correspondence task difficult 
subsequent processing overcome limitations tracker robustly determining intra frame correspondence ellipses 
employ simple technique determine intra frame correspondence ellipses single movie 
group ellipses believed track object frames ellipse chains 
weighted dimensional euclidean distance metric ellipse parameters determine object continuity adjacent frames 
chains contiguous sequences track motion single ellipse subrange frames movie 
due noise chains span entire movie 
subsequently relax requirement attempt attach ends chains produce contiguous sequences ellipses span entire movie 
relaxation frame adjacency requirement reduces problem ellipse drop outs elimination short chains reduces problem spurious ellipses 
final result technique set ellipse sequences track participant objects event entire movie 
result applying tracker complete movies shown original movies 
small subset key frames movie shown 
movies depict pick put push pull drop throw events respectively 
movies intra frame ellipse correspondence indicated line thickness 
notice fairly easy human recognise depicted event solely ellipse data 
event recogniser attempts mimic ability 
event recognition output tracker consists stream parameters ellipse frame movie 
movies typically objects constitutes roughly floating point numbers frame 
data stream compute larger feature vector 
feature vector contains absolute relative ellipse positions orientations velocities accelerations 
specifically feature vector includes features frame absolute features 
magnitude velocity vector centre ellipse 
orientation velocity vector centre ellipse 
angular velocity ellipse 
derivative area ellipse 
derivative eccentricity ellipse 
derivatives features relative features 
distance centres pair ellipses 
orientation vector centres pair ellipses pick put push pull drop throw frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame frame fig 

sample frames movies depicting different events result applying tracker movies 

difference orientations major axes pair ellipses 
pair ellipses difference orientation major axis ellipse orientation vector centre ellipse centre second ellipse 
derivatives features 
derivatives calculated finite differences adjacent frames 
feature vector adopt maximum likelihood approach event recognition 
supervised learning techniques train generative model class events set training examples class subsequently derived generative models classify new observations existing classes 
specifically pl constitute feature vector sequences set movies find parameters generative model maximise joint likelihood generating training sequences 
train fp plg argmax constitute parameters different event types classify new feature vector sequence class generated classify argmax pj adopt hidden markov models hmms generative model maximum likelihood framework 
event class described state model 
intend states represent major subevents event type 
instance pick event consist states 
state agent characteristically move patient patient stationary source 
second state agent move patient away source 
similarly hmms partition event types distinct states representing easily interpretable subevents 
hmms implementation assume independent normal probability distributions feature feature vector 
mean variance feature state model adjusted order maximise likelihood model generating training data 
assignment high low variances different features tantamount learning features results report simpler feature vector contains aforementioned absolute relative features derivatives 
obtain results smaller feature set classifying small set different event types believe larger feature set necessary classify larger set event types 
currently number states represent event type specified manually parameter training process 
relevant subevent event type likelihood sensitive changes values features having low variance features having high variance 
example variance derivative distance agent patient state pick event low indicating feature relevant variance orientation velocity vector agent high angle approach pick vary significantly indicating feature relevant 
contrast variance feature orientation velocity vector object low drop event objects typically fall straight downward 
train parameters hmms baum welch reestimation procedure baum petrie soules weiss viterbi procedure viterbi classification 
training restrict state transition matrix upper triangular disallowing non self cycles graph 
experience shows non ergodic models generalise better new observations 
severe restriction event types considered require repetitive subevents 
training classification procedures somewhat complex standard baum welch viterbi procedures number reasons 
tracker provide object identity information 
tracker track position objects time movie ellipse sequences identify objects tracking 
second tracker produce ellipse sequence object participate event object really exist example shadow 
problematic need know tracked objects movie participating event role objects play event 
event type specifies fixed number participant objects object plays welldefined role event type 
roles assigned tracked objects training group ellipse sequences different movies play role classification assign ellipse sequences existing roles model 
refer grouping problem external correspondence problem 
determine external correspondence members training set examining set candidate correspondences 
candidate correspondence contains subset ellipse sequences movie training set 
subset ordered match corresponding ellipse sequences training movies 
conceptually hmm trained candidate correspondence best correspondence chosen leads model highest likelihood generating event instances training set 
evaluating possible candidate correspondences intractable variant greedy algorithm choose candidate correspondences evaluate 
choose particular movie training set canonical event 
movie chosen represent canonical event contain number ellipse sequences participant objects event type 
arbitrary order chosen set ellipse sequences movie representing canonical event 
ordered subsets set ellipse sequences movie chosen establish candidate correspondence ordered set ellipse sequences canonical event 
choice done incrementally 
candidate correspondence established canonical event movie movie chosen training set 
correspondence chosen training hmm possible correspondence canonical event movie choosing hmm highest likelihood generating event instances 
explore successively larger candidate correspondences 
stage maintain set candidate correspondences movies choose candidate correspondences movies best ways augmenting previous candidate new movie 
iteration choose best hmm candidates correspondences constructed entire training set 
classification ellipse sequence role assignments determined manner 
examine possible permutations subsets set ellipse sequences derived new observation 
compute likelihood sequence generated models specifies number participant objects number ellipse sequences candidate 
new observation classified generated model assigns highest likelihood permutation subset set ellipse sequences derived observation 
experiments test techniques filmed movies system record image sequences resolution theta frames second compressed jpeg format 
movies comprised twelve instances event types pick put push pull drop throw 
movies filmed relatively uncluttered desk top environment movies contain extraneous objects 
camera position changed somewhat movie movie 
coloured foam blocks red blue green yellow props enact different event types 
clipped movies hand event coincided movie 
pick put movies uniformly clipped frames long push pull movies uniformly clipped frames long drop throw movies uniformly clipped frames long 
processed movies tracker 
movies randomly selected training movies movies event types 
constructed state non ergodic hidden markov models event classes 
classified movies original training data data training event classes 
model correctly classified training movies correctly classified test movies 
drop movie misclassified throwing event 
classifier selected drop second best choice movie 
misclassification appears result poor tracking 
discussion cautiously optimistic results 
plan test techniques larger set event types wider range participant objects filmed different length movies wider range environments 
plan evaluate robustness techniques face event occurrences exhibit larger variance motion profile 
furthermore event recogniser output tracker class events classify extent dependent properties current tracker 
built variety trackers drive recogniser currently tuning sophisticated tracker believe allow apply event recogniser wider class events environments 
longer term objective eliminate need manually specifying event automatically performing temporal segmentation events potentially overlap space time 
surprising similarities earlier event recognition reported siskind 
suggests event classes described temporal logic formulas pickup part disjoint supported supports contacts translating contacts attached supports translating set primitives describe spatial relations motion force dynamic relations support contact attachment 
surface approach taken appear fundamentally different approach taken 
deep similarities 
features input hmms analogous conceptual structure representations proposed jackendoff 
example orientation velocity centre ellipse viewed quantified representation conceptual structures go go 
similar analogies drawn remaining features 
temporal logic formulas viewed regular expressions symbols represent occurrence primitive events described representations 
symbols viewed thresholded feature values temporal logic formulas viewed finite state recognisers thresholded values 
hmms viewed probabilistic finite state recognisers features 
siskind presents techniques event descriptions recognise events assuming event descriptions produced hand training test data source code implementation available www cs toronto edu 
extends approach learn event descriptions supervised fashion 
uses spatial motion features ones 
pursued approach initial concern difficult robustly recover force dynamic relations camera input 
mann 
encouraging results show recovery force dynamics relations camera input feasible 
hope integrate force dynamics recovery techniques described event recognition techniques described 
event perception fundamental cognitive faculty 
solution ultimate goal artificial intelligence endowing computer human level intelligence embody mechanism perceiving events 
event recognition plays central role human cognition central role object recognition 
consider instance fact sentence structure natural languages built verbs nouns 
furthermore event recognition appears easier object recognition rely information 
may case event recognition evolutionarily primitive faculty 
earlier adopted tacit assumption object recognition precedes event recognition 
interesting consider reverse assumption 
event recognition easier evolutionarily primitive object recognition object recognition facilitated information provided prior event recognition 
instance difficult reliably segment recognise track hammer basis object model geometric 
easy recognise characteristic motion event detecting hammer 
having hypothesised event produced course object pose sequence process forming hypothesis possible knowledge guide search hammer confirm hypothesis 
prior event recognition prune space object models consider provide course grouping tracking data novel source top constraint 
applied particular strategy event classification maximum likelihood 
best knowledge approach previously applied task 
maximum likelihood methods proven extremely successful machine analysis speech 
methods provide important methodological advantages 
provide graded levels performance monolithic success failure 
crucial working hard problems unequivocally successful method sight 
second provide defined methods improving performance additional training data accurate generative models 
course speech recognition research past decades seen long intervals shallow steady performance growth punctuated small number discontinuous paradigm changes 
third systems maintain graded decisions internally delaying categorical decisions long possible robust operate pipe categorical decision processes 
systems category brittle minor inaccuracy affect categorical decision early pipe decision affect ultimate outcome 
visual event perception shares common speech analysis deal time varying signals 
surprising techniques applied speech applied visual event perception 
success maximum likelihood methods taken imply feasible approach performing event classification 
intend results taken simply encouragement problem event classification solved 
realisation encourage researchers explore alternate techniques solving problem 
acknowledgments wish peter dayan sven dickinson invaluable assistance project richard mann offering comments earlier draft 
remaining errors course sole responsibility authors 
supported natural sciences engineering research council canada 
abe tsuji 

plot understanding system image language 
proceedings seventh international joint conference artificial intelligence pp 
vancouver bc 
badler 

temporal scene analysis conceptual descriptions object movements 
tech 
rep university toronto department computer science 
baum petrie soules weiss 

maximization technique occuring statistical analysis probabilistic functions markov chains 
annals mathematical statistics 
jackendoff 

semantic structures 
cambridge ma mit press 
johansson 

visual perception biological motion model analysis 
perception psychophysics 
mann jepson siskind 

computational perception scene dynamics 
proceedings fourth european conference computer vision cambridge uk springer verlag 
neumann novak 

natural language dialogue moving objects automatically analyzed traffic scene 
proceedings seventh international joint conference artificial intelligence pp 
vancouver bc 
marr 

representation recognition movements shapes 
proc 
soc 
lond 

nagel 

analysing sequences tv frames 
proceedings fifth international joint conference artificial intelligence cambridge ma 
neumann novak 

event models recognition natural language description events real world image sequences 
proceedings eighth international joint conference artificial intelligence pp 
karlsruhe 
okada 

supp understanding moving picture patterns linguistic knowledge 
proceedings sixth international joint conference artificial intelligence pp 
tokyo 
rourke badler 

model image analysis human motion constraint propagation 
ieee transactions pattern analysis machine intelligence 
pinhanez bobick 

scripts machine understanding image sequences 
aaai fall symposium series computational models integrating language vision 
rashid 

system interpretation moving light displays 
ieee transactions pattern analysis machine intelligence 
siskind 

naive physics event perception lexical semantics language acquisition 
ph thesis massachusetts institute technology cambridge ma 
siskind 

grounding language perception 
artificial intelligence review 


artificial perception actions 
cognitive science 
tsotsos mylopoulos zucker 

framework visual motion understanding 
ieee transactions pattern analysis machine intelligence 
tsuji 

understanding simple cartoon film computer vision system 
proceedings fifth international joint conference artificial intelligence pp 
cambridge ma 
viterbi 

error bounds convolutional codes optimum decoding algorithm 
ieee transactions information theory 
waltz 

detailed model processing language describing physical world 
proceedings seventh international joint conference artificial intelligence pp 
vancouver bc 
yamamoto ohya ishii 

recognizing human action time sequential images hidden markov model 
proceedings ieee conference computer vision pattern recognition pp 

ieee press 
article processed macro package eccv style 
