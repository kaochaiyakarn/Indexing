parallel algorithm scalability issues ops architectures gupta hong han vipin kumar computer science department purdue university west lafayette 
cs purdue edu mathematical sciences department ibm watson research center box yorktown heights ny usa 
watson ibm com department computer science university minnesota minneapolis mn 
hang cs umn edu projected design space petaflops architectures entails exploitation large degrees concurrency locality data access tolerance latency 
puts considerable pressure design parallel algorithms capable ectively utilizing increasing amounts processing resources memory bandwidth constrained environment 
aspect algorithm design referred scalability analysis key component guiding algorithm designers hardware architects 
quantifying performance algorithm larger machine con gurations scalability analysis guides parallel algorithm development 
identifying bottlenecks scalability machine parameters uence bottlenecks scalability analysis uences hardware design 
motivate need bene ts scalability analysis context petaflops systems 
sample analyses sponsored nsf ccr army research oce da daag army high performance computing research center cooperative agreement number daah contract number daah content necessarily re ect position policy government ocial endorsement inferred 
access computing facilities provided minnesota supercomputer institute 
related papers available www url www cs umn edu kumar 
parallel algorithm scalability issues petaflops computations selected computational kernels dense linear algebra fast fourier transforms data intensive applications association rule mining 
objective analysis demonstrate analysis framework identifying desirable architectural features ability selected kernels scale petaflops systems 
impetus petaflops scale computing provided number critical applications various domains 
target achieving scale computing power year time frame likelihood rely large scale parallelism 
assuming best case scenario exponential growth peak processor speed envisioned petaflops scale computers require order computing elements achieve required computation rates 
projection assumption processor speeds increase gflops projected 
degree parallelism required achieving petaflops scale performance higher processor speeds realized 
example rst commercial petaflops computer announced blue gene expected contain processors 
scale parallelism puts severe strain ability algorithm eciently utilize available resources 
key aspect petaflops scale computing importance scalability parallel algorithms ability parallel algorithm yield performance increasing number computing elements 
fundamental challenges petaflops scale computing design hardware platform parallel algorithms way expect get performance large number processors 
scalability parallel algorithm limited variety parallel computing overheads 
commonly known amdahl law states fraction total computation serial speedup parallel formulation bounded simple rule consequence computation serial component processors 
computations ruled candidates fold parallelism 
general serial component computation function problem size 
example serial component integer addition log certain number processors perform computation need ensure reciprocal serial component exceeds number processors 
places constraints problem sizes eciently solved large scale parallel platforms 
addition serial component parallel computation incurs idling communication overheads 
communication overhead function ability underlying interconnection network deliver data processing elements 
networking technology seen signi cant improvements past years 
data rates range gb point point communications feasible foreseeable commercial platforms 
give impression overheads associated communication signi cant networking technology evolves 
scalability algorithm determined balance factor platform opposed raw communication latencies bandwidths 
balance factor loosely refers latency bandwidth underlying network relation computing speed processor 
balance factor petaflops scale platforms improve parallel algorithm scalability issues petaflops computations order magnitude may worse current generation systems 
implies algorithmic innovations minimize communication overheads continue critical scalability petaflops scale computations 
aforementioned motivations scalability analysis known understood years 
small number physical machines scaling processing elements built 
machines built speci computations underlying algorithms carefully crafted utilize machines 
exceptions asci class machines scalability issues relevant platforms 
petaflops scale computing ort distinguishes terms scale platform diversity application base 
speci cally anticipate order magnitude increase number processing elements larger application base 
puts emphasis designing platforms capable sustained petaflops scale performance wide range applications ii algorithm design methodologies metrics allow algorithms platforms resource constraints platform 
explore issues context commonly computational kernels chapter 
remainder chapter organized follows section describes terminology de nitions provides overview metrics quantifying scalability section presents case studies scalability analysis selected kernels diverse domains architectural implications section discusses extensions conventional scalability framework petaflops scale computing section presents concluding remarks need scalability analysis 
terminology de nitions background section terminology de nitions rest 
lay framework architecture independent analysis model motivate number scalability metrics 
conclude discussion suitability various metrics petaflops scale computers 
basic performance metrics parallel systems serial run time program time elapsed execution sequential computer 
parallel run time time elapses moment parallel computation starts moment processor nishes execution 
evaluating parallel system interested determining performance gain achieved parallelizing application sequential implementation 
measure called speedup captures relative bene solving problem parallel platform 
formally speedup de ned ratio time taken solve problem single processor time required solve problem parallel computer identical processors 
due various parallel processing overheads processors parallel ensemble devote time useful computation computation performed serial counterpart 
fraction time spent processor useful tasks determines eciency parallel algorithm 
formally eciency de ned ratio speedup number processors 
absence ects eciency parallel algorithm scalability issues petaflops computations parallel program bounded 
typical parallel programs incur overheads idling interprocessor communication excess computation 
overheads encapsulated single function called overhead function 
de ne total overhead overhead function parallel system part cost processor time product incurred fastest serial algorithm sequential computer 
total time collectively spent processors spent useful computation 
denote overhead function parallel system symbol overhead function depends write 
cost solving problem size processors total time spent solving problem summed processors pt units time spent performing useful remainder overhead 
relation cost pt problem size overhead function pt eciency parallel program pt expression parallel overhead equation rewrite expression asymptotically total overhead function increasing function program contain serial component 
serial component program takes time serial time processors idle 
corresponds total overhead function serial total overhead function grows linearly furthermore due communication idling excess computation function may grow number processors 
equation gives interesting insights scaling parallel programs 
problem size value remains constant increase number processors increases 
scenario clear equation eciency parallel program goes 
characteristic decreasing eciency increasing number processors problem size common parallel programs major issue scaling problems petaflops scale platforms 
hand increasing problem size keeping number processors constant opposite ect 
know total overhead function function problem size number processors cases grows sub linearly respect cases equation see eciency increases problem size increased 
phenomenon true parallel programs 
class programs true referred scalable 
parallel systems eciency maintained desired value increasing provided increased 
equation problem size usually obtained function algebraic manipulations 
function dictates growth rate required keep eciency xed increases 
call function isoeciency function parallel parallel algorithm scalability issues petaflops computations system 
parallel system refers combination parallel architecture parallel algorithm 
isoeciency function determines ease parallel system maintain constant eciency achieve speedups increasing proportion number processors 
small isoeciency function 
log means small increments problem size sucient ecient utilization increasing number processors indicating parallel system highly scalable 
high isoeciency function 
asymptotically higher indicates poorly scalable parallel system 
systems high achieved large numbers processors excessively large problems 
isoeciency function exist unscalable parallel systems systems eciency kept constant value increases matter fast problem size increased 
hand problem consists basic operations processors solve problem cost optimal fashion 
bound concurrency establishes lower bound isoeciency parallel system 
extensive analysis isoeciency function detailed descriptions provided 
related scalability metrics addition isoeciency metric number scalability metrics proposed particularly suited various scaling scenarios 
gustafson introduced scaled speedup metric de ned speedup obtained problem size increased linearly number processors 
scaled speedup curve close linear number processors parallel system considered scalable 
easy see linear scaled speedup curve corresponds constant eciency linear problem scaling 
indicates linear isoeciency function 
isoeciency superlinear non existent scaled speedup curve sublinear 
number scalability metrics proposed 
detailed discussion metrics provided 
scalability metrics relevant petaflops scale computing varying degrees 
isoeciency metric particularly useful features determines algorithm ectively utilize number processors speci ed con guration practical problem sizes 
practical problem sizes viewed terms available memory constraints time solution need hardware resources communication bandwidth 
determine bottlenecks architecture critically impact performance parallel algorithm provides insights alleviating bottlenecks 
guides algorithm development providing framework performance evaluation point designs 
memory scalability important notion scalability parallel algorithm requirement aggregate memory imposed algorithm ecient parallel execution 
key issue fast aggregate memory memory processor grow allow ecient parallel computer 
seen increase parallel algorithm scalability issues petaflops computations number processors accompanied appropriate increase problem size achieve eciency 
increase problem size translates directly increase aggregate memory requirement parallel algorithm 
rate increase superlinear argue parallel algorithm unable large number processors 
expect aggregate memory parallel computer grow number processors 
current generation computers operate range byte flops memory 
believed number increase petaflops scale architecture going decrease cost technology 
important implications architecture algorithm design 
speci cally problem scaling dictates superlinear aggregate memory growth machine characteristics bandwidth latency improved compensate 
argued aggregate memory asymptotically scale linearly number processors maintain constant eciency 
sublinear memory growth indicates reduction computation processor increasing results lower computation overhead ratio processor basis consequently drop eciency 
constraints time solution increasing problem size number processors maintain xed eciency lead extremely large problem sizes 
consider parallel systems isoeciency isoeciency 
rst case linear increase problem size number processors sucient maintain high eciency 
implies time solution remains approximately constant increasing number processors problem size processor constant 
second case problem size processor approximate time solution increases linearly number processors 
implies problem seconds processors yields eciency processors get eciency solve problem parallel runtime processors approximately days 
problem forecasting day weather petaflops scale computer immediately ruled algorithm architecture combination 
constraints time solution particularly important problems hard deadlines parallel systems superlinear 
scalability analysis algorithms section demonstrate power scalability analysis commonly parallel algorithms dense matrix multiplication fast fourier transform nding associations data 
show scalability analysis identify desirable architectural features performance bottlenecks algorithms 
algorithms wide range scalability issues covered 
parallel algorithms arising variety applications share scalability issues algorithms discussed section 
example dense sparse matrix factorization algorithms scalability characteristics similar dense matrix multiplication analysis algorithms sorting computing convolutions similar parallel fft 
detailed discussion algorithms refer reader 
parallel algorithm scalability issues petaflops computations model communication costs parallel programs order analyze selected kernels rst formalize model interaction costs incurred parallel programs 
interactions processors take form synchronizations communications 
interactions explicit message passing machines implicit shared address space platforms 
case associated time overhead incurred parallel program 
time required single point point communication uncongested interconnection network approximated terms startup latency bandwidth determined transfer time speci cally time communicate word message uncongested cut routed interconnection network approximated mtw purpose analysis convenient express terms time quanta unit computation opposed absolute time units 
rest chapter normalized representation startup word transfer times 
congestion underlying interconnection network may increase time 
communication patterns various algorithms di erent architectures varying degrees 
true communication time approximated mtw function determined underlying interconnection network communication pattern number processing elements linked network 
absence knowledge underlying interconnection architecture introduce notion ective word transfer time 
abstraction advantage analyze parallel algorithms architecture independent manner making quantitative statements architectural requirements various algorithms 
demonstrated greater detail section 
note ective bandwidth de ned context speci communication patterns architectures depending communication pattern architecture may may function dense matrix multiplication introduce isoeciency metric scalability analysis simple parallel algorithm dense matrix multiplication due cannon 
ecient parallel algorithms dense matrix multiplication exist chose discuss cannon algorithms simplicity 
consider logical dimensional mesh processors rows columns matrices multiplied yield product matrix matrices divided sub blocks size mapped naturally processor array 
sub blocks residing processor denoted ij ij respectively rst phase execution algorithm data input matrices aligned manner corresponding square submatrices processor multiplied locally 
done sending block ij processor mod block ij processor mod 
copied sub blocks multiplied 
parallel algorithm scalability issues petaflops computations sub blocks rolled step left sub blocks rolled step upward newly copied sub blocks multiplied results added partial results sub blocks 
illustrates steps parallel algorithm 
scalability analysis multiplication complete steps rolling sub blocks leftwards upwards respectively multiplying coming sub blocks processor 
total message transfers words data 
time spent communication step total parallel execution time equation equation follows total overhead processors algorithm wn order determine isoeciency term due proportional kt desired eciency maintained 
isoeciency relation results kt similarly determine isoeciency term due proportional equations asymptotic isoeciency function cannon algorithm 
maximum number processors algorithm isoeciency due concurrency 
scalability respect communication bandwidth memory preceding analysis clearly shows rate problem size needs scaled number processors maintain constant level cpu utilization 
derive interesting regarding behavior cannon algorithm massively parallel architecture 
words memory required solve larger problems maintaining xed eciency grows linearly result algorithm architecture combination scaled inde nitely su ering loss eciency long constant amount memory added processor 
secondly note multiplicative factor associated isoeciency term equation 
discussed earlier depends ratio data communication speed channels computation speed processors parallel architecture 
means processors multicomputer replaced times faster processors interconnection bandwidth parallel algorithm scalability issues petaflops computations initial alignment submatrix locations second shift submatrix locations shift submatrix locations third shift initial alignment initial alignment communication steps cannon algorithm processors 
parallel algorithm scalability issues petaflops computations remains problem size increased factor order obtain eciency 
hand increasing number processors factor requires problem increased factor maintain eciency 
contrary conventional wisdom suggests better performance obtained fewer faster processors 
scalability related matrix algorithms dense matrix factorization just dense matrix multiplication best parallel algorithms dense cholesky lu factorization pivoting isoeciency functions 
computational complexity algorithms matrices input size scale constant memory processor 
numerical constraints require partial pivoting performed lu factorization resulting extra overhead due additional communication constraints pipelining increase isoeciency function 
presence partial pivoting problem size increased inde nitely maintain xed eciency eventually running memory 
sparse matrix factorization analyzing scalability parallel run time involved case matrix factored sparse amounts computation overheads sensitive sparsity pattern original matrix 
analysis performed class sparse matrices arise discretization physical domain 
analysis reveals appropriate algorithms isoeciency function low achieved class sparse matrices absence partial pivoting 
somewhat surprising amount computation sparse matrix factorization smaller compared dense factorization communication pattern signi cantly complex 
dense factorization sparse matrix factorization scalable respect memory 
memory requirement computational complexity factoring sparse matrix resulting discretization dimensional physical domain log respectively 
isoeciency function memory increase rate log problem size increased rate isoeciency function 
parallel factorization scalable respect memory case 
sparse matrices arising dimensional domains space time complexity factorization respectively 
easy determine factoring matrices memory scalable isoeciency function 
fast fourier transform section analyze simpli ed versions parallel fft algorithms 
outlines serial cooley tukey algorithm point single dimensional unordered radix fft adapted 
input vector length integer fourier transform 
denotes complex number 
generally primitive nth root unity 
note lth take bit reversal account ect asymptotic analysis 
parallel algorithm scalability issues petaflops computations 







binary representation 












cooley tukey algorithm single dimensional unordered fft 
iteration loop starting line elements vector combined indices di er pattern combination elements identical butter network 
computation line independent di erent values processors compute values line processor computes values 
sake simplicity assume power precisely integer obtain performance parallel machine important distribute elements vectors processors way keeps interprocess communication minimum 
discussed section main contributors data communication cost message startup time word transfer time subsections parallel formulations cooley tukey algorithm 
analysis sections show formulations minimizes cost due constants 
parallel binary exchange algorithm commonly mapping minimizes communication binary exchange algorithm 
binary representation mapped processor number 

mapping processors need communicate rst iterations main loop starting line algorithm 
remaining iterations loop elements combined available processor 
lth iteration values required processor available single processor number di ers lth signi cant bit 
factors may contribute parallel implementation fft 
signi cant overheads due data communication processors 
discussed section processors communicate pairs log log parallel algorithm scalability issues petaflops computations iterations loop starting line 
processor stores transfers words communication steps total communication cost processors wn log increases order maintain eciency value equal kt 
log grow log log wn log clearly isoeciency function due rst term kt log requirement growth maintain xed eciency due second term complicated 
term requires grow rate log ignored favor rst term 
hand term requires grow rate higher log rst term ignored 
balancing second term yields log log ktw leads isoeciency function due second term ktw ktw log growth log long ktw 
soon product exceeds isoeciency function equation 
isoeciency function equation deteriorates rapidly increase value ktw fact eciency corresponding ktw acts somewhat threshold value 
parallel computer xed values obtained easily 
higher threshold obtained problem size extremely large 
examples illustrate ect value ktw isoeciency function 
consider hypothetical parallel computer relative values hardware parameters 
values threshold eciency 
isoeciency function algorithm due concurrency log isoeciency function due terms overhead function kt log ktw ktw log respectively 
maintain eciency isoeciency function log ktw ktw log pg shows isoeciency curves function 
notice various isoeciency curves regularly spaced parallel algorithm scalability issues petaflops computations isoeciency functions binary exchange algorithm computer various values threshold 
problem sizes required maintain threshold larger 
asymptotic isoeciency functions log 
isoeciency function log log 
shows eciency curve point ffts processor hypercube hardware parameters 
gure shows eciency initially increases rapidly problem size eciency curve threshold 
examples show limit eciency obtained reasonable problem sizes limit determined ratio cpu speed ective bandwidth communication channels parallel computer 
limit raised increasing bandwidth communication channels 
making cpus faster increasing communication bandwidth lowers limit 
binary exchange algorithm performs poorly computer communication computation speeds balanced 
hardware balanced respect communication computation speeds binary exchange algorithm fairly scalable reasonable maintained increasing problem size rate log 
parallel transpose algorithm vector arranged dimensional array row major order 
unordered fourier transform obtained performing unordered radix fft rows array followed unordered radix fft columns 
row fft corresponds rst log iterations fft entire vector column fft corresponds remaining log iterations 
parallel implementation mapped processors processor stores rows array 
fft rows performed parallel algorithm scalability issues petaflops computations threshold eciency binary exchange algorithm function processor parallel computer 
inter processor communication 
step array transposed fft rows transpose computed 
step requires inter processor communication transposing array processors 
data communication involved transpose algorithm transposition dimensional array processors 
involves communication unique block data size pair processors 
communication known personalized communication performed executing code processor send data processor number self address communication step takes time yields overhead function wn rst term independent increases problem size increase balance second communication term 
eciency yields isoeciency function kt isoeciency function transpose algorithm fft equation polynomial function change asymptotically hardware related parameters 
contrast isoeciency function binary exchange algorithm equation changes asymptotically depending ratio ective bandwidth computation speed cpu 
range ktw binary exchange algorithm preferable 
hand parallel computers communication speed balanced respect parallel algorithm scalability issues petaflops computations computation speed transpose algorithm suitable 
transpose algorithm dependent eciency threshold 
impact architecture ective usually word communication time function bandwidth links communication network speed number bu er copies involved passing message 
communication patterns sparse networks networks bisection bandwidth diminishing function number processors communication pattern binary exchange transpose algorithms congestion sparse network result ective value higher word transfer time point point link processors network 
ignoring component due message bu er copying operations ective higher word link transfer time factor ratio actual bisection width sparse network 
dense network hypercube ratio mesh ratio 
asymptotic isoeciency function fft algorithm higher sparse network predicted equations 
scalability parallel fft respect memory range eciency asymptotic isoeciency function binary exchange fft algorithm log memory requirement fft proportional asymptotic isoeciency function greater log case transpose algorithm binary exchange algorithm maintaining xed eciency require increasing amount memory processor number processors increase 
isoeciency function transpose algorithm 
transpose algorithm scalable respect memory consumption 
parallel algorithms discovering associations transaction data consider problem discovering associations data 
problem formulated originally context mining transaction data supermarket applicable wide variety domains data collected scienti experiments monitoring physical systems telecommunications networks transactions supermarket 
market basket data popularly known consists transactions customer 
transaction contains items bought customer 
goal see occurrence certain items transaction deduce occurrence items words nd associative relationships items 
problem far trivial exponential number ways items grouped 
research ort put devising ective serial parallel algorithms solve problem 
comparative survey parallel algorithms nding associations 
computational core association discovery phase computing frequency set itemsets transaction database 
set containing transactions set containing itemsets 
transaction itemset contains small number parallel algorithm scalability issues petaflops computations items possible set items goal nd number times itemset appears transaction 
shows example type computation 
database consists transactions interested computing frequency itemsets shown second column 
actual frequencies itemsets database shown third column 
instance itemset fd kg appears times second ninth transaction 
computation itemset frequency optimized storing itemsets hash tree 
run time serial algorithm processing transactions possible frequent item sets serial trans frequency counting hash tree construction trans cost updating itemset frequency hash tree transaction 
database transactions itemsets database transactions itemsets itemset frequency itemsets itemset frequency database transactions transactions itemsets need compute frequency partitioning itemsets tasks partitioning tasks task task task task sample transaction database itemsets 
problem inputs sets output array size stores frequency itemset data partitioned parallel algorithm scalability issues petaflops computations induce decomposition computations parallel processing 
possibility partition set transactions equal size parts shown 
possibility partition itemsets equal number parts shown 
cd algorithm example rst approach partitions set transactions processors 
task associated processor responsible computing frequencies itemsets solely transactions owns 
nal result obtained adding frequencies processors 
runtime cd algorithm processors tcd trans frequency counting global reduction hash tree construction comparing equation equation see cd able perfectly parallelize computation frequency counting adds addition step global reduction takes time :10.1.1.28.1451
step hash tree construction completely serial 
constant eciency maintained long number transactions increases linearly number processors size hash tree remains constant 
problem size grows due increase size hash tree happen desire frequent itemsets smaller support threshold cd scale 
idd algorithm example second approach partitions itemsets key feature distribute itemsets processors extract concurrency candidate generation counting phases :10.1.1.28.1451
task associated processor compute frequencies itemsets owns 
idd employs various ways reduce communication overhead exploit total available memory achieve reasonable load balance :10.1.1.28.1451
runtime idd algorithm idd trans frequency counting data movement hash tree construction comparing equation equation see idd better scalability cd respect hash tree size cost data movement idd idd scalable respect formulations combine approaches replicating distributing candidates reduce problems developed :10.1.1.28.1451
example hd algorithm :10.1.1.28.1451
brie works follows 
consider processor system processors split equal size groups containing processors 
hd algorithm execute cd algorithm processors 
partition transactions database parts size assign task computing counts itemset subset transactions parallel algorithm scalability issues petaflops computations groups processors 
group counts computed idd algorithm 
hd algorithm inherits features idd algorithm 
provides load balance computation maintaining minimum number candidates processor 
time amount data movement algorithm cut idd 
runtime hd trans frequency counting global reduction data movement hash tree construction compared serial runtime equation shows hd scalable respect just idd :10.1.1.28.1451
hd scales increasing provided chosen constant 
hd data movement cost 
increased increasing cost constant provided unchanged 
hd scalable respect increasing increase time hd unscalable needs xed respect increasing grow linearly respect increasing massively parallel computers nd patterns larger data sets ner patterns 
detailed parallel runtime analysis hd :10.1.1.28.1451
extensions scalability analysis frameworks isoeciency related scalability metrics developing variety parallel algorithms underlying cost model critical impact accuracy analytical results 
examples section underlying cost model relied latency bandwidth framework point point communication 
framework approximation calibrated largely static message passing networks clean communication abstraction accurate petaflops scale architecture 
modeling shared address spaces impact multithreading hardware assisted asynchronous communications pose challenges communication abstraction 
largely due fact overheads scenarios dependent just hardware parameters scheduling mechanisms 
example thread schedules may result markedly di erent cache patterns false sharing overheads 
done modeling contention accurate abstractions platforms dicult 
conventional processors rely multiple levels caches mask memory latency bandwidth bottlenecks 
poses challenges just optimizing programs optimal cache performance modeling program performance 
realistic assume hierarchy get deeper petaflops scale architectures compounding issues program performance modeling deep hierarchies 
programming model petaflops scale machines mix shared address space message passing paradigms 
tolerate high latencies communication rely threaded message passing programs threads swap communication operation ready operation completed 
parallel algorithm scalability issues petaflops computations modeling mixed mode programs involves complexities shared address space message passing paradigms 
concluding remarks demonstrated chapter scalability analysis play critical role development petaflops class systems 
gives clear view constraints hardware architecture satis ed scalability large platforms 
examples demonstrate interesting aspects respect algorithms analyzed show achieving dense matrix multiplication requires linear scaling memory number processors 
seen ideal memory scaling scenario 
demonstrate impact balance factor dense matrix multiplication 
speci cally show processor petaflops system replaced times faster changing interconnect problem size scaled factor achieve eciency 
quadratic scaling implies algorithm sensitive balance factor machine 
hand increasing number processors factor requires problem size increased factor maintain eciency 
clearly desirable scaling scenario yields insights desirable parts design space 
particularly relevant orts focused powerful processors building blocks petaflops computers 
transpose parallel fft algorithm known communication ecient unscalable respect memory 
ffts demonstrate sparse interconnects result poor ciency functions 
scenarios dicult achieve performance larger number processors 
solution increase ective bandwidth sparse networks compensate network congestion 
maintaining isoeciency critical memory scalability algorithm 
show memory requirement linear number processors isoeciency function log 
fft target kernel petaflops machine bisection width interconnect critical consideration ecient execution memory scalability 
context nding associations transaction datasets show parallel computers nding patterns larger datasets ner patterns 
similar analysis performed kernels interest 
isoeciency framework demonstrated context algorithms 
relationship scalability metrics explored 
just scalability analysis algorithm directs hardware design hardware characteristics identify algorithms ectively platform 
important point designs evaluated ability support target computational kernels assembling 
manner scalability analysis provides parallel algorithm scalability issues petaflops computations ective information conduit hardware algorithm design petaflops scale systems 
applications choice kernels solve problem 
serial context tradeo kernels terms memory computational characteristics complexities example large scale parallel context consider scalability kernels 
example block dense formulation sparse problems higher serial complexity scale better petaflops scale system 
net ect larger problem solved ectively kernel inferior serial context 
manner scalability analysis aid kernel selection applications 
agrawal imielinski swami 
mining association rules sets items large databases 
proc 
acm sigmod int 
conf 
management data washington 
agrawal shafer 
parallel mining association rules 
ieee transactions knowledge data eng december 
agrawal srikant 
fast algorithms mining association rules 
proc 
th vldb conference pages santiago chile 
aho john hopcroft ullman 
design analysis computer algorithms 
addison wesley reading ma 
david bailey 
ops algorithms workshop summary report 
url www gov pca wg pal html 
barton 
computing performance function speed quantity cost processors 
supercomputing proceedings pages 
cannon 
cellular computer implement kalman filter algorithm 
phd thesis montana state university mt 
larry davis 
approach parallel vision algorithms 
editor parallel processing 
siam philadelphia pa 
eager zahorjan lazowska 
speedup versus eciency parallel systems 
ieee transactions computers 
linda 
microprocessors beat generation 
ieee spectrum july 
gupta vipin kumar 
isoeciency measuring scalability parallel algorithms architectures 
ieee parallel distributed technology august 
parallel algorithm scalability issues petaflops computations gupta george karypis vipin kumar 
highly scalable parallel algorithms sparse matrix factorization 
ieee transactions parallel distributed systems may 
gupta vipin kumar 
scalability matrix multiplication algorithms parallel computers 
technical report tr department computer science university minnesota minneapolis mn 
short version appears proceedings international conference parallel processing pages iii iii 
gupta vipin kumar 
performance properties large scale parallel systems 
journal parallel distributed computing 
available technical report tr department computer science university minnesota minneapolis mn 
gupta vipin kumar 
scalability fft parallel computers 
ieee transactions parallel distributed systems august 
detailed version available technical report tr department computer science university minnesota minneapolis mn 
john gustafson 
reevaluating amdahl law 
communications acm 
john gustafson 
consequences xed time performance measurement 
proceedings th hawaii international conference system sciences volume iii pages 
john gustafson gary robert benner 
development parallel methods processor hypercube 
siam journal scienti statistical computing 
:10.1.1.28.1451
han george karypis vipin kumar 
scalable parallel data mining association rules 
ieee transactions knowledge data eng may june 
chris holt pal singh john hennessy 
application architectural bottlenecks distributed shared memory multiprocessors 
proceedings nd intl 
symposium computer architecture isca may 
matthew frank anant agarwal mary vernon 
modeling contention parallel algorithms 
proceedings sixth acm sigplan symposium principles practice parallel programming pages las vegas nv june 
jiang pal singh 
scaling application performance multiprocessors 
proc 
international symposium computer architecture may 
johnsson mcdonald 
radix fft connection machine 
technical report thinking machines cambridge ma 
parallel algorithm scalability issues petaflops computations mahesh joshi 
han george karypis vipin kumar 
ecient parallel algorithms mining associations 
zaki 
ho editors lecture notes computer science lecture notes arti cial intelligence lncs lnai volume 
springer verlag appear 
alan karp flatt 
measuring parallel processor performance 
communications acm 
clyde kruskal larry rudolph marc snir 
complexity theory ecient parallel algorithms 
technical report rc ibm watson research center yorktown heights ny 
vipin kumar gupta george karypis 
parallel computing design analysis algorithms 
benjamin cummings redwood city ca 
charles van loan 
computational frameworks fast fourier transform 
siam philadelphia pa 
norton 
parallelization performance analysis fft algorithm shared memory architectures 
ieee transactions computers 
daniel anant agarwal 
scalability parallel machines 
communications acm 
robert pool 
assembling life building blocks 
ibm research magazine november 
url www research ibm com resources magazine number html 
thomas sterling paul messina paul smith 
enabling technologies ops computing 
mit press 
sun john gustafson 
better parallel performance metric 
parallel computing december 
available technical report uc ames laboratory iowa state university ames ia sun diane rover 
scalability parallel algorithm machine combinations 
technical report ames laboratory iowa state university ames ia 
appear ieee transactions parallel distributed systems 
patrick 
ect time constraints scaled speedup 
siam journal scienti statistical computing 

measuring scalability parallel computer systems 
supercomputing proceedings pages 
