learn opponent strategy polynomial time 
mor claudia goldman jeffrey rosenschein computer science department hebrew university ram jerusalem israel ph fax email cs huji ac il cs huji ac il jeff cs huji ac il agents interact distributed environment increase utility behaving optimally strategies agents 
agents need learn share world 
examines interactions agents game theoretic perspective 
context learning assumed means reach equilibrium 
analyze complexity learning process 
start restricted agent model agents represented finite automata agents plays fixed strategy 
show restrictions learning process may exponential time 
suggest criterion simplicity induces class automata learnable polynomial time 
keywords distributed artificial intelligence learning repeated games automata standard notions equilibria game theory involve set players holding strategies player gain deviating current strategy strategies stay fixed 
idea implicitly assumes degree knowledge players strategies aumann obvious question knowledge came 
possible answer players negotiate strategies 
solution hold absence communication 
interested case players don communicate apart observing move 
problem pose problem learning players model opponent compute best response time 
interested complexity issue learning process 
player engaged repeated interaction fact doing things time playing game defined payoff structure interaction strategy 
attribute players degree rationality strategy player believes best response opponent strategy 
secondly trying learn opponent strategy note player incentive learn limited information relevant choice strategy 
third behavior player involved called training 
player assumes opponent trying learn strategy try influence opponent beliefs push preferable strategy 
instance repeated battle game player consistently play cost receiving payoff period order teach player ii play ii battle game matrix done model allowing simultaneous behaviors available 
examine restricted setting player chooses strategy plays 
player tries learn strategy design strategy best response 
require learn strategy polynomial time 
assume restricts strategies realizable deterministic finite state automata dfs 
reasons hand dfs strategies accepted widely model bounded rationality 
hand learning structure automaton shown hard problem kearns vazirani focused example repeated game prisoner dilemma fig 

results easily generalized wider class person non zero sum games 
prisoner dilemma game related finite automata players suggested model bounded rationality means resolving prisoner dilemma paradox rubinstein rubinstein neyman neyman extensive survey relevant literature appears kalai basic concept underlying trend players rational constrained submit automata limited size agents game 
number states automata accepted measure complexity 
series folk theorems shown players restricted automata size sub exponential game length number rounds cooperative behavior achieved equilibrium 
line sense common measures complexity 
papadimitriou papadimitriou shown bound number states automaton restrictive problem designing optimal automaton harder 
fortnow whang fortnow whang assume total ignorance opponent automaton 
show games rational player discover optimal strategy opponent automaton polynomial time non zero sum games general case 
apparent clear observation ka limit number states player automaton 
player allowed automaton size super exponential ka construct automaton optimal strategy construct ka deep tree enable identify automaton compute best reply automaton ka size automaton attach relevant branch tree 
idea pitfalls point view traditional complexity theory 
obvious time needed construct automaton unacceptable 
second allowing automata size undermines essence computational learning theory automaton instant learning machine 
fact serves table possible states world replacing desired decision process 
outline section unfolds theoretical framework 
central concept introduced section automata supporting certain payoffs 
idea restrict automata displaying level rational behavior ensuring exploited 
section addresses issue designing automaton tuned specific equilibrium payoff 
novelty existence equilibrium constructive proof presenting polynomial time algorithm 
reason bring proof see point polynomial time learning strategies designed polynomial time 
section focal point 
section show restricting set automata supporting rational payoffs sufficient learnable 
criterion simplicity needed 
criterion goes standard number states criterion 
preliminaries examines role learning person non zero sum repeated games 
section define concepts games game equilibrium 
def 
games game tuple fn ff pig ffl number players ffl ff fff ff fff ff set actions available player ffl pi theta ff payoff function pi assigns player real number payoff combination players actions 
denote payoff player def 
equilibrium nash equilibrium player game set strategies sigma foe oe player plays oe player get higher payoff playing strategy oe consider players playing game 
player strategy oe fa bg sequence actions taken player strategy represented deterministic finite dfs automaton actions state automaton transitions determined actions taken opponent 
example automaton fig 
represents strategy players stay initial state perform cooperate 
move state performs cooperate performs defect tit tat 
strategy example players restricted playing strategies realized set equilibria change 
interpret notion equilibrium respect set strategies available player 
instance repeated pd game players rational equilibrium mutual defection game 
neyman neyman rubinstein rubinstein shown player restricted automaton limited number states payoff pair individually rational region fig 
accomplished equilibrium payoff 
gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma individual rational region ae ae ae payoffs pd game denote automaton represents strategy fa bg states concerned connected automata 
playing automaton game history eventually cyclic 
player automaton trying maximize payoff consider simple cycles cycles state passed 
considering possible payoffs induced automaton sufficient examine simple cycles 
def 
cycle implements ff fi pi ff pi fi def 
cycle supports ff fi 
implements ff fi 
implements ff fi ff ff fi fi def 
cycle ffl supports ff fi supports ff fi ff fi gamma ff fi ffl def 
automaton ffl supports ff fi ffl supports ff fi 
polynomial time design automaton strategy theorem ffl supports ff fi ffl theta gamma furthermore exists algorithm constructs follow researchers gilboa samet fortnow whang restriction avoid strategies 
connected automata disjoint states states input sequence leads way avoid actions allow players opt see mor rosenschein mor 
notice ff fi nash equilibrium point supported automaton ff fi polynomial time proof 
ff fi equalities ff kt delta ks delta kr delta kp delta fi delta delta kr delta kp delta denotes number states player gets payoff loss generality assume 
general ks kr kp normalize values getting kt ks kr gamma kp putting equations matrix form equation delta kt kr ff fi gamma kp denote matrix ffi determinant 
ffi gamma gamma delta delta gamma gamma ffi delta gamma gamma gamma gamma gamma gamma gamma gammar gamma gamma gamma gamma gamma deduce coefficients equation equation fixing value kp ffi ff gamma gamma fi gamma gamma kp gamma ks ffi gammaff gamma fi gamma gamma gamma kp gamma kr ffi ff gamma gamma fi gamma gamma kp gamma normalized coefficients values sum coefficients number states automaton final values coefficients kt delta ks delta kr delta kp delta construct desired automaton 
construction consists stages ffl construct cycle imp states ffl implements ff fi coefficients computed determine number states type 
ffl construct punishment chain pun states plays chain linked escape playing successive rounds 
ffl link imp pun deviation cycle lead state pun punishing state linked back state cycle 
precise payoff player gets state playing optimal strategy point 
refer payoff gets type state 
payoff defined actions players state defines action automaton player 
optimal best response strategy unique state state question reached optimal strategy 
automaton ffl supports ff fi way built 
notice computed coefficients equations time build automaton determining action transitions states pass states 
learnable strategies automaton strategy denote tlb expected time take player learn automaton number states bounded theorem ffl supports ff fi tlb omega gamma proof 
ff fi construct automaton ffl supports ff fi follows ffl build cycle imp implements ff fi theorem 
denote consensus cycle 
ffl build punishing chain pun automaton fortnow whang idea choose random binary string cs ds construct punishing chain escape string 
shown fortnow whang pun learnt polynomial time 
enters pun tlb omega gamma 
lemma enters pun probability gamma 
proof 
visits state consensus cycle time information regarding action choose order stay cycle 
probability stays consensus cycle probability enters pun states consensus cycle probability consensus cycle probability entering pun gamma 
example automaton ff fi exponential time disturb researchers 
strategies discussed context pd state automata strategies 
note number states defines granularity grid possible payoff vectors 
instance class automata allows distinct payoff vectors rational region depending relation 
example automaton strategy learnable automata strategies objective categorize class game playing automata learnable polynomial time 
categorization propose criterion simplicity 
motivation studying strategies relative simplicity 
standard measure complexity automata number states obviously capture intuitive notion complexity 
consider automaton example 
clearly complex automaton number states identical 
def 
simp course theorem defined types states see footnote automaton pd game 
group states automaton chunks connected automaton graph states type 
number states automaton number chunks equi type states 
denote complexity relation automata 

class simple automata simp ff fi supports ff fi supports ff fi theorem class simp learnable polynomial time tlb proof 
proof consists stages show canonical structure automata simp compute size class canonical structure 
size polynomial number states automata polynomial number examples sufficient distinguish different automata class 
lemma automaton simp consists consensus cycle punishment chain 
proof 
definition automaton simp minimal complexity automaton supports certain ff fi 
supports ff fi cycle implements payoff vector 
cycles choose minimal complexity call consensus cycle imp 
transition table automaton holds entries state consensus cycle 
entry part cycle leading chain eventually connection back consensus cycle 
left prove chain 
assume contrary 
choose chain minimal 
denote state accessed consensus cycle 
redirect transitions consensus cycle chains different consensus cycle longer accessible remove 
constructed automaton supports ff fi states contradiction simp denote punishment chain 
lemma states punishment chain type proof 
lemma know exists punishment chain automaton replace chain pun pun number states type denote modified automaton 
pun pun supported ff fi 
states pun equi type 
simp iff states pun equi type 
contradiction assume states pun type different lo assume type chain imp decomposed parts prefix imp denoted pun average payoff delta pun delta pun number states pun number states pun average payoff receives pun number states pun type remains unchanged 
delta pun delta pun delta pun delta pun pun pun delta delta gamma delta gamma ffl ffl pun pun contradiction assumption simp lemma automaton simp type state chunk states type proof 
contradiction assume simp chunk states type construct automaton supports payoff vector contradicts simp group states type 
lemma jc simp proof 
possible types states lemma chunks 

possible ways arrange 
chunk states number states chunks determined size 
possible combinations chunks sizes 
arrangements 
shown number automata states simp polynomial player enumerate possible automata learn automaton time polynomial automaton size 
completes proof theorem 
example learning algorithm far dealt payoff vectors individually rational region 
range possible payoffs requires detailed inspection context 
setting studied player designs automaton tuned certain payoff vector player tries learn automaton play accordingly 
reasonable choose automaton gives payoff ffl maximize payoff 
want allow complex situations emerging various possible beliefs players 
consider instance setting opt game matched different partner 
players believe receive expected payoff opts construct automaton award equilibrium assume restricts strategies payoff fi equilibrium 
strategies choose maximizes payoff 
consider graph 
maximizes payoff certain minimal payoff attributes possible payoffs received players represented upper rightmost boundaries 
line defined kr second defined kr 
assuming player knows automaton simple automaton simp construct learning algorithm see 
notice doesn know states automaton 
algorithm played time order play automaton chunk type states connected chunk type states 
played taken advantage play forever 
added learning algorithm step play prevent abusing 
discover size polynomial time know log steps 
observation coincides empirical data human behavior roth learn play payoff play times play times kr repeat play kr times play play payoff kr kr break ks payoff play repeat play kr times play ks times learning algorithm players communicate actions take exponential time find best response opponent strategy 
shown holds players playing fixed nash equilibrium strategy 
defined notion automaton supports payoff vector ff fi 
algorithm design automaton supports certain payoff vector received players play 
shown complexity algorithm polynomial number states automaton 
reason deriving proof see point polynomial time learning strategies designed polynomial time 
defined class automata simp learned polynomial time example sub class specified learning algorithm 
issues need investigated regard extensions results prisoner dilemma player punish opponent harming 
interesting question payoffs supported doesn hold 
games equilibria pure strategies exist players randomize actions 
possible automata order create pseudo random strategies 
confined scenario player remains static adaptive 
general model need account mutual learning 
model players learn non fixed strategies 
furthermore players may attempt manipulate learning process 
shown existence learning algorithm class simple automata constructed algorithm 
automata learning literature rivest schapire kearns vazirani shows construct algorithms homing sequences available input sequences guarantee certain state reached 
side effect lemma identify sequence learning player thrown consensus cycle return state playing known number rounds 
aumann aumann 
epistemic conditions nash equilibrium 
working harvard business school 
fortnow whang fortnow whang 
optimality domination repeated games bounded players 
technical report department computer science university chicago chicago 
gilboa samet gilboa samet 
bounded vs unbounded rationality tyranny weak 
games economic behavior 
kalai ehud kalai 
bounded rationality strategic complexity repeated games 
neyman editors game theory pages 
academic press san diego 
kearns vazirani michael kearns umesh vazirani 
computational learning theory 
mit press cambridge massachusetts 
mor rosenschein mor jeffrey rosenschein 
time prisoner dilemma 
international conference multiagent systems appear 
mor mor 
computational approaches rational choice 
master thesis hebrew university 
preparation 
neyman neyman 
bounded complexity justifies cooperation finitely repeated prisoner dilemma 
economic letters pages 
papadimitriou christos papadimitriou 
players bounded number states 
games economic behavior 
rivest schapire rivest schapire 
inference finite automata homing sequences 
information computation 
roth alvin roth okuno fujiwara shmuel zamir 
market behavior jerusalem ljubljana pittsburg tokyo study 
american economic review 
rubinstein rubinstein 
finite automata play repeated prisoner dilemma 
st discussion london school economics 
