positive unlabelled examples help learning francesco de comit denis rmi gilleron fabien ura cnrs universit de lille france mail denis gilleron fr 
learning problems labelled examples rare expensive numerous unlabelled positive examples available 
learning algorithms labelled examples 
address problem learning help positive unlabelled data small number labelled examples 
theoretical empirical arguments showing learning algorithms improved unlabelled positive data 
illustrating problem consider learning algorithm statistics monotone conjunctions presence classi cation noise give empirical evidence assumptions 
give theoretical results improvement statistical query learning algorithms positive unlabelled data 
lastly apply ideas tree induction algorithms 
modify code get algorithm takes input set lab labelled examples set pos positive examples set unl unlabelled data uses sets construct decision tree 
provide experimental results data taken uci repository con rm relevance approach 
key words pac model statistical queries unlabelled examples positive examples decision trees data mining research partially supported cognition par nord pas de usual learning algorithms labelled examples 
machine learning settings gathering large sets unlabelled examples easy 
text classi cation tasks learning algorithms able classify text labelled unlabelled documents proposed bm 
argue machine learning problems labelled data limited expensive unlabelled data positive data abundant cheap 
consider problems containing natural source positive examples belong single class 
example consider classical domain diagnosis diseases unlabelled data abundant patients positive data may numerous patients disease labelled data rare tests disease expensive 
second example consider mailing speci marketing action unlabelled data clients database positive data clients asked information product concerned marketing action mailing done labelled data rare expensive mailing done part database clients 
address text classi cation problems concerned web page classi cation problem unlabelled web pages inexpensively gathered set web pages interested available bookmarks labelled web pages fairly expensive small set hand labelled web pages designed 
proved den concepts classes learnable statistical queries ciently learned pac framework positive unlabelled data 
price pay considerable increase number examples needed achieve learning remains polynomial size 
consider problem learning small set labelled examples set positive examples large set unlabelled examples 
assume unlabelled examples drawn hidden distribution labelled examples drawn standard example oracle ex positive examples drawn oracle ex distribution restricted positive examples 
reader note problem di erent problem learning imbalanced training sets see km 
method discuss labelled examples estimate target weight proportion positive examples examples estimate target weight available problem positive unlabelled data needed 
experimental results showing unlabelled data positive data ciently boost accuracy statistical query learning algorithm monotone conjunctions presence classi cation noise 
boosting explained fact sq algorithms estimate probabilities 
prove estimates replaced estimate weight target concept respect hidden distribution small set labelled examples estimates probabilities computed positive unlabelled data 
sets unlabelled positive data large estimates calculated accuracy estimate weight target concept 
theoretical arguments pac framework showing gain size query space vc dimension obtained number labelled examples 
usual results better real problems 
section consider standard methods decision tree induction examine commonly algorithm described qui 
algorithm re ning leaf internal node decision criterion statistical values 
seen statistical query algorithm ideas applied 
adapt code 
algorithm takes inputs sets set labelled examples set positive examples set unlabelled examples 
information gain criterion modi ed sets 
reader note labelled examples computation weight target concept hidden distribution 
provide promising experimental results experiments needed experimental validation approach 
preliminaries basic de nitions notations instance space constitutes set possible unlabelled examples 
set number boolean attributes 
concept subset instance space equivalently valued function known class concepts size concept size smallest representation representation scheme 
example concept pair hx example hx positive negative 
denote os set 
distribution de ned subset instance space denote probability event denote da induced distribution 
instance concept denote restriction set de ned follows os 
denote complement set 
symmetric di erence consider sect 
class monotone conjunctions 
monotone conjunction conjunction subset set variables fx xn notation indicate ith bit subset fx xn conjunction variables denoted 
pac sq models target concept concept class hidden distribution de ned pac model val learner access example oracle ex returns call example hx element instance space drawn randomly correct label respect concept class pac learnable exist learning algorithm polynomial property distribution access ex inputs probability outputs hypothesis concept satisfying error 
time bounded size 
sq model kea specialization pac model learner forms hypothesis solely basis estimates probabilities 
statistical query xn mapping xn associated tolerance 
sq model learner access statistics oracle stat query returns estimate fx hx accuracy concept class say sq learnable exist learning algorithm polynomials property distribution access stat input query predicate evaluated time size bounded size halts time bounded size outputs hypothesis satisfying 

clear access example oracle ex easy simulate statistics oracle stat drawing su ciently large set labelled examples 
formalized result theorem 
kea class concepts suppose sq learnable algorithm pac learnable furthermore uses nite query space lower bound allowed approximation error query number calls ex log jqj uses query space nite vc dimension lower bound allowed approximation error query number calls ex log reader note result noise free pac model extended white noise pac models classi cation noise model angluin laird constant partition classi cation noise model dec 
proofs may kea dec 
note concept classes known pac learnable sq learnable pac learnable classi cation noise 
learning monotone conjunctions presence classi cation noise section target concept conjunction unknown subset boolean variables xn noise free case learning algorithm monotone conjunctions learning monotone conjunctions noise free case input draw sample examples positive example hx fx endif endfor output proved log examples guarantee hypothesis output learning algorithm error con dence algorithm noise tolerant 
presence classi cation noise necessary compute estimate probability random example hidden distribution positive satis es 
variables estimate small included output hypothesis 
suppose examples drawn noisy oracle call rst draws instance correct label ips label probability 
suppose noise rate known consider learning algorithm monotone conjunctions statistics presence classi cation noise learning monotone conjunctions noise tolerant case input draw sample examples size su cient ensure estimates accurate con dence greater compute estimate fx endif endfor output noise rate known estimate techniques described kv 
consider case want show best expected gain 
probability random example noisy oracle positive satis es probability random example noisy oracle negative satis es 
estimate estimates 
simple algebra standard cherno bound may prove log log examples su cient guarantee hypothesis output learning algorithm error con dence reader note bound quite larger noise free case 
assumption labelled examples rare sources unlabelled examples positive examples available learner 
unlabelled examples drawn noisy positive oracle call draws examples noisy oracle gets label 
raise problems positive unlabelled examples previous learning algorithm expected gain learning algorithm conjunctions statistics noise estimate calculated 
usual formulas conditional probabilities may expressed probability labelled example positive noisy oracle times probability positive example drawn positive noisy oracle satis es 
formula probabilities disjoint events equal probability unlabelled example drawn satis es minus 
compute estimate equations consequently compute estimates compute estimate labelled examples estimates source positive examples compute estimates source unlabelled examples 
reader note labelled examples calculation estimate probability labelled example positive 
positive answer rst question unlabelled examples positive examples learning algorithm conjunctions statistics 
raise second question expected gain compare algorithms rst learning algorithm conjunctions statistics labelled examples second computes estimate labelled examples uses exact values 
amounts say nite pool positive unlabelled data available third computes estimate labelled examples estimates nite number positive unlabelled examples algorithms outputs ordered list variables 
ordered list de ne minimal error ordered list de ned error min ng error rate hope 
compare minimal errors algorithms 
precise algorithms 
recall labelled examples drawn noisy oracle positive examples drawn noisy oracle restricted positive examples noise rate known 
algorithm labn input sample lab labelled examples ci lab gj ci lab gj endfor output ordered list algorithm labn pos unl input sample lab labelled examples ci lab gj compute exactly compute exactly supposition possible endfor output ordered list algorithm labn input sample lab labelled examples sample pos positive examples sample unl unlabelled examples ci lab gj ci pos gj jfx unl gj endfor output ordered list describe experiments experimental results concept class class monotone conjunctions variables xn target concept conjunction containing variables 
class distributions de ned follows characterized tuple values selected independently set probability set probability note chosen drawn randomly independently average weight target concept 
suppose examples drawn accordingly noisy oracles noise rate set 
experiment 
number variables set 
compare averages minimal errors algorithms labn labn pos unl functions number labelled examples 
averages minimal errors algorithm obtained doing times randomly chosen conjunction variables chosen randomly choosing randomly independently examples drawn randomly labelled target concept correct label probability minimal errors labn labn pos unl computed compute averages iterations 
set 
results seen fig 

top plot corresponds labn bottom plot labn pos unl 
experiment 
consider realistic case positive examples equal number unlabelled examples 
show small number labelled examples positive unlabelled examples give information labelled examples 
compare averages minimal errors algorithms labn functions number variables set 
number labelled examples set 
results seen fig 

sources scripts ftp grappa univ lille fr pub 
lab size lab lab unlimited number pos unl examples fig 

target size variables iterations 
gure shows gain expect free positive unlabelled data pos unl lab sizes lab pos unl lab fig 

target size variables iterations size lab size os size unl size lab ranges step 
curves show labelled examples learning algorithm performs positive unlabelled examples labelled examples 
theoretical framework class concepts suppose sq learnable algorithm target concept consider statistical query statistics oracle stat returns estimate fx hx accuracy 
may write followings fx hx fx hx fx hx fx hx sets de ned fx hx fx hx 
furthermore subset instance space concept preceding equations obtain order estimate su cient estimate 
get estimate accuracy estimates accuracy easily shown estimate accuracy 
usual estimated oracle ex 
estimate positive oracle pos ex 
estimate oracle unl ex returns call unlabelled example 
modify statistical query algorithm uses ex pos unl oracles 
furthermore standard algorithm queries labelled positive unlabelled example sources estimate queries 
assumption labelled examples expensive unlabelled positive examples cheap 
stronger assumption positive unlabelled data free estimate arbitrary accuracy 
min smallest tolerance needed learning algorithm number queries see need labelled examples estimate probability say accuracy min query space theorem gives upper bound number calls ex necessary simulate statistical queries needed see expect divide number calls cdim 
precise theoretical study remains done 
instance interesting estimate expected improvements accuracy number labelled examples xed depending number positive unlabelled examples 
done usual statistical query learning algorithm 
tree induction labelled positive unlabelled data generally decision tree learning algorithms sq algorithms test choices depend statistical queries 
having quickly show sect 
improve unlabelled examples 
sq algorithm describe sect 
adapt treatment positive unlabelled data 
nally discuss experimental results modi ed version positive unlabelled examples 
top decision tree algorithm algorithms tree induction top greedy search space decision trees 
splitting criterion qui statistical property called information gain measure information theory called entropy 
sample target concept entropy entropy log proportion examples belonging class information gain expected reduction entropy partitioning sample attribute test de ned gain entropy entropy set possible value attribute test cardinality set examples value cardinality alternative measure gain ratio penalises attribute tests values 
de ned incorporating term called split information de ned log gain ratio measure de ned follows gainratio gain current node selects attribute test largest gain ratio information gain set training examples associated current node available attributes 
may produce unpruned trees pruned trees 
post pruning criterion pessimistic estimation error rate training set 
unlabelled data lab sample target concept unl set unlabelled data 
instance space target concept hidden distribution de ned lab set examples hx returned example oracle ex unl set instances drawn distribution set training examples current node tree construction dn ltered distribution hidden distribution restricted instances reaching node set training examples associated node fraction nv estimates probability attribute test value respect dn estimation take care labels examples 
straightforward modi cation gain case labelled unlabelled data obtained set unl calculation fractions examples set lab calculation entropy 
lab unl sets training labelled examples training unlabelled examples associated node gain de ned gain entropy lab entropy lab set possible value attribute test cardinality set unl examples unl value cardinality unl lab set examples lab value positive unlabelled data instance space consider binary classi cation problems 
classes denoted example said positive label 
pos sample positive examples target concept lab sample labelled examples unl set unlabelled data 
hidden distribution de ned pos set examples hx returned example oracle ex lab set examples hx returned example oracle ex unl set instances drawn distribution entropy sample de ned entropy log log formula set training examples associated current node proportion positive examples dn ltered distribution hidden distribution restricted instances reaching node xn set instances reaching node estimation dn 
light results sect 
modify formulas calculation information gain 
dn xn xn equation xn xn obtain dn xn xn estimate xn set positive examples associated node estimate complete set labelled examples estimate xn unlabelled examples 
precisely pos set positive examples associated node unl set unlabelled examples associated node lab set positive examples set labelled examples lab entropy node determined equations jp os jp entropy log log reader note independent node de ne information gain node gain entropy entropy nv set possible value attribute test unl set unlabelled examples associated node cardinality unl cardinality set unl examples unl value nv node corresponding value attribute test experimental results applied results previous section called resulting algorithm 
di erences compared takes input sets lab pos unl appears calculated current node entropy gain calculated gain ratio split information calculated unlabelled examples majority class chosen halting criteria top tree generation evaluated unl pruning tree classi cation errors estimated help proportions reader note consider problems classes 
consider data sets uci machine learning database mm kr vs kp adult 
majority class chosen positive 
sizes test set set positive examples set unlabelled examples 
values set kr vs kp test set set positive examples set unlabelled examples adult test set set positive examples set unlabelled examples number labelled examples vary compare error rate 
size lab iterate times sets selected randomly pos larger set drawn selected number positive examples kept compute error rate input lab error rate input lab pos unl 
average error rates experiments 
results seen figs 

error rates promising number labelled examples small 
think better results higher number examples due pruning algorithm best way positive unlabelled examples trees consistently larger ones 
experiments run class uci problems adult kr vs kp selected known contain examples 
results experiments ftp grappa univ lille fr pub experiments 
lab size lab lab fixed number pos unl examples fig 

error rate kr vs kp data set averaged trials 
practical learning situations labelled data rare expensive collect great number positive unlabelled data available 
experimental theoretical evidence lab size lab lab fixed number pos unl examples fig 

error rate adult data set averaged trials 
kind examples ciently boost statistical query learning algorithms 
lot remains done directions precise theoretical results stated speci statistical query learning algorithms modi ed especially pruning algorithm adapted data types intend collect real data kind studied labelled positive unlabelled test new variant method applied statistical query algorithm 
interesting know appropriate angluin laird 
learning noisy examples 
machine learning 
bm blum mitchell 
combining labeled unlabeled data training 
proc 
th annu 
conf 
comput 
learning theory pages 
acm press new york ny 
dec 
pac learning constant partition classi cation noise applications decision tree induction 
proceedings fourteenth international conference machine learning 
den denis 
pac learning positive statistical queries 
alt th international conference algorithmic learning theory volume lecture notes arti cial intelligence pages 
springer verlag 
kea kearns 
cient noise tolerant learning statistical queries 
proceedings th acm symposium theory computing pages 
acm press new york ny 
km kubat matwin 
addressing curse imbalanced training sets sided selection 
proceedings th international conference machine learning pages 
kv kearns vazirani 
computational learning theory 
mit press 
mm merz murphy 
uci repository machine learning databases 
nigam mccallum thrun mitchell 
learning classify text labeled unlabeled documents 
proceedings th national conference arti cial intelligence aaai 
qui quinlan 
programs machine learning 
morgan kaufmann san mateo ca 
val valiant 
theory learnable 
commun 
acm november 
