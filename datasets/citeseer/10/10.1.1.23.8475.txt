summary grids building accurate multidimensional histograms data summarization important data analysis tasks 
propose simple efficient data summarization algorithm outputs histogram multidimensional data comparative study usage different distributions existing algorithms 
idea iteratively grow modify regions homogeneous data 
different strategy commonly strategy iteratively subspaces straight lines 
compares strategies concludes new technique better results 
concluded discriminate handling outliers important provide approximates 
data reduction summarization important bases diverse tasks datacube representations efficient olap data mining selectivity estimation data analysis task 
alternative techniques multidimensional histograms choice simple easy construct maintain small run time overhead require data fit probability distribution occupy reasonably small space 
reason histograms frequently tasks query result size estimation help query processors optimize query execution strategy 
molap size disk pedro madeira eng 
inform tica univ coimbra coimbra portugal pnf dei uc pt able access reduced summarized versions retain distribution form important allow efficient analysis give preliminary approximated answers queries alternative methods sampling online data analysis 
emphasize summarizing different objective aggregation analyses data maintain form distribution aggregation simply computes averages sums ranges user 
techniques important understand summarization molap tool regions user 
propose new data summarization algorithm called summary grid sgrid builds histogram multidimensional data 
algorithm addresses shortcoming previous technique mhist build histograms data summarization purposes 
comparing sgrid mhist confronting alternative histogram construction strategies 
mhist iteratively fractures subspaces straight lines sgrid iteratively coalesces neighbors clustering constraints met 
line mhist prematurely cuts homogeneous subregions best partitioning 
sgrid algorithm avoids ideas clustering 
evaluate merits algorithm different data distributions compare mhist algorithm possible variants 
mhist compared favorably alternative techniques singular value decomposition svd terms error 
show technique presents better results mhist 
simplicity restrict experiments dimensional space 
major concern sgrid clustering technique computational overhead related scalability issue 
show overhead bounded easily adjustable 
compare sgrid mhist technique similar quasi cubes 
compares algorithm regression fixed grid partitioning datacube regr sgrid mhist strategies interesting experiment 
discriminate handling outliers important avoid large errors approximation 
distant values average summarized histogram buckets include complete characterization points 
important handling non uniform data shown results 
organized follows section discusses related 
section briefly reviews key concepts related histograms variations mhist technique 
section presents sgrid technique 
section studies complexity algorithms section briefly presents regr technique 
section presents results evaluation mhist sgrid regr techniques section concludes 
related techniques described data reduction 
parametric techniques singular value decomposition discrete wavelet transform assume model data 
non parametric techniques assume model data include histograms cluster reduction data index trees 
sampling mentioned providing way obtain quick approximate answers 
examples efficient clustering techniques birch uses concept clustering features tree cf tree dynamically build cluster tree clarans progressively refine clusters heuristics 
techniques produce histograms 
statistical information grid sting technique effectively summarizes data distribution spatial data mining 
space divided set hierarchical grids data characterized belonging defined distribution parameters mean standard deviation 
technique relies statistical information associated individual cells hierarchical sense number grids increasing resolution accomodate different degrees precision progressive refinement regions satisfying query 
main drawback technique need identify quantify distribution possible 
sgrid adapts grid patterns raw data doesn need user intervention 
quasi cubes effective way support approximate regression 
technique experiments comparison 
mentioned section advantages histograms 
simple histograms frequently commercial systems selectivity estimation query processors 
dimensional histograms comprehensively studied focusing database estimation problems query involving single attribute relation result size depends data distribution 
extensive framework histogram characterization results different combinations parameters compared identify histogram partitioning strategy choice close best construction time data approximation error 
multidimensional histograms studied 
result size query involving attributes relation depends joint data distribution attributes frequencies combinations attribute values database 
approximate joint data distributions commercial systems adopt attribute value independence assumption results size derived computing dimensional histograms individual attributes regardless actual data dependencies 
proposes multidimensional histograms drop attribute value independence assumption noticed real life data rarely satisfies assumption estimate inaccurate 
construction multidimensional histogram poses difficulties 
perceived multidimensional sort parameter harder handle requires finding arbitrary rectangular non overlapping regions 
large number choices rectangular regions 
approach adopted taken imposes priority dimensions sort parameter regions created highest priority dimension region broken subregions second highest priority dimension equivalent approach called phased compared techniques attribute value independence assumption avi singular value decomposition svd hilbert numbering new technique named mhist accurate estimation results 
strict order attribute partitioning phased approach results low quality approximation 
hand mhist exhibits flexibility picking dimension step criticality partitioning constraint 

mhist technique purpose histograms approximate particular data distribution precomputed tabular information 
histograms extensively studied example review important concepts 
attribute takes set values frequency denoting attribute value frequency 
onedimensional histograms attribute partition attributes data distribution subsets called buckets 
partitioning process uses partitioning rule approximate values frequencies bucket rules 
multidimensional histograms approximate joint data distribution attributes represent 
shows example dimensional data distribution frequencies combinations values possible division buckets data distribution 
adopted representation similar 
attribute attribute need partitioning joint occurences histogram joint data distribution mhist technique partitions space finding attribute marginal distribution need partitioning 
marginal distribution individual data distribution attribute number possible value fi depicted 
mhist achieves best results partitioning constraint labeled maxdiff determines boundary largest differences source values source value area spread frequency 
splitting done straight fracture lines 
introduced variations calculation differences obtain splitting point 
marginal difference mhist absolute value difference marginal frequencies fi fi ex 


normalized marginal difference mhist attribute attribute marg 
divide marginal difference number pairs values considered fi fi ex 

sum absolute differences mhist marginal distributions compute individual differences sum absolute values sum fi fi ex 


normalized sum absolute differences mhist divide mhist number pairs values considered sum fi fi dimensions 

maximum differences approach mhist consider greatest difference neighboring points multidimensional space max fi fi ex 

motivation considering different variations basic algorithm comes fact alternative strategies give weight different aspects multi dimensional problem finding partitioning strategy 
way able exhaustively study evaluate different alternatives 
approaches mhist mhist absolute sums favor consecutive lines parallel longest 
means subspace left dashed fracture line consecutively favored creating lines parallel 
mhist sums individual differences opposed cumulative differences mhist 
gives weight extremes 
approaches simple normalizations mhist mhist obtained dividing result number pairs considered 
avoids strategy longest dimensions favoring typical mhist favors smaller dimensions may result small regions 
computational burden equivalent approaches marginal distributions recomputed subspaces 
defer analysis approaches evaluation section 

summary grids sgrid mhist technique easy implement induces estimation error splitting line 
fracture line critical considering cumulative marginal source value differences prematurely separates subsets uniform valued neighbors 
problem relevant space volume big 
reflecting issues created alternative sgrid approach drops line strategy groups homogeneous data way tries minimize resulting error estimates 
sgrid technique uses incremental strategy sgrid incr works maximizing area regions objective constraints search restrictions 
parameters pre calculated sgrid heur module 
histograms technique assumes uniform spread frequencies buckets 
strategy sgrid incr tries alternative expansion directions region heuristics 
shows process 
implementation starts coalescing points corner point objective constraints met 
directions tried attempt maximize region area 
degree exhaustiveness region search totally configurable balance execution time overhead optimality 
subregion set remaining space goes process determine regions 
sgrid incr module probing region algorithm origin space point direction error metric limits reached grow region delta large growth passed extract outliers recall region error limits optional smaller step growth error metric limits reached grow region delta small growth passed extract outliers save region error limits choose region largest area saved regions assign point immediately boundaries follow predefined order dimensions 
regions parameters heuristic constraints find region boundaries 
radius diameter values tend smooth variations normalized 
reason added accumulated maximum error parameter corresponding sum absolute values differences bucket average point represented 
heuristic constraint number outliers allowed bucket 
way parameters tuned sgrid heur module radius equivalent standard deviation measures normalized deviation average 
vi diameter measures mean difference points region vi vj maximum error measures cumulative error 
implementation uses absolute deviation cumulative square error cse vi maximum number outliers outliers points approximated 
histogram bucket represent separately 
points distant mean chosen outliers 
result better approximation outliers contribute error 
oi candidate set outliers bucket region pair point value point attribute coordinates value corresponding joint occurrence frequency 
mo maximum number outliers bucket 
oi mo maximum values expression vj vj actual number outliers bucket determined algorithm 
directional search important parameter determines directions try greedy growth algorithm 
shows dimensional case trial generating vectors determined dividing sectors aperture 
value parameter crucial balance performance precision sgrid 
direction tried error measures 
algorithm determines region area just computed direction defined way algorithm tries find maximal area trial directions error measures 
corresponding region chosen excluded search space 
dimensions replaced ki dimension allowing greater selectivity preferred dimensions 
improvement optionally pre define borders selected attribute values hierarchical categorical information 
support pass regions region growing require complete recomputation measures overhead big 
prevent incremental nature algorithm supported set ls ss clustering features cf birch number elements ls linear sum values ss square sum values corresponding theorem case allows technique try boundary modification recalculating region features 
additivity theorem states coalescing regions cf values ls ss ls ss respectively resulting cf values ls ls ss ss 
parameters outliers easily calculated cf vector 
incremental property applied outliers simply keeping additional arrays maximum number outliers upper lower extremes bucket 
way upper lower extremes incremented region just maximum number outliers number extremes correspondent upper lower extremes subregions 
heuristics heuristics module determines maximum admissible values parameters 
user specify maximum admissible average error obtain high precision histogram matter space fixed number buckets obtain compact histogram ones selectivity estimation 
bucket sampling retrieve buckets way derive error parameters limits 
complexity estimation major concern study scalability properties sgrid algorithm 
sgrid mhist fixed grid scheme exhibit complexity size number data values original space 
sgrid mhist exhibit larger overhead data analysis determine partitions fixed partitioning scheme require access exactly values 
demonstrate statement reminding sgrid directional trials trials area ai chosen excluded search space 
number data values accessed process ai maximal area discovered process total number data values accessed ap ai number buckets determined sgrid algorithm careful study needed performance strongly depends number number chosen carefully depending number dimensions usual dimensions range 
reason brief comparative study 
dimensional experiments section fixed obtained results 
ki value dimension equal dimension simplicity 
equations determine number data values visited sgrid mhist algorithms derivation simple previous rationale 
determined possible equation number total trials ndim dimensions ki ndim sgrid algorithm ki ki ki ndim ki ndim total number data values accessed ki ndim furthermore introduce correcting factor equation considering average area account chosen rejected areas trial set ai trial 
way equations ki ndim number data values visited mhist algorithm approximated considering fact initially ndim values accessed determine marginal values ndim number dimensions simplifying approximation quad tree partitioning successive line fracture require recomputation number marginal values requiring successive access line fracture values line fracture values line fracture values line fracture values stated fracture requires recalculation marginal values directions fracture line plane hyperplane dimensions 
resulting formula ndim log nb log nb ndim actual value smaller usually space partitioned quad tree subspaces partitioned 
equations obtain values figures multiplying factors sgrid mhist 
instance buckets determined mhist dimensions imply overhead accesses data values 
case sgrid factor considered 
instance determine histogram dimension data trials covering wide range directions dimensions sgrid algorithm requires accesses data values 
clearly ki parameter chosen accordance number dimensions avoid large overhead higher dimensional datasets 
highlighted acceptable choices ratio average area trials maximum area trials sgrid technique 
multiplying factors sgrid ndim nb multiplying factors mhist nb buckets regression technique regression technique important context experiments provides algorithm simplest forms partitioning fixed grid partitioning 
effectively allows compare types adaptive partitioning strategies fixed grid strategy 
technique similar quasi cubes experiment divides space equal sized regions 
approximation achieved keeping coefficients regression line regression plane regression hyperplane best approximates bucket data 
quasi cubes rows columns marginal sums coordinates regression reconstruct points coordinates regression coefficients 
outlier handling supported 
evaluation section evaluate merits sgrid algorithm different data distributions compare mhist algorithm possible variations 
error measurement total error histogram approximation terror vi bucket vi belongs 
terror give estimate average error query average value point original space 
error measure expressed percentage way able compare results different datasets 
hand means extreme cases bad approximation produce value instance average data value average error means average value interval 
error magnitude adjustable simply varying number buckets 
chosen fixed number buckets experiment 
data distributions approach experimental evaluation different techniques model different distributions study behavior generating approaches 
approach populating space randomly distributed user defined number clusters normal distribution number clusters standard deviation specified user 
approach generates data zipf distribution said model typical joint data distributions databases attributes dependencies combinations attribute values occur frequently 
level dependency modeled parameter distribution 
high values imply strong dependence attributes small values imply uniform data 
data sets simplicity experiments focused dimensional space 
maximum number outliers considered 
representative subset results 
figures identify classes cluster zipf generated datasets 
label clusters stdev edge elems legend clustered dataset label edges elems label edges elems legend zipf dataset organized results dataset characteristics observed generation 
figures sgrid refers new technique regr refers fixed grid regression technique described section mhist evaluated different variants marginal calculation described section 
results labeled point estimation error labeled outliers refer reduction outliers 
shows shape typical distributions types studied 
quasi normal horse sell distribution quasi normal horse sell data sets dense space quasi normal distribution datasets result data values reasonably large standard deviation 
shows estimation error results data sets 
estimation errors data sets sgrid regr obtain similar results presence distributions mhist results worse 
distributions relatively easy regr data shows smooth monotone incline modeled lines 
mhist difficulty deciding appropriate splitting lines smooth 
half dense space horse sell datasets format results shown 
estimation errors data sets sgrid regr quite similar results better mhist 
different smooth monotone data sets 
shows typical peaked distributions corresponding clustered zipf data sets 
peaked zipf clustered distribution peaked zipf clustered data sets sparse space clustered distributions datasets contain cluster peaks reasonable large set clusters small standard deviation 
estimation errors data sets data sets irregular 
reason data analyzing algorithms sgrid mhist build better histograms fixed grid algorithms regr outliers help adapt distribution 
sgrid best results 
sparse space peaked distributions zipf generated datasets high single data value peaks remaining data sparse small valued 
careful data analysis important outlier support crucial 
estimation errors data sets sgrid achieves best results mhist able adapt 
thin peaks put outliers reducing error significantly 
execution times average execution times shown 
sgrid exhibits larger overhead mhist regr fastest algorithm adaptive 
algorithms partially optimized results give fuzzy idea actual execution time overhead 
mean execution times experiment experiments allowed determine important features algorithms handle various datasets 
regr algorithm fastest partitions space fixed grid manner problems zipfian heavily clustered data 
mhist algorithm cuts homogeneous regions produces partitioning data sets 
sgrid algorithm best 
directional trial parameter sgrid carefully chosen algorithm scalable higher dimensions 
discriminate outlier handling important eliminate large deviations 
mh mh reliable variants mhist similar results computation equivalent 
new technique histogram construction multidimensional data region coalescing sgrid compare alternative strategies histogram construction 
techniques mhist line algorithm regr fixed grid regression algorithm 
datasets studied understand behavior algorithms 
shown irregular distributions require data analysing algorithms sgrid mhist outliers help fixed grid techniques adapting irregularities 
sgrid consistently presents lower error mhist data approximation important data distributions better regr algorithm 
shown adaptivity pays execution overhead scalability price 
additionally shown outlier handling important addition reduce error algorithm 
barbara sullivan quasi cubes space efficient way support approximate multidimensional databases technical report ise dept september 
joseph hellerstein peter haas helen wang 
online aggregation proceedings acm sigmod international conference management data may tucson az 
yannis ioannidis universality serial histograms 
th international conference large data bases august dublin ireland proceedings 
morgan kaufmann pp 
yannis ioannidis stavros christodoulakis optimal histograms limiting worst case error propagation size join results 
transactions database systems tods yannis ioannidis viswanath poosala balancing histogram optimality practicality query result size estimation 
proceedings acm sigmod intl 
conf 
management data san jose california may pp 

david dewitt equi depth histograms estimating selectivity factors multi dimensional queries 
proceedings acm sigmod international conference management data chicago illinois june 
raymond ng 
jiawei han efficient effective clustering methods spatial data mining proceedings th international conference large data bases vldb september santiago de chile chile 
viswanath poosala yannis ioannidis peter haas eugene shekita improved histograms selectivity estimation range predicates 
proceedings acm sigmod intl 
conf 
management data montreal canada june pp 
poosala histogram estimation techniques database systems phd thesis university wisconsin madison 
poosala ioannidis 
selectivity estimation attribute value independence assumption 
proceedings rd vldb conference athens greece 
special issue data reduction techniques od bulletin technical committee data engineering ieee computer society december vol 

special issue supporting online analytical processing bulletin technical committee data engineering ieee computer society march vol 

wang yang muntz sting statistical information grid approach spatial data mining proceedings rd vldb conference athens greece 
zhang ramakrishnan 
birch efficient data clustering method large databases sigmod montreal canada 
george zipf human behaviour principle effort human ecology 
addison wesley 
