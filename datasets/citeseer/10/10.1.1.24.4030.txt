multicluster architecture reducing cycle time partitioning keith farkas farkas pa dec com paul chow pc toronto edu norman jouppi jouppi pa dec com toronto edu digital equipment western research lab university avenue palo alto california electrical computer engineering university toronto kings college road toronto ontario canada multicluster architecture introduce offers decentralized dynamically scheduled architecture register files dispatch queue functional units architecture distributed multiple clusters cluster assigned subset architectural registers 
motivation multicluster architecture reduce clock cycle time relative single cluster architecture number hardware resources reducing size complexity components critical timing paths 
resource partitioning introduces instruction execution overhead may reduce number concurrently executing instructions 
counter negative products partitioning developed static instruction scheduling algorithm 
describe algorithm simulations spec benchmarks evaluate effectiveness 
evaluation indicates configurations considered multicluster architecture may significant performance advantages feature sizes warrants investigation 
continuing challenge design microprocessors need balance complexity hardware speed clocked 
challenge exists increased hardware complexity impact cycle time processor ways 
component critical timing path increasing complexity component may increase cycle time processor 
second complex components may physically larger apart time copyright ieee 
published proceedings micro december research triangle park north carolina 
personal material permitted 
permission reprint republish material advertising promotional purposes creating new collective works resale redistribution servers lists reuse copyrighted component works obtained ieee 
contact manager copyrights permissions ieee service center lane box piscataway nj usa 
telephone intl 

signals travel may greater necessitating increase processor cycle time 
approach reducing consequences complexity partition hardware reducing complexity size components 
introduce dynamically scheduled partitioned architecture called multicluster architecture 
architecture implements dynamic scheduling dispatch queues explicit register renaming hardware basis dec alpha mips 
dispatch queues maintain pool instructions instruction scheduler issues instructions functional units register renaming map architectural registers named instructions larger set physical registers 
multicluster architecture dispatch queues register files functional units distributed multiple clusters 
instructions executed cluster dispatched dispatch queue cluster instructions instructions read write physical registers cluster cluster assigned subset architectural registers 
assignment architectural registers named instruction determines cluster execute instruction 
multiple cluster execution instruction names source registers accessible cluster names destination register uniquely assigned cluster section discusses assignment architectural registers clusters 
instructions clusters obtained single shared stream instructions fetched single instruction cache 
data cache shared clusters 
isolation cluster components provides benefits relative processor non partitioned architecture issue number instructions cycle clusters multicluster processor 
cluster issues fewer instructions cycle register files cluster require fewer read write register file bypassing register renaming instruction cache transfer buffers instruction dispatch queue execution unit execution unit data cache mem interface result operand central control result bypassing branch prediction register renaming instruction dispatch queue instruction scheduling control register file bypassing execution unit execution unit operand instruction scheduling control dual cluster processor built multicluster architecture framework 
ports 
number read write ports largely determines cycle time register file partitioning reduces cycle time processor 
dec alpha partitioned integer register file integer register file critical timing path 
second cluster issues fewer instructions cycle dispatch queue cluster requires fewer read write ports requires complex instruction scheduling logic 
consequently cycle time instruction scheduling hardware smaller 
example instruction queues mips critical timing path smaller cycle time obtained queues partitioned 
discussion multicluster architecture section describing architecture process instructions executed 
section describe successful static instruction scheduling algorithms developed 
section results simulation evaluation algorithm 
section reexamine motivation architecture light results suggest areas 
loss generality discuss multicluster architecture terms multicluster processor clusters 
model processor cluster comprises single dispatch queue multiple queues alpha register files integer values second floating point values 
architecture section describes multicluster architecture process instructions executed tradeoffs design multicluster processor 
complete description 
instruction distribution execution instructions read instruction cache fetch order distributed fetch order clusters 
instruction distributed cluster dispatch queue entry physical register available instruction stream stalled required resource available 
distribution instructions clusters registers named instruction cluster architectural registers assigned 
term local register refer architectural register assigned cluster term global register refer architectural register assigned clusters 
global registers typically stack global pointers commonly variables 
owing ease detecting architectural registers named instruction cluster register assigned hardware required instruction distribution relatively simple 
simplest case cluster configuration local registers identified bit mask cluster assignment registers register number odd 
simple distribution criterion especially important distribution cluster anticipated 
simple hardware mechanism exists support dynamic reassignment architectural registers see assume assignment static 
instruction executed names local register destination value computed instruction stored physical register cluster register assigned 
instruction executed names global register destination value computed instruction stored physical register cluster 
physical registers required maintain value global register cluster physical register required maintain value local register 
execution details execution instruction requires hardware perform sequence steps sequence dependent cluster named architectural registers assigned 
various scenarios sequences occur grouped main categories 
better examine categories consider integer add instruction scenario category 
scenario suppose registers named instruction local registers assigned cluster perform add hardware distributes instruction cluster distribution process comprises tasks source registers mapped physical registers cluster destination register renamed free physical register cluster instruction inserted free entry dispatch queue cluster source operands available suitable functional unit available hardware issues instruction reads source operands performs add writes result bound physical register 
scenario suppose registers local registers source register destination register assigned cluster source register assigned cluster perform add hardware distributes copy instruction clusters 
dual distribution provides mechanism source operand available cluster transfered cluster performs computation cluster 
master copy computation slave copy supplying source operands 
master copy executed cluster majority local registers named instructions assigned cluster selection master copy cluster discussed 
master copy distributed cluster renamed physical register belonging cluster 
slave copy distributed cluster allocated physical register destination instruction local register assigned cluster shows steps taken execute add instruction executing master slave copies 
steps explained 
exists data dependence slave copy time addition done master issued reg written slave issued reg written operand transfer buffer cluster cluster reg cluster reg reg dual execution instruction operand forwarded cluster immediately preceding instruction fetch order wrote slave copy issued dependence resolved integer issue slot available 
hardware requires integer issue slot issue slave copy slave copy read value integer register file requires access read port 
exists data dependence master copy immediately preceding instruction fetch order wrote dependence master slave copies 
dependence guarantees master copy issued second operand available 
master copy issued input dependences resolved suitable functional unit available 
write back stage execution pipeline slave copy writes value entry operand transfer buffer cluster master copy cluster 
entry operand transfer buffer allocated slave copy issued 
entry available slave copy blocked issued certain circumstances instruction replay exception required avoid issue deadlock see details 
slave copy writes value allocated entry stores unique id instruction copy 
id hardware associatively search operand transfer buffer locate operand associated master copy 
dependence master copy slave copy removed slave copy issued permitting master copy issued soon cycle 
master copy obtains value entry allocated slave copy freed 
entry instruction cycle 
scenario suppose source registers local registers assigned cluster destination register assigned cluster perform add hardware distributes copy instruction clusters time dual distribution provides mechanism result computation transfered cluster time slave issued reg written addition done master issued result copied result transfer buffer cluster cluster cluster reg reg reg dual execution instruction result forwarded cluster ation register assigned 
shows steps taken execute add instruction scenario steps explained 
source operands operation located cluster master copy instruction issued 
result computed forwarded slave copy 
slave copy issued writes forwarded result physical register bound second scenario physical register allocated slave copy destination register assigned slave copy cluster master copy cluster data transfer performed writing value computed master copy entry result transfer buffer cluster entry freed slave copy reads result entry prior writing result bound physical register 
prevent slave copy issued result available exists dependence slave master copies 
dependence removed cycles master copy due finish computing result simple cycle latency instructions add slave copy issued soon cycle master copy issued see description execution pipeline 
discussed separate result operand transfer buffers provided reduce implementation complexity reduce number times instruction replay exception required free buffer entry 
scenario suppose source registers local assigned cluster destination register global register 
destination global register slave master copies allocated physical registers inserted respective dispatch queues 
dual distribution provides mechanism physical register cluster allocated new value inter instruction dependences arising maintained dispatch queue value computed master copy written allocated physical registers 
sequence steps third scenario time result written buffer addition done master issued copy reg written reg cluster cluster reg reg reg slave issued copy reg written dual execution instruction global result forwarded cluster performed execute add exception master copy writes result slave copy result transfer buffer master copy writes result physical register allocated 
illustrates scenario 
scenario suppose source registers local registers destination register global register assigned cluster assigned cluster second scenario slave copy issued data dependence resolved integer issue slot operand transfer buffer entry available 
slave copy writes operand allocated entry hardware suspends 
master copy issued data dependence resolved suitable functional unit result transfer buffer entry available 
master copy obtains forwarded source operand frees operand transfer buffer entry associated cluster 
computes result writes allocated result transfer buffer entry associated slave copy cluster register file 
slave copy awakened obtains result frees result transfer buffer entry writes result register file 
illustrates steps scenario 
reg reg cluster cluster reg reg time slave issued slave wakes slave suspended copy reg written reg written buffer addition done master issued copy reg written result written buffer dual execution instruction operand forwarded cluster global result forwarded cluster performance obtained multicluster processor affected number instructions distributed cluster number distributed clusters instructions arranged instruction fetch stream order important affects resource availability 
dual distributed instructions require hardware resources instructions distributed cluster 
larger number dual distributed instructions contributes smaller instruction throughput 
addition instruction dual distributed copies operate pair perform required task 
mechanism supports cooperation introduces overhead dual distributed instruction requires clock cycles execute single distributed instruction assuming conditions 
dual distributed instructions contribute reduction throughput may require clock cycles execute 
note negative effects offset reduction cycle time processor clock provided partitioning hardware resources 
consequently application may require clock cycles execute multicluster processor single cluster processor run time may reduced 
related architectures number similarities differences exist proposed existing architectures multicluster architecture 
section briefly examines architectures 
aim multicluster architecture decrease cycle time processor permit single thread execution run faster 
partitioning components increase performance aims decoupled access execute architecture proposed smith 
architecture multicluster architecture consists tightly coupled clusters interconnected buffers 
clusters decoupled access execute architecture statically scheduled responsible reading writing memory responsible computing results 
decoupled access execute architecture requires values written read inter cluster buffers order 
access execute instruction streams may slip respect instructions different streams executed order 
multicluster architecture multiflow architecture physical registers functional units architectures distributed clusters respective machine 
mechanism exists multicluster architecture accessing registers clusters multiflow architecture alu arithmetic logic unit value stored registers associated alu value explicitly copied register register file step process coordinated compiler fact underlines hardware completely predictable true multicluster architecture due dynamic scheduling 
implication predictability multiflow architecture allows multiflow compiler balance performed alus encode single instruction stream 
discussed section balancing workload clusters multicluster architecture difficult due unpredictability dynamic scheduling 
multiscalar architecture ways similar multicluster architecture derive benefits partitioning large processor clusters execution resources 
addition architectures share common need static scheduling application keep functional units busy 
number important differences 
basis distribute instructions clusters multiscalar architecture information encoded binary compiler multicluster architecture basis architectural registers named instruction 
second cluster multiscalar architecture independently fetches instructions assigned clusters multicluster architecture share common instruction fetch stream 
result differences instruction scheduling multicluster architecture complex 
third important difference multiscalar architecture attempts exploit parallelism threads consisting basic blocks multicluster architecture primarily exploits parallelism basic blocks 
simultaneously multithreaded processors tightly coupled multiprocessors share property capable simultaneously executing independent operating sequences instructions called threads 
aim supporting capability reduce number clock cycles required execute multiple threads sequentially 
contrast aim multicluster architecture decrease cycle time processor permit single thread execution run faster 
static instruction scheduling static instruction scheduling process prior execution application machine level instructions ordered goal minimizing number clock cycles required execute application 
multicluster processor meet goal execution application instructions balanced clusters cluster concurrently performing similar amounts instructions executed cluster 
balanced workload desired cluster contains sub set total available hardware resources instruction distribution desired dual distribution increases hardware resource requirements execution latency 
workload balance directly addressed compiler done cluster function order instructions issued issue order deterministic dynamically scheduled processors 
compiler indirectly address workload balance seeking balance dynamic distribution instructions assumption balanced distribution result balanced workload 
objective balanced distribution competes objective minimum number instructions 
practice benchmarks considered performance cost instructions cost full advantage available hardware resources see 
consequently primary objective generate code schedule run generates instruction stream instruction distribution balanced 
address objectives compiler considers static instruction individually seeks register assignment data values instructions 
criterion select register cluster data value instruction distribution balanced 
compiler select register assigned subscribed cluster 
distribution balanced compiler select register allows instruction distributed cluster 
select register value instruction compiler determine instruction distribution balanced instruction run time 
compiler know order instructions fetched distributed 
information implicit ordered sequence instructions allocation values registers carried instructions ordered code schedule 
scheduling 
instruction balance estimated instruction register selection instruction compiler take account inter dependences instructions arise instructions value generated 
result source dependences decisions instruction affect instructions 
useful abstraction capturing source dependences live range 
code generation methodology code generation methodology takes account issues introduced previous subsection comprises steps 

application compiled intermediate language il applied conventional optimizations common subexpression elimination constant propagation 

il instructions arranged static code schedule 
il instructions correspond machine level instructions processor machine level instructions il instructions name live ranges registers 

live ranges associated stack pointer global pointer designated candidates global registers live ranges designated candidates local registers 
rational designation discussed 

live ranges candidates local registers partitioned goal maximizing concurrent utilization clusters minimizing number dual distributed instructions 

live ranges allocated architectural registers global register candidates allocated global registers local register candidates allocated local registers 

machine level instructions including required register spilling arranged code schedule 
steps correspond compilation problems code optimization code scheduling live range partitioning register allocation 
solutions problems handle unique characteristics multicluster architecture focused solving third problem live range partitioning problem captures idiosyncrasies architecture 
section briefly describe successful novel techniques developed solving problem sections briefly describe modified existing techniques solve compilation problems 
extensive description solutions problems 
code optimization code optimization problem solved techniques described aho 
problem arises early compilation application solutions relatively independent unique characteristics multicluster architecture 
limit scope research existing techniques modification 
code scheduling code scheduling problem best solved techniques tend generate large basic blocks 
techniques trace scheduling preferable due necessity estimating run time instruction imbalance basic block basis performing live range partitioning 
run time instruction imbalance function order basic blocks appear fetch stream static imbalance block 
ensure degree balance obtained run time compiler take account control flow paths basic block reached cluster allocation live ranges basic block 
owing complexity concurrently considering effects scheduling basic block basis mandated 
register allocation register allocation problem best solved graph coloring technique developed briggs 
technique suitable separates process coloring nodes process spilling live ranges 
separation phases provides convenient framework implementing desire spill live range local register cluster register available memory 
addition separation phases increases likelihood live range allocated register allows optimizations 
features compete increased likelihood live ranges spilled cluster multicluster architecture allocated subset architectural registers 
live range partitioning section describes local scheduler developed solve live range partitioning problem 
approach taken local scheduler determine live range intermediate language representation application cluster assigned ensure instruction distribution run time balanced vicinity instruction reads writes determine cluster assignments live ranges local scheduler begins sorting basic blocks number times instruction basic block estimated executed basic blocks equal estimates sorted number static instructions block 
basic block having largest estimate greatest number instructions removed list bottom order traversal carried instructions block 
example consider control flow graph shown execution estimates derived profiling execution application dual cluster processor 
basic block basic block basic block basic block basic block example control flow graph 
graph numbers parentheses give dynamic execution estimates basic block 
furthermore live range assumed candidate global register live ranges assumed candidates local registers 
estimates block numbers parentheses 
control flow graph basic blocks traversed order 
purpose traversal visit instruction turn instruction writes unassigned live range choose cluster live range 
cluster chosen live range written instruction examining instruction distribution instruction 
distribution balanced cluster chosen reduces degree imbalance 
instruction distribution considered unbalanced vicinity instruction run time point time distributed clusters execution number instructions distributed cluster number compile time constant 
reader referred formal definition imbalance 
distribution estimated balanced scheduler determines cluster preferred majority instructions read write scheduler selects cluster preferred cluster instructions assignment allow instruction distributed cluster 
bottom traversal basic block completed remain unassigned live ranges written instructions basic block 
completing bottom traversal basic block scheduler removes basic block list carries bottom traversal instructions 
process continues basic blocks visited 
result process cluster assignment live range determined time instruction encountered writes basic blocks traversals 
example local scheduler visit basic blocks order result live ranges assigned clusters order live range considered live range partitioning assumed candidate global register 
performance assessment performance impact schedulers developed determined atom object code instrumentation system simulate execution spec benchmarks 
simulations compiled benchmarks standard digital unix compilers workstations produce native binary 
atom analyzed native binary discover data control dependences instructions live ranges instructions read write 
atom standard compilers prohibited compilation techniques loop unrolling supported digital unix compilers improve performance multicluster architecture simplified implementation schedulers permitted fundamental scheduling problems focus 
identifying live ranges partitioned assigned architectural registers schedulers object code generated schedulers called rescheduled binary 
step schedulers assumed numbered architectural registers assigned cluster odd numbered registers cluster architectural register cluster assignment determined analysis early simulation results see details 
rescheduled binary instrumented atom linked multicluster simulator 
instrumentation took account new register assignments instruction code required spill live ranges 
combined application run number simulated clock cycles required execute application recorded 
number performance metric 
evaluate impact rescheduling compared performance obtained rescheduled binaries executed dual cluster processor obtained native binary executed single cluster processor 
comparison processor configured number resources entire dual cluster processor 
evaluation done way way issue processors results issue processor clearly show important trends 
simulation model single cluster dual cluster processors implement risc superscalar processor instruction set dec alpha instruction set 
processor supports non blocking loads non blocking stores allows instructions speculatively executed 
processor includes separate data instruction caches kbyte way set associative cache 
data cache assumed inverted mshr imposes restriction number flight cache misses 
memory interface instruction data caches lower levels memory hierarchy assumed cycle fetch latency unlimited bandwidth 
clock cycle processor fetch instructions instruction cache insert instructions dispatch queue 
processor entry dispatch queue cluster dual cluster processor entry dispatch queue 
enable fetching conditional branches processors branch prediction scheme proposed mcfarling comprises bimodal predictor global history predictor mechanism select control flow instructions assumed predictable 
instructions inserted dispatch queue architectural registers named renamed corresponding physical registers 
single cluster processor integer floating point registers cluster dual cluster processor integer floating point registers 
clock cycle instruction scheduling logic selects instructions issue dispatch queues greedy algorithm issues oldest ready issue instruction queue 
single cluster processor issue instructions cycle cluster dual cluster processor issue instructions cycle 
instruction issue rules processors second rows table functional unit latencies third row 
correctly executed instructions retired program order processor capable retiring cycle 
processors assumed implement precise exceptions cluster processor operand result buffer entries 
results common expected trend clock cycles required execute benchmark processor single cluster processor 
increase attributable increase number stalls instruction types integer floating point loads control multiply divide stores flow number issued single cycle dual cluster latency cycles table instruction issue rules single cluster row dual cluster row processors 
row gives functional unit latencies 
functional units fully pipelined exception floating point divider 
divider pipelined cycle latency bit divides cycle latency bit divides 
single load delay slot 
instruction fetch stream reduction number instructions issued cycle increase disorder slight increase data cache rate due increased issue disorder 
useful metric single number simulated clock cycles required execute native binary benchmark single cluster processor dual number simulated clock cycles required execute native binary rescheduled binary processor 
performance ratio said indicate speedup slowdown greater 
note performance really product number clock cycles period clock multicluster processor perform better single cluster processor clock period multicluster processor dual equal theta single performance ratios benchmark table percentage speedup slowdown 
percentage equal gamma 
comparison data points indicates general benchmarks incurred slowdown number clock cycles 
comparison performance ratios indicates exception ora speedup ratio benchmark local compress doduc gcc ora su cor tomcatv table speedup ratios gamma obtained benchmarks rescheduled column local scheduler rescheduling column 
local scheduler significantly reduces slowdown incurred running dual cluster processor 
furthermore case compress local scheduler benchmark performs better processor single cluster processor 
increase performance due single cluster processor having larger dispatch queue 
size dispatch queue important reasons 
larger dispatch queues greater amount time branch prediction branch predictor tables updated direction taken branch larger dispatch queues greater number predictions may information may reflect direction taken immediately preceding branches program order 
size dispatch queue important larger dispatch queue allows disorder issuing instructions 
case compress increase issue disorder leads increase cache rate performance degradation 
general better performance obtained local scheduler local scheduler generates code schedules result better utilization hardware resources 
particular local scheduler resulted higher degree concurrent utilization clusters reduction number dual distributed instructions 
addition local scheduler instructions issued order effect significantly fewer instruction replay exceptions required free operand transfer buffer entry 
exception trend ora local scheduler significantly increased number instruction replays degrading performance 
detailed analysis impact local scheduler 
considering ratios local scheduler indicates results worst case slowdown 
compensate increase clock cycles slowdown represents dual cluster processor processor clock period smaller gamma prediction point insertion dispatch queue updating occurs branch executed 
gamma gamma thetan single 
palacharla created delay models critical paths dynamically scheduled superscalar processors function issue width 
report process worst case delay increased ns issue processor ns processor increase 
difference cycle times issue processors process generation reducing cycle time partitioning improve performance 
process generation palacharla worstcase path increase moving issue processor issue processor 
larger relative delays wide issue machines feature sizes due wire delay increasing relative gate delays feature sizes reduced 
communication relatively expensive comparison computation 
larger cycle time difference narrow wide issue machines smaller feature sizes net effect partitioning multicluster architecture result significant performance increase 
introduced multicluster architecture decentralized dynamically scheduled architecture 
architecture register files dispatch queue functional units architecture distributed multiple clusters cluster assigned subset architectural registers 
motivation partitioning resources reduce size complexity components critical timing path centralized processor process reduce cycle time decentralized processor 
architecture provides mechanism allow register file cluster accessed instructions executed cluster 
mechanism distributing instruction cluster execution 
multiple distribution instructions increases number clock cycles required execute instructions reduces number instructions simultaneously execution 
negative effects offset reduction cycle time processor clock provided partitioning register file hardware resources 
consequently application may require clock cycles execute multicluster processor single cluster processor run time may smaller 
requirements application perform executing multicluster processor 
instructions required perform task balanced clusters cluster concurrently performing similar amounts 
requirement directly addressed compiler done cluster function order instructions issued issue order deterministic 
compiler indirectly address requirement ensuring distribution instructions clusters balanced 
second requirement number instructions distributed cluster minimized 
requirement seeks counter noted negative effects multiple distribution 
distribution instructions architectural registers named instructions static instruction scheduling process instructions ordered architectural registers assigned operands results instructions 
described novel algorithm developed implement process 
described results simulations performed number dual cluster processor configurations evaluate effectiveness algorithms 
processor cycle time analysis palacharla process negative instructions cycle effects partitioning slightly outweigh advantage gained reduction cycle time 
smaller feature sizes process model significant net performance improvement obtained 
believe multicluster architecture warrants investigation 
promising area investigation optimizations require information derived source code application consider owing limitations framework implement schedulers 
example techniques superblock scheduling trace scheduling increase number instructions jointly scheduled permitting better estimation runtime distribution workload 
loop unrolling part trace scheduling generate code schedule multiple iterations loop interleaved iteration scheduled separate cluster multicluster processor 
increase performance loop unrolling schemes devised decrease amount interaction iterations loop number inter cluster data transfers 
scheme duplicate code calculates addresses 
second scheme allocate key variables global registers variables accessed cluster inter cluster data transfer 
second set techniques exploit hardware mechanism see developed permit dynamic reassignment architectural registers clusters multicluster processor 
particular compiler provide hardware hints indicate reassignment directly specify architectural register cluster assignment architectural register 
functionality provide additional flexibility separating sequence instructions number threads 
acknowledgments research described partially funded natural sciences engineering research council canada digital equipment 
brad calder alan eustace helping atom simulation infrastructure annie warren jason wold logistical support simulations ran wrl putting simulations 
addition anonymous reviewers comments palacharla ahuja early architecture 
digital equipment providing alpha axp workstations 

digital sets new standard 
microprocessor report 
kenneth 
mips superscalar microprocessor 
ieee micro 
keith farkas 
memory system design considerations dynamically scheduled microprocessors 
phd thesis department electrical computer engineering university toronto ontario canada january 
url www toronto edu farkas thesis phd html 
james smith 
decoupled execute computer architecture 
proceedings th international symposium computer architecture pages 
geoffrey lowney stefan freudenberger thomas lichtenstein robert nix john donnell john 
multiflow trace scheduling compiler 
journal supercomputing may 
sohi scott breach 
multiscalar processors 
proceedings st international symposium computer architecture pages 
dean tullsen susan eggers joel emer henry levy jack lo rebecca 
exploiting choice instruction fetch issue implementable simultaneous multithreaded processor 
proceedings rd international symposium computer architecture pages may 
lance hammond olukotun 
evaluation design alternatives multiprocessor microprocessor 
proceedings rd international symposium computer architecture pages may 
alfred aho ravi sethi jeffrey ullman 
compilers principles techniques tools 
addison wesley publishing reading mass 
preston briggs keith cooper linda torczon 
improvements graph coloring register allocation 
acm transactions programming languages systems may 
amitabh srivastava alan eustace 
atom system building customized program analysis tools 
proceedings acm sigplan conference programming languages march 
keith farkas norman jouppi 
complexity performance tradeoffs non blocking loads 
proceedings st international symposium computer architecture pages 
scott mcfarling 
combining branch predictors 
dec wrl technical note tn 
palacharla norman jouppi james smith 
complexity effective superscalar processors 
proceedings th annual international symposium computer architecture pages 
chang scott mahlke william chen nancy warter wen mei hwu 
impact architectural framework multiple processors 
proceedings th annual computer architecture pages 
