symbiotic simultaneous multithreading processor allan university california san diego gilman drive la jolla california sdsc edu dean tullsen university california san diego gilman drive la jolla california tullsen cs ucsd edu simultaneous multithreading machines fetch execute instructions multiple instruction streams increase system utilization speedup execution jobs 
jobs system hardware support simultaneous execution operating system scheduler choose set jobs demonstrates performance hardware multithreaded processor sensitive set jobs operating system 
full benefits smt hardware achieved scheduler aware thread interactions 
mechanism allows scheduler significantly raise performance smt architectures 
done advance knowledge workload characteristics sampling identify jobs run 
demonstrate smt called sos 
sos combines overhead free sample phase collects information various possible schedules symbiosis phase uses information predict schedule provide best performance 
show small sample possible schedules sufficient identify schedule quickly 
system random job arrivals departures response time improved schedule incorporate symbiosis 

simultaneous multithreading smt architectures execute instructions multiple streams execution threads cycle increase instruction level parallelism :10.1.1.129.1383
jobs system hardware support simultaneous execution number hardware contexts implements multiprogramming levels 
running set jobs compete hardware resources cycle jobs move running set discretion os coarser granularity 
situation decides jobs running set 
term symbiosis refer effectiveness multiple jobs achieve speedup multithreaded machines 
jobs smt processor conflict various shared system resources 
throughput may go depending jobs running set get 
difference jobs 
job scheduler takes symbiosis account yield enhanced throughput response time 
presents symbiotic os level smt dynamically adjusts scheduling decisions enhance throughput lower response time 
scheduler begins jobs fairness policy 
sampling hardware performance counters periodically randomly perturbing sets jobs discovers job schedule entire increases system performance expected scheduling left chance 
call scheduler sos sample optimize samples space possible schedules making progress job mix 
examines hardware performance counters applies heuristic guess optimal schedule runs presumed optimal schedule boost system utilization 
sos scheduling improve system response time naive scheduler 
describe methodology experimental setup section introduce metric section measure progress execution 
section shows sos discovers efficient runtime counters predict combinations jobs run exhibits gains throughput 
sections discuss performance sos include parallel multithreaded programs section explores cache effects related techniques 
lastly section shows sos improves response time throughput system random job arrivals runtimes 

related simultaneous multithreading processor holds state multiple threads execution contexts hardware allowing execution instructions multiple threads cycle wide superscalar processor :10.1.1.129.1383
organization results doubling throughput processor excessive increases hardware 
techniques described apply multithreaded architectures smt architecture interesting threads interact fine granularity architecture closest widespread commercial having announced alpha processor 
contrast tera mta supercomputer features fine grain multithreading fewer shared system resources intimate interactions threads 
issues instruction cycle support order execution shared renaming registers data cache 
term symbiosis refer increase throughput occur particular jobs multithreaded machines exhibit user level schedule boosts throughput tera mta 
application massively parallel system largely protects threads 
scale scheduling problem great number factors determining threads interact relatively straight forward 
sobalvarro weihl gupta dusseau explore benefits parallel jobs communication patterns 
fact multiprocessor scheduler solve similar problem threads different processors maximize efficiency face bottlenecks shared system resource main memory communication fabric 
chapin emphasizes load balancing tucker gupta idea migrate threads utilized processors 
concentrated keeping cache warm favoring mapping threads processors executed 
traditional single threaded architectures leads increased throughput due overlapping job calculations 
scheduling discipline multi level feedback implemented flavors unix bsd unix unix system solaris ts timesharing scheduling class encourages bound jobs run frequently leading higher machine utilization 
bound jobs tend relinquish cpu soon obtain 
hardware support asynchronous allows cpu stay busy job serviced 
describes extension mach informed prefetching exploit jobs boost throughput dec workstation multiple scsi strings 
systems schedule software threads single threaded processors clusters single threaded processors 
explains daylight multithreading toolkit interface overlap computation increase system throughput 
describes method scheduling software threads hardware single threaded multiprocessor heuristic 
scheduling techniques strive jobs communicate frequently massively parallel mpp systems single threaded processors 
describes system dynamically jobs communicate frequently increase system utilization job response time 
improves gang scheduling dynamically produce emergent processes constituting parallel job 
improves gang scheduling fill holes utilization gang scheduled jobs pieces jobs require resources order progress 
evolves methods balancing demands parallel jobs waiting gang scheduled bound jobs require high cpu priority achieve interactive response times 
goal keep system highly utilized 
works explored tension scheduling system high utilization meeting objective function single threaded devoted real time mix jobs 
accounts scheduling overhead system dynamically schedules real time applications goal multiprocessor single threaded system efficiently meet maximum number deadlines 
describes scheduling mechanisms allowing system administrator balance demand fast turnaround demand high throughput 
administrator resources allow high utilization system resources origin 
describes hierarchical scheduling policy allowed tam machine schedule logically related threads closely time 
previous focused coarse grained overlapping computation single threaded hardware concentrated ways logically related jobs mpp systems single threaded focused mechanisms pack low priority jobs high priority jobs raise utilization hardware single threaded machines 
breaks new ground considering mechanisms increasing fine grained overlapping resource utilization hardware multithreaded machines jobs run reason 
previous takes account communication interaction need parallel jobs incorporates complex interactions jobs 
interactions phenomena particular multithreaded systems 

experimental setup smt processor comes equipped number hardware contexts roughly program counter set state holding registers 
number contexts determines threads executed number referred multithreading smt level 
selects pool jobs ready run number jobs equal multithreading level 
fairness running set swapped replaced new set jobs ready pool 
simulator models processor compaq alpha modest hardware additions support multithreading 
comes equipped performance counters capture dynamic execution information 
model instruction latencies functional units fully pipelined sizes instruction queues sizes caches tlb capacity 
particularly aggressive architecture study provides resource contention modest levels multithreading 
effects demonstrated evident wider processors may happen higher levels multithreading 
experiments detailed hardware multithreading levels 
multiprogrammed workloads single threaded multithreaded jobs spec int spec fp npb nas parallel benchmarks parallel program array parallel prefix operation array 
assume required progress jobs strictly fair manner jobs scheduled cpu number cycles course run 
cycles correspond millisecond timer interrupt mhz system receives clock pulse runnable jobs available scheduled previous timeslice swaps jobs ran timeslice replacing jobs 
schedule covering set job appears equal number 
jobs compete system resources cycle cycle scheduled timeslice 
goal find schedule exhibits highest average speedup jobs 
runs phases called sample 
follows label experiments tuple jmn number runnable jobs multithreading level number running jobs swapped replaced jobs runnable pool expiration timeslice 
character fs pg 
indicates multiprogrammed workload single threaded applications indicates workload includes parallel multithreaded jobs 
character ig indicates timeslice cycles indicates smaller timeslice 
example jsb single threaded jobs run time cycles job swapped replaced job running 
jobs selected swapped fifo effective resident timeslice job equal cycles 
example jobs array parallel jobs jobs run time entire running set jobs swapped cycles 
pb different run way see section 
exact jobs throughput experiment table 
experiment meant provide computational diversity 
combination high ipc floating point programs typical scientific computing fp mg ft lower ipc integer intensive codes typical workstation tasks gcc go 
particular effort represent jobs evenly ft example appears shows fp appears times 
experiment compare performance different schedules 
run number cycles sample phase sufficient profile schedules cycles phase 
number cycles required profile schedules timeslice cycles varies size multithreading level job replacement policy 
number cycles spent sample phase depends experiment table 
sample phase randomly permutes sets jobs records dynamic execution information observe performing 
experiments generates evaluates random schedules sample phase 
jsb possible schedules 
see table 
schedules represented permutations job identifiers starting parsed delineate 
example schedule jsb jobs taken time runs jobs tuple swaps replacing jobs 
consider identical tuples regardless order tuples scheduled 
jobs required run job runs swap fixed number jobs timeslice 
means average pressure memory subsystem regardless tuple order 
furthermore cache sweeping interaction jobs avoided simply changing order tuples schedule circular sequence tuples job sweeps job cache schedule 
section examine interaction symbiosis scheduling cache effects closely 
simulation benchmark partially executed 
avoids phase changes execution general benchmark sample phase typically starting 

weighted speedup jobs executed smt machine processor utilization go dramatically 
thread level parallelism tlp converted instruction level parallelism ilp 
net effect increase pool available execute instructions opportunity functional units utilized cycle 
wish formal measure goodness speedup 
intuitively executes useful instructions interval time symbiotic exhibits higher speedup 
suggests ipc measure speedup 
unfair schedule appear speedup favoring high ipc threads 
ensure experiments jobs jsb fp mg gcc jsb jsl fp mg wave gcc go pb fp mg wave swim su cor turb gcc gcc array array jsb jsb jsl fp mg wave gcc gcc go jsb jsb jsl fp mg wave swim gcc gcc go jsb jsb fp mg wave swim su cor turb gcc gcc go cg ep smt level cg mt array ep smt level fp mg wave mt ep cg smt level fp mg wave mt array ep cg smt level fp mg wave go gcc mt array ep cg ft table set applications experiments 
fp fpppp mg mgrid spec 
experiment distinct schedules sample cycles jsb jsb jsb pb jsb jsb jsl jsb jsb jsl jsb jsb table number distinct possible schedules time run schedules sample phase 
measuring real increases rate progress entire define quantity ws weighted speedup interval realized ipc job single threaded ipc job ws equalizes contribution thread sum total completed interval dividing instructions executing job behalf natural offer rate run 
implicit definition precise idea interval interval just measure elapsed time 
interval starts certain cycle particular point execution job 
interval ends certain cycle specific point execution job 
ws single threaded job running 
intuitive speedup due multithreading running thread 
importantly ws fair measure real done processing 
order value greater instructions executed case job simply contributed instructions proportion single threaded ipc 
short exercise may ws intuitive job single threaded ipc single threaded ipc run separately worst best weighted speedup multithreading levels job replacement policies 
cycles executed instructions 
cycles contributes instructions second contributes ws equal 
sense total number instructions executed exactly predicted natural ipc fair share machine scheduled 
machine utilization goes due primary aim purpose multithreading hope see instructions executed behalf job behalf total ws 
possible ws jobs interact pathological ways 
shows worst best weighted speedup observed different combinations smt multithreading level job replacement policy run permuted 
weighted speedup varies depending jobs run simultaneously 
symbiotic behavior jobs causes speedup vary average maximum limited number samples take 
clearly performance quite sensitive actual schedule cases potential symbiosis sensitive significant 

sos sos begins run jobs groups equal multithreading level fair policy allow runnable jobs progress 
initial phase called sample phase 
scheduler permutes schedule periodically changing jobs 
proceeds sample phase sos gathers dynamic execution profiles jobs run referencing hardware performance counters 
sampling performance schedule permutations sos picks thinks optimal proceeds run phase 
overhead occasional reading resetting counters typically necessary infrequently 
optimal ratio durations phase sample phase depends landscape changes 
time time jobs terminate new jobs enter system 
jobs naturally pass different phases execution resource utilization ipc profiles change 
experiments ratio sample approximately 
section models realistic system random job arrivals departures 
shared system resources predicting performance system needs ability find accurate predictor performance current snapshot counters 
hardware resources shared running threads smt cycle cycle include functional units instruction queues caches memory interconnections tlb renaming registers branch prediction tables 
part sharing competing resources threads interact ways contribute enhanced throughput 
thread uses system resource gone unused system utilization system throughput goes 
threads conflict resources utilization drop 
conjecture symbiosis function interrelated attributes schedule diversity instructions window instructions considered execution current cycle diverse 
goal keep functional units busy possible need instructions 
balance schedule alternates subscription subscription outperform balanced schedule 
system subscribed utilization throughput low 
system subscribed conflicts high little benefit accrues having sufficient functional units resources timeslice underutilized 
low conflicts fair schedules jobs lower conflicts perform bet weighted speedup achieved dynamic predictors jsb 
ter 
conflicts lower system utilization 
furthermore conflicts correlated previous attributes 
diverse instructions conflict smooth schedules lessen conflicts load balancing demand resources 
validity conjectures explored 
example jsb table shows dynamic predictor data gathered sos sample phase threads multithreading level 
possible ways dividing threads sets enumerated column 
see table possible fixed schedules jobs jobs time replacing timeslice 
sample phase run possible schedule cycles minimum time required evaluate schedule swap timeslice granularity cycles 
case cycle sample phase run possible schedules predictions performance possible schedules 
columns predictors gathered cycle sample phase 
best score column shown bold font predictors guess schedule perform subsequent cycle phase 
column weighted speedup schedule cycle phase 
shows weighted speedups obtained phase sos different predictors table vote tallying score 
predictors ipc schedule observed high ipc sampling phase predicted highly symbiotic 
schedule low sum conflicts integer queue floating point queue integer renaming registers floating point renaming registers scoreboard entries integer units floating point unit load store units sampling phase predicted highly symbiotic 
sum percentages cycles schedule conflicts schedule ipc dcache fq fp sum diversity balance composite ws table detailed results jsb including performance data collected various predictors sample phase weighted speedup schedule phase 
resources 
schedule lowest sum deemed best 
dcache schedule high hit rate data cache predicted highly symbiotic 
fq schedule low total conflicts floating point queue predicted highly symbiotic 
queue conflict arises instructions placed queue full 
fp schedule low conflicts floating point units predicted highly symbiotic 
sum schedule low sum conflicts floating point units floating point queue predicted highly symbiotic 
diversity schedule diverse mix instructions predicted highly symbiotic 
schedule lowest absolute difference percentage floating point integer instructions deemed best 
balance schedule little variation ipc consecutive predicted symbiotic 
schedule lowest standard deviation ipc deemed best 
composite schedule highest score minf fq fp sum balance predicted highly symbiotic 
lowest terms lowest values observed schedules sample phase 
predictor experimental fit correlates data gathered sample phase performance 
gives weight load balance weight low conflicts critical resources 
developed data jsb 
predictor sample phase highly correlated performance phase 
section evaluate predictor allowed see resulting performance decisions 
score schedule voted best majority predictors predicted best 
ties broken relative magnitude goodness predicted 
bar gives highest weighted speedup obtained possible schedules second bar gives lowest 
difference 
third bar average weighted speedup schedules thought expected throughput oblivious obtain 
best schedule better terms weighted speedup average 
smart find best schedule boost throughput 
rest bars show weighted speedup obtained sos various dynamic predictors guess schedules 
experiment predictors diversity avoided worst schedule 
ipc dcache fq composite score achieved best schedule gain expected value speedup 
particular expect performance gain average schedule naive choose unlucky schedule choice 
section shows similar results achieved wider range workloads architectures 
figures show results different show weighted speedup achieved sos scheduling combinations jobs multithreading levels job replacement policies 
jobs table 
case sampled schedules jsb possible schedules 
predict best dynamic predictors gathered sample phase run cycles phase see perform 
information gathered sample phase predict performance random schedules proceed run validate guesses 
note possible schedules jsb experiments see table schedules just statistical sample performance space cases 
figures confirm finding random schedules weighted speedup achieved sos different 
weighted speedup achieved sos 
produced substantial difference best worst schedule best average schedule sufficient identify schedule 
sampling find better schedule greater cost sampling phase 
shows sos discover schedule better average performance dynamic predictors dynamic predictors better 
interesting result ipc particularly predictor 
non intuitive high ipc means high system utilization essentially goal 
ipc quite variable granularity 
metrics typically stable sample sample mix provided better predictions performance 
temporarily high ipc schedule equate highest system throughput schedule happen high ipc threads system resources detriment low ipc threads sample phase 
diversity predictor effective variance diversity predictor great experiments 
insufficiently large manifest important effect 
balance predictor quite effective 
schedules balance demand system resources 
fact schedule balanced indication deliver high throughput 
predictor effective paradoxically high conflicts symptom high system utilization 
conflicts floating point queue floating point unit especially avoided processor model low scores fp fq sum predictor correlated performance 
dcache predictor inconsistent performer 
cases chose worst schedule 
kernels get cache reuse large seriously stress capacity cache run combination 
hit rate high little variation predictor schedules 
composite predictor uses criteria smoothness low conflicts consistent individual performer 
tried composite predictors 
intuitively predictor gives weight events detract performance dcache misses 
find correlation conflict penalty weight composite predictor 
conflicts cause drop throughput job progress 
loss job gain may negatively impact weighted speedup 
score tallies votes predictors best performer 
appears symbiosis leading increased throughput function factors 
score usually discovers best schedules 
ignoring moment gains exhibited special case explored section sos score predictor boosts weighted speedup unlucky schedules expected value random schedules 
best predictors general 
discovered effective ones particular simulation smt 
primary result predictors difficult find impact performance 

seen dramatic gain sos score predicted schedule increased gains due multithreading average 
artifact random scheduling 
array tight synchronization threads 
threads poor performance results 
random schedules threads array 
reasonably designed multithreaded system parent child threads job 
sos dynamically determines parent child threads run case 
feel justified claiming gain breakthrough result 
hand parent child thread communicate may best option 
pb uses variant array little synchronization 
case score predicted schedule parent child threads array outperforms 
see advantage dynamic scheduler sos scheduler uses rule thumb schedule parent child threads 
sos determines sense schedule threads performance 

hierarchical symbiosis automatic multithreading compiler technologies mature smt workloads include multithreaded jobs array 
compiler sophisticated generate code adapt number hardware contexts available runtime tera mta compiler additional degree freedom allocating resources decide contexts assign multithreaded job 
consider machine smt level workload includes multithreaded jobs array multithreaded version ep 
assuming sos decides array ep decide devote contexts array ep vice versa course keep single threaded third job 
turns devotes contexts array symbiotic complementary 
exactly ep array consider third possibility alternating threads ep array 
schedule worse best 
sos implement symbiosis levels deciding jobs deciding contexts give multithreaded jobs 
absence mta com improvements weighted speedup potentially achievable sos hierarchical symbiosis different levels multithreading 
piler smt hand coded multithreaded versions benchmarks different levels multithreading evaluated potential benefits giving extra degree freedom 
interestingly division resources optimal just ep array necessarily optimal larger schedule 
single threaded cg multithreaded ep array machine smt level optimal schedule context cg ep array 
resources job impact job 
case adding extra job mix changes optimal resource allocation 
sos heuristically approximate solution global optimization problem trying different ways dividing contexts sample phase 
extend definition ws include multithreaded jobs making denominator term equal issue rate job running jobs 
shows average percent improvement weighted speedup achievable sos score predictor various levels smt deciding threads sos determines threads devote parallel job 
seen levels choice allow sos significant advantage random average unlucky worst schedules 
smt level entries table give jobs experiments 

scheduling example jsb scheduling policy replaced members running set timeslice thread fixed partners schedule 
limits number possible schedules time required sample schedule making exhaustive sampling possible 
system may prefer swap job time reduce pressure memory subsystem 
furthermore experiments focused cpu bound infrequent system may event opportunity swap job bring new job sample new 
sos applies equally scheme job swapped time call scheduling sos samples number response time improvements obtained sos random various levels multithreading 
schedules picks observation 
benefits scheduling seen comparing jsb jsb comparing jsb jsb jsl comparing jsb jsb jsl 
recall experiments number triple swapped job timeslice 
effects increase utilization associated style scheduling 
resident timeslice single thread increases 
second pressure memory subsystem context switch decreases 
effect known 
longer job stays resident better amortizes cost warming memory subsystem 
experiments labeled benefit effects 
isolate effect simply reducing pressure memory subsystem swapping job time shortened swap timeslice experiments labeled 
seen modest gain symbiosis associated scheduling 
averages experiments labeled negligible cases 
results show symbiosis scheduling effective scheduling policies attempt minimize cache 

resampling response time job resource utilization profiles remain static time jobs come go enter system complete necessary repeat sample phase time time 
tension choosing rate resampling 
want sample little possible want maximize ratio duration phase sample phase 
allows amortize cost sampling 
want sample catch changes job execution profiles 
system designed adjust duration phase dynamically 
observed changing rapidly things changed lot previous sample phase sampling frequency goes 
stable sampling frequency goes 
model system jobs enter leave system exponentially distributed arrival rate exponentially distributed average time complete job study stable system number jobs system grow bound 
system sense measure response time throughput throughput possibly exceed rate job arrival 
stable systems compared faster faster complete jobs quickly typically fewer queued waiting run 
randomly generated jobs average distribution centered cycles generating random numbers distribution fetching instructions multiplied single threaded ipc jobs table 
purposes experiments job cycles worth instructions jobs table 
job arrival rate exponential distribution cause system remain stable equal double smt level little law 
time smt level jobs system 
model random system produce repeatable results fed jobs order arrival times sos control group scheduler 
control group scheduler random naive scheduler sense simply jobs tuples equal smt level order arrive 
sos hand selects symbiotic schedule sampling 
events trigger new sample phase job arrival job departure expiration symbiosis phase timer 
experiments default symbiosis interval 
new job arrives cycles new prediction old sos employs exponential backoff doubling time run sampling absence new job 
job arrives departs new prediction agree old duration symbiosis phase reverts experiments sos scheduler baseline scheduler swap jobs running set timeslice possible 
compares average response time delivered random delivered sos different levels smt multithreading response time improvement varying nearly 
response time improvement includes performance sampling phases speedup expected 
shows response time improvements sos random scheduler various job arrival rates smt multithreading level held constant 
arrival rates shown mean exponential distribution centered value indicated 
improvements shown differ smt level simply experiments different case different jobs random job lengths random orders arrival random rates arrival 
experiments concluded sos boosts response time substantially 
worthwhile resampling new job comes 
response time improvements obtained sos random various values cycles smt level held constant 
old schedule adjusted accommodate new job typically better random 
go straight sampling phase 
resource utilization profiles spec npb benchmarks quite stable 
experiments resampling new job arrived old job terminated result dramatic gains 
artifact stability spec npb benchmarks terms resource utilization 
expect workloads experience phased behavior 

demonstrates performance multithreaded processor sensitive set jobs operating system 
presents mechanism allows scheduler exploit phenomenon arrive schedule significantly improve performance 
done advance knowledge application characteristics sampling identify jobs run 
identify multithreaded parallel jobs perform better 
sos combines sample phase collects information various possible schedules symbiosis phase uses information predict schedule provide best performance 
show small sample possible schedules sufficient identify schedule quickly 
cost sample phase performance sample phase equivalent expected naive scheduler 
system random job arrivals departures response time improved schedule incorporate symbiosis 

anonymous reviewers useful comments 
larry carter symbiosis provided guidance suggestions 
wayne pfeiffer support 
jeff volker careful reading thoughtful observations progress 
supported part nsf career 
mip equipment compaq computer 
supported part nsf award asc darpa contract dabt 

science nas nasa gov software npb 
agarwal lim kranz kubiatowicz 
april processor architecture multiprocessing 
pages may 
callahan cummings koblenz porterfield smith 
tera computer system 
international conference supercomputing pages june 
arpaci dusseau culler mainwaring 
scheduling implicit information distributed systems 
sigmetrics 
blumofe leiserson 
scheduling multithreaded computations stealing 
proceedings th annual symposium foundations computer science nov 
chandra devine verghese 
scheduling page migration multiprocessor computer servers 
th international conference architectural support programming languages operating systems oct 
chapin 
distributed multiprocessor scheduling 
acm computing surveys mar 
camp 
turnaround vs throughput optimal utilization multiprocessor system 
sgi technical reports may 

daylight multithreading toolkit interface 
www daylight com meetings mug mt reentrant html may 

compaq chooses smt alpha 
microprocessor report dec 
dally carter chang gurevich lee 
machine multicomputer 
th annual international symposium microarchitecture nov 
gupta ticker 
impact operating scheduling policies synchronization methods performance parallel applications 
pages june 

dynamic scheduling real time aperiodic tasks multiprocessor architectures 
proceedings th hawaii international conference system sciences oct 
hirata kimura nishimura 
elementary processor architecture simultaneous instruction issuing multiple threads 
isca pages may 
lee frank lee mackenzie rudolph 
implications gang scheduled workloads 
rd workshop job scheduling strategies parallel processing apr 
leffler mckusick karels quarterman 
design implementation bsd unix operating system 
addison wesley 
little 
simple proof queuing formula operations research 
lo eggers emer levy tullsen 
converting thread level parallelism instruction level parallelism simultaneous multithreading 
acm transactions computer systems aug 
patterson gibson 
exposing concurrency informed prefetching 
proceedings third international conference parallel distributed information systems sept 
schauser culler thorsten 
compiler controlled multithreading lenient parallel languages 
proceedings fpca conference functional programming languages computer architecture july 
silva 
improving throughput utilization parallel machines concurrent gang 
proceedings ieee international parallel distributed processing symposium may 
nevin kimball loh 
mpi jobs spin daemon 
sc nov 
carter 
symbiotic mta 
workshop multi threaded execution architecture compilers jan 
mitchell carter ferrante tullsen 
explorations symbiosis multithreaded architectures 
workshop multi threaded execution architecture compilers jan 
sobalvarro weihl chien 
dynamic workstation clusters 
src technical note mar 
sobalvarro weihl 
demand parallel jobs multiprogrammed multiprocessors 
ipps pages apr 
thompson 
unix implementation 
bell system technical journal july 
thompson ritchie 
unix time sharing system 
communications acm july 
tucker gupta 
benefits cache affinity scheduling issues multiprogrammed shared memory multi processors 
acm sigmetrics may 
tucker gupta 
process control scheduling issues multiprogrammed shared memory multiprocessors 
symposium operating systems principals dec 
tullsen eggers emer levy lo 
exploiting choice instruction fetch issue implementable simultaneous multithreading processor 
isca pages may 
tullsen eggers levy 
simultaneous multithreading maximizing chip parallelism 
isca pages june 
tullsen 
simulation modeling simultaneous multithreading processor 
nd annual computer measurement group conference dec 
zahorjan 
implications cache affinity processor scheduling multiprogrammed shared memory multiprocessors 
symposium operating systems principals oct 
yamamoto nemirovsky 
increasing superscalar performance 
conference parallel architectures compilation techniques pages june 
