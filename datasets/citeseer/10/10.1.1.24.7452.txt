information retrieval krylov subspace method 
blom axel ruhe 
algorithm information retrieval developed 
searches documents data set relevant user query 
applies golub kahan algorithm term document matrix starting query vector 
development vector space method needs flexible latent semantic indexing lsi 
numerical tests small medline larger financial times data trec collection data sets reported 
key words 
information retrieval relevance feedback lanczos algorithm latent semantic indexing lsi vector space model singular value decomposition svd krylov subspace 


purpose information retrieval ir system seek large collection information items documents retrieve relevant information requests queries stated user 
contribution show computational tools numerical linear algebra helpful judgment user decide success failure 
large part relevant documents retrieved documents relevant user 
documents may books library documents data base news scientific papers journals web pages world wide web www 
document contain terms words significant way 
query formulated terms kind 
look document collection huge matrix row term occurs collection column represents document 
term document matrix denoted 
element ij row column nonzero th term document number zero 
term document matrix typically large sparse 
query expressed terms documents column vector th element nonzero th term part query zero 
simple ir algorithm choose documents contain terms query 
boolean search done ways 
term document matrix query vector just defined write row vector element scalar product query vector document column vector choose documents nonzero 
common linear algebra convention letting latin letter stand column vector stand transposing column row 
matrix columns 
vector space model refinement boolean search 
numerical values scalar products get angles query vector document vectors documents ranked starting smallest angle query vector 
latent semantic indexing lsi uses singular value decomposition svd term document matrix separate global general structure corresponding large singular vectors local noisy information hides small 
lsi reported perform quite large small document collections 
see example dumais 
handle synonymy words mean polysemy word distinct meanings depending context quite 
lsi needs substantial computational get svd simple way determine singular vectors needed span leading subspace 
done berry zha 
leary propose replace svd semi discrete decomposition sdd matrix approximated elements take values diagonal 
rank sdd larger rank singular value decomposition lsi matrices consist values sdd require storage svd lsi 
clustering approaches vectors grouped carefully selected set centroid concept vectors clear intuitive appeal see dhillon modha 
park compare singular centroid vectors general formulation low rank approximations term document matrix kleinberg studies information inherent link structure hyperlinked environment www 
column matrix document web page element ij nonzero link th page th 
borrow terminology scientific publication see garfield call term rows 
kleinberg calls cited documents columns authorities citing rows hubs 
leading singular vectors determine hub weight authority weight documents web pages 
kleinberg seeks documents high authority weight subset determined query 
problem approach leading singular vectors stand general weight factor high authority weight documents returned irrespective query kleinberg calls diffusion 
see ding studies link structures 
textual similarity give weights links bridging gap term document link similarity 
contribution limit text collections represented term document matrices sequence krylov subspaces starting query vector matrix language take query vector multiply transposed term document matrix get ranking scoring vector element scalar product query vector corresponding document vector elements give ranking vector space method columns normalized 
step krylov sequence find documents directly related query say sisters 
second step multiply scoring vector matrix get new vector ap new query contains terms contained documents pointed 
apply new query get points documents contain terms links away query say cousins 
steps continues chain letter fashion soon reach documents collection relation query 
computation just follow krylov sequence vectors orthogonal bases 
intuitively means remember asked query totally different query time standard practice numerical linear algebra 
angles document projection query vector krylov space score documents 
tried score documents computing principal angles document entire krylov space 
advantage approach compared lsi works original term document matrix svd computation needed outset trivial add delete terms documents queries 
main computational applications simple vector space search rest manipulation small matrices 
get fast convergence leading singular vectors give hub authority weights kleinberg 

summary contents 
section describe algorithm 
simply known golub kahan applied term document matrix starting query find projected query compute angles score document vectors give quantities determine convergence context algorithm stopped earlier stage instance solving squares problems 
section simple variant relevance feedback discussed 
ask user classify documents retrieved get improved starting vector second run algorithm 
section show algorithm closely related lsi simply differs choice subspace 
section show results numerical experiments small known medline data larger test matrix coming financial times collection trec conference material 
formulated algorithm got preliminary results licentiate thesis author 
experiments small matrices reported detail conference contribution 

notations 
denote theta term document matrix 
th column vector matrix denoted th column vector identity matrix denoted sigmav svd see 
best rank approximation frobenius sum squares norm sigma ss formed columns theta diagonal matrix sigma ss largest singular values oe oe delta delta delta oe diagonal 
seen mapping theta matrix maps dimensional space range space subspace spanned columns dimension rank krylov subspace square matrix starting vector subspace form av gamma vg 
algorithm 
algorithm propose golub kahan algorithm applied term document matrix starting query vector equivalent lanczos applied symmetric theta matrix starting vector take normalized query vector start kqk compute orthonormal bases adding column step see section 
algorithm start kqk fi 
ff gamma fi gamma 
fi ap gamma ff scalars ff fi chosen normalize corresponding vectors 
define theta theta ff fi ff 
ff fi steps basic recursion ap columns orthonormal basis krylov subspace span aa document space spanned query columns columns similarly span basis krylov subspace span term space spanned rows see ap projection krylov subspaces singular values approximations fi exhausted krylov space reachable query restriction reachable subspace singular values subset hand ff terms reached exhausted krylov space spanned restriction subspace singular values subset cases information directions search starting vector 
columns ap span reached subspace steps starting intersection krylov subspace column space ap span basic recursion implies orthonormal basis orthogonal factor qr factorization note orthogonal hessenberg computed product elementary rotations 
projected query vector 
easy basis project query documents reached subspace 
projected query pr apr 
see row gives coordinates query basis run steps algorithm new columns added column modified 
get projected document similarly scoring documents 
possible ways quantities obtained algorithm score documents relevance respect query natural mimic lsi see choose angles query document vectors projected reached subspace kqk alternatively may angles projected query original documents kqk ka compute quantities basis small orthogonal hessenberg 
apply elementary orthogonal transformation elements row zero 
forms new basis reached subspace 
element vector give component rest projected norm remaining elements cosine ky second slightly smaller ka experiments shown cosines angles projected query original documents scoring gives better performance standard 
gives preference documents vectors closer angle reached subspace 
measuring progress 
important follow progress iteration 
linear algebra measures distance query projection normal equation residual 
step distance query projected query gamma gamma gamma norm just kr jh decreases grow tend zero query linear combination documents get quantity tends zero follow normal equation residual ff ff norm ka jff starting scoring vector 
start scoring vector weighted combination documents 
natural reduce matrix upper form computing orthonormal bases krylov subspaces aa procedure ae ap gamma gamma gamma ae kpk 
start iteration procedure derived procedure discussed section 
relationships discussed paige saunders golub 

relevance feedback 
major problem finding relevant documents lies difference vocabulary user reflected query vector vocabulary document vectors 
relevance feedback relevant documents improve searches 
algorithm starting vector query vector plays important role improving starting vector performance algorithm may improve 
krylov subspace starting vector scoring vector model columns normalized 
second vector sequence gives scoring documents 
vectors form basis scoring vectors vectors easily modified relevance feedback user 
constructed starting vectors letting user judge best ranked documents vector model letting elements corresponding relevant document equal elements equal starting vector upper algorithm 
possible iterate steps procedure score documents give output user 
user judge answer judgement construct new starting vector start iterating steps score documents give output user 

relations lsi 
lsi term document matrix replaced best rank approximation 
similarity nearness query vector approximate document vector measured computing cosine angle vectors kqk ka sigma kqk ka sigma kqk ka sigmav kqk ka kqk ka kqk ka product projected query vector original document vectors projected query vector differs projected query vector leading singular values approximation leading singular values 
projected document vector differ way 
note kqk omitted scoring documents 
may replace projected document vector original denominator krylov space algorithm 
projected query avoid computing reduced rank approximation altogether 

numerical experiments 
measures 
standard measures information retrieval community precision recall 
precision ratio number relevant documents retrieved query total number documents retrieved 
recall ratio relevant documents retrieved total number relevant documents query 
precision recall usually inversely related precision goes recall goes vice versa 
recall level particular query arbitrarily chosen number relevant documents particular query 
order show precision various recall levels graphically interpolation may 
interpolated precision recall cutoff query defined maximum precision recall levels greater equal reporting results test sets multiple queries consider mean interpolated average precision queries fixed sequence recall cutoff values 
average precision apr single valued measure reflects performance relevant documents 
average precision average precision value obtained relevant document retrieved 
average precision reward systems rank relevant documents high relevant document equally important 
way compare performance finding relevant documents document level average dla precision certain number documents retrieved 
mimics search engine documents user time 
dla fraction relevant 
relevance judged comparing results algorithm relevance judgments provided test sets 
compiled panel human experts considered documents marked relevant 
details see harman 
experiments user simulated 
user score relevant documents relevant irrelevant documents irrelevant relevance judgments available test set 
data sets 
test collections consists document database set queries relevance judgments available 
ffl cranfield collection consists documents queries 
documents deals aerodynamics 
ffl medline collection consists documents queries 
documents deals medicine 
medline cranfield test collections old quite small 
test collections received ftp ftp cs cornell edu pub smart 
larger test collections received text retrieval conference trec 
ffl trec disc contains data collections financial times ft federal register fr congressional record cr 
ft collection fr collection cr collection consists documents respectively 
tests data medline collection financial times collection reported 
similar tests congressional record collection cranfield collection 
iq iq iq fig 

precisions recall medline collection 
left interpolated averaged queries 
line vector model line circles lsi rank dashed algorithm dotted 
algorithm relevance feedback 
right algorithm different queries 
parsing data sets 
medline collection data set parsed 
size matrix terms theta documents 
just zeros ones elements term document matrix theta ij ae term document term document starting process rows columns term document matrix normalized 
tends common terms long documents 
financial times collection algorithm determine set terms ffl non zero length string characters delimited white space return regarded term 
ffl terms occurred documents removed 
considered common words interest retrieval 
gave term document matrix size terms documents nonzero elements 
medline collection columns normalized starting 
results medline collection 
queries supplied test matrix indices relevant documents query 
gives relevant documents query altogether documents relevant query document relevant query 
compare results correct answers interested know quantities obtained computation determine query difficult simple handle method 
summarize performance averaged precision recall graph 
vector model compared lsi algorithm relevance feed back 
medline question singular values residuals basis sing val conv residual proj res fig 

medline matrix follow convergence procedure 
algorithm described section run steps 
relevance feedback method described section 
starting vector constructed letting user judge best ranked documents returned vector model letting elements corresponding relevant element equal elements equal 
lsi method optimal rank low rank approximation obtained computing sum average precisions query simply picking largest sum 
tests medline algorithms performed better pure vector model 
relevance feedback algorithm showed best performance 
requires relevance feedback user judge documents order construct starting vector strictly comparable 
include demonstrates importance starting vector 
results algorithm dimension fixed obtainable realistic case sense best average precision query occur subspace size 
note simple minded algorithm doing slightly better vector model 
follow algorithm query 
take query relevant documents medline query 
algorithm scores query quite 
follow progress linear algebra terms execute algorithm steps 
circles residual norms kr decrease slowly 
means query large angle reached subspace projection length 
plot normal equation residuals ka pluses note decrease fast linear rate 
steps projection query document space spanned 
curious see singular values converged plotted estimates accuracies points 
note leading singular value converged fast steps vector accurate singular value full machine precision 
known basis vectors keep orthogonal singular values converges verify plotted orthogonality basis vector predecessors gamma crosses true theory crosses points intersect half machine accuracy level step 
turn view documents see find relevant documents query 
plot dimensional coordinate system 
axis projected query 
axis plot component reached subspace orthogonal components vector 
infer length third component orthogonal reached subspace remembering vectors normalized unit length distances points plotted origin indicate close vectors reached subspace 
shown close origin far reached subspace 
continue full length vectors get unit length reached subspace span rare case query totally unrelated part document collection 
standard scoring method angles original documents projected query choose documents right left plotted check find relevant documents 
show giving ranking highest scored relevant documents 
look lower part 
comes document relevant comes point left numbered relevant 
come relevant missing 
relevant 
algorithm suggestions find relevant 
say dla document level average precision documents 
apr averaged precision relevant documents slightly lower relevant documents see scores number 
bad documents score 
final look lower half 
points axis denote documents orthogonal projected query ones scored 
documents orthogonal original projected query 
experiments shown run algorithm far apr reaches maximum steps matrix query 
look upper part 
projected query slightly shorter compared step points quite bit closer origin indicating components document vectors reached plane smaller 
hand relevant document scored giving dla relevant document scored number brings apr 
fig 

medline matrix query upper half step lower half step numbers rankings algorithm relevant documents 
circles mark relevant points relevant documents 
marks projected query 
scoring documents angles reached plane seen angles axis 
differ standard scoring gave slightly worse precision case apr 
third scoring choice angles krylov subspace seen directly plots amounts choosing documents plotted far origin gives choices somewhat lower precision fig 

interpolated precisions recall levels financial times collection trec database 
vector model compared algorithm algorithm relevance feedback 
average documents best ranked vector space method included 
case apr 
results financial times collection 
queries provided trec collection 
query number 
queries relevant answers financial times documents rest queries relevant documents 
altogether documents relevant query documents relevant queries documents relevant queries 
vector model compared algorithm run algorithm relevance feed back 
experiments way results lsi large matrix 
documents scored cosines angles 
choose dimension krylov subspace results better larger subspaces queries 
peculiar observation relevance feed back improve precision low recall medline relevance feed back improves performance medium recall region see 
choose query number report 
axis projected query axis plot component document vector reached subspace 
standard scoring method ranking documents 
labels show ranking relevant documents relevant documents quite seeking needle haystack 
note relevant documents get better ranking larger subspace different results medline 
question best questions included 
discussion 
experiments shown relevance feedback performance small database medline performance larger financial times ft set relevance feedback slight fig 

trec financial times matrix 
query upper half step lower half step numbers rankings relevant documents 
upper half documents interval lower half documents interval sample shown 
marks projected query improvement compared vector model seen 
notice major differences structure term document matrices distribution singular values differences sets 
ft set consists news medline consists medical documents 
documents medline collection appear distinguishable documents ft collection 
medline collection users probably agree relevance judgements set ft documents subjectivity involved relevance judgements 
instance fully agree relevance judgements topics ft collection 
believe larger sets reflect realistic case 
construction ft matrix plays role performance algorithm 
care taken deciding terms matrix 
remove terms occurring documents 
type row column normalization useful 
medline experiments normalized row vectors column vectors 
normalization column vectors destroys row normalization smoothing effect remains 
effect performance medline matrix 
ft matrix columns normalized 
starting vector query algorithm plays important role benefit algorithm pay attention construct query vector 
relevance feedback approach viewed action 
tried algorithm steps generating larger subspace time consuming method longer interesting realistic case 
starting vector looses importance longer iterate 
concentrate improving starting vector investigate relevance feedback approach algorithm 
berry dumais brien linear algebra intelligent information retrieval siam review pp 

blom information retrieval singular value decomposition krylov subspaces tech 
rep dept mathematics chalmers university technology goteborg 
issn 
blom ruhe information retrieval short krylov sequences computational information retrieval berry ed vol 
proceedings applied mathematics siam philadelphia pp 

dhillon modha concept decompositions large sparse text data clustering machine learning pp 

ding zha husbands simon analysis hubs authorities web tech 
rep cse department computer science engineering pennsylvania state university 
dumais latent semantic indexing lsi trec report harman editor third text retrieval conference trec nist special publication pp 

dumais furnas landauer deerwester harshman indexing latent semantic analysis journal american society information science pp 

garfield citation indexing theory application science technology humanities wiley new york 
reprinted isi press philadelphia 
golub kahan calculating singular values pseudo inverse matrix siam journal numerical analysis pp 

golub van loan matrix computations johns hopkins university press baltimore maryland ed 
harman eighth text retrieval conference trec nist special publication 
trec nist gov pubs trec appendix 
zha ding simon web document clustering hyperlink structures tech 
rep cse department computer science engineering pennsylvania state university 
kleinberg authoritative sources hyperlinked environment journal acm pp 

leary semi discrete decomposition latent semantic indexing information retrieval acm trans 
information systems pp 

paige saunders algorithm sparse linear equations sparse squares acm trans 
math 
soft pp 

park rosen lower representation text data vector space information retrieval computational information retrieval berry ed vol 
proceedings applied mathematics siam philadelphia pp 

zha marques simon large scale svd subspace methods information retrieval solving irregularly structured problems parallel ferreira simon teng eds springer lncs pp 


