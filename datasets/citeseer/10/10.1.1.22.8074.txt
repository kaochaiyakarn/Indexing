rj october computer science research report information theoretic external cluster validity measure byron dom limited distribution notice report submitted publication outside ibm probably copyrighted accepted publication 
issued research report early dissemination contents 
view transfer copyright outside publisher distribution outside ibm prior publication limited peer communications specific requests 
outside publication requests filled reprints legally obtained copies article payment 
ibm research division yorktown heights new york ffl san jose california ffl zurich switzerland information theoretic external cluster validity measure byron dom october propose measure similarity association partitions set objects 
motivation desire measure characterize quality accuracy clustering algorithms comparing clusters produce ground truth consisting classes assigned patterns manual means means veracity confidence 
measures referred external 
measure allows clusterings different numbers clusters compared quantitative principled way 
evaluation scheme quantitatively measures useful cluster labels patterns predictors class labels 
clusterings compared number clusters measure equivalent mutual information cluster labels class labels 
cases numbers clusters different computes reduction number bits required encode compress class labels encoder decoder free access cluster labels 
achieve encoding estimated conditional probabilities class labels cluster labels encoded 
estimated probabilities seen model class labels associated code length model cost 
addition defining measure compare commonly external measures demonstrate superiority judged certain criteria 
keywords clustering clustering accuracy clustering validity 
clustering problem common unsupervised learning problem clustering set omega objects patterns omega 
ji ng object representation 
feature space frequently treated dimensional continuum features may categorical 
goal clustering group objects grouping associated feature vectors 
follows usually speak clustering feature vectors usually drop notation dependence objects letting ultimate goal understood 
grouping fx ji ng number criteria 
assumed dimensions attributes relevant application interest 
grouping performed basis measure similarity relevant application associated feature space 
numerous objective functions algorithms clustering concerned task devise measure quality output clustering algorithms 
fk ji ng set cluster labels assigned elements labels taken set jkj number clusters 
clustering procedure maps definition clustering procedure omega gamma omega gamma procedure may determine optimal number clusters assignment feature vectors objects class labels may accept number clusters input 
set omega considered drawn larger population characterized probability density 
combination clustering procedure results probability distribution fp cluster labels 
define clustering problems 

pattern assigned cluster called partitional clustering 

pattern may assigned multiple clusters 
binary assignments 

pattern degree membership cluster 
measure propose applies partitional clustering 
addition categories distinction flat hierarchical clustering flat technically special case hierarchical depth tree 
measure applies flat clustering 
dimensions space referred variously features attributes measurements 
see survey 

evaluation problem evaluation validity quality accuracy output clustering algorithms difficult problem general 
measures indices cluster validity divided types external internal 
external validity criteria measure clustering results match prior knowledge data 
assumed information general computable common form external information set classes categories class labels objects corresponding usually obtained manual classification 
measure solely feature data internal measure begs question just measure objective function clustering 
may fact possible cases objective function exactly capture desirable particular application feasible algorithm finding optimal clustering 
cases evaluation problem moot 
cases course answer question may computational feasibility may possible devise algorithm efficiently find associated optimal clustering 
applications clustering algorithms attempt humans quite albeit slowly relative speed computer 
human sufficiency especially true case document clustering example natural language understanding vast amounts world knowledge specialized domain knowledge humans 
applications best accuracy quality measure human subjective judgments 
way obtain ask humans judge quality results directly 
expensive time consuming process algorithm variation single algorithm tried require new set subjective judgments 
alternative ask humans cluster data set consider appropriate set clusters 
done obtain set refer class labels fc ji ng idea intended users algorithm quite happy algorithm produced classes clusters 
treated ideal clustering quality judged measure cluster labels produced algorithm agree class labels 
accuracy assessment notion measuring quality clustering relative particular classification represented classification obviously result different measure general 
despite weakness external measures tend reliable usually preferable class labels available propose external validity measure appropriate flat non hierarchical clustering ground truth classification available evaluation purposes 
term different workers slightly different ways 
refer measure applied results clustering algorithm done job process clustering 
see appendix discussion external versus internal validity measures 
case cluster labels think sample drawn population described probability distribution fp think set pairs associated sample drawn population described distribution fp 
summaries class cluster relationship complete characterization behavior particular algorithm cluster data set course contained individual objects documents objects assigned clusters 
amount anecdotal evidence type invaluable diagnosing behavior clustering algorithm 
large numbers objects objects aggregate dealt manner 
reduced information essential 
partitional clustering usual level reduction expressed dimensional contingency table fh number objects labeled class assigned cluster perfect external measure point view clustering square matrix jcj jkj non zero element row column 
diagonal associated classes clusters label 
associated definitions dimensional marginal tables 
reduction embodied theta contingency table fa ij ji gg elements ij counts pairs vectors fx row index value indicates state pairs respect classes 
value indicates pairs assigned class value corresponds pairs occuring different classes 
similarly column index corresponds clusters classes 
associated definitions formulas terms 
number pairs vectors class cluster gamma 
number pairs occuring class cluster gamma 
number pairs occuring cluster class gamma 
number pairs vectors class cluster gamma 
column row sums 
ffl ffl symbol ffl place index indicates index summed 
example ffl ffl 
ij gamma delta total number pairs 

information theoretic external validity measure section describe proposed measure 

comparing clusterings number clusters fixed treat special case clustering problems number clusters known fixed advance 
problems measure essentially equivalent conditional entropy cjk defined cjk gamma jcj jkj log cjk don know distribution forced estimate 
refer associated estimate cjk empirical conditional entropy denote cjk cjk gamma jcj jkj log gamma general measure described section includes additional term depends primarily jcj jkj see appendix relatively insensitive details omit additional term pedagogical purposes 
see discussion conditional entropy mutual information 
alternately equivalently define empirical mutual information gamma cjk gamma jcj log cjk equivalent fixed ground truth set 
expect cjk measure clustering quality 
stated general approach equivalent asking expect measure usefulness elements predictors corresponding elements cjk number bits required encode compress class labels objects model assuming encoder decoder know fk worst case value cjk just number bits takes encode fc help fk case corresponds 
best case value cjk corresponds perfect correspondence corresponds 
conditional entropy external validity measure mutual information 
workers area discussed mutual information measure association categorical attributes 
assume external validity measure clustering viable comparing clusterings different numbers clusters 
discussed detail section 

clustering variable number clusters propose measure comparing output clustering algorithms designed determine number clusters clustering feature vectors 
cjk excellent measures clustering quality number clusters fixed deficiency don take number clusters consideration directly 
different clusterings compared cjk different numbers clusters fewer clusters usually preferable 
extreme case demonstrates clustering assigns different value object 
smallest possible code length cjk reality provides useful information 
missing coding scenario justifying cjk cluster labels useful predictors distribution available decoder 
coding analogy transmitted encoder decoder 
extreme cluster object example distribution equivalent list class labels objects 
assuming base logarithms 

cost encoding section explained conditional entropy validity measure number clusters fixed 
follows handle case variable number clusters add cost encoding estimation case distribution decoder knows fk fh encoder needs transmit predetermined encoding scheme code constructed code length equal cjk 
obtaining code length somewhat involved 
think matrix rows indexed columns quantity equal sum elements th column number possible columns corresponding number jcj component vectors non negative integer components summing 
combinatorial formula jcj gamma jcj gamma encode th column specifying integer index number 
assume columns consistent equally assumption code length integer index log 
number bits required encode entire matrix fh known log number consistent fh log jkj jcj gamma jcj gamma jkj log jcj gamma jcj gamma clustering quality measure smaller values better entire encoding cost data plus model object cjk jkj log jcj gamma jcj gamma encoding scheme implicit need additional term log bits encode jcj omit fixed constant ground truth set 
seen application minimum description length principle mdl 
note measure symmetric respect reasonable 
status sets labels equivalent context 

extreme cases list enumerates extreme cases measure 

perfect clustering minimum possible value occurs exactly clusters classes correspondence classes clusters 
case cjk equal zero cluster labels give perfect knowledge class labels left code length associated equal case jcj log jcj gamma jcj gamma 
fixed jcj jkj case worked detail appendix repeat result 
cjk jkj jcj gamma log large log term insignificant leaving cjk clusterings conditional entropy cjk different numbers clusters log term important deciding factor causes clustering smallest number clusters rated best smallest 

uncorrelated worst case maximum value occur cluster labels provide useful information class labels 
consider sub cases uncorrelated case 
jkj considering st term cjk 
nd term model encoding cost reduces log gamma jc gamma jcj gamma delta cost encoding fh jkj log jcj gamma jcj gamma jkj long cluster labels useful information class labels cjk increase jkj 
complete lack information strictly hold jkj strictly hold fh exactly divisible jkj 
ae jcj ae jkj hold approximately jkj impossible information case 
jkj case cjk class labels completely determined cluster labels known 
model encoding cost information utilized knows fh hand reduces log jcj cost simply directly encoding class labels assuming priori equally 
jkj log jcj may maximum value depending 
example clearly class labels equally priori cluster cost largest 
hand classes empty cluster cost largest 

possible forms measure modify definition analogous mutual information 
difference code length number bits required encode values gamma log bits 
code length difference equal log gamma jc gamma jcj gamma delta gamma jkj log gamma jc gamma jc gamma delta important qualitative difference symmetric respect 
discuss section external measures property best possible value equal worst zero 
transform property 
basic measure code length 
jcj log gamma jcj gamma jcj gamma delta clearly approached 
survey external validity measures extensive review related association measures prior including late th century papers goodman kruskal 

classification error external measure cases number clusters equal number classes classification error 
rows columns correspond associating majority class cluster cluster viewed confusion matrix pattern recognition sum elements divided total number objects total classification error 
problem ignores incorrect classifications distributed clusters 
distributed uniformly randomly clusters arguably worse going single cluster 
applying measure case number clusters different number classes problematic 
problem addressed defining normalized hamming distance associations arg max arg max directional hamming distance dh delta delta defined dh dh normalized hamming distance defined terms follows 
dh gamma dh dh 
measures jain dubes list commonly external measures partitional validity 
functions matrix defined section 
ffl rand ffl ffl fowlkes mallows ffl ffl ffl gamma statistic hubert schultz ma gamma gammaa ffl gammaa ffl 
comparison methodology compare clustering accuracy measures 
judging accuracy clustering algorithms difficult problem difficult meta question compares accuracy measures 
stated consider called external measures judge accuracy seeing closely appropriate sense partition objects produced clustering algorithm agrees deemed ideal ground truth partition 
constraint obviously reduced question constitutes best measure agreement clusterings 
discussed 
argument proceed follows 
acknowledging constitutes desirable accuracy measure depends particular application assert having general measure desirable assessing general clustering algorithms designed applications cases particular application targeted measuring relevant quantity time saved particular task may infeasible 
believe measure superior general measure acknowledge choice measure certain extent matter taste 
concession fact arguments 
argue measure superior appropriate cases comparing partition ground truth partition 
second argue doesn accept measure intrinsically superior acknowledged desirable qualitative properties produces different results measures cases accepted measure set choose 
support assertions 
show measure desirable properties 

argue philosophical grounds measure superior informationtheoretic basis 

show measures give counter intuitive simply incorrect results certain cases measure give desired behavior 

show measure gives results different produced commonly measures 

parametric form identify desirable properties clustering accuracy measure examine characterize statistical relationship class labels cluster labels corresponding set objects 
data set known class labels ground truth may characterized number objects number classes jcj distribution class labels fh thought sample drawn distribution characterized probability function fp addition dataset properties output clustering algorithm characterized number clusters joint distribution class cluster labels fh consider sample drawn population characterized fp define family distributions hope family captures essential characteristics distributions perspective characterizing accuracy clustering algorithms 
members family identified values certain parameters follows ffl jcj number classes ffl jcj ffl jkj number clusters ffl decomposition disjoint subsets useful noise 
cardinalities subsets jk jk respectively clearly jkj jk jk roles cluster subsets follows 
clusters completely noise sense correlation cluster labels class labels 
cjk jcj clusters useful set correlated classes decomposed jcj subsets fk jc cg correspondingly decomposed subsets fc jk role subsets follows 
probabilities equal 
sizes fk left parameters determine automatically follows 
jcj jk jk consists cluster jcj jk jc fc overlap corresponding cluster 
cluster class assignments proceed follows delta djk clusters assigned class 
delta jk gamma jc jcj gamma clusters assigned class 
delta 
number clusters assigned class ceiling ratio number unassigned clusters remaining number unassigned classes remaining 
jcj jk class cluster assignments proceed manner exactly analogous cluster class assignments jcj jk case 
ffl ffl total error probability ffl gamma ffl jk ffl ffl ffl error components ffl ffl ffl ffl ffl jk gamma jk ffl ffl jk kn ffl examples fp tables 
table class cluster joint probability distribution fp jk jcj ffl ffl cluster class table class cluster joint probability distribution jk jcj jk ffl ffl cluster class 
desirable characteristics clustering accuracy measures assume accuracy measure increases monotonically accuracy improves corresponding perfect clustering jkj jcj cluster corresponds class 
assume intend apply expected corresponding family distributions just defined 
fixed jcj behavior desire respect parameters table class cluster joint probability distribution jk jcj jk ffl ffl 
clusters noise useful 
cluster class family jk jk ffl ffl expressing answer terms differences derivatives respect single parameters held fixed table desirable properties jk jcj jcj gamma jk deltam 
jk jcj deltam 
deltam 
ffl equality holding jk 
ffl equality holding jk 
summarizing indicate clustering worse ffl number useful clusters varies away jk jcj ffl number noise clusters jk increases ffl error parameters ffl ffl increases 
analysis vis vis desiderata section simplicity base analysis discussion asymptotic forms measure 
consider variation respect various model parameters 
determined 
ffl jk certainly increasing jk jcj increase cjk model cost 
decreasing jcj increase cjk decreasing model cost 
see increase cjk dominate asymptotically 
ffl jk increasing jk holding ffl fixed increase model cost having effect cjk 
obvious due fact fraction ffl objects assigned noise clusters number noise clusters affects cjk 
ffl ffl ffl increasing ffl ffl clearly increase cjk effect asymptotic model cost jkj jcj gamma log ffl implies ffl 
shown measure satisfies desired characteristics asymptotically 
section exploration ability measures discussed satisfy characteristics certain set test cases 

comparison results comparison measures proceeds follows 
results obtained computing expected values corresponding specific values parameters jcj jk jk ffl ffl compute values various validity measures results form measure general behavior measures corresponds perfect clustering values decrease clustering accuracy gets worse 
forms measure obviously produce ordering group clusterings compared ground truth 

simple cases examining simple cases 
see jcj jkj jk jk 
ffl parameter varied range 
measures show desired expected behavior values decreasing increasing ffl second case examine hold jk ffl ffl fixed jcj increasing jk 
results shown 
measures show desired expected behavior decreasing jk measures require computing factorials certain values 
computed gamma function meaningful results obtained expected values non integer 
result computing external validity measures including varying error parameter ffl holding jcj jkj jk jk 
renormalized normalized vary range range ffl investigated 
result computing external validity measures including varying jk number useful clusters fixing model parameters values jcj jk ffl ffl 
renormalized normalized vary range range ffl investigated 

detailed comparison broad range model parameters 
comparison results calculated accuracy measure values reported section correspond fixed values jcj jcj 
model parameters varied values 
ffl jk values ffl jk values ffl ffl values ffl ffl values running complete range values result theta theta theta instances fp meaningless combinations jk non zero ffl values eliminated valid combinations 
valid parameter combination values measures rand fowlkes gamma hamming calculated 
clearly complete characterization behavior measures objectives 
ffl confirm analysis measure section 
absence violations desired characteristics proving hold cases evidence support contention 
ffl show measure produces unique ranking various cases ranking different produced measures 
ffl see measures violate desirability criteria cases suggest measure superior judged criteria 
results calculations associated ranks measures displayed graphically figures 
consists parts ranks various cases produced measures plotted versus ranks produced measure values measure plotted versus corresponding values 
seen figures values measures rankings range model parameter values explored measures clearly correlated measure produce different rankings 
measure clear alternative unique ranking 
comparison gamma measure ranks values comparison fowlkes mallows measure ranks values comparison hamming measure ranks values comparison measure ranks values comparison rand measure ranks values 
examination measures satisfy desirable properties section analyzed results calculations see desirable properties listed table section satisfied 
checking instances associated differences 
ffl measure satisfied tests 
ffl measures satisfied tests ffl criterion 
ffl measures rand satisfied tests ffl criterion 
observed cases rand failed test 
occured cases jk jcj jk jk jk 
ffl observed instances measures failing deltam tests 
rand hamming 
hamming cases minor deltam observed jk particular instances model parameters 
rand errors involved detecting peak jk 
large values error parameters ffl ffl ffl test created problems measures deltam 
difference ratio measured measures jk values combination values model parameters 
jk values ffl values ffl values time errors detected sequence measure values corresponding sequence jk values counted error 
distribution errors measures table 
note measures rand gamma hamming failed instances parameter triple jk ffl ffl 
hamming measure failed showed sensitivity parameter deltam 
table number cases various measures failed deltam test 
rand fowlkes gamma hamming 
discussion proposed evaluated new external cluster validity measure information theoretic considerations 
examined behavior measure ability satisfy certain desirability criteria 
compared commonly external validity measures 
general answer question clustering accuracy measure best depend particular application certainly impossible anticipate possible application 
cases judged accuracy best measured comparing results clustering algorithm ideal ground truth measure appropriate 
say measure propose offers choice list similarity measures appropriate comparisons measure may give relative ranking various clustering results different produced measures 
say stronger 
believe measure proposed superior measures certain fundamental sense 
information theory inception clearly demonstrated viability code length measure information content 
subsequent development theory algorithmic complexity extended ideas ultimately led minimum description length principle distilled essence extended 
reason feel measure embodies principles superior measures discussed consider heuristic nature 
course philosophical argument 
support shown compared measures measure satisfies set desiderata related measure values vary certain features class cluster distribution 
acknowledgment alex helpful detailed comments careful reading earlier draft document 
bradley usama fayyad cory reina 
scaling clustering algorithms large databases 
rakesh agrawal paul stolorz editors proceedings fourth international conference knowledge discovery data mining 
aaai press august 
thomas cover joy thomas 
elements information theory 
wiley new york 
dempster laird rubin 
maximum likelihood incomplete data em algorithm 
royal statistical society 
fowlkes mallows 
method comparing hierarchical clusterings 
journal american statistical association 
goodman kruskal 
measures association cross classification 
journal american statistical association december 
goodman kruskal 
measures association cross classification ii discussion 
journal american statistical association march 
qian huang byron dom 
quantitative methods evaluating image segmentation 
proceedings ieee international conference image processing icip 
ieee october 
hubert schultz 
quadratic assignment general data analysis strategy 
british journal mathematical statistical psychology 
jain dubes 
algorithms clustering data 
prentice hall 
isbn 
nicholas jardine robin sibson 
mathematical taxonomy 
wiley interscience london 
isbn 
dom niblack steele 
mdl multi band image segmentation fast region merging scheme 
technical report ibm research division may 
kolmogorov 
approaches quantitative definition information 
problems information transmission 
glenn milligan lisa soon 
effect cluster size dimensionality number clusters recovery true cluster structure 
ieee trans pami 
rand 
objective criterion evaluation clustering methods 
journal american statistical association 
rissanen 
modelling shortest data description 
automatica 
rissanen 
stochastic complexity statistical inquiry volume 
world scientific series computer science 
shannon 
mathematical theory communication 
bell syst tech 
peter robert sokal 
numerical taxonomy 
freeman san francisco 
isbn 
shivakumar vaithyanathan byron dom 
generalized model selection unsupervised learning high dimensions 
solla leen muller editors proceedings neural information processing systems 
mit press november 
shivakumar vaithyanathan byron dom 
model selection unsupervised learning applications document clustering 
dzeroski editors proceedings sixteenth international conference machine learning pages san june 
morgan kaufman 
shivakumar vaithyanathan byron dom 
hierarchical unsupervised learning 
proceedings seventeenth international conference machine learning stanford university stanford ca june 
zahn 
graph theoretical methods detecting describing gestalt clusters 
ieee transactions computers 
computing expectation discuss general problem computing expectations functions contingency table elements 
address specific problem obtaining expressions 
formal statistical clustering analyses assume set objects clustered sample drawn large population process source 
characteristics population combined clustering procedure yield probability distribution fp probability object drawn randomly population belong class cluster bernoulli parameter outcome 
distribution describing random variable multinomial distribution 
fh gamma fh delta represents multinomial coefficient fh 

write distribution number times randomly drawn object belong class cluster binomial distribution gamma gammah easy show ae oe efa ae oe results obtain efa ae oe gamma efa gamma efa ae oe gamma efa gamma efa gamma efa efa efa gamma gamma efa ffl ae oe efa ffl ae oe asymptotic form examine asymptotic behavior quality measure repeat cjk jkj log jcj gamma jcj gamma term equation cjk cjk second term model cost takes little analyze 
consider behavior gamma delta fixed 
gamma 
gammak 
numerator expression written gamma gamma gamma terms th degree polynomial coefficient highest order term 

log log apply result individual terms log jcj gamma jcj gamma log jcj gamma jcj gamma jcj gamma log jcj gamma jcj gamma log jkj log jcj gamma jcj gamma jkj jcj gamma log gives cjk jkj jcj gamma log large log term insignificant leaving cjk clusterings conditional entropy cjk different numbers clusters log term important deciding factor 
discussion external vs internal validity measures supplementary discussion issues related question types validity measures internal external appropriate situation 
discuss case internal measure may appropriate doing clustering process density estimation 
expand case external measures discuss crucial issue external measures obtaining appropriate ground truth set 

case internal measures validated likelihood internal validation measure sorts may appropriate certain cases example common approach doing clustering doing density estimation 
process involves estimating probability model characterizes data generating mechanism 
usual assumption data probability complete data set model usually structure associated parameters estimated 
specification structure includes number clusters 
example fit mixture density form ff ff ff component densities fff mixing coefficients ff 
example mixture gaussians frequently fitting usually performed expectation maximization em algorithm 
mixture fitting part clustering procedure mixing coefficients interpreted marginal cluster probabilities component densities conditional densities xjj 
compute jjx jjx xjj xji partitional hard clustering assign object corresponding cluster jjx maximum 
values fp jjx interpreted degrees membership soft clustering scheme 
standard way evaluate density estimation process take validation set drawn population model estimated compute probability density referred validated likelihood model 
reason external validation set original data preclude overly optimistic estimate due fitting 
potential problem validation set strategy amount data available may limited relationship number objects vectors number adjustable parameters optimum model may data needed get reliable estimates model structure parameters 
case technique cross validation 
fold cross validation divided non overlapping subsets vectors 
subsets model estimation process performed complement likelihood measured withheld subset 
performed subsets likelihoods averaged get final estimate 
extreme form known leave measure internal sense score feature values external sense feature vectors set mixture fitting separate validation set 
density estimation clustering evaluation validated likelihood may reasonable 
problem may give weight ability model describe distribution features little ability discriminate underlying clusters 
extreme form features called noise features identified example model selection clustering algorithms 
features follow distribution clusters 
case validated likelihood may appropriate clustering algorithm determines features clustering 
different density estimation clustering algorithms may operating different feature spaces associated likelihood values compared directly 

case external measures 
cases internal validation impossible addition cases described density estimation clustering validated likelihood may problematic cases density estimation isn 
fact cases feature values described pairwise similarity values 
clustering algorithms handle cases methods graph analysis 
early example minimum spanning tree mst 
cases external methods provide best choice choice validation measures 

ground truth goodness quality assessment performed external measure obviously limited quality validation set ground truth labels 
set objects representative algorithm encounter practice labeling obviously reflect task desired clustering algorithm perform 
certain cases constructing validation set may problematic 
example cases may meaningful way cluster set objects 
aspect granularity issue objects fit hierarchy categories taxonomy level hierarchy ground truth labels reflect 
difficult issue 
suppose wishes evaluate general purpose clustering algorithm multiple unrelated ways cluster objects 
validation set objects labeled cases 
propose answers 

case hierarchy labels reflect lowest level hierarchy 
clustering algorithm chooses cluster higher level hierarchy receive reasonable accuracy score due power labels higher level nodes predicting bottom level labels associated objects reduce number bits required encode bottom level labels 

second case multiple possible organizations set classes corresponding cartesian product sets organizations constructed class combined set treated different class 
possible organizations corresponding sets classes fa fb fc new set classes theta theta fa class corresponds objects intersection case best accuracy score obviously obtained discovering complete theta theta organization discovering single organizations associated pairs theta rewarded knowing associated labels allow full theta theta labels encoded fewer bits 
limited flat partitional clustering 
variation measure hierarchical clustering planned 
obviously important number objects class validation set sufficient allow underlying structure captured 
cartesian product classification scheme just outlined may result large number labeled objects required sufficient validation set 
practical considerations preclude large numbers objects proceed carefully attempting observe example clustering algorithm discovered viable structure reflected validation set 

