adaptive efficient algorithm detecting approximately duplicate database records alvaro monge california state university long beach cecs department long beach ca june integration information important area research databases 
combining multiple information sources complete accurate view world attained additional knowledge gained 
non trivial task 
sources contain information certain kind entity contain records concerning real world entity 
furthermore source may exact information source contains 
information may different due data entry errors example may missing altogether 
problem integrating information sources identify possibly different designators entity 
data cleansing process purging databases inaccurate inconsistent data 
data typically manipulated form useful tasks data mining 
addresses data cleansing problem detecting database records approximate duplicates exact duplicates 
efficient algorithm combines key ideas 
smith waterman algorithm computing minimum edit distance domain independent method recognize pairs approximately duplicates 
second union find data structure maintain clusters duplicate records incrementally pairwise duplicate relationships discovered 
third algorithm uses priority queue cluster subsets respond adaptively size homogeneity clusters discovered database scanned 
results significant savings number times pairwise record matching algorithm applied impairing accuracy 
comprehensive experiments synthetic databases real world database confirm effectiveness ideas 
key words merge purge data cleansing approximate duplicate database transitive closure smith waterman edit distance 
research areas knowledge discovery data cleansing seen growth 
growth due number reasons 
obvious exponential growth information available online 
particular biggest impact comes popularity internet world wide web www web 
addition web traditional sources information relational databases impacted growth information available online 
availability sources increases amount data variety quality data appears 
factors create number problems 
concentrates problem detection multiple representations single entity 
data cleansing process cleaning databases containing inaccurate inconsistent data 
inconsistency existence different multiple representations real world entity 
task detect reconcile differences single representation 
differences may due data entry errors typographical mistakes abbreviations differences detailed schemas records multiple databases reasons 
information multiple sources integrated real world entity duplicated 
detection records approximate duplicates exact duplicates databases important task 
solution problem data mining algorithms rendered useless depend quality data mined 
presents solutions problem 
duplicate detection method proposed date including requires algorithm detecting duplicate relationships pairs records 
section summarizes algorithm determine records represent entity 
record matching algorithms monge database level duplicate detection algorithms section 
section starts defining problem identifying related area 
typically record matching algorithms relatively expensive computationally database level duplicate detection algorithms grouping methods reduce number times applied 
major contribution article sections section provides empirical evaluation duplicate detection algorithms including comparison previous 
article concludes section final remarks 

algorithms match records knowledge discovery database mining applications need combine information heterogeneous sources 
information sources relational databases worldwide web pages provide information real world entities describe entities differently 
resolving discrepancies entities described problem addressed section 
specifically record matching problem determine syntactically different record values describe semantic entity real world object 
solving record matching problem vital major knowledge discovery tasks 
ffl ability perform record matching allows identify corresponding information different information sources 
allows navigate source combine information sources 
relational databases navigating relation called join 
record matching allows joins information sources relations strict sense 
worldwide web knowledge discovery application uses record matching join separate internet information sources called described 
ffl second ability record matching allows detect duplicate records database multiple related databases 
duplicate detection central issue called merge purge task identify combine multiple records database concern entity distinct data entry errors 
task called data scrubbing data cleaning data cleansing 
detection problem focus article studied detail section 
article propose solutions question done duplicate records detected 
ffl third doing record matching way solve database schema matching problem 
problem infer attributes different databases columns relations relational databases denote real world properties objects 
values attribute matched pairwise values attribute infer inductively attributes correspond 
technique schema matching internet information sources information learning agent ila example 
remaining section discusses related area record matching stating record matching problem precisely 
section briefly summarizes domain independent record matching algorithms proposed 

defining problem record matching problem recognized important years 
papers studied matching medical records name record linkage 
papers concerned identifying medical records individual different databases purpose performing epidemiological studies 
record matching recognized important business decades 
example tax agencies record matching correlate different pieces information taxpayer social security detecting approximately duplicate records numbers missing incorrect 
earliest duplicate detection business database 
record linkage problem business focus workshops sponsored census bureau 
record matching useful detecting fraud money laundering 
published previous record matching specific application domains gives domain specific algorithms 
example papers discuss record matching customer addresses census records variant entries lexicon 
record matching domain specific assumes domain specific knowledge supplied human application domain 
important area research relevant approximate record matching approximate string matching 
string matching studied problems computer science 
main approach edit distance 
edit distance minimum number operations individual characters substitutions insertions deletions needed transform string symbols 
survey authors consider different problems definition equivalence second similarity 
definition equivalence allows small differences strings 
examples allow alternate spellings word ignore case letters 
similarity problem allows errors due typing transposed letters missing letters equivalence strings mathematical notion equivalence respects reflexivity symmetry transitivity property 
similarity problem hand difficult problem typing spelling errors allowed 
similarity problem necessarily transitive respects reflexivity symmetry properties 

proposed algorithm word record mean syntactic designator real world object tuple relational database 
record matching problem arises records identical bit bit sense may refer object 
example database may store name name person jane doe database may store initials name person doe 
say records equivalent equal semantically designate real world entity 
semantically problem respects reflexivity symmetry transitivity properties 
record matching algorithms solve problem depend syntax records 
syntactic calculations approximations really want semantic equivalence 
calculations errors bound occur semantic equivalence properly calculated 
claim errors approximation 
experiments section provide evidence claim 
equivalence may question degree function solving record matching problem returns value means certain equivalence means certain non equivalence 
study assumes scores ordinal particular scalar meaning 
degree match scores necessarily probabilities fuzzy degrees truth 
application typically just compare scores threshold depends domain particular record matching algorithm 
record matching algorithms vary amount domain specific knowledge 
pairwise record matching algorithms previous application specific 
example authors production rules domain specific knowledge written ops programming language rule production systems primarily artificial intelligence translated hand section presents algorithms pairwise record matching relatively domain independent 
particular proposes generalized edit distance algorithm 
domain independent algorithm variant known smith waterman algorithm originally developed finding evolutionary relationships biological protein dna sequences 
record matching algorithm domain independent monge tions range applications 
definition smith waterman algorithm domainindependent assumptions records similar schemas records alphanumeric characters 
assumption needed smith waterman algorithm address problem duplicate records containing fields transposed 
second assumption needed edit distance algorithm assumes records strings fixed alphabet symbols 
naturally assumption true wide range databases including numerical fields social security numbers represented decimal notation 

smith waterman algorithm strings characters smith waterman algorithm uses dynamic programming find lowest cost series changes converts string minimum edit distance weighted cost strings 
costs individual changes mutations insertion deletions parameters algorithm 
edit distance algorithms spelling correction text applications show edit distance method effectively general textual record matching 
matching textual records define alphabet lower case upper case alphabetic characters digits punctuation symbols space comma period 
characters removed applying algorithm 
particular choice alphabet critical 
smith waterman algorithm parameters alphabet sigma sigmaj theta sigmaj matrix match scores pair symbols alphabet 
matrix entries exact matches approximate matches non matches symbols alphabet 
original smith waterman algorithm matrix models mutations occur nature 
matrix tries account typical phoneme typing errors occur record entered database 
power smith waterman algorithm due ability introduce gaps records 
gap sequence non matching symbols seen dashes example alignments 
smith waterman algorithm parameters affect start length gaps 
scalar cost starting gap alignment cost continuing gap 
ratios parameters strongly affect behavior algorithm 
example gap penalties relatively inexpensive continue gap smith waterman algorithm prefers single long gap short gaps 
intuitively smith waterman algorithm allows gaps unmatched characters cope abbreviations 
perform records small pieces missing information minor syntactical differences including typographical mistakes 
smith waterman algorithm works computing score matrix strings placed horizontal axis matrix second string goes vertical axis 
entry matrix best possible matching score prefix string prefix second string 
prefixes entire strings match exactly optimal alignment main diagonal 
approximate matches optimal alignment small distance diagonal 
formally value max gamma gamma letter letter gamma align gamma gamma ends gap gamma align gamma gamma ends match gamma align gamma gamma ends gap gamma align gamma gamma ends match experiments reported smith waterman algorithm gap penalties match matrix 
parameter values determined small set technically variant needleman wunsch algorithm calculates minimum weighted edit distance entire strings 
strings better known smith waterman algorithm finds substring string pair substrings minimum weighted edit distance 
detecting approximately duplicate records department chemical engineering stanford university ca dep 
chem 
eng stanford univ ca usa 
psychology department stanford univ palo alto calif dept psychol stanford univ ca usa 
fig 
optimal record alignments produced smith waterman algorithm 
affiliation records 
experiments showed values chosen intuitively reasonable provided results 
match score matrix symmetric entries gamma exact match scores regardless case approximate matches score 
approximate match occurs characters sets fd tg fg jg fl rg fm ng fb vg fa ug penalties starting continuing gap respectively 
informal experiments just mentioned show penalty start gap similar absolute magnitude score exact match letters penalty continue gap smaller score approximate match 
conditions met accuracy smith waterman algorithm nearly unaffected precise values gap penalties 
experiments varied penalty starting gaps considering values smaller greater exact match 
similarly penalty continue gap varied considering values greater 
final score calculated algorithm normalized range dividing times length smaller records compared 
shows typical optimal alignments produced smith waterman algorithm choice parameter values described 
records shown taken datasets experiments measuring accuracy smith waterman algorithm record matching algorithms 
examples show chosen values gap penalties algorithm detects abbreviations introducing gaps appropriate 
second pair records shows inability smith waterman algorithm match order 
smith waterman algorithm uses dynamic programming running time proportional product lengths input strings 
quadratic time complexity similar basic record matching algorithms 
smith waterman algorithm symmetric score matching record score matching symmetry may natural requirement applications record matching 
example name alvaro monge matches monge reverse necessarily true 

algorithms detect duplicate database records section considers problem detecting records database duplicates textually identical 
multiple duplicate records concern real world entity detected order consistent database 
multiple records single entity may exist typographical data entry errors abbreviations differences detailed schemas records multiple databases reasons 
problem consolidating records databases entity represented single record 
necessary crucial preprocessing step data warehousing data mining applications data collected different sources inconsistencies lead erroneous results 
performing data analysis operations data preprocessed organized consistent form 

related duplicate detection problem different related schema matching problem 
problem find correspondence structure records database structure records different database 
problem detecting monge matching records exists schema matching problem solved 
example consider records different databases include personal names 
fact personal name attributes record detected schema matching 
record level approximate duplicate detection needed order combine different records concerning person 
record level duplicate detection record matching may needed typographical errors varying abbreviations related records 
record matching may substitute detailed schema matching may impossible semi structured data 
example records differ detailed format personal names addresses 
records follow fixed high level schema fields may follow fixed low level schema division fields subfields may standardized 
general interested situations records may refer real world entity syntactically equivalent 
set records refer entity interpreted ways 
way view records correct records duplicates containing erroneous information 
task database duplicate records 
interpretation consider matching record partial source information 
aim merge duplicate records yielding record complete information 

standard method improvements standard method detecting exact duplicates table sort table check neighboring tuples identical 
exact duplicates guaranteed sorted order regardless part record sort performed 
number optimizations approach described 
approach extended detect approximate duplicates 
idea sorting achieve preliminary clustering pairwise comparisons nearby records 
case guarantees duplicates located relative sorted order 
scenario approximate duplicate records may nearby 
worse case opposite extremes sorted order 
result depends field sort probability error field 
sorting typically application specific key chosen duplicate records appear near 
authors compare nearby records sliding window fixed size sorted database 
window size record compared records gamma gamma records gamma 
number comparisons performed tw total number records database 
order improve accuracy results passes duplicate detection combined 
typically combining results passes database small window sizes yields better accuracy cost pass database large window size 
way combine results multiple passes explicitly computing transitive closure discovered pairwise duplicate relationships 
record duplicate record record duplicate record transitivity duplicate record transitivity true definition duplicate records concern real world identity practice errors computing pairwise duplicate relationships transitivity propagate errors 
typical databases sets duplicate records tend distributed sparsely space possible records propagation errors rare 
experimental results confirm claim section :10.1.1.39.999
uses different expensive method preliminary grouping records 
record considered separately source record query remaining records order create group potentially matching records 
record group compared source record pairwise matching procedure 
detecting approximately duplicate records similarity entire documents related body 
authors provide method determining document similarity build clustering syntactically similar documents 
expensive try compare documents entirety 
authors calculate sketch document size sketch order bytes 
sketch unique contiguous subsequences words contained document called shingles authors 
authors show document similarity compromised sketches documents compared entire document 
compute clusters similar documents authors calculate number shingles shared documents 
shingles documents common similar 
documents share shingles deemed similar put cluster 
maintain clusters union find data structure 
cluster gets created document comparisons performed 
see algorithm union find data structure efficiently allowing record comparisons performed 
addition system queries union find data structure improve accuracy performing additional record comparisons 

transitivity duplicate detection problem assumption transitivity problem detecting duplicates database described terms keeping track connected components undirected graph 
vertices graph represent records database size initially contain unconnected vertices record database 
undirected edge vertices records corresponding pair vertices match pairwise record matching algorithm 
considering apply expensive pairwise record matching algorithm records query graph records connected component determined previously approximate duplicates comparison needed 
belong different components known match 
comparing records results match respective components combined create single new component 
done inserting edge vertices correspond records compared 
time connected components graph correspond transitive closure duplicate relationships discovered far 
consider records rw corresponding nodes fact duplicate record detected edge inserted nodes putting nodes connected component 
similarly fact duplicate rw detected edge inserted nodes transitivity duplicate relation equivalent reachability graph 
reachable vice versa corresponding records ru rw duplicates 
duplicate relationship detected automatically maintaining graph comparing rw 
union find data structure known data structure efficiently solves problem incrementally maintaining connected components undirected graph called union find data structure 
data structure keeps collection disjoint updatable sets set identified representative member set 
set connected component graph 
data structure operations union combines sets contain node node say new set union representative union chosen new set replaces collection disjoint sets 
find returns representative unique set containing find invoked twice modifying set requests answer 
monge find connected components graph create jgj singleton sets containing single node edge find find perform union 
time nodes connected component sets representative find find 
note problem incrementally computing connected components graph harder just finding connected components 
linear time algorithms finding connected components graph 
require union find data structure need find connected components incrementally duplicate records detected 

improvements standard algorithm previous section described way maintain clusters duplicate records compute transitive closure duplicate relationships incrementally 
section uses union find data structure improve standard method detecting approximate duplicate records 
done algorithms algorithm performs multiple passes sorting scanning 
previous algorithms sort records pass domain specific criteria proposes domain independent sorting criteria 
specifically algorithm uses passes 
pass treats record long string sorts lexicographically reading left right 
second pass reading right left 
sorting algorithm scans database fixed size window 
initially data structure collection dynamic sets contains set record database 
window slides records sorted database record time windows overlap 
standard window method new record enters window compared records window 
done algorithm exception comparisons unnecessary 
comparison performed records cluster 
easily determined querying union find data structure 
considering new record window record window algorithm tests cluster 
involves comparing respective cluster representatives comparing value find find 
values comparison needed records belong cluster connected component 
records compared 
comparison successful new duplicate relationship established 
reflect union find data structure algorithm combines clusters corresponding making function call union 
section results experiments comparing improved algorithm standard method 
expect improved algorithm perform fewer comparisons 
fewer comparisons usually translates decreased accuracy 
similar accuracy expected comparisons performed correspond records members cluster due transitive closure duplicate relationships 
fact experiments show improved algorithm accurate standard method significantly performing fewer record comparisons 

priority queue algorithm algorithm described previous section weakness window scanning database records fixed size 
cluster database duplicate records size window possible duplicates detected comparisons 
furthermore cluster duplicates possible comparisons done may needed 
algorithm needed responds adaptively size homogeneity clusters discovered database scanned 
section describes strategy 
high level strategy adopted duplicate detection algorithm proposed 
describing algorithm need analyze fixed size window method 
fixed size window algorithm effectively saves jw gamma records possible comparisons detecting approximately duplicate records new record enters window slides record 
key observation cases unnecessary save records 
evidence sorting placed approximate duplicate records near 
jw gamma records window belong cluster 
new record member cluster member member entirely different cluster 
case exactly comparison cluster represented window needed 
cases records window belong cluster comparison needed 
saving individual records window algorithm saves clusters 
leads priority queue place window save record clusters 
rest section describes strategy embedded duplicate detection system 
algorithm described previous section passes sorting scanning performed 
algorithm scans sorted database priority queue record subsets belonging clusters detected 
priority queue contains fixed number sets records 
experiments reported number 
set contains records detected cluster 
efficiency reasons entire clusters saved may contain records 
hand single record may insufficient represent variability cluster 
records cluster saved priority queue add variability cluster represented 
set representing cluster detected cluster member highest priority queue 
algorithm scans sorted database sequentially 
suppose record record currently considered 
algorithm tests known member clusters represented priority queue 
test done comparing cluster representative representative cluster priority queue 
comparisons successful known member cluster represented set priority queue 
move set head priority queue continue record result comparisons computationally inexpensive done just find operations 
pass find comparisons guaranteed fail algorithm scans records sorted database sequentially time record encountered 
tests avoided pass 
case known member existing priority queue cluster algorithm uses smith waterman algorithm compare records priority queue 
algorithm iterates set priority queue starting highest priority set 
set algorithm scans members set 
compared smith waterman algorithm 
match cluster combined cluster union operation 
addition may included priority queue set represents cluster represents new combined cluster 
specifically included smith waterman matching score certain strong match threshold 
priority queue cluster inclusion threshold higher threshold declaring match lower 
intuitively similar necessary include subset representing cluster somewhat similar degree match inclusion threshold including subset help detecting members cluster 
hand smith waterman comparison yields low score certain bad threshold algorithm continues directly set priority queue 
intuition similarity comparisons members cluster containing fail 
comparison fails score close matching threshold worthwhile compare remaining members cluster 
strong match bad thresholds counter errors propagated computing pairwise duplicate relationships 
compared members set priority queue detecting duplicate member cluster currently represented monge equational smith waterman soc 
sec 
name address city state theory score number zip code true missing th st apt 
missing positive missing john th st ap 
missing false jubin toledo oh negative st toledo oh po box false po box walton positive brought corson ave blanco nm corson road raton nm table example pairs records status matching algorithms 
priority queue 
case saved singleton set priority queue highest priority 
action causes size priority queue exceed limit lowest priority set removed priority queue 

experimental results experiments reported databases mailing lists generated randomly software designed implemented :10.1.1.39.999
record mailing list contains fields social security number name middle initial name address apartment city state zip code 
field values chosen randomly independently 
personal names chosen list real names 
address fields chosen lists state abbreviations city names zip codes 
database generator creates random record creates random number duplicate records fixed probability distribution 
creates duplicate record generator introduces errors noise record 
possible errors range small typographical slips complete name address changes 
generator introduces typographical errors frequencies known previous research spelling correction algorithms 
algorithms designed detect errors introduced algorithm developed knowledge particular error probabilities database generator 
pairwise record matching algorithm special rules transpositions entire words complete changes names zip codes social security number omissions smith waterman algorithm variant 
table contains example pairs records chosen especially instructive pairwise scores assigned smith waterman algorithm :10.1.1.39.999
pair correctly detected duplicates rules 
smith waterman algorithm classifies duplicate threshold 
equational theory detect second pair duplicates 
smith waterman algorithm performs correctly pair duplicate detection threshold set lower 
equational theory falsely finds third fourth pairs duplicates 
smith waterman algorithm performs correctly pairs threshold higher 
examples suggest choose threshold 
threshold somewhat aggressive 
small experiments show conservative threshold detects real duplications keeping number false positives negligible 

measuring accuracy measure accuracy number clusters detected pure 
cluster pure contains records belong true cluster duplicates 
accuracy measure considers entire clusters individual records 
intuitive cluster corresponds real world entity individual records 
cluster detected duplicate detection algorithm classified follows 
cluster equal true cluster detecting approximately duplicate records true clusters pqs sw pure clusters merge purge pure impure clusters pqs hs pure clusters impure clusters average number duplicates original record fig 
accuracy results varying number duplicates original record zipf distribution 

cluster subset true cluster 
cluster contains true clusters 
definition pure cluster falls cases 
clusters fall case referred impure clusters 
detection algorithm detected clusters pure impure 

algorithms tested sections follow provide results experiments performed study 
algorithms compared different features 
main features algorithm pairwise record matching algorithm structure storing records possible comparisons 
main algorithms compared called merge purge algorithm versions algorithm section 
version pqs sw uses smith waterman algorithm match records second version pqs hs uses equational theory described 
short priority queue strategy abbreviated pqs 
pqs algorithms union find data structure described section 
priority queue cluster subsets discussed section 
equational theory matcher returns smith waterman algorithm estimate degrees pairwise matching 
need modify strategy keeping priority queue set representative records cluster 
current implementation pqs hs algorithm detected member cluster kept 
pqs algorithms figures show number pure impure clusters detected 
figures show number true clusters database number clusters detected merge purge 
unfortunately merge purge software distinguish pure impure clusters 
accuracy results reported include pure impure clusters slightly accuracy 

varying number duplicates record duplicate detection algorithm unaffected changes number duplicates record 
study effect increasing number varied number duplicates record zipf distribution 
zipf distributions give high probability small numbers duplicates give non trivial probability large numbers duplicates 
zipf distribution parameters probability duplicates ci gamma normalization constant monge true clusters sw impure clusters pqs sw impure clusters pqs hs impure clusters number clusters total number records database fig 
accuracy results varying database sizes log log plot 
gamma having maximum number duplicates necessary gamma diverges 
databases created different value parameter set 
maximum number duplicates original record kept constant 
noise level maintained constant 
sizes databases ranged total records 
experiments merge purge engine run fixed window size experiments performed 
duplicate detection algorithm priority queue containing sets records 
number chosen accuracy algorithms approximately 
course easy run algorithm larger priority queue order obtain greater accuracy 
shows algorithm performs slightly better merge purge engine 
number pure clusters detected algorithms increases slowly value theta increased 
increase constitutes decrease accuracy want get close number true clusters possible 
desired number impure clusters remains small 
fact nearly detected clusters pure suggests relax various parameters algorithm order combine clusters erroneously creating impure clusters 

varying size database accuracy duplicate detection 
consider databases respectively original records 
case duplicates generated zipf distribution high noise level zipf parameter maximum duplicates original record 
largest database considered contains records total 
figures show performance pqs algorithms merge purge algorithm databases 
algorithm parameters 
figures clearly display benefits pqs algorithm 
shows number clusters detected strategies similar pqs strategy having slightly better accuracy 
algorithms detect nearly number clusters achieve accuracy similar numbers record comparisons 
shown pqs algorithms doing fewer pairwise record comparisons 
largest database tested pqs strategy performs comparisons merge purge algorithm performs comparisons 
times comparisons pqs algorithm uses pairwise matching method achieves essentially accuracy 
experiments show significant improvement union find data structure priority queue cluster subsets strategy merge purge algorithm 
best detecting approximately duplicate records merge purge sw pqs sw pqs hs number record comparisons total number records database fig 
number comparisons performed algorithms log log plot 
depiction comparing merge purge algorithm pqs hs algorithm 
cases exact record matching function 
difference number times function applied 
merge purge algorithm applies record matching function records fall fixed size window making unnecessary record comparisons 
pqs hs pqs sw algorithms apply record matching function effectively union find data structure priority queue sets 
savings number comparisons performed crucial dealing large databases 
algorithm responds adaptively size homogeneity clusters discovered database scanned 
results depend record matching algorithm 
savings due maintenance clusters union find data structure priority queue determine records compare 
addition benefits experiments show loss accuracy smith waterman algorithm uses domain specific knowledge 

detecting approximate duplicate records real bibliographic database section looks effectiveness algorithm real database bibliographic records describing documents various fields computer science published sources 
database slightly larger version 
presents algorithm detecting bibliographic records refer 
task purge database duplicate records create clusters contain records entity 
entity context document called may exist versions 
may technical report appears form conference journal 
bibliographic records contain fields algorithm considers author title document methods tested 
bibliographic records gathered major collections available internet 
primary source collection computer science bibliographies assembled alf christian 
records taken collection currently contains bibtex records 
secondary source collection computer science technical reports produced major universities cs tr project 
contains approximately records 
total database contains records 
records come collection bibliographies database contains multiple bibtex records document 
addition due different sources records subject typographical errors errors accuracy information provide variation abbreviate author names 
monge cluster number number size clusters records records total table results duplicate detection database bibliographic records apply duplicate detection algorithm database created simple representative records complete bibtex records 
derived record contains author names document title bibtex record 
experiments pqs algorithm uses passes database uses domain independent sorting criteria 
small experiments allowed determine best smith waterman algorithm threshold match database 
threshold higher database noise synthetic databases experiments 
results pqs algorithm priority queue size table 
algorithm detected total clusters average records cluster 
true number duplicate records database known 
visual inspection great majority detected clusters pure 
number clusters detected pqs algorithm comparable results database 
reports making comparisons determine clusters pqs algorithm performs just comparisons 
savings comparable savings observed synthetic databases 

integration information sources important area research 
gained integrating multiple information sources 
obstacles overcome obtain valuable results integration 
article explored provided solutions problems overcome area 
particular integrate data multiple sources identify information common sources 
different record matching algorithms determine equivalence records sources 
section presents smith waterman algorithm useful typical alphanumeric records contain fields names addresses titles dates identification numbers 
smith waterman algorithm successfully applied problem detecting duplicate records databases mailing addresses bibliographic records changes algorithm 
smith waterman component tunable parameters typical alphanumeric domains confident numerical parameters suggested section change 
parameter changed different applications threshold declaring match 
threshold easy set examining small number pairs records true matching status known 
section smith waterman algorithm detecting duplicate bibliographic records compared algorithm developed 
perform experiments equational theory equational theory applies mailing list records 
entirely detecting approximately duplicate records new equational theory bibliographic records written order comparisons 
smith waterman algorithm domain independent successfully algorithm experiments previous section modifications 
thresholds needed adjusted database 
investigate automated methods learning optimal values thresholds smith waterman algorithm parameters 
duplicate detection methods described improve previous related ways 
contribution approximate record matching algorithm relatively domainindependent 
algorithm adaptation smith waterman algorithm parameters principle optimized automatically provide better accuracy specific applications 
second contribution show compute transitive closure duplicate relationships incrementally union find data structure 
third contribution heuristic method minimizing number expensive pairwise record comparisons performed comparing individual records potential duplicates 
important note second third contributions combined pairwise record matching algorithm 
particular performed experiments algorithms contained contributions different record matching algorithms 
experiments resulted high duplicate detection accuracy significantly performing fewer record comparisons previous related 
ace marvel richer 
matchmaker matchmaker find address exact address match processing 
telephone engineer management 
alf christian achilles 
collection computer science bibliographies 
url ira uka de bibliography index html 
batini lenzerini navathe 
comparative analysis methodologies database schema integration 
acm computing surveys 
bitton dewitt 
duplicate record elimination large data files 
acm transactions database systems 
robert boyer strother moore 
fast string searching algorithm 
communications acm 
andrei broder steve glassman mark manasse geoffrey zweig 
syntactic clustering web 
proceedings sixth international world wide web conference pp 
www scope gmd de info www technical html 
farrell kant 
programming expert systems ops rule programming 
addison wesley publishing 
census bureau editor 
census bureau record linkage workshop arlington virginia 
statistical research division census bureau 
chang 
theoretical empirical comparisons approximate string matching algorithms 
cpm rd symposium combinatorial pattern matching pp 

thomas cormen charles leiserson roland rivest 
algorithms 
mit press 
brenda cox 
business survey methods 
john wiley sons wiley series probability mathematical statistics 

du chang 
approach designing fast approximate string matching algorithms 
ieee transactions knowledge data engineering 
oren etzioni mike perkowitz 
category translation learning understand information internet 
proceedings international joint conference ai pp 

fellegi sunter 
theory record linkage 
journal american statistical association 
galil giancarlo 
data structures algorithms approximate string matching 
journal complexity 
giles brooks hummel 
experiment computer assisted duplicate checking 
proceedings asis annual meeting page 
monge patrick hall geoff dowling 
approximate string matching 
acm computing surveys 
hern andez stolfo 
merge purge problem large databases 
proceedings acm sigmod international conference management data pp 

mauricio hern andez :10.1.1.39.999
generalization band joins merge purge problem 
ph thesis columbia university 
hopcroft ullman 
set merging algorithms 
siam journal computing 
jeremy 
identifying merging related bibliographic records 
thesis mit published mit laboratory computer science technical report 
jacquemin 
retrieving terms variants lexicalized unification framework 
proceedings acm sigir conference research development information retrieval pp 

robert kahn 
cs tr project www document 
url www cnri reston va home cstr html 
beth wendy alvey editors 
record linkage techniques proceedings workshop exact matching methodologies arlington virginia 
internal revenue service statistics income division internal revenue service publication 
kim choi 
resolving schematic heterogeneity multidatabase systems 
distributed parallel databases 
donald knuth james morris jr vaughan pratt 
fast pattern matching strings 
siam journal computing 
kukich 
techniques automatically correcting words text 
acm computing surveys 
levenshtein 
binary codes capable correcting deletions insertions reversals 
soviet physics doklady 
ali ming zhou 
integrating database systems 
computers industrial engineering 
tova milo zohar 
schema matching simplify heterogeneous data translation 
ashish gupta oded shmueli jennifer widom editors vldb proceedings rd international conference large data bases august new york city new york usa pp 

morgan kaufmann 
alvaro monge charles elkan 
automatic retrieval scientific papers world wide web 
working notes fall symposium ai applications knowledge navigation retrieval page 
aaai press 
alvaro monge charles elkan 
field matching problem algorithms applications 
proceedings second international conference knowledge discovery data mining pp 

aaai press 
alvaro monge charles elkan 
mining external sources guide www discovery demo 
proceedings second international conference knowledge discovery data mining 
aaai press 
alvaro monge charles elkan 
tool finding scientific papers worldwide web 
proceedings rd international congress computer science research pp 
california 
alvaro monge charles elkan 
efficient domain independent algorithm detecting approximately duplicate database records 
proceedings sigmod workshop research issues data mining knowledge discovery tucson arizona 
needleman wunsch 
general method applicable search similarities amino acid sequences proteins 
journal molecular biology 
howard newcombe 
handbook record linkage methods health statistical studies administration business 
oxford university press 
howard newcombe kennedy james 
automatic linkage vital records 
science reprinted 

peterson 
computer programs detecting correcting spelling errors 
communications acm 
senator goldberg financial crimes enforcement network ai system identifying potential money laundering reports large cash transactions 
ai magazine 
detecting approximately duplicate records silberschatz stonebraker ullman 
database research achievements opportunities st century 
report nsf workshop database research 

set theory matching system application ethnographic research 
social science computer review 
smith waterman 
identification common molecular subsequences 
journal molecular biology 
song bubenko jr semantic similarity relations computation schema integration 
data knowledge engineering 
wang madnick horton 
inter database instance identification composite information systems 
proceedings second annual hawaii international conference system sciences pp 

william winkler 
advanced methods record linkage 
american statistical association proceedings section survey research methods pp 

william winkler 
matching record linkage pp 

brenda cox wiley series probability mathematical statistics 

detection duplicate secondary documents 

yan garcia molina 
information finding digital library stanford perspective 
sigmod record 
