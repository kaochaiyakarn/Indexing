clustering validation techniques maria yannis vazirgiannis department informatics athens university economics business athens greece email yannis gr 
cluster analysis aims identifying groups similar objects helps discover distribution patterns interesting correlations large data sets 
subject wide research arises application domains engineering business social sciences 
especially years availability huge transactional experimental data sets arising requirements data mining created needs clustering algorithms scale applied diverse domains 
introduces fundamental concepts clustering surveys widely known clustering algorithms comparative way 
addresses important issue clustering process regarding quality assessment clustering results 
related inherent features data set concern 
review clustering validity measures approaches available literature 
furthermore illustrates issues addressed algorithms gives trends clustering process 
keywords clustering algorithms unsupervised learning cluster validity validity indices 
clustering useful tasks data mining process discovering groups identifying interesting distributions patterns underlying data 
clustering problem partitioning data set groups clusters data points cluster similar points different clusters guha 
example consider retail database records containing items purchased customers 
clustering procedure group customers way customers similar buying patterns cluster 
main concern clustering process reveal organization patterns sensible groups allow discover similarities differences derive useful 
idea applicable fields life sciences medical sciences engineering 
clustering may different names different contexts unsupervised learning pattern recognition numerical taxonomy biology ecology typology social sciences partition graph theory theodoridis 
feature selection data data process 
steps clustering process clustering algorithm selection validation results algorithm results interpretation final clusters knowledge clustering process predefined classes examples show kind desirable relations valid data perceived unsupervised process berry 
hand classification procedure assigning data item predefined set categories fayyad 
clustering produces initial categories values data set classified classification process 
clustering process may result different partitioning data set depending specific criterion clustering 
need preprocessing assume clustering task data set 
basic steps develop clustering process summarized follows fayyad feature selection 
goal select properly features clustering performed encode information possible concerning task interest 
preprocessing data may necessary prior utilization clustering task 
clustering algorithm 
step refers choice algorithm results definition clustering scheme data set 
proximity measure clustering criterion mainly characterize clustering algorithm efficiency define clustering scheme fits data set 
proximity measure measure quantifies similar data points feature vectors 
cases ensure selected features contribute equally computation proximity measure features dominate 
ii clustering criterion 
step define clustering criterion expressed cost function type rules 
stress take account type clusters expected occur data set 
may define clustering criterion leading partitioning fits data set 
validation results 
correctness clustering algorithm results verified appropriate criteria techniques 
clustering algorithms define clusters known priori irrespective clustering methods final partition data requires kind evaluation applications 
interpretation results 
cases experts application area integrate clustering results experimental evidence analysis order draw right 
clustering applications 
cluster analysis major tool number applications fields business science 
summarize basic directions clustering theodoridis data reduction 
cluster analysis contribute compression information included data 
cases amount available data large processing demanding 
clustering partition data set number interesting clusters 
processing data set entity adopt representatives defined clusters process 
data compression achieved 
hypothesis generation 
cluster analysis order infer hypotheses concerning data 
instance may find retail database significant groups customers age time purchases 
may infer hypotheses data young people go shopping evening old people go shopping morning 
hypothesis testing 
case cluster analysis verification validity specific hypothesis 
example consider hypothesis young people go shopping evening 
way verify true apply cluster analysis representative set stores 
suppose store represented customer details age job time transactions 
applying cluster analysis cluster corresponds young people buy evening formed hypothesis supported cluster analysis 
prediction groups 
cluster analysis applied data set resulting clusters characterized features patterns belong clusters 
unknown patterns classified specified clusters similarity clusters features 
useful knowledge related data extracted 
assume example cluster analysis applied data set concerning patients infected disease 
result number clusters patients reaction specific drugs 
new patient identify cluster classified decision medication 
specifically typical applications clustering fields han kamber business 
business clustering may help marketers discover significant groups customers database characterize purchasing patterns 
biology 
biology define taxonomies categorize genes similar functionality gain insights structures inherent populations 
spatial data analysis 
due huge amounts spatial data may obtained satellite images medical equipment geographical information systems gis image database exploration expensive difficult users examine spatial data detail 
clustering may help automate process analysing understanding spatial data 
identify extract interesting characteristics patterns may exist large spatial databases 
web mining 
case clustering discover significant groups documents web huge collection semi structured documents 
classification web documents assists information discovery 
general terms clustering may serve pre processing step algorithms classification operate detected clusters 
clustering algorithms categories 
multitude clustering methods proposed literature 
clustering algorithms classified type data input algorithm 
clustering criterion defining similarity data points theory fundamental concepts clustering analysis techniques fuzzy theory statistics method adopted define clusters algorithms broadly classified types jain partitional clustering attempts directly decompose data set set disjoint clusters 
specifically attempt determine integer number partitions optimise certain criterion function 
criterion function may emphasize local global structure data optimisation iterative procedure 
hierarchical clustering proceeds successively merging smaller clusters larger ones splitting larger clusters 
result algorithm tree clusters called dendrogram shows clusters related 
cutting dendrogram desired level clustering data items disjoint groups obtained 
density clustering 
key idea type clustering group neighbouring objects data set clusters density conditions 
grid clustering 
type algorithms mainly proposed spatial data mining 
main characteristic space finite number cells operations quantised space 
categories wealth subtypes different algorithms finding clusters 
type variables allowed data set categorized guha huang statistical statistical analysis concepts 
similarity measures partition objects limited numeric data 
conceptual cluster categorical data 
cluster objects concepts carry 
classification criterion way clustering handles uncertainty terms cluster overlapping 
fuzzy clustering uses fuzzy techniques cluster data consider object classified clusters 
type algorithms leads clustering schemes compatible everyday life experience handle uncertainty real data 
important fuzzy clustering algorithm fuzzy means 
crisp clustering considers non overlapping partitions meaning data point belongs class 
clustering algorithms result crisp clusters categorized crisp clustering 
kohonen net clustering concepts neural networks 
kohonen network input output nodes 
input layer input nodes node attribute record connected output node output layer 
connection associated weight determines position corresponding output node 
algorithm changes weights properly output nodes move form clusters 
general terms clustering algorithms criterion assessing quality partitioning 
specifically take input parameters number clusters density clusters attempt define best partitioning data set parameters 
define partitioning data set certain assumptions necessarily best fits data set 
clustering algorithms discover clusters known priori final partitions data set requires sort evaluation applications 
instance questions clusters data set resulting clustering scheme fits data set better partitioning data set call clustering results validation subjects methods discussed literature 
aim quantitative evaluation results clustering algorithms known general term cluster validity methods 
remainder organized follows 
section main categories clustering algorithms available literature 
section discuss main characteristics algorithms comparative way 
section main concepts clustering validity indices techniques proposed literature evaluating clustering results 
experimental study validity indices section synthetic real data sets 
conclude section summarizing providing trends clustering 

clustering algorithms years number clustering algorithms proposed available literature 
representative algorithms categories follow 
partitional algorithms category means commonly algorithm macqueen 
aim means clustering optimisation objective function described equation mi equation mi center cluster ci mi euclidean distance point mi 
criterion function attempts minimize distance point center cluster point belongs 
specifically algorithm begins initialising set cluster centers 
assigns object dataset cluster center nearest re computes centers 
process continues centers clusters changing 
algorithm category pam partitioning medoids 
objective pam determine representative object medoid cluster find centrally located objects clusters 
algorithm begins selecting object medoid clusters 
non selected objects grouped medoid similar 
pam swaps medoids non selected objects objects qualify medoid 
clear pam expensive algorithm regards finding medoids compares object entire dataset ng han 
clara clustering large applications implementation pam subset dataset 
draws multiple samples dataset applies pam samples outputs best clustering samples ng han 
clarans clustering large applications randomized search combines sampling techniques pam 
clustering process searching graph node potential solution set medoids 
clustering obtained replacing medoid called neighbour current clustering 
clarans selects node compares user defined number neighbours searching local minimum 
better neighbour having lower square error clarans moves neighbour node process start current clustering local optimum 
local optimum clarans starts new randomly selected node search new local optimum 
prototypes mode huang means algorithm aim clustering categorical data 
hierarchical algorithms hierarchical clustering algorithms method produce clusters divided theodoridis agglomerative algorithms 
produce sequence clustering schemes decreasing number clusters east step 
clustering scheme produced step results previous merging closest clusters 
divisive algorithms 
algorithms produce sequence clustering schemes increasing number clusters step 
contrary agglomerative algorithms clustering produced step results previous splitting cluster 
sequel describe representative hierarchical clustering algorithms 
birch zhang uses hierarchical data structure called cf tree partitioning incoming data points incremental dynamic way 
cf tree height balanced tree stores clustering features parameters branching factor threshold referred diameter cluster diameter radius cluster 
birch typically find clustering single scan data improve quality additional scans 
clustering algorithm handle noise effectively zhang 
correspond natural cluster node cf tree hold limited number entries due size 
order sensitive may generate different clusters different orders input data 
cure guha represents cluster certain number points generated selecting scattered points shrinking cluster centroid specified fraction 
uses combination random sampling partition clustering handle large databases 
rock guha robust clustering algorithm boolean categorical data 
introduces new concepts point neighbours links order measure similarity proximity pair data points density algorithms density algorithms typically regard clusters dense regions objects data space separated regions low density 
widely known algorithm category dbscan ester 
key idea dbscan point cluster neighbourhood radius contain minimum number points 
dbscan handle noise outliers discover clusters arbitrary shape 
dbscan basis incremental clustering algorithm proposed ester 
due density nature insertion deletion object affects current clustering neighbourhood object efficient algorithms dbscan incremental insertions deletions existing clustering ester 
hinneburg keim density clustering algorithm proposed 
algorithm introduces new approach cluster large multimedia databases basic idea approach model point density analytically sum influence functions data points 
influence function seen function describes impact data point neighbourhood 
clusters identified determining density attractors 
density attractors local maximum density function 
addition clusters arbitrary shape easily described simple equation density function 
main advantages clustering properties data sets large amounts noise allows compact mathematically description arbitrary shaped clusters high dimensional data sets 
clustering parameters approaches quality resulting clustering depends choice 
parameters hinneburg keim parameter determines influence data point neighbourhood ii describes density attractor significant allowing reduction number density attractors helping improve performance 
grid algorithms number clustering algorithms spatial data known grid algorithms 
algorithms space finite number cells operations quantised space 
sting statistical information grid method representative category 
divides spatial area rectangular cells hierarchical structure 
sting wang goes data set computes statistical parameters mean variance minimum maximum type distribution numerical feature objects cells 
generates hierarchical structure grid cells represent clustering information different levels 
structure sting enables usage clustering information search queries efficient assignment new object clusters 
latest grid algorithm proposed literature 
signal processing techniques wavelet transformation convert spatial data frequency domain 
specifically summarizes data imposing multidimensional grid structure data space han kamber 
grid cell summarizes information group points map cell 
uses wavelet transformation transform original feature space 
wavelet transform convolution appropriate function results transformed space natural clusters data distinguishable 
identify clusters finding dense regions transformed domain 
priori knowledge exact number clusters required 
fuzzy clustering algorithms described result crisp clusters meaning data point belongs cluster 
clusters non overlapping kind partitioning called crisp clustering 
issue uncertainty support clustering task leads algorithms fuzzy logic concepts procedure 
common fuzzy clustering algorithm fuzzy means fcm extension classical means algorithm fuzzy applications 
fcm attempts find characteristic point cluster considered center cluster grade membership object clusters 
approach proposed literature solve problems crisp clustering probabilistic models 
basis type clustering algorithms em algorithm provides quite general approach learning presence unobservable variables mitchell 
common algorithm probabilistic variant means mixture gaussian distributions 
approach means uses probability density distance associate records clusters berry 
specifically regards centers clusters means gaussian distributions 
estimates probability data point generated jth gaussian belongs jth cluster 
approach gaussian model extract clusters assigns data points clusters assuming generated normal distribution 
approach implemented case algorithms em expectation maximization algorithm 

comparison clustering algorithms clustering broadly recognized useful tool applications 
researchers disciplines addressed clustering problem 
difficult problem combines concepts diverse scientific fields databases machine learning pattern recognition statistics 
differences assumptions context different research communities caused number clustering methodologies algorithms defined 
section offers overview main characteristics clustering algorithms comparative way 
consider algorithms categorized groups clustering method partitional hierarchical density grid algorithms 
tables summarize main concepts characteristics representative algorithms clustering categories 
specifically study features algorithms type data algorithm supports numerical categorical ii shape clusters iii ability handle noise outliers iv clustering criterion complexity 
input parameters algorithms study influence parameters clustering results 
describe type algorithms results information algorithm gives represent discovered clusters data set 
table depicts partitional algorithms applicable mainly numerical data sets 
variants means mode handle categorical data 
mode means method discover clusters adopts new concepts order handle categorical data 
cluster centers replaced modes new dissimilarity measure deal categorical objects 
characteristic partitional algorithms unable handle noise outliers suitable discover clusters non convex shapes 
certain assumption partition data set 
need specify number clusters advance clarans needs input maximum number neighbours node number local minima order define partitioning dataset 
result clustering process set representative points discovered clusters 
points may centers medoids centrally located object cluster clusters depending algorithm 
regards clustering criteria objective algorithms minimize distance objects cluster representative point cluster 
criterion means aims minimization distance objects belonging cluster cluster center pam medoid 
clara clarans mentioned clustering criterion pam 
consider samples data set clustering applied consequence may deal larger data sets pam 
specifically clara draws multiple samples data set applies pam sample 
gives best clustering output 
problem approach efficiency depends sample size 
clustering results produced samples data set 
clear sample biased clustering samples necessarily represent clustering data set 
hand clarans mixture pam clara 
key difference clarans pam searches subset dataset order define clusters ng han 
subsets drawn randomness step search contrast clara fixed sample stage 
benefit confining search localized area 
general terms clarans efficient scalable clara pam 
algorithms described crisp clustering algorithms consider data point object may belong cluster 
boundaries cluster hardly defined crisp way consider real life cases 
fcm representative algorithm fuzzy clustering means concepts order partition data set clusters 
introduces concept uncertainty assigns objects clusters attached degree belief 
object may belong cluster different degree belief 
summarized view characteristics hierarchical clustering methods table 
algorithms category create hierarchical decomposition database represented dendrogram 
efficient handling noise outliers partitional algorithms 
break due non linear time complexity typically complexity number points dataset huge cost number input data points large 
birch tackles problem hierarchical data structure called cf tree multiphase clustering 
birch single scan dataset yields clustering additional scans improve quality 
handles numerical data order sensitive may generate different clusters different orders input data 
birch perform clusters uniform size shape uses centroid cluster redistributing data points final phase 
hand cure employs combination random sampling partitioning handle large databases 
identifies clusters having non spherical shapes wide variances size representing cluster multiple points 
representative points cluster generated selecting scattered points cluster shrinking centre cluster specified fraction 
cure sensitive parameters number representative points shrink factor handling outliers number partitions 
quality clustering results depends selection parameters 
rock representative hierarchical clustering algorithm categorical data 
introduces novel concept called link order measure similarity proximity pair data points 
rock clustering method extends non metric similarity measures relevant categorical data sets 
exhibits scalability properties comparison traditional algorithms employing techniques random sampling 
handle successfully data sets significant differences sizes clusters 
third category study density clustering algorithms table 
suitably handle arbitrary shaped collections points ellipsoidal spiral cylindrical clusters different sizes 
efficiently separate noise outliers 
widely known algorithms category mentioned dbscan 
dbscan requires user specify radius neighbourhood point eps minimum number points neighbourhood minpts 
obvious dbscan sensitive parameters eps minpts difficult determine 
similarly requires careful selection input parameters value parameters may influence quality clustering results 
major advantage comparison clustering algorithms han kamber solid mathematical foundation generalized clustering methods partitional hierarchical ii clustering properties data sets large amount noise iii allows compact mathematical description arbitrary shaped clusters high dimensional data sets iv uses grid cells keeps information cells contain points 
manages cells tree access structure significant faster influential algorithms dbscan 
general terms complexity density algorithms nlogn 
perform sort sampling incur substantial costs 
density algorithms may fail random sampling reduce input size sample size large 
may substantial difference density sample cluster clusters data set 
category study see table refers grid algorithms 
basic concept algorithms define grid data space operations quantised space 
general terms approaches efficient large databases capable finding arbitrary shape clusters handling outliers 
sting known grid algorithms 
divides spatial area rectangular cells stores statistical parameters numerical features objects cells 
grid structure facilitates parallel processing incremental updating 
sting goes database compute statistical parameters cells generally efficient method generating clusters 
time complexity 
sting uses multiresolution approach perform cluster analysis quality clustering results depends granularity lowest level grid 
sting consider spatial relationship children neighbouring cells construct parent cell 
result cluster boundaries horizontal vertical quality clusters questionable 
hand efficiently achieves detect arbitrary shape clusters different scales exploiting known signal processing techniques 
require specification input parameters number clusters neighbourhood radius priori estimation expected number clusters helps selecting correct resolution clusters 
experimental studies outperform birch clarans dbscan terms efficiency clustering quality 
study shows efficient high dimensional space han kamber 
table 
main characteristics partitional clustering algorithms 
category partitional name type data complexity geometry outliers input noise parameters mean numerical non convex number shapes clusters mode categorical non convex shapes pam numerical non convex shapes clara numerical non convex shapes clarans numerical kn non convex shapes fcm fuzzy means numerical non convex shapes number points dataset number clusters defined number clusters number clusters number clusters number clusters maximum number neighbors examined number clusters results clustering criterion center clusters modes clusters medoids clusters medoids clusters medoids clusters center cluster beliefs vk ek xk qk ek qi xi ql distance categorical objects xl modes qi min min cost replacing center far oj concerned min minu vk jm jm ik table 
main characteristics hierarchical clustering algorithms 
category hierarchical name type data complexity geometry outliers input parameters birch numerical non convex radius shapes clusters branching factor cure numerical logn arbitrary shapes rock categorical logn mm maximum number neighbors point ma average number neighbors point number points dataset consideration arbitrary shapes number clusters number clusters ves number clusters results clustering criterion cf number points cluster linear sum points cluster ls square sum data points ss assignment data values clusters assignment data values clusters point assigned closest node cluster chosen distance metric 
clusters definition requirement number points cluster satisfy threshold 
clusters closest pair representatives scattered points merged step 
max el link pq pr el ni pq pr vi center cluster link pq pr number common neighbors pi pr 
table 
main characteristics density clustering algorithms 
category density name type data complexity geometry outliers input noise parameters dbscan numerical nlogn arbitrary cluster shapes radius minimum number objects numerical nlogn arbitrary cluster shapes radius minimum number objects table 
main characteristics grid clustering algorithms category grid name type data complexity wave cluster spatial data arbitrary shapes sting spatial data number grid cells lowest level results clustering criterion assignment data values clusters assignment data values clusters merge points density reachable cluster 
density attractor point attached cluster belonging 
geometry outliers input parameters output clustering criterion arbitrary shapes number points dataset consideration wavelets number grid cells dimension number applications wavelet transform 
number objects cell clustered objects clustered objects gauss near decompose feature space applying wavelet transformation average sub band clusters detail sub bands clusters boundaries divide spatial area rectangle cells employ hierarchical structure 
cell high level partitioned number smaller cells lower level 
data set consists clusters results application means ask clusters 
cluster validity assessment important issues cluster analysis evaluation clustering results find partitioning best fits underlying data 
main subject cluster validity 
sequel discuss fundamental concepts area various cluster validity approaches proposed literature 
problem specification objective clustering methods discover significant groups data set 
general search clusters members close words high degree similarity separated 
problem face clustering decide optimal number clusters fits data set 
algorithms experimental evaluations data sets order reader able visually verify validity results clustering algorithm discovered clusters data set 
clear visualization data set crucial verification clustering results 
case large multidimensional data sets dimensions effective visualization data set difficult 
perception clusters available visualization tools difficult task humans accustomed higher dimensional spaces 
various clustering algorithms behave different way depending features data set geometry density distribution clusters ii input parameters values instance assume data set 
obvious discover clusters data set 
consider clustering algorithm means certain parameter values case means number clusters partition data set clusters result clustering process clustering scheme 
example clustering algorithm means best clusters data set partitioned 
optimal partitioning considered data set 
define term optimal clustering scheme outcome running clustering algorithm partitioning best fits inherent partitions data set 
obvious depicted scheme best data set clustering scheme fit data set 
optimal clustering data set scheme clusters 
consequence clustering algorithm parameters assigned improper value clustering method may result partitioning scheme optimal specific data set leading wrong decisions 
problems deciding number clusters better fitting data set evaluation clustering results subject research efforts dave geva smyth theodoridis xie beni 
sequel discuss fundamental concepts clustering validity important criteria context clustering validity assessment 
fundamental concepts cluster validity procedure evaluating results clustering algorithm known term cluster validity 
general terms approaches investigate cluster validity theodoridis 
external criteria 
implies evaluate results clustering algorithm pre specified structure imposed data set reflects intuition clustering structure data set 
second approach internal criteria 
may evaluate results clustering algorithm terms quantities involve vectors data set proximity matrix 
third approach clustering validity relative criteria 
basic idea evaluation clustering structure comparing clustering schemes resulting algorithm different parameter values 
criteria proposed clustering evaluation selection optimal clustering scheme berry 
compactness members cluster close possible 
common measure compactness variance minimized 

separation clusters widely spaced 
common approaches measuring distance different clusters single linkage measures distance closest members clusters 
complete linkage measures distance distant members 
comparison centroids measures distance centers clusters 
approaches statistical tests major drawback high computational cost 
indices related approaches aim measuring degree data set confirms priori specified scheme 
hand third approach aims finding best clustering scheme clustering algorithm defined certain assumptions parameters 
number validity indices defined proposed literature approaches sharma theodoridis xie beni 

confidence interval tailed index right tailed index left tailed index proportion hypothesis 
theodoridis validity indices section discuss methods suitable quantitative evaluation clustering results known cluster validity methods 
mention methods give indication quality resulting partitioning considered tool disposal experts order evaluate clustering results 
sequel describe fundamental criteria described cluster validity approaches representative indices 
external criteria approach basic idea test points data set randomly structured 
analysis null hypothesis ho expressed statement random structure dataset test hypothesis statistical tests lead computationally complex procedure 
sequel monde carlo techniques solution high computational problems theodoridis 
monde carlo cluster validity goal monde carlo techniques computation probability density function defined statistic indices 
generate large amount synthetic data sets 
synthetic data sets called xi compute value defined index denoted qi 
respective values qi data sets xi create scatter plot 
scatter plot approximation probability density function index 
see possible cases probability density function shape index different possible shapes depending critical interval corresponding significant level statistic constant 
see probability density function statistic index ho single maximum region half line union half lines 
assuming shape right tailed generated scatter plot values index called qi order accept reject null hypothesis ho examine conditions theodoridis reject accept ho value data set greater smaller qi values respective synthetic data sets xi 
assuming shape left tailed reject accept ho value data set smaller greater qi values 
assuming shape tailed accept ho greater number qi values smaller qi values 
external criteria different ways 
firstly evaluate resulting clustering structure comparing independent partition data built intuition clustering structure data set 
secondly compare proximity matrix partition comparison partition hierarchy clustering consider cm clustering structure data set ps defined partition data 
refer pair points xv xu data set terms ss points belong cluster clustering structure group partition sd points belong cluster different groups ds points belong different clusters group dd points belong different clusters different groups assuming number ss sd ds dd pairs respectively maximum number pairs data set meaning total number points data set 
define indices measure degree similarity rand statistic jaccard coefficient indices take values maximized index mallows index 
fm previous indices proven high values indices indicate great similarity higher values indices similar 
indices statistic high values index indicate strong similarity normalized statistic element matrices respectively compare 
respective means variances matrices 
index takes values 
statistics right tailed probability density functions random hypothesis 
order indices statistical tests know respective probability density function null hypothesis ho hypothesis random structure data set 
means statistical tests accept null hypothesis data randomly distributed 
computation probability density function indices difficult 
solution problem monde carlo techniques 
procedure follows 
generate data set xi vectors points area means generated vectors dimension data set assign vector yj xi group xj belongs partition run clustering algorithm produce structure xi ci resulting clustering structure 
compute ci value defined index ci 

create scatter plot validity index values ci computed loop 
having plotted approximation probability density function defined statistic index compare value ci values qi 
indices fm defined previously index mentioned procedure 
example assume data set containing dimensional vectors points 
points form clusters points 
cluster generated normal distribution 
covariance matrices distributions equal identity matrix 
mean vectors distributions independently group data set groups partition vectors points belong group belong second group belong third group vectors belong fourth group 
run means clustering algorithm clusters assume resulting clustering structure 
compute values indices clustering partition get fm 
follow steps described order define probability density function statistics 
generate data sets xi consists random vectors dimensions uniform distribution 
partition defined earlier xi assign vectors second third forth groups vectors respectively 
run means times time xi define respective clustering structures datasets denoted ci 
compute values indices ri ji fmi 
set significance level compare values fm values corresponding accept reject null hypothesis values ri ji fmi greater smaller corresponding values fm 
case ri ji fmi values smaller corresponding values fm lead null hypothesis ho rejected 
expecting predefined clustering structure data set comparison proximity matrix partition partition considered mapping nc 
assuming matrix xi xj compute normalized statistic proximity matrix matrix index value may indication matrices similarity 
proceed evaluation procedure monde carlo techniques mentioned 
generate step procedure generate corresponding mappings gi generated xi data set 
compute step compute matrix yi xi order find corresponding statistic index 
internal criteria 
approach cluster validity goal evaluate clustering result algorithm quantities features inherent dataset 
cases apply internal criteria cluster validity depending clustering structure hierarchy clustering schemes single clustering scheme 
validating hierarchy clustering schemes 
matrix called matrix pc represent hierarchy diagram produced hierarchical algorithm 
pc element matrix represents proximity level vectors xi xj cluster time 
may define statistical index measure degree similarity pc proximity matrix matrices 
index called correlation coefficient defined dij ij ij cij number points dataset 
means matrices pc respectively equation pc dij cij elements pc matrices respectively 
value index close indication significant similarity matrices 
procedure monde carlo techniques described case validation 
validating single clustering scheme goal find degree agreement clustering scheme consisting nc clusters proximity matrix defined index approach hubert statistic normalized statistic 
additional matrix computation index xi xj belong different clusters application monde carlo techniques way test random hypothesis data set 
relative criteria 
basis described validation methods statistical testing 
major drawback techniques internal external criteria high computational demands 
different validation approach discussed section 
relative criteria involve statistical tests 
fundamental idea approach choose best clustering scheme set defined schemes pre specified criterion 
specifically problem stated follows palg set parameters associated specific clustering algorithm number clusters nc 
clustering schemes ci nc defined specific algorithm different values parameters palg choose best fits data set consider cases problem palg contain number clusters nc parameter 
case choice optimal parameter values described follows run algorithm wide range parameters values choose largest range nc remains constant usually nc number tuples 
choose appropriate values palg parameters values correspond middle range 
procedure identifies number clusters underlie data set 
ii palg contains nc parameter 
procedure identifying best clustering scheme validity index 
selecting suitable performance index proceed steps run clustering algorithm values nc minimum maximum 
minimum maximum values defined priori user 
values nc run algorithm times different set values parameters algorithm different initial conditions 
plot best values index obtained nc function nc 
plot may identify best clustering scheme 
stress approaches defining best clustering depending behaviour respect nc 
validity index exhibit increasing decreasing trend nc increases seek maximum minimum plot 
hand indices increase decrease number clusters increase search values nc significant local change value index occurs 
change appears knee plot indication number clusters underlying dataset 
absence knee may indication data set possesses clustering structure 
sequel representative validity indices crisp fuzzy clustering 
crisp clustering 
section discusses validity indices suitable crisp clustering 
modified hubert statistic 
definition modified hubert statistic equation proximity matrix data set nxn matrix element equal distance representative points vci clusters objects xi xj belong 
similarly define normalized hubert statistic equation 
vci close xi xj close agreement values normalized high 
conversely high value indicates existence compact clusters 
plot normalized versus nc seek significant knee corresponds significant increase normalized 
number clusters knee occurs indication number clusters underlie data 
note nc nc index defined 
dunn dunn indices 
cluster validity index crisp clustering proposed dunn attempts identify compact separated clusters 
index defined equation specific number clusters nc min min nc nc max nc ci cj dissimilarity function clusters ci cj defined ci min ci diam diameter cluster may considered measure dispersion clusters 
diameter cluster defined follows diam max clear dataset contains compact separated clusters distance clusters expected large diameter clusters expected small 
dunn index definition may conclude large values index indicate presence compact separated clusters 
index dnc exhibit trend respect number clusters 
maximum plot dnc versus number clusters indication number clusters fits data 
implications dunn index considerable amount time required computation ii sensitive presence noise datasets increase values diam dominator equation indices proposed pal biswas robust presence noise 
widely known dunn indices dunn index 
indices definition concepts minimum spanning tree mst relative neighbourhood graph rng gabriel graph respectively theodoridis 
consider index mst 
cluster ci complete graph gi vertices correspond vectors ci 
weight edge graph equals distance points ei mst set edges mst graph gi ei mst edge ei mst maximum weight 
diameter ci defined weight ei mst dunn index concept mst equation number clusters dm mst ci dnc min min nc nc mst max diam nc takes maximum value indicates number clusters underlying data 
similar arguments may define dunn indices gg nad rgn graphs 
diam davies db index 
similarity measure rij clusters ci cj defined measure dispersion cluster ci dissimilarity measure clusters dij 
rij index defined satisfy conditions davies 
rij 
rij rji 
si sj rij 
sj sk dij dik rij rik 
sj sk dij dik rij rik 
conditions state rij nonnegative symmetric 
simple choice rij satisfies conditions davies db index defined db nc rij si sj dij 
nc max nc nc ij nc clear definition average similarity cluster ci nc similar 
desirable clusters minimum possible similarity seek clusterings minimize db 
index exhibits trends respect number clusters seek minimum value plot versus number clusters 
alternative definitions dissimilarity clusters dispersion cluster ci defined davies 
pal biswas variants index proposed 
mst rng gg concepts similarly cases dunn indices 
validity indices crisp clustering proposed dave milligan 
implementation indices computationally expensive especially number clusters number objects data set grows large xie beni 
milligan cooper evaluation study validity indices proposed literature 
small data sets points separated clusters 
results study milligan cooper place je je index gamma beale best indices 
noted results concerning methods encouraging data dependent 
behaviour indices may change different data structures milligan cooper 
indices sample clustering results 
representative example je je computed information provided items involved cluster merge 
spr rs cd 
point give definitions validity indices simultaneously determine number clusters existing data set 
indices applied step hierarchical clustering algorithm known sharma root mean square standard deviation new cluster semi partial squared spr squared rs distance clusters 
getting detailed description say new clustering scheme defined level clustering hierarchy square root pooled sample variance variables attributes clustering process 
index measures homogeneity formed clusters step hierarchical algorithm 
objective cluster analysis form homogeneous groups cluster small possible 
case values higher step ones previous step indication new clustering scheme homogenous 
definitions shall symbolism ss means sum squares refers equation ss shall additional symbolism ssw referring group sum squares ii ssb referring groups sum squares 
iii sst referring total sum squares data set 
spr new cluster difference pooled ssw new cluster sum pooled ssw values clusters joined obtain new cluster loss homogeneity divided pooled sst data set 
index measures loss homogeneity merging clusters single algorithm step 
index value zero new cluster obtained merging perfectly homogeneous clusters 
value high new cluster obtained merging heterogeneous clusters 
rs new cluster ratio ssb sst 
understand ssb measure difference groups 
sst ssb ssw greater ssb smaller ssw vise versa 
result greater differences groups homogenous group vise versa 
rs may considered measure degree difference clusters 
furthermore measures degree homogeneity groups 
values rs range 
case value rs zero indicates difference exists groups 
hand rs equals indication significant difference groups 
cd index measures distance clusters merged step 
distance measured time depending selected representatives hierarchical clustering validity graphs perform 
instance case centroid hierarchical clustering representatives formed clusters centers cluster cd distance centers clusters 
case single linkage cd measures minimum euclidean distance possible pairs points 
case complete linkage cd maximum euclidean distance pairs data points 
indices determine number clusters exist data set plotting graph indices values number different stages clustering algorithm 
graph search steepest knee words greater jump indices values higher smaller number clusters example assume data set table 
running hierarchical clustering centroid method evaluate clustering structure defined indices 
agglomerative schedule table gives way algorithm worked 
indices computed follows stage step instance see table clusters merged meaning tuples 
merging subjects resulting cluster called 
new cluster denoted smaller label number clusters labels merged 
stage step sample variances sample means analytic equation variable income variable education 
cd clusters income income education education respective number values variables income education 
previous equation compute 
spr rs clusters table 
hierarchical algorithm results centroid method stage table 
dataset example subject id income 
education years table 
indices values cluster combined cluster cluster agglomeration schedule stage cluster appears coefficients cluster cluster stage stage step spr rs cd rs lets compute rs index merging clusters 
ssw income variable income cluster ssw income cluster giving total ssw income variable income 
similarly variable education ssw education ssw income giving ssw income 
pooled sum squares clusters variables ssw 
sst pooled variables data set ssb sst ssw 
compute rs 
spr stage loh loss homogeneity ssw new cluster ssw cl ssw cl spr loh sst 
cd index shown table coefficients column 
procedure followed find values index rest algorithm stages 
table summarizes values 
values plot graphs shown 
graphs search point significant change values consider indices occur 
case nonhierarchical clustering means may indices order evaluate resulting clustering 
indices meaningful case rs 
idea run algorithm number times different number clusters time 
plot respective graphs validity indices clusterings previous example shows search significant knee graphs 
number clusters knee observed indicates optimal clustering data set 
case validity indices described take form rs ij nc ij kd ij nc number clusters number variables data dimension nj number data values dimension nij corresponds number data values dimension belong cluster mean data values dimension 
sd validity index 
clustering validity approach proposed 
sd validity index defined concepts average scattering clusters total separation clusters 
sequel give fundamental definition index 
average scattering clusters 
average scattering clusters defined nc nc nc total separation clusters 
definition total scattering separation clusters equation dis nc max min nc nc dmax max vi vj nc maximum distance cluster centers 
dmin min vi vj nc minimum distance cluster centers 
define validity index equations follows sd nc nc dis nc weighting factor equal dis cmax cmax maximum number input clusters 
term nc defined equation indicates average compactness clusters intra cluster distance 
small value term indicates compact clusters scattering clusters increases compact value nc increases 
second term dis nc indicates total separation nc clusters indication inter cluster distance 
contrary term second dis nc influenced geometry clusters centres increase number clusters 
obvious previous discussion terms sd different range weighting factor needed order incorporate terms balanced way 
number clusters nc minimizes index considered optimal value number clusters data set 
influence maximum number clusters cmax related weighting factor selection optimal clustering scheme discussed 
proved sd proposes optimal number clusters irrespectively cmax 
index handle properly arbitrary shaped clusters 
applies aforementioned indices 
fuzzy clustering 
section validity indices suitable fuzzy clustering 
objective seek clustering schemes vectors dataset exhibit high degree membership cluster 
note fuzzy clustering defined matrix uij uij denotes degree membership vector xi cluster 
set cluster representatives defined 
similarly crisp clustering case define validity index search minimum maximum plot versus case exhibits trend respect number clusters seek significant knee decrease increase plot sequel categories fuzzy validity indices discussed 
category uses memberships values uij fuzzy partition data 
hand involves matrix dataset 
validity indices involving membership values 
bezdek proposed partition coefficient defined pc nc ij pc index values range nc nc number clusters 
closer unity index clustering case membership values fuzzy partition equal uij nc pc obtains lower value 
closer value pc nc clustering furthermore value close nc indicates clustering tendency considered dataset clustering algorithm failed reveal 
partition entropy coefficient index category 
defined pe nc ij log base logarithm 
index computed values nc greater values ranges 
closer value pe harder clustering previous case values index close upper bound indicate absence clustering structure dataset inability algorithm extract 
drawbacks indices monotonous dependency number clusters 
seek significant knees increase pc decrease pe plot indices versus number clusters ii sensitivity specifically indices give values values nc 
hand pc pe exhibit significant knee nc 
iii lack direct connection geometry data dave data 
indices involving membership values dataset 
xie beni index xie beni xb called compactness separation validity function representative index category 
consider fuzzy partition data set xj vi nc centers cluster uij membership data point belonging cluster fuzzy deviation xj form cluster dij defined distance xj center cluster weighted fuzzy membership data point belonging cluster dij uij xj vi cluster summation squares fuzzy deviation data point denoted called variation cluster summation variations clusters called total variation data set 
quantity ni called compactness cluster ni number point cluster belonging cluster average variation cluster separation fuzzy partitions defined minimum distance cluster centres dmin min vi vj xb index defined xb dmin number points data set 
clear small values xb expected compact separated clusters 
note xb monotonically decreasing number clusters nc gets large close way eliminate decreasing tendency index determine starting point cmax ij monotonic behaviour search minimum value xb range cmax 
values index xb depend values xb 
index category sugeno index defined mean vector positive definite symmetric matrix 
distance squared euclidean distance 
clear compact separated clusters expect small values fsm 
term parenthesis measures compactness clusters second measures distances clusters representatives 
fuzzy validity indices proposed geva concepts density 
fuzzy covariance matrix th cluster defined ij fuzzy hyper volume th cluster equation ij vj determinant measure cluster compactness 
total fuzzy hyper volume equation fh small values fh indicate existence compact clusters 
average partition density index category 
defined pa nc nc nc xj set data points pre specified region vj ij center cluster called sum central members cluster different measure partition density index defined pd fh nc fs nc ij xi vj indices proposed discussed krishnapuram 
approaches cluster validity approach finding best number cluster data set proposed smyth 
introduces practical clustering algorithm monte carlo cross validation 
specifically algorithm consists cross validation runs chosen train test partitions data set partition em algorithm define nc clusters training data nc varied cmax 
log likelihood lc calculated model nc clusters 
defined probability density function data lk log fk probability density function data denotes parameters estimated data 
repeated times cross validated estimates averaged nc 
estimates may define posterior probabilities value number clusters nc nc 
nc near strong evidence particular number clusters best data set 
evaluation approach proposed smyth density functions considered data set 
concepts related probabilistic models order estimate number clusters better fitting data set concepts directly related data inter cluster intra clusters distances 

experimental study validity indices section comparative experimental evaluation important validity measures aiming illustrating advantages disadvantages 
consider known relative validity indices proposed literature rs sharma db theodoridis sd 
definitions validity indices section 
rs taken account simultaneously order find correct number clusters 
optimal values number clusters significant local change values rs occurs 
regards db indication optimal clustering scheme point takes minimum value 
study synthetic dimensional data sets referred dataset dataset dataset dataset see real data set real data representing part greek road network theodoridis 
table summarizes results validity indices rs db sd different clustering schemes mentioned data sets resulting clustering algorithm 
study results algorithms means cure input value number clusters ranging 
indices rs propose partitioning dataset clusters db selects clusters best partitioning 
hand sd selects clusters best partitioning dataset correct number clusters fitting data set 
index db selects correct number clusters optimal partitioning dataset rs sd select clustering scheme clusters respectively 
indices 
datasets dataset dataset dataset real data dataset propose clusters best partitioning real data 
case dataset db sd select clusters optimal scheme rs selects clusters correct number clusters fitting data set 
sd finds correct number clusters dataset contrary rs db indices propose clusters best partitioning 
mention validity indices clustering algorithms measure evaluate results clustering algorithms give indication partitioning best fits data set 
essence clustering totally resolved issue depending application domain may consider different aspects significant 
instance specific application may important separated clusters consider compactness clusters 
having indication partitioning proposed index domain experts may table 
optimal number clusters proposed validity indices dataset dataset dataset dataset real data optimal number clusters rs db sd analyse validation procedure results 
select partitioning schemes proposed indices select better fitting demands crisp overlapping clusters 
instance dataset considered having clusters slightly overlapping having separated clusters 

trends clustering cluster analysis major tasks various research areas 
may different names different contexts unsupervised learning pattern recognition taxonomy biology partition graph theory 
clustering aims identifying extract significant groups underlying data 
certain clustering criterion data grouped data points cluster similar points different clusters 
clustering applied fields number clustering techniques algorithms proposed available literature 
main characteristics applications clustering algorithms 
discussed different categories algorithms classified partitional density grid fuzzy clustering representative algorithms category 
concluded discussion clustering algorithms comparative presentation stressing pros cons category 
important issue discussed cluster validity 
related inherent features data set concern 
majority algorithms certain criteria order define clusters data set partitioned 
clustering unsupervised method priori indication actual number clusters data set need kind clustering results validation 
survey known validity criteria available literature classified categories external internal relative 
discussed representative validity indices criteria sample experimental evaluation 
trends clustering process cluster analysis subject thorough research years variety disciplines open research issues 
summarize interesting trends clustering follows discovering finding representatives arbitrary shaped clusters 
requirements clustering handling arbitrary shaped clusters efforts context 
established method describe structure arbitrary shaped clusters defined algorithm 
considering clustering major tool data reduction important find appropriate representatives clusters describing shape 
may effectively describe underlying data clustering results achieve significant compression huge amount stored data data reduction 
ii non point clustering 
vast majority algorithms considered point objects cases handle sets extended objects hyper rectangles 
method handles efficiently sets non point objects discovers inherent clusters subject research applications diverse domains spatial databases medicine biology 
iii handling uncertainty clustering process visualization results 
majority clustering techniques assumes limits clusters crisp 
data point may classified cluster 
points classified cluster belong degree belief values treated equally clustering process 
result cases interesting data points fall cluster limits classified 
everyday life experience value may classified categories 
direction account uncertainty inherent data 
interesting direction study techniques efficiently visualize multidimensional clusters account uncertainty features 
iv incremental clustering 
clusters data set may change insertions updates deletions occur life cycle 
clear need evaluating clustering scheme defined data set update timely manner 
important exploit information hidden earlier clustering schemes update incremental way 
constraint clustering 
depending application domain may consider different clustering aspects significant 
may important stress ignore aspects data requirements considered application 
years trend cluster analysis parameters constraints 
constrains may exist data space users queries 
clustering process defined take account constrains define inherent clusters fitting dataset 
supported general secretariat research technology project 
suggestions help experimental study 
grateful implementation cure algorithm dr hong sam han providing information source code cure algorithm 
michael berry gordon 
data mining techniques marketing sales customer support 
john sons ehrlich full 
fcm fuzzy means algorithm computers geoscience 
dave 

validating fuzzy partitions obtained shells clustering pattern recognition letters vol pp 
davies dl 
cluster separation measure 
ieee transactions pattern analysis machine intelligence vol 

dunn 

separated clusters optimal fuzzy partitions cybern 
vol pp 

ester kriegel sander xu 

density algorithm discovering clusters large spatial databases noise proceedings nd int 
conf 
knowledge discovery data mining portland pp 

ester kriegel sander xu 

incremental clustering mining data warehousing environment proceedings th vldb conference new york usa 
fayyad shapiro uthurusamy 

knowledge discovery data mining 
aaai press 
geva 
unsupervised optimal fuzzy clustering ieee transactions pattern analysis machine intelligence vol 

guha rastogi shim 

cure efficient clustering algorithm large databases published proceedings acm sigmod conference 
guha rastogi shim 
rock robust clustering algorithm categorical attributes published proceedings ieee conference data engineering 
han kamber 

data mining concepts techniques 
morgan kaufmann publishers 
vazirgiannis 

quality scheme assessment clustering process proceedings pkdd lyon france 
hinneburg keim 

efficient approach clustering large multimedia databases noise 
proceedings kdd conference 
huang 
fast clustering algorithm cluster large categorical data sets data mining dmkd 
jain murty 
data clustering review acm computing surveys vol 
krishnapuram nasraoui 
quadratic shell clustering algorithms detection second degree curves pattern recognition letters vol 

macqueen 
methods classification analysis multivariate observations proceedings th berkley symposium mathematical statistics probability volume statistics pp 
milligan cooper 
examination procedures determining number clusters data set psychometrika vol pp 
mitchell 
machine learning mcgraw hill 
milligan soon 

effect cluster size dimensionality number clusters recovery true cluster structure 
ieee transactions pattern analysis machine intelligence vol 
pp 

ng han 
clustering methods spatial data mining 
proceeding th vldb conference santiago chile 
pal biswas 

cluster validation graph theoretic concepts 
pattern recognition vol 


new cluster validity index fuzzy mean pattern recognition letters pp 

chatterjee zhang 

multiresolution clustering approach large spatial database 
proceedings th vldb conference new york usa 
sharma 

applied multivariate techniques 
john sons 
smyth 

clustering monte carlo cross validation 
proceedings kdd conference 
theodoridis 

pattern recognition academic press 
theodoridis 
spatial datasets unofficial collection 
dias cti gr research datasets spatial html wang yang muntz 

sting information grid approach spatial data mining 
proceedings rd vldb conference 
xie beni 

validity measure fuzzy clustering ieee transactions pattern analysis machine intelligence vol 
zhang 

birch efficient method large databases acm sigmod montreal canada 
