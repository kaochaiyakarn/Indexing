filtered document retrieval frequency sorted indexes michael persin department computer science rmit st carlton australia email mp kbs edu au justin zobel department computer science rmit gpo box melbourne australia phone fax email jz cs rmit edu au ron sacks davis faculty applied science rmit gpo box melbourne australia phone fax email rsd cs rmit edu au july material appeared preliminary form acm sigir conference international conference applications databases 
research supported key centre knowledge systems australian research council collaborative information technology research institute 
dr zobel contact author correspondence 
persin zobel sacks davis ranking techniques effective finding answers document collections expensive evaluate 
propose evaluation technique uses early recognition documents highly ranked reduce costs test data queries evaluated memory standard implementation degradation retrieval effectiveness 
cpu time disk traffic dramatically reduced designing inverted indexes explicitly support technique 
principle index design inverted lists sorted decreasing document frequency document number method experimentally reduces cpu time disk traffic third original requirement 
show frequency sorting lead net reduction index size regardless index compressed 
ranking retrieve documents database order estimated relevance user query 
multi gigabyte databases available ranking considered best option data access boolean queries require expert formulation techniques browsing ineffective initial location answers large numbers documents 
need ranking led efforts international trec project cooperative experiment involving gigabyte text database manual checking documents relevance test query set 
comparison boolean queries retrieve exactly documents contain specified query terms ranked queries statistically compared documents 
statistical similarity document query assumed correspond relevance document query answers query documents highest similarity values 
functions proposed computation similarities 
successful functions terms retrieval effectiveness ability locate answers humans judge correct cosine measure 
straightforward implementation similarity measure cosine measure document database inverted index contains term database inverted list identifiers documents persin zobel sacks davis containing term 
costs ranked query evaluation index memory store similarity values usually requiring accumulator document database disk traffic transfer inverted lists query term disk memory processing cpu time process index information 
large document database cost evaluation cosine measure prohibitively high ranked queries usually expressed natural language contain large number terms occur high proportion database documents ranking techniques assign similarity value document containing query terms 
consequence typically documents database non zero similarity candidates presentation user 
reason top ranked documents retrieved candidate documents discarded 
propose technique filtering documents ranking allowing significant reduction volume main memory required 
effect filter document accumulator updated combination frequency term document term importance large impact final ordering documents 
inverted list common term may processed documents term frequent accumulator updated 
experiments applying technique cosine measure show allows evaluation queries large document collection approximately memory previous techniques deterioration retrieval effectiveness 
show re organise inverted files support filtering heuristic 
inverted lists generally document sorted sorted document identifier filter implies list processed documents term frequent 
sorting inverted lists decreasing document frequency frequency sorted identifiers interesting documents brought start list yielding reduction disk traffic part inverted list retrieved 
frequency sorting potentially adverse impact index size index compression techniques rely small differences adjacent documents longer inverted lists achieve size reductions 
show possible frequency persin zobel sacks davis sorting achieve net reduction index size regardless index compressed 
improvements information retrieval possible small machines pcs large multi user document systems library systems thousands simultaneous users 
document databases cosine measure described section 
technique document filtering described section experimental results 
section show structure inverted lists support filtering give experimental results compressed uncompressed inverted files 
section 
ranked query evaluation ranking technique demonstrate techniques cosine measure 
measure similarity document query practical purposes computed cq wd wd length document partial similarity respect term defined wq wd wx weight document query accumulators hold running totals expression information totals extracted inverted lists 
wd values precomputed expression wd 
term weighting systems proposed explored 
assign weight term query document inverse document frequency described wx log fx log fx number occurrences document frequency number documents collection ft number documents containing expression wt log ft ft persin zobel sacks davis importance collection 
function assigns high weight terms encountered small number documents collection 
supposed rare terms high discrimination value presence term document query indication document relevant query 
database structure inverted files index documents 
inverted index document database typically components vocabulary set inverted lists 
vocabulary contains term database number ft documents containing knowledge ft allows terms query processed order decreasing weight necessary technique shall describe 
inverted list consisting identifiers documents containing term identifier document frequency fd inverted lists consist document entries pairs fd values 
inverted lists usually sorted document identifier convenience processing sorting allows index compression sorted differences run lengths adjacent identifiers computed yielding small integers suitable compression 
example consider list consisting fd pairs represents fact term indexed occurs times document twice document 
list converted sequence run lengths number documents containing term compute average run length parameterised code run lengths efficiently compressed run lengths conform known distribution known mean 
high frequency terms bits required represent run length coded integer coding schemes elias golomb 
fd values skew distribution small integers effectively represented unary persin zobel sacks davis 
document collection set accumulator ad 
term query retrieve inverted list disk 
term entry fd inverted list set ad ad 
divide non zero accumulator ad document length wd 

identify highest accumulator values number documents user retrieve corresponding documents 
basic algorithm computing cosine measure elias code gamma code 
inverted index compression techniques reduce index size factor 
large document database indexed inverted file index simultaneously compute cosine correlation document collection query follows 
accumulator created document initially allocating accumulator document database dynamically adding accumulator document allocated non zero similarity 
similarity document query computed retrieving inverted list query term adding accumulator document term inverted list 
accumulator divided appropriate wd value documents highest cosine values chosen 
version algorithm moffat zobel shown 
evaluation cosine measure requires file containing length wd document 
values query independent need computed database creation time effectively compacted stored bits 
reason stored separately allow effective compression inverted file 
storage document frequencies normalised document lengths imply storage floating point numbers small integers effectively compressed substantial increase size inverted file 
main costs query evaluation memory space accumulators disk traffic retrieve inverted lists cpu time decode inverted persin zobel sacks davis lists 
reducing costs levels suitable small machine subject 
reducing number accumulators described usual approach evaluation ranked queries consecutive processing term query inverted list term 
technique computes query term document containing term partial similarity document query document requires accumulator 
particular shortcoming technique memory required accumulators 
common terms typical query contained large proportion documents collection 
processing identifiers inverted lists leads large number accumulators 
partial similarities common terms low weight 
processing values produces little increase accuracy expensive particularly systems compression inverted lists evaluate queries large volumes data decompressed 
attempts improve efficiency ranked query evaluation 
elimination words frequent words closed class words reduce number uninformative terms processed 
difficult determine list words 
example test database word text especially common english encountered document collection discrimination value 
word washington common collection provide useful discrimination 
sophisticated algorithms implement dynamic stopping condition 
typical approach taken algorithms order terms query decreasing weight process terms order stopping condition met 
moffat zobel implemented stopping condition limiting number accumulators 
tested versions algorithm 
version processing query stopped soon number accumulators exceeded certain limit 
second processing query continued reaching limit number accumulators new documents inserted set candidates 
version persin zobel sacks davis algorithm showed dramatic improvement response time cost significant deterioration retrieval effectiveness 
second version gave retrieval effectiveness basic version processed inverted lists conjunction modification index structure discussed approximately halved processing time 
harman candela experimented pruning algorithm 
accumulated partial similarities documents inverted lists second algorithm moffat zobel limited number accumulators setting condition insertion new documents set relevant documents algorithm considered documents contained terms inverse document frequency certain fraction maximum inverse document frequency term database 
overview pruning algorithms additional salton frakes baeza yates 
techniques effect saving time retrieving processing inverted lists saving space having fewer accumulators 
penalty retrieval effectiveness 
property common techniques may process inverted list term particularly important document process inverted list discriminating term simply fairly frequent abruptly switch free addition accumulators allowing addition accumulators 
yield reduction number processed term entries usually lead deterioration retrieval effectiveness decision global parameters data set 
algorithms select processing rejection inverted lists separate document entries lists consequence algorithms provide gradual transition acceptance terms rejection terms 
filtering documents accumulator values effectively compressed real numbers way reducing space requirement reduce number documents accumulator required 
propose filtering technique provides gradual transition inclusion omission documents consideration global parameter term importance collection local parameter persin zobel sacks davis number occurrences term document 
modify algorithm way 
basic algorithm query terms sorted decreasing wt sothat important terms processed 
term processed thresholds computed insertion threshold sins addition threshold sins 
process inverted list partial similarity query document list compared thresholds 
sins candidates necessary accumulator created added accumulator value 
sins important interesting user affect final order documents accumulator added value action taken 
information unimportant discarded 
rationale thresholds large number candidate documents high values similarity query profitable consider small partial similarities significantly change final ranking 
example test database experiments described section typical common query term wt typical common query term wt 
query terms processed highest accumulator values order differences adjacent accumulator values 
context values typically common terms effect final ordering 
threshold ignore inverted list entries yield small partial similarities saving cpu time 
likewise threshold sins allows ignore documents saving memory space 
words thresholds provide mechanism tuning system load 
thresholds previously decide process reject inverted lists decide process reject individual documents 
values thresholds term determined function accumulated partial similarity currently relevant document smax 
heuristic supposes current relevant document high weight need process document small value similarity query change final ranking identify important document included set relevant documents 
persin zobel sacks davis values thresholds determined sins smax cadd smax cadd constants choice values constants discussed 
effect query terms processed value accumulated similarity documents set answers grows increasingly difficult update add new accumulators 
process term entry fd inverted list partial similarity query greater current value threshold sins 
substituting definitions wd wq definition final condition fd wt fq wt fq fd expressing decision process term entry fd condition fd thresholds directly expressed terms frequencies fins smax fq fadd cadd smax fq threshold values constant processing inverted list decision term entry requires single integer comparison 
thresholds provides smooth transition acceptance rejection term entries inverted lists progressively difficult accumulators added updated 
terms processed value smax small value wt large identifiers considered 
smax rises wt falls thresholds rise limit fd values fadd processing inverted list effect accumulator values 
filtering algorithm computing cosine measure 
constants cadd control resources required algorithm 
increasing constant cadd reduce number term entries correspondingly reduce number partial similarities documents persin zobel sacks davis 
create empty structure accumulators 

sort query terms decreasing weight 

set smax 
term query compute values thresholds fins add 
retrieve inverted list disk 
term entry fd inverted list fd fins create accumulator ad necessary set ad ad ii 
fd fadd ad set accumulators set ad ad iii 
set smax max smax ad 

divide non zero accumulator ad wd 

identify highest accumulator values retrieve corresponding documents 
filtering algorithm computing cosine measure query inspected accumulated algorithm decrease cpu time 
increasing constant reduce number documents candidates decrease memory usage 
constants chosen discarded information included minimal impact final ordering 
production system constant values simply adjusted query observation system load occasional queries run values constant best values chosen distortion introduced answer set 
potential weak point filtering technique vulnerability presence documents large number occurrences rare term 
documents large weight theoretically values filters large documents able meet filtering conditions taken consideration 
document contains rarest term query set answers query consist documents containing term 
test robustness method filtering tried way calculating thresholds smax persin zobel sacks davis replaced sq defined sq log ft set query terms processed 
experimentally difference performance versions filtering algorithm insignificant smax approach experiments described 
possibility average similarity top documents highest version expensive 
document filtering sharply reduces volume main memory needed evaluation ranked queries 
filtering technique stands yield substantial savings disk traffic cpu time 
perform ranking fetch process inverted list query term comparing fd document current threshold values 
long inverted lists fd values pass thresholds time spent processing lists effect final ranking 
section describes techniques avoiding problems 
experimental results database experiments collection wall street journal articles extracted trec data 
value database set queries manual relevance judgements determine retrieval effectiveness 
database contains documents totalling mb average document size term occurrences longest document consists terms 
queries trec experiment stemming removing sgml markup length queries ranges terms 
measured retrieval effectiveness algorithms ability retrieve answers human judges relevant recall proportion relevant documents retrieved precision proportion retrieved documents relevant averaging precision 
recall 
consistency trec experiments retrieved top documents query pessimistically assumed recall values outside top zero 
results shown average values queries 
retrieval effectiveness shown function addition threshold 
depict parameters horizontal axis value persin zobel sacks davis retrieval effectiveness filtering algorithm basic algorithm add processed term entries retrieval effectiveness different values cadd constant cadd percentage term entries processed algorithm value cadd 
comparison show horizontal line performance cadd algorithm shown 
value insertion threshold fixed experiment 
prior experiments measured retrieval effectiveness different values chose gave retrieval effectiveness small number accumulators 
value obtain answer ranked query retrieval effectiveness basic algorithm having processed term entries 
interestingly processing term entries obtain better retrieval effectiveness comparison standard algorithm 
believe pruning common terms encountered document create informational noise help discriminate documents 
note necessary process small number term entries obtain decent level retrieval effectiveness 
example processing term entries deterioration retrieval effectiveness 
shows dependency retrieval effectiveness number accumulators 
number accumulators varied changing insertion threshold 
value constant corresponding number accumulators depicted horizontal axis 
cadd experiment prevent skipping common terms document included set candidate documents accumulated partial similarities terms 
note relatively small number candidate documents obtain better retrieval effectiveness basic persin zobel sacks davis retrieval effectiveness filtering algorithm basic algorithm ins number documents database number accumulators number accumulators different values cadd algorithm 
interestingly phenomenon consistent different techniques different document collections example similar results obtained moffat zobel experiments explicit limit number accumulators experiments different version cosine measure 
main saving yielded technique sharp reduction number accumulators 
illustrated 
horizontal axis vary affects number accumulators example results roughly accumulators results document having accumulator accumulators total 
vertical axis retrieval effectiveness remains high number accumulators small number accumulators drops retrieval effectiveness constant equal basic algorithm 
technique yields small saving cpu time compute values document identifiers filtered 
filtering algorithm reasonably insensitive cadd pro performance wide range values 
query largest number accumulators experiments times average value performance greatly depend characteristics individual queries 
major effect thresholds system performance affecting memory usage cadd affecting response time disk traffic 
confirm results applied filtering method subset trec data associated press subcollection 
observed identical behaviour excellent performance accumulators persin zobel sacks davis little impact cpu time 
queries experiments quite long 
argued short queries terms adversely affected information discarded filtering believe case 
filtering discards contributions small compared values accumulated far information discarded query terms typically information discarded terms processed 
performance gains short queries modest resource requirements spectacular long queries expect effectiveness degrade 
term weighting systems cosine measure described section similarity measure 
similarity measures example described harman candela 
tested robustness document filtering applying similarity measures 
determined similarity document query formula wq wd query document wx weight term document query weight term determined wx fx max wt wt log ft fx number occurrences term max maximum occurrence frequency terms associated document query number documents collection ft number documents containing measure similar form cosine measure importance document frequency term document smaller measure normalised 
harman candela employed similarity measure log fd wt log md persin zobel sacks davis retrieval effectiveness harman candela standard cosine number accumulators number documents collection retrieval effectiveness different number accumulators md total number significant terms including duplicates document similarity measure considers frequency term documents account number term occurrences query 
measures examined reduction number accumulators 
able measure time savings technique yield similarity measures required reimplementation inverted index 
volume computation required evaluation similarity query documents approximately similarity measure measures harman candela expect time savings similarity measure system 
shows similarity measures retrieval effectiveness function number accumulators 
number accumulators varied changing constant 
standard cosine measure document filtering allows queries evaluated deterioration retrieval effectiveness previous memory requirement harman candela algorithms respectively 
inverted file structures filtering ranking technique decision process reject term entry depends document frequency fd usual structure inverted lists term entries sorted document identifier process list comparing fd term entry current value threshold 
propose inverted lists persin zobel sacks davis frequency sorted sorted decreasing fd time wasted processing small fd values entirely avoided 
fd value encountered threshold processing inverted list 
second inverted list longer disk block block list needs retrieved time tail long inverted list contain small fd values required little cost associated leaving disk requested 
useful store vocabulary maximal document frequency max term allow skipping inverted lists 
commencing processing term query compute threshold frequencies fadd fins compare maximal document frequency term max max fadd document con taining term processed proceed term query retrieving inverted list disk 
unfortunately frequency sorting incompatible compression inverted lists 
document identifiers unsorted run lengths taken index size dramatically increase 
impact space requirements immediate effect increase real time required compute ranking inverted lists expensive retrieve disk 
queries penalty outweigh gain re ordering 
crucial find way maintaining compression performance 
simple way having compression frequency sorted inverted files term entries fd value sort document identifier 
inverted lists consist series sequences sequence triple pf dpf fd value documents dpf sequence pf number documents 
sequence documents frequency potential space saving frequency stored 
identifiers sequence sorted allowing run lengths taken allowing compression 
example inverted list illustrated section scheme represented box sequence number frequency second number documents sequence expression brackets persin zobel sacks davis documents sequence 
expression represents document numbers run lengths taken documents contain term frequency 
sequence method yield compression document sorted inverted lists 
reason possible poorer compression pattern document identifiers sequences 
run length typically compressed little log bits average run length identifiers sequence larger average run length sorted inverted list compression performance degrades 
reason possible increase size sequences documents long sequence parameters stored 
database documents size document sorted inverted list identifiers estimated follows 
number bits required store document identifiers approximately bg log addition fd value stored document 
space required values depend distribution frequencies 
assume distribution integral function largest fd value distribution 
assume fd value represented gamma code number bits required represent frequency gamma log space required fd values total space document sorted inverted list approximately bds bg bits needed represent length list 
assumptions size frequency sorted list determined follows 
sequence frequency identifiers sequence requires bg bits identifiers 
addition sequence requires approximately bit frequency frequencies persin zobel sacks davis ordered differences taken usually difference bits store number identifiers sequence 
total space required frequency sorted inverted list identifiers approximately bfs bg largest fd value inverted list needed represent number sequences 
bfs bds larger depends distribution frequencies 
extreme documents fd thatis bds bg bg bfs bg bg case inverted lists fd values results slightly better compression 
extreme document different fd value bds bg bfs bg case fd value occurring better depend sizes similar 
wall street journal database observed fd values inverted lists remainder strong skew low frequencies 
distribution modelled persin zobel sacks davis size lists kb frequency sorted frequency sorted document sorted document sorted number identifiers estimated size compressed inverted lists follows 
suppose integer distribution frequencies identifiers inverted list fd ofthe remainder fd total 
number identifiers fd 
integral 
estimated sizes compressed inverted lists andv database records 
seen sizes identical frequency sorted index slightly smaller 
straightforward extend model developed predict volume index data retrieved response query result depends estimates function distribution values query terms smax value predictions model best broad indicator possible performance 
clear filtering reduces potential drastically reduce disk traffic 
scale reduction best determined experimentally wall street journal section 
possible drawback frequency sorting inverted lists impact update 
costs update inverted index locating fetching list identifying part list modified modifying list writing list disk making reorganisation necessary minimise space fragmentation list length changed 
costs persin zobel sacks davis second searching list affected change document sorting frequency sorting typically searching cost double costs unchanged 
believe frequency sorting minor impact update 
indexing methods text databases update expensive requiring disk accesses indexed term modified inserted document 
method filtering re ordering inverted lists sequences documents frequency possible solution problem ignoring majority document identifiers 
moffat zobel proposed inverted lists ordered identifier addition contain pointers inverted list evenly spaced intervals allow search skip sections list decompression 
skipping provides benefit random access usually impossible context compression maintaining reasonable compression performance 
conjunction scheme small fixed number accumulators skipping reduces cpu time degrading retrieval effectiveness scheme slightly increases disk costs support filtering 
show gain achieve limited compared scheme describe 
representations sequences analysis indicates sequence method representing inverted lists yield reasonable compression better compression may possible particularly sequences higher frequency terms typical long inverted list contain term entries fd small number term entries fd large 
high frequencies sequences documents overheads representing short sequence need store number documents loss compression due large run lengths high 
problems overcome selective application idea sequences 
seen advantages long sequences low frequencies short sequences inefficient 
follows efficient form inverted list initial sequence fd pairs high frequencies lead short sequences followed series sequences low frequencies 
propose structure representing inverted list 
list split sequences problem choice discussed 
leading sequence fd pairs persin zobel sacks davis documents fd remaining sequence documents frequency fd sequences ordered decreasing frequency 
sequence entries sorted document identifier 
leading sequence storing fd values store fd 
minimum value case list stored sequence 
final filtering algorithm sequences shown 
scheme effective longer inverted lists common terms distribution fd values highly skew 
scheme low fd values sequence long high fd values share sequence 
start inverted list grouped sequences store number sequences sequences starts number entries 
frequency sequence determined ordinal number 
method means leading sequence frequencies explicitly stored means store zero number documents empty sequence 
example method storing inverted lists follows 
example corresponds inverted list shown 
box number sequences list 
second box leading sequence third fourth boxes sequences frequencies respectively 
examine inverted lists compressed sequence method optimisation index size query evaluation time 
consider effect having inverted lists inverted file results varying increase number sequences inverted list 
hand allows storage document identifiers corresponding frequencies 
hand store sequence length sequence including zeros sequences contain documents 
sequence lengths significant overhead size inverted file increases quickly unacceptably large 
decrease length sequence implies increase average run length worse rate compression 
small implies small inverted file 
consider problem proper choice fast query evaluation case wish processing term entries ordered decreasing fd fadd 
persin zobel sacks davis value threshold fadd minimal frequency documents leading sequence process leading sequence possibly subsequent sequences documents processed update accumulators decoding time wasted 
fadd process leading sequence documents sequence ignored 
value inverted lists achieve fast query evaluation increase size increase size inverted file 
possibility allow vary lists 
simple method list set compress list increment compress minimum 
existence minimum guaranteed size sequence lengths limit dominant 
note scheme varying addition sequence lengths value stored list 
scheme impractical 
heuristic scheme chose selection observation separate sequence fd value fd high length sequence low expensive sequence overheads 
call number identifiers compression gains outweigh overheads sequence threshold 
fact function just sequence length fd sequence test collection inverted lists frequencies sequences length approach reasonable approximation 
achieve compression avoid sequences length determine size inverted list term procedure 
initially distinct value fd find number documents contain number times 
find highest fd number documents denote frequency ft create inverted list having frequency sequences frequencies ft leading sequence contains documents remaining frequencies 
value 
hand frequency inverted list sequence value inverted list highest fd value list 
hand say database documents inverted lists sequence inverted lists common terms persin zobel sacks davis probably sequences terms typical database occur document 
having leading sequences mixed fd allows achieve aims simultaneously 
hand avoid creation inverted lists containing short sequences effectively compressed similarly avoid storing sequence lengths 
hand able keep leading sequences short fast query evaluation 
experimental results wall street journal database built document sorted inverted file frequency sorted inverted file evaluated trec queries described 
experiments filter values cadd gave retrieval effectiveness requiring small number accumulators 
times volumes disk traffic query averaged trec queries sun sparc model local disks 
size document sorted compressed inverted file mb frequency sorted inverted file mb size original data 
cost storing sequence parameters offset saving storing duplicate fd values 
document sorted index average query evaluation cpu seconds stopped queries closed class words removed grounds little impact retrieval effectiveness cpu seconds queries frequency sorted index comparable times cpu seconds cpu seconds respectively 
times similar demonstrating filtering method completely excludes words consideration 
method obviates need manually select list words 
frequency sorted indexes require far data fetched disk document sorted indexes usually read block inverted list 
document sorted inverted files stopped queries volume data fetched kb queries kb 
contrast technique volume index fetched just kb kb respectively 
number disk accesses reduced deciding reject term require disk access 
results compare skipping scheme moffat persin zobel sacks davis zobel larger database able halve cpu time increase disk traffic slightly 
scheme applicable boolean queries achieve greater performance gains 
idea scheme break usual identifier sorted indexes blocks store additional information allowing decoding algorithm skip block necessary decoding contents 
scheme applied frequency sorted index 
inverted lists index consist sequences store documents ordered numbers inside sequence moffat zobel scheme 
skipping information inserted sequence allowing efficient searching documents numbers evaluation boolean queries 
believe approach provide performance evaluating boolean queries cost slightly decreased efficiency processing ranked queries due necessity decompressing additional skipping information 
built series indexes different values sequence threshold experiment effect performance 
size inverted file shown function sequence threshold 
extreme assigning forces creation separate sequence frequency document 
inverted lists file leading sequences 
leads increase index size shortness sequences number sequence lengths stored larger 
large values lead gradual increase inverted file size leading sequences long represent large frequencies sequences 
examined query evaluation time different values constant small values difference size leading sequences small 
performance deteriorates large values processing common terms process long leading sequences searching documents pass filter ignoring rest 
limit huge document sorted index 
note processing overheads independent number processed documents decrease time query evaluation linear function quantity index processed 
volume inverted lists fetched decompressed query evaluation shown stopped queries 
frequency sorted inverted files built small values provide persin zobel sacks davis constant amount decompressed data 
hand smaller value smaller leading sequence smaller number documents decompressed ignored hand small values give rise inverted lists consisting small sequences overheads storing sequence parameters increase number compressed identifiers occupy space 
small values phenomena balance producing plateau graph 
hand inverted files built large values long leading sequences leading increase amount data fetched processed 
performance excellent wide range values values performance better document sorted compressed inverted files 
retrieval effectiveness maintained index size reduced cpu time disk traffic reduced 
expect relative performance improve growth database size 
performance depends marginally conclude production system 
note majority documents wall street journal database short average document frequency small 
databases longer records higher value may preferable 
uncompressed inverted files structure inverted files documents inverted lists ordered decreasing fd effective systems uncompressed inverted files 
structure yields significant reduction size inverted files 
typically fd pair occupies bytes consisting bytes storage document number bytes storage term frequency 
structure inverted file allows decrease size inverted file mb basic structure mb completely avoid storing fd values 
size uncompressed inverted file different values sequence threshold shown 
shown dramatic reductions major costs ranking query large document database disk traffic cpu time memory usage degrading retrieval effectiveness 
basis reductions persin zobel sacks davis filtering method documents high document frequency considered candidate answers technique reduces memory usage having fewer candidates means fewer accumulators required store information candidates 
despite reduction memory usage deterioration improvement retrieval effectiveness 
reductions disk traffic cpu time simple observation ordering inverted lists decreasing document frequency part list contain high frequencies rest ignored 
frequency sorted inverted lists effectively compressed splitting inverted lists sequences documents frequency applying existing compression techniques sequence 
modelling experiment shown change frequency sorting negative impact index size 
test database techniques maintain retrieval effectiveness reduce memory requirements accumulators reduce quantity data requested disk kb kb reduce cpu time seconds 
gains queries greater 
time saving noticeable systems compression storage data cost decompression long inverted lists major component processing time 
slight reduction index size mb mb massive saving mb required uncompressed index 
dramatic improvements allow ranking performed faster smaller machines previously possible 
alistair moffat 
bell moffat nevill manning witten zobel 
data compression full text retrieval systems 
journal american society information science october 
persin zobel sacks davis buckley 
optimisation inverted vector searches 
proc 
acm sigir international conference research development information retrieval pages montreal canada june 
elias 
universal codeword sets representations integers 
ieee transactions information theory march 
frakes baeza yates editors 
information retrieval data structures algorithms 
prentice hall 
golomb 
run length encodings 
ieee transactions information theory july 
harman candela 
retrieving records gigabyte text statistical ranking 
journal american society information science 
harman editor 
proc 
text retrieval conference trec washington november 
national institute standards technology special publication 

document retrieval system nearest neighbour searching 
journal information science 
moffat zobel 
coding compression full text retrieval systems 
proc 
ieee data compression conference pages snowbird utah march 
ieee computer society press los alamitos california 
moffat zobel 
self indexing inverted files fast text retrieval 
acm transactions information systems press 
moffat zobel sacks davis 
memory efficient ranking 
information processing management november 
perry willett 
review inverted files best match searching information retrieval systems 
journal information science 
salton 
automatic text processing transformation analysis retrieval information computer 
addison wesley reading ma 
persin zobel sacks davis salton mcgill 
modern information retrieval 
mcgraw hill new york 
zobel moffat sacks davis 
efficient indexing technique full text database systems 
proc 
international conference large databases pages vancouver canada august 
symbols symbol meaning set accumulators ad accumulator document cq cosine document cadd threshold constants document identifier fins fadd document frequency thresholds fd frequency fq frequency ft sequence threshold frequency ft number documents containing term number answers symbol meaning number documents query sq current threshold similarity sins partial thresholds similarity partial similarity respect sequence threshold term wd weight wq weight wt weight collection weight length wd persin zobel sacks davis 
create empty structure accumulators 

sort query terms decreasing weight 

set smax 
term query compute values filters fins fadd 
max fadd go step 
leading sequence inverted list document sequence fd fins create accumulator ad necessary set ad ad ii 
fd fadd ad set accumulators set ad ad iii 
ad updated set smax max smax ad 
remaining sequence inverted list fd add document sequence fd fins create accumulator ad necessary set ad ad ii 
fd fadd set accumulators set ad ad iii 
ad updated set smax max smax ad 

divide non zero accumulator ad document length wd 

identify highest values accumulators number documents user retrieve corresponding documents 
filtering algorithm sequences compute cosine measure persin zobel sacks davis size compressed index kb value threshold size compressed index different values sequence threshold size decoded lists kb size file kb queries stopped queries value threshold volume inverted lists decoded query evaluation value threshold size uncompressed index different values sequence threshold 
