improving accuracy tagging combination machine learning systems hans van halteren language speech university nijmegen zavrel walter daelemans language technology group university antwerp examine differences language models learned different data driven systems performing nlp task exploited yield higher accuracy best individual system 
means experiments involving task morpho syntactic tagging basis different tagged corpora 
known tagger generators hidden markov model memory transformation rules maximum entropy trained corpus data 
comparison outputs combined voting strategies second stage classifiers 
combination taggers outperform best component 
reduction error rate varies material question high lob corpus 

natural language processing nlp systems find language models predict classify interpret language related observations 
real world nlp tasks require approaches full language understanding order perfect automatic systems access limited superficial information limited resources reasoning information language models tend errors system tested new material 
engineering task nlp design systems amount errors small possible little effort possible 
common ways reduce error rate devising better representations problem spending time encoding language knowledge case hand crafted systems finding training data case data driven systems 
limited resources options available 
devising new representation task combine different systems employing known representations 
observation suggests approach systems designed differently different formalism contain different knowledge typically produce different errors 
hope fact reduce number errors little additional effort exploiting disagreement different language models 
approach applicable type language model focus case statistical trained annotated corpora 
examples task corpus annotation fed learning algorithm induces model desired input output mapping form classifier 
eo 
box hd nijmegen netherlands nl belgium zavrel uia ua ac association computational linguistics computational linguistics volume xx number number different learning algorithms simultaneously training corpus 
type learning method brings inductive bias task produce classifier slightly different characteristics different methods tend produce different errors 
investigate ways exploiting differences 
gang effect 
simply classifier voting outputs expect eliminate quirks errors due bias particular learner 
way better differences create arbiter effect 
train second level classifier select output basis patterns occurrence outputs various classifiers 
way counter bias component exploit identification correct output 
method admits possibility correcting collective errors 
hypothesis types approaches yield accurate model training data accurate component combination training data arbiter type method able outperform gang type 
machine learning literature interest theoretical aspects classifier combination gang effect type arbiter type see section 
general shown errors uncorrelated sufficient degree resulting combined classifier perform better individual systems 
wish take empirical approach examine methods result substantial accuracy improvements situation typical statistical nlp learning morpho syntactic tagging known part speech pos tagging annotated corpus words 
morpho syntactic tagging entails classification tagging token natural language text terms element finite palette tagset descriptors tags 
reasons choice task 
tagging widely researched understood task cf 
van halteren ed 
second current performance levels task leave room improvement state art performance data driven automatic taggers usual type material tagging english text single tags low detail tagset correctly tagged words accuracy levels specific classes ambiguous words lower 
number different methods automatically generate fully functional tagging system annotated text available shelf 
experi ments van halteren zavrel daelemans brill wu basic validity approach tagging error rate best lower best individual tagger van halteren zavrel daelemans 
experiments restricted single language single tagset importantly limited amount training data combiners 
led perform extensive tagging experiments moving tasks 
method applied nlp tasks results see section 
remaining sections introduce classifier combination basis previous machine learning literature combination methods experiments section 
explain experimental setup sec previous van halteren zavrel daelemans unable confirm half hypothesis unequivocally 
judged due insufficient training data proper training second level classifiers greatly increase amount training data cross validation 
van halteren zavrel daelemans combination machine learning systems ton describing corpora tagger generators experiments 
section go report results experiments comparison component taggers underlying tagger generators comparison combination methods 
results examined detail section discuss aspects accuracy specific words tags influence inconsistent taining data taining set size contribution individual component taggers tagset granularity 
section discuss results light related conclude summary important observations interesting directions re search section 

combination methods years explosion research machine learning finding ways improve accuracy supervised classifier learning methods 
important finding set classifiers individual decisions combined way ensemble accurate component classifiers errors individual classifiers sufficiently uncorrelated see dietterich chan stolfo wolpert overviews 
ways ensemble created individual classifiers way combined 
way create multiple classifiers subsamples training examples 
bagging training set individual classifier created randomly drawing training examples replacement initial training set breiman :10.1.1.32.9399
boosting errors classifier learned taining set new training set misclassified examples get weight 
sequentially performing operation ensemble constructed adaboost freund schapire :10.1.1.133.1040
class methods called arcing adaptive resampling combining 
general boosting obtains better results bagging data noisy dietterich 
way train classifiers different sources information task giving access different subsets available input features 
ways represent output classes bitstrings bit predicted different component classifier error correct output coding dietterich bakiri develop learning method specific methods ensuring random variation way different classifiers ensemble constructed dietterich :10.1.1.72.7289
take multi strategy approach ensemble const classifiers resulting taining different learning methods data see alpaydin 
methods combine outputs component classifiers ensemble include simple voting component classifier gets equal vote weighted voting component classifier vote weighted accuracy see 
golding roth 
sophisticated methods designed 

pazzani apply naive bayes algorithm learn weights classifiers 
voting methods lead gang effect discussed earlier 
approach combination stacking classifier trained predict correct output class input outputs ensemble classifiers possibly additional information wolpert breiman ting witten ting witten :10.1.1.17.7602:10.1.1.32.9399
stacking lead arbiter effect 
compare voting stacking approaches tagging problem 
remainder section describe combination methods computational linguistics xx number ti component taggers si tok probable tag token tok suggested ti quality tagger ti measured precision ti tag tag prec ti tag recall ti tag tag rec ti tag precision ti prec ti vote tag tok tagging token tok tag tag majority si tok tag si tok tag prec ti si tok tag prec ti tag precision recall elf si tok tag prec ti tag rec ti tag simple algorithms voting component taggers 
experiments 
start variations weighted voting 
go types stacked classifiers model disagreement situations observed training data detail 
input second stage classifier limited level outputs contain additional information original input pattern 
consider number different second level learners 
apart known machine learning methods memory learning maximum entropy decision trees introduce new method grouped voting 
simple voting straightforward method combine results multiple taggers way vote 
tagger allowed vote tag choice tag highest number votes selected 
question large vote allow tagger cf 

democratic option give tagger vote majority 
require tuning voting mechanism training data 
component taggers distinguished figures merit appears useful give weight taggers proved quality 
purpose precision recall known measures applied evaluation tagger output 
tag precision measures percentage tokens tagged tagger tagged benchmark 
recall measures percentage tokens tagged benchmark tagged tagger 
abstracting away individual tags precision recall equal tagger produces exactly tag token mea experiments ties resolved random selection winning tags 
van halteren zavrel daelemans combination machine learning systems sure tokens tagged correctly case generic term accuracy 
call voting method tagger weighted general quality tagger votes precision 
allow detailed interactions tagger weighted quality relation current situation tagger votes precision tag suggests 
way taggers accurate particular type ambiguity act specialized experts 
information tagger quality derived cross validation results taining set 
precise setup deriving training data described detail section 
access information taggers perform 
know believe propose precision know fail recognize correct tag recall 
information forcing tagger add vote tags suggested opposition amount equal minus recall opposing tag precision recall 
example suppose tagger suggests dt hmm tagger tnt suggests cs possible tags lob tagset token 
precision dt recall cs tnt precision cs recall dt dt receives vote cs vote 
note simple voting combiners return tag suggested weighted majority component taggers 
result restricted combination taggers tagset 
case arbiter type combination methods fact exploited bootstrapping tagger new corpus existing taggers completely different tagsets zavrel daelemans 
stacked probabilistic voting best methods tagger combination van halteren zavrel daelemans method 
looks situations tagger suggests tag estimates probability situation tag 
variant voting fact stacked classifier necessarily select tags suggested component taggers 
example voting section tagger suggests dt tagger tnt suggests cs find probabilities appropriate tag cs cs dt subordinating conjunction second half token sub conjunction determiner wh pronoun combining taggers tagger pair taken turn allowed vote weight equal probability tax ta described possible tag cf 

tag pair tae observed training data fall back information individual taggers ta 
note method tag suggested minority taggers chance win practice chance beat majority slight 
computational linguistics xx number ti component taggers si tok probable tag token tok suggested ti 
vote tag tok tagging token tok tag tag tag tok tag tok tag tok frequency si tok si tok sj tok sj tok tag tok tag tok tag tok tag si si tok tag sj sj tok algorithm voting component taggers 
case classified corresponds feature value pair set 
estimate probability class weighted sum possible subsets 
normalizing weight wi containing elements equal constant 
weighted probability distribution voting wpdv classification algorithm combination experiments 
seeing success earlier experiments decided try generalize stacked probabilistic voting approach combinations larger pairs 
things include word context features 
method eventually developed called weighted probability distribution voting henceforth 
wpdv classification model limited pairs features pairs tagger outputs probability distributions feature combinations observed training data cf 

voting fallback strategy weights prevent lower order combinations excessively influencing final results higher order combination exact information 
original system weights combination order factor number observation combination order contains combinations order competed 
parameter threshold number times combina van halteren zavrel daelemans combination machine learning systems tags suggested base taggers systems jj vbn vbd jj focus token stacked classifiers level tags word word restored full form tags suggested base tagger previous token stacked classifiers level tags context wpdv jj nn nn jj nn nn nn nn compressed form context tags wpdv tags context system unable cope large number features prev jj nn nn jj nn nn nn nn target feature systems tag vbd features combination systems 
examples taken lob material 
tion observed taining data order helps prevent combinatorial explosion atomic features 
contrast voting stacking classifiers allows combination outputs component systems additional information decision context 
investigated versions approach 
basic version tags taining case second level learner consists tags suggested component taggers correct tag cf 

advanced versions add information word question tags word tags suggested taggers previous position tags context 
types extended second level features exploited wpdv wide selection machine learning algorithms 
memory combination choice algorithms memory second level learner implemented timbl daelemans package developed tilburg university antwerp university 
memory learning learning method storing examples task memory classifying new examples similarity reasoning memory examples 
example represented fixed length vector feature values called case 
case classified observed stored cases case base frequent corresponding output 
case case base nearest determined similarity metric output observed outputs 
value similarity metric selected parameters system 
tags version similarity metric overlap count number matching feature values test taining item kept experiments parameter set 
wpdv evolved parameters involved weighting schemes tested tasks tagger combination van halteren van 
timbl available ttl ilk 

nl 
computational xx number 
versions tags word tags context value overlapping feature weighted information gain daelemans van den bosch weijters 
information gain feature defined difference entropy priori class distribution conditional entropy classes value feature 
maximum entropy combination second machine learning method maximum entropy implemented system dehaspe classification task selecting probable class maximum entropy model 
type model represents examples task cases sets binary indicator features task hand conjunctions particular tag particular set feature values 
model form exponential model case tag pa tag lcase case indexes binary features fi binary indicator function feature normalizing constant ai weight feature model iteratively adding binary features largest gain probability training data weights numerical optimization method called improved iterative scaling 
model observed dis features training data property having maximum entropy models fit constraints distributions data left uniform possible 
maximum entropy takes information memory learner input internally translates multi valued features binary indicator functions 
improved iterative scaling algorithm applied maximum iterations 
algorithm tagger described section beam search tagging appli cation 
decision tree combination third machine learning method quinlan example top induction decision trees 
decision tree constructed recursively partitioning taining set selecting step feature reduces uncertainty class partition split 
uses gain ratio estimate utility splitting features 
gain ratio corresponds information gain measure feature described measure normalized number values feature dividing entropy feature values 
decision tree pruned avoid overfitting method described detail quinlan 
classification test case traversing tree leaf node branches match test case returning frequent class node 
case representation uses exactly features memory learner 
referred mutual information computational linguistics literature 
available www cs kuleuven ac ldh 
detailed discussion see berger della pietra della pietra ratnaparkhi 
available www 

corn 
predecessor downloaded www 
cse unsw 
edu au quinlan 
van halteren zavrel daelemans combination machine learning systems 
experimental setup order test potential system combination obviously need systems combine number different taggers 
primarily interested combination classifiers trained data sets fact looking data sets case tagged corpora systems automatically generate tagger basis data sets 
current experiments selected tagged corpora tagger generators 
go detailed description describe ingredients experiments 
corpus way test tagger performance 
split set test set 
evaluate base taggers set train tagger generators test set test resulting tagger 
combiners complex strategy followed done material unseen base taggers involved 
setting apart fixed training set fold 
set split equal parts 
part tagged component taggers parts 
results concatenated earlier training set effectively available training 
resulting combiners tested test set 
test set identical methods compute statistical significance results mcnemar chi squared test dietterich :10.1.1.37.3325
see increase training set size viz 
corpus vs fixed tune set earlier experiments results better performance 
hand increased amount data increases time space requirements systems degree exclude parts experiments 
data set information tagger components taggers combiners lexicon context statistics entirely data driven manual adjustments 
tagger method parametrized default settings available 
default choose intuitively appropriate values preliminary testing 
cases report parameter system 
data current experiments corpora 
lob corpus johansson earlier experiments van halteren zavrel daelemans proved testing ground 
switch wall journal material wsj tagged penn treebank ii tagset marcus santorini marcinkiewicz 
lob consists approximately words american english 
furthermore different structure newspaper text tagged different tagset 
experiments wsj compare results reported brill wu show pronounced accuracy increase lob 
final corpus slightly smaller kw eindhoven corpus uit den tagged wotan tagset 
examine tagging cf 
tune set van halteren zavrel daelemans 
consisted tokens agreement taggers yielded tokens useful training material resolve disagreements 
suspected main reason relative lack performance sophisticated combiners 
computational linguistics volume xx number different language english dutch 
furthermore wotan tagset detailed error rate individual taggers tends higher 
easily projections tagset study effects levels granularity 
lob 
data set experiments consists tagged bergen corpus lob johansson 
corpus comprises words british english text divided samples words text types 
tagging lob corpus manually checked corrected generally accepted quite accurate 
slight adaptation tagset 
changes mainly cosmetic non alphabetic characters tag names replaced 
genitive markers split negative marker 
example sentence tagged resulting tagset ati singular plural article lord npt singular noun major npt singular noun extended vbd past tense verb singular article invitation nn singular common noun preposition abn pre quantifier ati singular plural article parliamentary jj adjective candidates nns plural common noun period tagset consists different tags including ditto average ambiguity tags corpus 
impression difficulty tagging task gained baseline measurements table representing completely random choice potential tags token random selection lexically tag 
training test separation corpus done utterance boundaries lst th utterance training th test leads token training set token test set 
test set tokens unseen training set known tokens unseen tags 
wsj 
second data set consists words wall street journal material 
differs lob american english importantly completely newspaper text 
material tagged penn treebank tagset mar cus santorini marcinkiewicz smaller lob 
consists tags 
tm attempt annotate compound words ditto tags components multi token units taken coordinating conjunction tagged cc cc cc related different ditto tags 
numbers calculated basis lexicon derived corpus 
actual tagger deal unknown words test set tend increase ambiguity decrease random 
note actual taggers combiners cope unknown words lexicons purely training sets 
way tagger generators treat input count tokens different underlying token differ capitalization characters 
material available quotes represented slightly differently different tags 
addition corpus contains limited number instances indeterminate tags indicates choice adjective past participle decided annotator unsure 
van halteren zavrel daelemans combination machine learning systems ditto tags 
example sentence preposition subordinating conjunction cd cardinal number 
rb adverb tokyo nnp singular proper noun time nn singular common noun comma determiner index nn singular common noun vbd past tense verb rb adverb cd cardinal number points nns plural common noun comma cd cardinal number preposition subordinating conjunction investors nns plural common noun vbd past tense verb new nnp singular proper noun york nnp singular proper noun pos possessive overnight adjective rally nn singular common noun sentence final punctuation detailed tagset average ambiguity tags lower lob tags token corpus 
means tagging task easier lob 
supported values random table 
hand detailed tagset means taggers detailed information base decisions 
factor quality automatic tagging consistency tagging corpus 
wsj material checked extensively lob corpus expected lower consistency level see section closer examination 
training test separation corpus done utterance boundaries leads token training set token test set 
test set unseen tokens known tokens previously unseen tags 
eindhoven 
final data sets eindhoven corpus uit den 
slightly smaller lob wsj 
written part experiments consists words samples ranging words 
variety lies lob wsj containing kw samples dutch newspapers cdb obl magazines popular scientific writings novels 
tagging corpus created part master thesis project 
employs wotan tagset dutch newly designed project 
classification popular descriptive grammar dutch ans 
actual distinctions encoded tagset selected basis importance potential users estimated number depth interviews interested parties netherlands 
wotan tagset large base tags leading tags counting ditto tag separately furthermore contains distinctions difficult automatic taggers verb transitivity syntactic adjectives recognition multi token units 
average computational linguistics xx number ambiguity tags token corpus 
experiments designed simplification tagset dubbed wotanlite longer contains problematic distinctions 
wotanlite tags complement ditto tags leading total average ambiguity tags token 
example wotan tagging underlined parts remain wotanlite 
master title eigen ev neut eigen ev neut ott ev de art bep mv neut post ev neut commissioner prep voor eigen ev neut trans dw en conj neven hij pron ev nom ott ev dus adv alle pron neut attr opportunity ev neut hebben trans inf er adv pron er het art bep neut best neut van adv adv te prep voor inf trans inf punc part singular neutral case proper norm second part singular proper norm rd person singular tense auxiliary verb neutral case non plural definite article singular neutral case common norm preposition singular neutral case proper norm base form past participle transitive verb coordinating conjunction rd person singular nominative personal rd person singular tense auxiliary verb demonstrative non pronominal adverb neutral case indefinite singular neutral case common norm infinitive transitive verb pronominal adverb neutral case definite article nominally inflected superlative form adjective particle adverb infinitival infinitive transitive verb period annotation corpus realized semi automatic upgrade tagging inherited earlier project 
resulting consistency exhaustively measured wotan original tagging 
training test separation corpus done sample boundaries lst th sample training th test 
stricter separation applied lob wsj corpora test utterances related training ones samples 
partly result word compounding dutch see higher percentage new tokens viz 
tokens unseen training set 
known tokens new tags wotan wotanlite 
training set consists tokens test set tokens 
master post commissioner opportunity 
van halteren zavrel daelemans combination machine learning systems table features available taggers study 
systems different models features known unknown words 
brill transformation learning system tbl applies models sequence faced unknown words giving unknown word tagger access features known word model 
columns table show features focus word capitalization hyphen digit number suffix prefix letters word 
brill tbl system unknown words takes account addition deletion suffix results known lexicon entry indicated 
columns represent access actual word range words left right ig 
columns show access tag information word range words left tf right 
note expressive power method purely determined features access algorithm combinations available features allows consider 
system features wf ql tbl tbl mbt mbt mxp tnt tnt tagger generators second ingredient experiments set tagger generator systems selected basis variety availability 
systems represents popular type learning method uses slightly different features text see table completely different representation language model 
publicly available systems default settings suggested documentation 
error driven transformation learning learning method finds set rules transforms corpus baseline annotation minimize number errors refer system tbl 
tagger generator learning method described brill brill 
implementation eric brill publicly available set programs perl scripts 
training system starts baseline corpus annotation 
known word tagged tag taining set unknown word tagged noun proper noun capitalized 
system searches space transformation rules defined rule templates order reduce discrepancy current annotation provided correct 
separate templates known words mainly local word tag context unknown words suffix prefix lexical information 
exact features tagger shown table 
learner unknown words tained applied 
output rules context disambiguation learned 
learning step instantiations rule templates corpus generated receive score 
rule corrects highest num systems differ possible learning strategies biases insufficient differences opinion combiners 
shown clearly early experiments gram taggers produced limited accuracy improvement cf 
van halteren 
brill system downloaded ftp ftp 
cs 
jhu 
edu pub brill tagger 
tar 
computational linguistics volume xx number ber errors step selected applied corpus yield annotation basis step 
process stops rule reaches score predefined threshold 
experiments usually yielded hundreds rules 
systems tbl access features contextual information words tags window spanning positions focus word lexical information existence words formed suffix prefix addition deletion 
conjunctions features available order keep search space manageable 
restriction search computationally costly 
important rule templates form context change context condition tags neighbouring words 
learning speed roughly cubic tagset size 
tagging system starts baseline annotation new text applies rules derived training sequence derived 
means application rules fully deterministic 
corpus statistics basis selecting rule sequence resulting tagger explicitly probabilistic model 
memory learning learning method explicitly manipulate probabilities extracting concise set rules storing examples task memory efficient way cf 
section 
new examples classified similarity reasoning memory examples 
tagger learning method mbt proposed daelemans 
training phase training corpus transformed case bases known words unknown words 
cases stored heuristically indexed version case memory daelemans van den bosch weijters tagging new cases classified matching cases memory going important feature important 
order feature relevance determined information gain 
known words system access information focus word potential tags disambiguated tags preceding positions tags positions 
unknown words preceding position suffix letters information capitalization presence hyphen digit features 
case base unknown words constructed words training set occur times 
maximum entropy modeling cf 
section tagging maximum entropy tagger called developed ratnaparkhi refer tagger mxp system uses number word context features similar system mbt trains maximum entropy model improved iterative scaling algorithm iterations 
final model weighting parameter feature value relevant estimation probability combines evidence diverse features explicit probability model 
contrast taggers known unknown words processed model 
striking difference tagger computational complexity exclude system experiments large wotan tagset 
online version tagger available ilk 

nl 
ratnaparkhi java implementation system freely available non commercial research purposes ftp ftp 
ci upenn 
edu pub adwait 
van halteren zavrel daelemans combination machine learning systems separate storage mechanism lexical information focus word possible tags 
word merely feature probability model 
result generalizations groups words set potential tags possible 
tagging phase beam search find highest probability tag sequence sentence 
hidden markov models view tagging task finding maximum probability sequence states stochastic finite state machine 
states emit words sentence probability states st model tags sequences tags 
transitions controlled state probabilities ist 
sentence generated number different state sequences states considered hidden 
methods unsupervised training hmm exist training usually done supervised way estimation probabilities relative frequencies training data 
hmm approach tagging far studied applied church derose charniak 
van halteren zavrel daelemans straightforward implementation hmm turned worst accuracy competing methods 
replaced tnt system refer tagger hmm 
tnt tagger brants means considers previous tags features deciding current tag 
considers capitalization previous word state representation 
lexical probabilities depend identity current word known words suffix tee smoothed successive abstraction samuelsson guessing tags unknown words 
see shows surprisingly higher accuracy previous hmm implementation 
compare taggers see hmm tagger uses limited set features table 
hand able access information rest sentence indirectly viterbi algorithm 

results set results experiments measurement accuracy base taggers 
addition observe agreement systems estimate gain possibly expect combination 
application various combination systems shows projected gain realized 
base tagger quality additional benefit taining popular tagging systems controlled conditions corpora experimental comparison accuracy 
table lists accuracies measured test set 
see tbl achieves lowest accu racy data sets 
mbt better tbl outperformed mxp hmm 
data sets lob wotan hidden markov model system tnt better maximum entropy 
wsj wotanlite better system 
cases difference mxp hmm lob differences statistically significant tnt system obtained author www coli uni sb de thorsten tnt tables best performance indicated bold type 
computational linguistics xx number table baseline individual tagger test set accuracy datasets 
bottom rows shows accuracies tagging systems various data sets 
addition list baselines viz 
selection completely random tag potential tags token random selection lexically tag 
lob wsj wotan wotanlite baseline random single tagger tbl mbt mxp hmm table pairwise agreement base taggers 
base tagger pair data set list percentage tokens test set taggers select tag 
dataset tagger pair mxp mxp mxp hmm hmm mbt hmm mbt tbl mbt tbl tbl lob wsj wotan wotanlite squared test 
see results wsj size lob smaller tagset higher difficulty level lob 
suspect important reason wsj annotation cf 
ratnaparkhi 
examine effect detail 
eindhoven corpus wotan wotanlite tagset difficult difficulty lies mainly complexity tagset large percentage unknown words test sets 
see reduction complexity tagset wotan wotanlite leads enormous improvement accuracy 
granularity effect examined detail 
base tagger agreement basis output single taggers examine feasibility combination combination dependent different systems producing different errors 
expected large part errors uncorrelated agreement systems table level agreement benchmark tagging 
detailed view inter tagger agreement shown table lists groups patterns dis agreement data sets 
interesting see general accuracy wsj lower lob inter tagger agreement wsj average higher 
consistent tagging wsj easier systems fall traps 
clearer examine patterns agreement see number tokens taggers agree wrong tag practically doubled 
training tbl large wotan tagset aborted weeks training failed produce useful results 
van halteren zavrel daelemans combination machine learning systems table presence various tagger dis patterns data sets 
addition percentage test sets pattern observed list cumulative percentage cum 
lob wsj wotan wotanlite pattern cum taggers agree correct 
majority correct 
correct tag tied 
minority correct 
taggers vary wrong 
taggers agree wrong 
table projected accuracies increasingly successful levels combination achievement 
level list accuracy percentage errors best individual tagger corrected combination ae 
lob wsj wotan wotanlite pattern ae ae ae ae best single tagger hmm mxp hmm mxp ties randomly correct ties correct minority vs taggers correct minority vs taggers correct agreement pattern distribution enables determine levels combination quality 
table lists accuracies ideal combiners error reduction relation best base tagger data set question 
lob ties correct produces errors corresponding accuracy hmm errors 
minimal level combination achieve ment majority better lead correct tag ties handled appropriately time pattern pattern pattern wotan 
optimistic scenarios combiner able select correct tag tied cases cases majority overcome 
possibility overcoming majority arbiter type combiners situation improbable 
result express error reduction form percentage relative measure absolute value feel informative 
vast difference accuracy improvement ae ae 
computational linguistics xx number table accuracies combination systems corpora 
system list accuracy percentage errors best individual tagger corrected combination system ae 
lob wsj wotan wotanlite ae ae ae ae best single tagger hmm mxp hmm mxp voting majority precision recall stacked classifiers wpdv tags wpdv tags word wpdv tags context mbl tags mbl tags word mbl tags context tags tags word 
tags context tags tags word tags context ought satisfied combiners approach level corresponding projected combiner resolves ties correctly 
results combination table results experiments various combination methods shown 
list accuracies combiners error reduction relation best base tagger 
lob produces errors corresponding accuracy errors 
combiners generally fall short ties correct level cf 
table trivial voting system majority significantly outperforms best individual tagger data sets 
simple voting systems appears detailed voting weights necessarily lead better results 
clearly inferior 
closer examination expected 
looking actual tag precision values cf 
table see precision generally dependent tag tagger tends select easier tag 
words uses specific specific information 
precision recall meant correct behaviour involvement recall values 
intended precision recall generally higher accuracy improve 
bottom rows viewed light potential extremely intelligent combination systems 
moment better view containing recall values best versions combination taggers best combination tagger lob simply provides tags suggested components recall score 
able cope large amount data involved tags word experiments tags context experiment wotan 
van halteren zavrel daelemans combination machine learning systems previously unconfirmed hypothesis arbiter type combiners able outperform gang type ones confirmed 
exception tags word versions tags context version wsj sophisticated systems significantly better accuracy simple voting systems data sets 
simple voting stacking falls middle accuracy concerned 
general said stay close real stacking systems cleanest data set lob clearly outperformed 
fundamental change earlier experiments significantly better mbl decision trees 
explanation time stacked systems suffered lack taining data appears correct 
closer shows amount taining data cross point quality occurs lob 
unresolved issue earlier experiments effect making word context information available stacked classifiers 
lob single tune set van halteren zavrel daelemans mbl decision trees de graded significantly adding context mbl adding word 
increased amount training material addition context generally leads better results 
mbl wsj data pronounced nature 
data sets improvement significantly lob 
decision trees limited degradation wsj wotanlite slight improvement lob 
systems appear able context effectively 
wpdv shows relatively constant significant improvement data sets 
shows variation comparable improvement lob wotanlite slight degradation wsj spectacular improvement wotan yields accuracy higher ties correct level 
addi ron word generally counterproductive 
wpdv manages translate extra information accuracy improvement small 
vastly larger amounts taining data necessary word information useful 

combination detail observations accuracies important interesting ones 
examine results experiments detail evaluating results combination specific words tags trying discover disappointing results wsj 
furthermore run additional experiments determine effects size training set number base tagger components involved granularity tagset 
specific words accuracy various tagging systems gives impression relative performance useful detailed look tagging results 
importantly details give better feel differences base taggers exploit differences 
generally users taggers tagged corpora rarely interested corpus 
focus specific words accuracy tagging may just current experiments decision tree system cope amount data word added 
clear explanation exceptional behaviour conjecture able optimal tagging differences caused high error rate taggers 
computational linguistics volume xx number table error rates confusing words 
word list total number instances test set number tags associated word tags base tagger wpdv tags context rank error list rank absolute number errors err percentage instances 
mxp hmm mbt tbl wpdv word tags err err err err err differ greatly accuracy 
start detailed examination words 
lob corpus evaluation cleanest data set best example 
base tagger wpdv tags context list top words terms absolute numbers errors table 
base taggers shown produce different errors see tend errors words top contain words 
high number errors word due combination tagging difficulty frequency 
examples primarily difficult words 
relatively low frequencies high ranks error lists 
words recognized high error percentage scores 
examples merely frequent words 
error percentages show words tagged surprisingly usually quoted tough case taggers choose possible tags 
place list taken high frequency high difficulty level ambiguous word possible tags lob 
table shows clear differences base taggers providing opportunity effective combination 
word manages improve best tagger specific word 
compare best tagger hmm improvements spectacular 
course especially case hmm particular difficulties word reduction error rate cases reduction error rate reduction 
specific tags away words simply look common confusions token tagged vbd past tense verb tagged vbn past participle verb 
table shows tag confusions top confusion list systems base taggers wpdv tags context lob 
number right system column number times error number left position van halteren zavrel daelemans combination machine learning systems table confusion rates confused tag pairs 
pair tagger correct take possible confusion directions separately list corresponding error list ranks rank absolute number errors err base taggers wpdv tags context 
list information pair directions 
mxp hmm mbt tbl wpdv tagger correct rank err rank err rank err rank err rank err vbn vbd vbd vbn pair jj nn nn jj pair cs cs pair nn vb vb nn pair rp rp pair table precision recall tags involved confused tag pairs 
tag list percentage tokens test set tagged tag test followed precision prec recall rec values systems 
mxp hmm mbt tbl wpdv tag test prec rec prec rec prec rec prec rec prec rec cs jj nn rp vb vbd vbn confusion list 
rows marked tag values show individual errors 
addition pair rows show combined value inverse errors preceding 
word errors see substantial differences base taggers 
situation words number cases base taggers perform better 
partly base tagger degree quality maintained nn jj 
furthermore probably unfair look half pair 
attempt decrease number errors type tend increase number errors type 
balance best shown pair rows performing cases improving best base tagger pair 
additional point view show precision recall values tags cs subordinating conjunction preposition jj adjective nn singular common noun rp adverbial particle vb base form verb vbd past tense verb vbn past participle 
rp top added complete pair inverse errors 
computational linguistics volume xx number table comparison benchmark consistency small sample wsj lob 
list reasons differences wpdv tags context output benchmark tagging terms absolute numbers percentages test set 
wsj lob tokens tokens tagger wrong benchmark right benchmark wrong tagger right wrong benchmark left ambiguous tagger right systems tags table percentage test set tagged specific tag 
differences taggers cases produces best score precision recall 
furthermore precision recall form balanced pair improvements recall tend decrease precision vice versa remaining cases nn vbd considered handled quite adequately 
effects inconsistency seeing bad performance combiners wsj feel need identify property wsj material explain relative lack success 
prime candidate property allegedly low degree consistency wsj material 
investigate effects low consistency way comparison lob data set known consistent 
taken tenth test sets wsj lob manually examined token wpdv tags context tagging differs benchmark tagging 
indication consistency major factor performance basic correctness information table 
wsj larger percentage difference tagging due erroneous tag benchmark 
mean tagger higher accuracy score may part benchmark tagger benchmark agree contains similar percentage benchmark errors 
imply wsj tagging contains errors lob tagging detrimental derivation automatic taggers 
cases tagger wrong provide interesting information 
examination shows erroneous tags occur situations handled inconsistently corpus 
situations look word 
numerous type problematic word errors proper noun 
appears unclear word tagged nnp 
words leading errors test set examining training data see near split practically word 
frequent ones securities nnp vs airlines nnp vs 
unbalanced cases viz 
times nnp vs savings nnp vs 
similar situation occurs frequently common nouns headquarters gets nn nns tags 
cases difficult words handled inconsistently specific contexts 
examples cases vs rb vs rb ago cases years ago vs rb jjr vs rbr 
general confusions adjective particle van halteren zavrel daelemans combination machine learning systems wpdv wpdv size training accuracy combiner methods lob function number tokens training material 
noun adjective noun positions 
harder provide numerical examples problematic situation recognized 
limit sample phrases 
stock index leads errors combinations stock index futures stock index arbitrage 
taining set stock index position tagged jj times nn times 
second phrase chief executive officer words choices tagging jj jj nn chosen times jj nn nn times nn jj nn times nn nn nn times 
admittedly problematic cases cases handled quite consistently 
inconsistently handled cases account errors best tagging system 
circumstances feel quite justified assuming inconsistency main cause low accuracy scores 
size training set important result undergone change van halteren zavrel daelemans current experiments relative accuracy stacked systems mbl 
significantly better mbl roles reversed 
appears hypothesis time stacked systems plagued lack taining data correct hold 
order see point property contribute relatively low scores wsj material small tagset 
annotation easier human annotators provides information automatic taggers combiners 
may remaining information insufficient systems discover useful disambiguation patterns 
measure effect wsj differences lob data set feel influence inconsistency wsj material 
computational linguistics volume xx number table wpdv tags context accuracy measurements various component tagger combinations 
combination list tagging accuracy test error reduction expressed percentage error count best component base tagger ae best subsequent error reductions adding components gain 
comb test ae best gain gain gain gain tbl mbt mxp hmm tbl mbt mbt tbl mbt mxp hmm hmm tbl hmm hmm mbt hmm mxp tbl mxp hmm mbt tbl hmm mxp mbt mxp mxp hmm hmm mxp mbt tbl mxp mxp hmm tbl hmm mxp hmm mbt hmm mxp hmm mbt tbl hmm tained systems increasing amounts taining data lob incre ment training corpus parts described 
results shown 
best single part earlier experiments 
quickly left increasingly unable additional taining data advantage 
systems base tagger outputs comparable accuracy growth curves initial growth higher wpdv 
curves wpdv appear leveling right graph 
mbl clear 
accuracy level mw approximation eventual ceiling 
advantage context information clear kw 
tags systems start level wpdv tags context keeps showing constant growth 
mw indication accuracy approaching ceiling 
model getting increasingly accurate specific contexts 
interaction components way amount input data varied subsets set component taggers 
relation accuracy combinations lob wpdv tags context individual taggers shown table 
columns show combination accuracy improvement relation best component 
columns show improvement gained adding component 
important observation combination outperforms combination strict subset components 
difference significant cases mxp hmm mbt tbl vs mxp hmm mbt hmm mbt tbl vs combination uses variable number parts 
base taggers trained full 
van halteren zavrel daelemans combination machine learning systems hmm mbt 
recognize quality best component major factor quality combination results 
hmm mxp add gain mbt adds gain tbl 
major factor difference language model 
mxp having lower accuracy hmm leads better combination results witnessed gain columns 
cases mxp able outperform pairs components combination mxp mbt mxp hmm better hmm mbt tbl 
effects granularity final influence combination measure tagset examined highly structured wotan tagset 
part examination taken place added wotanlite tagset granular projection wotan 
seen wotanlite taggers higher accuracy wotan ones 
hardly surprising easier task perform 
order fair comparison measure performance task viz 
prediction wotanlite tags 
output wotan taggers base taggers wpdv tags wpdv tags context wotanlite tags 
additionally measure taggers main level removal attributes ditto tag markers 
results listed table 
major vertical blocks represent level correctness final output measured 
lower blocks lines represent type tags base taggers 
lines wotan wotanlite represent actual taggers described 
line represent real tagger virtual tagger corresponds best tagger wotan output projected wotanlite format wotanlite 
choice best granularity taken system individual token 
leads equal wotanlite tbl mbt projected wotan mxp hmm 
major horizontal blocks represent combination strategies viz 
combination combination tags combination tags direct context 
combination blocks divided columns representing tag level combination performed lite column output base taggers projected wotanlite tags input combiner 
hypothesized general information system better results 
unfortunately base taggers reality simple 
mxp hmm wotan tagger yields better wotanlite tagging wotanlite tagger supporting hypothesis 
hand results mbt confirm wotanlite tagger accurate 
seen mbt severe problems dealing complex wotan data 
furthermore lowered accuracy mbl combiners provided words cf 
indicate memory learning problems coping surplus information 
means adjust hypothesis information better point wealth information overwhelms machine learning system 
point obviously differs system 
combiners situation inconclusive 
cases especially wpdv tags combining higher granularity information produces better results 
combining lower granularity works better 
cases computational linguistics volume xx number table accuracy base taggers different levels combiners measured various levels granularity 
rows divided blocks listing accuracies different comparison granularity 
block individual rows list base taggers ingredients combination 
columns contain left right accuracies base taggers combination accuracies tags wpdv tags different levels combination granularity full lite main combination accuracies adding context wpdv tags context levels combination granularity 
base taggers wpdv tags wpdv tags context tbl mbt mxp hmm pull lite main pull lite main measured wotan tags wotan wotan wotanlite measured wotanlite tags wotan wotanlite measured main tags difference scores columns extremely small hardly supports way 
obviously important combiners quality information 
higher granularity part ingredients preferable combiners wotan taggers perform better wotanlite taggers ingredient performance useful yields better results cases 

related research combination ensembles classifiers established machine learning literature applied method increasing accuracy natural language processing tasks 
course lot research combination different methods knowledge statistical hybrid systems combination different information sources 
explicitly uses voting counted ensemble approach 
rigau agirre combine different heuristics word sense disambiguation voting agirre spelling correction evaluation heuristics 
difference single classifiers learning combine information sources input features see roth general framework combination ensembles classifiers trained subsets features clear anyway 
part speech tagging significant accuracy increase combining output different taggers demonstrated van halteren zavrel daelemans brill wu 
approaches different tagger generators applied training data predictions combined different combination methods including stacking 
reported lower accuracy im comparison perfect combination wotan tags include tbl 
hand means combination information go impressed better performance 
hand tbl lowest scoring base tagger better performance due having cope flawed ingredient 
van halteren zavrel daelemans combination machine learning systems table comparison results wsj brill 

brill wu experiments training test split unigram trigram tnt mbt transformation transformation maximum entropy maximum entropy transf 
comb 
wpdv tags context error rate reduction error rate reduction provement figures 
apply methods van halteren zavrel daelemans wsj easier comparison 
exact comparison impossible exact data preparation taggers put roughly corresponding figures side side table 
base taggers differences easily explained unigram deal unknown words tnt advanced trigram system 
slight difference maxent explained difference training test split 
puzzling substantial difference transformation tagger 
possible explanations brill wu better parametrisation system different version wsj material 
may final results comparable clear lower numbers relation lob caused choice test material wsj methods 
single tagger generator trained different corpora representing different language registers 
combination method called credibility profiles worked best 
profile component tagger information kept accuracy accuracy tag study investigate types ensemble construction decision tree learning framework tagging specific classes ambiguous words opposed tagging words 
construction ensembles bagging selection different subsets features context lexical features decision tree construction selection different splitting criteria decision tree construction 
experiments simple voting combine component tagger decisions 
combination approaches resulted better accuracy error reduction average compared basic decision tree trained data 
error reductions refer part tagging task ambiguity classes hard compare results 
abney schapire singer adaboost variants tagging wsj material 
component classifiers different information sources subsets features capitalization current word triple string capitalization tag word left current word basis training component classifiers 
resulting accuracy comparable better maximum entropy tagger 
approach demonstrated prepositional phrase attachment results comparable better state art single classifier systems 
high accuracy task claimed combining ensembles neural networks 
adaboost applied text filtering schapire singer singhal text categorization schapire singer :10.1.1.48.6710
chen bangalore vijay shanker classifier combination overcome sparse data problem contextual information supertag computational linguistics volume xx number ging approach parsing reduced tagging complex tagset consisting partial parse associated lexical items 
pairwise models trained different contextual information error reduction achieved best component model 
parsing task henderson brill apply combination methods reductions precision error recall error compared best previously published results single statistical parsers 
research shows combination approach potentially useful nlp tasks apart tagging 

experiments shown tagging task combination different systems enables raise performance ceiling observed data driven systems 
tested data sets combination provides significant improvement accuracy best component tagger 
amount improvement varies error reduction wsj lob 
data set appears primary factor variation especially data set consistency 
type stacked systems set proposed tags features reach performance 
clearly better simple voting systems long sufficient training data 
absence data fall back sophisticated combination strategies 
addition word information lead improved accuracy current training set size 
possible get positive effect restricting word information frequent ambiguous words 
addition context information lead improvements systems 
wpdv best extra information wpdv having edge consistent data wsj high error rate material wotan 
results reported positive directions research remain explored area 
particular high expectations directions 
reason believe better results obtained probability distributions generated component systems just best guesses see 
ting witten :10.1.1.17.7602
second disagreement fixed set component classifiers 
exist number dimensions disagreement inductive bias feature set data partitions target category encoding fruitfully searched yield large ensembles modular components evolved cooperate optimal accuracy 
open question combination technique actual nlp applications 
natural language text hand processed base systems combiner 
especially runtime computational difficulties experienced training combining systems time needed process text expected factor single system 
worth improvement achieved expressed percents factors depend amount text processed results 
clear cut cases corpus annotation project cpu time tagging negligible re lation time needed manual correction combination information retrieval large text collections accuracy improvement van halteren zavrel daelemans combination machine learning systems impact justify enormous amount extra cpu time combination 
time choice combining combining evidence carefully designed pilot experiments hope provide suggestions encouragement 

authors creators tagger generators classification systems making systems available thorsten brants guy de pauw erik tjong kim sang de members ilk research groups anonymous reviewers comments discussion 
research done second third author tilburg university 
research done context induction linguistic knowledge ilk research programme supported partially netherlands organization scientific research nwo 
abney schapire singer 

boosting applied tagging pp attachment 
proceedings joint sigdat conference empirical methods natural language processing large corpora pages 
agirre voutilainen 

single proposal spelling correction 
coling acl pages 


pp attachment committee machine approach 
proceedings joint sigdat conference empirical methods natural language processing large corpora pages 
ali pazzani 

error reduction learning multiple descriptions 
machine learning 
alpaydin 
techniques combining multiple learners 
alpaydin editor proceedings engineering intelligent systems pages 
berger della pietra della pietra 

maximum entropy approach natural language processing 
computational linguistics 

wotan een tagger voor het 
master thesis dept language speech university nijmegen 
brants 
tnt statistical part speech tagger 
proceedings th applied nlp conference anlp april may seattle wa 
breiman 
bagging predictors 
machine learning 
breiman 
stacked regressions 
machine learning 
brill 
simple rule part speech tagger 
proceedings third acl conference applied nlp pages trento italy 
brill 
advances transformation part speech tagging 
proceedings aaai 
brill jun wu 

classifier combination improved lexical disambiguation 
coling acl pages montreal canada august 
chan stolfo wolpert 

guest editors 
special issue integrating multiple learned models improving scaling machine learning algorithms 
machine learning 
charniak 
statistical language learning 
cambridge ma mit press 
chen bangalore vijay shanker 

new models improving supertag disambiguation 
proceedings joint sigdat conference empirical methods natural language processing large corpora pages 

human expert level performance scientific image analysis task system combined artificial neural networks 
chan editor working notes aaai workshop integrating multiple learned models pages 
church 
stochastic parts program noun phrase parser unrestricted text 
proc 
second applied nlp acl 
computational linguistics volume xx number daelemans van den bosch weijters 

trees compression classification lazy learning algorithms 
artificial intelligence review 
daelemans zavrel 

mbt memory part speech tagger generator 
dagan editors proc 
fourth workshop large corpora pages 
acl sigdat 
daelemans zavrel van der van den bosch 

timbl tilburg memory learner version manual 
technical report ilk ilk tilburg university 
dehaspe 
maximum entropy modeling clausal constraints 
inductive logic programming proceedings th international workshop ilp lecture notes artificial pages 
springer verlag 
derose 
grammatical category disambiguation statistical optimization 
computational linguistics 
dietterich 
machine learning research current directions 
ai magazine 
dietterich bakiri 

solving multiclass learning problems error correcting output codes 
journal artificial research 
dietterich 
approximate statistical tests comparing supervised classification learning algorithms 
neural computation 
freund schapire 

experiments new boosting algorithm 
saitta editor proceedings th international conference machine learning icml pages san francisco ca 
morgan kaufmann 
de van der 


groningen leuven 
golding roth 

winnow approach context sensitive spelling correction 
machine learning 
van halteren 
comparison tagging strategies prelude democratic tagging 
hockey ide editors research humanities computing 
selected papers ach conference christ church oxford april pages oxford england 
clarendon press 
van halteren 
default order weight determination procedure wpdv models 
proceedings conll 
van halteren 
chunking wpdv models 
proceedings conll 
van halteren zavrel daelemans 

improving data driven tagging system combination 
proceedings th annual meeting association computational linguistics th international conference computational linguistics montreal quebec canada pages montreal canada august 
van halteren ed 
syntactic tagging 
dordrecht netherlands kluwer academic publishers 
henderson brill 

exploiting diversity natural language processing combining parsers 
proceedings joint sigdat conference empirical methods natural language processing large corpora pages 
johansson 
tagged lob corpus user manual 
bergen norway norwegian computing centre humanities 
marcus santorini marcinkiewicz 

building large annotated corpus english penn treebank 
computational linguistics 
rodriguez 

improving pos tagging machine learning techniques 
proceedings joint sigdat conference empirical methods natural language processing large corpora pages 
quinlan 
programs machine learning 
san mateo ca morgan kaufmann 
ratnaparkhi 
maximum entropy part speech tagger 
proc 
conference empirical methods natural language processing may university pennsylvania 
rigau agirre 

combining unsupervised lexical knowledge methods word sense disambiguation 
proceedings acl eacl pages 
roth 
learning resolve natural language ambiguities unified approach 
proceedings aaai pages 
van halteren zavrel daelemans combination machine learning systems samuelsson christer 

handling sparse data successive abstraction 
proceedings th international conference computational linguistics coling copenhagen denmark 
schapire singer 

boostexter system multiclass multi label text categorization 
technical report appear learning labs 
schapire singer singhal 

boosting rocchio applied text filtering 
proceedings st annual international conference research information retrieval sigir 
ting witten 

stacked generalization 
international joint conference artificial japan pages 
ting witten 

stacking bagged models 
international conference machine learning tennessee pages 

tiered tagging combined language models classifiers 
proceedings workshop text speech dialogue 
uit den 
en 
utrecht 
wolpert 
stacked generalization 
neural networks pergamon press 
zavrel daelemans 

bootstrapping tagged corpus combination existing heterogeneous taggers 
proceedings second international conference language resources evaluation lrec pages 

