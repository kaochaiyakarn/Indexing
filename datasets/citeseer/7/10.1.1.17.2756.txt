selection bulk synchronous parallel model applications priority queues computing laboratory oxford university wolfson building oxford ox qd uk 
new randomized selection algorithm bulk synchronous parallel bsp model computation application algorithm dynamic data structures parallel priority queues 
show methods improve previous results communication requirements amount parallel slack required achieve optimal performance 
establish optimality small multiplicative constant factors achieved wide range parallel machines 
algorithms fairly simple descriptions performance terms bsp parameters somewhat involved 
main reward quantifying complications allows transportable software written parallel machines fit model 
experimental results selection algorithm reinforce claims 
bsp model main technical contribution architecture independent study communication synchronization requirements fundamental computational problem selection application parallel priority queues 
ppq data structure generalizes known sequential priority queue data structure 
processor ppq implementation allows efficient simultaneous insertion new items processor simultaneous deletion items associated smallest values 
noted employed efficiently implement parallel techniques branch bound require solution sub problems associated possibly different cost 
utilizing processors insert phase newly generated sub problems efficiently select global best sub problems solved phase 
establish time bounds ppq operations function available communication throughput system 
computational model adopted bulk synchronous parallel bsp model deals explicitly notion communication synchronization computational threads 
bsp model originally proposed valiant bridge software hardware 
bsp computer described consists author supported part epsrc uk gr second author supported foundation graduate scholarship 
parts collection processor memory components communication network router deliver messages point point components facilities global synchronization barrier style sub set components 
bsp computer parametrized number processor memory components minimal time measured terms basic computational operations successive synchronization operations ratio total throughput system terms basic computational operations throughput router terms words information delivered 
computation bsp model proceeds succession supersteps 
superstep may thought segment process processor performs task data available locally start superstep 
task may include local computations ii message transmissions iii message receipts 
superstep charged max fl basic time steps maximum number basic computational operations executed processor maximum number messages transmitted received processor 
related new results selection problem computation th smallest key set keys interesting research topic 
median finding linear time examined lower bounds various values 
minimum average number comparisons required find th largest keys drawn considerable interest 
lower bound gamma dn matches performance low order terms algorithm 
sequential randomized algorithm median finding extended parallel proposed 
sequential version requires log comparisons high probability 
remainder shall log lg denote logarithm base respectively 
improved sequential median finding algorithm bootstrapping technique suggested required high probability fi comparisons constant fi 
generalize median finding results general selection problem extend deriving parallel implementations 
parallel algorithms bsp model computation require parallel time probability gamma gammac constant 
previous parallel selection algorithms include results 
techniques provide tighter probabilistic bounds optimal number comparisons lower order terms realistic parallel computational model 
show results extended efficiently solve interesting problem parallel priority queues subject operations insert find min delete min 
previous approaches traditional concurrent priority queues provide limited parallelism 
concern parallel priority queues offer prospect high degree parallelism 
approach parallel priority queues implied karp zhang 
derive parallel randomized algorithm approximate priority queue 
algorithm extended handle exact priority queues 
derive deterministic algorithms maintaining parallel priority queues 
introduce new data structures bandwidth heap bandwidth leftist heap obtained extensions sequential binary heap leftist heap 
approaches fail deliver optimal performance directly implemented bulk synchronous parallel model computation 
improve communication requirements previous results parallel priority queues extend randomized results improving communication requirements amount parallel slack required achieve optimal performance 
show optimality small multiplicative constant factors achieved wide range bsp parameters 
high probability algorithms new randomized processor mapping variant bandwidth heaps 
particular underlying data structure mixture bandwidth heaps concurrent pipelined heaps efficient selection algorithm achieve low contention 
primitive operations section state results bsp algorithms fundamental operations broadcast parallel prefix sorting 
proofs results 
primitives auxiliary routines randomized selection priority queue algorithms sections 
lemma exists bsp algorithm broadcasting word message requires time brd dn dn hee gamma max fl integer dlog gamma gamma 
lemma exists bsp algorithm computing independent parallel prefix operations requires time ppf dn dn hee gamma max fl ppf dn dn hee gamma max fl computation communication respectively integer dlog pe total time ppf 
write ppf respectively ppf ppf ppf respectively ppf ppf 
notational convention applies pipelined operations 
randomized sorting algorithm random sampling techniques variation algorithm 
fundamental difference algorithm ones works utilizes exclusively broadcast parallel prefix regular routing operations 
randomized algorithm selects sample size sorted sahni algorithm 
set gamma splitters chosen 
input keys divided buckets procedure requires parallel prefix regular routing operations 
buckets sorted recursively allocating number processors bucket 
recursion terminates bucket size square root number processors allocated 
sahni algorithm sort keys bucket 
randomized algorithm performance summarized theorem 
theorem exists randomized bsp sorting algorithm probability gamma gammaae constant ae sorts keys ffl processors constant ffl time ffl dlg ffl ppf ffl dlg ffl max fl 
randomized selection initially results related random sampling generalize special case median finding 
discussion proofs follow notation originally 
fx xn set input keys ordered gamma 
assuming keys distinct appending key index 
interested finding th smallest keys set assume loss generality dn 
symmetric arguments find gamma th largest key 
integers fy gamma randomly chosen subset gamma keys ordered subsets formed positive integers cs fx gamma fx cs gamma cs fx cs xg 
randomized bsp selection algorithm describe discussion partitions input key set sets 
establishing lower upper bounds sizes guarantee required statistic located set need determine lower bounds size set symmetrically proving probability having set size cn gamma function negligible 
investigate bounds hold 
cases identically handled show result substituting similarly upper bounds size set symmetrically established 
deduce relationships proofs results 
proposition dn gamma cs ae 
ae log probability set size cn gamma gamma gamma gammaae proposition dn gamma cs ae 
ae log probability set size cn gamma gamma gammaae bounds size derived 
similar bounds derived symmetric arguments set claim dn gamma ae 
ae log 
probability gamma gammaae set size gamma 
claim dn gamma ae 
ae log 
probability gamma gammaae set size cn gamma ae log randomized selection algorithm section derives ideas extends results 
general formulation algorithm follows 
random sample input initially chosen keys sample selected th smallest key 
iterative version algorithm improves lower order terms non iterative version proceeds step new sample selected superset sample selected previous iteration 
depending size sample iteration number iterations sequential version requires time fi comparisons fi depends choices 
number iterations determines lower bound value fi 
bsp algorithm derived selection method uses essentially parallel prefix broadcast regular routing operations sample sorting 
procedure manage selection process summarized proposition 
proposition constant ae exists randomized bsp selection algorithm probability gamma gammaae determines th smallest keys integers requires time sel log ffi lg ffi lg ppf log log ppf arbitrarily small constants ffi ffi 
proof 
assume keys randomly evenly distributed processors 
keys initially randomly distributed pre randomization phase required optimal time bounds derived bsp algorithm requires comparisons high probability 
non random distribution bsp algorithm requires high probability comparisons 
case algorithm optimal total comparison count processors 
process manage selection operation outlined procedure select denotes input set required statistic 
select 
ae log gamma gamma ae 
ae log ae gamma log 
select randomly sample fy gamma size gamma 
processors parallel 
sort 
denote hy gamma sequence keys sorted order 
ae log 
gamma 

gamma 
broadcast fm mg 
processor hki gamma parallel 
hki hki hki hki hki fg 
jx hki 
hki 
hki hki hki hki fx hki 
elseif hki 
hki hki hki hki fx hki 

hki hki fx hki 
parallel prefix sum fr hki hki 
broadcast hki hki processors parallel 
hki hki gamma 
sort hki 
denote sequence keys hki sorted order 
return gamma hki 

re execute procedure select select procedure select 
remainder proof briefly sketch time complexity procedure select detailed proof appears full version 
local operations lines take time 
sample selection line realized method similar time bounded time complexity sorting operation line 
sample sorted line algorithms depending number processors available 
particular distinguish cases analysis stage 
case gammaffl constant ffl algorithm implied theorem employed 
time required step bounded ppf lg 
case ffl constant ffl algorithm implied theorem time complexity step ppf max fl 
algorithm implied theorem employed ffi processors arbitrarily small constant ffi 
time required step bounded ppf ffi lg gn ffi 
time complexity broadcast parallel prefix operations lines bounded ppf 
iterative comparison sequence lines realized single superstep 
processor bn pc keys altogether prove way chernoff bounds total number comparisons step bounded ae log cc ae log logn probability gamma gammaae 
way claims total number keys pivot keys probability gamma gammaae 
input randomly distributed processors show way chernoff bounds probability processor local memory max pe log ng keys constant 
time complexity sorting operation line identical sorting operation line 
note keys sorted evenly distributed processors 
information collected parallel prefix broadcast operations lines effectively realize required distribution 
way preceeding analysis actual distribution routing operation takes time max fl max pe log constant max fl 
combining costs steps procedure select substituting gives desired result 
order improve lower order terms iterative version aforementioned algorithm designed 
algorithm bootstrapping technique full version 
main result stated proposition 
proposition constant ae exists randomized bsp selection algorithm probability gamma gammaae determines th smallest keys integers requires time sel log ffi lg ffi lg ppf log log ppf arbitrarily small constants ffi ffi 
parallel priority queue algorithms describe section desirable independent selection operations performed 
selection operates disjoint data sets size statistic involved operations 
probabilistic arguments analysis procedure select related data distribution extended due independency involved problems handle simultaneously selection problems 
observation exploited decrease amount parallel slack required operations involved selection process include broadcast improve selection process pipelining operations refer section 
verify analogue proposition 
similar result obtained proposition 
proposition constant ae exists randomized bsp algorithm probability gamma gammaae solves independent selection problems statistic disjoint data sets size integers requires time sel log hp ffi lg ffi lg ppf log hp logn ppf arbitrarily small constants ffi ffi 
bsp priority queues section study introduced data structure parallel priority queue ppq formulate ppq implementation bsp model 
results improve communication requirements previous approaches extend randomized algorithms improving communication requirements amount parallel slack required achieve optimal performance 
show optimality small multiplicative constant factors achieved wide range bsp parameters 
ppq data structure maintaining collection possibly duplicate items selecting items associated smallest values 
operations defined ppq insert fy insertion items fy findmin determination smallest items deletemin deletion smallest items implicit assumption exists operation construction empty queue high probability algorithms supporting pre mentioned ppq operations new randomized processor mapping variant bandwidth heaps introduced 
formally new data structure call bandwidth concurrent heap short bch defined concurrent ary heap nodes containing items arranged extended heap order 
extended heap order imply value item node greater value items children 
employing contrast achieve speedup insertions expense deletions 
adapt parameter select data structure fits relative frequencies operations 
number items stored bch number nodes depth dlog gamma gamma 
heap conveniently implemented terms data structure 
processor hii gamma maintains dimensional array hii size position array associated list hii items kg 
list hii contains items node reside processor hii note order items lists irrelevant 
associated data fields full level elem 
data field full level index node deepest non empty level elem index non empty node empty heap full level elem set 
path root empty node target denoted oe ins called insertion path shown binary case insertion path oe ins represented sequence gamma digits radix node insertion path determined time 
bsp ppq algorithm section new approach implementing 
general formulation randomized technique follows 
insert respectively delete min processes realized sequence phases 
number phases corresponds height underlying bch 
phase gamma processes advance pipelined top fashion data structure insert respectively delete min paths level level 
phase realized utilizing selection algorithm section 
algorithm terminates phases 
note previous approaches employing bandwidth heaps quite complex communication intensive merging sorting algorithms 
procedures manage insert delete min operations summarized proposition 
proposition function 
constant ae exists bsp algorithm supporting ppq operations insert deletemin probability gamma gammaae integers lg requires time sel pr ppf max fl max fl grg gamma gamma sel dpr sel pr brd ppf max fl lg procedures insert deletemin respectively depth underlying bch 

proof 
initially procedures realize insertion deletion operations bch provide correctness proof analysis resources required 
notation required proceeding details algorithms 
node bch denote set items stored node max fe maximum item nodes fu children min fu denote child minimum max fe path root empty node denoted oe ins called insertion path process manage insertion operation bch outlined procedure insert fy 
note order achieve communication efficiency maintain randomized mapping processors 
items fy randomly distributed processors insertion process line 
phases items transferred node simply re labeled locally refer lines inter processor communication required subsequent phases 
step line place physical movement items occurs input output 
remainder analysis data movement implied local re labeling operation takes place 
re labeling technique guarantees low contention algorithms preserves random distribution items processors 
observe insertion process preserves extended heap order particularly node joe ins jg insertion path oe ins value max fe incremented procedure insert 
consequently items stored children max fe correctness procedure follows 
resources required single iteration procedure insert determined insert fy 

denote set fy 
node level hg node insertion path oe ins 

elem elem 
elem full level 
full level elem 
distribute randomly items processors 
processors parallel 
select 
processor hki gamma parallel 

hki hki 

hki fx hki hki 
hki fx hki hki 
insert procedure insert 
follows 
local operations lines require time 
random distribution items processors line requires max fl grg time probability gamma gammaae constant ae 

claim derived way chernoff bounds right tail binomial distribution 
remainder proof assume processor items node median selection process line takes sel pr time 
note expression pr compensate uneven distribution items processors 
re labeling operation realized product selection process local operations lines require time 
implementation purposes require maximum item newly added node determined maintained line 
step implemented performing linear scan items node followed parallel prefix operation total time max fl ppf 
process manage deletion operation bch complicated 
define auxiliary routine adjust set sibling nodes violate extended heap property facilitates deletion process 
particular procedure rearranges items stored children shift items children maintain extended heap order 
process outlined procedure adjust fu size node fu set sibling nodes 
procedure adjust re labels items stored nodes fu maintaining extended heap order execution node holds smallest items set node holds smallest items set initially hu sequence nodes fu max fe max fe dg 
preservation extended heap order follows directly fact max fe dg incremented process 
time complexity procedure adjust derived follows 
determination sequence hu line realized broadcasting items max fe dg processors adjust fu 
processors parallel 
hu sequence nodes fu max fe max fe dg 
select jn gamma 
processor hki gamma parallel 
hki fx hki 
hki fx hki gamma gamma 
hki fx hki gamma adjust procedure adjust 
time brd subsequently sorting locally items time max fl lg 
selection process line takes gamma sel dpr 
note sufficiently large efficient sort dpr items performing gamma selection processes 
re labeling operation realized product selection process local operations lines take time 
deletion process realized procedure deletemin denotes number items deleted deletemin 
gamma 

return root 
root elem 
node root node deletion path 
elem elem gamma 
elem full level 
full level full level 
denote children node 
adjust fu 
processors parallel 
select min fu 
processor hki gamma parallel 
hki fx hki hki min fu 
hki min fu fx hki hki min fu 
node min fu node deletion path deletemin procedure deletemin 
note deletion process maintains extended heap order fact node hg deletion path value max fe incremented procedure deletemin way procedure adjust line 
time required single iteration procedure deletemin determined follows 
deletion smallest items line local operations lines realized computation time 
time required adjust procedure line analyzed previous paragraphs 
selection process line takes sel pr time 
re labeling operations realized product selection process local operations lines take time 
stated probability bound derives fact procedures insert adjust deletemin access total hd nodes underlying graph 
success probability node stated operations gamma gammaae desired bound follows 
substituting appropriate values parameters proposition multiplicity bounds time required ppq operations obtained 
bound 
replace result time bounds hold 
theorem constant ae exists bsp algorithm supporting ppq operations insert findmin deletemin probability gamma gammaae integers lg lg lg requires time insert findmin gamma deletemin operation depth underlying bch 
introducing concurrency procedures previous section manage insert delete min operations conveniently pipelined manipulate underlying bch heap top bottom 
pipelining operations exploited twofold basis 
procedures insert deletemin heavily utilize broadcast operations underlying algorithms expected benefit pipelining operations 
second pipelining exploited order decrease amount parallel slack required height underlying heap 
remainder section focus case 
case treated similar line arguments 
pipelining process straightforward procedures insert deletemin operate simultaneously 
verify analogue proposition 
proposition function 
constant ae exists bsp algorithm supporting ppq operations insert deletemin simultaneously pipelined fashion probability gamma gammaae integers hn lg requires time sel pr ppf max fl distr gamma gamma sel dpr gamma sel pr gamma brd gamma ppf gamma max fl lg procedures insert deletemin respectively depth underlying bch 
min gamma lg ng distr max min lg lg lg lg lg max proof 
proof follows similar line arguments proposition briefly sketched discussion 
pipelining possible procedures insert deletemin manipulate underlying bch top bottom require small portion heap time consisting level insert procedure levels deletemin procedure 
substituting analysis proposition proposition broadcast parallel prefix operations pipelined versions employing proposition obtain desired result 
note expression expresses portion degree concurrency exploited decrease amount parallel slack required proposition 
operation efficiently pipelined initial distribution items line procedure insert due synchronous nature bsp model 
remainder proof focus bounding time distr required initial distribution 
distinguish cases 
case lg constant ae random distribution items processors results probability gamma gammaae lg lg lg ng items processor 
claim derived way chernoff bounds right tail binomial distribution 
case treated arguments similar analysis non pipelined version algorithm see proposition 
procedures insert deletemin manipulate underlying heap top bottom problem realizing concurrently turns complicated 
particular procedure insert progress procedure deletemin begins execution target node procedure deletemin empty 
faced options satisfactory procedure deletemin selects leaf node result unbalanced heap ii procedure deletemin delays operation insert procedure finishes results limited concurrency 
alleviate limitations adopt implementation locking scheme achieves concurrency preserving consistent deadlock free operation underlying algorithms 
locking entire heap lock small portion heap time consisting node insert procedure nodes deletemin procedure 
distinct insert delete min operations access contents node locking ensure mutual exclusion 
implementation details follow 
associate field called status node heap 
field may obtain distinct values associated semantics pending insertion progress ultimately insert key node wanted delete min operation waiting key 
procedure insert starts status target set pending 
accordingly procedure deletemin starts insert operation progress status target insert operation set wanted deletemin procedure delayed phase 
iteration procedure insert status target node checked set wanted node node associated status wanted placed root insertion process node abandoned 
node placed root deletemin procedure resumes operation 
data fields full level elem modified initialization phase procedures insert deletemin 
additional operations implemented parallel prefix operation require ppf time 
additional cost affect asymptotically time bounds section 
obtain result similar proposition case procedures insert deletemin operate concurrently 
noticed cost procedures insert deletemin longer separated due concurrent nature implementation synchronous nature bsp model consider iteration maximum cost procedures 
longer benefit adapting parameter select data structure fits relative frequencies insert delete min operations 
limit notion ary heaps binary ones 
main result summarized theorem 
result similar theorem established 
replace result time bounds hold 
theorem constant ae exists bsp algorithm supporting pipelined fashion ppq operations insert findmin deletemin table speedup randomized selection 
processors size theta machine statistic ibm sp sgi integers hn lg hn lg min fh hn lg probability gamma hn gammaae requires time insert findmin gamma deletemin operation depth underlying bch lg ng 
experimental results briefly outline experimental results obtained procedure select oxford bsp library 
statistics selected th smallest median set keys 
speedup indicated table refers average speedup series experiments processor sgi power challenge shared memory system processor ibm sp distributed memory system 
input consisted integers drawn uniformly random input size varied items 
angluin valiant 
fast probabilistic algorithms hamiltonian circuits matchings 
journal computer system sciences 
blum floyd pratt rivest tarjan 
time bounds selection 
journal computer system sciences 
bollob 
random graphs 
academic press new york 
munro 
average case selection 
proceedings sixteenth annual acm symposium theory computing pp 

floyd rivest 
expected time bounds selection 
cacm 
valiant 
direct bulk synchronous parallel algorithms 
journal parallel distributed computing 

deterministic sorting randomized median finding bsp model 
appear proceedings th acm spaa june 

communication efficient data structures bsp model applications 
technical report computing laboratory oxford university may 

concurrent heaps bsp model 
technical report computing laboratory oxford university june 
karp zhang 
randomized parallel branch bound procedure 
proceedings acm symposium theory computing pp 

knuth 
art computer programming 
volume iii sorting searching 
addison wesley reading 
mccoll 
scalable parallel computing grand unified theory practical development 
proceedings ifip world congress hamburg august 
sahni 
parallel permutation sorting algorithms new generalized connection network 
jacm 

parallel priority queues 
ipl 
rajasekaran 
randomized parallel selection 
th conference foundations software technology theoretical computer science pp 
lncs springer verlag 
cheng jones shih 
parallelism locality priority queues 
th ieee symposium parallel distributed processing pp 

rao kumar 
concurrent access priority queues 
ieee transactions computers 
sanders 
fast priority queues parallel branch bound 
second international workshop irregular lncs pp 
springer verlag 
valiant 
bridging model parallel computation 
cacm 
