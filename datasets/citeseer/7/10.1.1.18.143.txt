incremental learning swiftfile richard segal watson ibm com je rey kephart kephart watson ibm com ibm thomas watson research center yorktown heights ny swiftfile intelligent assistant helps users organize mail folders 
swiftfile uses text classi er predict new message led user provides shortcut buttons quickly le messages predicted folders 
challenges faced swiftfile user mail ling habits constantly changing users frequently creating deleting rearranging folders meet current ling needs 
discuss importance incremental learning swiftfile 
criteria judging incremental learning algorithms adapt quickly changing data evaluate swiftfile classi er criteria 
nd swiftfile classi er surprisingly responsive require extensive training assumed learning systems 

swiftfile intelligent assistant helps users organize mail folders segal kephart 
text classi er dynamically adjusts user mail ling habits swiftfile predicts incoming message folders deems chosen user destinations 
user may le message predicted folders clicking shortcut button representing desired folder 
swiftfile predictions correct user simply resort usual method ling messages 
previously swiftfile classi cation accuracy assessed standard static evaluation techniques 
static evaluation entirely satisfactory 
mail environment highly dynamic folders messages constantly created destroyed reorganized 
classi er useful today may month 
static analysis fails address key questions dynamic learner swiftfile perform dynamic environment 

quickly swiftfile adapt new users 
swiftfile bootstrap learning user previously led messages rst installed 
user new mail previously led messages data available initialize classi er 
messages user le swiftfile useful suggestions 

swiftfile track changing environment established users 
important frequent source change creation new folder 
new folder may re ect change stream mail received user change user ling habits 
initially new folders contain handful messages 
messages swiftfile see new folder start suggesting messages placed 

important incremental learning 
systems designed help users prioritize organize mail incremental learning maes payne edwards 
authors systems address need adaptation recommending retraining system scratch daily basis 
retraining classi er daily basis sucient highly dynamic environment mail 
brief description swiftfile brief review results obtained standard static evaluation develop variety dynamic evaluation measures inspired questions assess performance swiftfile incremental learning algo rithm 
conclude brief discussion including comparison related 

swiftfile swiftfile add lotus notes helps users le mail folders 
shows swiftfile action 
swiftfile places shortcut buttons message 
shortcut buttons allow user quickly move message folders swiftfile predicts message destinations 
buttons ordered top bottom topmost representing swiftfile best guess bottommost representing third best guess 
buttons clicked message immediately moved indicated folder 
swiftfile predictions text classi er 
classi ers require large number training messages yield accurate predictions swiftfile circumvents potential problem 
installation treats previously led messages corpus labeled documents uses train text classi er 
initial training swiftfile immediately ready accurate predictions 
swiftfile adapts changing conditions incremental learning 
classi er trained classi er model continuously updated presenting classi er messages added deleted folder 
cost update linear length message 
updating classi er predictions identical obtained training classi er scratch entire mail database 

aim swiftfile uses modi ed version aim classify messages barrett selker 
aim tf idf style text classi er 
modi ed original aim implementation support incremental learning 
aim represents message word frequency vector component represents total number times word appears folder represented weighted word frequency vector 
steps involved computing 
folder centroid vector computed summing word frequency vectors message folder folder centroid vector converted weighted word frequency vector tf idf principle weight assigned word proportional frequency folder inversely proportional frequency folders 
de ne ff fractional frequency word messages contained folder number times word occurs folder divided total number words ff de nition term frequency tf aim tf ff ff represents set messages entire database organized mail 
de ne document frequency df fraction folders word appears 
de nition inverse document frequency idf aim idf df aim combines formulas de ne weight word folder tf idf weight vectors folder classify new message 
message arrives classi ed rst converted word frequency vector 
aim computes similarity weighted word frequency vectors folder 
aim computes similarity message vector weighted folder vectors variation cosine distance called sim salton mcgill sim min sums taken words contained aim takes folders greatest similarity predictions 
original aim classi er implemented classi cation technique batch algorithm 
modi ed aim implementation support incremental 
swiftfile creates shortcut buttons folders predicts user place message 
predictions correct buttons enable user quickly le messages folders 
learning 
new aim implementation maintains database containing centroids folder new message added folder centroid updated adding vector message similarly message removed folder word frequency vector message subtracted folder centroid 
centroids folder stored inverted index quick access 
classify message aim computes sim similarity folder weight vector 
weight terms required compute sim computed folder centroids 
sim similarity score computed folder aim predicts message belonging folders highest score 

static experiments rst analyzed performance swiftfile standard static evaluation techniques 
applied swiftfile text classi er mailboxes users local institution 
experiments performed original users participated previous study 
experiments new versions user mail database 
user previous study omitted available second round experimentation 
table presents characteristics test databases 
databases range messages led folders 
number folders important folders database dicult classi cation table 
mail databases test swiftfile 
database folders messages user user user user user problem 
experiment conducted user previously led messages data 
randomly sampled user previously led messages training remaining messages testing 
repeated experiment times averaged results 
shows results experiment 
graph shows swiftfile accuracy user swiftfile provides shortcut buttons 
accuracy buttons de ned frequency rst buttons move message correct folder 
swiftfile performance just button varies 
performance level deemed helpful users performance level borderline 
user may save time swiftfile perception swiftfile frequently incorrect may lead user dissatisfaction 
shortcut buttons swiftfile accuracy improves 
extra buttons substantially improve performance adversely ecting user 
swiftfile slightly accurate buttons extra performance merit increase screen real estate 
swiftfile automatically ling messages level performance unacceptable 
swiftfile incorrect predictions easily overridden error rate minor annoy buttons accuracy user buttons user buttons user buttons user buttons user 
static performance swiftfile 
solid lines show accuracy swiftfile buttons 
dotted lines show accuracy naive strategy providing shortcut buttons frequently folders 
ance compensated bene receiving right suggestion time 
compares performance swiftfile naive strategy providing shortcut buttons frequently folders 
swiftfile provides substantial improvement naive strategy databases 
naive strategy performs user user actively uses folders 
swiftfile advantageous user cuts perceived error rate buttons half 

dynamic experiments static evaluation swiftfile necessarily reveal performance dynamic environment 
goal dynamic evaluation understand swiftfile performs time 
analysis allow answer key questions swiftfile performs new users reacts new information creation new folders important incremental learning 
accurate way evaluate swiftfile dynamic behavior give swiftfile users chart performance year 
method accurate time consuming dicult experiment algorithmic variations 
static mail database simulate dynamic environment 
basic idea previously led messages mailbox simulate continuous stream messages 
previously led messages swiftfile simulator date order 
message arrives classi ed swiftfile latest classi er 
running score maintained comparing swiftfile classi cations known destination folder 
message led destination folder classi er model destination folder updated 
simulator assumes folders simulation assumes new folder created simulator processes rst message folder 
procedure examples accuracy 
simulation results mailbox user 
solid line graphs accuracy messages seen 
dotted line identical swiftfile penalized missing messages destined new folders 
repeated message mail database 
experiments follow su cient space show learning curves experiment database tested learning curve user summarize results databases table 
rst question answer messages tf idf style classi er need see useful predictions 
helps answer question plotting swiftfile learning curve simulating behavior user mailbox 
messages span period years 
solid line graphs accuracy swiftfile buttons 
rst results appear disappointing 
missing rst messages classi er stabilizes accuracy 
classi er continues struggle level processed messages point classi er displays classic learning curve steady improvement 
classi er start performing processed messages 
results suggest classi er needs hundreds examples ectively learn user mail ling habits closer evaluation reveals subtle happening 
rst messages fourteen messages placed new folders 
swiftfile cor table 
performance swiftfile rst fty training examples 
results show swiftfile need examples achieve performance 
database cumulative accuracy user user user user user rect predictions messages destination folders exist classi cation time 
swiftfile hardly blamed classifying message category exist 
dotted line shows swiftfile performance exclude messages prompt creation new folders 
results dramatically di erent 
swiftfile classi er performs exceptionally right start 
swiftfile perfect rst messages sixteen go new folders fourteen classi ed correctly 
swiftfile performance stays high experiment brie dropping level near 
demonstrates interesting phenomenon common swiftfile inverted learning curve accuracy starts high slowly decreases 
decreasing learning curve result classi cation task constantly changing 
swiftfile initial classi cation task easy user folders 
fact user creates folders swiftfile shortcut buttons provide quick access user folders 
small number folders exists rst part experiment explains swiftfile performs limited training data 
classi cation task gets dicult time progresses number folders choose gradually increasing 
messages placed folder homogeneous time content messages placed folder shifts 
learning problem gets harder learning algorithm data learn 
competing forces forces curve downward forces curve upward 
case result downward sloping learning curve 
table shows performance swiftfile text classi er rst fty messages mail database classi er penalized messages destined new folders 
results clearly demonstrate nature domain training examples needed successfully train classi er predictions 
goal investigate learning rate tf idf learned mail classi cation require quick learner 
mail classi cation task starts easy dicult substantial number messages available training 

classi er adaptation investigate classi er adapts changes user mail ling habits 
graphs shown previous section display shortterm dynamics performance measure graphed averaged entire history experiment 
graph data moving averages 
moving average tells classi er performs dozen messages gives better idea performance varies time 
displays data performance displayed moving average 
moving average calculated dampening function discounts weight earlier predictions 
dampening function half life messages 
assigns half weight messages quarter weight previous messages graph shows accuracy swiftfile classi er penalized messages placed new folders 
graph demonstrates classi er accuracy vary considerably usually maintains accuracy level 
dips performance messages 
right side gure shows graph vertical lines indicating folders created 
dip associated substantial folder creation activity 
system usually recovers quickly dip dip messages longest messages classi er rst drops returns 
results show creation new folders cause classi er performance degrade amount degradation acceptable classi er stays level drops 
table shows results experiment databases 
table summarizes moving average database varies time calculating minimum maximum mean standard deviation moving average length experiment 
rst fty examples excluded calculation lter early variations 
examples accuracy examples accuracy 
simulation results user graphed moving average 
graphs identical right shows new folders created 
performance varies considerably time rarely drops 
table 
performance incremental learning 
cumulative accuracy mean moving average indicative absolute performance minimum maximum standard deviation moving average suggest performance varies time 
moving average cumulative std 
database accuracy min max mean dev 
user user user user user results show mean moving average close button accuracy reported static experiments suggesting incremental learning fact successful 
furthermore standard deviations indicate volatility variations usually large user experience low accuracies 
interestingly folder creations shown accompanied drops classi er performance 
swiftfile classi er maintains performance despite faced harder classi cation problem new folders created having data learn new folders 
suggests swiftfile classi er successfully learn new folders examples 
analyzes swiftfile classi es user messages folder seeing single message folder 
graph shows cumulative accuracy swiftfile ling second message placed folder 
graph identical second message placed folder scored 
graph shows swiftfile classi er quite second message placed folder especially considering limited training data base decision 
swiftfile perfect examples accuracy 
swiftfile accuracy ling second message placed folder 
single training example performance 
table 
performance incremental learning newly created folders 
results training example new folder 
database cumulative accuracy user user user user user rst folders misses rst sixteen 
importantly swiftfile continues perform number folders gets large 
folders swiftfile accurate placing second message new folder 
table shows swiftfile accuracy newly created folders test databases 
ability swiftfile classi er learn single example unexpected 
usually learning algorithms require substantial number examples predictions 
success tf idf learning single example probably partially due tf idf features message classi cation selecting salient features common decision tree decision rule algorithms 
leave testing hypothesis 

incremental learning incremental learning allows swiftfile adapt changes user les mail 
swiftfile updates classi er user les message moves message folders deletes message 
incremental learning ensures classi er date possible comes cost 
incremental learning reduces choices learning algorithms algorithms text classi cation incremental cohen apte :10.1.1.41.8517
second requires classi er mail client closely integrated order classi er noti ed important events 
costs incremental learning decision empirical evidence doing confers advantage 
evaluate importance incremental learning comparing performance periodic learning classi er updated messages 
intent compare incremental learning common strategy batch systems update classi er overnight maes payne edwards mitchell :10.1.1.153.2100
chose period messages estimate average active mail user receives messages day 
second believe users le mail daily 
wait inbox starts get large le messages sitting 
result users receive fewer messages day may classi er order new examples session 
left side compares performance incremental learning dotted line periodic learning solid line 
performance periodic learning slightly incremental learning experiment places performance periodic learning dips considerably incremental learning 
periodic learning drops times falls low incremental learning drops rarely drops 
cumulative accuracy periodic learning entire database points lower cumulative accuracy incremental learning 
table shows performance periodic learning databases 
compared results incremental learning table see periodic learning substantially reduces accuracy classi er simultaneously increases volatility 
right side compares performance incremental periodic learning task pre table 
performance periodic learning 
periodic learning results lower accuracy increased variability compared incremental learning 
moving average cumulative std 
database accuracy min max mean dev 
user user user user user table 
performance periodic learning newly created folders 
periodic learning match incremental learning success infrequent updates 
database cumulative accuracy user user user user user second message placed folder 
solid line represents periodic learning dotted line represents incremental learning 
periodic learning task averaging accuracy 
similar results occur databases shown table 
results suggest incremental learning er substantial improvement mail classi cation tasks 
incremental learning improves accuracy reduces amount time user perceives classi er performing poorly enables classi er perform newly created folders 

related mitchell 
performs similar analysis dynamic behavior cap calendar scheduling assistant learns user preferences assist user scheduling meetings 
cap uses batch learning algorithm retrained nightly 
interestingly tested academic environment cap demonstrates cyclical learning curves changes academic calendar 
substantial body investigating text classi cation help users handle email lashkari payne edwards cohen :10.1.1.41.8517
focused accurately predicting actions performed static training corpus ignoring equally important issues regarding classi er adapts continuous change 
notable exceptions 
lashkari 
presents examples accuracy examples accuracy 
comparison incremental learning periodic learning learning occurs messages 
solid line shows periodic learning dotted line shows incremental learning 
left graph compares moving average right graph compares learning second example placed new folder 
accuracy periodic learning slightly incremental learning displays large performance drops 
small learning curve demonstrate agents learn collaborate 
payne edwards consider possibility incremental learning details provided 

learning systems designed operate dynamic environment evaluated static analysis techniques 
argued importance studying dynamic properties learning algorithm 
evaluating dynamic properties swiftfile learned valuable lessons nature mail classi cation problem properties tf idf text classi ers 
particular able myths learning mail classi er 
take messages mail classi cation system learn user mail ling habits time user creates folders problem dicult learning algorithm ample training data predictions 
second updating classi er overnight sucient overnight updates respond quickly frequent changes user mail ling habits 
learned tf idf classi ers responsive useful predictions category seeing just single message 
hope compare responsiveness tf idf classi ers types text classi ers 
apte damerau weiss 

language independent automated learning text categorization models 
proceedings seventeenth annual acm sigir conference pp 

new york acm press 
barrett selker 

aim new approach meeting information needs technical report 
ibm almaden research center almaden ca 


concept features re agent intelligent email agent 
proceedings second international conference autonomous agents pp 

new york acm press 
cohen 

fast ective rule induction 
proceedings twelfth international conference machine learning pp 

san francisco ca morgan kaufmann 
cohen 

learning rules classify email 
proceedings aaai spring symposium machine learning information access pp 

menlo park ca aaai press 
lashkari metral maes 

collaborative interface agents 
proceedings twelfth national conference arti cial intelligence pp 

menlo park ca aaai press 
maes 

agents reduce information overload 
communications acm 
mitchell caruana freitag mcdermott zabowski 

experience learning personal assistant 
communications acm 
payne edwards 

interface agents learn investigation learning issues mail agent interface 
applied arti cial intelligence 
salton mcgill 

modern information retrieval 
new york mcgrawhill book 
segal kephart 

intelligent assistant organizing mail 
proceedings third international conference autonomous agents pp 

new york acm press 
