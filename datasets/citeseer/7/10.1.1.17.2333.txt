connectionist inference systems hans werner gesellschaft fur mathematik und gmd birlinghoven sankt augustin uunet uu net steffen holldobler fg intellektik fb informatik th darmstadt darmstadt steffen intellektik informatik th darmstadt de presents survey connectionist inference systems 
motivation situations life decisions huge amounts knowledge incomplete inconsistent 
gathered knowledge decision procedures long process education experience 
fact learning process stops life 
decisions viewed inference processes apply certain rules inference situation knowledge order achieve certain goal 
humans perform wide variety inferences extremely fast 
inference processes needed solve object recognition speech processing story understanding commonsense reasoning tasks just examples 
glance observation surprising main building block human nervous system neuron quite slow 
computational speed milliseconds account complex behavior carried milliseconds posner 
means entire complex behaviors carried time steps feldman ballard 
field artificial intelligence model complex behaviors 
current models need millions time steps 
problems humans solve reflex intractable modelled conventional way cf shastri 
possible 
massive parallelism take place human nervous system 
human nervous system structured central controller supervises activities various parts 
neurons interconnected excitatory inhibitory synapses perform local operations 
operations thresholding operations spatial temporal summation quite simple 
neurons capable transmitting significant amounts symbolic information 
knowledge encoded connections neurons strength neurons excite inhibit 
nervous system remarkable features 
quite robust 
neurons dying constantly 
hamper skills nervous system injured accident handicapped 
nervous system handle noisy input certain level 
degrades gracefully noise level increased 
nervous system evidential gathers information order best decision 
context sensitive general powerful mechanisms learning generalization 
connectionist artificial neural networks received attention applied models behavior match psychological data biological plausible computationally efficient cf rumelhart 
applications mainly concerned low level cognitive tasks perception cf mcclelland rumelhart motor control associative information retrieval cf 
hopfield feature discovery cf rumelhart zipser 
considerably experience gathered far modelling high level cognitive tasks connectionist networks 
know pot refers cooking pot context different context cf lange dyer 
understand stories 
rules learned follow immediately told cf hadley 
knowledge represented reason knowledge 
reason knowledge main goals field mathematical logic deduction 
proposed idea lingua possibly truth expressed calculus possible truth computed universal encyclopedia knowledge represented 
know lingua calculus sense gathered quite experience representing knowledge formal symbolic language drawn logically suitable inference mechanism 
field automated reasoning mainly concentrated mechanizing inference processes conventional computer really concerned question humans reason 
automated reasoning systems slow solving interesting problems 
quite impressive power poor exercising control reasoning process 
exhibit reasonable form common sense 
adequate sense solve simpler problems faster difficult ones cf bibel 
adapted massive parallelism 
super computing community convinced year fastest computers massively parallel 
massive parallelism may serve vehicle reconcile research field connectionism field automated reasoning 
just want build systems show intelligent behavior want understand humans 
fields may profit insights connectionist inference systems 
automated reasoning systems may efficient may able solve interesting problems may adequate 
conversely vast knowledge techniques developed field automated reasoning applied model high level inferences connectionist setting 
article gives overview state art connectionist inference systems 
inference article understood kind high level inference sense inferred set facts rules 
brief connectionist systems section classes systems principle mode operation 
connectionist inference systems energy minimization essentially symmetric networks binary threshold units compute minimizing energy encoded network section 
connectionist inference systems spreading activation essentially structured networks patterns activation propagated network section 
section section briefly describe basic techniques followed systems techniques 
section gives brief overview hybrid conventional connectionist systems conventional part prolog system connectionist techniques learn heuristic examples 
outlook current research problems completes article 
connectionist systems connectionist systems aim modeling aspects animal human nervous system computational level cf 
feldman ballard rumelhart 
central concept connectionist system individual unit models functionality neuron group neurons 
feldman ballard unit characterized potential real number value integer input vector potential represents action potential neuron 
value represents output firing neuron 
restriction finite number integers biologically motivated fact firing neuron impulses second neurons react th second 
frequency encode limited amount information 
input represents input received neuron externally output receptor internally weighted possibly modified output unit 
units connected set directed weighted possibly modified links 
weight kj connection unit unit represents strength neuron inhibits neuron 
modifier may allows quickly turn connections input received unit connection unit determined kj modifier output th unit 
weights modifiers usually omitted equal 
units connectionist network updated synchronously asynchronously 
update potential value unit computed activation function output function respectively denotes assignment 
activation output function simple functions threshold sigmoid functions 
example consider binary threshold unit potential value determined kj constant denoting threshold unit 
units transmit large amounts information knowledge connectionist network encoded connections units 
central controller 
operations performed locally 
initial external activation units excite inhibit 
obvious problem spreading activation controlled collection locally operating units global decision 
massive parallelism efficient approach 
ensure process spreading activation converges quickly 
ideal case connectionist system converges single sweep spreading activation 
computation result time proportional diameter network 
keep mind np hard problem remains np hard solved connectionist network 
energy minimization energy minimization technique model behavior certain class connectionist networks 
technique formally introduced hopfield observed strong similarity statistical models magnetic materials physics behavior called symmetric networks symmetric network consists set binary threshold units unit connected unit weight ij connection unit unit equal ji weight connection unit unit shows small symmetric network 
external activation units network behaves procedure stable state unit changes output anymore reached ij weight connection unit output unit threshold unit sums range number units network 

select arbitrary unit 
ij ij ij 
goto 
shows example activation network depicted 
network converges possible stable states shown depending selection step update procedure 
example unit selected receives total input larger threshold 
unit turned net received stable state shown 
hopfield showed state symmetric network described energy function gamma ij ffifl fflfi ffifl fflfi ffifl fflfi ffifl fflfi small symmetric network 
numbers edges denote weights numbers nodes denote thresholds units tiny numbers node numbers assigned units 
recall ij ji connections weight ij shown 
connections units units weights connections 
hx example activation 
units activated output shown filled circles units remain output shown open circles 
stable states network reached depending selection step update procedure 
remaining stable states network reached different initial activations 
energy network decreases unit changes output 
example shown obtain pl gamma gamma gamma activation pattern find pl 
select unit sum input equal gamma smaller threshold unit turned obtain network shown 
observe energy network reduced pl 
easy see example value defines global minimum energy function 
update procedure symmetric network specifies gradient descent energy function 
guaranteed procedure finds global minimum may get stuck local minimum 
poses problem find global minimum examples discussed subsection case 
escape local minima hinton sejnowski result statistical physics 
output unit longer computed deterministically changes probability gamma ij parameter called pseudo temperature temperature short relates temperature statistical models magnetic materials gases physics 
stochastic networks shown system equilibrium output units change time anymore system state low energy state high energy 
drive system equilibrium 
obviously behavior stochastic network equal behavior symmetric network approaches 
recall symmetric networks equilibrium quite easily quickly gradient descent 
equilibrium may local minima 
hand high temperature system finds global minima may take long reach 
solve dilemma kirkpatrick etal 
applied technique called simulated annealing taken physics 
start large value gradually decrease value approaches 
geman geman able prove technique guaranteed find global minima energy function steps value decreased infinitesimal small 
words time find global minima exponential number units network 
detailed discussion symmetric stochastic networks user referred hertz 
propositional logic energy minimization important technique parallel distributed processing problems rephrased problem finding global minima energy function 
typical example cube shown 
brain able switch different spatial representations cube 
representation corner showing representation corner hidden 
feldman ballard showed observation modelled symmetric neural network possible representations stable states network 
field artificial intelligence cognition bibel gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma cube 
interested inferencing know kind inference problems computed minimizing energy symmetric stochastic network 
pinkas answered question formally showing problem finding global minima energy function equivalent satisfiability problem propositional logic 
illustrate pinkas results come back example 
behavior network characterized propositional logic formula pl sense assignment variables satisfies pl defines global minimum pl vice versa 
assignment fv 



corresponds network formula pl evaluated true 
pinkas proofs constructive 
propositional logic formula define equivalent energy function form vice versa 
scope give details transformation pinkas 
worth repeat computing symmetric network equivalent computing propositional logic calculus 
give application mention related system want point computation symmetric network usually means units network externally activated network converges stable state 
sense interested stable state close initial activation 
mentioned previous subsection find global minimum energy function simulated annealing may take time exponential number units network 
practical applications simulated annealing steps temperature decreased usually quite large network converges faster 
systems guaranteed find global minimum usually converge stable state close local minima 
optimization problems see subsection means network find optimal solution suboptimal 
formally systems trade soundness time 
applications related systems optimization problems immediate consequence pinkas results symmetric neural networks applied solve optimization problems 
illustrate application consider travelling salesman problem tsp 
tsp np hard problem received considerable attention neural network community cf hopfield tank wilson 
formalisation taken brandt hertz 
salesman visit cities 
travel city city costs amount ij problem travelling salesman consists finding tour visits city returns starting point minimal costs 
represent problem binary threshold units ik interpretation ik th th city 
need units 
total costs tour computed ij ik ik gamma indices range gamma taken modulo solution obtained city visited ik holds city ik holds 
equations combined tsp ij ik ik gamma fl gamma ik gamma ik fl scaling factor 
obviously tsp global minimum iff assignment ik defines solution tsp 
tsp easily transformed form 
represented symmetric network global minimum simulated annealing 
constraint satisfaction special form inference realized constraint satisfaction techniques applied successfully subfields ai computer vision waltz circuit analysis stallman sussman planning stefik diagnosis davis geffner pearl williams logic programming jaffar lassez connectionist approaches 
constraint satisfaction may described follows set variables set constraining relations subsets variables find values domains assigning variables satisfies constraints 
formally constraint satisfaction related concepts defined follows 
ary constraint consists variables domains decidable relation theta delta delta delta theta ary relation ith place symbolized 
different constraints tied constraint networks sharing variables constraint network variables xm consists constraints variables subset xm 
tuple am satisfies constraint subsequence am corresponds variables element relation 
solution constraint network constraints variables xm domains dm tuple am theta delta delta delta theta dm satisfies constraints 

task finding solution constraint network called constraint satisfaction problem csp 

csp consisting unary binary constraints called binary csp 
csp transformed binary csp way solution binary csp yields solution original csp 
restrict oneself binary csps loss generality 
variety algorithms constraint satisfaction 
constraint satisfaction general np hard special subclass constraint satisfaction algorithms deserves attention 
algorithms may viewed preprocessing methods simplify problem transforming constraint network equivalent easier solve 
come back algorithms section 
approach solving combinatorial search problems appears promising generate initial solution repair solution applying energy function 
minton shown technique extended constraint satisfaction problems 
initial assignment values constraint variables repaired assignment violates constraints 
repair method guided ordering heuristic selects variable currently participating constraint violation value variable minimizing number outstanding constraint violations 
minton inspired hubble space telescope scheduling problem traditional programming methods failed initial scheduling system developed fortran supposed require weeks schedule week observations 
consequence constraint system developed guarded discrete stochastic gds network developed johnston 
gds network derivation hopfield network having main network guarded network 
means particular constraint variable represented set nodes node set representing value variable 
representation analogy 
node value 
solution state exactly node variable value nodes value 
nodes value represent assignment values variables constraint network 
constraint represented gds network inhibitory connections nodes 
opposed hertzberg network ensures value assigned variable 
network provides excitatory input large turn node set nodes belonging variable 
hand connection weights set way turning node set 
update network works follows 
set nodes represents variable picked randomly 
node set selected state inconsistent state node flipped 
states nodes consistent solution reached 
analysis gds network showed performance better backtracking certain tasks queens problems 
reason lies 
node chosen update means ffl inconsistent value retracted ffl new value minimizes number variables 
heuristic expressed follows cf minton 
min conflicts heuristic set variables set binary constraints assignment specifying value variable 
variables conflict values violate constraint 
procedure select variable conflict assign value minimizes number conflicts 
minton network behavior approximated symbolic system uses hill climbing min conflicts heuristic 
similar hill climbing network may settle local optimum involving group unstable states oscillate 
cause problems practice network fails converge stopped started 
unfortunately gds network shown effectively problems solutions 
fails solve problems solutions local minima 
wang tsang shown remedy drawback 
proposed multilayer neural network learning rule updates connection weights order escape local optima 
issue closely related constraint satisfaction constraint relaxation 
turned practical problems inconsistent solution 
handle problems idea constraint relaxation developed assumes constraint constraint network satisfied subset 
cases constraints divided hard constraints ones satisfied soft constraints ones may violated 
hertzberg neural net approach introduced realizing constraint satisfaction constraint relaxation 
idea transform constraint satisfaction problem boltzmann machine way constraint relaxation enabled problem inconsistent 
problem inconsistent boltzmann machine tends converge best solutions 
restricted unit resolution ballard ballard ballard tried construct symmetric network global minima corresponding energy function represent restricted unit resolution proofs 
see chang lee definition unit resolution 
system formulas proofs restricted variables constants terms clause proof 
consequently herbrand universe underlying ballard logic finite logic decidable 
furthermore set substitutions finite 
formula network constructed unit substitution 
restricted unit resolution proof soon proof discovered substitution units activated represent substitutions proof 
restricted order logic pinkas lifted ballard restriction 
allows general order terms including function symbols applies unrestricted resolution 
set clauses query pinkas compiles symmetric network global minima network viz 
energy function encoded network corresponds order resolution proof 
remaining restriction length proof bound 
words bound length proof knowledge base query proof length system find proof 
kind restriction automatic theorem prover obey 
connectionist frame system supporting binding variables allocation frames equality anandan mjolsness 
main operation matching term variables ground term terms represented directed acyclic graphs dags 
words attempts find substitution oe instance oes equal find substitution distance metric objective function dags defined specifies mismatch dags 
objective function equivalent energy function form matcher oe corresponds global minimum energy function 
symmetric network represent objective function simulated annealing compute matching substitution 
distributed connectionist production system touretzky hinton connectionist interpreter restricted class production system distributed representations 
finite set constants essentially variable comprise set terms 
hypothesis production rule consists triples terms ground form hx bi hx di variable letters constants 
words hypothesis rule contains variables contains variable occurs argument second triple 
touretzky hinton production system restricted assuming time hypothesis rule successfully matches content working memory 
conflict 
working memory set binary state units 
coarse coded unit represents set triples 
certain triple stored working memory activating units vote triple 
find hypothesis production rule matches working memory called clause spaces introduced 
networks sense mozer pull second triple hypothesis production rule 
units clause spaces copies units working memory 
bidirectional excitatory connection units working memory clause spaces 
similarly rule units representing triples hypothesis production rules bidirectional excitatory connected respective units clause space 
weights connections set exactly triple selected triples stored main memory 
atoms working memory form hypothesis production rule activate clause spaces respective rule vice versa 
solutions suppressed inhibitory connections units clause space units representing different rules 
far considered ground production rules 
effect variables touretzky hinton production systems constrain hypothesis rules constant triples order fire rule 
bind space constants coarse coded bidirectional excitatory connected respective units clause space 
bind unit representing constant connected units clause space represent triples element matching rule minimum energy state 
done simulated annealing production system modeled symmetric network 
soon matching rule discovered action part rule executed storing new triples removing old triples working memory 
details see touretzky hinton 
dolan smolensky formal account behavior tensor product techniques smolensky 
interesting part organization working memory worth mention properties easily achieved standard ai technologies 
working memory consists units representing triples em receptive field unit consists triples 
triples built constants different triples 
distributed equally units working memory triple occurs receptive fields 
triple stored memory activating units receptive field contains triple 
units represent triples 
pose problem long triples stored memory 
stored triples receive votes triples 
triples stored time ghosts may occur triples may receive votes considered memory explicitely stored 
hand triple deleted memory inhibiting units receptive fields contain triple 
units represent triple process may cause stored triples lose votes 
consequently triple votes considered stored votes may suffice 
triples deleted previously stored triples may vanish explicitely deleted 
techniques applied touretzky show structured objects lists trees distributively represented associatively retrieved 
main idea represent list structure shown set triples fha ci hb peter di hd likes di hc art cig represent manipulate triples way triples represented manipulated 
peter likes art simple cons cell representation lisp 
propositional non monotonic reasoning previous subsections satisfiability problem propositional logic mapped energy minimization problem symmetric network vice versa 
symmetric networks may applied propositional non monotonic reasoning pinkas 
illustrate approach consider meeting example taken brewka assume commonsense statements 
usually go project meeting 
rule apply somebody sick cold 
rule applicable somebody vacation 
statements formalized propositional formulae obvious intended meaning 
positive real numbers associated formulae regarded penalties paid assignment satisfy respective formulae 
intuitively prefer assignment assignment iff penalty paid penalty paid want meet person know assignment fm 



preferred 
formulae satisfied assignment penalty paid 
assignment falsifies formula receives higher penalty 
assume learn person going meet sick 
formally add fact represents real number larger penalty 
informally falsifies pay penalty 
easy check circumstances assignments fm 



fm 



preferred ones falsify meeting canceled 
situation changes sick person cold 
adding fact assignment fm 



preferred meeting take place 
person having cold happens vacation assignment fm 



preferred chance meet 
pinkas showed problem finding preferred assignment set propositional formulae encoded minimization problem energy function vice versa 
proofs constructive obtain function gamma gamma cs gamma cm sm function encoded symmetric network shown 
easy see global minima corresponds precisely preferred assignment 
simulated annealing performed long network settle stable state unit active units passive 
ffifl fflfi ffifl fflfi ffifl fflfi ffifl fflfi gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma symmetric network meeting example 
learn fact sickness person simply clamp unit network settle 
clamping unit corresponds addition term gamma corresponding energy function real number larger maximal input received combines frame language similar kl brachman schmolze non monotonic reasoning 
pinkas approach socalled viz 
positive real numbers associated formulae specify penalty paid interpretation satisfy formulae 
searches model proposition 
believes proposition proposition true model extension respect underlying default theory 
summary learned previous subsections simulated annealing schedule run fast symmetric network may settle global minima local minima 
note may omit constants energy function seeking minima 
unit clamped externally activating unit keeping activation computation 
clamped unit active 
propositional non monotonic reasoning task corresponds selection assignment preferred 
improve selection viz 
escape local minima add time annealing schedule 
words time limited resource network decision 
necessarily optimal 
soon time available network second thoughts reconsideration eventually better decision 
spreading activation previous section discussed inference systems energy minimization 
problem hand transformed energy function global minima energy function correspond solutions problem 
energy function encoded symmetric network binary threshold units driven stable state viz 
minima energy function asynchronous updates units 
section consider inference systems spreading activation metaphor 
problem encoded structured connectionist network necessarily symmetric 
input units externally activated activation spread network output units excited inhibited 
simple example consider feed forward network binary units shown 
externally excite unit steps unit activated 
similarly excite unit steps unit activated easy see network encodes xor function 
ffifl fflfi ffifl fflfi ffifl fflfi ffifl fflfi phi phi phi phi phi phi hj ffifl fflfi xxxxx xz connectionist network encoding xor function 
networks binary threshold units investigated mcculloch pitts 
showed networks encode finite automata vice versa finite automaton encoded network 
done computer done network binary threshold units 
constraint satisfaction previous section sketched constraint satisfaction realized energy minimization 
describe alternative special subclass constraint satisfaction algorithms 
algorithms preprocessing methods complete constraint satisfaction algorithms methods computing level local consistency 
examples arc consistency algorithms mackworth complexity nodes nodes hx yi hx zi hy zi ha ai ha bi hb ai hb bi pi sigma scheme connectionist network constraint satisfaction 
discussed kasif 
algorithms implemented parallel easily connectionist approaches computing arc consistency 
introduce approach part section described cooper swain 
show second part section approach extended compute global consistency local consistency connectionist networks designed compute solutions constraint satisfaction problems 
previously published 
connectionist networks accordance unit value principle cf feldman ballard separate connectionist node dedicated value variable tuple constraint constraint network 
approach analogy way represents constraint networks propositional clauses kleer 
computing arc consistency set variables csp sake simplicity union variable domains 
cooper approach variable value pair hx ai represented connectionist node node denote ai 
binary constraint variables consists set pairs pair representing consistent value assignment variables 
cooper introduces connectionist node node quadruple hx bi denote node bi 
symmetry bi chy ai denote node 
shown cooper swain nodes nodes connected way resulting network computes arc consistent solution corresponding constraint satisfaction problem cf 
purpose nodes initialized follows ffl node obtains potential 
ffl node bi obtains potential ha bi admissible assignment values hx yi obtains potential 
convenient ai example referring potential node denoting node 
node reset find node variable constraint node node satisfied 
rule called arc consistency label discarding rule ai bi bi easy verify equivalent sgn denotes signum function ai sgn bi delta bi shortcoming label discarding rule computes arc consistency mackworth 
arc consistency may help find global solution restricting search space needs additional mechanisms obtain globally consistent network 
show section connectionist network designed compute global consistency 
approach described section may compared lange dyer signatures maintain variable bindings 
global consistency idea apply communication scheme cooper swain potential node encode information variable value pair contributes solution 
information composed codings associated nodes 
particular encode node prime number denote encoding function theta set nodes set prime numbers 
example fx yg fa bg may defined follows ai ai ai bi bi ai ai ai bi bi bi bi nodes bi sense omitted coding 
notation node potential term bi example may denote connectionist node representing tuple ha bi constraint may denote potential node 
determined context meaning intended 
initial potentials nodes cooper 
node bi assigned potential pair ha bi constraint 
initial potential node ai determined product codes nodes refer variable node different value variable factor occur product bi fxg sgn gamma square root due fact chy chy identical nodes 
computing arc consistency node potential reset inconsistent perform called graceful degradation 
node receives potentials nodes computes greatest common divisor gcd 

gcd returned nodes node potential returned 

node computes common multiples lcm data coming nodes refer variables combines computing gcd 
idea potentials nodes shall reflect paths network correspond solutions constraint satisfaction problem 
node may path node node potential 
start allowing paths nodes 
part path determined admissible corresponding node potential path deleted 
means global information solution paths held locally nodes network 
keep information consistent nodes compute gcd potentials neighboring nodes 
gcd reflects piece information neighboring nodes agree 
order consider alternatives nodes compute lcm data comes nodes connecting variable combine results applying gcd operator 
alternation application gcd lcm directly corresponds semantics constraints constituting tuples constraint network viewed conjunction constraints gcd constraint viewed disjunction tuples lcm 
formally degradation rule denoted follows ai gcd lcm bi bi gcd ai bi bi degradation rule monotonous discrete network settles 
potentials nodes characterize set solutions constraint satisfaction problem 
particular solution subset nodes holds 

variable occurs exactly 
potentials nodes divisible ai bi bi square root due fact bi chy ai identical nodes 
show approach sound complete 
purpose answer questions 

subset nodes variable occurs exactly 
potentials nodes divisible ai bi bi represent solution degradation rule converge solution approach sound 

subset nodes properties exist solution constraint satisfaction problem approach complete 
answer question assume subset nodes conditions hold represent solution constraint satisfaction problem 
means tuple suggested violates constraint network 
bi node representing tuple constraint violated potential bi 
due initialization scheme potential node contain factor bi holds potential bi neighboring node provide factor bi factor potential ai potential bi potentials divisible bi 
divisible defined 
contradiction assumption subset nodes conditions hold represents solution constraint satisfaction problem 
hand solution constraint satisfaction problem defines subset nodes holds 

constraint represented exactly node 

potentials nodes equal 
subset nodes connected nodes ai bi cg easy see represents solution 
potentials nodes equal potentials nodes divisible code node divisible product codes nodes satisfies conditions proposed 
shown soundness completeness approach toone relationship solutions constraint satisfaction problem special subsets nodes corresponding connectionist network 
discuss space complexity approach 
number variables constraint satisfaction problem number values domain 
number nodes nodes estimated follows 
number nodes mn number nodes total number nodes addition consider local space required storing numbers 
node potential product factors corresponding nodes network 
factors represented bit vectors facilitates gcd lcm operations reducing intersection und union operations 
means need additional space magnitude node additional space total 
limited inference systems humans capable performing wide variety cognitive tasks extreme ease efficiency 
shastri called inferences reflexive human react reflex 
hand traditional ai systems tasks modeled inference problems problems turn intractable 
problem serious intend model common sense reasoning 
expect common sense knowledge base spanning human consensus knowledge may comprise rules facts lenat 
want model reflexive reasoning environment discover inference processes yield answers decisions time sublinear size knowledge base 
shastri ajjanagadde system performs inferences 
shastri ajjanagadde inspired criticism john mccarthy observed commentary smolensky connectionist models seen basic predicates unary applied fixed object concept propositional function predicates overcome propositional fixation allow predicates shastri ajjanagadde solve variable binding problem problem dynamically binding values variables 
shastri ajjanagadde system detail mention inference system robin developed lange dyer essentially equivalent shastri ajjanagadde system 
differ small technical detail concerning binding variables discuss subsection 
scope shastri ajjanagadde system detail 
want give flavour system showing example 
data base shastri ajjanagadde inference system contains prolog clauses owns gives owns buys sell owns gives carl josephine book buys carl owns josephine ball queried goals owns josephine book owns josephine queries expect answer second query expect set bindings variable answer shastri ajjanagadde system generate answers conditions satisfied 
ffl constants variables terms 
ffl body rule contains variables terms ffl body rule variable occurs variable bound thr rule called 
ffl derivation rule instantiated 
set program clauses shastri ajjanagadde generate structured connectionist network shown josephine example 
predicate symbol occurring rule represented units argument units fl argument 
units interconnected shown 

connections unit owns unit sell second argument unit sell second argument unit owns respectively represent rule sell owns 
constant occurring program represented constant unit fl 
josephine example find constant units book john ball josephine 
facts represented units 
units interconnected units representing rules constants shown 
example consider fact owns josephine ball 
connection unit owns unit fact unit unit owns furthermore connections second argument owns modify connection unit owns unit 
connections modified connections constant units josephine ball respectively 
variable binding problem solved shastri ajjanagadde introducing phases 
unit may activated certain phase eventually produces output phase 
similarly modifiers phase sensitive 
words information encoded phases sent connections network 
query sell josephine book answered follows 

unique phase assigned constant query 

phases may assigned josephine book respectively 

constant units argument units predicate query clamped respective phases 

unit predicate query clamped phases 

activity propagated net 
argument units activated soon excited certain phase output phase 
fact units activated excited phases 
modifiers activated soon excited certain phase filter phase connection modify 

finite time unit predicate query activated query answered answered latest version system condition relaxed rule instantiated times fixed 
delta delta delta delta gives delta delta delta delta buys phi phi phi phi john josephine book john gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma psi gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma delta delta delta delta owns sell delta delta delta delta phi phi josephine john ball book connectionist network josephine example 
shows various activation patterns units josephine network assume units synchronously updated 
john gave josephine book owns book sell book 
observe unit gives receives uninterrupted input second third argument gives activ 
activation spread units blocked activation josephine book constant units respectively 
hand unit owns activated 
unit owns send activation unit second phase filtered modifier receives activation second argument owns unit receive input remains passive 
book john ball josephine sell sell sell st arg sell nd arg owns owns owns st arg owns nd arg owns gives gives gives st arg gives nd arg gives nd arg gives buys buys buys st arg buys nd arg buys propagation phases josephine network answer query josephine sell book 
argument predicate bound certain constant unit representing argument activated phase unit representing constant activated 

argument sell bound josephine binding propagated argument owns second argument buys gives respectively 
answer derived time proportional depth search space activation unit sell travel unit gives back unit sell worst case result 
ask josephine sell ball activation unit sell travel unit owns back unit sell answer derived steps example 
number units connections bound size knowledge base linear size knowledge base 
network shown extended slightly order compute answer allow fixed number rules allow multiple literals body rule update network asynchronously built taxonomy 
details shastri ajjanagadde 
ajjanagadde shows inference system extended handle function symbols 
lange dyer robin differs shastri ajjanagadde inference system signatures phases encode variable bindings 
units standard units sense 
feldman ballard signatures sent connections network 
propagation information connections neural network necessarily violate condition artificial neural networks biologically plausible 
certain evidence limited amount information propagated natural neural network cf churchland miller shastri ajjanagadde 
inference systems section means long number different constant occurring initial query restricted propagation information conform findings animal human brain 
logical point view restrictions imposed formulae shastri ajjanagadde lange dyer quite severe 
essentially unify terms propagate constants network function symbols usually allowed conditions rule may contain variables terms hand answers computed extremely fast size network linear knowledge base 
trading expressiveness time size 
overcome limitations inference systems subsection developed 
connectionist inference system orn bibel connection method inferences holldobler holldobler 
connectionist inference system handle arbitrary order terms 
system built connectionist unification algorithm order terms holldobler 
know bibel stickel proof formula identify spanning complementary set connections connection consists positive negative literal having predicate symbol 
informally spanning conditions ensure connections set form complete proof formula propositional level obtained omitting arguments predicates 
spanning set complementary iff connected literals simultaneously unifiable 
search space reduced help reduction techniques typically applied linearly time space 
reduces formula generates spanning sets simultaneously unifies connected literals set 
connectionist system sense feldman ballard note connection sense bibel stickel pair literals logical formula connection neural network link units 
formula represented artificial neural network un satisfiability formula determined spreading activation network 
details see holldobler book 
related systems neural net implementation performs reasoning core aspects johnson laird mental model theory johnson laird bara 
theory states inference 
chemists 
chemists 
way 
mental models constructed conform premises 
tried read mental model 
mental model data structure consisting tokens identity links tokens 
example tokens chemists 
links proper non empty set athlete tokens tokens subset indicates links tokens chemist tokens 
chemists indicated fact chains links athlete tokens chemist tokens 
system introduced constructs mental models symbolic data structures encode syllogism premises represents configuration matrix 
matrix consists registers register associated symbol vector binary flags 
symbols denote example classes chemists individuals classes situations overlapping classes 
flags denote relationships neighboring registers example member relationship register representing individual register representing class 
uses production rules manipulate configuration matrix 
production rule consists condition part tests presence absence sorts state configuration configuration matrix 
action part production rule changes symbols flags configuration matrix 
applying production rules inferences syllogism deducted premises 
points neural net implementation register machine 
network consists subnetwork register subnetworks neighboring registers connected 
subnetwork connected called parallel distributor receives command signals nodes corresponding rule action parts 
summarize represents johnson laird mental models straightforward way performs inferences representations models 
system able maintain limited forms variable bindings example bindings ones involved rule loves loves aspects johnson laird approach addressed 
understanding generation natural language 
thorough attempted falsification process 
negative premises 
frequency modulation neural network extension current neural models 
heterogeneous network consists various neuron ensembles capable oscillating pulses 
information represented propagated frequency modulation superposition pulses 
variable binding problem solved specifying oscillation originated 
structures built modulating oscillations top received frequencies 
supports massively parallel models structured marker developed field model human cognitive activities 
evidential reasoning knowledge represented terms concepts properties hierarchical relationship concepts cf quillian 
hierarchy concepts property values usually inherited higher concepts rule thumb specified 
large hierarchy concept potentially conflicting property values obvious property values certain concept may 
vice versa certain property values unknown concept know concept best matches property values 
problems referred inheritance classification problem 
thesis shastri showed inheritance classification problem solved selecting set hypothesis viz 
evidence gathered 
operationally hypothesis computed maximizing entropy system 
example suppose rational agent seen fruit basket apples knows apples red green apples sweet 
agent picks apple property values apple 
specifically best estimate number red sweet apples 
scenario possible models micro configurations red sweet apple possible micro configurations red sweet apples 
micro configurations plausible ones rational agent assume macro configuration apple red sweet macro configuration apples red sweet supported micro configurations 
shastri demonstrates solutions inheritance classification problems solved structured connectionist setting 
emphasis obtain largest class problems solved devised limited inference system number units order size knowledge base time needed find solution bound depth search space 
strategy learning far considered purely connectionist approaches 
connectionist techniques may supplement traditional ai systems order overcome weaknesses 
theorem proving task usually divided logic problem control needed find proof kowalski 
comparatively easy specify problem logical formula difficult specify control knowledge kind knowledge domain dependent 
automated theorem provers logic programming systems programmer provide rudimentary control knowledge applications insufficient finding short proofs 
ultsch applied connectionist learning techniques order learn control strategies automated theorem provers 
considered order theorem prover setheo letz considered logic programming language prolog 
cases multi layer feedforward network trained backpropagation order select inference step alternative may lead shortest proof 
alternatives classified static dynamic features number distinct variables occurring part clause total number uses clause current derivation 
training examples provided optimal proofs obtained setheo prolog computing possible proofs selecting shortest ones 
results obtained far encouraging training resulted significant speed setheo prolog overhead applying learned strategies tolerable 
outlook article discussed number connectionist inference systems tried classify 
systems attempts explore techniques methods developed field artificial neural networks successfully merged results obtained field automated reasoning 
systems perform operations encoded simple symbol manipulations traditional ai 
number advantages easily obtained traditional ai systems 
ffl connectionist systems potentially fast exploit massive parallelism inherent reasoning 
limited inference systems ones section compute answer query time depth search space 
ffl kind natural operation connectionist systems may gather evidence order best decision 
example shastri shown certain classes inheritance classification problems solved connectionist setting maximizing entropy problem 
ffl connectionist systems potentially robust 
noise damage certain degree render massively parallel system useless performance systems degrade gracefully 
distributed production system section exhibits properties coarse coding technique represent objects 
ffl general powerful learning algorithms large classes massively parallel systems 
connectionist models may recognize patterns similarities generalize past experience 
experiments ultsch section show connectionist learning algorithms successfully applied obtain powerful heuristics guiding search inference systems 
ffl connectionist systems may base decisions context may combine multiple cues 
example non monotonic reasoning system section may revise decisions context changes 
ffl connectionist systems may give immediate responses required may second thoughts yield better time 
non monotonic reasoning system section example 
ffl connectionist models plausible biological point view traditional ai systems 
methods techniques applied artificial neural networks findings real neural networks 
research artificial neural networks concentrated high level cognitive functions perception speech performed humans 
reasoning typical human capability believe parts captured reasoning system findings areas importance field automated reasoning vice versa 
connectionist systems may serve vehicle stimulate research bringing people areas cognition psychology biology artificial intelligence 
connectionist models inference developed far quite simple single model exhibits certain desired property 
surprising field just emerge 
variety fundamental research problems 
general problems learning problem techniques backpropagation rumelhart reinforcement learning barto recruitment learning feldman diederich solved interesting problem failed far demonstrate complex structures needed representing formulas learned 
failed show complex structures rules learned instantaneously capability humans typically hadley 
scaling problem connectionist models far fairly small 
hopfield tank attempted solution travelling salesman problem takes cities account scaling solution major problem wilson 
merging problem article seen solution various parts deductive system 
example holldobler specified connectionist unification algorithm kernel inference system 
strategy investigating search space fixed demonstrate heuristics automatically 
representation formulas localist holldobler touretzky hinton distribute formulas widely 
desired effects units best match algorithm replaces perfect match unification algorithm performance system degrades gracefully constants allow function symbols occurrences numbers variables fairly limited distributed representation artificial guided semantic considerations 
point probably overcome apply techniques developed jordan elman 
merge various parts single system retaining benevolent properties single system 
research problems taken mcclelland deals connectionist models general framework cognitive science 
plausibility problem certain massively parallel model biologically plausible violate established knowledge 
methodology problem massive parallel systems lack design methodology 
connectionist counterparts classical concepts recursion iteration data structures 
representation problems form problem shall information represented locally distributed 
shall represented symbolically sub symbolically 
problem representing relational knowledge system represent propositions john loves mary john hates sue fred loves sue fred hates mary system retrieve appropriate completion proposition constituents 
problem equivalent xor problem minsky papert solved pairwise connections units representing john fred loves hates sue mary trivial solution assigning unit possible triple 
number units needed solution grows exponentially number constituents 
cross talk problem soon coarse coded representation chosen cross talk problem may arise 
ghosts objects explicitely stored may appear result superimposing various representations 
problem specifying domain adequately domain specific modelling reduces number units connections massively parallel model cf cooper swain 
important properties domain 
binding problem shall bind variables objects connectionist setting 
possible binding represented locally ensemble units exponential number units required 
restrict number units significantly distributed representation run cross talk problem 
control problem connectionist systems generally autonomous 
input clamped unit computes locally independently system generates output activating certain units going minimal energy state 
inherent problems variable binding problem cross talk problem require consider unrealistic number units focus attention certain parts network parts ignored 
controlling search space deductive systems requires attention problem hand vast experience 
article started authors stayed international computer science institute icsi usa 
jerry feldman staff icsi providing stimulating environment 
franz christian 
johnston johnston 
discrete stochastic neural network algorithm constraint satisfaction problems 
proceedings international joint conference neural networks 
ajjanagadde ajjanagadde 
reasoning function symbols connectionist system 
proceedings annual conference cognitive science society 
anandan anandan letovsky mjolsness 
connectionist optimization 
proceedings annual conference cognitive science society pages 
ballard ballard 
parallel logic inference energy minimization 
proceedings aaai national conference artificial intelligence pages 
ballard ballard 
parallel logic inference energy minimization 
technical report tr computer science department univ rochester rochester ny 

short term information processing connectionist theories 
cognition brain theory 

neural net implementation complex symbol processing mental model approach reasoning 
proceedings international joint conference artificial intelligence pages 
barto barto sutton anderson 
neuronlike adaptive elements solve difficult learning control problems 
ieee transactions systems man cybernetics pages 
bibel bibel 
automated theorem proving 
vieweg verlag braunschweig second edition 
bibel bibel 
perspectives automated deduction 
boyer editor automated reasoning essays honor woody bledsoe pages 
kluwer academic utrecht 
brachman schmolze brachman schmolze 
overview knowledge representation system 
cognitive science 
brandt brandt wang mitra 
alternative networks solving travelling salesman problem 
ieee international conference neural networks pages vol 
ii 
brewka brewka 
preferred subtheories extended logical framework default reasoning 
proceedings international joint conference artificial intelligence pages 
chang lee chang lee 
symbolic logic mechanical theorem proving 
academic press new york 
churchland churchland 
unified science mind brain 
mit press cambridge ma 
cooper swain cooper swain 
parallelism domain dependence constraint satisfaction 
technical report computer science department univ rochester 
cooper cooper 
parallel object recognition structure project 
technical report tr university rochester computer science department 
davis davis 
diagnostic reasoning structure behavior 
artificial intelligence 
williams williams 
diagnosing multiple faults 
proceedings aaai national conference artificial intelligence pages 

mundane reasoning settling plausible model 
artificial intelligence 
diederich diederich 
connectionist recruitment learning 
proceedings european conference artificial intelligence pages 
dolan smolensky dolan smolensky 
implementing connectionist production system tensor products 
touretzky hinton sejnowski editors proceedings connectionist models summer school pages 
morgan kaufmann 
elman elman 
structured representations connectionist models 
proceedings annual conference cognitive science society pages 
feldman ballard feldman ballard 
connectionist models properties 
cognitive science 
feldman feldman 
dynamic connections neural networks 
biological cybernetics 
geffner pearl geffner pearl 
improved constraint propagation algorithm diagnosis 
proceedings international joint conference artificial intelligence pages 
geman geman geman geman 
stochastic relaxation gibbs distribution bayesian restoration images 
ieee transactions pattern analysis machine intelligence 

connectionist networks constraint satisfaction 
proceedings ismm international conference parallel distributed computing systems pages 
hadley hadley 
connectionism rule symbolic manipulation 
proceedings aaai national conference artificial intelligence pages 
hertz hertz krogh palmer 
theory neural computation 
addison wesley publishing 
hertzberg hertzberg 
transforming constraint relaxation networks boltzmann machines 
proceedings german workshop artificial intelligence pages 
springer 
hinton sejnowski hinton sejnowski 
optimal perceptual inference 
proceedings ieee conference computer vision recognition pages 
holldobler holldobler 
spatial reasoning connectionist inference system 
etal 
editor massive und pages 
th darmstadt aida 
holldobler holldobler 
connectionist inference system horn logic connection method limited resources 
technical report tr international computer science institute berkeley ca 
holldobler holldobler 
structured connectionist unification algorithm 
proceedings aaai national conference artificial intelligence pages 
holldobler holldobler 
connectionist inference system 
cercone valle editors computational intelligence iii pages 
north holland 
hopfield tank hopfield tank 
neural computation decisions optimization problems 
biological cybernetics 
hopfield hopfield 
neural networks physical systems emergent collective computational abilities 
proceedings national academy sciences usa pages 
jaffar lassez jaffar 
lassez 
constraint logic programming 
proceedings acm symposium principles programming languages pages 
johnson laird bara johnson laird bara 
inference 
cognition 
jordan jordan 
attractor dynamics parallelism connectionist sequential machine 
proceedings annual conference cognitive science society pages 

problem solving hopfield neural nets 
biological cybernetics 
kasif kasif 
parallel complexity discrete relaxation constraint satisfaction networks 
artificial intelligence 
kirkpatrick kirkpatrick gelatt jr vecchi 
optimization simulated annealing 
science 
kleer de kleer 
comparison atms csp techniques 
proceedings international joint conference artificial intelligence pages 
kowalski kowalski 
algorithm logic control 
communications acm 
lange dyer lange dyer 
frame selection connectionist model high level inferencing 
proceedings annual conference cognitive science society pages 
lange dyer lange dyer 
high level inferencing connectionist network 
connection science 
lenat lenat guha pittman pratt shepard 
cyc programming common sense 
communications acm 
letz letz schumann bibel 
setheo high performance theorem prover 
journal automated reasoning 
mackworth mackworth 
consistency networks relations 
artificial intelligence 
mackworth mackworth 
constraint satisfaction 
shapiro editor encyclopedia artificial intelligence pages 
john wiley sons 
mcclelland rumelhart mcclelland rumelhart 
interactive activation model effect context perception part 
psychological review 
mcclelland mcclelland feldman bower mcdermott 
connectionist models cognitive science goals directions implications 
mcculloch pitts mcculloch pitts 
logical calculus ideas nervous activity 
bulletin mathematical biophysics 
miller miller 
magical number plus minus limits capacity processing information 
psychological review 
minsky papert minsky papert 
perceptrons 
mit press 
minton minton johnston philips laird 
solving largescale constraint satisfaction scheduling problems heuristic repair method 
proceedings aaai national conference artificial intelligence pages 
mjolsness mjolsness anandan 
optimization model matching perceptual organization 
neural computation 
mozer mozer 
perception multiple objects parallel distributed approach 
phd thesis university california san diego 
pinkas pinkas 
equivalence energy minimization propositional calculus satisfiability 
technical report wucs washington university 
pinkas pinkas 
propositional non monotonic reasoning inconsistency symmetrical neural networks 
proceedings international joint conference artificial intelligence pages 
pinkas pinkas 
symmetric neural networks logic satisfiability 
neural computation 
posner posner 
explorations mind 
lawrence erlbaum associates 
quillian quillian 
semantic memory 
minsky editor semantic information processing pages 
mit press 
rumelhart zipser rumelhart zipser 
feature discovery competitive learning 
cognitive science 
rumelhart rumelhart hinton williams 
learning internal representations error propagation 
rumelhart 
rumelhart rumelhart mcclelland pdp research group 
parallel distributed processing 
mit press 
shastri ajjanagadde shastri ajjanagadde 
associations systematic reasoning connectionist representation rules variables dynamic bindings 
technical report ms cis department computer information science university pennsylvania philadelphia school engineering applied science pa 
shastri ajjanagadde shastri ajjanagadde 
optimally efficient limited inference system 
proceedings aaai national conference artificial intelligence pages 
shastri shastri 
connectionist approach knowledge representation limited inference 
cognitive science 
shastri shastri 
semantic networks evidential formalization connectionist realization 
research notes artificial intelligence 
pitman london 
shastri shastri 
connectionism knowledge representation effective reasoning 
brauer freksa editors proceedings international gi congress knowledgebased systems pages 
shastri shastri 
default reasoning semantic networks formalization recognition inheritance 
artificial intelligence 
smolensky smolensky 
proper treatment connectionism 
behavioral brain sciences 
smolensky smolensky 
tensor product variable binding representation symbolic structures connectionist systems 
artificial intelligence 
stallman sussman stallman sussman 
forward reasoning dependency directed backtracking system computer aided circuit analysis 
artificial intelligence 
stefik stefik 
planning constraints part 
artificial intelligence 
stickel stickel 
automated deduction 
bibel editors fundamentals artificial intelligence pages 
springer 

connectionist networks guiding search theorem prover 
journal neural networks research application 
kitano kitano 
pdp frequency modulation neural network architecture 
proceedings international joint conference artificial intelligence pages 
touretzky hinton touretzky hinton 
distributed connectionist production system 
cognitive science 
touretzky touretzky 
dynamic symbol structures connectionist network 
artificial intelligence 
ultsch ultsch hartmann weber 
connectionist represented control knowledge prolog 
neuro pages 
waltz waltz 
generating semantic descriptions drawings scenes shadows 
technical report ai tr massachusetts institute technology cambridge massachusetts 
wang tsang wang tsang 
solving constraint satisfaction problems neural networks 
department computer science university essex 
wilson wilson 
stability travelling salesman problem algorithm hopfield tank 
biological cybernetics 

