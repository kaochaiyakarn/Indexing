comparative study multiple objective metaheuristics bi objective set covering problem pareto memetic algorithm andrzej working ra september institute computing science university technology ul 
poland cs put poznan pl www cs put poznan pl andj describes comparative study multiple objective metaheuristics bi objective set covering problem 
representative methods genetic algorithms multiple start local search hybrid genetic algorithms simulated annealing evaluated computational experiment 
methods known literature 
introduces new hybrid genetic algorithm called pareto memetic algorithm 
results experiment indicate performance hybrid genetic algorithms algorithm able outperform methods instances 
furthermore results indicate performance multiple objective metaheuristics may differ radically methods single objective algorithm exactly problem specific operators 
keywords multiple objective optimization metaheuristics set covering problem 

years observe growing interest multiple objective metaheuristics 
goal methods generate single run set solutions approximating part nondominated set 
methods kind applied various computationally hard multiple objective problems combinatorial optimization problems nonlinear programming problems 
authors multiple objective metaheuristics claim methods may effectively solve large scale problems relatively low number comparative experiments particular involving multiple objective combinatorial optimization problems published literature 
compare multiple objective metaheuristics bi objective set covering problem 
methods known literature 
methods multiple objective genetic local search algorithm mogls proposed ishibuchi murata multiple objective genetic local search serafini multiple objective simulated annealing multiple objective simulated annealing proposed 
pareto simulated annealing psa proposed nondominated sorting genetic algorithm nsga controlled elitist non dominated sorting genetic algorithm strength pareto evolutionary algorithm spea simple multiple objective multiple start local search random weight vectors 
addition introduce new multiple objective metaheuristic called pareto memetic algorithm pma 
methods implemented library 
implementations shared significant fractions common code 
code methods experiment freely available www idss cs put poznan pl 
set covering problem np complete combinatorial optimization problem test single objective metaheuristics 
finds practical applications especially crew scheduling 
practice solutions set covering problem evaluated single objective 
example case crew scheduling may necessary take account cost quality 
objectives important case crew scheduling discussed 
organized way 
section basic definitions 
pareto memetic algorithm described third section 
fourth section methods experiment briefly characterized 
adaptation methods multiple objective set covering problem fifth section 
sixth section experiment design described 
approach evaluate quality obtained results seventh section 
eighth section results experiments discussed 
concluding remarks ninth section 

basic definitions general multiple objective optimization moo problem formulated maximize solution vector decision variables set feasible solutions 
variables discrete moo problem called multiple objective combinatorial optimization problem 
image solution objective space point 
point dominates vj zj zj solution dominates image dominates image 
solution pareto optimal efficient dominates point image pareto optimal solution called nondominated 
set pareto optimal solutions called pareto optimal set 
image pareto optimal set objective space called nondominated set pareto front 
approximation nondominated set set feasible points corresponding solutions set composed mutually nondominated points 
point composed best attainable objective function values called ideal point max lx 
range equalization factors ch 
defined way 
approximate range objective zi nondominated set objective function values multiplied range equalization factors called normalized objective function values 
weighted linear defined way zj 
weight vector aj vj 
weighted functions defined way max max point 
weight vector weighted scalarizing function global optimum minimum belonging set pareto optimal solutions 
note optimum unique optima may dominated objective component equal pareto optimal solution 
pareto optimal solution exists weighted scalarizing function global optimum minimum ch 

weight vectors meet conditions called normalized weight vectors 
minimization weighted scalarizing function corresponds min max problem 
problem transformed minimize xd 
bi objective set covering problem problem covering rows row column zero matrix ay subset columns minimizing cost type objectives 
defining xi column costs selected solution xi minimize 
xie 
objectives minimized problem easily transformed form problem pl changing signs objectives 
definition introduced remain valid 

pareto memetic algorithm hybrid genetic algorithms relatively new metaheuristics recombination operators local search generally local heuristics 
frequently names memetic algorithms genetic local search 
methods type perform combinatorial optimization problems travelling salesperson problem graph coloring problem quadratic assignment problem 
perform single objective set covering problem 
development multiple objective versions promising directions research 
pareto memetic algorithm introduced developed basis previously proposed multiple objective genetic local search mogls algorithm 
general scheme pma mogls may summarized algorithm 
algorithms differ way solutions drawn recombination 
case mogls relatively small temporary elite population te composed number solutions best current scalarizing function selected current set solutions 
solutions drawn recombination temporary elite population uniform probability 
way solutions recombined assured current scalarizing function 
process repeated iteration 
generate initial set solutions repeat draw random weight vector defining current scalarizing function select probabilistically previously generated solutions current scalarizing function recombine solutions apply local heuristic offspring stopping criterion met 
general scheme multiple objective genetic local search algorithm selection process mogls time consuming 
mogls originally applied multiple objective traveling salesperson problem opt local search 
case time needed selection recombined solutions meaningless respect local search time 
general mogls relatively simple fast heuristics see 
case solutions selection time significantly influences running time 
pma uses faster approach tournament selection select solutions recombination 
cs denote current set solutions 
iteration sample drawn random repetitions cs 
best solutions winners tournament selected recombination 
size set order obtain expected rank induced current scalarizing function recombined solutions similar case mogls 
current scalarizing function induces rank set cs best solution having rank 
simplicity assume solutions cs equal value case mogls expected rank recombined solutions obviously 
analyze expected rank case tournament selection 
consider solution having rank selected tournament 
better solutions icsi better solutions including 
probability best solution condition selected tournament equal probability drawing times solution better cs probability drawn tournament equal probability pa best solution tournament cs expected ra best solution tournament erl way may calculate expected ra second best solution 
case probability solution having ra selected second best solution bernoulli distribution equ expected ra second best solution er equal result expected recombined solutions er equ cs cs formula quite complicated tic ranges icsi er icsi er approximated formula gr csl tl pma expected rank recombined solutions parameter method size tournament sample set way csl irl er general low values er result high selection pressure may cause premature convergence 
algorithm pma summarized 
set potentially pareto optimal solutions pp outcome method approximation nondominated set 
empty updated new solution generated local heuristic 
updating set potentially pareto optimal solutions solution consists adding pp point pp dominates removing pp points dominated 
experiment weighted scalarizing functions pma hybrid genetic algorithms 
scalarizing functions point set potentially pareto optimal solutions defined way note case signs objectives changed see section zj pp max max min 
set cs organized queue size number initial solutions parameter method typically equal er value assuring compatibility approach mogls 
new solutions added queue 
size queue bigger solution queue removed 
experiment value er allowed store generated solution cs algorithm run 
parameters er expected rank recombined solutions number initial solutions parameter condition stopping criterion initialization set potentially pareto optimal solutions pp current set solutions cs generation approximation ideal point objective construct new feasible solution randomized algorithm apply local heuristic optimizing objective solution obtaining add current set solutions cs update set pp generation initial set solutions repeat draw random weight vector construct new feasible solution randomized algorithm apply local heuristic optimizing 
solution obtaining add current set solutions cs update set pp initial solutions generated condition fulfilled main loop repeat draw random weight vector cs draw random uniform probability sample csl er solutions recombine best second best solution 
obtaining apply local heuristic optimizing 
solution obtaining better 
second best solution add current set solutions cs update set pp stopping criterion met 
algorithm pareto memetic algorithm 

stands pp 
version experiment initial solutions generated local optimization randomly selected scalarizing functions 
number initial solutions additional parameter method 
approach allows automatically stopping generation initial solutions 
single objective hybrid genetic algorithms start generation number solution local optimization 
multiple objective case propose generating initial solutions average quality best solutions set initial solutions scalarizing functions average quality solutions generated local heuristic optimization functions 
precisely generation initial solutions stopped condition met minimization scalarizing function assumed initial solution obtained local optimization scalarizing function sx note need best solution set cs solutions obtained local optimization functions may better cs cs set solutions function different sj cs sj average value cs sj cs sx cs sx order draw random weight vector algorithm 
algorithm uniformly samples set normalized weight vectors 
note changing algorithm drawing weight vectors concentrate method subregion nondominated set 
real life applications ranges objectives usually differ lot levels magnitude 
normalized weight vectors applied normalized objective values see section 
range equalization factors updated line ranges particular objectives set potentially pareto optimal solutions 

algorithm generating random normalized weight vectors 
function rand returns random value range uniform probability 
methods tested experiment limited space basic information algorithms tested experiment 
details may literature 
mentioned previous section pma normalizes objective values range equalization factors calculated line ranges particular objectives set potentially pareto optimal solutions 
descriptions algorithms refer issue objective values normalization algorithms scalarizing functions distance measures objective space 

hybrid genetic algorithms hybrid genetic algorithms tested experiment 
pareto memetic algorithm pma described section 
multiple objective genetic local search algorithm mogls briefly described section 
ishibuchi murata multiple objective genetic local search multiple objective hybrid genetic algorithm described literature 
mentioned section general scheme pma mogls 
method stores relatively small number solutions standard genetic population 
new population replaces old elite solutions preserved 
solutions selected recombination roulette wheel scheme fitness depending current scalarizing function 
results pressure recombination solutions current scalarizing function general solutions recombined worse function case mogls pma 

multiple objective multiple start local search method corresponds generation initial set solutions phase pma hybrid genetic algorithms 
method repeatedly draws scalarizing function uses local heuristic optimize function starting random solution 

simulated annealing algorithms multiple objective version simulated annealing proposed serafini 
method called serafini multiple objective simulated annealing 
algorithm method algorithm single objective sa 
method uses single current solution 
serafini considered number multiple objective rules acceptance new solutions 
experiment new neighborhood solution accepted acceptance rule may interpreted local weighted linear scalarizing function 
iteration weight vector acceptance rule modified randomly 
weight allowed change 
proposed method called multiple objective simulated annealing 
method uses number generating solutions exploring different regions nondominated set 
solutions predefined weight vector associated 
weight vectors change run method 
acceptance rule new solutions case 
pareto simulated annealing psa uses sample generating solutions 
weight vectors associated generating solutions modified iteration order induce repulsion mechanism assuring dispersion solutions regions nondominated set 
method uses acceptance rule algorithms 
summarizing simulated annealing algorithms locally scalarizing functions acceptance rules different weight vectors predefined updated run algorithm order assure dispersion search regions nondominated set 

genetic algorithms nondominated sorting genetic algorithm nsga relatively simple pareto ranking multiple objective ga scheme similar single objective ga generations replacements 
difference fitness assignment ranking induced dominance relation 
iteration nsga assigns rank solutions nondominated current population 
nondominated solutions temporarily removed population rank assigned solutions nondominated remaining part population 
process continued solutions population ranked 
method uses fitness sharing order avoid convergence solutions small region nondominated set caused genetic drift 
controlled elitist non dominated sorting genetic algorithm modification nsga preserves solutions current population 
order assure diversification population preserves solutions nondominated current population dominated solutions 
uses effective way rank assignment 
strength pareto evolutionary algorithm spea solutions current population set potentially pareto optimal solutions participate selection pareto ranking 
addition method uses new pareto niching method preserve diversity population 
original versions nsga external set potentially pareto optimal solutions outcomes methods final populations 
case set methods 
set updated newly generated solution 

adaptation methods multiple objective set covering problem metaheuristics solve single objective set covering problem 
various adaptations metaheuristics problem described example 
base adaptation multiple objective metaheuristics works 
note bi objective instances experiment adaptation may case general multiple objective set covering problem 
solutions encoding case solution encoded set columns set columns matrix see section 
course encoding equivalent binary representation binary variables genes see binary representation directly implementation 
generation initial solutions initial solutions constructed way similar proposed 
consider row 
starting randomly selected row 
covered column covers drawn random 
column covers row ai solutions obtained way may include redundant columns columns removed violating feasibility 
step redundant columns removed iteratively redundant column remains solution 
case methods scalarizing functions simulated annealing algorithms hybrid genetic algorithms iteration redundant column highest ratio scalarizing function value improvement caused removal column number non zero elements column removed 
case genetic algorithms iteration randomly selected redundant column removed 
neighborhood operator neighborhood operator guided scalarizing function 
randomly selected column removed solution 
result unfeasible solution obtained 
solution repaired greedy manner inserting columns lowest ratio scalarizing value decline caused insertion column number uncovered rows covered column column removed step considered greedy procedure neighborhood operator produces new solution 
local search local search guided scalarizing function 
steepest version local search neighborhood current solution tested best local move performed 
local search ends improving move may neighborhood current solution 
order test neighborhood removal column considered neighborhood operator 
recombination operator recombination operator produces single offspring recombined solutions parents 
operator idea distance preserving crossover preserves elements common parents 
place offspring columns included recombined solutions 
columns appear parents placed offspring probability 
general guarantees covering rows 
uncovered rows randomly selected columns 
rows selected mutation probability 
mutation consists drawing random column covering mutated row adding solution 
case genetic algorithms redundant columns removed random order 
case hybrid genetic algorithms local search assures removal redundant columns 

computational experiment design evaluation metaheuristics involve criteria quality obtained results running time 
way evaluate quality results described section 
order measure running time main approaches usually number generated solutions number function evaluations see cpu time see 
advantage cpu time takes account differences time needed generate new solutions different operators cpu time overload introduced method time needed selection solutions recombination 
cpu time highest practical importance running time measures 
disadvantage cpu time influenced computer programming language implementation style characteristics 
case able test methods computer implemented language library 
result lines code method shared methods 
decided cpu time measure experiment 
instances generated available www univ fr road html 
instances differ size characteristics 
instances rows columns 
sets instances 
case instances set costs generated randomly independently 
case instances set coefficients objective generated randomly coefficients second objectives set way cl case instances set columns divided subsets 
columns subset coefficients objectives 
set instances combines characteristics sets limited space report results results obtained representative instances 
results generated approximations available www idss cs put poznan pl 
table 
characteristics test instances instance number rows number columns set scp scp scp scp scp scp lb scp scp scp scp scp scp instance method run times 
method allowed run time 
instances differ significantly approach cpu time instances 
pma run times parameters described average running time pma stopping criterion methods 
parameters methods selected experimentally basis best choice principle 
tune parameters particular instances set parameters order obtain relatively performance instances 
number initial solutions set way hybrid genetic algorithms 
automatic approach described section 
number initial solutions obtained way deterministic usually characterized low dispersion decided number initial solutions runs 
condition tested number initial solutions runs pma mogls instance 
parameter set 
size temporary elite population mogls set 
case pma expected rank er set 
pma allowed perform times recombinations number initial solutions 
case size genetic population set equal number initial solutions elite size set equal population size 
multiple objective genetic algorithms populations size quite typical value methods 
neighborhood distance nsga set 
reduction rate set 
nondominated population size spea set clustering performed size population exceeded 
simulated annealing algorithms starting temperature set final temperature 
temperature plateau temperature multiplied 
result temperature plateaus obtained 
temperature plateau average running time pma allocated 
number generating solutions psa number predefined weight vectors set 
weights change coefficient psa set 

quality evaluation quality measure approximations nondominated set average best value weighted scalarizing function set systematically generated normalized weight vectors 
normalized weight vectors individual weight takes values kk sampling parameter 
set weight vectors denoted defined mathematically 
tp set normalized weight vectors 
measure calculated mian best value achieved function approximation experiment sampling parameter equal tot weight vectors 
case instances rows columns exact ideal points optimizing objective individually lingo premium ip solvers 
ideal points points quality measure 
case instances upper approximations ideal points obtained optimization individual objectives relaxed version 
relaxed version obtained allowing variables xi take continuous values range applying quality measure objective values normalized objective ranges observed individual optimization objectives range objectives objective equal difference best value optimization objective value objective optimization objective 
measure achieves best minimum value nondominated set 
best value may generating nondominated set able find optimum value weighted scalarizing function weight vector set requires solving problem 
mentioned solvers 
time requirements able find best values measure instances rows columns 
interesting observation instances sets difficult solvers instances sets average running time solvers times higher instances sets noticed instances sets contain fewer nondominated points cf 

case instances lower bounds quality measure solving relaxed version problem weight vector 
relaxed version obtained allowing variables xi take continuous values range 
results discussion table presents running times numbers solutions generated particular algorithms representative instances 
calculations run mhz pc 
note case count local optima count intermediate solutions generated local search numbers generated solutions naturally lower case algorithms 
case simulated annealing count accepted solutions 
results compare algorithms class 
results experiment representative instances table 
detailed numerical results instances available www idss cs put poznan pl 
chart corresponds different instance 
chart contains results representing distribution left right best possible value lower bound pma mogls spea nsga psa 
method average value standard deviation range 
chart scale best possible value lower bound bottom highest observed value top 
include results average results worse algorithms high standard deviations 
detailed analysis indicated runs gave results comparable results simulated annealing algorithm psa 
runs results enormously poor 
indicates single solution algorithm gets trapped poor regions solution space 
simulated annealing algorithms vulnerable situations due generating solutions 
results indicate instances sets difficult multiple objective metaheuristics see section 
general gap results metaheuristics best possible value lower bound higher case instances 
table 
numbers generated solutions running times test instances instance scp scp scp scp number initial solutions running time pma mogls number generated spea solutions nsga psa instance scp scp scp scp number initial solutions running time pma mogls number generated spea solutions nsga psa instance scp scp scp scp number initial solutions running time pma mogls number generated spea solutions nsga psa account results hybrid genetic algorithms especially pma mogls best performers experiment 
performance methods similar 
new faster selection mechanism introduced pma deteriorate quality respect mogls 
pma usually generates slightly solutions mogls case opposite situation observed 
pma uses faster selection mechanism expect pma able generate solutions mogls 
reduction selection time low influence running time case time spent local optimization 
advantage pma selection mechanism evident simpler faster heuristic 
performs worse pma mogls instances scp scp 
cases able generate fewer solutions pma mogls time 
opinion general worse solutions offspring local optima case pma 
results indicate selection solutions recombination crucial performance algorithms 
performs worse 
method able generate fewer solutions local search needs time achieve local optimum started initial solution 
results show hybridization recombination operator local search beneficial case 
performance psa similar significantly depends instance size 
methods gave best results scp scp instances performed poorly scp scp instances 
probably due difficulty finding parameters appropriate instances 
expect performance smaller instances significantly improved parameters especially starting final temperature tuned instance 
psa capable giving high quality results robust 
note normalized objective values phenomenon explained different ranges objectives different instances 
accepted time solutions psa psa cases accepted solutions 
psa modify weights scalarizing function iteration 
furthermore greater changes weights single iteration 
excluding multiple objective genetic algorithms worst performers experiment 
scp scp instances gives results comparable pma mogls 
cases gas give worst results 
addition dispersion quality results higher case methods 
simplest algorithm nsga gives worst results gas 
extensions basic idea pareto ranking resulted improved performance newer algorithms new algorithm competitive multiple objective metaheuristics 
furthermore may note spea performs relatively instances sets performs better instances sets note puts emphasis diversification see section apparently pays difficult instances 
cases spea generates highest number solutions gas 
table 
average values standard deviation quality results instance scp scp lb scp scp pma mogls spea nsga psa best possible value instance scp scp lb scp scp pma mogls spea nsga psa lower bound instance scp scp lb scp scp pma mogls spea nsga psa lower bound 

ll ll scp scp 
scp 
scp ii ii ill ii scp scp lb scp scp la ii ii iiii ii scp scp scp scp 
results experiment graphical form figures exemplary approximations different instances generated run algorithm 
include approximations order preserve clarity figures 
points referred exact obtained local optimization weighted scalarizing functions ip solvers see section 
note points may dominated see section apparently happens cases 
points referred relaxed points obtained local optimization weighted scalarizing functions relaxed version continuous variables 
may note large gap relaxed points approximations case scp instance 
clear gap mainly due poor performance metaheuristics instance due gap pareto fronts original relaxed problems 
noted case instance solutions relaxed problem contain fractional values 
possible solutions far feasible solutions binary values 
exact pma psa ix 
exemplary approximations obtained scp instance exact pma psa 
exemplary approximations obtained scp instance xx xx 
exemplary approximations obtained scp instance 
relaxed pma psa ce nsga 

exemplary approximations obtained scp instance 
multiple objective metaheuristics compared bi objective set covering problem 
main experiment instances repeating values objectives coefficients difficult ip solvers metaheuristics pma mogls best performers experiment able outperform methods instances 
comparison pma mogls indicates recombination operator recombination solutions crucial performance algorithms psa capable giving high quality results sensitive parameters setting single generating solution results high dispersion quality results pareto ranking genetic algorithms perform general worse algorithms new mechanisms introduced spea improve results basic pareto ranking evaluation mechanism nsga performs relatively small difficult instances repeating values objectives coefficients 
furthermore results indicate performance multiple objective metaheuristics may differ radically methods single objective algorithm exactly problem specific operators 
elements methods specific multiple objective case substantial influence performance 
consider advanced adaptations metaheuristics set covering problem account effective approaches proposed single objective case 
plan extend experiments instances objectives include multiple objective metaheuristics methods tabu search pareto ranking memetic algorithms 

chu 
genetic algorithm set covering problem 
european journal operational research 
ak 
pareto simulated annealing metaheuristic technique multiple objective combinatorial optimisation journal multi criteria decision analysis 
deb goel 
controlled elitist non dominated sorting genetic algorithms better convergence zitzler deb thiele coello coello corne eds 
proceedings international conference evolutionary multi criterion optimization lecture notes computer science springer berlin 

genetic algorithm non binary representation set problem proc 
operations research 
springer verlag 
fr ville 
tabu search procedure solving multiobjective knapsack problem objectives case journal heuristics 
garey johnson 
computers intractability guide theory completeness freeman san francisco 
hao 
hybrid evolutionary algorithms graph coloring 
journal combinatorial optimization 
hansen 
evaluating quality approximations nondominated set working institute mathematical modelling technical university denmark imm rep 
com www com www idss cs put poznan pl ishibuchi murata 
multi objective genetic local search algorithm application scheduling ieee transactions systems man cybernetics part 
applications reviews 

comparison local search metaheuristics multiple objective knapsack problem foundations computing decision sciences 

performance multiple objective evolutionary algorithms distribution system design problem computational experiment zitzler deb thiele coello coello corne eds 
evolutionary multi criterion optimization lecture notes computer science springer berlin 

multiple objective metaheuristic algorithms combinatorial optimization habilitation thesis poznan university technology poznan 

appear 
genetic local search multiple objective combinatorial optimization european journal operational research 

appear 
performance multiple objective genetic local search knapsack problem 
comparative experiment ieee transactions evolutionary computation 
knowles corne 
paes memetic algorithm multiobjective optimization congress evolutionary computation volume piscataway new jersey ieee service center 
kwan kwan wren 
driver scheduling genetic algorithms embedded combinatorial traits wilson 
ed computer aided transit scheduling springer verlag 
portugal 
crew scheduling module gist system working departament universitat pompeu fabra portugal 
marchiori 
evolutionary algorithm large scale set covering problems application airline crew scheduling real world applications evolutionary computing 
springer verlag lecture notes computer science 
merz freisleben 
genetic local search tsp new results proceedings ieee international conference evolutionary computation ieee press 
serafini 
simulated annealing multiple objective optimization problems proceedings tenth international conference multiple criteria decision making taipei vol 

smith wren bus crew scheduling system set covering formulation transportation research 
srinivas deb 
multiple objective optimization nondominated sorting genetic algorithms evolutionary computation 
steuer 
multiple criteria optimization theory computation application wiley new york 
taillard 
comparison iterative searches quadratic assignment problem location science 
ph 
method tool solving multiobjective combinatorial optimization problems journal multi criteria decision analysis 
van veldhuizen 
multiobjective evolutionary algorithms classifications analyses new innovations phd thesis department electrical computer engineering graduate school engineering 
air force institute technology wright patterson afb ohio 
zitzler thiele 
multiobjective evolutionary algorithms comparative case study strength pareto evolutionary algorithm ieee transactions evolutionary computation 

