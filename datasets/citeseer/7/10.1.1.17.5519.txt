touretzky mozer hasselmo eds advances neural information processing systems 
mit press cambridge ma 
improving elevator performance reinforcement learning robert crites computer science department university massachusetts amherst ma crites cs umass edu andrew barto computer science department university massachusetts amherst ma barto cs umass edu describes application reinforcement learning rl difficult real world problem elevator dispatching 
elevator domain poses combination challenges seen rl research date 
elevator systems operate continuous state spaces continuous time discrete event dynamic systems 
states fully observable nonstationary due changing passenger arrival rates 
addition team rl agents responsible controlling elevator car 
team receives global reinforcement signal appears noisy agent due effects actions agents random nature arrivals incomplete observation state 
spite complications show results simulation surpass best heuristic elevator control algorithms aware 
results demonstrate power rl large scale stochastic dynamic optimization problem practical utility 
algorithmic theoretical advances reinforcement learning rl attracted widespread interest 
rl algorithms appeared approximate dynamic programming dp incremental basis 
traditional dp algorithms algorithms perform models system online offline focusing computation areas state space visited actual control 
large problems provide computationally tractable ways approximating dp 
example tesauro td gammon system tesauro rl techniques learn play strong masters level backgammon 
best human experts poor teachers class problems know best actions 
state space large difficult experts provide sufficient training data 
rl algorithms naturally suited class problems learn basis experiences require teacher dictate best actions 
describes application rl elevator dispatching problem classical dp completely intractable 
elevator domain poses number difficulties backgammon 
spite complications show results surpass best heuristic elevator control algorithms aware 
sections describe elevator dispatching domain rl algorithm neural network architectures results 
elevator system particular elevator system examine simulated story building elevator cars lewis bao 
passenger arrivals floor assumed poisson arrival rates vary course day 
simulations traffic profile bao dictates arrival rates minute interval typical afternoon peak rush hour 
table shows mean number passengers arriving floor minute interval headed lobby 
addition inter floor traffic varies traffic lobby 
time rate table peak traffic profile system dynamics approximated parameters floor time time move floor maximum speed secs time time needed decelerate open close doors accelerate secs turn time time needed stopped car change direction sec load time time passenger enter exit car random variable th order truncated erlang distribution range secs mean sec car capacity passengers 
state space continuous includes elapsed times hall calls registered real valued 
real values approximated binary values size state space immense 
components include possible combinations hall call buttons buttons landing top bottom possible combinations car buttons possible combinations positions directions cars rounding nearest floor 
parts state fully observable example desired destinations passengers waiting floor 
ignoring configuration hall car call buttons approximate position direction cars obtain extremely conservative estimate size discrete approximation continuous state space states 
car small set primitive actions 
stopped floor move move 
motion floors floor continue past floor 
due passenger expectations constraints actions car pass floor passenger wants get turn serviced car buttons direction 
added additional action constraints attempt build primitive prior knowledge car floor wants get pick passengers floor car stopped choice moving prefer move peak traffic tends push cars bottom building 
constraint real choices left car continue actions 
actions elevator cars executed asynchronously may take different amounts time complete 
performance objectives elevator system defined ways 
possible objective minimize average wait time time arrival passenger entry car 
possible objective minimize average system time sum wait time travel time 
third possible objective minimize percentage passengers wait longer dissatisfaction threshold usually seconds 
common objective minimize sum squared wait times 
chose performance objective tends keep wait times low encouraging fair service 
algorithm network architecture elevator systems modeled discrete event systems significant events passenger arrivals occur discrete times amount time events real valued variable 
systems constant discount factor fl discrete time reinforcement learning algorithms inadequate 
problem approached variable discount factor depends amount time events bradtke duff 
case returns defined integrals infinite sums follows fl fi immediate cost discrete time instantaneous cost continuous time sum squared wait times waiting passengers fi controls rate exponential decay 
calculating reinforcements poses problem require knowledge waiting times waiting passengers 
ways dealing problem 
simulator knows long passenger waiting 
information determine called omniscient reinforcements 
possibility information available real system online 
online reinforcements assume waiting time passenger queue known elapsed button time 
poisson arrival rate queue estimated reciprocal inter button time queue gamma distribution estimate arrival times subsequent passengers 
time th subsequent arrival follows gamma distribution 
queue subsequent arrivals generate expected penalties seconds hall button pressed prob th arrival occurs time penalty arrival time 
fi dw fi dw integral solved parts yield expected penalties 
online reinforcements produced somewhat better results omniscient reinforcements presumably algorithm trying learn average values anyway 
elevator system events occur randomly continuous time branching factor effectively infinite complicates algorithms require explicit lookahead 
employed team discrete event learning agents agent responsible controlling elevator car 
application team learning agents described 
defined expected infinite discounted return obtained action state optimal policy watkins 
vast number states values stored feedforward neural networks 
networks receive state information input produce value estimates output 
tested architectures 
parallel architecture agents share single network allowing learn experiences forcing learn identical policies 
fully decentralized architecture agents networks allowing specialize control policies 
case agents explicit access actions agents 
cooperation learned indirectly global reinforcement signal 
agent faces added stochasticity nonstationarity environment contains learning agents 
algorithm calls car select actions probabilistically boltzmann distribution value estimates temperature lowered gradually training 
decision error backpropagation train car estimate target output fi fi min action taken car state time decision car required state time fi defined 
fi ty tx acts variable discount factor depends amount time events 
learning rate parameter set fi set experiments described 
considerable experimentation best results obtained networks pure traffic input units hidden sigmoid units linear output units action value 
input units follows ffl units units encode information hall buttons 
real valued unit encodes elapsed time button pushed binary unit button pushed 
ffl units units represents possible location direction car decision required 
exactly units time 
ffl units units represent floors cars may located 
car footprint depends direction speed 
example stopped car causes activation unit corresponding current floor moving car causes activation units corresponding floors approaching highest activations closest floors 
ffl unit unit car decision required highest floor waiting passenger 
ffl unit unit car decision required floor passenger waiting longest amount time 
ffl unit bias unit 
results optimal policy elevator dispatching problem unknown measured performance algorithm heuristic algorithms including best aware 
algorithms sector sector algorithm similar actual elevator systems dlb dynamic load balancing attempts equalize load cars huff highest unanswered floor gives priority highest floor people waiting longest queue gives priority queue person waiting longest amount time fim finite minimization receding horizon controller searches space admissible car assignments minimize load function esa empty system algorithm receding horizon controller searches fastest way empty system assuming new passenger arrivals 
esa uses queue length information available real elevator system 
esa nq version esa uses arrival rate information estimate queue lengths 
details see bao 
receding horizon controllers sophisticated computationally intensive difficult implement real time 
rlp rld denote rl controllers parallel decentralized 
rl controllers trained hours simulated elevator time took days mips workstation 
results averaged hours simulated elevator time 
table shows results traffic profile traffic 
algorithm percent secs sector dlb basic huff huff fim esa nq esa rlp rld table results peak profile traffic table shows results peak traffic profile traffic including average passengers minute lobby 
algorithm trained traffic generalizes traffic added upward moving cars forced upward hall calls 
algorithm percent secs sector dlb basic huff huff esa fim rlp rld table results peak profile traffic table shows results peak traffic profile traffic including average passengers minute lobby 
time twice traffic rl agents generalize extremely new situation 
algorithm percent secs sector huff dlb basic huff fim esa rld rlp table results peak profile twice traffic see rl systems achieved performance notably measured system time sum wait travel time measure directly minimized 
surprisingly decentralized rl system able achieve level performance parallel rl system 
better performance nonstationary traffic profiles may obtainable providing agents information current traffic context part input representation 
expect additional advantage rl heuristic controllers may buildings homogeneous arrival rates floor rl adapt individual traffic patterns 
results demonstrate utility rl large scale dynamic optimization problem 
focusing computation states visited simulated trajectories rl avoids need conventional dp algorithms exhaustively sweep state set 
storing information artificial neural networks avoids need maintain large lookup tables 
achieve results rl system experienced hours simulated elevator time took days computer time mips processor 
considerable amount computation negligible compared conventional dp algorithm require 
results suggest approaches decentralized control rl considerable promise 
research elevator dispatching problem investigate traffic profiles explore parallel decentralized rl architectures 
john christos gandhi dave kevin victor lesser rod grupen rich sutton steve bradtke group assistance simulator helpful discussions 
research supported air force office scientific research 
bao gandhi 
elevator dispatchers peak traffic 
technical report ece department university massachusetts amherst ma 
bradtke duff 
reinforcement learning methods continuous time markov decision problems 
tesauro touretzky leen eds advances neural information processing systems mit press cambridge ma 
lewis 
dynamic load balancing approach control polling systems applications elevator system dispatching 
phd thesis university massachusetts amherst ma 

efficient learning multiple degree freedom control problems quasi independent agents 
mozer smolensky touretzky elman weigend eds proceedings connectionist models summer school 
erlbaum associates hillsdale nj 
tesauro 
practical issues temporal difference learning 
machine learning 
tesauro 
td gammon self teaching backgammon program achieves master level play 
neural computation 
tesauro 
temporal difference learning td gammon 
communications acm 
watkins 
learning delayed rewards 
phd thesis cambridge university 
