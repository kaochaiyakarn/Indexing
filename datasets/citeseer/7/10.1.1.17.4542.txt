model feedback language modeling approach information retrieval zhai school computer science carnegie mellon university pittsburgh pa john lafferty school computer science carnegie mellon university pittsburgh pa language modeling approach retrieval shown perform empirically 
advantage new approach statistical foundations 
feedback important component retrieval system dealt heuristically new retrieval approach original query usually literally expanded adding ditional terms 
expansion feedback creates inconsistent interpretation original expanded query 
principled approach feedback language modeling approach 
specifically treat feedback updating query language model extra evidence carried feedback documents 
model feedback strategy easily fits extension language modeling approach 
propose evaluate different approaches updating query language model feedback documents generarive probabilistic model feedback documents minimization kl divergence feedback documents 
experiment show approaches effective outperform rocchio feedback approach 

language modeling approach text retrieval introduced ponte explored :10.1.1.43.7803:10.1.1.54.6410
relative simplicity effectiveness language modeling approach fact leverages statistical methods developed speech recognition areas attractive framework develop new text retrieval methodol ogy 
language modeling approach performed empirically significant amount performance increase due feedback :10.1.1.54.6410
unfortunately feedback far dealt heuristically language modeling approach 
existing incorporated unnatural way expanding query set terms 
expansion feedback strategy generally compatible essence language modeling approach model estimation 
result expanded query usually interpreted differently original query 
contrast natural way performing feedback classical relevance probabilistic model binary independence model 
propose model approach feedback incorporated kl divergence re trieval framework introduced 
model ap proach feedback new essence classical probabilistic model 
unclear incorporate model methods query likelihood ranking function existing language modeling approach 
propose different schemes query model set feedback documents 
generarive model 
assuming generarive model estimate query topic model observed feedback documents maximum likelihood regularized maximum likelihood criterion 
particular generarive model consider simple mixture model collection language model component query topic model 

divergence risk minimization feedback documents 
maximizing likelihood estimate query model minimizing average kl divergence tween model feedback documents 
section provide detailed account feedback techniques previous 
section introduces kl divergence framework text retrieval sections new modelbased frameworks incorporating feedback 
section presents results experiments carried evaluate methods 

previous feedback methods lm framework papers techniques improving language modeling techniques relevance pseudo relevance feedback 
ratio approach selects terms having high probability feedback documents low probability collection language model proposed :10.1.1.54.6410
approach performs similarly rocchio relevant documents significantly better rocchio relevant documents 
pseudo relevance feedback results promising significantly better results baseline language modeling approach :10.1.1.54.6410
ratio approach conceptually restricted view query set terms naturally applied general case query considered sequence terms frequency information query term considered 
number terms needs determined heuristically 
miller treat feedback essentially expanding original query terms feedback documents 
terms pooled bins number feedback documents occur bin different transition probability hmm heuristically estimated 
result smoothing longer equivalent simple linear interpolation basic hmm smoothing document language model 
model form changes result incorporating feedback 
interpretation query text generated hmm set terms conceptually inconsistent 
involves heuristic adjustment transition probabilities incorporating document frequency filter high frequency words 
approach developed document likelihood ratios interesting ideas concerning feedback explored 
feedback criterion optimization scores feedback documents developed turns similar ratio approach :10.1.1.54.6410
second threshold number selected terms derived score optimization cri 
approach reported effective shares problem inconsistent interpretation mentioned 
related feedback doc uments reestimate smoothing parameters query likelihood retrieval function 
effect similar query term reweighting traditional retrieval model fully take advantage feedback documents new terms introduced enhance query 
begun develop model approaches feedback appears promising area development 
approach feedback developed uses markov chains estimate query model 
translation model markov chain query expansion method applied set feedback documents regarded model approach query language model 
relevance model estimation method proposed es richer query model feedback documents 
approaches rely query words focus model 
methods proposed feedback documents estimate query model update existing query model 

kl divergence retrieval model general approach retrieval problem decomposed basic components query representation document representation matching query representation document representation 
kl divergence model components realized probabilistic way 
assume query document viewed observation probabilistic query document model 
representation problem equivalent model estimation 
second relevance value document respect query measured kullback leibler divergence query model document model 
matching problem equivalent measuring similarity distance estimated query model document model 
kl divergence retrieval model intro duced special case general risk minimization retrieval framework 
interestingly similar vector space model language models ordinary term vectors represent document query 
model formally 
probability mass functions kullback leibler divergence relative entropy denoted ii defined ii ep log easy show ii non negative zero distance distributions symmetric satisfy triangle inequality useful think kl divergence distance distributions 
assume query obtained sample generarive model ql parameters 
similarly assume document generated model parameters 
estimated query document language models respectively relevance value respect measured kl divergence function ep lq logp id cons document independent constant cons entropy query model dropped affect ranking documents ranking risk equivalent ranking cross entropy query language model respect document language model 
minimum value query model entropy achieved identical perfect sense retrieval 
popular query likelihood ranking function previous language modeling approach easily obtained special case kl divergence model query model estimated empirical distribution query 
kl divergence model appears similar probability distribution model proposed information theoretic retrieval strategy general flexible explicit modeling query documents 
multi nomial term distribution proposed primarily alter native representation documents query sense vector space model generarive model documents query 
surprising issue model estimation considered term distribution representation naturally assumed best approximated relative frequency terms 
model smoothing considered possibility 
kl divergence model retrieval problem essentially equivalent problem estimating principle language model query document 
flexibility model quite general allows model query document different ways 
example collection regarded document model distributed information retrieval 
interesting direction xu croft estimates topic model set ex ample documents uses kl divergence select topic models query 
approach relies estimation document query language models 
lack query model previous language modeling approach unnatural incorporate feedback important retrieval technique 
view query language model necessary step powerful retrieval methods language modeling 
assume user topic information need may modeled represented language model simplest case unigram model 
model expected generate text indicating user information need task estimate underlying model exploiting information know information need 
traditional setup major pieces information user may help infer model query judged relevant documents 
explore simple smoothing strategies combining relevant set query simplest linear interpolation 
specifically original query model esti mated feedback query model feedback documents dl documents judged relevant user top documents initial retrieval case pseudo relevance feedback 
new query model controls influence feedback model 
sections describe different strategies estimating feedback documents 

generative model feedback documents natural way estimate feedback query model assume feedback documents generated probabilistic model 
simplest generarive models unigram language model generates word independently 
ii iip di count word document di 
simple model reasonable feedback documents contain relevant information 
documents probably contain background information non relevant topics 
reasonable model mixture model generates feedback document mixing query topic model collection language model 
document generated picking word query topic model collection language model 
collection language model reasonable model irrelevant content feedback document 
simple mixture model log likelihood feed back documents logp di log ap note estimated maxi mum likelihood estimate zero mixture model reduce simple unigram model 
intuitively non zero indicating amount background noise generating document 
set constant estimate done em algorithm 
em updates px jn dj xn toi dj toi intuitively estimating query model trying purify document eliminating background noise 
estimated query model generally concentrated words common feedback document set common collec tion language model 

precisely effect traditional feedback methods rocchio try capture 
score document estimated query model interpolate original query model obtain updated query model compute kl divergence 
iq 
id smoothed empirical word distribution 
divergence minimization feedback documents different strategy estimating query model feedback documents minimize divergence tween model feedback documents 
dl dn set feedback documents 
define empirical kl divergence query model feedback documents ii average divergence smoothed empirical word distribution document ai 
intuitively estimate query model minimizing average divergence query model score documents give best average score feedback documents 
estimated query model close feedback document model feedback documents typically share common words due language domain characteristics query model may quite general 
way specializing model add regularization term divergence function 
preferring model incurs greater divergence respect collection model approximation language model topic background content 
incorporating condition empirical divergence function feedback query model yd id ic weighting parameter collection language model 
minimizing divergence equivalent maximizing entropy model preference constraint encoded second term 
similar maximum entropy approach estimation 
criterion estimate exp see resulting model assigns high probability words common feedback documents common collection language model 
controls weight collection language model 
collection mixture model set zero effect collection model completely ignored query model strictly minimizes divergence feedback documents 
case model geometric mean distributions feedback docu ments 
exploit kl divergence retrieval model st interpolate original query model obtain updated model score document ii 
experiments kl divergence retrieval framework allows combine pair document query language models experimentally possible combinations explore 
fix document language model focus different ways estimating query model feedback documents 
specifically dirichlet prior hyperparameter estimating document language models experiments 
effect interpolates maximum likelihood estimate document language model collection language model document dependent interpolation coefficient idl collection model 
approach described detail evaluated experimentally 
appropriate way evaluating feedback method consider relevance feedback pseudo blind feedback step consider pseudo feedback 
experiments take top documents set previously retrieved results obtained basic query likelihood ranking function dirichlet smoothing 
compare query models estimated collection mixture divergence minimization methods described previous sections varying interpolation parameter feedback model estimation parameters 
testing collections evaluation evaluated feedback approaches trec col ap topics 
collections labeled ap 
trec disk minus congressional record topics 
official trec ad hoc task collection labelled trec 
trec small web collection topics 
official trec small web task collection labelled web 
cases titles topic description closer actual queries real applications feedback expected useful short queries 
done minimal preprocessing documents queries tokenization performed stemming porter stemmer stopword list applied 
believe appropriate probabilistic modeling words effectively weighted 
run top documents returned evaluated commonly done trec evaluations 
performance measures considered evaluation interpolated precision different fixed recall levels pr curve initial precision best precision achievable document cutoff non interpolated average precision recall documents ap baseline mixture fb div min fb trec web baseline baseline mixture fb mixture fb div min fb effect feedback ap left trec middle web right 
plot feedback methods compared baseline simple language modeling approach feedback 
collection simple lm mixture fb improv 
div 
min 
improv 
ap recall trec recall web recall table comparison basic language modeling method model feedback methods 
column give performance mixture model divergence minimization respectively 
performance query set reported average corresponding performance figures individual queries called macro average average recall total number retrieved relevant documents queries divided total count relevant documents called micro average 
take average precision primary single summary performance experiment reflects ranking accuracy report measures 
effect feedback order see effect feedback compare feedback results baseline non feedback results 
general find appropriate parameter settings feedback techniques propose effective 
example best feedback results method compared baseline performance table 
average precision recall consistently improved performing feedback 
increase average precision larger cases 
note initial precision feedback results slightly decreased cases 
top documents may relevant surprising initial precision sensitive ranking particular document top goal improve ranking documents 
interesting improvement ap greater trec web 
true approaches true rocchio approach discussed suggesting feedback ap easier trec web homogeneity documents 
experiments analysis needed understand better 
table compare feedback results tuned rocchio approach tf idf weighting 
tf formula bm retrieval formula parameter settings 
fixed number documents feedback top varied main parameters rocchio coefficient number terms 
reported results best results obtained 
note rocchio baseline results strong compared published official trec web results especially considering title queries 
compared rocchio results model feedback methods perform better terms precision recall slightly worse rocchio 
suspect decrease recall may tuned number terms rocchio method tuned probability cutoff methods essentially controls number terms introduce feedback 
experiments collection rocchio fb mixture fb improv 
div 
min 
fb improv 
ap recall trec recall web recall table comparison rocchio feedback method model feedback methods 
column give performance mixture model divergence minimization respectively 
ap trec web mixture div min feedback mixture div min feedback mixture div min mixture divergence min 
mixture divergence min 
mixture divergence min 
sensitivity precision feedback model parameters ap left trec middle web right 
plot horizontal line non feedback performance lines correspond feedback methods respectively 
note axis means different different methods 
dataset interpolation coefficient set 
truncated estimated query model ignoring terms having probability 
reasonable expect recall improved lower probability cutoff 
note precision expected stay increase terms selected extra terms generally small probability great impact ranking documents high scores 
comparisons best feedback results 
important study feedback performance may affected choice parameters model 
look sensitivity parameter feedback method 
sensitivity performance feedback model parameter mixture model method parameter controls amount background noise feedback documents divergence minimization method parameter controls influence collection language model included geometric mean 
cases indicates extent estimated query model deviate collection language model 
play similar role conceptually find affect feedback performance different ways 
difference seen show average precision changes different values fixed value 
specifically see performance relatively insensitive setting mixture model method quite sensitive setting divergence minimization method 
mixture model performance generally baseline matter value set 
divergence minimization performance baseline small 
large performance extremely bad significantly worse baseline performance 
influence interpolation coefficient recall interpolate estimated feedback query model original maximum likelihood model estimated query text 
interpolation controlled coefficient original model feedback completely ignore original model estimated feedback model 
actual experiments truncated estimated feedback model ignoring terms probability lower renormalized interpolating 
shows average precision feedback varies value line represents sensitivity feedback precision ap mix ap div min web mix web div min trec mix trec div min influence value precision 
lines represent different feedback models different testing collections 
specific feedback model estimated mixture model divergence minimization method par ticular test collection 
note precision baseline non feedback performance precision performance resulting feedback model 
see setting affect performance significantly 
example ap feedback model better original query model optimal setting tends close 
hand trec web feedback model worse original query model interpolated original query model effective model 
means models complement 
original query model helps focus topic feedback model supplements suggesting related words 
precision mixture model method appears sensitive precision divergence minimization method especially web collection 
appears usually safe set value close smaller 
propose model methods performing feedback language modeling approach information retrieval 
contrast feedback methods existing 
advantage model approach maintains conceptual consistency interpreting query retrieval model explicitly treats feedback learning process 
methods proposed feedback documents estimate query model update original query model linear interpolation 
methods differ way estimate query model feedback documents 
method assumes feedback documents generated mixture model component query topic model collection language model 
observed feedback documents maximum likelihood criterion estimate query topic model 
second method uses completely different estimation criterion chosing query model smallest average kl divergence smoothed empirical word distribution feed back documents 
methods evaluated representative large retrieval collections 
results show methods effective feedback perform better rocchio method terms precision 
analysis results indicates performance sensitive settings interpolation coefficient parameter feedback method 
precision mixture model tends sensitive divergence minimization method 
hand precision relatively insensitive mixture model method sensitive divergence minimization method 
appears setting value close smaller cases 
smaller probably appropriate divergence minimization mixture model method set 
patterns observed feedback documents experiments reported feedback documents sensitivity pattern appears basically reported performance gain feedback usually 
obviously documents performance eventually decrease 
fact little control true relevant examples serious drawback experimenting pseudo feedback hard tell inferior feedback performance due poor technique just due errors noise feedback examples 
extreme case top documents non relevant bad initial ranking 
obviously expect feedback technique gain case 
important consideration test proposed feedback techniques relevance feedback able examine effectiveness learning closely 
related direction consider confidence assuming top documents relevant 
associate relevance probability feedback document estimated query model affected documents having higher relevance probability 

research sponsored full advanced research development activity information technology arda statistical language modeling information retrieval research program 

berger lafferty 
information retrieval statis tical translation 
proceedings acm sigir conference research development information retrieval pages 
cover thomas 
elements information theory 
wiley 
dempster laird rubin 
maximum likelihood incomplete data em algorithm 
journal royal statist 
soc 

hiemstra 
language models information re trieval 
phd thesis university twente 
hiemstra kraaij 
trec adhoc cross language track 
proc 
seventh text retrieval conference trec 
lafferty zhai 
document language models query models risk minimization information retrieval 
proceedings sigir sept 
lavrenko croft 
relevance language mod els 
proceedings sigir sept 
miller leek schwartz 
hidden markov model information retrieval system 
proceedings acm sigir conference research development information retrieval pages 
ng 
maximum likelihood ratio information retrieval model 
trec workshop notebook 
ponte :10.1.1.54.6410
language modeling approach information retrieval 
phd thesis univ massachusetts amherst 
ponte croft :10.1.1.54.6410
language modeling approach information retrieval 
proceedings cm sigir pages 
robertson sparck jones 
relevance weighting search terms 
journal american society information science 
robertson walker 
okapi trec 
voorhees harman editors eighth text retrieval conference trec 
nist special publi cation 
rocchio 
relevance feedback information retrieval 
smart retrieval system experiments automatic document processing pages 
prentice hall 
song croft 
general language model infor mation retrieval 
proceedings acm sigir conference research development information retrieval pages 
voorhees harman editors 
proceedings text retrieval conference trec 
nist special publications 
trec nist gov pubs html 
wong yao 
probability distribution model information retrieval 
information processing management 
xu croft 
cluster language models distributed retrieval 
proceedings sigir pages 
zhai lafferty 
study smoothing methods language models applied ad hoc information retrieval 
proceedings sigir sept 
