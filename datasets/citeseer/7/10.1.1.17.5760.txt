active support vector machine classification mangasarian computer sciences dept university wisconsin west dayton street madison wi cs 
wisc edu david dept mathematics computer science carleton college north college street mn carleton 
edu active set strategy applied dual simple reformulation standard quadratic program linear support vector machine 
application generates fast new dual algorithm consists solving finite number linear equations typically large dimensionality equal number points classified 
making novel sherman formula smaller matrix order original input space inverted step 
problem dimensional input space points required inverting positive definite symmetric matrices size total running time minutes mhz pentium ii 
algorithm requires specialized quadratic linear programming code merely linear equation solver publicly available 
support vector machines svms powerful tools data classifi cation 
classification achieved linear nonlinear separating surface input space dataset 
propose fast simple algorithm active set strategy solving quadratic programs bounds 
algorithm capable accurately solving problems millions points requires complicated commonly available linear equation solver typically small dimensional input space problem 
key approach changes standard linear svm 
maximize margin distance parallel separating planes respect orientation location relative origin 
see equation 
approach successfully utilized successive overrelaxation sor approach smooth support vector machine ssvm approach 

error soft margin minimized norm squared conventional norm 
see equation 
approach successfully generating virtual support vectors 
simple fundamental changes lead considerably simpler positive definite dual problem nonnegativity constraints 
see equation 
section standard svm formulation dual give formulation simpler dual 
corroborate solid computational evidence simpler formulation compromise generalization ability evidenced numerical tests section public datasets 
see table 
section gives active support vector machine asvm algorithm consists solving system linear equations dual variables positive definite 
invoking sherman morrison woodbury formula need invert dimen input space 
key feature approach allows solve problems millions points merely inverting smaller matrices order concurrent ferris munson formula conjunction interior point approach solve massive problems formulation conventional formulation 
burges active set method applied standard svm formulation 
burges appeal different ways active set computational strategy mor 
note active set computational strategy bears relation active learning 
section describes numerical results indicate asvm formulation tenfold testing correctness ordinary svm capability accurately solving massive problems millions points attacked standard methods ordinary svms 
describe notation give background material 
vectors column vectors transposed row vector prime vector denotes vector negative components set zero 
notation mx signify real matrix 
denote transpose ai denote th row vector ones zeroes real space arbitrary dimension denoted respectively 
identity matrix arbitrary dimension denoted vectors denotes orthogonality xy 
tm ub denotes qb denotes denotes principal submatrix rows columns notation denotes set minimizers set real valued function defined wc denote definition 
norm bc denoted ql 
separating plane respect point sets plane attempts separate halfspaces open halfspace contains points special case sherman morrison woodbury formula bc utilized 
positive number arbitrary 
formula enables invert large matrix merely inverting smaller matrix 
linear support vector machine consider problem classifying points dimensional real space represented membership point ai class specified diagonal diagonal 
problem standard svm linear kernel quadratic program parameter min aw 
oa oo separating margin plane bounding planes soft errors margin plane approximately separating 
normal bounding planes determines location relative origin 
plane xw bounds points possibly error plane bounds points possibly error 
separating surface plane midway bounding planes 
quadratic term twice reciprocal square norm distance bounding planes see 
term maximizes distance called margin 
classes linearly inseparable depicted planes bound classes soft margin 
bound set approximately error determined nonnegative error variable yi dii yi traditionally norm error variable minimized parametrically weight resulting approximate separation depicted 
dual standard quadratic linear svm rain lu daa du du uc variables primal problem determine separating surface obtained solution dual problem eqns 

note immediately matrix daa appearing dual objective function positive definite general typically equality constraint addition bound constraints large problems necessitates special computational procedures smo :10.1.1.43.4376
furthermore dimensional optimization problem solved order determine locator separating surface 
order overcome difficulties dealing necessity having essentially invert large order propose simple critical modification standard svm formulation 
change constraint redundant 
append term ww 
effect maximizes margin parallel separating planes respect respect orientation location planes just respect merely determines orientation plane 
leads reformulation svm min vy ww 
aw 
crn dual problem rain cr aa cc 
variables primal problem determine separating surface recovered directly solution dual relations immediately note matrix appearing dual objective function positive definite equality constraint upper bound dual variable constraint simple nonnegativity 
facts lead simple finite active set algorithm requires sophisticated inverting iteration order solve dual problem 
asvm active support vector machine algorithm algorithm consists determining partition dual variable nonbasic basic variables 
nonbasic variables set zero 
values basic variables determined finding gradient objective function respect variables setting gradient equal zero solving resulting linear equations basic variables 
basic variable takes negative value solving linear equations set zero nonbasic 
essence algorithm 
order algorithm converge terminate additional safeguards need put place order allow invoke mor finite termination result 
key feature algorithm computational formula 
feature allows invert matrix step bigger matrix order stating algorithm define matrices simplify notation follows hh 
definitions dual problem min lu qu cu 
understood asvm algorithm evaluated formula inverted 
state algorithm 
note commented parts algorithm needed general rarely numerical results section 
essence algorithm displayed boxes 
algorithm active svm asvm algorithm 
start 
having compute follows 

define determine teil qc iz global solution quiz 
ui go ja 
ifo qb ub eb global solution face active constraints un set go jb 
set go 
ja move direction global minimum face ac tive constraints un set bi set go 
global minimum face un go jb 
jb iterate gradient projection step 
set iterate qs ui 
set set go 
commented parts algorithm optional usually implemented algorithm gets stuck rarely examples 
algorithm particularly simple consists steps 
commented parts inserted order comply active set strategy mor result give finite termination 
iteration step jb gradient projection step guaranteed converge global solution pp placed ensure strict inequality eventually holds required 
similarly step ja ensures function value increase remains face compliance 
numerical implementation comparisons implemented asvm visual windows nt 
experiments run uw madison data mining institute machine utilizes mhz ii xcon processor maximum memory available process 
wrote code linear equation solver 
stopping criterion asvm triggered error bound residual ii zero solution goes 
set experiments designed show reformulation svm associated algorithm asvm yield similar performance standard svm referred svm qp 
slx datasets available uci machine learning repository performed tenfold cross validation order compare test set accuracies asvm svm qp 
implemented svm qp high performing cplex barrier quadratic programming solver utilized tuning set algorithms find optimal value parameter default stopping criterion cplex 
altering cplex default stopping criterion match asvm result significant change timing relative asvm reduce test set correctness 
order obtain additional timing comparison information ran known svm optimized algorithm svm 
joachims author svm provided newest version software version advice setting parameters 
features experiments normalized range recommended svm light documentation 
chose training testing time dataset training testing time correctness correctness cpu sec correctness correctness cpu sec disorders plex ionosphere plex ht svm svm heart plex tic tac toe plex ht svm svm ima diabetes plex votes plex ht svm svm table asvm compared conventional svm qp cplex svm light uci datasets 
asvm test correctness comparable svm qp timing faster cplex faster comparable svm 
training testing time points iterations correctness correctness cpu min table performance asvm ndc generated datasets 
default termination error criterion svm stringent criterion asvm 
criterion asvm see aggregate errors points svm criterion reflects minimum error threshold point 
second set experiments show asvm performs massive datasets 
created synthetic data gaussian distribution ndc data generator suggested usama fayyad 
results experiments shown table 
try run svm datasets ran memory difficulties 
note experiments data brought memory 
running time reported consists time solve problem termination excluding time 
consistent measurement techniques popular approaches 
putting data memory simpler code results faster running times 
fundamental requirement algorithm block multiplications incremental evaluations application formula indices dataset create efficient disk version asvm 
fast finite simple algorithm asvm capable classifying massive datasets proposed implemented 
asvm requires complex commonly available linear equation solver solving small systems variables massive datasets 
includes extensions parallel processing data handling large datasets directly disk extending approach nonlinear kernels 
indebted colleagues thorsten joachims helping get svm light running significantly faster uci datasets glenn fung efforts running experiments revisions 
research described data mining institute report april supported national science foundation ccr cda air force office scientific research microsoft 
anderson bai bischof 

dongarra 
du baum hammarling 
lapack user guide 
siam philadelphia pennsylvania second edition 

nonlinear programming 
athena scientific belmont ma second edition 


tutorial support vector machines pattern recognition 
data mining knowledge discovery 


improving accuracy speed sup port vector machines 
jordan editors advances neural information processing systems pages cambridge ma 
mit press 
muller 
learning data concepts theory methods john wiley sons new york 

ccd version lapack 
www org 
cristianini 
taylor 
support vector ma chines 
cambridge university press cambridge 
ferris munson 
interior point methods massive support vector machines 
technical report computer sciences department university wisconsin madison wisconsin may 
golub van loan 
matrix computations 
john hopkins university press baltimore maryland rd edition 
ilog incline village nevada 
cplex manual 

svm light 
www ai 
informatik uni dortmund 
de forschung verfahren svm light svm light 
eng 
html 
lcc mangasarian 
ssvm smooth support vector machine 
computational optimization applications 
mangasarian 
nonlinear programming 
siam philadelphia pa 
mangasarian 
generalized support vector machines 
smola bartlett schuurmans editors advances large margin classifiers pages cambridge ma 
mit press 
mangasarian 
successive overrelaxation support vector machines 
ieee transactions neural networks 
mangasarian 
new improved error bounds linear problem 
mathematical programming 
matlab 
user guide 
mathworks natick ma 
mor 
algorithms bound constrained quadratic pro grams 
numerische mathematik 
murphy aha 
uci repository machine learning databases 
www ics uci cdu 
html 

ndc normally distributed clustered datasets 
www cs wisc cdu data ndc 
platt :10.1.1.43.4376
sequential minimal optimization fast algorithm training support vector machines 

pages 
smola editors 
advances kernel methods support vector machines 
mit press cambridge ma 
vapnik 
nature statistical learning theory 
springer ny 
