sequential conditional generalized iterative scaling joshua goodman microsoft research microsoft way redmond wa microsoft com describe speedup training conditional maximum entropy models 
algorithm simple variation generalized iterative scaling converges roughly order magnitude faster depending number constraints way speed measured 
attempting train model parameters simultaneously algorithm trains sequentially 
algorithm easy implement typically uses slightly memory lead improvements maximum entropy problems 
conditional maximum entropy models variety natural language tasks including language modeling rosenfeld partof speech tagging prepositional phrase attachment parsing ratnaparkhi word selection machine translation berger finding sentence boundaries reynar ratnaparkhi 
unfortunately maximum entropy maxent models applied generally typical training algorithm maxent generalized iterative scaling gis darroch ratcliff extremely slow 
personally month computer time train single model 
attempts speed maxent training della pietra wu khudanpur goodman 
describe suffered applicability limited number applications 
darroch ratcliff describe gis joint probabilities mention fast variation appears missed conditional maxent community 
show fast variation conditional probabilities useful larger range problems traditional speedup techniques 
achieves speedups simplest models speedups order magnitude typical problems 
disadvantage possible output values memory needed prohibitive 
combining technique speedup technique goodman disadvantage eliminated 
conditional maxent models form exp exp input vector output called indicator functions feature values true particular property true weight indicator instance trying word sense disambiguation word bank context occurrence word particular sense financial river context includes word money financial sense large positive number 
maxent models valuable properties 
important constraint satisfaction 
count times observed training data observed 
model parameters see times model predicts expected expected 
maxent models property expected observed equalities called constraints 
additional property models form equation maxent model maximizes probability training data 
property maxent models close possible uniform distribution subject constraint satisfaction 
maximum entropy models commonly learned gis simple algorithm 
iteration step taken direction increases likelihood training data 
step size guaranteed large small likelihood training data increases iteration eventually converges global optimum 
unfortunately guarantee comes price gis takes step size inversely proportional maximum number active constraints 
maxent models interesting precisely ability different kinds information weakness gis means maxent models slow learn precisely useful 
describe variation gis works faster 
learning parameters model simultaneously learn sequentially back 
new algorithm converges point original 
sequential learning lead improvement show cache subcomputations 
combination leads improvements order magnitude 
algorithms describing classic gis algorithm 
recall gis converges model expected observed 
equal move closer 
simple idea just add log observed expected problem ignores interaction updates iteration gis similar effect easily go far things worse 
gis introduces slowing factor equal largest total value max 
gis computes update log observed expected add update provably converges global optimum 
gis joint models darroch ratcliff conditional version due brown 
unpublished described rosenfeld 
practice pseudocode 
write number training instances published versions gis algorithm require inclusion slack indicator function number constraints applies 
practice necessary total indicator functions bounded necessarily equal 
alternatively see including slack indicator fixing corresponding expected training instance output output expected log observed expected iteration generalized iterative scaling gis number indicator functions number output classes values 
assume keep data structure listing training instance value 
describe variation gis 
basically updating simultaneously loop indicator function compute update indicator function turn 
particular change exchange outer loops training instances indicator functions 
notice order efficiently need rearrange data structures previously assumed training data stored sparse matrix indicator functions non zero values instance assume data stored sparse matrix instances non zero values indicator 
size matrices obviously 
change update near inner loop immediately expected computed expected values features computed 
update features time meaning changes 
original version gis largest total features 
needs largest total features updated updating equations proofs gis improves iteration global optimum hold 
feature expected output instance expected max log observed expected output instance iteration sequential conditional generalized iterative scaling scgis case feature 
max 
maxent applications take values typically max 
slowing factor may slowing 
change order get speedup 
recompute instance output corresponding normalizing factors keep arrays computed invariants incrementally update changes 
important change get substantial speedup 
code transformed algorithm 
space models form equation convex single global optimum 
gis scgis guaranteed converge point 
convergence proofs see darroch ratcliff prove convergence algorithm joint models 
time space section analyze time space requirements scgis compared gis 
space results depend number output classes 
small scgis requires small amount space gis 
note section describe technique output classes uses clustering get speedup reduce number outputs alleviating space issues 
typically gis training data stored sparse matrix size non zero indicator functions instance output transposed matrix scgis size order relationship gis scgis clearer algorithms figures wasted space 
instance matrix sums needs simple array gis wrote matrix meaning algorithms 
space time analyses assume space wasting techniques optimized coding 
analyze space time gis 
gis requires training matrix size size expected observed arrays size gis requires space 
large eliminate indicator functions don appear training data 
scgis potentially somewhat larger 
scgis needs store training data albeit different form size particular matrix interchanged outermost index indicator functions training data 
scgis needs observed arrays size array size importantly full array size iy problems small iy negligible problems language modeling large 
space scgis iy essentially gis small larger large see optimization described section 
consider time algorithm execute iteration 
assume instance output non zero indicator function true practice 
notice gis top loops iterating non zero indicator functions output training instance 
words examine entry training matrix require time bottom loops simply require time smaller gis requires time 
scgis top loops nonzero entry training data takes time 
bottom loops require time 
iteration scgis takes long iteration gis practice im plementation scgis iteration takes times long gis iteration 
speedup scgis comes step size update gis slowed update scgis 
expect scgis converge factor faster 
applications large 
speedup larger step size difficult analyze rigorously may obvious speedup fact observe due improvement caching 
note caching iteration scgis times slower iteration gis caching certainly key component 
caching iteration scgis marginally slower gis small constant factor section fact empirically observe fewer iterations required achieve level convergence reduction roughly proportional 
speedup appear larger step size 
exact speedup step size depends factors including correlated features order trained 
aware problems maxent training data fit main memory model learned reasonable time scgis gis requires sequential random access training data 
wanted train model large amount data disk tape done reasonable efficiency long arrays need random access fit main memory 
analyses assumed training data stored precomputed sparse matrix non zero values training instance output 
applications language modeling case computed fly 
bit thought data structures rearranged 
chen rosenfeld describe technique smoothing maximum entropy best currently known 
maximum entropy models naturally maximally smooth sense close possible uniform subject satisfying constraints 
practice may constraints models nearly smooth overfit training data 
chen rosenfeld describe technique gaussian prior parameters assumed 
models longer satisfy constraints exactly better test data 
particular attempting maximize probability training data maximize slightly different objective function probability training data times prior probability model arg max words probability simple normal distribution mean standard deviation 
chen rosenfeld describe modified update rule find updates solves observed expected scgis modified similar way update rule solves observed expected max previous sequential updating described joint probabilities original gis darroch ratcliff gis sequential updating conditional models appears previously unknown 
note nlp community maxent models conditional models typically far efficient learn knowledge speedup 
appear main reasons speedup conditional models 
issue joint models turns natural compute conditional models natural compute store sums storing essential speedup 
best known uses conditional maxent models language modeling rosenfeld number output classes vocabulary size typically words 
applications array size times number training instances clearly impractical see berger 
algorithm appear sequential examination definition related shows 
discovered trick 
unsurprising speedup forgotten 
previous attempts speed maxent modeling 
best known della pietra 
improved iterative scaling iis algorithm 
treating constant treat function particular solve numerically equation observed exp notice special case constant equation reduces equation 
training instances iis update take proportionately larger step 
iis lead speedups substantially hard think applications difference typically large 
know limited experiment comparing iis gis lafferty 
experiment showed roughly factor speedup 
noted compared gis iis harder implement efficiently 
solving equation uses algorithm newton method repeatedly evaluates function 
repeatedly cycle training data compute right hand side equation tricks bucketing values 
option inefficient second adds considerably complexity algorithm 
note iis scgis combined update rule solves observed exp model types take values 
case equation reduces normal scgis update 
brown describes iterative scaling applied joint probabilities jelinek page shows apply conditional probabilities 
binary valued features caching trick scgis algorithm described jelinek 
advantage scgis caching speedup variation gis applied non binary valued features 
scgis clear apply improvements smoothing technique chen rosenfeld 
techniques developed specifically speeding conditional maxent models especially large language models space precludes full discussion 
techniques include unigram caching cluster expansion lafferty wu khudanpur word clustering goodman 
best appears word clustering leads factor speedup additional advantage allows scgis speedup large number outputs 
word clustering speedup applied problem outputs just words works follows 
notice gis scgis key loops outputs certain optimizations applied length loops bounded proportional number outputs 
change model form modeling cluster cluster 
consider language model word represents words preceding vocabulary size words 
model outputs 
hand create word clusters words cluster model cluster outputs model cluster outputs 
training model time proportional train time proportional 
example times speedup 
practice speedups quite large achieve speedups factor 
model form learned exactly original model perplexity form models marginally lower better perplexity form single model disadvantage 
word clustering technique extended multiple levels 
instance putting words part speech clusters semantically similar words part speech level model 
fact technique extended log levels outputs level meaning space requirements proportional original scgis works increasing step size cluster speedup works increasing speed inner loop scgis shares expect techniques complement speedups nearly multiplicative 
preliminary language modeling experiments consistent analysis 
interesting unpublished minka 
preliminary experimental setting somewhat unrealistic dense features artificially generated especially natural language tasks results dramatic worth noting 
particular minka version conjugate gradient descent worked extremely faster gis 
problem domain resembles minka conjugate gradient descent related techniques worth trying interesting try techniques realistic tasks 
scgis turns related boosting 
shown collins 
boosting ways sequential version maxent 
single largest difference algorithm collins update feature order collins algorithms select possibly new feature update 
algorithm require storage algorithm data sparse fast implementations require storage training data matrix compute feature update transpose training data matrix perform update efficiently 
experimental results section give experimental results showing scgis converges order magnitude faster gis depending number non zero indicator functions method measuring performance 
ways measure performance maxent model objective function optimized gis scgis entropy test data percent correct test data 
objective function scgis gis smoothing equation probability training data times probability model 
interesting measure percent correct test data tends noisy 
test corpus chose exactly training test problems feature sets brill 
problems consisted trying guess confusable words user intended 
banko brill chose data representative typical machine learning problems trying data sizes different pairs words exhibits deal different behaviors 
banko brill standard set features including words window part speech tags window pairs word tag features word occurred window 
altogether feature types 
thousands features model depending exact model true training test instance 
examine performance scgis versus gis different axes 
important variable number features 
addition trying banko brill feature types tried feature sets feature types words window plus unigram feature feature types words window tags window unigram pairs words window 
tried smoothing tried varying training data size 
table typical configuration feature types words training smoothing gaussian prior 
columns show different confusable words 
column shows ratio longer terms elapsed time takes gis achieve results iterations scgis 
xxx denotes case gis achieve performance level scgis iterations 
included averages 
objec column shows ratio time achieve value objective function equation ent column show ratio time achieve test entropy cor column shows ratio time achieve test error rate 
measurements ratio factor average somewhat lower cases gis converged faster 
table repeat experiment smoothing 
objective function smoothing just training entropy increase scgis larger 
ghz pentium iv words training feature types took seconds iteration scgis seconds gis 
feature types took seconds scgis seconds gis 
note experiments larger datasets feature types run time scales linearly training data size 
objec ent cor accept affect effect xxx peace piece xxx principal principle xxx weather xxx re average table baseline standard feature types words smoothed objec ent cor accept affect effect peace piece xxx principal principle weather re average table baseline smoothing criteria test entropy percentage correct increase scgis smaller smoothing consistently large 
tables show results small medium feature sets 
seen speedups smaller features sets feature types speedups medium sized feature set feature types smaller baseline speedup features 
notice experiments cases gis converged faster scgis objective function cases faster test data entropy cases converged faster test data correctness 
objective function measure noisy test data entropy test data entropy noisy test data error rate noisier data chance unexpected result 
possibility cases simply due noise 
similarly cases gis reached test data objec ent cor accept affect effect peace piece xxx principal principle weather re average table small feature set feature types objec ent cor accept affect effect xxx peace piece principal principle xxx weather re average table medium feature set feature types entropy scgis cases gis reached test data error rate scgis attributable noise 
alternative explanation worth exploring 
different data set newsgroups early stopping techniques helpful gis scgis benefited differently depending exact settings 
possible effects similar smoothing effect early stopping played role xxx cases scgis presumably benefited effects cases gis beat scgis cases gis presumably benefited 
additional research required determine explanation early stopping noise correct suspect explanations apply cases 
ran experiments baseline experiment changing training data size words words 
individual speedups different different sizes appear higher lower qualitatively different 
discussion reasons maxent speedups useful 
applications active learning parameter optimization feature set selection may necessary run rounds maxent making speed essential 
fast algorithms winnow available experience problems smoothed maxent models better classifiers winnow 
furthermore fast classification algorithms including winnow output probabilities useful precision recall curves non equal tradeoff false positives false negatives output classifier input models 
applications maxent huge amounts data available language modeling 
unfortunately previously difficult maxent models types experiments 
instance language modeling experiment performed took month learn single model 
clearly models type speedup helpful 
expect technique widely 
leads significant speedups order magnitude 
easy implement need transpose training data matrix store extra array complex standard gis 
easily applied model type leads largest speedups models feature types 
models interacting features type maxent models interesting typical 
requires additional resources large number output classes uses space standard gis large number output classes combined clustering speedup technique goodman get additional speedups reduce space requirements 
appear real impediments leads large broadly applicable gains 
chelba stan chen chris meek anonymous reviewers useful comments 
banko brill 

mitigating paucity data problem 
hlt 
adam berger stephen della pietra vincent della pietra 

maximum entropy approach natural language processing 
computational linguistics 
brown dellapietra dellapietra mercer nadas roukos 
unpublished 
translation models learned features generalized csiszar algorithm 
ibm research report 
brown 

note approximations probability distributions 
information control 
chen rosenfeld 

gaussian prior smoothing maximum entropy models 
technical report cmu cs computer science department carnegie mellon university 
michael collins robert schapire yoram singer 

logistic regression adaboost bregman distances 
machine learning 
darroch ratcliff 

generalized iterative scaling log linear models 
annals mathematical statistics 
stephen della pietra vincent della pietra john lafferty 

inducing features random fields 
pattern analysis machine intelligence april 
joshua goodman 

classes fast maximum entropy training 
icassp 
frederick jelinek 

statistical methods speech recognition 
mit press 
lafferty pereira anda 
mccallum 

conditional random fields probabilistic models segmenting labeling sequence data 
icml 
john lafferty 

gibbs markov models 
computing science statistics proceedings th symposium interface 
thomas minka 

algorithms maximumlikelihood logistic regression 
available www white media mit edu papers learning html 
adwait ratnaparkhi 

maximum entropy models natural language ambiguity resolution 
ph thesis university pennsylvania 
reynar ratnaparkhi 

maximum entropy approach identifying sentence boundaries 
anlp 
ronald rosenfeld 

adaptive statistical language modeling maximum entropy approach 
ph thesis carnegie mellon university april 
wu khudanpur 

efficient training methods maximum entropy language modeling 
icslp volume pages 
