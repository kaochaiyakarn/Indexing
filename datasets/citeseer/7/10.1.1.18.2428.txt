lamarckian evolution baldwin effect function optimization darrell whitley scott gordon keith mathias computer science department colorado state university fort collins whitley cs colostate edu 
compare forms hybrid genetic search 
uses lamarckian evolution second uses related method local search employed change fitness strings acquired improvements change genetic encoding individual 
search method exploits baldwin effect 
modeling simple genetic algorithm show functions exist simple genetic algorithms learning lamarckian evolution converge local optimum genetic search utilizing baldwin effect converges global optimum 
show simple genetic algorithm exploiting baldwin effect outperform forms lamarckian evolution employ local search strategy 
hybrid genetic algorithm combines local search traditional genetic algorithm 
common form hybrid genetic algorithm uses local search improve initial population strings produced genetic recombination 
resulting improvements coded strings processed genetic algorithm 
equivalent form lamarckian evolution 
local search context thought analogous kind learning occurs lifetime individual string 
way learning local search evolution interact 
coding improvements back string fitness value improvement transferred individual 
effect changing fitness landscape resulting form evolution darwinian nature 
various phenomena associated form combining learning evolution collectively known baldwin effect 
compare form lamarckian evolution simple genetic algorithm exploits baldwin effect 
compare approaches simple genetic algorithm learning 
empirical analytical tests look specifically function optimization problems 
binary encoding problems local search context involves changing bits string encoding 
local search limited step search space 
transferring fitness string baldwinian strategy string unique evaluation 
steepest ascent local search ascent 
analytical empirical results indicate lamarckian strategies extremely fast form search 
functions exist simple genetic algorithm learning lamarckian strategy converge local optima simple genetic algorithm exploiting baldwin effect converges global optimum 
study phenomenon exact models simple genetic algorithm developed whitley special case vose liepins models 
show equivalence classes exist functions functions equivalence class processed identical fashion specific forms lamarckian baldwinian search strategies 
lamarckian evolution versus baldwin effect hybrid genetic algorithms combine local search genetic search effect form lamarckian evolution 
way learning evolution interact allow learning local optimization change fitness individual altering individual genetic code 
local search learning effect changing fitness landscape 
part known baldwin effect 
gruau whitley evolving boolean neural networks grammar trees genetic search learning change fitness function just effective lamarckian strategies lamarckian strategies search exploiting baldwin effect efficient effective genetic search 
explores combination local genetic search domain function optimization problems encoded binary strings 
local search algorithm uses iteration steepest ascent 
current solution flip bits current solution local optimum improved solution best possible neighbor states 
improved solution coded back chromosome refer lamarckian search strategy 
case state replaces current state 
improved solution merely change fitness current state search strategy referred baldwinian 
taken gruau whitley illustrates local search alter fitness landscape 
steps basin attraction ascent taken neighbors string checked random order ascent yield unique solution 
steepest ascent bit changes tested best improvement taken 
dimensional variable fitness learning fitness descent local optimum fitness steps hill effect local search fitness landscape dimensional function 
improvements move downhill fitness landscape 
making function flatter local optimum 
local search done convergence fitness function flat basin attraction 
note basin attraction potentially different evaluation corresponding evaluation local optimum 
changing fitness landscape way creates potential impacting genetic search increasing likelihood allocating samples certain basins attraction 
hinton nolan researchers explore baldwin effect genetic algorithms 
illustrate baldwin effect genetic algorithm simple random learning process develops simple neural network 
genetic encoding specifies neural network topology indicating potential connections connect set artificial neurons 
objective function learning correct network results increased fitness networks inferior fitness 
creates spike correct solution flat fitness landscape 
genetic encoding uses character alphabet specifies existence connection absence connection connection unspecified 
connection unspecified set randomly set learning 
learning case merely random search possible assignments unspecified connections denoted symbol 
hinton nolan symbol fully disappeared genetic code search got close global optimum reached learning 
appears product genetic drift coupled premature convergence 
harvey provides explanation anomalous results hinton nolan respect puzzle persistent questions marks 
belew offers review critique hinton nolan 
analytical results better understand lamarckian baldwinian search strategies exact model simple genetic algorithm study approaches solving small test problems 
model track expected representation strings infinitely large population 
model effect baldwinian strategy fitness function needs changed 
string refer evaluation value returned evaluation function simple genetic algorithm learning 
baldwinian search strategy second evaluation function constructed 
string define evaluation string maximum evaluation value set strings composed string neighbors hamming space 
running simple genetic algorithm function evaluation produces results identical running simple genetic algorithm function evaluation iteration steepest ascent change evaluation current string 
example function illustrates effect modeling baldwinian search strategy 
bit function created sorting binary strings length integer value 
string value integer value strings increases value assigned string decremented 
string value 
string assigned value 
function denoted function function posed maximization problem 
function fully deceptive 

average evaluation strings hyperplane significant amount deception 
function eb represents evaluation constructed function 
eb eb eb eb eb eb eb eb eb eb eb eb eb eb eb eb note basins attraction deeper flatter local minimum 
lamarckian strategy string best value local neighborhood string replace string best value case string local optimum 
implementation lamarckian search strategy string distributions altered generation model effects iteration steepest ascent 
string residing local optimum example increases distribution sum distributions immediate neighbors 
neighbor points necessarily zero representation 
neighbors hamming distance local optimum move downhill step assuming basin attraction creating new representations strings step closer local optimum 
representation string population time generation proportional representation strings changed doing iteration steepest ascent 
equations represents distribution strings steepest ascent 
note redistribution string representations usually different functions different 
function changes 
strings lie saddle basins attraction representation iteration steepest ascent 
number points falling saddle local optima quite high small bit function 
larger functions 
obviously bit function local optima smaller percentage saddle points compared size search space follows fewer strings zero representation infinite population genetic algorithm 
issues worth considering 

number local optima increase generally number saddle points increase 
maximal number local optima exists binary coded space exactly half points space local optima half saddle points local optima 
generations sga generations sga learning generations sga baldwinian learning generations sga baldwinian learning scaled fitness values sga behavior lamarckian baldwinian learning 
string local optimum global optimum 
generally basins attraction radius greater number saddle points local optima grow function hamming distance local optima nearest saddle point 

finite population genetic algorithm points representation population local search applied may representation local search applied 
illustrates results obtained exact model simple genetic algorithm process function 
includes results executing evaluation version function models behavior baldwinian search strategy results lamarckian search strategy 
crossover rate mutation rate experiments 
simple genetic algorithm learning lamarckian search strategy converge local optimum 
baldwinian search strategy converges global optimum slowly 
reason slow convergence baldwinian search strategy variation evaluation strings space evaluation version function 
strings evaluation version function evaluation half strings evaluation 
time scaling function performed subtracting value points space 
completely remove scaling problem cause genetic algorithm converge faster 
equivalent classes hybrid genetic search strings lie saddle basins attraction representation iteration steepest ascent follows actual evaluations strings sense irrelevant 
specific evaluations strings saddle points change effecting lamarckian search long gradient directions induced local search change 
function converted function refer function half hyperplanes fitness averages favor global optimum 




function ways quite different behaves identically function lamarckian search strategy defined 
set equations describing redistribution strings lamarckian search remains exactly 
note string function representation iteration steepest ascent change evaluation function 
saddle points change evaluation 
moves occur functions iteration steepest ascent applied 
implies function function processed identical fashion baldwinian search strategy saddles points acquire evaluation points space 
actual values saddle points irrelevant clear sets functions equivalent lamarckian baldwinian search strategies different functions sets unique simple genetic algorithm learning 
simple genetic algorithm learning executed function search converges local minimum 
results lamarckian baldwinian strategy identical results obtained function 
empirical function optimization tests tested effects adding baldwinian lamarckian search strategies simple genetic algorithm numerical optimization problems rastrigin gamma cos gamma schwefel gammax sin jx gamma griewank gamma cos gamma schwefel function negative global minimum added function move global minimum zero 
exact value depends system precision experiments 
experiments elitist form standard simple genetic algorithm 
probability crossover set mutation rate 
tournament selection tournaments size gray coding case 
string length problems 
local optimization employed form steepest ascent table shows performance data algorithm functions variety population sizes 
particular consider population sizes functions population size griewank hardest functions genetic algorithm solve 
table shows times genetic algorithm finds global solution runs generations 
note minimization problems problems section maximization problems 
rastrigin schwefel griewank popsize baldwin lamarckian table performance numeric functions 
number times ga finds optimal solution runs shown 
wishes obtain results quickly lamarckian strategy consistently best 
interested long term effects search strategies lamarckian search appears better rastrigin griewank functions baldwinian learning works better schwefel function 
shows convergence graphs rastrigin schwefel best string generations rastrigin plain baldwin lamarkian generations schwefel plain baldwin lamarkian baldwin vs lamarckian learning numeric optimization functions 
functions value best string population averaged runs plotted genetic algorithm population size 
similar results observed larger population sizes 
cases lamarckian search results faster improvement 
schwefel function average best solution poorer lamarckian search baldwinian learning extended period time 
results largely exploratory nature 
results clearly indicate baldwinian search strategy defined effective lamarckian strategy form local search 
noted effective mean baldwinian search strategy converge global optimum lamarckian strategy converges local optimum 
cases baldwinian search strategy slower lamarckian search 
clear exist equivalence classes functions lamarckian baldwinian search strategies 
equivalence class case defined functions equivalence class processed identical fashion lamarckian baldwinian search strategy 
notable difference results reported results obtained gruau whitley baldwinian search strategy prove efficient lamarckian search strategy function optimization problems studied 
may due part fact test problems easy 
rastrigin schwefel functions evaluation subfunction associated parameter nonlinear subfunctions applied parameter simply summed 
non linear interactions individual parameters 
problems relatively easy solve stochastic hillclimbing methods surprising lamarckian search effective problems 
ideally effectiveness baldwinian search strategy evaluated complex domains 
noted gruau whitley type genetic algorithm steady state genetic algorithm model simple genetic algorithm impact results 
original idea local search change fitness landscape communicate rik belew 
supported part nsf iri 
ackley littman interactions learning evolution 
proc 
nd conf 
artificial life langton ed addison wesley 
baldwin new factor evolution 
american naturalist 
belew individuals populations search adding simple learning genetic algorithm 
th intern 
conf 
genetic algorithms schaffer ed morgan kaufmann 
goldberg genetic algorithms walsh functions part ii deception analysis 
complex systems 
gruau whitley adding learning cellular development neural networks evolution baldwin effect 
evolutionary computation 
harvey puzzle persistent question marks case study genetic drift 
th intern 
conf 
genetic algorithms forrest ed morgan kaufmann 
hinton nolan learning guide evolution 
complex systems 
vose liepins punctuated equilibria genetic search 
complex systems 
whitley fundamental principles deception 
foundations genetic algorithms 
rawlins ed 
morgan kaufmann 
whitley das tracking primary hyperplane competitors genetic search 
mathematics artificial intelligence 
