improving functional density run time circuit reconfiguration thesis submitted department electrical computer engineering brigham young university partial fulfillment requirements degree doctor philosophy fl michael michael november dissertation michael accepted form department electrical computer engineering brigham young university satisfying dissertation requirement degree doctorate philosophy 
brad hutchings committee chairman brent nelson committee member brian committee member james archibald committee member doran wilde committee member date michael rice graduate coordinator ii acknowledgments supported defense advanced research projects agency darpa information technology office ito contract numbers dabt dabt 
addition effort possible inspiration contribution people 
assistance ideas provided fellow graduate students byu configurable computing laboratory played important role 
jim original run time reconfigured neural network provided initial motivation description benefits potential runtime reconfiguration 
jim hadley follow rrann project successfully demonstrated advantages exploiting partial reconfiguration 
low level design project provided motivation needed explore unique uses partial reconfiguration 
dave clark eased development disc applications porting compiler disc processor 
justin assisted design hand layout testing partially reconfigured circuits 
paul graham generous assistance support mutual activities classes projects byu 
graduate students assisting include russel peterson mike richard ross peter 
advisor brad hutchings provided essential assistance encouragement projects ideas results 
decision complete degree write dissertation influenced largely advice positive encouragement 
brent nelson faculty members electrical computer engineering department byu provided critical feedback wide variety topics relating 
acknowledge insight assistance collaborators researching closely related subjects 
fortunately research community investigating configurable computing machines open friendly group people eager share information assist 
specifically members soft logic group national semiconductor provided essential device tool support assistance needed successfully complete projects contained 
support family critical successful completion 
parents provided continual support motivation pursuit higher education set high standards education learning 
importantly acknowledge wife children patience support academic interests 
provided essential encouragement graduate education assisted final editing 
iii contents acknowledgments iii custom computing machines 
run time reconfiguration 
thesis organization 
configurable computing machines reconfigurable computing 
custom computing machines 
dec perle 
src splash 
specialization techniques 
customization functional units 
exploitation concurrency 
optimized communication networks 
custom interfaces 
summary 
run time reconfiguration opportunities run time specialization 
temporal locality 
partitioning large systems 
run time reconfigured applications 
artificial neural network 
video coding 
variable length code detection 
automatic target recognition 
stereo vision 
dynamic instruction set computer disc 
configuration overhead 
analysis run time reconfigured systems functional density 
functional density run time reconfigured systems 
architectural analysis 
application specific circuit parameters 
comparing functional density 
iv applications run time reconfigured artificial neural network 
rrann system architecture 
performance 
area cost 
functional density 
configuration overhead 
partially run time reconfigured artificial neural network 
partial configuration 
performance 
area cost 
functional density 
configuration overhead 
template matching 
system architecture 
performance 
area cost 
functional density 
configuration overhead 
sequence comparison 
limited hardware systems 
run time reconfiguration edit distance pes 
functional density 
application summary 
dynamic instruction set computer disc functional density disc instructions 
functional density static processor core 
functional density custom instructions 
low pass filter 
maximum value search 
improving functional density exploiting temporal locality 
functional density disc instruction cache 
measuring hit rate 
example hit rate function 
example functional density calculation 
functional density disc program 
summary 
reconfiguration time configuration conventional fpgas 
configuration bandwidth ae 
configuration length 
configuration improvement techniques 
improving configuration bandwidth 
partial configuration 
simultaneous configuration execution 
exploiting temporal locality 
distributed configuration 
summary 
review 
run time reconfiguration 
functional density 
configuration time 

special purpose bit serial template matching circuit propagating template constants 
clay implementation 
functional density 
edit distance algorithm unidirectional array 
specialization unidirectional array 
mapping clay fpga 
distance unit 
general purpose matching unit 
special purpose matching unit 
functional density 
disc disc architecture 
disc processor core 
custom instructions 
partial reconfiguration 
relocatable hardware 
application example 
object thinning 
run time execution 
execution results 
configuration data vi list tables dec perle applications 
splash applications 
example circuit parameters functional density 
rrann circuit parameters 
circuit parameters neuron network 
configuration overhead neuron network 
rrann circuit parameters 
rrann ii circuit parameters neuron network 
rrann ii partial bit stream sizes 
improvement functional density rrann ii 
circuit parameters correlation pe 
functional density template matching circuit 
configuration overhead template matching circuit 
comparison edit distance alternatives 
application summary 
area static processor core 
configuration rate disc 
maximum functional density maximum value custom instruction 
configuration time configuration ratio maximum value search custom instruction 
sample disc instruction sizes 
distances instruction insta listing 
hit rate instructions listing 
fpga device configuration bandwidth 
xilinx xc configuration data 
improvement functional density partially reconfigured systems 
configuration overhead hit rate bounds values ff 
correlation cell parameters 
area time comparison edit distance components 
functional density general special purpose edit distance pes 
run time composition sample disc instructions 
disc pc execution time 
disc custom instructions 
lucent orca xx series fpga configuration data 
altera flex configuration data 
altera flex configuration data 
xilinx xc configuration data 
vii xilinx xc configuration data 
xilinx xc ex configuration data 
xilinx xc family configuration data 
atmel family configuration data 
national semiconductor clay configuration data 
viii list figures dec perle 
src splash 
signal flow graph newton mechanics problem 
stages backpropagation training algorithm 
run time reconfiguration special purpose neuron processors 
signal flow graph concurrent fir filter 
constant propagated special purpose fir filter 
partitioning fir circuit 
run time reconfiguration fir filter taps 
video coding algorithm 
sample hardwired decoding tree 
merging similar templates 
degradation functional density 
example functional density comparison 
system architecture rrann 
configuration overhead rrann 
functional density rrann 
configuration overhead rrann ii 
functional density rrann ii 
parallel computation correlation 
array correlation pes programmed specific template image 
general purpose conditional bit serial adder 
special purpose conditional adders 
partial configuration correlation array 
functional density template matching circuit function image size 
partitioning systolic edit distance array 
buffering partial results fifos 
execution sequence partitions 
execution configuration special purpose pes 
functional density edit distance circuit function character length 
data flow mean instruction module 
architectural overview low pass instruction module 
functional density low pass filter 
maximum value instruction block diagram 
functional density maximum value instruction 
sample instruction sequence 
hit rate insta function instruction cache size 
functional density insta function instruction cache size 
ix functional density insta lru optimal replacement policies 
functional density insta low configuration ratio 
functional density listing cache size 
improvement limitations constant configuration time 
reduction functional density larger fpga devices 
limitations area overhead configuration improvements 
maximum allowable area mb sec configuration interface 
simultaneous execution configuration fpgas 
maximum ff function 
multiple fpga resources interconnected form configuration cache 
rrann neural processor cache 
functional density cached rrann system function network size 
multiple context fpga 
binary template correlation pe 
correlation column processor 
parallel computation column processors 
spatial organization correlation pe 
processor array 
bit serial correlation pe 
proper data alignment bit serial correlation pes 
special purpose bit serial correlation pes 
special purpose array correlation pes 
physical bit serial adder layout 
physical layout bit serial add 
dependency graph edit distance calculation 
projection hyper planes unidirectional array 
signal flow graph unidirectional array 
block diagram unidirectional pe 
general purpose matching unit 
special purpose matching unit 
constant propagated processing element 
customized source sequence processor array 
distance unit schematic 
layout clay distance unit 
general purpose matching unit schematic 
general purpose matching unit layout 
special purpose matching unit schematic 
special purpose matching unit layout 
worst case special purpose matching unit layout 
general purpose edit distance pe layout 
special purpose edit distance pe layout 
disc architecture processor core reconfigurable logic 
disc processor core 
relocation irregular shaped custom instructions 
linear hardware space communication network 
constrained instruction module 
multiple instructions linear hardware space 
disc instruction execution 
object thinning steps 
disc state executing histogram 
disc state executing threshold value subroutine 
disc executing skeletonization instruction 
xi improving functional density run time circuit reconfiguration michael chapter programmable logic devices common building blocks digital systems 
name implies logic devices user programmable programmable device manufacturing 
user programmable logic allows circuit designers enjoy benefits circuit customization non recurring engineering fees typically associated custom silicon devices 
addition programmable logic shrinks development cycle custom circuits removing time consuming step circuit manufacturing 
rapidly growing segment programmable logic market includes field programmable gate arrays fpgas 
name implies devices provide array gates logic resources surrounded rich interconnection network 
conventional gate array fpgas provide considerably logic available discrete logic components 
gate array requires custom manufacturing fpga programmable user 
publications provide description commercial fpga technology architectures design styles 
fpgas programmed user fpga families allow reprogramming logic resources 
fpgas static memory technology programmed reprogrammed loading circuit bit stream internal configuration memory 
static configuration memory volatile loses configuration state power allows unlimited reconfiguration device 
reconfigurability exploited novel ways ffl logic prototyping ffl multi purpose hardware ffl configurable computing 
logic prototyping common reconfigurability circuit prototyping environments 
single fpga device test circuit progresses development phase 
circuit improvements changes easily accommodated fpga reconfiguration 
fabrication custom device risks involved reconfiguring circuit fpga 
errors circuit modified configured additional fabrication costs 
ability prototype arbitrary digital circuits fpgas motivated fpgas key components logic emulation systems 
multi purpose hardware reconfigurability fpga offers increased flexibility risk reduction reconfiguration provides unique opportunities hardware reuse 
single fpga device operate different circuits needed system 
example fpga configured perform system diagnostics power 
diagnostics complete fpga reconfigured perform standard operational functions 
dual fpga device allows system operate fewer resources possible non configurable system 
examples hardware reuse include adaptive systems multi mode hardware interfaces 
configurable computing circuit reconfigurability allows fpgas operate custom computers 
application circuits designed perform computation fpga logic resources configured fpga software program loaded memory processor 
fpga resources reconfigurable number circuit configurations executed fpga resource 
configurable computing systems designed solve wide range application specific problems 
conferences workshops organized investigate fpga technology fpga computers provide ample examples computing structures 
addition articles popular trade magazines report growing technology commercial systems 
custom computing machines computing architectures designed fpga resources called custom computing machines 
names include reconfigurable computers adaptive computing systems computers 
machines aptly termed computers due reconfigurability computational capabilities 
reconfiguration application specific circuit perform computation replaced application specific circuit performing different possibly unrelated computation 
traditional computers structures perform computation ccm specialized computational task hand 
architectural specialization allows ccm system provide unusually efficient computational structures 
surprisingly fpga resources solve important computationally challenging problems optimizing datapath control communication network gate level 
computing structure specialized computation interest greater efficiency performance 
computational efficiency provided architectural specialization allows modest array fpga devices achieve surprising levels performance 
ccm applications demonstrated performance superior high workstations supercomputers 
application examples demonstrating impressive performance include genetic database searching long integer multiplication volume visualization real time image processing rsa cryptography 
small arrays fpgas including single device shown provide superior performance costly alternatives :10.1.1.21.7928
run time reconfiguration benefits efficiency performance provided architectural specialization extended specializing computing architecture runtime 
dynamic circuit specialization possible reconfiguring fpga resources run time 
technique called run time reconfiguration rtr provides additional opportunities circuit specialization unavailable static systems 
ccm applications demonstrate improved hardware efficiency specializing circuits run time 
neural network application example increases efficiency fpga hardware removing idle circuits run time 
image processing system uses similar technique optimize hardware resources image processing algorithms 
examples achieve greater levels efficiency specializing fpga resources run time dynamic conditions system 
rtr shown improve efficiency computation additional time required configuring circuit resources execution 
ccm applications reconfiguration occurs line computation takes place rtr requires configuration occur line circuit execution 
currently available devices reconfiguration time order milli seconds orders magnitude greater time required complete individual computation 
cases lengthy configuration time clearly mitigates advantages rtr 
cases trade clear 
rtr involves trade reduction hardware penalty reconfiguration time 
practice rtr net advantage traditional static approach shown 
date general quantitative method suggested balance advantages rtr associated configuration costs 
dissertation address issue introducing metric balances advantages run time reconfiguration added cost configuration time 
metric address important questions ffl sensitive configuration time rtr applications 
ffl rtr including associated configuration time justified conventional static methods 
ffl rtr appropriate application 
ffl composite benefits technique improves configuration time 
thesis organization dissertation commence introducing application specific computing chapter 
application specific computing architectures achieve impressive levels performance efficiency specializing aspects computing structure application interest 
architectural specialization techniques demonstrate advantages 
advantages fpga technology application specific computing described examples 
chapter follow introducing run time reconfiguration rtr 
specifically chapter describe additional opportunities specialization exploited reconfiguring circuit resources run time 
published examples rtr demonstrate techniques working systems 
chapter continue introducing method measuring advantages obtained run time circuit specialization 
metric called functional density balances improvements area execution time provided run time circuit specialization added overhead configuration time 
chapter apply functional density metric applications exploiting rtr 
functional density rtr application compared functional density application operating conventional static environment 
comparison indicate appropriateness rtr identify conditions rtr justified 
applications analysis include variations artificial neural network template matching circuit sequence matching circuit 
appendices included provide details applications 
chapter follow analyzing effects run time reconfiguration dynamic instruction set computer 
functional density metric benefits reconfiguring special purpose processor instructions balanced associated reconfiguration overhead 
chapter address importance reconfiguration time review performance conventional configuration methods 
commercially available fpgas provide relatively slow configuration interfaces configuration improvement techniques reviewed 
techniques include partial configuration simultaneous execution configuration exploitation temporal locality distributed configuration 
chapter conclude summarizing results analysis 
chapter configurable computing machines computationally challenging problems real time computing requirements demanding general purpose programmable processors 
computational requirements operations real time video compression image processing dimensional graphics exceed billions operations second 
computing architectures solving challenging problems handle enormous amount data simultaneously performing computation 
computational capability sub systems general purpose processors insufficient demands placed real time computing challenges 
application specific computing architectures solve computationally intensive operations 
architectures perform demanding real time operations specializing computing structure application problem interest 
aspects computing architecture including functional units interfaces control memory optimized perform operation efficiently possible 
example custom device designed solely compute fast fourier transform fft achieves significantly greater performance efficiency general purpose approaches 
application specific architectures poorly suited solving computing problems outside intended application area 
custom fft device example incapable performing computation fft designed 
operations fft performed system highly specialized device 
highly specialized devices discouraged economic reasons 
cases application specific architecture specialized limited appeal design manufacturing costs justified 
inflexibility devices specialized single operation mind 
application specific architectures routinely sacrifice performance efficiency provided architectural specialization greater flexibility 
programmable architectures particularly attractive function changed updating executing program 
programmability digital signal processor dsp example attractive computation fft higher performance custom device 
dsp compute fft perform countless important signal processing functions 
architectural specialization techniques involves classic tradeoff improvements efficiency loss flexibility 
specialized architecture application greater efficiency performance 
time specialized architectures flexible useful unrelated application areas 
lack flexibility specialpurpose architectures limits extent architectural specialization take place 
quotation suggests architectural specialization special purpose architectures limited economic factors technical advantages fundamental factor tool building enterprise trade generality performance 
cases generalpurpose tool cost effective particular case tool designed especially case 
practice trade usually decided economic factors extra application design cost special purpose device balanced lower efficiency general purpose device 
limitations overcome exploiting reconfigurability fpgas 
chapter describe circuit reconfigurability allows application specific architectures achieve greater levels specialization static full custom alternatives 
configurable computing examples demonstrate important principle 
important specialization techniques ccm systems reviewed 
reconfigurable computing economic factors limiting specialization overcome exploiting reconfigurability sram fpgas 
described section fpga provides unlimited reconfiguration logic resources 
circuit reconfiguration wide variety application specific circuits configured reconfigured fpga resource 
custom vlsi architectures add general purpose architectural features preserve flexibility fpga systems provide flexibility form circuit reconfiguration 
circuit reconfigurability allows development application specific architectures exploitation unique specialization techniques custom silicon devices 
example application specific computing architectures lack sufficient market interest justify development custom device 
architectures justified fpga fpga reconfigured useful architecture time 
reconfigurability fpgas allows development specialized computing architectures preserving architectural flexibility demanded economic constraints 
flexibility exploited computing machines reconfigurable fpgas 
architectures called custom computing machines organize fpga resources memory interfaces purpose application specific computing 
provide flexibility traditional computer allowing circuit reconfiguration number applicationspecific computing circuits programmed ccm reconfiguration 
time preserve efficiency performance specialpurpose architectures allowing fine grain circuit specialization 
reconfiguration fpga resources combines flexibility programmable architectures efficiency high performance application specific architectures 
custom computing machines successful ccm systems demonstrated significant performance computational efficiency wide range applications 
systems achieve high levels performance executing custom highly specialized computing architecture problem interest 
functional units data path control interfaces optimized application specific computing architecture operating system 
successful ccm systems include developed digital equipment paris research laboratory splash system developed supercomputer research center 
systems demonstrate significant performance improvements applications continue research community 
introduced brief description associated application examples 
dec perle perle successor perle demonstrate significant performance surprisingly wide range computing problems :10.1.1.137.6843
architectures comprise dimensional mesh fpgas coupled host workstation high speed system bus 
shown perle contains central matrix fpgas computation mb static ram edge array high bandwidth connection array host system 
configurable interfaces available creating links external physical devices 
host dec perle 
architecture designed accelerate application programs run host workstation loading computationally intensive tasks ccm array 
addition novel programming environment created allowing integrated development host program custom application 
perle architectures associated programming tools accelerate computationally challenging problems 
computationally challenging problems solved perle architecture listed table 
applications obtain significant levels performance specializing functional units control interconnect requirements problem 
ffl long integer multiplication ffl rsa cryptography ffl data compression ffl string matching ffl laplace equations ffl newton equations ffl neural networks ffl convolution ffl stereo vision ffl video compression ffl geometry ffl high energy physics ffl sound synthesis table dec perle applications 
src splash ccm demonstrating extremely high performance splash system designed supercomputer research center successor splash ii 
dec perle architectures splash attached host machine accelerate computationally intensive application programs 
splash ii architecture designed linear systolic array includes global bus simd processing crossbar application dependent interconnect structures see 
single board contains processing elements pe composed fpga local memory 
system scales adding boards linear systolic chain 
ease application development programming models created including vhdl simulation development environment logic description language simd programming model 
applications successfully demonstrated splash including crossbar splash array board sun sparc host dma xl dma xr splash interface board crossbar splash array board ram xilinx processing element src splash listed table 
applications demonstrate performance improvements specializing computing architecture problem interest 
ffl text searching ffl genetic database searching ffl image processing ffl convolution ffl custom floating point ffl genetic algorithms ffl automatic target recognition table splash applications 
perle splash architectures successfully demonstrate single ccm platform achieve impressive levels performance surprisingly wide range applications 
performance improvements achieved creating unique highly specialized computing architecture problem interest 
reconfiguration endless set application specific architectures executed platforms 
high levels performance wide variety computation possible fixed architecture systems 
custom asic designed perform computational variations applications listed example offer lower levels performance specialization techniques performance improvements obtained perle splash architectures available specializing structures computing architecture 
architectural specialization techniques consistently successful ccm applications 
section review ccm specialization techniques 
customizing functional units 
exploiting concurrency 
optimizing communication networks 
customizing interfaces 
techniques extensively custom vlsi architectures special emphasis technique reconfigurable technology 
customization functional units important techniques reconfigurable architectures specialization data path functional units 
resources required perform arithmetic logical operations reduced specializing functional units ways ffl functional specialization ffl customized precision ffl constant propagation 
functional specialization functional unit need reused wide variety operations specialized single arithmetic logical operation 
custom asic probably designed provide greater performance application set including special purpose circuitry applications 
inclusion special purpose circuitry large number wide range unrelated applications economically viable 
resources necessary create special purpose functions units need support large variety operations general purpose functional units 
logic specialized unique operation commonly general purpose functional units 
specialized functional units efficient series general purpose instructions performing operation 
examples unique operators implemented 
prism compiler provides custom hardware attached acceleration unit generates custom operators user supplied sequential code 
custom operators generated compiler include hamming distance calculation bit reversal function custom error correction units 
highly specialized operators achieve greater performance host processor modest amount fpga resources 
specialization precision significant hardware savings achieved optimizing arithmetic precision operation 
functional unit need reused parts algorithm precision operation fixed minimum required numerical representation 
minimum numerical representation results non standard word sizes numerical representation formats reduces hardware needed perform operation 
bit parallel multiplier example requires half hardware resources bit parallel multiplier 
ccm applications optimize numerical precision needs application 
arithmetic operators synthesized described dehon demonstrate improvements area timing optimizing precision 
custom bit floating point operators developed decrease size operators complex image processing system 
addition development tools allow specification custom numerical data types system description 
constant propagation way specializing functional unit propagate fold constant circuit 
operand functional unit change course computation significant hardware resources recovered propagating constant function 
registers decoding circuitry hold operand value removed 
addition constant input circuit allows standard logic minimization techniques remove additional hardware resources 
operations digital filters perform arithmetic logical operations fixed operand values entire computation 
ccm applications technique reduce hardware improve circuit speed 
digital filters designed fpgas propagate filter coefficients multipliers free hardware additional functionality 
dedicated iir filter shown fit half space generalpurpose counterpart 
application areas demonstrating technique fpgas include neural networks text searching 
exploitation concurrency advantage application specific architectures ability exploit concurrency 
exploitation concurrency shown reduce cost computation vlsi architectures 
computationally intensive problems solved real time constraints exploiting concurrency 
fortunately problems exhibit significant amounts concurrency amenable concurrent architectures 
efficient functional units described modest circuit resources exploit surprisingly high level concurrency 
systolic arrays example commonly tile hundreds fine grain pes achieve significant levels performance 
ccm applications demonstrating impressive improvements performance exploit massive concurrency 
example genetic sequencing application mapped splash platform achieves speedup cm supercomputer allowing special purpose processing elements operate concurrently 
addition long multiplication acceleration library developed dec perle architecture demonstrates multiplication rate faster known machine time 
accomplishes replicating large set digit serial multiplication processors 
optimized communication networks achieving high degree concurrency limited cost communication processing elements system 
applicationspecific architectures reduce cost specializing communication structures functional units natural flow data algorithm 
interconnecting functional units control memory manner reflects natural data flow problem balances computation facilitates exploitation massive concurrency 
ccm applications exploit rich interconnect resources fpgas customizing communication network concurrent pes functional units 
advantages network specialization seen reviewing calculation newton equations :10.1.1.137.6843
shown signal flow graph operation computes gravitational field acting body floating point operations 
floating point operators interconnected directed natural data flow problem operations may execute parallel 
computation requires significant aggregate bandwidth concurrently perform operations local connections operators significantly reduces external bandwidth requirements 
specialized operators interconnect application achieve impressive gflops 
custom interfaces special purpose computing problems complex unusual requirements 
situations general purpose standard interfaces frequently inadequate extremely inefficient 
interface developed specifically sensor example provide far greater bandwidth faster response time general purpose standard interface 
cases adding signal flow graph newton mechanics problem 
custom functionality bit packing word striping signal routing special purpose interface provides significant improvements system performance 
specializing interfaces ccm systems demonstrate significant improvements general purpose alternatives 
relatively small pamette ccm example system designed custom highbandwidth interfaces 
single pamette board supports significantly image bandwidth conventional components video sensor interfaces 
techniques interfaces include packing image pixels double buffering camera data support host dma image access 
pci variant pamette developed application specific testing measurement pci bus performance 
circuit configurations available measure bus activities generate custom bus traffic trace bus performance 
summary limiting architecture narrow application area avoiding architectural reuse specialization techniques maximize performance limited hardware resources 
limited target application specialized efficient architecture 
architecture application areas specialized efficient architecture 
quotation ganglion neural network project summarizes advantages limiting application range configurable computing machine narrowing function silicon specific application architecture allows extract maximum performance silicon potential 
chapter run time reconfiguration reconfigurability fpgas ccm systems allows exploitation extremely specialized computing structures 
addition traditional architectural specialization techniques vlsi circuits ccm applications specialized user input system parameters user preferences 
specialization techniques allow ccm applications achieve high performance surprisingly hardware resources 
specialization opportunities exploited particular ccm application greater computational efficiency performance 
ability exploit high levels circuit specialization extended specializing computing architectures run time circuit reconfiguration 
execution single ccm application circuit resources reconfigured take advantage dynamic conditions system 
run time reconfiguration circuit resources allows additional opportunities specialization available statically configured systems 
properly run time reconfiguration increase efficiency performance ccm system 
rtr appropriate ccm systems applications ccm applications may benefit run time circuit specialization 
chapter discussing application conditions amenable rtr follow providing complete survey rtr applications published literature 
survey briefly describe application system conditions motivate rtr 
chapter conclude identifying overhead configuration imposed rtr suggest specialization advantages obtained rtr balanced added configuration time 
opportunities run time specialization different conditions motivate run time circuit specialization presence idle underutilized hardware need partition large special purpose system limited fpga resource 
methods described detail 
temporal locality condition motivating rtr presence idle underutilized hardware ccm application 
run time reconfiguration remove idle hardware system replace useful circuitry 
run time removal hardware allows operation proceed fewer fpga resources possible static system 
rtr insure fpga resources efficiently 
individual sub systems circuit remain idle needed time immediately contribute computation 
data dependencies algorithm example may dictate operator wait completion different operation proceeding 
application specific operation may infrequently needed schedule computation 
waste hardware resources idle circuitry rtr improves circuit efficiency replacing idle circuits useful circuitry 
idle circuits application longer consume valuable resources application may operate fewer resources possible static non reconfigured system 
adding removing hardware run time increase virtual size hardware similar caching memory general purpose processor memory hierarchy 
technique optimizing active circuit resources run time dpga architecture maximize capacity utilization device 
run time reconfigured artificial neural network rrann exploitation temporal locality application specific computing architecture demonstrated artificial neural network developed byu 
neural network called run time reconfigured artificial neural network rrann implements popular backpropagation training algorithm fpga computing machine 
backpropagation algorithm iterative gradient search technique train node weights neural network 
iteration search method involves distinct phases feedforward backpropagation update 
feed forward calculates output values network current node weights backpropagation calculates error output node values differential activation function update stage recalculates neuron weights network error values 
iterative process shown repeated pattern training set network converges 
feed forward backpropagation update stages backpropagation training algorithm 
stage training algorithm requires data produced predecessor commencing operation 
update stage example may proceed backpropagation stage completed calculation node error values 
data dependency prevents simultaneous execution stages 
application specific architecture provides dedicated circuitry stages stages remain idle times 
rrann exploits temporal nature algorithm creating specialized circuit stages executing stage time 
run time fpga resources reconfigured special purpose neuron processor performing appropriate stage algorithm 
process reconfiguration special purpose feed forward backpropagation update neural processors shown 
special purpose processor provides functionality required single algorithm stage special purpose processors significantly smaller general purpose static processor implementing update update circuit circuit feed feedforward forward circuit circuit backprop 
backprop 
circuit circuit reconfigure reconfigure reconfigure run time reconfiguration special purpose neuron processors 
stages 
rrann project identifies reduction hardware developing general purpose neural processor implements algorithm stages set special purpose neural processors implement stages 
results analysis specializing neural processors single stage reduces size neural processor factor 
reduction hardware allows neural processors amount fixed fpga resources 
application described analyzed detail chapter 
partitioning large systems application specific circuits contain idle hardware exhibit temporal locality 
special purpose circuits deeply pipelined exhibit efficient hardware utilization 
appears run time reconfiguration offers advantages highly pipelined specialized ccm applications 
fact highly specialized ccm applications mapped platform demonstrate high hardware utilization rtr offers advantage 
situations highly specialized ccm application requires resources available fixed resource platform rtr may offer advantages conventional partitioning scheduling techniques 
large specialized fully pipelined circuit fit finite resources ccm circuit partitioned scheduled fixed static resource 
algorithms available assist system partitioning scheduling problem 
partitioning large circuit limited fixed resource reduces ability system exploit circuit specialization techniques described chapter 
single static architecture designed execute different algorithmic partitions sequential execution schedule general purpose support computational variations algorithm 
reuse hardware algorithmic partitions limits amount specialization take place forces inclusion general purpose architectural features 
example precision arithmetic operator partitions algorithm determined worst case precision requirements 
extra hardware required support worst case condition wasted operator computation requiring precision 
operators architecture support unique functional variations required algorithm 
addition data flow resulting architecture general purpose support variations data flow entire algorithm 
usually results efficient global communication structures multi ported register files centralized memory storage 
varied operations data flow algorithm general purpose efficient resulting architecture partitioned scheduled limited resource platform 
large special purpose computing systems require partitioning run time reconfiguration preserve special purpose nature algorithm 
providing static circuit generalized support computational variations algorithm algorithm partitioned special purpose circuits reconfigured run time 
preservation specialization allows computation occur efficiently general purpose alternative 
simple finite impulse response fir filter exploits run time reconfiguration preserve specialization demonstrate important point 
finite impulse response filter finite impulse response filter common operation performed discrete time signal processing systems 
time invariant linear operation calculated summing finite number weighted discrete time inputs follows gamma gamma custom hardware solutions employed operation ability exploit natural parallelism operation 
specifically multiply accumulate mac operations computed parallel mac units suggested 
signal flow graph concurrent fir filter 
dedicated multiplier available filter weights suggested filter weight input multiplier remains constant operation 
constant nature weights exploited propagating weights directly multiplication unit 
general purpose multiplier filter tap custom constant propagated multiplier suggested 
constant propagated multipliers consume significantly fewer resources general purpose counterparts 
fir filters constant propagated multipliers inflexible fir filter designed specific set filter coefficients useless fir filter different set coefficients 
configurable systems poses problems 
various constant propagated fir circuits reconfigured constant propagated special purpose fir filter 
configurable resources needed user 
configurable systems exploit constant propagation filter coefficients significantly reduce system resources 
dedicated filter shown fit half space general purpose counterpart 
advantages constant propagation available sufficient hardware resources available implement tap filter parallel 
insufficient resources available provide dedicated multiplier filter tap multipliers system reused filter tap 
example order compute tap filter limited resource circuit providing taps filter partitioned manageable sub parts suggested 
partition produces partial sum impulse response follows gamma lm gamma partition executed sequentially partitions completed 
execution partition filter weights circuit updated represent filter partition 
partitioning fir circuit 
fixed circuit compute operation reused partition system gamma filter weights circuit programmable 
tap tap circuit example perform multiplication weight partition second partition 
need support arbitrary weight value filter tap partitioned system eliminates ability exploit constant propagation 
suggested earlier chapter run time reconfiguration preserve special purpose nature constant propagated multipliers limited hardware system 
general purpose multipliers supports possible filter values efficient constant propagated multipliers reconfigured run time 
example fir filter taps partitioned limited circuit providing taps enjoy benefits circuit specialization exploiting circuit reconfiguration 
shown limited tap circuit configured special purpose multipliers weights partition 
partition completed taps reconfigured subsequent weights 
weights configured executed array 
ability modify circuit reconfiguration overcomes inability exploit circuit specialization limited hardware systems 
reconfigure reconfigure run time reconfiguration fir filter taps 
limited resource constraints sequence comparison circuit newton equations algorithm achieve improvements efficiency reconfigured run time 
run time reconfiguration offers benefits circuit specialization small cost sensitive environments forced efficient general purpose architectural structures 
applications described section exploit technique 
run time reconfigured applications applications successfully demonstrated advantages rtr 
applications exploit temporal locality algorithm system partition large circuits limited resource ccm platform 
rtr applications introduced described special emphasis run time specialization techniques employed application 
artificial neural network artificial neural network designed university strathclyde exploits advantages rtr 
rtr neural network preserve special purpose nature large specialized network partitioned limited array fpga resources 
specialized multi layered neural network reduces size neuron processor hard coding value synaptic weights 
pulse stream arithmetic synaptic pulse stream weights hard coded gating appropriate global chopping clocks custom arrangement gates 
hard coding technique requires hardware statically implement neuron processors 
hardware neuron processors general purpose support synaptic weight 
run time reconfiguration application preserve special purpose nature neuron processors system requiring partitioning 
multi layered neural network partitioned network layer boundaries layer network executed sequentially hardware 
run time hard coded synaptic weights reconfigured represent values associated layer executed 
intermediate results network layers stored global resources fpga 
video coding run time reconfiguration demonstrated wireless video coding application developed ucla 
basic operations coding application shown 
transform step discrete wavelet transform dwt augmented short integer arithmetic 
dwt followed scalar quantization run length encoding step 
entropy coding step added provide lossless compression 
quantization transform entropy encoding run length encoding 
image video coding algorithm 
operations operate parallel sufficient hardware memory bandwidth system partitioned sequentially executing phases order reduce hardware needed complete algorithm 
video coding algorithm implemented rtr preserve special purpose nature circuits computing algorithm phases 
algorithm partitioned custom circuits dwt quantization encoding entropy coding 
custom circuit exploits specialization techniques appropriate associated algorithm stage 
specialization techniques include application specific addressing units optimized hard wired control custom functional units 
run time reconfigured video coding algorithm mapped single national semiconductor clay fpga 
rtr reduced hardware required complete algorithm fpgas single fpga 
run time circuits sequentially configured executed fpga 
algorithm begins configuring dwt circuit fpga 
completing transform image circuit halts operation quantization rle circuit configured fpga 
completing operation image circuit execution stops fpga configured entropy encoder 
entropy encoding complete cycle continues available video frame 
variable length code detection rtr exploit temporal locality real time variablelength code detection application 
application huffman coding scheme detects presence variable length codewords input sample hard wired decoding circuit 
decoding circuit hardwired specific set codewords fax standard case binary decoding tree 
codewords detected allowing successive bits input steer signal binary decoding tree valid codeword 
example demonstrates decoding codeword custom decoding tree 
root sample hardwired decoding tree 
statistical properties codewords huffman code designed longer codewords codewords bits occur frequently shorter codewords 
example codewords typical documents encoded standard require maximum bits 
infrequent occurrence long codewords suggests upper bits specialized decoding tree remain idle long time 
temporal locality hardware exploited coding system paging hard wired decoding branches necessary 
static binary decoding tree limited bits provided decode bits incoming codewords 
codewords bits occur time static circuit active 
decoding process traverses sixth bit codeword rest appropriate decoding tree reconfigured hardware run time 
paging infrequently decoding branches hardware run time significantly fewer hardware resources needed complete decoding process 
automatic target recognition rtr automatic target recognition atr application developed ucla reduce hardware resources required computationally demanding template matching problem 
algorithm system correlation incoming grey scale synthetic aperture radar sar image data set binary target templates 
system exploits advantages fpgas specializing unique correlation circuit target templates 
sparseness binary target templates system significantly reduces hardware resources required complete correlation 
hard wired correlation circuit designed sparse template example requires far fewer resources general purpose correlation circuit designed correlate image template 
improve efficiency computation target templates similar spatial arrangements merged single custom circuit 
shown merging common templates allows sharing common resources correlation computation 
computational requirements system need correlate image extremely large set target templates 
computing correlation templates parallel possible reasonable amount hardware 
templates divided smaller manageable partitions 
correlation templates partition computed sequentially hardware resources 
hardware resources support correlation template template set special purpose correlation circuits static hardware 
preserve efficiency special purpose hardware fpga resources reconfigured run time appropriate template specific correlation circuits 
template specific correlation circuits reconfigured template template image scan lines merging similar templates adapted permission limited fpga resources template correlations complete 
run time reconfiguration template specific correlation circuits allows extremely specialized efficient template correlation circuits requiring hardware complete operations parallel 
stereo vision stereo vision algorithm mapped dec perle runtime reconfiguration 
circuit recursive software algorithm requiring tremendous amount computation 
hardware implementation algorithm divided distinct stages data acquisition correlation maximum detection 
data acquisition stage receives input external source stores data system memories 
correlation stage performs windowed correlation images offsets multiple depth levels offset 
stage scales correlated data division determines maximum correlation offset pipelined maximum detection circuit 
stage computation requires data previous stage proceeding 
requirement prevents simultaneous execution stages 
rtr reconfigure hardware resources circuits specialized stages 
intermediate results produced consumed circuit partitions buffered host transferred high speed turbo channel interface 
notwithstanding need reconfigure fpga resources run time system improves performance factor dedicated dsps factor sparc station ii 
dynamic instruction set computer disc simple programmable processor created author support run time reconfiguration special purpose computing structures 
system called dynamic instruction set computer disc allows user program determine sequencing custom instruction units 
run time reconfiguration custom instructions allows small array fpga resources implement large special purpose algorithms 
details system described chapter appendix image processing routines exploiting rtr implemented architecture 
object thinning application example demonstrated performance improvements software program implementing computationally intensive operations custom hardware 
algorithm partitioned stages input filtering histogram generation peak detection thresholding iterative thinning 
stages executed sequentially combination custom deeply pipelined circuits general purpose programmable functional units 
run time reconfiguration circuits allowed computation complex algorithm modest array fpga resources 
configuration overhead run time reconfiguration provides opportunities circuit specialization available static systems additional time required computation circuit reconfiguration 
static specialization techniques reconfigure circuit resources line computation run time specialization techniques require reconfiguration occur line computation 
circuit reconfiguration occurs computation reconfiguration time critical parameter rtr system performance directly affected circuit reconfiguration time 
time reconfigure today fpga devices order milliseconds 
long time orders magnitude longer time required complete individual operation 
reconfiguration carefully sparingly 
careless reconfiguration easily mitigate advantages obtained greater levels specialization 
applications reduce effects reconfiguration time executing long periods time reconfiguration 
stereo vision application example involved actual computation times long associated reconfiguration time 
run time circuit reconfiguration involves trade improvements efficiency due run time circuit specialization addition configuration time 
rtr advantages run time circuit specialization outweigh disadvantages configuration time 
chapter describe method introduced dissertation balancing advantages run time circuit specialization disadvantages configuration time 
chapter analysis run time reconfigured systems cases run time reconfiguration allows ccm system exploit greater levels specialization possible statically configured systems 
advantages specialization techniques include reduction circuit area execution time required complete computation 
advantages balanced added time required circuit configuration 
fortunately advantages rtr associated costs added configuration time measured allow quantitative analysis guide 
chapter introduce define new metric termed functional density balances reduction circuit area obtained rtr associated configuration time 
introduced section metric area time costs required complete computation 
section augment functional density metric run time reconfigured systems including cost circuit reconfiguration 
measuring functional density run time reconfigured systems facilitates comparison run time reconfigured applications conventional static approaches 
section describe various ways functional density metric evaluate run time reconfigured systems 
functional density metric important contribution evaluate rtr applications chapter disc system chapter configuration improvement techniques chapter 
functional density benchmarks general purpose computers speed response time computation 
shorter response time latency computation desirable computer architecture 
performance metrics general purpose computers reflect emphasis specifying performance inverse execution time required complete computation performance latency execution time architectural enhancements strive increase measurement performance reducing execution time latency computation 
common measure performance throughput computation 
response time measures absolute time complete computation throughput measures rate computation 
throughput frequently measured dividing number operations time required complete computations performance throughput number operations fixed time throughput important real time computing environments sustain minimum rate computation 
examples important throughput measurements include instructions second general purpose processors samples second discrete time signal processing environment polygons second graphics application frames second video processing environment 
performance enhancing architectural techniques systems strive increase rate computation 
cost sensitive benchmarks cases performance enhancements available cost 
computing environments cost sensitive balance improvements performance associated costs 
cost performance metrics frequently measure trade 
cost performance metrics usually calculated dividing performance computation measurable cost 
cost associated improved performance measured ways depends specific constraints system 
example cost measured monetary value dollars power watts circuit area um design time 
metrics proposed balance performance cost 
cost performance metrics include mips watt mips um mips dollar 
metrics available measuring cost computation ccm platform straightforward cost measurement amount logic resources required complete computation 
fpga systems logic resource cost measured terms fpga specific logic element count clbs cells physical hardware area computation um 
logic resource physical area cost generalized simply area required computation 
circuit area cost cost performance ccm application simply performance application divided area ccm cost performance performance cost execution time circuit area measurement provides performance unit area logic resources density computation fpga resources 
cost sensitive metric termed functional density measured inverse area time product follows metric similar area time cost metric commonly evaluate efficiency vlsi circuits 
cost sensitive metrics functional density evaluate cost effectiveness improvements modifications existing architectures 
analysis involves cost performance comparison architectures existing base architecture proposed architectural improvement 
architectural enhancement undoubtedly improve performance type analysis balances increased performance associated costs 
improvements improve cost effectiveness computation justified 
budget constrained analysis investigate cost effectiveness increasing width processor datapath 
cost sensitive analysis rtr systems functional density evaluate effectiveness run time specialization technique 
specifically functional density run time reconfigured circuit compared static non configured circuit 
run time specialization technique provides functional density improve cost effectiveness computation 
improvement functional density circuit employing run time reconfiguration evaluated measuring normalized difference functional density run time reconfigured system rtr static alternative follows deltad rtr gamma rtr gamma improvement measured percentage multiplying 
functional density run time reconfigured system greater static system rtr improvement positive run time reconfiguration justified 
added overhead imposed configuration reduces functional density static circuit rtr negative run time reconfiguration difficult justify 
functional density run time reconfigured systems order compare functional density run time reconfigured system static system functional density metric equation augmented run time reconfigured systems 
system exploiting run time reconfiguration requires additional time system support bandwidth 
issues important costs rtr system functional density metric include added time circuit reconfiguration 
traditional static circuit specialization techniques run time circuit specialization requires additional time circuit reconfiguration 
circuit execution halt reconfiguration conventional fpgas support simultaneous reconfiguration execution configuration circuit resources decreases performance application adding configuration time total operation time system 
total operational time run time reconfigured systems includes execution time configuration time follows configuration time device specific parameter addressed chapter 
functional density run time reconfigured system rtr obtained substituting execution time equation functional density metric equation clear equation configuration time reduces functional density circuit reconfiguration time increases functional density decrease 
configuration ratio absolute configuration time system important parameter rtr systems ratio configuration time execution time informative 
ratio termed configuration ratio obtained dividing configuration time rtr system associated execution time configuration ratio important parameter run time reconfigured applications extensively analysis applications chapter 
total operation time rtr system expressed terms configuration ratio systems propose configuration circuit resources circuit execution 
issue addressed chapter 
substituting equation original functional density metric provides functional density metric terms suggested equation long configuration times tolerated followed correspondingly longer execution time 
systems operate large data sets exhibit coarse granularity run time reconfiguration configure infrequently major computation steps shown tolerate relatively long configuration times today devices 
limit ae overhead imposed configuration negligible 
systems approach maximum functional density available rtr system 
maximum value max calculated ignoring effects configuration time follows max lim functional density equation represented terms max replacing term max max clearly functional density rtr system continually degrade configuration ratio increases 
degradation functional density maximum value max plotted function configuration ratio 
identifiable regions 
functional density left area graph near maximum 
occurs configuration time significantly smaller execution time changes little effect functional density 
right region configuration time dominates total operation time 
functional density diverges max changes significant impact functional density 
improvements configuration time significantly increase functional density 
clear separation regions functional density reach max falls gamma 
max indicating execution time times configuration time 
maximum functional density functional density configuration time execution time functional density dmax degradation dmax vs architectural analysis benefits limitations run time reconfigured applications analyzed measuring functional density statically configured run time reconfigured systems 
section describe approach analyzing run time reconfigured applications functional density metric 
analysis determine appropriateness rtr justify rtr conventional implementation approaches identify overhead imposed circuit configuration application considering rtr 
important reiterate analysis run time reconfigured applications include comparison static alternative 
run time reconfigured applications published comparison conventional static approaches lack comparison hides advantages disadvantages offered rtr 
run time reconfiguration common technique ccm machines improvements traditional approaches shown 
approach analyzing run time reconfigured applications thesis comparison run time reconfigured implementation conventional static alternative performing function ccm platform 
application specific circuit parameters step analysis run time reconfigured application obtain application specific parameters needed compute functional density run time static implementation approaches 
parameters include performance tn circuit area configuration time 
obtaining values may require complete design timing analysis circuit implementations 
alternatively may involve estimation known circuit parameters sub modules design 
case performance area measurements implementation approaches form basis analysis 
cases application specific parameters depend size scope computation 
execution time example depend amount data processed application sample size string length 
size circuit depend scope problem 
dna sequencing circuit described section example requires distinct processing element character source sequence 
cases functional density application function size scope problem 
calculating configuration overhead imposed rtr version application helpful understand maximum benefits available rtr 
understanding maximum benefits rtr provides early indication appropriateness rtr application effects configuration considered 
maximum improvement max defined improvement offered maximum functional density max see equation static approach follows max max gamma rtr applications large potential improvement functional density candidates run time reconfiguration 
comparing functional density suitable application specific circuit parameters available static rtr implementation approaches functional density systems compared 
run time reconfigured approach justified provides functional density static alternative 
run time reconfigured version application improves functional density reduction circuit resources due run time specialization significant overhead imposed circuit configuration 
conditions run time reconfiguration improves functional density investigated examining relation rtr representing area execution time run time reconfigured circuit relation reduced follows rtr relation simplified substituting max follows max gamma left hand side relation maximum improvement possible rtr see equation 
substituting max equation produces relation max equation important result describes maximum allowable configuration ratio rtr system 
relation states order run time reconfigured system provide functional density static alternative configuration ratio maximum potential improvement max run time reconfigured system 
intuitively relation equation suggests greater potential advantage run time reconfigured circuit stringent configuration overhead limitations 
run time reconfigured circuits providing substantial improvements efficiency sensitive configuration time providing marginal potential improvements 
run time specialization techniques provide significant improvements efficiency justify rtr light poor configuration performance today devices 
result suggests systems providing modest improvements rtr justified long configuration ratio low 
example functional density demonstrate analysis approach consider static circuit requiring circuit area time complete operation 
suppose run time reconfigured circuit performs computation half area thirds time 
summarized table maximum improvement rtr circuit 
equation result suggests rtr circuit provide greater functional density static circuit long configuration time twice execution time 
max max static rtr table example circuit parameters functional density 
demonstrate effects configuration time example functional density run time reconfigured system represented terms maximum functional density max configuration ratio suggested equation 
functional density example plotted function functional density static alternative maximum value max low configuration overhead functional density example near maximum max configuration overhead increases functional density decreases falls functional density static system 
consistent result obtained point systems provide functional density occurs 
configuration overhead increases break point functional density run time reconfigured system static circuit 
maximum functional density functional density static functional density configuration time execution time functional density dmax example functional density comparison 
analysis approach introduced chapter demonstrated simple example evaluate rtr actual ccm applications 
steps summarize analysis rtr systems 
obtain area performance measurements static runtime reconfigured systems 
compute maximum improvement max run time reconfigured circuit circuit parameters obtained 
determine maximum configuration ratio max allowable system max 
determine configuration time intended fpga 
compute determine max max problem sizes interest rtr justified rtr justified 
rtr may justified functional density factors considered employing rtr system 
added design time configuration bandwidth support circuitry needed implement rtr may mitigate actual system 
analysis focus primarily improvements functional density provided rtr systems 
analysis approach listed demonstrate advantages rtr applications chapter 
chapter applications chapter demonstrate analysis technique previous chapter measuring functional density run time reconfigured applications 
application mapped existing fpga technology demonstrates improvements functional density exploiting rtr 
applications study include ffl run time reconfigured neural network ffl partially run time reconfigured neural network ffl template matching circuit ffl dna sequencing circuit 
applications implementation approaches static non configured circuit run time reconfigured circuit 
functional density calculated approach determine run time reconfiguration improves functional density application 
calculating functional density application require circuit parameters logic resource utilization execution time 
addition configuration time required run time reconfigured circuit 
cases calculation parameters depend size desired computation network size image size dna sequence length 
analysis applications chapter involve modeling evaluation functional density system parameters 
run time reconfigured artificial neural network run time reconfigured neural network rrann applications demonstrate improvements circuit density exploiting run time circuit reconfiguration 
introduced earlier chapter application implements popular backpropagation learning algorithm custom hardware 
rtr application reconfigure system hardware neurons special purpose neural processors customized backpropagation stages see 
reduction size associated run time specialization allows times special purpose neurons operate amount hardware static general purpose neuron 
rrann project demonstrates increase neuron density developing comparing static non configured neural network run time reconfigured neural network 
approaches designed tested ccm platform provide fair comparison fpga resource required approach 
addition negative effects configuration time considered comparing approaches 
discussion extend analysis rrann applying analysis approach described previous chapter 
functional density metric analysis identify rtr justified neural network architecture 
analysis rrann architecture investigate benefits rtr rock vs mine target application described 
network application requires neuron layers neurons layer neurons second layer neurons layer 
rrann system architecture identifying application specific parameters necessary computing functional density rrann necessary review system architecture rrann describe system scales additional neurons 
rrann architecture designed scale network size limiting growth hardware interconnection execution time network 
size network important system parameter affects hardware resources execution time ultimately functional density computation 
rrann architecture consists global controller array fpga neural processors 
shown global controller neural processors communicate series global system busses 
neurons network interconnected time multiplexed scheme order limit growth interconnect hardware required network 
time multiplexed interconnection scheme limits growth execution time hardware area number neurons layer network 
adding neurons network lengthen execution time require hardware resources 
pc host neural processor fpga ram broadcast bus error bus neural processor fpga ram global controller fpga ram data control bus system architecture rrann 
area execution time rrann determined number neurons network functional density rrann depend size network 
sections describe application dependent circuit parameters needed calculate functional density specify parameter terms neurons required largest layer system 
network specific parameters applied neuron rock vs mine application mentioned 
performance training performance network throughput measurement weight updates second wups 
performance measurement dividing number weighted connections synapses network time required update weight time complete complete iteration training algorithm wups parameters function number neurons system 
weighted connections number weighted connections neural network determined number layers network number nodes layer nodes follows gamma nodes theta nodes purpose simplifying analysis assumptions ffl network consists layers ffl layers contain number nodes nodes 
assumptions reduce calculation connection count number neurons largest layer 
network neurons layer example contains weighted connections synapses 
execution time execution time required complete computation entire iteration algorithm static rtr versions 
execution time obtained multiplying clock cycle count single iteration algorithm clock frequency 
clock cycle count determined number non output neurons network number layers follows adapted equation cycle count gamma nodes theta gamma theta accurate equation described considers quantization errors associated larger networks 
added execution time required address quantization error negligible effect results analysis 
multiplying cycle count clock rate applying assumptions stated nodes reduces execution time iteration algorithm clk clock cycle mhz clk ns network neurons layer requires ms execute algorithm complete iteration 
composite performance rrann network computed dividing connection count execution time clk training connections neurons layer network example requires ms composite performance theta wups 
run time reconfigured network execution time single iteration algorithm require configuration steps 
circuit reconfiguration network idle computation takes place 
account reconfiguration total execution time rtr circuit add time required reconfiguration steps 
added configuration time reduces performance network follows clk area cost complete computation functional density rrann area costs approach known 
area circuit execution time depends number neurons system 
total area consumed network includes area global controller gc area consumed neuron network gc na original analysis rrann area circuit measured terms number xilinx fpgas 
analysis measure area terms number xilinx series configurable logic blocks clbs design 
clb count fpga count area measurement offers advantages 
measuring circuit area terms fpga count introduces quantization error 
unused resources fpgas unnecessarily attributed computation 
second specifying particular fpga area measurement limits analysis specific fpga device 
measuring area terms clbs allows application analysis fpgas fpga family 
clb resources required global controller various neural processors listed table 
global controller neural processors clbs clbs neurons clbs neuron static system feedforward backpropagation update estimated table rrann circuit parameters 
assuming estimated clbs global controller static system total hardware area global controller neural processors calculated follows static measuring area run time reconfigured case slightly complicated 
run time reconfigured approach uses different neural processors different hardware requirements 
hardware required neural processor varies clbs update processor clbs feedforward processor 
run time resource utilization system change system configured various phases algorithm 
account differences area area largest neural processor 
area largest processor resources available neural processors fewer resources idle purposes 
update phase largest global controller clbs feedforward phase largest neural processor clbs 
total area run time reconfigured system rtr savings hardware area due run time reconfiguration reduces clb requirements network clbs 
functional density functional density systems calculated combining performance area cost measurements obtained 
performance measurement equation area cost equation functional density static system determined follows static clk functional density run time reconfigured system obtained combining performance measurement equation efficient area measurements equation follows rtr clk functional density static network neurons layer achieves weight updates second clb wups clb 
maximum functional density max ignoring effects configuration time 
maximum functional density network achieves value wups clb 
investigating effects configuration overhead functional density run time reconfigured circuit important identify maximum benefits available rtr 
maximum improvement available rtr max obtained substituting functional density results maximum improvement equation max max static gamma gamma maximum improvement run time reconfigured network improvement statically configured counterpart 
circuit parameters maximum functional density static rtr implementation approaches neuron network listed table 
static rtr neurons layer connections ms wups theta clbs max wups clb max table circuit parameters neuron network 
maximum improvement suggests rrann potential offer significant improvements static alternative 
large improvement due run time reconfiguration indicates application excellent candidate rtr 
result indicates iteration neurons layer rrann architecture tolerate configuration time times execution time provide greater functional density static alternative 
ms execution time required iteration backpropagation algorithm ms additional time spent configuring fpgas provide functional density static alternative 
configuration overhead early evaluations application indicate rtr provides significant improvements actual configuration overhead considered 
configuration rate rrann limited configuration time associated xilinx fpgas 
fortunately fpga board rrann allows parallel configuration fpgas system 
allows configuration time system remain constant networks size configuration step required configure hardware resources phases backpropagation algorithm 
serial slave mode single fpga requires ms configure configuration bits mhz serial interface 
reconfiguration steps require total ms unfortunately reconfiguration time larger maximum allowable configuration time 
configuration time ms times execution time configuration ratio 
substituting configuration time functional density equation reduces functional density maximum value wups clb wups clb 
due excessive configuration overhead functional density run time reconfigured approach lower static approach see table 
ms rtr table configuration overhead neuron network 
configuration time network neurons layer reduces functional density rtr approach functional density static version configuration overhead reduced increasing size network 
configuration time constant execution time increases network size configuration overhead decrease size network increases 
reduction configuration overhead demonstrated dividing fixed configuration time ms execution time equation ms clk true networks fit single board 
multiple boards required configuration bandwidth limited system bus interface 
theta reduction configuration ratio shown plotting function network size clearly configuration ratio declines network size increases 
maximum improvement imax configuration ratio neurons layer configuration overhead rrann 
plotted configuration ratio maximum improvement max equation 
described chapter rtr justified configuration ratio maximum improvement max seen networks sufficient size drop max justify rtr 
rtr justified neuron network networks sufficient size execute long overcome overhead imposed configuration time 
break point functional density static approach equals rtr approach setting functional density run time reconfigured circuit equal functional density static circuit solving rtr static clk ms clk reconfiguration overhead run time reconfigured circuit limits benefit rtr networks neurons layer 
networks larger neurons layer rtr provide functional density static approach 
summarizes effects network size functional density rrann architecture 
plotted functional density rtr approach functional density static non configured circuit maximum functional density rtr approach 
important facts confirmed plot 
rtr reduces functional density system 
second functional density rtr approach increases network size equals static approach 
third network sizes greater neurons layer functional density continues improve approaches maximum functional density max improvement static approach 
run time reconfiguration rrann application significantly reduces hardware requirements neural processors backpropagation algorithm 
rrann demonstrates increase neuron density exploiting run time reconfiguration 
significant configuration overhead required rrann limits rtr networks neurons 
requirement suggests rtr appropriate rock vs mine neurons 
configuration time reduced rtr justified neural network applications 
partially run time reconfigured artificial neural network rrann architecture demonstrates significant reduction hardware density run time reconfiguration rrann achieve maximum functional density rtr functional density static functional density neurons layer functional density rrann 
significant improvements functional density large sized neural network 
failure improve functional density due extreme sensitivity rrann architecture configuration time 
address issue second rrann architecture rrann ii developed 
rrann ii designed exploit reduced configuration time partial reconfigurability improved configuration bandwidth available national semiconductor clay fpga 
architectural modifications rrann ii designed solve algorithm original rrann architecture 
backpropagation algorithm partitioned sequentially executing phases feedforward backpropagation update 
addition scalable system architecture depicted rrann ii 
major difference rrann ii predecessor partially configurable clay fpga 
development board clay fpga modified implement rrann architecture described 
algorithm implementation approach rrann ii similar original rrann architecture analysis rrann ii similar analysis original rrann architecture 
functional density metric analyze viability neuron layer rock vs mine application described earlier 
rrann ii analysis section focus benefits partial configuration 
variations run time reconfigured circuit compared static non configured baseline architecture 
globally configured circuit reconfigures circuit resources algorithm steps 
traditional global rtr approach original rrann architecture 
second rtr variation partially configured circuit configures changes algorithmic steps 
comparison identify advantages provided partial configuration 
partial configuration partial configuration available fpga families allows configuration subset logic resources fpga 
requiring user configure fpga resources small pieces fpga configured needed 
run time reconfigured systems feature provides important advantages 
ability configure subset device reduces amount configuration data required reconfiguration step 
reduction configuration data directly reduces effective configuration time 
second ability preserve circuitry fpga resources configuration allows crucial state information saved device configuration 
avoids overhead loading storing system state circuit configuration steps 
rrann ii architecture attempts extend advantages rtr exploiting advantages 
exploit advantages partial reconfiguration rrann ii identifies similarities specialpurpose neural processors 
special purpose processor designed share hardware possible limit amount configuration data required convert processor 
order design system partially configurable project required considerable hand layout manual design 
design step project manual placement common circuit functions neural processors 
circuits shared processors remain static computation require circuit reconfiguration 
common circuit functions rrann ii include address generation units accumulator registers overflow underflow detectors basic control 
mapping shared functions circuits unique neural processor identified designed 
circuits unique neural processor include global neural processor control multiplier fixed constants 
circuit modifications carefully designed mapped interact properly static logic remains fpga times 
reconfiguration time reduced approach limiting circuit reconfiguration circuit modifications 
hand layout circuit produced efficient highly optimized design 
system circuits operate mhz achieve unusually high utilization fine grain fpga resources 
static neural processor contains neurons single fpga 
run time reconfigured neural processor offers advantages increased specialization increases neuron density neurons fpga 
performance rrann performance rrann ii measured terms weight updates second wups specified equation 
connection count rrann ii slightly different connection count rrann 
rrann ii adds bias nodes increase networks ability learn 
addition bias node indicated term connection count gamma nodes gamma theta nodes making assumptions rrann layers neurons layer connection count reduces modified equation connection count increases number synapses neuron network 
cycle count required execute phases backpropagation specified terms network size 
adapted equation cycle count rrann ii specified follows cycle count gamma gamma total execution time calculated applying assumptions nodes multiplying clock period clk extra cycles required rrann ii due addition bias nodes deeper pipelining circuit 
deep pipeline allows circuit operate mhz clk ns reduces total execution time neurons layer network ms composite performance rrann ii system dividing connection count execution time clk performance static version training algorithm neuron network theta wups 
area cost compute functional density rrann ii area circuit known 
clay fpga rrann ii requires measure area terms clay cells 
total area computation includes area global controller neural processors suggested global controller neural processors cells neurons cells cells neuron static system feedforward backpropagation update table rrann circuit parameters 
equation 
area requirements global controller neural processors listed table terms clay cells 
global controller static run time reconfigured system consumes cells global controller fpga 
neural processors differ size 
static non configured neural processor consumes cells processors operating clay fpga 
total area consumed static circuit run time specialization neural processors reduces amount hardware required complete algorithm 
specialized neural processors example fit clay fpga 
neural processors fit fpga actual cell count neural processor differs 
neural processor largest cell count backpropagation free hardware resources stages productively 
total area consumed run time reconfigured circuit neuron network run time reconfiguration reduces hardware requirements cells cells 
functional density functional density metric static run time reconfigured circuits computed substituting performance area cost metrics obtained 
functional density rrann ii measured terms weight updates second cell wups cell 
functional density static circuit obtained dividing performance measure equation area cost equation static clk functional density neuron network operating static system wups cell 
functional density metric run time reconfigured system obtained augmenting performance measure equation reconfiguration time reduced area 
area cost efficient run time reconfigured circuit equation functional density reduces rtr clk zero configuration overhead maximum functional density run time reconfigured neuron network wups cell 
knowing overhead imposed circuit reconfiguration maximum improvement run time reconfigured circuit 
maximum improvement offered rtr substituting functional density systems maximum improvement equation max gamma maximum improvement rtr approach rrann ii 
execution time ms maximum allowable configuration time run time reconfigured system ms see equation 
circuit parameters static rtr implementation approaches listed table 
configuration overhead predecessor advantages offered rtr rrann ii limited circuit reconfiguration time 
rrann ii designed static rtr neurons layer connections ms wups theta cells max wups cell max table rrann ii circuit parameters neuron network 
reduce configuration overhead exploiting higher configuration bandwidth clay fpga partial reconfigurability device 
rrann ii investigate advantages global rtr partial reconfiguration 
section address reconfiguration time global partial run time reconfigured implementation approaches identify effects reconfiguration times functional density 
reconfiguration time rrann ii limited parallel reconfiguration neural processor fpgas single clay fpga requires ms complete reconfiguration reconfiguration steps consume total ms complete iteration training algorithm 
byte wide configuration path clay device allows configuration occur times faster configuration time original rrann project 
fortunately configuration time globally configured approach slightly lower maximum allowable configuration time ms insures globally reconfigured approach provide functional density non configured static alternative 
substituting configuration time ms equation functional density wups cell achieved improvement static alternative 
fpga boards configuration board rrann ii limited host system bus 
rrann ii analysis assumes configuration limited device configuration constraints bus bandwidth limitations 
partial configuration suggested earlier major purposes rrann ii project reduce excessive configuration time rtr systems partially reconfiguring circuit resources 
limiting configuration fpga circuit changes amount data required configuration significantly reduced 
reducing configuration data directly reduces time required circuit reconfiguration 
rrann ii investigates benefits technique reconfiguring changes needed convert neural processors phase 
example reconfiguring fpga resources feedforward neural processor backpropagation neural processor accomplished bytes fewer configuration bytes needed full configuration step 
reduction configuration data neural processors shown table 
total reconfiguration time partially reconfigured system reduced ms ms reduction configuration time 
configuration bit stream time reduction total size bytes ms complete fpga feed forward backpropagation backpropagation update update feed forward table rrann ii partial bit stream sizes 
reducing configuration time partial configuration increases functional density neuron network 
applying configuration time ms equation functional density partially reconfigured system increases wups cell 
represents improvement static implementation approach 
improvement functional density global partially reconfigured systems listed table 
global partially configured circuits improve functional density neuron network important investigate effect network size functional density 
additional neurons added global rtr partial rtr ms rtr table improvement functional density rrann ii 
system execution time increase 
constant configuration time configuration ratio correspondingly decrease 
plots decrease configuration ratio function network size 
plotted configuration ratio maximum improvement rrann ii architecture 
areas configuration ratio max rtr justified 
lower reconfiguration time partially configured system reduces break point justifies smaller networks partially reconfigured system 
break points systems evaluated setting functional density static circuit equation equal functional density run time reconfigured circuit equation solving configuration time ms globally configured circuit break point occurs network size neurons 
partially configured circuit ms break point reduced neurons 
lowering breakeven point allows smaller sized networks benefit run time reconfiguration 
effects network size functional density approaches summarized plotting functional density static circuit functional density partially configured circuit 
addition maximum functional density run time reconfigured circuit shown 
important advantages partial reconfiguration demonstrated plot 
shorter configuration time partially reconfigured system insures functional density greater globally configured counterpart 
second important break rtr justified lower partial reconfiguration global reconfiguration 
maximum advantages rtr rrann ii maximum improvement imax partial configuration ratio global configuration ratio neurons layer configuration overhead rrann ii 
architecture lower predecessor rrann shorter configuration time rrann ii ability exploit partial reconfiguration allows smaller useful networks enjoy benefits rtr 
template matching template matching common operation object target recognition systems identify regions interest 
operation requires significant computation performance bottleneck target recognition systems 
template matching systems brute force correlation compute cross correlation incoming images set target templates 
template size theta cross correlation maximum functional density globally reconfigured system partially reconfigured system static system neurons functional density rrann ii 
image computed location follows gamma gamma image size theta multiply accumulate operates required correlate image template 
small number templates correlated input image special purpose correlation circuit designed template interest 
described appendix template values propagated directly hardwired correlation circuit improve efficiency computation 
exploiting constant propagation reduces size circuit allows computation take place fewer resources 
technique undoubtedly increases functional density computation 
correlation circuit specialized single template limits flexibility system 
inflexibility custom correlation circuit required template template set 
large template sets approach impractical immense amount hardware required implement custom correlation circuit template image set 
example single template class sandia automatic target recognition system requires correlation templates input image 
tremendous amount hardware required provide separate custom correlation circuits template images 
instances template set large provide separate custom circuit template template set may partitioned smaller manageable template subsets 
template subsets sequentially programmed executed limited hardware resources 
approach forces general purpose correlation circuit support image template 
general purpose correlation circuits require resources cost effective constant propagated alternative 
described earlier section run time reconfiguration preserve special purpose nature computation faced limited hardware resources 
template matching computation run time reconfiguration preserve special purpose nature circuit described appendix section discuss analyze run time reconfiguration bit serial template matching circuit introduced described appendix system architecture automatic target recognition system sandia national laboratories involves computationally intensive stages focus attention second level detection final identification :10.1.1.17.6915
template matching system described section second level detection stage system 
templates system limited binary precision reduce computational requirements correlation operation 
binary template values equation replaces multiplication simple operation 
templates theta input images theta 
architecture implement correlation operation equation dimensional array conditional bit serial adder pes shown 
size array bit serial adders size template image conditional adder represents specific pixel template image 
templates size example require corresponding array pes 
details general purpose special purpose implementation approaches associated circuit details described appendix parallel computation correlation 
initiating correlation computation array bit serial adders programmed value corresponding template pixel 
template pixel corresponding pe performs bit serial addition 
template bit pe performs simple cycle delay 
example array programmed particular template image demonstrated 
versions architecture designed general purpose correlation circuit supports user defined template special purpose correlation circuit specialized single template image 
pe general purpose circuit programmable bit serial adder supports template image array function array correlation pes programmed specific template image 
correlation functions 
pe shown performs conditional bit serial addition value internal template register 
value template register enables bit serial adder value disables addition 
reprogramming circuit built pe requires reloading template bit pe array 
mapped clay fpga pe requires cells internal delay ns 
carry sum template sum sum general purpose conditional bit serial adder 
special purpose correlation circuit designed specialpurpose pes special purpose pe case special purpose pe cell cell sum sum sum carry sum sum sum special purpose conditional adders 
case 
shown pe optimized template pixel value designed 
pe performs unconditional addition dedicated bit serial adder 
optimizing pe case allows removal template bit storage register multiplexer gate 
mapped clay fpga pe consumes cells operates shorter internal delay ns 
pe provides simple delay function single flip flop 
sum flip flop needed perform function 
simple function requires single clay cell operates delay ns 
pe operate slower pe actual operating speed pe limited ns 
improvements area time special purpose pes listed table 
processing element size critical path cells ns general purpose special purpose special purpose table circuit parameters correlation pe 
special purpose circuit programmed specific template image reconfiguring arrangement special purpose pes specified template image 
reconfiguration process consumes time reprogramming general purpose pes 
analysis functional density metric balance reduction hardware achieved special purpose circuit corresponding reconfiguration overhead 
performance performance system measured terms correlations second cps correlation defined calculation single correlation pixel value indicated equation 
performance measured dividing number valid pixels output image execution time required complete correlation operation entire image 
valid pixels resulting correlated image occur template image input image completely overlap 
size output image gamma theta gamma input image size theta template image size theta theta images sandia atr algorithm require correlation operations correlated theta template 
execution time correlation operation size input image template image 
operation performed bit serial arithmetic execution time depends size bits correlation result 
maximum bit correlation result total execution time operation gamma delta clk execution time required correlation theta input image theta template ms general purpose pes 
slightly faster special purpose pes execution time reduces ms performance system obtained dividing size correlated image associated execution time follows gamma gamma gamma clk gamma mt clk performance run time reconfigured system include cost circuit reconfiguration 
reconfiguration time added execution time follows rtr gamma gamma gamma clk gamma mt clk gamma area cost area circuit depends size template image 
described earlier correlation circuit requires pe pixel template image 
size circuit simply number pixels template image multiplied area pe nma pe theta template images sandia atr system cells required 
listed table clay cells required implement general purpose pe 
complete circuit composed pes requires total fpga cells 
size special purpose pes differ cases larger cell pe area measurements 
complete array special purpose pes requires fpga cells area improvement 
functional density functional density general purpose template matching operation obtained dividing performance equation area follows gamma mt gp clk nma gp substituting area cells template size theta reduces functional density gamma delta mt gp clk image size theta general purpose circuit provides functional density cps cell 
functional density run time reconfigured circuit obtained dividing performance run time reconfigured system area follows rtr gamma mt clk gamma nma sp substituting cells area theta template size reduces functional density rtr gamma mt rtr clk gamma reconfiguration time ignored maximum functional density run time reconfigured circuit max cps cell theta image 
values max obtained maximum improvement run time reconfigured circuit calculated 
relatively modest value max places strict limits maximum reconfiguration time 
execution time ms ms allowed circuit reconfiguration 
circuit parameters improvement offered rtr application summarized table 
static rtr image size theta theta correlations ms cps theta theta cells max cps cell max table functional density template matching circuit theta image 
configuration overhead circuit reconfiguration required special purpose template matching system modify hard wired template image 
system partial reconfiguration reduce reconfiguration time 
reconfiguring entire array pes partial reconfiguration reduces reconfiguration time reconfiguring pes change 
demonstrated configuration approach significantly reduces amount configuration data required convert template array 
partial configuration correlation array 
reconfiguration time circuit depends number specialpurpose pes requiring reconfiguration 
pes required configuration longer configuration time 
reconfiguration single cell specialpurpose pe requires transfer configuration bytes 
reconfiguration rate mb sec cells configured total configuration time simply number pes requiring reconfiguration multiplied pe configuration time 
number pes requiring reconfiguration depend similarity templates template database 
templates similar require reconfiguration pes templates differ significantly require reconfiguration pes 
number pes requiring reconfiguration differ configuration step 
complicates calculation configuration time change configuration step 
address conventional configuration methods additional configuration bytes required start byte configuration packet 
undocumented configuration mode device allows random access configuration eliminate overhead 
issue average number pes requiring reconfiguration measured 
example pixels change successive template images required reconfiguration 
reconfiguration time far lower maximum allowable configuration time ms configuration time functional density rtr implementation cps cell improvement static alternative 
worst case situation pes require reconfiguration 
reconfiguration pes requires provides functional density cps cell 
provides improvement functional density static alternative 
configuration time overhead configuration approaches listed table 
pes pes rtr table configuration overhead template matching circuit 
success rtr application images size theta suggests approach may viable smaller images 
functional density run time reconfigured system best case run time reconfigured system static system plotted function image size 
demonstrates low configuration overhead run time reconfigured system allows functional density rtr implementation quickly approach maximum value 
addition rtr approach viable extremely small images 
suggests rtr cost effective approach image sizes interest 
break point functional density run time reconfigured approach equals static approach setting equations equal solving 
average configuration time break point occurs images size theta 
maximum configuration time break point increased maximum functional density worst case rtr system average rtr system static system image size functional density template matching circuit function image size 
images size theta 
maximum potential rtr application provides improvement functional density static circuit low configuration time allows exploitation advantages relatively small useful images 
sequence comparison edit distance algorithm known method comparing similarity long complex character sequences 
computational requirements algorithm implemented special purpose custom vlsi chip 
addition algorithm implemented known splash ccm platform ccm applications demonstrate supercomputer performance 
described appendix application exploit unique levels specialization implemented reconfigurable hardware 
specifically hardware resources required implement computation reduced propagating character source sequence directly pes linear systolic array 
propagating characters array improves functional density system mapped clay fpga 
advantages constant propagation available ccm platforms containing resources dedicate custom pe character source sequence 
sufficient resources source sequence partitioned sequentially scheduled limited array pes forces inefficient general purpose pe 
section address scheduling partitioning algorithm suggest method exploiting constant propagation source character pe run time reconfiguration 
advantages improved specialization due rtr balanced added cost configuration functional density metric 
details edit distance algorithm implementation approaches described appendix limited hardware systems described appendix standard approach edit distance algorithm requires dedicated character matching pe character source sequence 
long source sequences significant hardware resources required create long linear systolic array 
dna sequence comparison splash example requires fpgas perform sequence comparison source string characters 
smaller ccm platforms minimum processor requirements met problem solved completely parallel alternative architecture 
fortunately nodes dependency graph dg operation see partitioned scheduled limited resource platform locally parallel globally sequential partitioning approach 
partitioning approach divides nodes dg smaller manageable sized blocks 
block small solved limited resources system 
blocks scheduled execute resource sequential order preserves data dependencies original dg 
intermediate results block stored local memory subsequent blocks 
partition sequence comparison algorithm columns dg divided sub blocks columns 
partitioned block contains columns dg number pes system 
total number partitioned blocks dividing source sequence length number pes system follows demonstrates approach partitioning dg source sequence architecture pes 
block contains columns dg pe 
dividing column dg column blocks results partition system 
partitioning systolic edit distance array 
partitioned blocks scheduled order preserves original data dependencies dg 
partition example execute partition partition execute partition preserve communication pattern original dg data produced partition buffered memory 
results retrieved memory subsequent partition order preserves original function dg 
buffering data global fifo buffer shown 
global fifo buffering partial results fifos 
execution algorithm partitioned array begins setting match character pe array appropriate source character 
pes properly loaded initialized target data streamed array 
output results buffered memories subsequent partitions 
completing partition operation pes array modified represent source characters second partition 
execution proceeds array receiving entire target data data calculated partition 
process executing dg partitions updating source character pe continues partitions executed 
demonstrates process example introduced 
run time reconfiguration edit distance pes partitioning scheduling approach allows limited resource system implement edit distance algorithm special purpose hardware 
partitioning scheduling prevents ability propagate source characters pes array 
pe may perform match different character values special purpose pe 
pe pe global fifo step pe pe global fifo step pe pe global fifo step execution sequence partitions 
example character sequence partitioned processor array demonstrated pe array perform match operation third fifth characters source sequence 
source character changes completing partition general purpose pe supports possible source character values 
need reuse pe character prevents specialization pe forces larger general purpose pe 
described earlier chapter run time reconfiguration preserve circuit specialization techniques limited hardware resources 
rtr allows exploitation efficient specialized pes cost circuit reconfiguration 
general purpose pes support character alphabet special purpose pes reconfigured appropriate special purpose pe run time 
example sequence executed pe array special purpose hardware reconfiguring execution steps 
efficient constant propagated pes allows pes operate fixed resource 
increasing pe count array allows computation complete fewer partitions see equation 
example suppose constant propagated pes operate hardware required general purpose pes 
pes partitions needed compute character target sequence suggested 
reducing number partitions undoubtedly reduces time required execution 
pe pe global fifo pe step step pe pe global fifo pe global fifo reconfigure execution configuration special purpose pes 
functional density run time reconfigured applications advantages special purpose pes balanced associated configuration costs 
functional density metric measure trade 
functional density array static general purpose pe compared run time reconfigured constant propagated pe 
functional density partitioned sequence comparison circuit differs slightly functional density non partitioned system described appendix see equation 
specifically measurement area execution time modified represent smaller array size execution multiple partitions system 
area measurement area previous applications area analysis fixed static run time reconfigured systems 
smaller efficient pe run time reconfigured circuit allow special purpose pes operate fixed area 
number pes fixed resource dividing size fixed resource size pe pe pe smaller pe fewer partitions needed complete computation 
example special purpose pe half size general purpose counterpart number special purpose pes may operate fixed resource twice general purpose alternative 
reduces number circuit partitions needed system 
execution time execution time limited resource system requiring partitioning significantly longer fully pipelined non partitioned system 
partitioned system requires multiple passes target data limited resource array 
number passes required partitioned system size source sequence divided array size suggested equation 
total execution time time required complete single partition multiplied number partitions execution partition includes parts pes loaded configured appropriate source characters second entire target sequence streamed array 
streaming target sequence array requires cycles load target sequence gamma cycles flush sequence array compare equation gamma clk load total system execution time multiplying equation delta gamma clk load functional density operation applying fixed area execution time equation mn delta gamma clk load effects run time reconfiguration identified evaluating functional density approaches constrained platform clay fpgas 
specifically source target sequence characters 
functional density general purpose pes order determine functional density general purpose approach time required update pe source sequence partitions known 
current implementation pes updated streaming source sub sequence serially array storing appropriate character registers 
sub sequence length loading time calculated follows load gp delta clk result reduces functional density equation gp mn delta delta gamma clk source sub sequence length known 
length determining number pes fit system fpgas 
ideally cells needed implement general purpose pe allow pes fit single cell fpga 
fpgas general purpose pes operate parallel solve edit distance problem 
pe array large provide pe source sequence characters computation partitioned sequenced limited resource array 
specifically character sequence partitioned sub sequences mapped pe array 
substituting clk equation reduces functional density statically configured approach follows gp theta source sequence length general purpose edit distance pes provide theta cell updates cell second 
functional density special purpose pes smaller size special purpose pe allows pes operate limited resources 
specifically cell special purpose pe allows pes fit single cell fpga 
fpgas special purpose pes operate parallel 
increased size pe array allows character sequence computed fewer source sequence partitions 
specifically partitions required compute edit distance special purpose pes 
substituting equation reduces functional density run time reconfigured system follows sp theta gamma clk load reconfiguration time system ignored load specialpurpose array provides theta cell updates cell second maximum improvement general purpose alternative 
usual reconfiguration time special purpose array considered 
execution partition system pes array reconfigured appropriate source character value 
fortunately minor changes needed convert special purpose pe 
specifically match signal requires modification generation null signal remains 
shown layouts generation signal requires clay cells configuration bytes 
reconfiguration rate mhz reconfiguration time single pe ns complete reconfiguration pes 
single partition execution time configuration ratio run time reconfigured system 
unfortunately far greater maximum improvement 
excessive configuration overhead system suggests run time reconfiguration provide functional density general purpose static alternative 
fact functional density run time reconfigured system theta cell updates cell second static alternative 
results analysis summarized table 
general purpose special purpose pe size cells clock period ns ns pes fpga pes partition partitions partition execution time load time load total time delta load ms ms functional density cell updates cell second theta theta improvement table comparison edit distance alternatives 
amortizing configuration time clearly run time reconfigured edit distance circuit execute long justify reconfiguration costs 
computation configuration costs reduced longer target sequence increase 
functional density general purpose pe array equation special purpose run time reconfigured pe array equation plotted function target sequence length target sequence length increases character configuration overhead reduced functional density increases 
functional density approaches target sequence contains characters 
requiring large target sequence justify rtr suggests rtr may appropriate application 
characters target sequence length functional density best case rtr circuit rtr circuit static circuit functional density edit distance circuit function character length 
application summary run time reconfigured applications described chapter represent particularly wide application range provide insight potential benefits problems facing run time reconfigured systems 
table summarizes results applications including upper bound benefits rtr max configuration overhead actual improvement rtr break point application described 
application max actual break rrann gamma neurons rrann ii global neurons rrann ii partial neurons template matching avg theta image template matching max theta image edit characters table application summary 
clear table application offers potential improvement functional density configuration time ignored max positive applications rrann offer significant potential advantages 
improvement functional density suggests significant potential ignored 
modest improvement template matching circuit significant large cost sensitive systems 
advantages associated rtr balanced corresponding configuration overhead 
relatively slow configuration times todays devices limit potential rtr 
due high configuration overhead applications demonstrate functional density far lower potential 
applications listed table sensitive configuration time improvements configuration time significantly increase functional density systems 
addition reducing configuration time allows justification rtr smaller reasonable sized problems 
reducing partial configuration rrann ii system example increases achievable functional density reduces break point rtr neurons 
summary rtr provides advantages digital systems available today technology 
improvements configuration time devices allow rtr justified situations offer greater improvements functional density 
chapter dynamic instruction set computer disc run time reconfiguration limited special purpose architectures described previous chapter 
improvements circuit efficiency functional density provided rtr exploited conventional general purpose processor architectures 
novel programmable processor architecture called dynamic instruction set computer disc designed tested explore benefits 
designed entirely reconfigurable fpga resources disc uses rtr increase size instruction set reconfiguring special purpose instructions run time 
virtual memory conventional processors disc pages application specific instruction modules run time overcome resource limitations physical hardware 
complete description disc architecture associated run time environment appendix run time reconfigured systems rtr disc requires additional time circuit reconfiguration 
reconfiguration processor instructions free current disc implementation processor halts activity configuration complete 
processor cycles spent reconfiguring special purpose instruction spent executing general purpose instruction modules 
rtr applications added time circuit reconfiguration mitigate advantages provided instruction set specialization 
custom instructions requiring excessive configuration time may reduce performance processor 
avoid degradation performance due configuration benefits specialized instruction set balanced added cost configuring instruction hardware 
chapter evaluate benefits rtr disc environment applying functional density metric described chapter 
section chapter functional density metric determine appropriateness custom run time reconfigured instruction module application specific operation 
custom instruction justified improvements performance software alternative override area reconfiguration overhead 
second section benefits instruction caching disc investigated 
specifically added area create cache balanced reduction configuration time 
functional density disc instructions described appendix disc allows execution standard general purpose instructions special purpose run time reconfigured instructions application program 
operation performed general purpose instruction set operations readily exploit advantages specialization custom dedicated instruction module 
instruction modules requires additional hardware resources added time circuit reconfiguration 
functional density metric determine development custom instruction justified particular application specific operation 
custom instruction module justified provides functional density software program performing operation standard instruction set 
order comparison functional density disc program measured 
analysis describing functional density measured software programs executing static processor core 
relatively weak processor disc processor core provide extremely low functional density application specific operations 
processor limitations analysis unrealistically favor application specific instruction modules 
practice improved custom processor provides significantly functional density current fpga disc processor core 
functional density static processor core order measure functional density software program executing static processor core system area time parameters known 
processor core applications change run time area fixed applications 
area core consumed distinct processor units global controller general purpose functional units accumulator 
area units shown table 
area cells notes controller chip clay theta functional units rows accumulator rows total cells row table area static processor core 
execution time application program executing processor core determined number instructions executed application program 
instruction sequence compute operation application specific instruction count calculated application application basis 
execution time calculated summing clock cycles required instruction multiplying system clock rate functional density application executing processor core simply inverse area time product follows core delta delta functional density custom instructions calculating functional density custom instruction slightly involved 
area required executing application specific custom clock rate current disc system mhz 
instruction includes area processor core core applicationspecific instruction extension inst 
area custom instruction measured terms rows consumed linear hardware space see discussion linear hardware space appendix 
cell rows clay area required custom instruction circuitry number rows consumed instruction 
total area required run time reconfigured custom instruction core inst execution time required custom instruction depends details application specific circuit 
clearly execution time custom instruction significantly execution software alternative order justify added processor resources configuration time 
functional density application specific function run time reconfigured custom instruction inst time required configure custom instruction linear hardware space 
configuration time custom instructions configuration time custom instructions important parameter functional density calculation 
parameter slightly involved configuration time rtr systems 
due instruction caching disc instructions configured linear hardware space eventually removed hardware 
removal instruction involves second reconfiguration step required avoid undesirable side effects 
addition second reconfiguration step custom instructions relocated appropriate location linear hardware space runtime 
time consuming process requires careful manipulation configuration bit stream modify location circuit 
total configuration time disc custom instruction sum steps circuit relocation relocate initial circuit configuration config circuit removal remove 
fortunately custom instructions disc partially configured fpga array 
reduces configuration time instruction limiting configuration data instruction interest see chapter depth discussion partial configuration 
configuration time instruction simply rate configuration ae multiplied size configuration bit stream required instruction 
configuration rate current disc system measured byte kb sec removal instruction consumes amount time configuration instruction modified bit stream length original bit stream erase custom instruction circuitry 
time required relocate instruction depends size configuration 
rate configuration data modified ae relocate depends complexity custom instruction configuration windows associated custom instruction longer takes process relocate instruction 
tests current disc system instruction relocation occurs average rate byte kb sec 
sum configuration sub steps byte shown table 
configuration rate byte removal rate byte relocation rate byte total byte table configuration rate disc 
custom instructions low pass filter maximum value search analyzed functional density metrics 
functional density software hardware version application measured identify benefits run time circuit specialization 
run time reconfigured configuration rate far slower maximum configuration rate allowed device 
configuration rate limited system pc isa bus 
custom instruction justified provides functional density static software alternative 
low pass filter filtering image simple low pass common operation systems remove high frequency noise sampled images 
lowpass filter implemented disc finds average value theta pixel neighborhood follows gamma gamma software subroutine custom instruction developed perform operation theta images 
low pass filter software subroutine software version operation written disc assembly language general purpose instruction set 
program shown listing performs operation equation inner loop general purpose disc instructions 
instructions program spent performing arithmetic operations overhead required pointer calculation loop indexing control adds significant time 
instruction inner loop consumes processor cycles process pixel image 
total time complete computation delta clk number pixels image 
functional density filter operation executing software substituting execution time functional density equation equation delta delta clk pixels cell second low pass filter custom instruction special purpose hardware custom low pass filter instruction performs operation software subroutine 
suggested listing disc assembly code low pass filter 
filter lsp pin load stack pointer center pixel address ld sp load accumulator add sp add accumulator add sp add accumulator add sp add accumulator add sp add accumulator add sp add accumulator add sp add accumulator add sp add accumulator add sp add accumulator shift divide sd pout store result output pixel address ld increment center pixel address add pin sd pin ld increment output pixel address add pout sd pout lt output pixel image 
filter go back process pixel instruction computes sum theta window parallel adders 
addition shift circuit performs divide operation pixel sum 
software implementation algorithm requires instructions perform arithmetic concurrent circuit perform computation single cycle 
shift data flow mean instruction module 
parallel circuit perform arithmetic operation single cycle computation limited bandwidth 
current disc system allows access pixel external memory cycle 
need load rightmost pixels window gamma additional cycle writing result computation single pixel requires cycles memory accesses 
limited operation improvements performance obtained maximizing bandwidth memory resource 
fortunately memory bandwidth optimized operation control memory interface 
special purpose address generator accessing controlling global memory custom instruction achieves utilization available memory bandwidth cycles needed perform required operations 
arithmetic computation requiring single cycle operates parallel accesses allows computation pixel occur clock cycles 
represents significant improvement cycles required software alternative 
advantage custom hardware operation ability exploit custom control 
executing instruction pixel image internal counter allows single invocation instruction filter entire image 
causes instruction execute clock cycles avoids instruction fetch decode overhead associated long instruction stream 
organization instruction including datapath address generation control shown 
address generator data bus address bus control architectural overview low pass instruction module 
execution time instruction includes overhead loading initiating instruction plus time required filter pixels input image 
cycles consumed instruction overhead cycles required process pixel total execution time instruction delta clk theta images interest instruction executes clock cycles ms custom low pass filter instruction relatively complex instruction module consumes rows cells hardware 
including processor core instruction requires total area cells 
functional density approach substituting execution time area equation delta delta clk maximum functional density custom instruction obtained ignoring configuration overhead max delta clk pixels cell second upper bound value needed determine maximum improvement approach software alternative 
equation custom instruction provides maximum improvement static software alternative 
improvement suggests low pass custom instruction provide functional density software version long configuration ratio 
execution time ms allows configuration time ms configuration overhead relatively complex custom instruction requires bytes configuration data 
current disc configuration relocation rates table instruction requires ms relocation reconfiguration removal 
composite reconfiguration time greater execution time consumes disc processor clock cycles reconfiguration time falls ms limit determined 
indicates custom instruction provides functional density software alternative 
fact theta image custom instruction provides functional density pixels cell second improvement software approach 
image size increases overhead associated configuring custom instruction decrease improve functional density 
result seen plotting functional density function image size small images configuration overhead reduces functional density custom instruction software program 
break point occurs theta image setting equations equal solving size functional density custom instruction greater software alternative 
custom instruction software program image size functional density hardware software low pass filter 
maximum value search identifying maximum value data set useful operations peak detection data searching 
find maximum value data set requires evaluation elements set 
simple algorithm operation shown listing 
algorithm implemented disc determine peak value image histogram histogram bins part thresholding operation 
operation implemented disc sequence general purpose instructions custom instruction module 
order listing algorithm finding maximum value 
maxval max data max maxval data max determine custom instruction module appropriate operation functional density alternatives analyzed compared 
maximum value search software subroutine simple subroutine performs maximum value search written general purpose disc assembly instructions 
program shown listing performs searching function inner loop sequence instructions 
execution single pass loop proceed directions 
current maximum value max greater equal current data item set ptr instructions label update skipped instructions executed processor cycles 
instructions loop executed processor cycles internal max register updated current data item 
actual time required complete entire search depend number times update instructions executed 
assuming half loop iterations execute instructions average cycle count loop cycles 
total time required algorithm delta clk size data set 
substituting execution time functional density processor core equation provides functional density software maximum value search operation delta delta clk data values cell second listing disc assembly code maximum value search 
ld ptr load current value data set sub max subtract current maximum value jc carry set max ptr skip update ld ptr current data value greater max 
sd max update max value pointer ld ptr sd ld ptr increment pointer data element set add sd ptr sub done determine data set reached jc maximum value search custom instruction low pass filter application custom instruction operation implemented 
advantages circuit specialization analyzed suggesting application specific solution estimating area time 
analysis propose custom instruction maximum value search model effects various circuit size functional density 
custom instruction specialization techniques described section custom instruction designed perform search operation efficiently special purpose hardware 
shown proposed architecture instruction exploits custom control address generation unit simple comparison unit 
dedicated comparison unit determines incoming data item greater current maximum value 
reloads instruction local maximum register 
evaluating data set internal maximum register contains maximum value data set 
custom control max max register address generator address bus data bus control control bus maximum value instruction block diagram 
traverse entire data set single invocation instruction 
removes overhead repeated instruction invocation associated software alternative 
addition control unit synchronizes activities address generation comparison units 
dedicated address counter instruction optimize transfer data memory bus 
synchronized comparison unit address counter accesses unique data item cycle 
simple architectural features combined custom instruction allow single data item processed cycle 
total number clock cycles required instruction include cycles instruction issue overhead cycles data processing size data set 
total execution time cycle count multiplied clock rate delta clk bin histogram execution time operation instruction implemented area known 
simplicity operation suggests instruction require rows 
actual circuit parameters area custom instruction area represented terms variable number rows consumed proposed instruction 
cells row special purpose implementation consumes theta cells instruction processor core functional density operation determined combining execution time area parameters obtained clk ae maximum functional density approaches value max clk maximum value calculated possible sizes table 
addition maximum improvement custom instruction software alternative listed table 
large improvements available circuit specialization suggests custom instruction may effective solution 
max cell max table maximum functional density maximum value custom instruction 
configuration overhead configuration time custom instruction depends size instruction amount configuration data required instruction 
size known configuration time represented terms number rows required instruction 
instructions previously developed average instruction requires bytes configuration data row hardware 
configuration relocation rate byte total configuration time instruction config theta theta byte configuration times possible sizes listed table 
config ms ms ms table configuration time configuration ratio maximum value search custom instruction 
absolute configuration time instruction excessive ratio configuration time execution time large justify custom instruction 
shown table relatively short execution time produces higher configuration ratio acceptable system 
case row instruction maximum allowable configuration ratio actual configuration ratio 
substituting configuration time ms equation functional density row instruction calculated data items cell second 
represents reduction functional density compared non configured software alternative 
cases hardware required functional density lower 
custom instruction potential provide significantly functional density software alternative short execution time module fails overcome configuration overhead 
custom instruction operate larger data set disadvantages reduced 
shown larger data set greater functional density custom instruction 
software subroutine bins histogram size functional density maximum value instruction 
improving functional density exploiting temporal locality important aspect disc system ability cache frequently instructions linear hardware space 
suggested appendix caching custom instructions reduces effective reconfiguration time exploiting temporal locality executing instructions 
principle temporal locality suggests custom instruction executed subsequent instruction occur soon 
instruction executed second time soon occurrence reconfiguration step avoided caching holding instruction reconfigurable resource 
allows frequently instructions avoid time consuming reconfiguration step 
reduction configuration time due instruction caching represented terms hit rate instruction cache 
hit rate specifies probability instruction exists hardware cache instruction issued processor 
higher hit rate fewer number times instruction require reconfiguration 
reconfiguration step instruction eliminated cache hit effective reconfiguration time instruction reduced 
reduced configuration time instruction simply product instruction rate reconfiguration time effective configuration time gamma delta mt hit rate instruction increased lengthening extending cache size 
larger cache allows instructions reside simultaneously increases probability instruction resident cache needed processor 
hit rate instruction increases effective configuration time declines 
increasing cache size improve instruction hit rate requires hardware resources unnecessary 
addition excess resources mitigate advantages improved hit rate unnecessarily increasing hardware costs 
functional density metric balance improvements reduced configuration time additional hardware costs cache 
functional density disc instruction cache effects instruction caching integrated functional density metric equation making modifications 
effective configuration time equation custom instruction configuration time 
second size hardware cache included total area measurement 
modifications result modified functional density measure cache delta mf measure evaluate effect cache size functional density particular disc program 
inclusion hit rate cache size functional density metric balances advantage reduced configuration time disadvantages added hardware 
functional density measure equation evaluate effects increasing instruction cache 
specifically functional density disc program operating minimal cache compared functional density program operating larger cache 
functional density large cache system greater smaller cache improvements instruction hit rate override costs larger cache 
conditions larger cache increases functional density system evaluating relationship delta delta gamma gamma deltaa gamma result equation suggests benefits instruction cache depend configuration ratio instruction additional cost cache deltaa improvement cache hit rate gamma configuration ratio instruction greater added cost cache divided improvement cache hit rate functional density instruction increase larger hardware cache 
instructions low configuration ratio added cost larger cache difficult justify instructions high configuration ratio improvement hit rate override added cost cache 
measuring hit rate balancing improvement hit rate added cost cache equation requires actual hit rate instruction cache size interest 
hit rate function created specifies hit rate function cache size 
function indicates probability particular instruction reside cache executed 
hit rate function begins zero increases size little need improve configuration time instruction low configuration ratio configuration minor fraction total operating time 
cache 
cache large hold instruction modules function reaches maximum value instruction hit rate 
hit rate function depends cache replacement policy 
replacement policy determines disc instructions removed room instruction cache full 
actual disc system simple lru algorithm determine instruction remove 
simple lru replacement policy inefficient proved ineffective disc applications 
replacement algorithms better results considered 
hit rate function evaluated lru replacement policy optimal statically scheduled replacement policy 
hit rate function individual disc instruction measuring closely successive occurrences instruction executed 
closer instruction executes trace higher potential hit rate 
measurement closeness quantified form instruction distances 
distance instruction trace defined minimum size cache needed insure instruction hit cache occurrence instruction trace 
general closely instances instruction executed trace smaller distance 
distance measurements demonstrated lru optimal replacement policies 
lru replacement lru replacement policy instruction hit guaranteed cache large hold instruction interest instructions executed occurrence instruction interest 
example instruction sequence instruction cache large hold instructions insure second occurrence instruction remains cache 
cache large hold instructions instruction removed instruction executed instruction entry invocation instruction simple instruction trace distance second occurrence rows rows rows sample instruction sequence 
instruction 
distance minimum cache size needed insure second occurrence instruction cache executed 
instruction trace distance second occurrence instruction size instructions cache size disc measured terms rows distance instruction measured rows 
minimum cache size second occurrence instruction sum area consumed instructions rows 
hardware cache rows insure cache hit second occurrence instruction static scheduled replacement dynamic cache replacement algorithms lru sub optimal know instructions executed 
complete instruction trace known program execution optimal replacement schedule 
example complete instruction sequence known execution smaller cache size insure instruction hit second occurrence instruction instruction removed cache execution instruction static analysis knows instruction executed 
reduces minimum cache size needed guarantee instruction hit second occurrence instruction size instructions rows 
static scheduling reduces distance second instruction rows rows 
assumes cache resources optimally utilized 
practice fragmentation cache rows require additional rows insure cache hit 
example hit rate function hit rate instruction program cache size distance occurrence instruction trace 
hit rate simply percentage instructions trace distance minimum cache size equal cache size interest 
calculation demonstrated measuring hit rate instruction insta listing replacement policies 
listing sample disc instruction trace 
insta instb insta insta instb insta instb insta instruction insta appears times trace listing 
order measure hit rate instruction function cache size distance instances insta measured 
distance occurrence instruction insta infinite reconfiguration required matter large instruction cache second occurrence instruction insta appearing line listing preceded execution insta instb 
distance instruction lru policy size instructions 
instruction sizes listed table instructions consume rows cache analysis assumes pre fetching occurrence instruction trace require reconfiguration 
size rows insure hit second insta instruction executed 
statically scheduled replacement distance reduced size instructions insta rows 
distances occurrences instruction insta appearing lines listing shown table replacement policies 
instruction insta instb area rows table sample disc instruction sizes 
line lru static scheduled distance set distance distance set distance insta instb insta insta insta insta instb insta instb insta instb insta table distances instruction insta listing 
distance occurrence insta tabulated hit rate instruction 
hit rate specific cache size determined percentage instructions distance equal cache size interest 
example occurrences insta hit executed cache rows lru replacement instructions lines see table 
instructions represent insta instructions trace 
result indicates insta experience hit rate row cache 
hit rate function process cache sizes interest 
hit rate function shown replacement policies instruction insta 
cache size rows lru optimal hit rate insta function instruction cache size 
example functional density calculation hit rate function instruction determined effects instruction caching functional density investigated 
larger cache increase hit rate functional density instruction improve improvements reconfiguration time outweigh costs added cache resources 
specifically configuration ratio instruction greater ratio cache cost cache advantage suggested equation 
effects increasing cache size demonstrated comparing functional density instruction insta cache size rows 
hit rate added cache resources increases rows rows lru replacement rate decreases 
minimum configuration ratio required instruction justify added cache evaluated solving equation rows delta gamma rows delta rows delta gamma rows delta improving hit rate insta addition cache rows justified configuration ratio insta greater 
functional density instruction cache sizes applying hit rate function 
function plotted lru replacement policy configuration ratio execution time cache size rows functional density instruction insta computed 
additional rows added cache hardware added system increasing hit rate 
reduces functional density system hardware added improving reconfiguration time 
added cache resources rows example offer benefits hit rate provide lower functional density 
rows hit rate jumps increases functional density due reduction reconfiguration time 
rows added functional density declines peak hit rate occurs rows 
rows functional density reaches peak adding additional rows system continually degrades functional density improvements hit rate possible 
cache size rows functional density insta function instruction cache size 
indicated hit rate lru replacement policy sub optimal 
demonstrates effects replacement policy plotting functional density insta lru optimal replacement policy 
achieving higher hit rate optimal replacement policy provides higher functional density smaller cache size 
example optimal replacement achieves peak functional density improvement peak lru functional density 
optimal lru cache size rows functional density insta lru optimal replacement policies 
instruction caching provides improvements functional density cached instructions exhibit high configuration ratio see equation 
instructions low configuration ratio benefit caching configuration represents small fraction total operating time 
necessity high configuration ratio seen plotting functional density insta configuration ratio 
seen peak functional density replacement policies occurs minimum cache size rows 
additional cache rows reduction configuration time provided higher hit rate fails justify hardware costs cache 
cache size rows optimal lru functional density insta low configuration ratio 
functional density disc program incorporating hit rate cache size functional density balances advantages caching instruction added cache cost 
analysis identifies effects caching single instruction disc program fails consider net effect instruction caching entire disc program 
various cache sizes affect custom instruction different way optimal cache size instruction sub optimal instruction 
benefits instruction caching involve effects instruction program 
effects instruction caching evaluated measuring functional density entire disc program 
area disc system simply area static controller plus area instruction cache 
total operating time program sum execution configuration times instruction program trace 
program trace instructions functional density represented disc delta cn en cn en rate configuration time execution time nth instruction program trace 
calculation composite functional density demonstrated evaluating program listing 
hit rate instruction listed table function cache size replacement policy 
cache size rows support largest instruction trace 
maximum useful cache size size instructions trace rows 
functional density disc program plotted assuming 
cache size lru optimal instruction insta instb table hit rate instructions listing 
important points worth noting 
functional density program lru cache replacement policy identical row caches 
rows functional density system improves due increase hit rate instructions 
rows functional density increases significantly due relatively large improvement hit rate instb instruction 
cost larger cache justified significant improvements hit rate 
second concept highlight relatively small variation functional density different cache sizes 
functional density insta instruction varies functional lru optimal cache size rows functional density listing cache size 
density composite program varies 
functional density composite disc program sensitive cache size due impact instructions trace 
benefits cache size instruction countered disadvantages cache size different instruction 
third point note effect replacement policy functional density 
expected higher hit rate optimal replacement policy allows disc program operate functional density simple lru replacement policy 
addition peak functional density optimal case occurs smaller cache size 
general exploiting locality disc programs offer improvements functional density 
benefits depend locality disc instructions configuration ratio replacement scheme disc system 
order improve functional density disc program exploiting instruction cache program exhibit temporal locality custom instructions require relatively high configuration ratio 
summary disc system successfully exploits advantages run time circuit reconfiguration reconfiguring application specific instruction modules directed executing program code 
approach allows limited hardware cost sensitive system benefit circuit specialization requiring substantial hardware resources 
circuit reconfiguration disc processor architectures forced solve application specific operations software processor architecture provide custom hardware large set application areas static hardware resources 
analysis demonstrates run time reconfiguration improve functional density processor architecture allowing run time reconfiguration instruction set 
addition disc system reduces effects configuration time exploiting temporal locality instructions program 
demonstrated additional fpga resources instruction cache increase functional density system retaining frequently custom instructions 
instructions held cache avoid time consuming circuit reconfiguration step executed 
arbitrarily increasing instruction cache may reduce functional density cache resources consume valuable resources provide diminishing improvements instruction hit rate 
disc system successfully demonstrates advantages rtr processor environment system related issues limit usefulness 
configuration rate current disc system extremely slow 
manipulation configuration data pc host transfer data system bus consumes far time 
improving configuration time allow justification application specific custom instructions 
second benefits instruction caching limited disc programs exhibiting temporal locality 
high cost fpga resources instruction cache require corresponding improvements configuration time 
configuration time reduced instructions remain cache 
third core processor disc severely limited 
processor able execute program limited resources prevent processor effectively computing simple control operations 
capable processor improve system performing local computation handling configuration instruction relocation need host 
issues addressed projects run time reconfiguration appropriate programmable processor environments 
chapter reconfiguration time discussion run time reconfigured systems functional density metric justify rtr conventional static alternatives 
key parameter metric added configuration time config required circuit reconfiguration 
demonstrated examples functional density run time reconfigured systems sensitive configuration time 
time required circuit configuration major factor determining rtr justified configurable system 
suggested applications chapter configuration performance available reconfigurable devices poor limits effectiveness rtr 
poor reconfiguration performance surprising conventional fpga devices designed low volume gate replacement static digital systems 
markets logic density speed important configuration time 
run time circuit reconfiguration significantly improves performance efficiency cost effectiveness configurable systems configuration time may important parameter optimize 
fact potential advantages offered run time reconfigured systems motivated investigation configuration improvement techniques 
chapter address issue configuration time surveying state conventional device configuration performance second reviewing configuration improvement techniques 
configuration conventional fpgas configuration time custom computing machine depends bandwidth configuration interface amount data required configuration 
systems additional overhead required initiating completing configuration sequence 
configuration time expressed follows config ael fi ae bandwidth configuration interface mb sec amount data required configuration fi system specific configuration overhead 
configuration overhead fi increases reconfiguration time vast majority configuration time spent transferring configuration data respective fpgas 
analysis focus primarily fpga dependent parameters configuration bandwidth configuration length 
importance parameters rtr system addressed separately 
configuration bandwidth ae configuration bandwidth fpga determined dedicated configuration interface provided fpga device 
configuration interface usually includes set external pins configuration clock configuration data bus configuration control signals 
configuration bandwidth simply width configuration data bus multiplied maximum configuration clock rate 
parameters described data sheets fpga devices 
bit width configuration clock rate maximum configuration bandwidth fpga families summarized table see tables detailed listing 
configuration data obtained respective fpga data sheets 
fpgas provide configuration modes varying configuration data widths mode offering highest aggregate bandwidth listed table fpgas listed table offer modest configuration bandwidth range mb sec 
exception xilinx fpga fpga devices support serial bit parallel configuration path single bit configuration mode usually provides bandwidth due internal single bit configuration path fpgas 
vendor device width configuration bandwidth family clock rate altera mhz mb sec mhz mb sec atmel mhz mb sec lucent orca mhz mb sec national clay mhz mb sec semiconductor xilinx mhz mb sec mhz mb sec ex mhz mb sec mhz mb sec table fpga device configuration bandwidth 
operating mb sec optimized fast configuration 
relatively low configuration bandwidth offered devices attributed factors 
static memory cells hold configuration data optimized density speed 
small compact reliable memory cell preferable high speed memory cell 
second configuration interface fpga optimized reliability speed 
complex functions checksum calculation read back added interface regard effects configuration speed 
third configuration interface address control slave configuration memories 
memories usually programmable memories operate slower conventional static memory cell 
limited configuration bandwidth offered fpgas places severe limitations effectiveness run time reconfigured systems 
configuration rates significantly lower bandwidth provided microprocessors system interfaces simple serial busses 
mb sec bandwidth rambus interface example provides orders magnitude bandwidth configuration interface fpgas 
run time reconfigured systems provide significant improvements functional density configurable computing machines configuration bandwidth bottleneck addressed 
significant bandwidth limitations fact configuration bandwidth fpgas scale improvements device operating speed 
fpgas listed table configuration clock rate speed grades device 
configuration interface fast speed grade device operates faster slow speed grade device manufacturers characterize timing configuration circuitry 
device manufacturers guarantee timing improvements configuration interface faster operating fpgas configuration bandwidth conventional devices remain constant device speed grades 
configuration time device held constant reduction execution time due timing improvements offer limited benefits runtime reconfigured system 
improvements device reduce execution time system configuration overhead quickly system bottleneck 
limitations seen evaluating diminishing improvement functional density rtr system increasing execution time constant configuration time 
consider baseline rtr system area execution time configuration time functional density system configuration ratio execution time system reduced factor ff due device improvements configuration time held constant functional density improves follows ff ff fff improvement functional density due reduction execution time substituting functional density systems equation ff fff gamma ff gamma fff presence configuration ratio denominator equation significantly reduces improvements provided reduction execution time 
example rtr system reduces execution time half ff improvement functional density limited 
systems higher configuration ratio improvements smaller 
demonstrates principle plotting limited improvement functional density due faster configuration time values reduction te alpha improvement improvement limitations constant configuration time 
suggested improving execution time rtr system holding configuration time constant places bounds improvement system 
maximum improvement evaluating limits equation lim ff ff gamma fff result suggests larger configuration ratio limited benefits provided reduced execution time 
configuration times fpga devices scale timing improvements device rtr systems quickly configuration limited 
configuration length configuration time depends amount configuration data required configuration step 
globally reconfigured fpgas resources reconfigured configuration step amount configuration data proportional size fpga 
larger fpga configuration data needed reconfiguration step 
varying device sizes xilinx series family demonstrates point 
shown table devices range size logic gates 
mb sec configuration interface device family total reconfiguration time ranges ms xc ms xc 
fixed configuration bandwidth fpga devices larger fpgas require circuit reconfiguration time 
device clbs gates configuration configuration bits time xc ms xc ms xc ms xc ms xc ms xc ms table xilinx xc configuration data 
configuration bandwidth devices fpga family configuration time fpga function device size larger device time consumed circuit reconfiguration 
larger devices provide logic computation time required circuit reconfiguration 
example large fpga device may replace set smaller fpgas providing amount programmable logic 
single large fpga configuration port smaller fpgas provide configuration ports 
assuming fpgas configured parallel configuration bandwidth large fpga factor smaller small fpgas 
effects increasing configuration time demonstrated evaluating reduction functional density larger fpga devices 
consider baseline rtr system performs computations fpga area functional density baseline system assuming larger fpga area exploit parallelism algorithm increasing size fpga factor ff ff ideally allow ffn computations 
larger fpga increases reconfiguration time fft composite functional density larger fpga ffn ffa fft fft added configuration overhead larger fpga reduces functional density system 
change functional density evaluated follows gamma fft gamma gamma ff fft gamma ff fff ff improvement negative indicating reduction functional density 
reduction functional density plotted values example original configuration ratio system fpga doubles size ff functional density decrease 
fpgas larger configuration times continually increase 
fact minimum reconfiguration times largest fpgas quickly approaching second boundary 
trends coupled poor configuration time fpgas available today cloud prospects rtr systems 
growing mismatch configuration time execution time addressed conventional fpgas large configure slowly run time reconfigured systems 
increase area alpha improvement reduction functional density larger fpga devices 
configuration improvement techniques configuration enhancement techniques implemented proposed address limitations 
techniques reduce reconfiguration time exploiting specific properties special purpose application investing resources configuration interface 
section introduce review configuration improvement techniques 
increase configuration bandwidth 
reduce configuration data partial configuration 
execute reconfigure parallel 
exploit temporal locality 
distribute configuration 
techniques additional hardware resources required unneeded 
cases added hardware represented follows ff delta area fpga system enhancement ff area overhead parameter 
functional density metric evaluate benefits technique determine limitations 
improving configuration bandwidth direct way improving reconfiguration time invest additional hardware resources configuration interface 
resources widen configuration data bus improve speed internal configuration control increase speed internal configuration memory 
method consumes valuable silicon resources additional programmable logic 
analysis balance advantages configuration time added cost hardware functional density metric 
reduction configuration time provided methods specified fit configuration time enhancement fi factor configuration time reduced fi 
assuming execution time application conventional device enhanced device configuration ratio reduced factor fi 
parameters functional density enhanced fpga specified ffa fif configuration improvement justified reduction configuration time offsets added area cost 
conditions configuration enhancement technique improves functional density reducing relation functional density non enhanced device fif ff fif relation places upper bound additional area allowed configuration interface improvements 
bound depends configuration reduction factor fi original configuration ratio maximum allowable hardware configuration improvement plotted values suggested plot greater reduction configuration time provided enhancement area tolerated enhancement 
percent reduction configuration time limitations area overhead configuration improvements 
improvements configuration time graphed represent modest range 
emerging high speed memory interfaces significantly greater improvements configuration time possible 
example increasingly popular rambus interface demonstrates mb sec memory interface cost sensitive consumer product 
memory interface configuration interface conventional fpga configuration bandwidth improve factor fi 
run time reconfigured application improvement configuration time may tolerate addition considerable hardware resources implement fast configuration interface 
maximum increase hardware system reduces configuration time factor plotted function configuration ratio 
system configuration ratio example tolerate times hardware implement high speed configuration interface 
configuration ratio maximum allowable area mb sec configuration interface 
partial configuration method reducing configuration time reduce amount configuration data sent fpga device 
fpga devices support partial configuration ability configure sub set fpga resources configuration step 
partial reconfiguration reduces configuration time rtr systems allowing small circuit changes run time forcing reconfiguration entire device 
small circuit changes require far configuration data consume significantly time complete global configuration fpga device 
assuming partial reconfiguration require resources conventional reconfiguration interface functional density partially reconfigured system fit improvement functional density globally configured alternative gamma fit gamma gamma fi fit gamma fi fif fewer configuration bytes required lower fi significant improvement 
benefits partial reconfiguration depend high configuration ratio 
disc processor applications described chapter demonstrate significant improvements configuration time exploiting partial reconfiguration 
reduction configuration data fi varies partially configured rtr system 
parameter ranges partially reconfigured systems listed table 
addition configuration ratio example provided 
configuration reduction factor configuration ratio example improvement functional density provided partial configuration applying equation 
partially reconfigured system fi rrann ii feedforward rrann ii backpropagation rrann ii update atr worst case atr best case disc lowpass instruction disc instruction table improvement functional density partially reconfigured systems 
interesting note similar improvements functional density rrann ii feedforward circuit atr best case circuit 
atr example provides significantly greater reduction configuration data fi relatively low configuration ratio limits benefits partial reconfiguration 
rrann ii example relatively high configuration ratio configuration limited enjoys advantages reduced configuration time provided partial reconfiguration 
reducing granularity configuration individual wires cells substantially reduce reconfiguration time configurable systems 
partial reconfiguration exploited run time reconfigured systems require minor circuit changes reconfigure highly correlated circuits 
partial reconfiguration allows temporal characteristics rtr application determine reconfiguration time necessarily size device 
simultaneous configuration execution simple approach reducing configuration overhead allow simultaneous execution configuration fpga resources 
purpose approach hide latency configuration transferring configuration data fpga circuit operation 
ideally configuring fpga execution completely hides configuration step allows run time reconfigured circuits operate interruption 
technique requires additional hardware resources justified functional density metric 
total operating time traditional phase reconfiguration execution cycle sum execution time configuration time equation 
allowing execution configuration occur simultaneously total operating time reduced larger phases conventional fpgas simultaneous reconfiguration execution possible single configuration memory logic resource forces execution reconfiguration occur separately 
approach implemented fpgas connecting parallel shown fpgas executes configured 
execution configuration fpgas completed roles fpgas exchanged reconfigured fpga begins operate new circuit executing circuit halts operation receives configuration 
process swapping roles execution configuration continues entire reconfiguration cycle 
partially reconfigured devices allow operation logic resources logic resources reconfigured 
devices allow logic resource simultaneously reconfigured affecting operation associated logic 
external interface fpga executing fpga configuring configuration control external interface fpga configuring fpga executing configuration control simultaneous execution configuration fpgas 
suggested hardware fpgas contexts available handle configuration execution time 
second context requires additional hardware resources needed 
example twice hardware resources needed implement contexts fpgas ff 
overhead imposed second context reduced incorporating internal shadow context fpga resource 
functional density system exploiting technique measured combining area ffa operating time equation 
operating time dependent relationship functional density depend relationship follows shadow improvement provided approach evaluating equation shadow gamma follows gamma ff fft gamma ff fft gamma ff ff gamma ff fff improvement approach plotted values ff 
configuration ratio maximum ff function interesting observations available 
benefits approach limited applications relatively close value 
operation time dominated execution configuration ae benefits simultaneous execution configuration minimal configuring context executing context remain idle time 
second technique offers improvements small values ff 
reflects limited advantages provided technique best total operating time reduced half 
limits maximum hardware overhead ff 
limitation fpga example offer improvements functional density 
costs adding second context extremely low configuration improvement technique offers limited advantages 
exploiting temporal locality important method improving configuration time exploitation temporal locality run time reconfigured systems 
principle temporal locality suggests particular circuit configuration executed needed soon 
reconfiguration time configurations exhibiting temporal locality reduced caching configurations closer reconfigurable resource 
circuit configuration needed second time close hand configured reconfigurable resource significantly shorter time 
disc system example reduces effective configuration time system caching frequently custom instructions directly reconfigurable resource 
temporal locality circuit configurations appears applications described chapter 
run time reconfigured neural network reviewed section example continually executes cycle unique circuit configurations 
cache created hold circuits time consuming reconfiguration step circuit avoided 
edit distance circuit partitioned limited resource array cycles set constant propagated circuit partitions 
cache large hold part special purpose circuits reduce effective reconfiguration time 
improvements reconfiguration time due configuration caching available configuration sequence reconfigurable resource demonstrates temporal locality 
circuit configurations reused exhibit temporal locality configuration caching technique provides benefits 
measure temporal locality probability run time reconfigured circuit exists local circuit cache 
measure called hit rate disc analysis demonstrate advantages instruction caching 
composite reconfiguration time system incorporates configuration caching includes time required reconfigure cache resources conventional reconfiguration interface 
time represented terms hit rate follows effective configuration time ce delta cache gamma delta cases time required reconfigure circuit cache significantly smaller external reconfiguration rate cache 
cases reconfiguration time cached circuits ignored effective reconfiguration time reduces ce gamma delta system exploits caching circuit configurations consume hardware resources conventional configuration approach 
increased hardware resources needed implement cache represented ffa functional density metric balance reduction reconfiguration time added resources 
simplified reconfiguration time equation ffa area measurement functional density reconfigurable system employing circuit caching represented follows cache ffa gamma delta system exploits temporal locality circuit configurations increase functional density improvement reconfiguration time overrides added hardware cost 
conditions configuration caching improves functional density reducing relationship cache functional density conventional non cached system ffa gamma ff gamma ff gamma configuration improvement techniques configuration caching easier justify configuration ratio conventional approach large 
benefits configuration caching available applications demonstrating high hit rate 
relationship evaluate configuration caching methods replication fpga resources multiple context fpgas 
replication fpga resources simple method creating configuration cache replicate set fpga resources system interconnect parallel suggested 
frequently configurations cached added fpga resources activated needed run time environment 
cached configurations preloaded resource time consuming configuration process avoided 
configuration needed exist cache fpgas traditional configuration methods add configuration fpga cache resources 
fpga idle fpga operating fpga reconfiguring external interface multiple fpga resources interconnected form configuration cache 
method configuration caching demonstrated adding fpga resources rrann application described section 
circuit configurations application cached system augmenting neural processor fpga additional cache fpgas see 
interconnecting fpgas parallel original neural processor fpga fpgas may operate successfully neural processor configuration 
clearly fpgas may operate time avoid signal contention 
ram update fpga backpropagation feed forward ram update fpga backpropagation feed forward ram update backpropagation feed forward fpga rrann neural processor cache 
initiating neural network application fpga neural processor configurations feedforward backpropagation update 
run time neural processor fpgas executes sequentially dictated schedule 
neural processor configured fpga time consuming configuration processes associated rrann avoided 
aside minor delays needed activate cached configuration execution stage cycle continues interruption 
fpgas neural processor triples resources required system ff 
resources justified relationship equation holds 
fortunately fpgas replace need reconfiguration insure hit rate 
neuron example rrann exhibits configuration ratio see table additional fpgas cache justified 
impact configuration cache rrann identified adapting run time reconfigured functional density metric equation cached system 
specifically area consumed neuron multiplied clbs neuron clbs neuron 
addition reconfiguration time adjusted represent effects configuration caching 
case reconfiguration time completely eliminated configurations fit cache 
modifications provide functional density cached rrann system rrann cache clk neuron network configuration caching increases functional density rrann wups clb second improvement 
large configuration overhead original rrann system reduction configuration time offsets overhead imposed configuration caching 
greater values configuration ratio conventional rtr approach decreases suggests advantages configuration caching provide diminishing returns neurons system 
functional density cached rrann system original rtr system static system plotted function compare 
multiple context fpgas creating configuration cache replicating conventional fpga resources improve functional density extremely inefficient caching method 
expensive fpga resources create cache idle time configuration memory device device active 
efficient method provide multiple circuit contexts single reconfigurable device 
devices called multiple context time multiplexed fpgas provide efficient circuit caching replicating configuration memory reconfigurable device 
multiple context fpga created replicating configuration memory cell programmable resource device 
context contains distinct memory element programmable cell switch interconnect resource 
active context selected multiplexer controlled global context select signal 
allows switching active context rapid rate 
organization context fpga rtr system best case cached rtr system conventional rtr system static system neurons layer functional density cached rrann system function network size 
demonstrated 
configuration select programmable logic interconnect context memory multiple context fpga 
multiple context fpgas developed proposed 
dynamically programmable gate array dpga proposes provided configuration contexts dynamic memory cells multiple context configuration memory 
second example includes time multiplexed fpga outlined xilinx 
proposed device provides configuration contexts allows storage communication context state micro registers 
addition rapid reconfiguration devices designed related purposes 
ability reconfigure device clock cycle allows single device operate multiple independent functions 
includes emulation large circuits 
large circuits requiring resources static device execute multiple context device dividing scheduling circuit distinct time exclusive partitions 
run time reconfigured systems multiple context fpgas provide advantages high speed circuit caching lower hardware cost replication discrete fpga devices 
time multiplexed fpga proposed xilinx example provides circuit contexts amount resources required comparable single context fpgas ff 
conventional devices context system requires fpgas ff 
reducing hardware cost configuration cache multiple context fpga systems justify configuration caching 
example minimum configuration ratio required application exploiting approach solving equation ff gamma gamma ff gamma assuming best case hit ratio minimum configuration ratio reduces ff gamma 
area overhead example limits configuration caching systems configuration overhead configuration time original non cached rtr system greater twice execution time 
hardware overhead ff increases fewer applications enjoy benefits circuit caching 
constraint placed cached systems minimum hit rate min minimum hit rate solving equation 
ff gamma fff assuming best case configuration ratio absolute minimum hit rate reduces ff gamma ff area overhead ff example requires minimum configuration hit rate configuration caching considered 
overhead increases hit ratio restrictive 
bounds parameters listed table proposed context xilinx fpga ff conventional fpga cached system ff 
clearly efficient fpga configuration cache justified extreme cases 
ff min min table configuration overhead hit rate bounds values ff 
distributed configuration configuration improvement technique involves distribution configuration programmable device 
providing single global configuration interface distributed configuration interface allows programmable resources device configured independently simultaneously 
distributing configuration interface device allows aggregate configuration bandwidth scale larger devices 
introduced architectures distribute configuration reviewed 
striped configuration example device proposing distributed configuration striped configured fpga developed cmu 
partially reconfigured fpgas architecture reduces granularity configuration smaller subblocks device 
atomic unit configuration device coarse grain logic stripes 
ideally stripes large implement pipeline stage application small preserve fine granularity configuration 
device distributes configuration allowing stripe configured nearest neighbor 
configuration interface involves local interconnect adjacent stripes reconfiguration occur clock cycle 
simultaneous configuration stripes clock cycle provides extremely high aggregate configuration bandwidth 
device best suited deeply pipelined applications ability shift circuit configuration device allows large pipelined applications operate essentially configuration overhead 
wormhole run time reconfiguration example device distributes configuration wormhole run time reconfiguration colt fpga 
centralized configuration controller coarse grain programmable resources configured independent streams 
streams contain header information self steer appropriate reconfigurable resources 
form partial reconfiguration approach allows reconfiguration resources stream path requiring change 
addition independent nature streams allow multiple streams configure different resources array simultaneously 
targeted stream dsp applications device reconfigures programmable resources data driven manner 
applications mapped architecture including dot product calculation floating point multiplication factorial computation 
data arrives device configuration streams prepare logic resources computation configuring resources needed application 
distributed independent nature configuration device allows configuration bandwidth scale device size application resource requirements 
summary configuration techniques chapter improve configuration performance directly enhancing configuration interface exploiting unique application specific properties 
released xilinx fpga example provides order magnitude improvement reconfiguration time widening optimizing configuration interface 
performance conventional configuration methods falls short requirements placed run time reconfigured systems improvements reconfiguration time provided techniques offers promise rtr systems 
exploiting reconfiguration improvement techniques advantages rtr available systems 
chapter study run time reconfigured systems began successful demonstration run time reconfigured systems 
application examples suggested rtr offers advantages configurable computing machines light lengthy reconfiguration times conventional devices 
trade improvements computing efficiency reconfiguration time clearly understood 
analysis rtr applications motivated need quantify clarify trade 
concluding chapter review key principles dissertation suggest research directions 
review reconfigurability fpga circuits allows exploitation unique specialization techniques 
techniques increase efficiency performance special purpose computing applications 
common specialization techniques exploited ccm systems include ffl customizing functional units ffl exploiting concurrency ffl optimizing communication networks ffl customizing interfaces 
ccm applications demonstrated impressive computational efficiency performance specialization techniques 
run time reconfiguration improvements efficiency performance provided circuit specialization extended reconfiguring ccm applications run time 
appropriate ccm applications rtr increase specialization applications exhibiting conditions ffl existence temporal locality circuit ffl insufficient resources large specialized architecture 
temporal locality application specific architectures temporally active circuitry rtr replace idle circuitry useful circuitry run time 
insuring fpga resources composed active useful circuitry times run time reconfiguration improves efficiency computation allows computation take place fewer resources 
insufficient resources deeply pipelined highly specialized applications resources required available single ccm 
circuit partitioned scheduled static ccm general purpose architectural features added support architectural variation circuit partitions 
special purpose nature systems preserved reconfiguring circuit partitions run time 
run time reconfigured applications exploiting conditions reviewed chapter 
run time reconfigured neural network rrann successor rrann ii exploit temporal locality backpropagation training algorithm 
systems reduce hardware requirements computation reconfiguring special purpose neural processors temporally exclusive stages algorithm 
bit serial template matching circuit method propagating template constants hardware run time 
run time reconfiguration hard wired constants allows computation take place hardware generalpurpose approach 
run time reconfigured sequence comparison architecture preserves special purpose nature character matching pes limited hardware system 
advantages rtr demonstrated programmable processor architecture 
dynamic instruction set computer uses rtr reconfigure special purpose instruction set run time 
run time reconfiguration allows relatively small fpga resource emulate extremely large application specific instruction set 
extremely specialized application specific instruction modules may processor instruction removed replaced instruction time 
functional density rtr approaches requires additional time circuit reconfiguration 
cases excessive reconfiguration time diminishes advantages rtr 
functional density metric balance reduction hardware execution time provided rtr reconfiguration overhead 
rtr ccm architecture provides functional density conventional static alternative 
run time reconfigured applications introduced chapter analyzed functional density metric 
summarized table rtr increases functional density applications 
applications reviewed chapter represent particularly wide application range demonstrate positive results today limited technology 
early positive results suggest rtr may important technique fpga devices improve application understanding grows 
configuration time clear application study chapter reconfiguration time plays important part functional density run time reconfigured applications 
lower reconfiguration overhead application greater functional density 
addition faster reconfiguration allows applications shorter execution times enjoy benefits rtr 
reconfiguration times conventional devices long applications 
fortunately relatively new fpga devices research efforts address issue 
techniques reviewed ways improving reconfiguration fpga devices ffl increase configuration bandwidth ffl reduce configuration data partial configuration ffl execute reconfigure parallel ffl exploit temporal locality ffl distribute configuration 
techniques require additional hardware resources hardware cost technique balanced improvement reconfiguration time functional density metric 
cases larger configuration ratio rtr application easier justify costs configuration improvement technique 
techniques improve reconfiguration time fpga devices additional applications benefit run time circuit specialization 
run time reconfigured applications reviewed represent small fraction applications developed custom computing machines 
appears growing interest rtr configurable computing machines research field infancy 
lack results attributed tremendous amount effort required implement working run time reconfigured system 
tools devices adequately support rtr integrating rtr application requires considerable effort 
section briefly review hurdles suggest appropriate research directions extending understanding rtr ccm systems 
applications applications successfully demonstrated rtr additional rtr application examples needed identify appropriate application areas introduce implementation approaches 
demonstrations identify limitations current technology may suggest methods maximizing benefits rtr 
application examples provide data points needed determine breadth applications rtr 
essential aspect rtr application effort architectural comparison static non configured alternative 
comparison suggests rtr appropriate application 
rtr justified application current technology comparison may suggest appropriate rtr possibly improved technologies 
case architectural contrasting provides additional information benefits limits potential run time reconfiguration 
design tools design development working run time reconfigured system requires considerable effort conventional design tools available today 
tools directly supports design run time reconfigured applications important difficult design steps rtr application done hand 
designer manually identify appropriateness rtr application temporally partition system hand 
determining relatively equal sized partitions rrann example time consuming iterative process requiring design changes frequent circuit place route 
partial reconfiguration run time reconfigured circuits manually mapped fpga resources insure proper alignment interconnection existing static logic 
partially reconfigured rrann ii project example required careful time consuming hand layout insure address generation logic multiplier extensions control operate properly reconfigured existing static circuits 
temporally exclusive circuits physically independent physical changes circuit disrupt physical layout circuits 
excessive design costs run time reconfigured systems inhibit development additional rtr applications 
design run time reconfigured applications simplified design tools developed specifically rtr 
important design tools assist temporal partitioning run time reconfigured circuits 
efforts investigating tools identifying methods expressing temporal locality 
multi context fpga devices tools created logic temporal partitioning 
addition partial evaluation dynamic networks suggested ways expressing run time reconfiguration 
efforts simplifying physical mapping partially reconfigured circuits include virtual hardware manager responsible run time physical translation partial circuits incremental configuration generator 
hopefully developments related tools reduce design efforts required create run time reconfigured application 
device architectures conventional fpgas clearly designed run time reconfiguration mind 
fact successful demonstration rtr fpgas surprised people 
suggested chapter important device issues improvement reconfiguration time 
configuration improvement techniques improve functional density rtr applications reducing cost configuration 
device enhancements need limited configuration improvement techniques 
related architectural enhancements include coarse grain logic functions arithmetic computation inclusion fixed function components 
custom processor example simplify sequencing run time circuits providing built support logic configuration 
addition internal memory may allow internal manipulation configuration data 
architectural modifications improve functional density ease development run time reconfigured applications 
rtr important design technique configurable computing machines applications demonstrate advantages additional design tools simplify application development architectural modifications improve reconfiguration time 
appendix special purpose bit serial template matching circuit template matching common operation image understanding target recognition systems 
operation example important computation sandia automatic target recognition system atr 
parallelism fine granularity regularity operation ideal candidate ccm architectures 
systems demonstrate advantages ccm technology application exploiting unique innovative implementation techniques 
section describe implementation details bit serial approach algorithm exploits benefits constant propagation :10.1.1.17.6915
template matching circuit described section computation cross correlation image target template cross correlation theta image theta template defined gamma gamma delta output image defined template image input image completely overlap image indices fall defined input image range restriction limits size valid output image gamma theta gamma 
computationally intensive operation requires mn multiply accumulate operations output pixel gamma gamma mn multiply accumulate operations correlation entire image 
precision template image limited single bit order reduce computational requirements operation 
binary template simplifies computation replacing multiplications equation simple operation 
multiplications needed entire operation performed addition 
simplification significantly reduces hardware resources required implement computation fpga resources 
building multipliers hardware simple gates adders 
important benefit custom hardware correlation operation ability exploit large amounts parallelism 
sufficient hardware proper access image data mn accumulation operations required output pixel performed parallel 
providing dedicated processing element pe mn accumulation operations allows custom solution achieve significantly greater levels parallelism general purpose approaches 
conditional adder pe perform accumulation operation 
input image pixel gated template bit input image bits 
corresponding template bit image pixel passes gate accumulated incoming partial correlation sum 
image pixel gated partial sum passes unmodified output pe 
sum sum binary template correlation pe 
ways organize mn pes needed parallel computation implementation approach described 
column processor computes partial sum correlation follows gamma delta column processor created tiling correlation pes shown 
column processor dedicated single column template image performs summation operation template pixels column gamma 
provide column processor sufficient data image values broadcasted column suggested 
correlation column processor 
complete correlation value computed parallel summing results column processors column template image gamma delta delta delta pm gamma parallel computation correlation operation column processors shown signal flow graph 
implementation provides column processors pes operating parallel adder network sums results 
parallel computation column processors 
suggested pe correlation array dedicated different pixel template image 
pes programmed perform function dictated corresponding template pixel value 
pes corresponding pixel template image perform accumulation function pes corresponding pixel perform simple pass function 
addition spatial arrangement pes pe array corresponds spatial arrangement pixels template image pe located pe array corresponds pixel template image 
spatial correspondence pes template image shown 
pipelined correlation circuit operates mn image pixels simultaneously pixels loaded circuit cycle 
output pixel column pixels column processor pipelined circuit shown 
example produce output pixel column input image data gamma gamma gamma loaded column processor 
compute row output image pe array requires template image array function spatial organization correlation pe 
clock cycles stream input image rows array 
gamma valid output pixels provided additional gamma input pixels needed fill pipeline 
gamma output rows total computation time circuit gamma delta clk retiming correlation array registers pipeline input image data pe array consume considerable hardware resources 
shown gamma image pixel registers required buffer data 
typical bit image data represents considerable amount fpga resources 
fortunately operation reduce internal image buffering registers 
shown internal buffering registers removed adding retiming registers sum column processor 
approach termed column broadcast circuit allows broadcast input image data column processors 
bit serial arithmetic hardware implement mn adders required array significantly reduced employing bit serial arithmetic 
fully parallel adder conditional adder processor array 
significantly smaller conditional bit serial adder 
simple block diagram conditional bit serial adder shown 
carry sum template sum sum bit serial correlation pe 
small size conditional bit serial adder allows large mn array adders fit easily modest sized fpga 
bit serial operators advantages 
limited combinational logic bit serial operators allows circuit operate significantly higher clock rate 
second memory bandwidth clock period significantly reduced 
broadcasting bit pixel values clock bit values required 
input sequence column processor order support bit serial arithmetic 
single bit pipelining register lies sum bit conditional bit serial adder input image values column broadcast simultaneously 
input pixel value offset adjust delays 
insure proper data alignment input succeeding pe delayed single bit 
demonstrates skewed input sequence column length 
pe receives lsb associated image pixel cycle 
order properly sum results pe second pe image pixel input second pe delayed single bit 
sent cycle followed individual bits appropriate pixel 
process delaying input pixels single bit continues rest pes 
sum delay registers output pe column processor delayed cycles shown 
proper data alignment bit serial correlation pes 
sending bits input image pixel zero bits follow allow bit growth correlation sum 
image bits plus zero bits provide arithmetic range worst case correlation sum 
worst case sum mn times largest image pixel value 
bit image data largest correlation sum mn requires bits log mn insure array handle bit growth log mn zeros sent bit input value 
bit length number clock cycles required process output pixel 
total time required process entire image bit serial arithmetic qm gamma delta clk propagating template constants template matching systems input images correlated single template 
cases function pe correlation array changes template values propagated directly pe array 
propagating template array reduces hardware requirements circuit decreases system cycle time 
constant propagation template matching system general purpose pes replaced efficient specialpurpose pes 
unique pes available correlation array constant constant 
pes require fewer hardware resources general purpose pe removing template register propagating constant logic pe 
constant gate associated generalpurpose circuit removed 
reduces logic associated pe simple unconditional bit serial adder shown 
propagating constant pe provides greater reductions hardware 
hardware associated general purpose pe removed flip flop needed sum delay 
special purpose pes shown 
cell cell sum sum sum carry sum sum sum special purpose bit serial correlation pes 
template image cell cell cell cell cell cell cell cell cell cell cell cell cell cell cell cell special purpose array correlation pes special purpose array correlation pes 
dimensional array special purpose pes combined create custom correlation array specific template image 
special purpose correlation pe template pixel template image 
specialpurpose pes location template pixels special purpose pes locations template pixels 
demonstrates construction special purpose pe array arranging pes template image 
clay implementation general purpose special purpose implementation approaches template matching operation mapped national semiconductor clay fpga order determine benefits constant propagation 
specifically correlation pes designed general purpose pe special purpose pes 
pes designed facilitate tiling simple dimensional structure 
theta array pes created verify design 
general purpose pe requires clay primitives shown half adder xor gate registered multiplexer inverter registered half adder 
physically mapped clay device additional cells required routing 
shown pe consumes total fpga cells 
critical path pe calculated cycle ns total area consumed system pe gp mn fd inv inv xond fd fdmux fdmux fdmux fdmux physical bit serial adder layout 
expected special purpose cell requires fewer hardware resources 
architecture propagating template value timing parameters calculated fastest device parameters interactive layout editor fd xond xond inv inv physical layout bit serial add 
circuit allows removal registered multiplexer gate 
removal resources simplifies routing requirements cells needed route pe 
pe consumes cells slightly faster cycle time ns 
physical layout circuit seen 
special purpose cell requires fewer hardware resources 
pe requires single flip flop clay cell needed 
cell operates speed ns 
need tile pe special purpose pe forces standard physical footprint 
pe designed consume cells empty routing order facilitate interconnection cell counterpart 
total area required array special purpose pes sp mn functional density advantages constant propagation template matching system identified comparing functional density approaches 
functional density application measured diving performance measured terms correlations second total area cost correlations cell second functional density measured terms correlations cell second 
performance performance system obtained dividing number valid correlation output pixels total execution time 
output image size gamma theta gamma execution time equation performance calculated gamma gamma qm gamma delta clk gamma qm delta clk large images ae performance simplified follows delta clk area shown equations area circuit simply mna pe pe circuit size corresponding pe 
dividing performance area measurement produces functional density operation follows gamma mna pe qm delta clk mna pe delta qt clk functional density approaches listed table template size theta correlation quantization bits 
improved speed size special purpose cell improves functional density 
pe pe clk path cells ns correlations cell second general purpose theta special purpose theta special purpose theta values worst case cell table correlation cell parameters 
appendix edit distance algorithm edit distance algorithm popular method comparing similarity character strings complex genetic sequences 
computational workload required problem implemented custom vlsi chips ccm hardware 
section review algorithm implementation approach describe constant propagation reduce hardware resources 
edit distance defined minimum cost transforming sequence operations insert delete substitution 
distance source sequence delta delta delta target sequence delta delta delta defined terms distance sub sequences delta delta delta delta delta delta 
sub sequence distance defined follows gamma del gamma ins min gamma del gamma int gamma gamma sub del cost deleting character ins cost inserting character sub cost substituting character particular implementation del ins sub 
dependency graph calculation described equation shown source target sequence length 
locality dependency graph edit distance calculation 
communication nodes dg suggests systolic architecture computation 
mapping dg systolic architecture involves assignment scheduling nodes dg processor elements pe 
nodes assigned processor elements projecting straight line projection vector dg assigning nodes line common pe 
nodes pe scheduled applying uniformly spaced set hyper planes dg normal schedule vector projection methods possible projections common bi directional unidirectional 
projections implemented splash ii 
implementation described chapter unidirectional array 
unidirectional array unidirectional array created assigning nodes column dg pe 
projection vector points downward shown 
nodes scheduled nodes diagonal execute time 
schedule vector points diagonally downward normal hyper planes shown 
projection schedule produces signal flow graph 
projection requires processors size source sequence 
target sequences length computed streaming sequence array 
name suggests data flows single direction array results streaming opposite 
projection hyper planes unidirectional array 
signal flow graph unidirectional array 
pes array perform functions character matching distance value computation 
pe compares incoming target character locally stored source character 
match detected distance value change cost keep character 
characters match distance updated equation 
simple block diagram functions pe seen 
pes array operate parallel computation continues entire target sequence traversed array 
source sequence length target sequence length desired result distance value unidirectional array schedule value available pe pem gamma cycles 
cycles required completely stream target sequence gamma cycles required flush array 
distance calculation match unit target character input distance source character block diagram unidirectional pe 
specialization unidirectional array assigning nodes dg column processor shown offers optimization possibilities available schedules bi directional array 
suggested dg column nodes dg match single source character target characters 
assigning pe single column insures pe array matches source character incoming target characters entire computation 
pe example compares target characters source character cycle computation 
constant nature source characters pe exploited propagating value pe 
propagating source character pe offers advantages 
logic associated general purpose matching unit removed 
source character register input multiplexor associated general purpose matching unit removed 
source register target register general purpose matching unit 
second general purpose matching function performed generalpurpose matching unit replaced custom matching unit designed match desired source character constant source character folded matching function 
result optimizations smaller efficient matching circuit 
sample special purpose matching unit shown 
target register special purpose matching unit 
exploit technique complete edit distance calculation system library special purpose matching units created character alphabet 
custom pes created replacing general purpose matching unit corresponding special purpose matching unit 
pe composed special purpose matching unit shown 
distance calculation target character input distance match constant propagated processing element 
parallel array special purpose pes created tiling pes needed sequence custom pes 
special purpose pe array match corresponding source character demonstrates array source sequence 
mapping clay fpga demonstrate advantages propagating source character matching unit pe general purpose pe specialized pe mapped national semiconductor clay fpga 
pe pe pe pe customized source sequence processor array 
mapping algorithm clay architecture required design modules distance unit pes general purpose matching unit specialpurpose matching units 
designs addressed separately 
distance unit shown distance calculation unit contains distance inputs control signals match unit 
distance inputs include input distance preceding pe input delayed input preceding pe input current distance input 
inputs match unit include null signal indicating null target character match signal indicating match source target characters 
simplify hardware distance calculation bit modulo distance encoding scheme implemented design 
encoding scheme reduces precision distance values pe bits 
computation output distance bits optimized clay architecture follows null delta null delta match delta null delta null delta delta phi match delta null delta phi delta phi circuit implementing function consumes clay cells flip flops xor gates multiplexors flip flop multiplexor primitives shown 
physically mapped clay fpga circuit consumes cells theta block cells operates ns cycle time see 
circuit designed facilitate aligning input distance value left output distance value right 
addition null match inputs provided top cell 
general purpose matching unit implementation bit dna character data representation described 
character bits represent basic nucleotides form dna sequence adenine 
match occurs target character bits match corresponding source character bit 
encoding scheme allows representation wild card characters 
single character sequence represented nucleotides setting character bits 
example bit character represents nucleotide adenine 
matching unit provide null signal addition match signal 
signal prevent improper modification distance value empty pipeline fills 
null signal generated simply ing template character input bits 
circuit implement general purpose matching unit consumes clay primitives shown 
physically mapped clay fpga circuit consumes cells theta block cells operates ns cycle time 
circuit physically designed abut directly distance unit described tile horizontal direction aligning input target characters left output target characters right 
layout circuit shown 
special purpose matching unit special purpose matching units designed calculate match null signals generated general purpose matching unit 
propagating source character matching circuit significant hardware resources removed 
specifically source character register input multiplexers removed circuit 
addition fully populated tree gates perform general purpose compare character bits reduced bits interest source character 
special purpose matching unit designed match target characters character demonstrates reduction hardware 
shown circuit requires clay primitives simpler routing requirements 
physically mapped device circuit consumes cells theta block shown 
special purpose matching unit useful single source character designed custom matching unit designed unique character alphabet case 
special purpose matching unit created modifying circuitry create match signal 
fortunately addition gates wild card characters increase physical size circuit 
shown special purpose matching circuit worst case character consume additional physical resources 
area timing edit distance circuits summarized table 
complete edit distance pe created combining distance unit matching units 
general purpose pe requires cells theta operates ns cycle time dictated match unit 
layout pe shown 
special purpose pe requires cells theta operates clock rate ns 
layout efficient pe shown 
area cells time ns distance unit theta general purpose match theta special purpose match theta table area time comparison edit distance components functional density advantages constant propagation identified comparing functional density general purpose special purpose pes 
functional density application measured dividing throughput performance measurement cell updates second cups associated area cost cell updates area delta time functional density measured terms cell updates cell second cups cell 
sum area required distance match unit cells additional cells consumed due differences aspect ratio components 
cells rectangular area consumed pe adjacent pes total area cost pe reflect wasted resources 
cell updates number cell updates particular sequence comparison number nodes cells dg 
number nodes square dg simply product source character length target character length cell updates source length theta target length mn execution time time required execute algorithm uni directional array amount time required stream complete target sequence source sequence pes 
target sequence length source sequence length cycles required enter target sequence array gamma cycles required flush array data 
total time processing array cycle count multiplied cycle time gamma delta clk area described earlier pe required character source sequence 
total area circuit simply number source characters times area pe ma pe composite functional density obtained combining previous equations mn ma pe gamma clk calculation simplified assuming source target sequences length ae pe clk improvements functional density due constant propagation evaluated applying circuit parameters pe equation 
results shown table demonstrate constant propagation improves functional density edit distance pe 
area cells time ns cell cell general purpose pe theta theta special purpose pe theta theta table functional density general special purpose edit distance pes distance calculation unit michael reconfigurable logic laboratory created modified copyright brigham young university fdmux match clk clk clk clk fd fd null new fdmux xo new mux sel xo sel mux distance edit distance algorithm distance unit schematic 
fd fd xo fd fd fdn xo mux mux fdmux fdmux nd xo inv layout clay distance unit 
michael reconfigurable logic laboratory created modified copyright brigham young university match nd match nd match nd match nd char fdmux char fdmux char fdmux char fdmux fd fd fd fd load clk clk clk clk load clk clk load clk clk load match match match match null ort null ort null ort null match desired general purpose character matcher general purpose matching unit schematic 
fdmux fd fdmux fdmux fd fd fdmux fdmux fd fd fd nd nd nd nd fdmux general purpose matching unit layout 
michael special purpose character matcher spm reconfigurable logic laboratory created modified copyright brigham young university outb match match outb null outb outb outb fdn clk fdn fdn fdn null null nd null inv inv clk clk clk outb inv inv inv inv inv inv outb outb outb outb character special purpose matching unit schematic 
fdmux nd inv inv inv inv fd fdn fdn fdn fdn fdmux nd special purpose matching unit layout 
fdmux nd inv inv inv inv fd fdn fdn fdn fdn fdmux nd worst case special purpose matching unit layout 
fd fd xo fd fdmux fdmux fd fd fdmux fdmux fd fd fd fd xo mux nd nd nd nd mux fdmux fdmux xo fd fdmux fdmux fd fd fdmux fdmux fd fd general purpose edit distance pe layout 
mux fdmux fdmux nd xo inv inv inv inv fd fd fdn fdn fdn fdn xo mux mux fdmux fdmux nd special purpose edit distance pe layout 
appendix disc special purpose stored program processors effective components application specific computing environment combine enhanced performance special purpose circuitry flexibility programmable processor 
customization instruction set functional units interfaces memory hierarchy control substantially improve performance simplest programmable processors 
addition special purpose features limits application domain processor processor specialized application unsuitable unrelated applications 
limited application domain special purpose processors inhibits wide spread fails justify high development costs economically viable processor 
reconfigurability fpgas ideal implementing specialpurpose processors 
special purpose processor designed fpga application reconfigured different special purpose processor time 
number general purpose processors developed demonstrate feasibility implementing processor architecture fpga 
special purpose processors successfully demonstrated advantages adding specialized hardware general purpose processor cores 
application areas processors include digital audio processing systems linear equations statistical physics 
significant limitation building customized processors fpga resources lack hardware resources available processor core special purpose processor extensions 
suitable processor core coupled special purpose processor extensions quickly consume resources largest fpgas available today 
cases special purpose processor extensions periodically specified executing program 
special purpose processor extensions remain idle waste valuable reconfigurable hardware resources 
fortunately run time reconfiguration hardware resources replace idle unused circuitry useful special purpose functions 
programmable processor environment run time reconfiguration add remove performance enhancing special purpose hardware specified executing program 
flexibility allows processor architecture enjoy wide variety special purpose functions processor extensions worrying resource limitations 
reconfiguring processor extensions run time similar paging virtual memory system 
paging blocks main memory physical memory needed executing program limitations physical memory overcome provide larger virtual memory space 
fact rtr increase available hardware called virtual hardware 
dynamic instruction set computer disc programmable processor architecture employs approach 
rtr application specific instruction modules added removed hardware resources application execution 
application specific instruction modules removed program execution different custom instructions executing program 
run time reconfiguration disc instructions overcomes limitations physical hardware allows essentially unlimited instruction set application program 
architectures propose run time circuit reconfiguration processor 
programmable instruction set computer prisc proposes incorporate hardware programmable functional units pfu datapath conventional microprocessor 
residing cpu chip offer high speed custom solutions complex irregular combinational functions 
able perform wide variety special purpose combinational functions program reprogramming pfu run time 
initial analysis architecture suggests reconfigurable increases specint benchmark mhz mips 
garp architecture programmable processor exploits rtr 
garp architecture standard mips processor tightly coupled array reconfigurable hardware 
relatively large amount reconfigurable resources allows complex special purpose functions operate reconfigurable array 
instructions added mips core provide reconfiguration hardware resources program execution 
initial estimates architecture indicate reconfigurable array mips processor increase performance order magnitude selected applications 
cases ability support hardware reconfiguration execution allows limited array programmable hardware exploit wide variety application specific functions program 
section describe disc architecture implements run time reconfiguration instruction set efficient manner 
disc architecture disc architecture composed simple processor core coupled array reconfigurable logic seen 
reconfigurable processor architectures reconfigurable logic enhance performance processor core application specific processor extensions 
disc application specific processor extensions organized custom processor instructions 
reconfiguration instructions added removed needed processor core 
reconfigurable logic disc architecture processor core reconfigurable logic 
custom instructions disc sequenced issued controlled static processor core traditional instructions general purpose processor 
executing time application specific instructions operate issued processor core 
addition custom instructions modify application specific behavior opcode operand provided complete instruction word 
organizing application specific processor extensions form custom instructions allows traditional programming tools compilers assemblers aid development disc applications 
traditional general purpose instructions custom instructions highly specialized deeply pipelined 
custom instruction modules perform application specific functions exploit performance enhancing specialization techniques described chapter 
specialization techniques allow custom instructions provide superior performance traditional sequence general purpose instructions 
custom instructions disc added removed processor circuit reconfiguration 
reconfiguration allows single application program unlimited number performance enhancing instructions 
wide variety performance enhancing custom instructions organized application sequencing traditional executable program 
reconfiguration custom instructions removes limits faced fixed silicon systems allows essentially infinite instruction set 
frequent reconfiguration custom instructions adds significant configuration overhead 
disc architecture addresses issue caching custom instructions reconfigurable logic resources 
frequently issued custom instructions cached reconfigurable logic resources executed reconfiguration time 
caching custom instructions reduces negative effects circuit reconfiguration exploiting temporal locality custom instruction execution 
run time execution example paging custom instructions assembly language program listing demonstrates principles 
initiating program reconfigurable logic cleared custom instructions 
program initiated instruction insta loaded program memory processor 
executing instruction processor queries reconfigurable resources determine presence custom instruction 
processor detects absence insta configures reconfigurable resource 
configured instruction executes normal 
fetching second instruction insta processor identifies presence insta module reconfigurable logic executes instruction configuration 
process configuration execution continues step program 
instruction fetched step program processor recognizes missing instruction attempts configure instruction reconfigurable resource 
reconfigurable resource happens listing sample disc assembly language program insta op insta op instb op op op op instb op op full accept instruction existing instruction removed 
case insta instruction replaced 
instruction instb resident reconfigurable resource executed reconfiguration 
executed replacing instruction 
table summarizes execution temporal composition instructions reconfigurable resource 
insta omega omega theta theta theta instb omega theta theta theta omega theta omega omega theta theta omega theta theta omega omega indicates active instruction theta indicates instruction hardware table run time composition sample disc instructions 
constructing processor architecture offers run time reconfiguration caching special purpose instructions involves unique architectural enhancements 
architectural features disc addressed ffl disc processor core ffl custom instruction specialization techniques ffl partial reconfiguration ffl relocatable hardware 
disc processor core reconfigurable processor architectures disc relatively modest weak processor core 
suggested hardware resources processor core intentionally limited preserve hardware performance enhancing custom instructions 
processor core capable performing computation performance sensitive operations computed reconfigurable logic resources 
ideally execution time spent executing custom instructions general purpose instructions available processor core 
disc processor core simple non pipelined accumulator processor core internal datapath bits see 
processor core designed completely fpga resources contains single bit accumulator register independent functional units perform general purpose processor operations 
addition processor contains program counter address register stack pointer performing standard instruction sequencing address calculation functions 
limited resources available processor core optimized provide surprisingly large instruction set 
general purpose instructions associated processor core include standard control instructions conditional unconditional branching basic arithmetic addition subtraction standard logical operations common shifting operations directional shifting rotate arithmetic shifting comparison operations equal equal greater 
performance processor limited instruction set rich support standard compiler custom instructions performance sensitive operations intended execute custom instructions disc processor designed provide flexibility control possible individual custom instructions 
accomplish dedicated processor core designed custom silicon solution fpga resources chosen flexibility prototyping environment fpga resources allowed experimentation architectural options 
real world implementation disc approach fixed silicon processor core 
disc instruction set include multiplication division standard library developed provide software support operations 
program counter address register stack pointer instruction register accumulator address bus functional units disc processor core 
custom instruction interface designed allows individual instruction modules exploit unique specialization techniques 
custom instructions exploit specialization techniques listed ffl special purpose datapath ffl control global resources ffl control instruction completion 
special purpose datapath important specialization techniques available custom instructions ability specialize datapath functional units applicationspecific operation 
described chapter techniques constant propagation exploitation concurrency logic optimization provide greater performance non standard application specific operations 
implementing applicationspecific function custom hardware replaces relatively long sequence instructions needed complete function programmable processor 
examples custom datapath units developed disc custom instructions include pipelined edge detection unit custom sorting unit morphological dilation erosion unit 
control global resources technique available custom instructions ability take control global resources processor core 
resources placed control custom instruction include external memory interface external interface internal accumulator register 
providing control resources allows custom instruction replace conventional addressing data transfer methods processor core custom interfaces appropriate effective application specific operation 
example custom image processing instructions control addressing external memories order optimize addressing patterns memory bandwidth processor 
application specific address generators operate parallel datapath instruction provide proper access pattern data introducing overhead 
custom control memory interface provides significant improvement performance avoiding typical multi instruction address calculation required data access patterns 
control instruction completion technique offered custom instruction interface ability custom instruction provide internal control indicate completion 
custom instruction issued processor core retains control global resources completes special purpose function 
cases custom instruction execute hundreds thousands cycles terminating 
control processor long period time offers advantages 
executing special purpose instruction extended period time allows custom instruction exploit deep pipelining 
extended execution times overhead loading flushing pipeline insignificant compared improvements throughput 
second suspending fetching decoding subsequent instructions long period time frees valuable memory bandwidth useful transfer data 
bandwidth transfer instruction data needed custom instruction 
partial reconfiguration essential aspect disc architecture ability page individual custom instructions processor run time 
paging instruction modules runtime allows processor operate essentially infinite instruction set idle unused instructions replaced demanded executing program 
addition ability hold custom instructions reconfigurable logic time form cache reduces configuration time frequently instructions 
features implemented effectively reconfigurable logic resource supports partial configuration 
disc environment partial reconfiguration significantly reduces overhead imposed circuit reconfiguration 
partial reconfiguration configuration time instruction size instruction size device 
custom instructions developed disc invariably vary size simple instructions require resources complex instructions require significant resources 
reconfigurable resource globally reconfigured configuration time size device worst case instruction size instruction module 
table demonstrates principle configuration bit streams instructions range complexity rows complex instruction complete clay configuration rows simple instruction complete clay configuration 
forcing complete configuration instruction imposes significant configuration overhead 
important advantage partial reconfiguration ability optimize composition instructions resident reconfigurable resources 
partial reconfiguration instruction module configured removed reconfigurable resource disturbing resident instruction modules 
allows frequently instruction modules remain resident hardware unneeded instructions replaced useful instructions run time 
time set instructions resident array demands executing program static analysis 
example consider composition instructions run time execution example table 
initially reconfigurable resource empty gradually filled instructions resources consumed 
resource filled additional instructions needed older useful instructions removed replaced needed run time 
time step example reconfigurable resource contains instructions instb 
step configuration required instb resident hardware 
composition instructions changes meet demands executing program 
relocatable hardware paging instruction modules disc virtual memory systems page blocks memory run time overcome resource limitations physical memory 
support paging memory individual memory pages relocatable physical memory 
relocation memory pages allows run time conditions dictate optimal memory management avoids conflicts imposed fixed overlapping memory pages 
demand driven paging custom instruction modules disc benefit relocation 
relocation custom instruction modules run time allows greater utilization limited physical hardware resources custom instructions placed dictated run time conditions 
custom instruction modules relocated operate physical location designed benefits instruction caching severely limited 
example custom instructions designed physical location physical circuits overlap exist reconfigurable logic time 
custom instructions frequently reconfiguration required time different physically conflicting instruction executed 
physical constraints reduce benefits circuit caching 
allowing custom instructions removes physical interdependencies facilitates effective instruction caching 
relocation hardware circuits simple relocating memory blocks 
hardware circuits contain physical constraints prevent arbitrary circuit relocation 
hardware circuits dimensional entities arbitrary shape 
relocating wide variety circuit shapes sizes constrained resource difficult problem solve run time 
example consider composition custom instructions reconfigurable resource 
irregular shaped custom instruction relocated dimensions optimal placement 
suggested circuit rotation translation facilitate problem complexity problem limits effectiveness run time environments 
relocation irregular shaped custom instructions 
second difficulty relocating hardware circuits need preserve communication circuit entities individual circuits operating isolation external influence limited communication circuit modules involves physical wires input ports providing inputs circuit output ports returning results 
physical wires specific physical locations 
successful communication circuits involves proper physical alignment communication ports 
circuits may physically coexist resources may able properly communicate respective input output ports properly interconnect 
relocation circuit modules implemented shape arrangement communication ports significantly constrained 
linear hardware space disc system solves physical issues constraining reconfigurable resources form linear hardware space 
custom instruction modules constrained conform physical shape communication protocol specified linear hardware space 
designed properly custom instructions able operate location linear hardware space relocated needed run time environment 
name suggests linear hardware space dimensional array reconfigurable resources 
dimensional grid configurable logic cells memory mapped flip flops provided xilinx fpga configuration interface may allow circuits operate isolation surrounding circuit modules 
central communication resource independent circuit modules introduces global communication bottleneck 
organized array horizontal rows suggested 
uniform communication network constructed logic array running global signal vertically die spreading global signals width die parallel 
communication network remains static processor execution 
linear hardware space communication network 
custom instruction modules operating linear hardware space designed horizontally width die 
module may consume arbitrary amount hardware varying height 
location instruction specified vertical location linear hardware space size specified terms height 
designed horizontally custom instructions access global signals regardless vertical placement 
suggested custom instructions designed operate independently custom instruction communicating global communication network local routing 
designed conform specifications linear hardware space custom instructions may operate vertical location 
addition multiple custom instructions may coexist hardware placing non overlapping regions 
suggested multiple custom instructions varying size reside linear hardware space conflict 
flexibility placement allows run time conditions dictate instruction composition placement 
width fpga global signals module placed vertical location constrained instruction module 
run time environment run time instruction swapping requires support dedicated run time hardware manager 
duties run time hardware manager include determining location run time reconfigured instructions deciding instructions remove hardware resources consumed optimizing utilization linear hardware resources 
disc system run time hardware management duties performed host computer 
host run time manager initiates disc application loading program memory target application second configuring disc fpga global controller 
host initiates application enabling clock preparing process run time instruction faults 
execution processor core validates presence instruction hardware 
instruction requested application program exist hardware processor enters halting state requests instruction module host 
receiving request instruction module host evaluates current state disc fpga hardware chooses physical location requested module 
physical location chosen available fpga resources existence idle instruction modules 
possible instruction module loaded fpga location currently occupied instruction module 
empty hardware locations available simple lru algorithm remove idle hardware 
idle instruction removed hardware instruction instruction instruction multiple instructions linear hardware space 
hardware different instruction 
removal step required avoid negative side effects 
stray circuitry consume additional power 
second existence unneeded hardware may interfere global control data lines linear hardware space 
third leaving idle unneeded hardware fpga may create undesirable asynchronous circuits 
circuits may create logic spikes adversely affect system 
unneeded instruction removed system host modifies bit stream requested hardware module reflect placement changes configures module linear hardware resources sending modified configuration information fpga 
provides simplified flow chart run time hardware management functions 
application example run time operation disc best demonstrated application example 
section describe operation object recognition algorithm custom disc instructions 
developing application disc involved distinct stages 
application specific custom instructions designed linear hardware space provide performance enhancing functionality 
second performance enhancing custom instructions stitched software 
case software program written compiled general purpose custom instructions compiler ported disc 
application instruction 
hardware available 
remove old instruction compute new location instruction configure module execute instruction fetch pc instruction disc instruction execution 
described related applications developed reordering custom instructions different software program 
object thinning object thinning common operation object recognition systems 
large amount data computation required steps operation amenable special purpose hardware 
library custom instructions image processing machine vision developed disc address image processing applications 
particular object thinning algorithm processes incoming images steps 
pre filtering 
thresholding 
skeletonization 
source code algorithm shown listing 
modification grey scale image step operation demonstrated 
purpose step reliance custom hardware described 
listing disc object thinning code 
main int thresh int hist int int skel skel int mean mean filter instruction clear clear histogram table histogram generate histogram thresh hist determine threshold value thresh thresh 
threshold thresh threshold image iterate skeletonization skel algorithm thinning skel complete skel skel original image low pass pre filtering threshold image image skeleton object thinning steps 
pre filtering step operation filter high frequency noise input grey scale image simple low pass filter 
removal high frequency noise reduces number unwanted foreground regions created thresholding step 
low pass filter operation processed custom filter instruction 
custom instruction described earlier section significantly improves performance processor employing custom address generation dedicated control pipelined datapath 
thresholding high frequency noise image removed ready operation thresholding 
thresholding algorithms reduce image information converting gray scale image simple binary image 
thresholding algorithms objects interest placed foreground image information placed background 
straight forward method performing thresholding operation compare pixel values image predetermined threshold value 
pixels intensity greater threshold value placed foreground threshold placed background 
process thresholding relatively simple obtaining threshold value troublesome 
method choosing threshold value begins obtaining histogram input image 
cases finding mean median pixel histogram sufficient 
simple approaches inadequate high contrast images dominant foreground background 
effective technique types images involves detecting peaks histogram 
surprisingly threshold value obtained calculating midpoint foreground peak background peak 
thresholding input image disc involves stages 
histogram image intensities created custom histogram instruction 
dedicated addressing unit operation significantly reduces control address overhead associated stream general purpose instructions 
histogram processed determine appropriate threshold value 
described operation requires identification histogram peaks 
short processing time operation need complex control suggest software approach appropriate 
thresholding operation performed image comparing pixel chosen threshold value 
custom threshold instruction designed perform operation 
skeletonization grey scale image converted simple binary image image information reduced skeletonization algorithm 
skeletonization algorithms reduce redundant shape information binary region order simplify process object recognition 
simplified images obtained skeletonization operation single pixel lines represent shape original object 
single pixel line representing object shapes called image skeleton 
skeletonization algorithms usually involve successive removal outer edges object skeleton object remains 
thinning process similar erosion operation uniformly outer edges image objects 
erosion object thinning completely destroy object disconnect object regions 
zhang suen thinning algorithm chosen acceptable results suitability hardware 
deeply pipelined image processing operations custom instruction created efficiently perform skeletonization operation 
run time execution executing steps object thinning requires custom image processing instructions lowpass clear histogram threshold skeleton instructions necessary support constructs shift compare add 
instructions consume rows custom logic times available static hardware custom instructions 
instructions fit processor time instructions swapped room instructions algorithm proceeds 
addition general purpose instructions paged hardware room large lowpass skeleton instructions rows respectively 
clean linear hardware space custom instruction modules lowpass clear histogram configured executed disc 
executing steps custom instruction space appears seen 
histogram control control clear memory low pass filter disc state executing histogram 
histogram complete software subroutine computes threshold value 
code performs operation uses general purpose instructions add compare shift 
room fpga modules disc room removing older modules 
stage lowpass module module removed 
displays state hardware space transition 
threshold value computed image converted binary image threshold custom instruction 
ample space hardware place instruction modules removed 
thresholding image image thinned skeletonization instruction 
stage skeleton module fit available hardware oldest modules clear histogram removed free hardware resources 
skeleton module place histogram compare clear memory add subtract control shift control disc state executing threshold value subroutine 
shift compare add subtract threshold control skeletonization control disc executing skeletonization instruction 
executed iteratively object thinning complete 
displays transition 
execution results purposes comparison versions object thinning algorithm implemented disc mhz pc 
cases disc outperformed pc significant margin shown table 
disc provided performance improvements host machine execution time spent configuring moving custom instructions 
silk screen image execution time spent configuring disc image disc speedup silk screen block letter news print table disc pc execution time 
handling instruction moving 
note disc running clock rate approximately mhz microprocessor 
module function rows configuration bytes add addition subtraction compare comparison operations shift shift rotate operations logical logical operations interface identify histogram median mean low pass filter invert image skeleton object thinning threshold image segmentation histogram histogram generation edge detection pc disc transfer clear image memory table image difference morph morphological operations table disc custom instructions 
appendix configuration data device input config config config config partial luts bits bandwidth bits lut time config mb sec ms frame mb sec ms frame mb sec ms frame mb sec ms frame mb sec ms frame mb sec ms frame mb sec ms frame mb sec ms frame average table lucent orca xx series fpga configuration data 
device les input config config config config partial luts bits bandwidth bits lut time config epf mb sec ms epf mb sec ms epf mb sec ms epf mb sec ms epf mb sec ms epf mb sec ms average table altera flex configuration data 
device les input config config config config partial luts bits bandwidth bits lut time config epf mb sec ms epf mb sec ms epf mb sec ms epf mb sec ms epf mb sec ms epf mb sec ms epf mb sec ms average table altera flex configuration data 
device clbs input config config config config partial luts bits bandwidth bits lut time config xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms average table xilinx xc configuration data 
device clbs input config config config config partial luts bits bandwidth bits lut time config xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms xc mb sec ms average table xilinx xc configuration data 
device clbs input config config config config partial luts bits bandwidth bits lut time config xc ex mb sec ms xc ex mb sec ms xc ex mb sec ms xc ex mb sec ms xc ex mb sec ms average table xilinx xc ex configuration data 
device cells config config config config partial bits bandwidth bits le time config xc mb sec ms ns cell xc mb sec ms ns cell xc mb sec ms ns cell xc mb sec ms ns cell average table xilinx xc family configuration data 
device cells config config config config partial bits bandwidth bits le time config mb sec ms ns cell mb sec ms ns cell mb sec ms ns cell mb sec ms ns cell average table atmel family configuration data 
device cells config config config config partial bits bandwidth bits le time config clay mb sec ms ns cell clay mb sec ms ns cell average table national semiconductor clay configuration data 
bibliography stephen brown robert francis jonathan rose 
field programmable gate arrays 
kluwer academic publishers 
stephen 
field programmable gate array technology 
kluwer academic publishers 
john richard 
field programmable gate arrays reconfigurable logic rapid prototyping implementation digital systems 
john wiley sons 
michael jon joseph varghese 
efficient logic system 
ieee international conference computer design vlsi computers processors pages 

dynamic reconfigurable logic xc logic cell array 
electro mini micro northeast conference record pages may 
fawcett 
applications reconfigurable logic 
moore luk editors fpgas proceedings international workshop field programmable logic applications pages oxford england september 
oxford university 
proceedings international workshop logic applications 
ieee computer society 
proceedings ieee workshop fpgas custom computing machines 
acm special interest group design automation sigda 
acm sigda international symposium field programmable gate arrays 
murray 
chameleon computer 
oem magazine systems software builders page december january 
doug conner 
reconfigurable logic hardware speed software flexibility 
edn design magazine electronics industry march 
john mayer 
reconfigurable computing redefines design flexibility 
computer design pages february 
waugh 
field programmable gate array key reconfigurable array outperforming supercomputers 
proceedings ieee custom integrated circuits conference pages 

searching genetic databases splash 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
shand bertin vuillemin 
hardware speedups long integer multiplication 
computer architecture news 
carter snider 
exploring architectures volume visualization custom computer 
pocek arnold editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
ieee computer society ieee computer society press 
athanas abbott 
real time image processing custom computing platform 
ieee computer february 
shand vuillemin 
fast implementations rsa cryptography 
th ieee symposium computer arithmetic 

field programmable gate array systolic computing 
borriello ebeling editors research integrated systems proceedings symposium pages 
athanas silverman 
processor reconfiguration instruction set metamorphosis 
ieee computer march 
king 
modular real time processing hardware 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
box 
common processor element packaging 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
hutchings 
density enhancement neural network fpgas run time reconfiguration 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
hutchings 
implementation approaches reconfigurable logic applications 
moore luk editors logic applications pages oxford england august 
springer verlag 
ross turner 
fpga hardware accelerator image processing 
moore luk editors fpgas proceedings international workshop field programmable logic applications pages oxford england september 
thomas michael butler 
pipelined high precision fft architecture 
th midwest symposium circuits systems volume pages 
allan fisher kung 
vlsi modern signal processing chapter special purpose vlsi architectures general discussions case study pages 
prentice hall 
john william mangione smith 
configurable computing 
scientific american pages june 

reprogrammable gate array applications 
proceedings ieee pages july 
bertin vuillemin 
programmable active memories 
jr editors systolic array processors pages 
prentice hall 
arnold buell davis 
splash 
proceedings th annual acm symposium parallel algorithms architectures pages june 
bertin vuillemin :10.1.1.137.6843
programmable active memories performance assessment 
borriello ebeling editors research integrated systems proceedings symposium pages 
vuillemin bertin shand touati 
programmable active memories reconfigurable systems come age 
ieee transactions vlsi systems 
bertin touati 
pam programming environments practice experience 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
moll 
implantation un algorithme de st er par corr sur active programmable perle 
technical report ecole des mines de paris centre de math ematiques appliqu ees sophia antipolis france 
laurent moll vuillemin 
high energy physics programmable active memory 
acm sigda international symposium field programmable gate arrays pages monterey ca february 
gokhale holmes lucas lopresti 
building highly parallel programmable logic array 
ieee computer january 
arnold 
splash software environment 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
arnold buell davis 
vhdl programming splash 
fpgas proceedings international workshop field programmable logic applications pages oxford england september 
gokhale lucas 
logic description generator 
technical report src tr supercomputer research center src 
gokhale 
data parallel reconfigurable logic array 
journal supercomputing 
pryor shirazi 
text searching splash 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
lopresti 
rapid implementation genetic sequence comparator field programmable gate arrays 
sequin editor advanced research vlsi proceedings university california santa cruz conference pages santa cruz ca march 
abbott athanas chen elliott 
finding lines building pyramids splash 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
athanas abbott 
image processing custom computing platform 
hartenstein editors field programmable logic architectures synthesis applications 
th international workshop field programmable logic applications pages prague czech republic september 
springer verlag 
jain rover 
convolution splash 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
shirazi walters athanas 
quantitative analysis floating point arithmetic fpga custom computing machines 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
graham nelson 
hardware genetic algorithm travelling salesman problem splash 
moore luk editors field programmable logic applications pages oxford england august 
springer verlag 
hutchings 
automated target recognition splash 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
dehon 
specialization versus configuration 
technical report mit transit project 
transit note 

data folding sram configurable fpgas 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 

high speed digital filtering sram fpgas 
th international conference vlsi design pages january 
les 
fir filters field programmable gate arrays 
journal vlsi signal processing 

xilinx fpgas design custom digital signal processing devices 
proceedings pages january 
chou evans 
fpga implementation digital filters 
proceedings fourth international conference signal processing applications technology pages santa clara ca 
van jeavons shawe taylor 
stochastic neural architecture exploits dynamically reconfigurable fpgas 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
cox blanz 
ganglion fast field programmable gate array implementation connectionist classifier 
ieee journal circuits march 
gunther milne narasimhan 
assessing document relevance run time reconfigurable machines 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 

run time reconfiguration fpga scanning genomic databases 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
charles seitz 
vlsi parallel computation chapter concurrent architectures pages 
morgan kaufmann 
leonard haynes richard lau daniel siewiorek david 
survey highly parallel computing 
ieee computer pages january 
ivan carver mead 
microelectronics computer science 
scientific american september 
kung 
systolic architectures 
ieee computer pages january 
shand 
flexible image acquisition reconfigurable hardware 
athanas pocek editors ieee workshop fpgas custom computing machines pages napa ca april 
moll shand 
systems performance measurement pci pamette 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
dunlop 
dynamic reconfiguration fpgas 
moore luk editors fpgas proceedings international workshop field programmable logic applications pages oxford england september 
rosenberg 
implementing cache logic tm fpgas 
configurable logic design application book pages 
atmel san jose ca 
rosenberg 
data acquisition systems cache logic fpgas 
configurable logic design application book pages 
atmel san jose ca 
andr dehon 
dpga utilization application 
acm sigda international symposium field programmable gate arrays pages monterey ca february 
james hadley 
performance enhancement run time reconfigurable fpga system reconfiguration 
master thesis brigham young university provo ut november 
kung 
vlsi array processors 
prentice hall 
don heller 
vlsi modern signal processing chapter partitioning big matrices small systolic arrays pages 
prentice hall 
dan moldovan jose fortes 
partitioning mapping algorithms fixed size systolic arrays 
ieee transactions computers january 
law 
artificial neural network implementation fine grained fpga 
hartenstein editors field programmable logic architectures synthesis applications 
th international workshop field programmable logic applications pages prague czech republic september 
springerverlag 

simulation tool dynamically reconfigurable field programmable gate arrays 
ieee transactions large scale integration vlsi systems september 
murray 
pulse arithmetic vlsi neural networks 
ieee micro pages december 
schoner jones 
issues wireless coding run time reconfigurable fpgas 
athanas pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
national semiconductor 
configurable logic array clay data sheet december 
gordon john gray 
reconfigurability variable length code detection video rates 
moore luk editors logic applications pages oxford england august 
springer 
schoner chia zapata 
configurable computing solutions automatic target recognition 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
faugeras hotz mathieu vi zhang fua th moll berry vuillemin bertin 
real time stereo algorithm implementations applications 
technical report institut national de recherche en informatique en automatique inria sophia antipolis france 
hutchings 
dynamic instruction set computer 
athanas pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
hutchings 
sequencing run time reconfigured hardware software 
acm sigda international symposium field programmable gate arrays pages monterey ca february 
hennessy patterson 
computer architecture quantitative approach pages 
morgan kaufmann nd edition 
carver mead lynn conway 
vlsi systems 
addisonwesley 
charles seitz 
concurrent vlsi architectures 
ieee transactions computers december 
ho snyder 
normalized time architectural design 
th allerton conference communication control computing pages 
ho snyder 
balance architectural design 
proceedings th annual international symposium computer architecture pages 

fpga density enhancement neural network runtime reconfiguration 
master thesis brigham young university provo ut december 
gorman sejnowski 
analysis hidden units layered network trained classify sonar targets 
neural networks 
hutchings 
run time reconfiguration method enhancing functional density sram fpgas 
journal vlsi signal processing 
atmel san jose ca 
configurable logic design application book 
xilinx san jose ca 
xilinx preliminary data sheet 
hadley hutchings 
design methodologies partially reconfigured systems 
athanas pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
michael 
comparison fpga platforms sar atr algorithm implementation 
master thesis department electrical computer engineering brigham young university provo utah 
hutchings :10.1.1.17.6915
improving functional density run time constant propagation 
acm sigda international symposium field programmable gate arrays pages monterey ca february 
lipton lopresti 
systolic array rapid string comparison 
fuchs editor chapel hill conference vlsi pages 
computer science press 

rambus consumer technology powers 
technical report rambus 
dehon 
dpga coupled microprocessors commodity ics early st century 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
tau chen brown dehon 
generation dpga implementation 
proceedings third canadian workshop field programmable devices pages may 
steve dean carberry anders johnson jennifer wong 
time multiplexed fpga 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
ong 
programmable logic device stores configuration means switching configurations 
patent 
herman schmit 
incremental reconfiguration pipelined applications 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
bittner athanas 
wormhole run time reconfiguration 
acm sigda international symposium field programmable gate arrays pages monterey ca february 
bittner athanas 
computing kernels implemented wormhole rtr ccm 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
churcher wilkie 
xc fastmap tm processor interface 
moore luk editors field programmable logic applications th international workshop volume lecture notes computer science pages oxford united kingdom august september 
springer verlag berlin 
hadley hutchings 
designing partially reconfigured system 
editor proceedings international society optical engineering spie 
field programmable gate arrays fpgas fast board development reconfigurable computing volume pages philadephia pa october 
bhat 
novel techniques high performance field programmable logic devices 
ucb erl november 
berkeley 
singh hogg mcauley 
expressing dynamic reconfiguration partial evaluation 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
luk shirazi cheung 
compilation tools run time reconfigurable designs 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
luk shirazi cheung 
modelling optimising run time reconfigurable systems 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
burns hogg singh de wit 
dynamic reconfiguration run time system 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
richard ross 
fpga implementation atr embedded ram control 
master thesis department electrical computer engineering brigham young university provo utah 
peter david 
vlsi signal processing bit serial approach 
addison wesley 
davidson 
fpga implementation reconfigurable microprocessor 
proceedings ieee custom integrated circuits conference pages 
fagin 
quantitative measurements fpga utility special general purpose processors 
journal vlsi signal processing august 
wolfe shen 
flexible processors promising application specific processor design approach 
proceedings st annual workshop microprogramming microarchitecture micro pages san diego ca november 
hutchings 
nano processor low resource reconfigurable processor 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 

reconfigurable multi bit processor dsp applications statistical physics 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
singh 
virtual hardware graphics applications fpgas 
buell pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
smith 
high performance microarchitecture hardware programmable functional units 
proceedings th annual international symposium microarchitecture pages 
ieee acm november 
john hauser john wawrzynek 
garp mips processor reconfigurable coprocessor 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
christopher fraser david hanson 
retargetable compiler ansi acm sigplan notices 
clark hutchings 
supporting fpga microprocessors retargetable software tools 
arnold pocek editors proceedings ieee workshop fpgas custom computing machines pages napa ca april 
zhang suen 
fast parallel algorithm thinning digital patterns 
communications acm 

