peer peer networking ian clarke scott miller theodore hong imperial college science technology medicine oskar sandberg brandon wiley freenet project protecting free expression online freenet freenet uses decentralized architecture create secure global information storage system 
growth censorship erosion privacy internet increasingly threatens freedom expression digital age 
personal information flows subject pervasive monitoring surveillance various state corporate actors trying block access controversial information destroy certain materials altogether 
incidents publication monica deleted personal mails congressional report point unprecedented level intrusion private life 
trends cause concern political disturbed thought reading mail web activities 
fortunately concurrent advances power personal computers possible develop peer peer technologies respond challenges 
project freenet distributed information storage system designed address information privacy survivability concerns 
beta version software currently available open source www org 
simulations nodes freenet proved scalable fault tolerant 
operates self organizing network pools unused disk space potentially hundreds thousands desktop computers create collaborative virtual file system 
increase network robustness eliminate single points failure freenet employs completely decentralized architecture 
environment inherently untrustworthy unreliable assume participants operate maliciously fail warning time 
freenet implements strategies protect data integrity prevent privacy leaks instance provide graceful degradation redundant data availability 
system designed adapt usage patterns automatically replicating deleting files effective available storage response demand 
january february computer org internet ieee ieee internet computing design motivation documented human rights watch www org advocacy internet global internet liberty campaign www 
org governments world undertaken efforts force internet service providers block access content deemed unsuitable liable material hosted servers 
electronic privacy information center www 
epic org raised privacy civil liberties questions developments federal bureau investigation carnivore electronic monitoring system european union new convention gives authorities broad powers intercept record digital communications 
seemingly separate prevention censorship maintenance privacy fundamental free expression potentially hostile world 
preserving availability controversial information half problem individuals subject adverse personal consequences writing reading information need conceal activity order protect 
supreme court long recognized important role anonymous speech political 
common objection mechanisms secure communication criminals evade law enforcement 
freenet particularly attractive purposes designed broadcast content world useful secret criminal plots 
case anonymous electronic communication simply tool postal mail bad 
terrorist plan attack informant turn terrorist authorities 
importantly freedom communicate fundamental value democratic society 
way deny bad guys denying freedom guys civil rights minority religious groups ordinary citizens simply wish keep affairs private 
designing freenet focused privacy information producers consumers holders resistance information censorship high availability reliability decentralization efficient scalable adaptive storage routing 
maintaining privacy creating retrieving files means little protecting files particular keeping holders hidden attack 
hard discover exactly computers store files 
redundant replication data holder privacy extremely difficult block destroy files network 
freenet explicitly try guarantee permanent data storage 
disk space finite tradeoff exists publishing new documents preserving old ones 
systems solve problem requiring payment disk space money example encourage publishing keep authors run peer nodes poor pay storage 
keep junk documents filling available space ing existing data implement probabilistic storage policy 
hope freenet attract sufficient resources participants preserve files indefinitely 
assume participants operate maliciously freenet architecture freenet participants run node provides network storage space 
add new file user sends network insert message containing file assigned location independent globally unique identifier guid causes file stored set nodes 
file lifetime migrate replicated nodes 
retrieve file user sends request message containing guid key 
request reaches nodes file stored node passes data back request originator 
guid keys freenet guid keys calculated sha secure hashes 
network employs main types keys content hash keys primary data storage signed subspace keys intended higher level human 
analogous inodes filenames conventional file system 
content hash keys 
content hash key chk low level data storage key generated hashing contents file stored 
freenet fail warning 
ieee internet computing computer org internet january february peer peer networking best known systems similar freenet napster www napster com gnutella gnutella wego com implement large scale pooling disk space individual users major difference freenet provides file storage service systems provide file sharing service participants files available push files nodes storage 
architecture means data persistent network files available originators subsequent requesters online difference system attempts provide anonymity gnutella extremely inefficient broadcasting thousands messages request 
freenet closely resembles eternity service described proposal highly survivable network permanently anonymously archiving information 
proposal lacked specifics efficiently implement related service free haven eternity anonymous publication system uses trust mechanisms file trading enforce server accountability user anonymity 
unfortunately take long time days retrieve files 
security issues developed file storage systems focus efficient data location privacy security malicious participants 
systems oceanstore cooperative file system cfs past routing models node assigned fixed identity maintains knowledge nodes identities vary specified ways systems deterministically place data nodes closely match data globally unique identifier guid user locate data progressively visiting nodes identities match bits desired guid main advan process gives file unique absolute identifier sha collisions considered nearly impossible verified quickly 
urls certain chk point exact file intended 
permit identical copies file inserted different people automatically coalesced user calculate key file 
signed subspace keys 
signed subspace key ssk sets personal namespace read owner write 
create subspace archive vietnam war example generating random public private key pair identify 
add file choose short text description politics pentagon papers 
calculate file ssk hashing public half subspace key descriptive string independently concatenating hashing 
signing file private half key provides integrity check node handles signed subspace file verifies signature accepting 
retrieve file subspace need subspace public key stored tage systems provide strong guarantees data located certain time bounds generally logarithmic exists provide better handling issues storage management 
main disadvantage systems relative freenet difficult secure attack easier malicious node manipulate identity gain responsibility particular piece data suppress 
links routing visible deterministically structured making easier trace messages harder route malicious nodes sabotage requests example pretending data 
past currently constituted requires users trust external smart cards 
privacy issues systems focusing privacy information consumers include browser proxy descriptive string recreate ssk 
adding updating file hand requires private key order generate valid signature 
facilitate trust guaranteeing pseudonymous person created files subspace subspace tied realworld identity 
example send newsletter publish web site operated reverse receive mail 
typically store indirect files containing pointers store data files directly 
indirect files combine human readability publisher authentication fast verification 
allow data updated preserving referential integrity 
perform update data owner inserts new version data get new chk file contents different 
owner updates ssk point new version 
new version available original ssk old version remain accessible old chk 
indirect files split large files multiple pieces inserting part separate chk creating indirect file points parts 
january february computer org internet ieee internet computing vices anonymizer www 
anonymizer com triangle boy www com provide anonymity requests web content user behalf users vulnerable logging services 
crowds improves anonymity simple request chaining technique similar systems directly stores information provide anonymized access information available web 
producer holder side rewebber www rewebber de provides privacy information holders encrypted url service inverse browser proxy similarly vulnerable logging service operator taz temporary anonymous zone servers continued extend idea chains nested encrypted urls point successive rewebber servers con indirect files create hierarchical namespaces directory files point files directories 
implement alternative domain name system nodes change address frequently 
node subspace contact looking public key address resolution key retrieve current address 
messaging privacy freenet designed assumption hostile attack inside 
intentionally difficult nodes direct data keeps routing topology dynamic concealed 
unfortunately considerations side effect hampering changes improve freenet routing characteristics 
date discovered way guarantee better data compromising security 
privacy freenet maintained variation chaum mix net scheme anonymous communication 
move directly sender recipient messages travel node chains link individually related cont 

system protects information producers provides redundant information storage 
publius enhances robustness protects producer anonymity distributing files redundant partial shares holders identity holders anonymized adversary destroy information attacking sufficient number shares 
systems protects information consumers rewebber operates separate browser proxy service 

anderson eternity service proc 
st int conf theory applications cryptology publishing house prague czech republic pp 


dingledine freedman molnar free haven project distributed anonymous storage service designing privacy enhancing technologies lecture notes computer science springer verlag berlin federrath ed pp 
encrypted message reaches recipient 
node chain knows immediate neighbors points network hundreds thousands nodes continually exchanging messages 
node immediately sender tell predecessor message originator merely forwarding message node 
similarly node immediately receiver tell successor true recipient continue forward 
arrangement intended protect information producers consumers chains information holders chains 
protecting prevent adversary destroying file attacking holders 
course ensuring privacy queries able locate data 
routing routing queries data important element freenet system 
simplest routing method services napster freenet 
rhea maintenance free global data storage ieee internet computing vol sep oct pp 


dabek wide area cooperative storage cfs proc 
th acm symp 
operating system principles sosp acm press new york 

rowstron druschel storage management caching past large scale persistent peer peer storage utility proc 
th acm symp 
operating system principles sosp acm press new york 

reiter rubin anonymous web transactions crowds comm acm vol 
pp 


goldberg wagner taz servers rewebber network enabling anonymous publishing world wide web monday vol 
available www firstmonday dk issues issue goldberg 

waldman rubin cranor publius robust tamper evident censorship resistant web publishing system proc 
th usenix security symp usenix assoc berkeley calif pp 
ieee internet computing computer org internet january february peer peer networking requester data holder data request data reply request failed typical request sequence request moves network node node backing dead step loop step locating desired file 
maintain central index files users send requests directly information holders 
unfortunately centralization creates single point failure easy attack 
example trying phone michael jordan simplest way get number ordinarily call directory assistance 
directory assistance centralized access easily blocked jordan decides remove directory entry service goes 
systems gnutella broadcast queries connected node radius 
method ask friends knew jordan number get ask friends 
steps thousands people looking number 
process eventually find answer clearly wasteful unscalable 
freenet avoids problems steepest ascent hill climbing search node forwards queries node thinks closest target 
start searching jordan asking friend played college basketball example pass request coach pass talent scout pass jordan agent put touch man 
requesting files 
node maintains routing table lists addresses nodes guid keys thinks hold 
node receives query checks store finds file returns tag identifying data holder 
node forwards request node table closest key requested 
node checks store 
request suc node chain passes file back upstream creates new entry routing table associating data holder requested key 
depending distance holder node cache copy locally 
conceal identity data holder nodes occasionally alter reply messages setting holder tags point passing back chain 
requests locate data node retains true data holder identity routing table forwards queries correct holder 
routing tables revealed nodes 
limit resource usage requester gives query time live limit decremented node 
ttl expires query fails user try higher ttl maximum 
ttl give clues chain requester freenet offers option enhancing security adding initial mix net route normal routing 
effectively start chain away requester 
node sends query recipient chain message bounced back node tries closest key 
node runs candidates try reports failure back predecessor chain tries second choice 
depicts typical request sequence 
user initiates request node forwards request forwards node unable contact nodes returns request failed message node tries second choice forwards request node forwards request detects loop bounces message back 
unable contact additional nodes node backtracks step forwards request second choice locates file 
returns file back sends user 
way cache file 
approach request homes closer hop key 
subsequent query key tend approach request path locally cached copy satisfy query paths converge 
subsequent queries similar keys jump intermediate nodes previously supplied similar data 
nodes reliably answer queries added routing tables contacted nodes 
january february computer org internet ieee internet computing inserting files 
insert message follows path request key take sets routing table entries way stores file nodes 
new files placed queries look 
insert file user assigns guid key sends insert message user node containing new key ttl value represents number copies store 
receiving insert node checks data store see key exists 
insert fails file network user inserted file description 
case user choose different description perform update insert 
note implemented updates working mechanism ensure old copies get replaced 
key exist node data store node looks closest key forwards message corresponding node query 
ttl expires collision final node returns clear message 
user sends data path established initial insert message 
node path verifies data guid stores creates routing table entry lists data holder final node chain 
requests insert encounters loop dead backtracks second nearest key third nearest succeeds 
data encryption political legal reasons node operators wish remain ignorant contents data stores 
encourage publishers encrypt data insertion 
network proper knows level encryption just ships encrypted bits 
data encryption keys routing included network messages 
distribute directly users time corresponding guids 
node operators read files users decrypt retrieval 
node operators gain information looking guids hashes generate scramble identifying characteristics 
node operator point view data store consists random guids attached opaque data 
network evolution network evolves time new nodes join existing nodes create new connections handling queries 
requests handled local knowledge nodes network improves routes adapt accurate requiring global directories 
adding nodes join network new node generates public private key pair 
pair serves logically identify node sign physical address 
note public keys certified 
don need link real world identities node public key identity changes physical addresses 
certification useful deciding trust new node freenet uses trust mechanism 
node sends announcement message including public key physical address existing node located means personal communication lists nodes posted web user specified ttl 
receiving node notes new node identifying information forwards announcement node chosen randomly routing table 
announcement continues propagate ttl runs 
point nodes chain collectively assign new node random guid keyspace cryptographic protocol shared random number generation prevents participant biasing result 
procedure assigns new node responsibility region keyspace participants agree guaranteeing malicious node influence assignment specific key want attack 
nodes routing tables specialize handling clusters similar keys 
training routes requests processed network routing better trained 
nodes routing tables specialize handling clusters similar keys node receive requests keys similar keys associated nodes routing tables 
requests succeed node learns freenet ieee internet computing computer org internet january february peer peer networking previously unknown nodes supply keys creates new routing entries 
node gains experience handling queries keys successfully answer positive feedback loop get asked 
nodes data stores specialize storing clusters files similar keys 
inserts follow paths requests similar keys tend cluster nodes paths 
nodes similarly cluster files cached requests requests similar keys 
taken twin effects clustering routing tables data stores improve effectiveness queries self reinforcing cycle 
mathematical model analyze training convergence freenet algorithm simulations described show network practice locate files quickly median path length just hops node network 
known nodes tend see requests better connected 
key clustering guid keys derived hashes closeness keys data store unrelated corresponding files contents 
lack semantic closeness unimportant routing algorithm locations particular keys particular topics 
suppose example descriptive string politics pentagon papers yields key af ec 
requests file satisfied creating clusters containing keys af ec af ec af ec clusters containing works politics 
fact hashes useful ensure similar works scattered network lessening chances single node failure entire category files unavailable 
similarly contents subspace scattered different nodes increases robustness 
searching open issue users search net relevant keys 
similar problem searching web similar solutions possible freenet individuals publish lists bookmarks 
approaches entirely satisfactory terms freenet design goals 
simple approach true freenet search create special public subspace indirect keyword files 
authors insert files insert indirect files corresponding search keywords original file 
pentagon papers file indirect files named keyword politics keyword pointing example 
system allow multiple keyword files key coexist normal files requests keys return multiple matches 
search politics return pointer papers pentagon papers 
managing large number indirect files common keywords difficult files name attracted nodes 
sophisticated approach type distributed search detailed metadata descriptors inserted original files devised way route search efficiently 
managing storage encourage participation freenet require payment inserts impose restrictions amount data publishers insert 
finite disk space system decide files keep 
currently prioritizes space allocation popularity measured frequency requests file 
node orders files data store time request new file arrives fit space available node deletes requested files room 
routing table entries smaller kept longer files 
evicted files don necessarily disappear right away node respond request file routing table contact original data holder able supply copy 
original holder file 
freenet data holder pointers structure 
nodes leaves see local requests file higher tree receive requests larger part network copies popular 
january february computer org internet ieee internet computing file distribution determined competing forces tree growth pruning 
query routing mechanism automatically creates copies area network file requested tree grows direction 
improves response time prevents overloading popularity file increases suddenly 
files go part network subject deletion 
part tree shrinks space freed files 
net effect number location copies adjust demand file 
performance analysis tested freenet performance simulations 
described extended results summarize important results 
freenet demonstrates scalability fault tolerance characteristics explained terms small world network model 
small world networks characterized power law distribution graph degree number routing table entries general form constant graph degree probability node degree distribution majority nodes relatively local connections nodes significant small number nodes large wide ranging sets connections 
large networks small world topology enables efficient short paths nodes provide shortcuts 
shows graph degree distribution simulation node trained network 
distribution closely approximates power law outlier resulting maximum routing table size simulation 
surprising power law distributions tend arise naturally networks grow preferential attachment new nodes prefer connect nodes links 
new node announcement protocol initially creates preferential attachment effect random links gives higher probability arriving nodes links 
normal operation effect continues known nodes tend see requests better connected rich get richer 
scalability test freenet scalability created simulated network nodes initially connected ring topology 
sent inserts randomly gener fraction nodes ated files random nodes network interspersed random requests files inserted ttl 
inserts requests created new node announced random existing node ttl 
measured network performance inserts requests issuing set test requests previously inserted files recording resulting path length distribution number hops required find data 
continued network reached nodes 
shows evolution second third quartiles request path length versus network size averaged trials 
freenet number links 
degree distribution freenet nodes network shows close fit power law distribution 
request path length hops quartile median third quartile network size nodes 
request path length versus network size median path length network scales ieee internet computing computer org internet january february peer peer networking request path length hops quartile median third quartile fraction nodes failing 
request path length random failure 
performance remained reasonable percent failure rate simulation 
size largest connected component random failure targeted attack fraction nodes removed 
connectivity random failure targeted attack network falls apart quickly connected nodes targeted 
see median path length scales sublinearly network size agrees results mathematical modeling peer peer networks 
extrapolation appears freenet capable scaling nodes median path length just 
fault tolerance repeating previous training procedure nodes progressively removed random nodes network simulate node failures 
shows resulting evolution request path length averaged trials shows network surprisingly robust quite large failures 
median path length remained percent nodes failed 
note requests capped hops giving 
power law distribution gives small world networks high degree fault tolerance random failures eliminate nodes poorly connected majority 
routing performance noticeably affected failures knock significant number connected nodes 
small world network falls apart quickly connected nodes targeted 
evident shows size largest connected component node network nodes removed randomly order connected connected 
random failure vast majority network remained connected 
targeted attack network underwent percolation transition near percent removal point abruptly broke disconnected fragments 
initial beta deployment freenet way users downloaded hundreds thousands copies software far 
system anonymous nature impossible tell exactly users inserts requests working anecdotal evidence positive 
working simulation visualization suite enable rigorous tests protocol routing algorithm 
realistic simulation formal modeling needed explore effects nodes joining leaving variations node capacity bandwidth larger network sizes 
need develop search mechanisms provide protection denial service attacks flood system junk data 
eviction mechanism works eliminate files requested important files pushed act quickly attack 
hand reducing priority new data result files deleted chance requested 
exploring various modifications caching policy caching aggressively farther data holder pointer tree balance considerations 
january february computer org internet ieee internet computing acknowledgments third author marshall aid commission support 
material partly supported national science foundation graduate research fellowship 

rosen unwanted gaze destruction privacy america vintage books new york 

clarke freenet distributed anonymous information storage retrieval system designing privacy enhancing technologies lecture notes computer science federrath ed springer verlag berlin pp 


chaum untraceable electronic mail return addresses digital pseudonyms comm 
acm vol 
pp 


hong performance peer peer harnessing power disruptive technologies oram ed reilly assoc sebastopol calif pp 


watts strogatz collective dynamics small world networks nature june pp 


albert jeong barab si error attack tolerance complex networks nature july pp 


adamic search power law networks physical rev vol 
article 
set industry standards ian clarke vice president chief technology officer received bs honors computer science artificial intelligence university edinburgh scotland 
original architect coordinator freenet project 
theodore hong phd student imperial college london 
research interests include dynamics complex networks multiagent systems game theory grammatical inference information extraction 
appeared bbc digital rights issues 
received ab chemistry physics mathematics harvard msc university college london marshall scholar 
scott miller senior software engineer 
received bs honors computer science indiana university 
research interests include cryptography self organizing systems converged freenet project 
oskar sandberg core programmer freenet 
board freenet project sandberg final year master degree mathematics university stockholm sweden 
readers contact clarke ian org 
posix gigabit ethernet enhanced parallel ports wireless token rings networks computer society members define standards ieee 
help shape technologies join computer society standards working group computer org standards freenet ieee internet computing computer org internet january february 
