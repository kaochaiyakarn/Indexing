comparative evaluation sequential feature selection algorithms david aha navy ai center naval research laboratory washington dc nrl navy 
mil richard marine meteorology division naval research laboratory monterey ca 
navy 
mil machine learning publications demonstrate utility feature selection algorithms supervised learning tasks 
feature ion algorithms receiving attention 
frequently studied variants algorithms forward backward sequential selection 
studies supervised learning sequential feature selection report applications algorithms consider variants appropriate performance tasks 
reports positive empirical results variants argues serious consideration similar learning tasks 
motivation feature selection algorithms attempt reduce number dimensions considered task improve performance dependent measures 
restrict attention supervised learning tasks dependent variables classification accuracy size feature subset computational efficiency 
feature selection studied decades fu cover van 
publications reported performance improvements measures feature selection algorithms dietterich kononenko caruana skalak moore lee aha townsend weber kibler langley sage :10.1.1.48.2488
feature selection algorithms typically composed components 
search algorithm searches space feature subsets size number features 

evaluation function inputs feature subset outputs numeric evaluation 
search algorithm goal maximize function 

performance function performance task studied classification 
subset perform best evaluation function classifier classify instances dataset 
ai statistics workshop aha 
identified ond 
ond bound hove complexity number ond ore frequently prohibitively expensive hove complexity number 
include genetic ond methods 
high de jong require yield subsets 
best done open issue 
hove complexity odd ond hill climbing 
ore frequently aho 
common selection ore wat ess ond bac wa bss ond focus 
ess begins zero oll subsets ond selects best 
odds subset thor yields best subsets size 
cycle improvement extending current subset 
bss begins oll ond removes yields improvement 
reported thor bss frequently outperformed ess bss contribution context oll 
con utility single limited context previously selected 
ond note problem ess results 
ess outperform bss unknown 
study 
ess ond noted thor frequently outperformed ess 
predicted thor bss outperform bss 

focuses bss ond ess ond set interest meteorology division 
define ore possible 
show thor selection improves provide evidence john ond conjecture thor models outperform filter models ond provide evidence thor bss preferred ess 
show thor bss ond ess con frequently outperform ond thor tested possible 
cloud pattern classification task selection hold improve 
encountered cloud provided meteorology division thor expected testing selection thor perform poorly presence low 
known thor neighbor perform poorly aho 
non ore excellent choices functions tuning number different describes feature selection experiments variant dataset differences datasets prevent direct comparison 
evaluations additional datasets discussed extended versions 
beam framework sequential feature selection input search algorithm evaluation function size queue number states evaluated iteration number subsets evaluated state partial key queue ordered queue states best best performing state beam 
queue initialize queue 
best initialize best queue 
queue empty states select states queue evaluations evaluate states states queue queue st es ions queue best update best best queue 
output best feature subsets evaluated 
chose ib aha classifier implementation nearest neighbor classifier 
features describe instance consist shape size spectral textural measures cloud pattern region 
examples group include features compactness perimeter size maximum pixel value cluster prominence respectively 
features defined continuous range values 
describes features detail 
framework experiments investigated fss bss search algorithm ib classifier 
ib separability index measure evaluation function 
selection evaluation functions motivated hypothesis wrapper models classifier evaluation function outperform filter models 
conjectured john kohavi 
cited informal evidence conjecture describe detailed analysis 
additional search related variables varied experiments allowed test variants fss bss 
variables constrain beam search conducted 
describes parameterizable framework refer beam 
briefly beam implements beam search variants search algorithm 
queue states maintained state subset features indication subsets immediately derivable evaluated 
evaluation state maintained queue 
initialize queue initializes queue complete set features bss empty set fss 
milligan cooper index perform best indices experiments 
table best averages accuracy size selected subset number subsets evaluated ib fss bss queue size different evaluation functions search best averages acc sz eval acc sz eval ib fss ib bss ib fss index bss index evaluation computed recorded initial best state 
beam loops queue empty 
step loop stochastically selects states queue states higher queue higher probability selected 
step evaluates subsets derivable search algorithm states evaluation function queue updated states exhaustively searched dropped states current top states integrated appropriately ordered locations queue 
best state located far maintained best 
queue exhausted best state output classifier 
empirical comparisons experiments run leave strategy 
report averages classification accuracy size selected feature subset number subsets evaluated 
averages computed runs experiments ib evaluation function 
implementation separability index measure deterministic run experiments evaluation function 
subsections report results exploring hypotheses 
appropriateness feature selection dataset sparse features instances features un known possibly low classification relevance expected feature selection improve ibl performance 
table displays results ib feature selection algorithms fss bss search algorithms tested ib sep index evaluation function 
feature selection consistently increased accuracy reduced feature set size 
results support hypothesis 
specifically function selects ordered state probability size queue 
dataset constructed features chosen assumption may provide useful information classifying cloud patterns 
verification performed ensure chosen features predictive particular cloud patterns 
features known relevant discriminating cloud pattern classes relevance distinguishing cloud patterns unknown 
table best averages ib evaluation function queue size search best averages acc sz eval acc sz eval fss fss fss bss bss bss superiority wrapper model evaluation functions compared ib separability index 
expected ib classifier evaluation function yield superior results 
shown table performance standard fss bss algorithms lower separability index measure ib evaluation function 
supports hypothesis 
believe reason separability index measure bias different ibl bias 
index measure necessarily select performing subset ib 
bss outperforms fss bss outperformed fss studies examined smaller numbers features task 
unsure algorithm yield better results 
differences accuracy fss bss significant tailed test evaluations table summarizes results search algorithms varied number states selected evaluation number subsets evaluated selected state queue size 
fss average accuracy higher variants significantly higher third variant variant cases 
accuracy results differ majority results 
suspect bss easily confused large numbers features deletion single feature relevant effect presence larger number features 
plan explore hypothesis systematic experimentation artificially generated data 
general pattern suggests fss preferred optimal number selected features small bss preferred 
suggests bss performance enhanced situations biased small sized subsets features 
show evidence aha 
similarly situations features relevant performance fss probably enhanced biased searching large sized subsets features 
beam search variants outperform standard fss bss caruana report evidence hypothesis combinations algorithms simple extensions 
beam search version fss preferable evaluate extensions bss 
accuracies beam searching variants table queue size higher queue size table 
differences significant third variant fss variants bss variants significantly reduced size selected feature subsets sizes increased significantly fss variants evaluated subsets significantly increased variants significantly bss summary beam search variants standard sequential feature selection approaches significantly increase classification accuracies task 
simultaneously significantly reduce size subsets located tend significantly increase search requirements number subsets evaluated 
examines variants forward backward sequential feature selection algorithms cloud pattern classification task defined sparse dataset numerous features 
nearest neighbor algorithm classifier results show feature selection improves accuracy task classifier evaluation function yields better performance separability index bss outperform ess contrary claims beam search variants algorithms improve accuracy task 
similar results datasets plan discuss extensions 
additional studies showed random initial subset selection comparatively small number features drastically reduced amount search performed bss sacrificing accuracy 
karl branting pat langley reviewers comments suggestions 
aha 

generalizing case studies case study 
proceedings ninth international conference machine learning pp 

aberdeen scotland morgan kaufmann 
aha 

feature selection case classification cloud types empirical comparison 
aha ed 
case reasoning papers workshop technical report ws 
menlo park ca aaai press 
aha 

comparative evaluation sequential feature selection algorithms 
proceedings fifth international workshop artificial intelligence pp 

ft lauderdale fl unpublished 
almuallim dietterich 

learning irrelevant features 
proceedings ninth national conference artificial intelligence pp 

menlo park ca aaai press 


cloud classification avhrr imagery maritime regions probabilistic neural network 
journal applied meteorology 


cloud pattern identification part automated image analysis 
proceedings seventh conference satellite meteorology oceanography pp 

boston ma american meteorological society 
caruana freitag 

greedy attribute selection 
proceedings eleventh international machine learning conference pp 

new brunswick nj morgan kaufmann 
cover van 

possible orderings measurement selection problem 
ieee transactions systems man cybernetics 


evaluation feature selection methods application computer security technical report cse 
davis ca university california department computer science 
fu 

sequential methods pattern recognition machine learning 
new york academic press 
john kohavi 

irrelevant features subset selection problem 
proceedings eleventh international machine learning conference pp 

new brunswick morgan kaufmann 
kononenko 

estimating attributes analysis extensions relief 
proceedings european conference machine learning pp 

catania italy springer verlag 
langley sage 

oblivious decision trees cases 
aha ed case reasoning papers workshop technical report ws 
menlo park ca aaai press 
milligan cooper 

examination procedures determining number clusters data set 
psychometrika 
moore lee 

efficient algorithms minimizing cross validation error 
proceedings eleventh international conference machine learning pp 

new brunswick nj morgan kaufmann 


comparison techniques choosing subsets pattern recognition properties 
ieee transaction computers 
skalak 

prototype feature selection sampling random mutation hill climbing algorithms 
proceedings eleventh international machine learning conference pp 

new brunswick nj morgan kaufmann 
townsend weber kibler 

instance prediction continuous values 
aha ed case reasoning papers workshop technical report ws 
menlo park ca aaai press 
vafaie de jong 

robust feature selection algorithms 
proceedings fifth conference tools artificial intelligence pp 

boston ma ieee computer society press 
