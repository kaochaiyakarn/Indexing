envy non volatile main storage system appear asplos vi memory michael wu dept electrical computer engineering rice university edu willy department computer science rice university edu describes architecture envy large non volatile main memory storage system built primarily flash memory 
envy presents storage space linear memory mapped array emulated disk order provide easy software interface 
flash memories provide persistent storage memory access times lower cost solid state technologies 
number drawbacks 
flash chips write bulk erase devices contents updated place 
suffer slow program times limit program erase cycles 
envy uses copy write scheme page remapping small amount battery backed sram high bandwidth parallel data transfers provide low latency place update semantics 
cleaning algorithm optimized large flash arrays reclaim space 
algorithm designed evenly wear array extending lifetime 
software simulations gigabyte envy system show support rates corresponding approximately transactions second tpc database benchmark 
despite added done overcome deficiencies associated flash memories average latencies storage system low ns reads ns writes 
estimated lifetime type storage system year range exposed workload transactions second 
ch supported pm national science foundation ccr texas tec 
traditional random access storage systems magnetic disks stable storage 
magnetic disks possess properties enabled dominate storage market low media cost reasonable access times 
mechanical nature disks difficult significantly reduce access times creating discrepancy computation time time growing processors get faster 
methods caches write buffers raid arrays developed alleviate disk bottlenecks 
caches commonly hide read latency disks non volatile write buffers developed hide write latency 
raid arrays improve available rates transferring data parallel 
exploring alternative approach building persistent storage system solid state memories avoiding mechanical latencies associated disks 
solid state memories provide factor improvement access times compared disks ns memory ms disks 
rapid decreases memory prices due increasing densities feasible build memory arrays order gigabytes size cost order magnitude greater disk 
expectation applications performance currently bound disk random access rates data requirements stay gigabytes performance solid state storage system worth extra cost 
examples applications include small medium sized high performance databases 
argue access permanent storage system provided means word sized reads writes just conventional memory 
interface simplifies data access routines need concerned disk block boundaries optimizations sequential access specialized disk ave formats 
substantial reductions code size instruction result 
backwards compatibility simple ram disk program low power feature disk dram sram flash read access ms ns ns ns write access ms ns ns 
cost mbyte data retention ma current gbyte feature comparison storage technologies memory array usable standard file system 
compares various characteristics disks memory technologies dram flash battery backed sram 
flash attractive persistent storage system costs memories needs power maintain contents 
contrast low power sram times expensive requires battery backup persistent data storage 
dram memory computers large arrays requires power data retention batteries provide extended periods time 
possible dump contents dram disk power failure add complexity storage system subsystem performs function highly reliable 
addition availability system suffer data recovered disk peak performance restored 
cheap inherently non volatile flash memory drawbacks 
flash memory updated place 
block memory erased reprogrammed 
presents image worm write read drive mem ory 
furthermore updates flash memory slower updates conventional memory number program erase cycles limited 
envy large flash storage system uses variety techniques overcome deficiencies contents conventional linear array non volatile memory place updates 
envy uses copy write memory remapping provide normal place update semantics 
relatively small amount battery backed sram functions nonvolatile write buffer hiding latency flash program operations 
space flash array invalidated copy write needs reclaimed erased available new data 
algorithm purpose 
cleaning algorithm similar function sprite lfs cleaning algorithm optimized large flash array :10.1.1.117.5365
simulation results gigabyte envy system running tpc database benchmark workload show system support rates corresponding tps transactions second 
sustained average latencies storage system low ns reads ns writes 
stress fact performance claims relate rates transaction throughput dependent factors 
presents architecture envy focusing particular techniques overcome deficiencies flash memory 
outline rest follows 
section provides basic infor mation characteristics flash memories problems encountered trying modify data flash array 
section describes methods envy uses overcome flash memory limitations section elaborates cleaning algorithm 
simulation results section 
remaining sec tions discuss extensions 
flash characteristics flash chip structurally functionally similar fact electrically 
simple structure allows manufactured high densities low cost 
chip consists byte wide array non volatile memory cells 
arbitrary read performed dram access times ns 
individual bytes programmed fs arbitrarily rewritten entire device erased takes ms 
newer flash chips allow flexibility dividing memory array large independently blocks kbytes size 
current flash technology uses programming method slightly degrades program erase times time operations executed 
chip guaranteed program erase specific time frames minimum number cycles ranging depending manufacturer 
failure chip defined write erase operation takes time allowed specification 
operation succeed time allowed 
existing data remain read able 
failure mode different disk data lost 
manufacturer specifications appear extremely conservative chips tested 
example chip rated cycles programmed fs erased ms cycles far corresponding guaranteed limits fs seconds 
exceptional performance shows technology matures flash potential durable 
flash chip normally operates read mode 
functions initiated writing commands internal command user cui 
commands exist programming verifying bytes erasing blocks checking status suspending long operations 
depending chip commands required single logical operation 
example single byte programming operation usually involves series program verify steps desired data changed chip 
memory bus cpu bits bus bits dram main memory disk disk display printer envy storage subsystem diagram envy host workstation provide general purpose non volatile memory system flash technology basic deficiencies 
bulk erase nature prevents normal update place semantics 
second program erase operations take longer reads 
number guaranteed cycles limits lifetime array 
section describes envy addresses deficiencies 
envy architecture envy large persistent storage system built top flash memory 
primary goal flash memory host computer simple linear array non volatile memory 
additional goal achieve access times close battery backed sram possible ns 
envy designed reside memory bus accessible lead store instructions main memory 
presents high level diagram envy storage system shows located relation computer system components 
implementation transparent inplace update obvious problem flash memory allow place updates look normal memory 
envy uses copy write scheme changes appear done inplace host processor 
flash array divided pages overhead required manage data word level 
page table maintains mapping linear logical address space host physical address space flash array 
write particular address flash array requested host new copy corresponding page including newly written value 
page table updated point modified copy requests data page directed new version 
sram write buffer copy write operation described provides appearance place updates relatively slow involves write flash memory 
faster create new version page type memory better suited updates 
envy includes relatively small array battery backed sram purpose 
performing copy write operation original flash page copied unused page sram 
write request executed sram copy page table updated point modified page sram 
demonstrates steps copy write process 
changes visible page table updated entire copy write appears done single atomic operation 
flash page invalidated valid copy page sram 
reason sram battery backed prevent data loss event power failure 
sram managed fifo write buffer 
new pages inserted head pages flushed tail 
pages flushed buffer number exceeds certain threshold 
complex management schemes discarded difficult handle hardware 
ability retain pages sram time helps reduce traffic flash array multiple writes page require additional copy write operations 
changes directly sram 
page remapping mapping logical physical addresses critical integrity system kept non volatile memory 
mappings updated frequently changes occur place page table kept battery backed sram flash memory 
memory expensive tradeoff choosing page size 
hand larger pages lead smaller page table lower page page page page table flash table flash table flash table flash original copy sram sram sram new copy write data updated page table pointer sram invalid copy original state copy page update new update page table flash sram copy sram invalidate old copy received write page steps copy write function write page flash chip bik bik bik 
bik bik bik bik bik bik bik bik bik chip chip chip chip bank flash memory segment segment segment segment flash bank organization sram requirements 
hand entire page written flash flush larger pages cause unmodified data written word changed 
interests maximizing flash array lifetime page size small possible 
tradeoff page size bytes chosen 
fortunately page table mapping requires bytes relatively little data compared bytes flash memory system cost affected significantly 
gigabyte flash mbytes sram required page table increase cost costs 
order copy write operation fast possible byte wide data path sram flash 
flash array organized banks byte wide chips 
organization lows entire page transferred just memory cycle 
cleaning sram write buffer filled threshold envy attempts flush pages sram flash 
free space controller wants flush page cleaning operation initiated reclaim space 
envy cleaning system basic responsibility sprite lfs segment cleaner reasons cleaning differ :10.1.1.117.5365
envy recovers space invalidated copy write overwritten new data bulk erase nature flash memory 
lfs data invalidated files modified 
space occupied data reused doing require random accesses costly disk 
flash chips normally allow erasure large blocks 
organization flash array wide memory banks described section imposes restriction erasure 
combining flash chips bank smallest independently unit consists physical flash erase blocks see 
refer unit flash segment 
flash segment larger typical sprite lfs segment envy system far fewer segments sprite system comparable size 
example current technology envy segments gigabyte storage space sprite lfs 
importance distinction clear discuss various cleaning algorithms section 
envy cleans segment live data copied empty segment original erased reused 
new segment contains cluster live data head remaining space unused ready accept data flushed write buffer 
steps involved cleaning process shown 
envy keep valid data read erased segment valid data new copy ata read locate fresh segment copy valid data new segment update pointers new copy active page invalidated copy writable unused page writable steps cleaning process segment completely erased cleaning operations free segment available cleaning operation 
state cleaning process kept persistent memory controller recover quickly failure 
flushing cleaning labeled long operations take order magnitude longer memory access 
host request arrives long operation progress long operation suspended host access serviced minimizing latency seen host 
memory controller waits microseconds resuming long operation avoid spurious restarts bursts activity 
cleaning policy decisions segments clean clean write new data important effect performance 
decisions described cleaning policy 
flash cleaning cost measure amount involved cleaning define term flash cleaning cost number flash program operations performed cleaning algorithm page flushed write buffer 
ratio essentially amount overhead cleaning done useful write flash 
cleaning cost differs write cost sprite lfs ways :10.1.1.117.5365
cleaning cost include cost reads cleaning time dominated time takes write flash memory 
second include cost doing initial flush sram 
cleaning cost measures overhead due cleaning 
flash array utilization cleaning costs various flash utilizations number program operations needed clean segment depends utilization percentage storage space occupied live data 
utilization segment cleaning cost 
fig ure graphically illustrates cost different levels utilization 
utilization cleaning cost quickly reaches unreasonable levels 
reason limit percentage live data envy system total flash array size 
naive cleaning scheme keeps segment utilization average cleaning cost 
primary goals cleaning policy reduce cleaning costs resulting higher performance bandwidth wasted cleaning longer array lifetime fewer program erase cycles 
lower cleaning costs achieved managing segments ones cleaned large amount greedy locality gathering hybrid segment writes segment writes segment writes space clean new data available space distribution space various cleaning methods partition partition valid data providing large amounts recovered space 
sprite lfs reduces cleaning costs separating data different access frequencies different segments picking segments clean cost benefit equation :10.1.1.117.5365
sprite lfs cleaner reads seg ments sorts active data age rewrites data unused segments 
block age roughly function frequency access segments get filled frequently accessed hot data get filled data 
lfs cleaning policy reasons 
requires segments cleaned 
lfs envy segments defined hardware tend large size number 
cleaning takes time consumes large portion available resources 
second envy need concerned cost seeks 
need try force log structure data 
penalty write different segments quick succession 
small page size envy maintaining age page entail substantial storage overhead 
different cleaning strategies 
greedy method shown perform poorly sprite lfs 
second strategy allocates varying amounts data different segments array reduce cleaning costs 
conclude showing hybrid method combination algorithms performs better isolation 
analyzing policies important note writes modifications flash array write locality write access patterns affect cleaning efficiency 
remainder section refer figures 
summarizes data distribution data movement clean ing methods 
presents cleaning cost algorithms various localities system segments 
subsequent graphs numbers locality axis represent parameters bimodal access distribution 
example means accesses go data goes remaining data 
greedy method greedy policy similar described sprite lfs :10.1.1.117.5365
space flush data cleaner chooses clean segment invalidated space hoping recover space possible 
cleaning operation writes directed free space newly cleaned segment full time new cleaning operation started 
sprite lfs policy greedy method attempt create bimodal data distribution age sorting cleaning multiple segments time reasons section 
predicted sprite lfs greedy method lowers cleaning costs uniform distributions performance suffers locality increased see 
greedy policy tends clean segments fifo order 
fairly intuitive uniform distribution 
segment cleaned cleared invalid data 
uniform distribution invalidates data segments similar rates 
segment cleaned wait segment cleaned chosen demonstrating fifo cleaning order 
uniform distribution fifo ordering lowers utilizations cleaned segments giving data segment time invalidated cleans 
results lower cleaning costs 
intuitive fifo behavior continues high localities long cold data accessed occasionally 
segment cleaned accepts flushed data full 
flushed data hot cold segment gets cleaned ends mixture hot cold data 
cold data introduced hot segments 
time segments distribution hot cold data cleaned 
data invalidated segment rate algorithm exhibits fifo behavior just uniform distribution 
contrast locality locality gathering hybrid approach greedy method comparison cleaning algorithms effect uniform accesses fifo ordering produce low cleaning costs distributions high locality 
locality goes cold area grows size experiences fewer invalidations tends increase cleaning cost 
opposite occurs hot data 
cold data hot data effect dominant cleaning cost goes 
locality gathering locality gathering algorithm attempts take advantage high localities 
involves parts locality preservation gathering active data redistribution 
hot segments cleaned cold ones 
want lower cleaning costs 
redistribute data segments lower utilizations hot segments 
fixed amount free space envy system balance benefits lowering utilization hot segments cost increasing utilization cold ones 
heuristic decide free space segment 
algorithm aims situation product frequency segment cleaned cleaning cost segments 
intuitively means segment times tenth cleaning cost 
segment cleaned cleaner computes product segments cleaning cost frequency cleaned 
value compared average segments 
value product cleaned segment average utilization lowered 
increased 
pages transferred cleaned segment neighbors bring products closer average 
cleaning policy moves pages segments manner encourages locality 
particular tries migrate hot data lower numbered segments cold data travels opposite direction 
accomplish take advantage fact cleaning segment order pages maintained valid pages read old segment written new segment 
normal operation new data written tail segment data near tends hotter average 
cold data sinks 
pages moved lower numbered segment taken original segment pages headed higher segment taken 
tends gather hot data near segment 
care taken prevent flushes sram write buffer destroying locality 
page placed sram buffer record segment comes 
flushed written back segment 
time process creates multimodal distri bution hot data cold data reside different segments 
redistribution take advantage different needs segments find allocation free space array improving cleaning 
shows locality gathering algorithm takes advantage increasing locality 
unfortunately uniform access distributions techniques take advantage locality prevent cleaning performance improved 
data distribution procedure allocates amount data segment accessed frequency 
pages flushed back original segments preserve locality segment stay utilization leading fixed cleaning cost 
locality gathering policy allows segments cleaned different rates care taken insure segments cycled evenly 
envy keeps statistics number program erase cycles segment exposed oldest segment gets cycles older youngest cleaning operation initiated swaps data areas 
leads wearing segments 
hybrid approach greedy fifo algorithms perform uniform access distributions locality gathering algorithm gives performance higher localities 
hybrid approach combines methods 
adjoining segments gathered single partition 
locality gathering approach manage pages partitions fifo cleaning order partition 
fifo chosen greedy method simpler implement produces cleaning cost 
write gets flushed back partition segment read written sequentially active segment partition 
intuition hybrid approach follows 
locality gathering method effect sorts number segments partition cleaning costs vs partition size number segments flash array cleaning costs vs number segments segments fi access keep data frequencies access 
segments share frequency accesses essentially uniform case handled fifo 
grouping segments partitions allows cleaner break array uniformly accessed pieces large fifo algorithm time small locality gathering method efficiently separate data varying localities 
efficiency resulting algorithm depends size partitions 
shows cleaning cost varies function number segments partition segment array 
extreme values partition size segments correspond locality gathering fifo algorithms advantages disadvantages 
lowest cleaning cost occurs partition size 
choice partition size provides performance low cleaning costs uniform access distributions patterns high locality 
shows partition size hybrid approach comes close performance greedy algorithm uniform access distributions consistently beating pure locality gathering 
effect number segments performance cleaning algorithm related size segments 
smaller segments allow cleaner finer granularity achieve greater efficiency 
clearly making segment size smaller desirable limited phys ical size erase blocks described section 
demonstrate fixed size array fixed number partitions cleaning costs hybrid algorithm vary function number segments array divided 
cleaning efficiency get better system divided segments 
segment represents array gains marginal 
characteristic especially important smaller systems fewer chips 
simulation results performance envy architecture involves factors including wide variety architectural design choices flash memory parameters various timing constraints 
simulation system done provide reasonably accurate picture envy performs allow careful study individual issues 
section discusses hardware implementation simulated workload results obtained simulation 
simulated hardware detailed diagram simulated envy storage system shown 
envy controller responsible translating memory accesses host bus appropriate operations flash sram performing background maintenance flash array 
hardware memory controller bit risc cpu memory management unit mmu page table 
hardware memory controller handles low level operations reads sram flash arrays copy write function 
order able complete copy write operation cycle controller contains logic check status flash chips parallel having poll individual chips 
complex tasks clean ing handled risc cpu called cleaning processor 
memory controller cleaning processor cooperate shared register communications link 
register logical address physical address data bits block envy architecture polled processor interrupt 
memory controller ond processor powerful oll envy functions ond host processor interrupted 
source ond removes need system host side 
provided host os log ond sram kept sram os described section 
memory unit mmu os foster 
copy write executed reduce 
sram con hold recovery ond system store 
models envy system includes memory divided segments size 
size wos fixed ot segments results section 
system size requires sram write buffer ond write buffer 
buffer size chosen size segment 
cost system numbers 
ond sram memories ore expensive components system ond represent bulk price 
envy system costs pure sram system size 
memory ond times ore described 
lists row chips 
times chips ore ns memory involves os ond control 
ns sram ns 
simulated workload driven tpc 
consists short processing susceptible bound 
tpc models system mode tellers ond thor ore tellers responsible 
teller ond kept form byte record 
involves consisting ond corresponding ond teller records reflect 
index trees hove find desired records ond records hove modified 
implements index tree os tree entries node 
con fit system described 
system records 
account numbers ore uniform distribution ond times ore distributed corresponding rote 
includes ters 
derived tpc specific tpc os defined 
depends system os ond just component 
flash parameters flash array size gbytes flash chip type mbyte bits flash chips flash banks flash chips bank read time ns write time ns program time ns erase time ms erase blocks chip sram parameters write buffer sram array size mbytes sram chip size kbytes sram chips sram banks sram chips bank read time ns write time ns tpc parameters btree size pointers node branch records index levels teller records index levels account records index levels envy simulation parameters transaction request rate tps throughput increasing request rates ooo flash array utilization tps tps tps tps throughput various levels utilization throughput demonstrates throughput increases steadily transaction request rate rate exceeds capacity envy cleaning system 
peak load simulated system handle transactions second 
amount data written flash puts upper bound envy maximum throughput 
efficiency cleaning algorithm heavily influences quantity 
array utilization increases time spent cleaning time doing useful 
shows additional cleaning time degrades throughput envy system 
utilization performance drops steeply reinforcing decision keep flash array storage space free time 
utilization transaction rate tps envy system idle 
conditions approximately time servicing reads 
remaining time spent ei ther cleaning flushing oz erasing 
functions reading solely overcome drawbacks writing flash memory 
completely eliminated battery backed sram array throughput increase factor 
factor fairly small database workloads typically perform reads writes requires extra done flash 
drop peak performance considered context near reduction price obtained flash sram 
latency plots read write latencies seen host conditions 
transaction rate gets near system maximum throughput latencies types access constant ns reads ns writes 
rate surpasses envy ability process write latency jumps dramatically ns ps slowly climbs ps 
envy receives write requests faster handle write buffer fills 
buffer transaction request rate tps read latency write latency latency increasing request rates full copy write initiated controller flush page flash proceed 
flush may require segment cleaned written 
write request triggered write proceed flush done exposed latency 
shows combination able interrupt long flash operations write buffer effective hiding latency reads writes 
times simulated closer flash read time longer operations page flush cleaning operation 
writes exhibit close sram access times 
estimated envy lifetime envy practical respectable usable lifetime 
give sample calculation tps workload example flash durability 
rate simulator reports pages flushed second cleaning cost 
lifetime system equal number pages written lifetime write capacity divided rate pages ally written 
cycle parts system continuously ratio mbytes ot cycles days continuous years year lifespan modern computer equipment especially considering high sustained workload exposed 
true lifetime proportional size array array half size half lifetime generations flash chips provide cycles size array feasible 
hardware extensions low cost performance enhancements basic envy architecture 
obvious example perform multiple program erase operations time different banks flash memory 
order pages flushed write buffer affect correctness easy select pages written parallel 
parallel erasures allow multiple cleaning operations run time 
cleaner executing concurrent programming operations average time flush page drop see low cost feature available envy hardware atomic transaction support 
traditional transaction processing systems sort software con logging checkpointing procedure allow ery consistent state transaction abort system failure 
envy automatically copies modified data flash sram part copy write mechanism 
original data flash destroyed provide free shadow copy 
application roll back transaction simply copying data back flash 
order implement feature controller keep track location shadow copies protect cleaned 
function studied context log file systems similar data movement primitives 
related done areas relevant envy 
researchers mitl argue flash interesting benefits memory mapped storage medium suggest similar copy write scheme handled software operating system hardware controller lower performance 
studied problem minimize write costs data reclamation log structured file systems 
benefits possible having fast access stable storage demonstrated advocates non volatile write caches 
exten sive memory data structures aspects retrieval data large memory arrays done researchers main memory database field 
particularly interesting done ibm part starburst project database tested storage components uses memory mapped data structures uses standard cached disk model 
systems log changes disk memory keep entire database memory resident uses memory data structures performed substantially better 
flash memory increasingly important storage medium 
high density non volatility rapidly decreasing cost positioned practical solid state mass storage device 
past year flash reached milestones including surpassing sales intel dropping dram terms cost megabyte 
semiconductor manufacturers competing flash product fueled demand expanding portable computing industry 
premium flash products paid portable standard hard disks 
believe flash attractive performance standpoint 
larger desktop applications databases long hindered disk bottleneck non volatile solid state memory cheap mass storage reduce problem 
envy provides efficient interface high speed flash storage system 
uses parallel data transfers copy write scheme efficient cleaning algorithm overcome problems caused flash worm characteristics long write latency limited cycling ability 
non volatile memory persistent store allowing easy software access maintaining near sram access times ns reads ns writes 
ability access stable storage quickly envy match today computers especially running currently bound applications 
performance main providing reliable transaction type op erations eliminating performance reliability trade disk systems 
implementation mbyte prototype planned interface host 
system chips transfer entire page single memory cycle techniques tested maintain reasonable performance levels lower transfer rate 
baker seltzer 
non volatile memory fast reliable file system 
proceedings lb symposium architectural support programming languages operating systems pages october 
caceres douglis li marsh 
operating system implications solid state mobile computers 
technical report mitl tr matsushita information technology laboratory may 
copeland keller krishnamurthy smith 
case safe ram 
proceed lags th international conference large databases pages 
intel 
flash memory 
transaction processing performance council 
tpc benchmark standard specification rev 
garcia molina salem 
main memory database systems overview 
ieee data engineering pages december 
gibson 
performance reliability re arrays inexpensive disks 
computer measurement group annual conference proceedings pages december 
lehman shekita cabrera 
evalua tion starburst memory resident storage component 
ieee transactions data engineering pages december 
li naughton 
multiprocessor main memory transaction processing 
proceedings international symposium databases parallel distributed systems pages december 
patterson gibson katz 
case redundant arrays inexpensive disks raid 
proceedings sigmod pages 
reddy banerjee 
evaluation multiple disk systems 
ieee transactions computers december 
wilkes 
unix disk access patterns 
proceedings winter usenix conference pages january 
rosenblum :10.1.1.117.5365
design implementation log structured file system 
acm transactions computer systems february 
seltzer bostic mckusick staelin 
implementation log structured file system unix 
proceedings winter usenix conference pages january 
smith 
disk cache ratio analysis design considerations 
cm transactions cam purer systems august 
