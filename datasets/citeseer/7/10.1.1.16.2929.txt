infinite hidden markov model matthew beal zoubin ghahramani carl edward rasmussen gatsby computational neuroscience unit university college london queen square london wc ar england www gatsby ucl ac uk fm beal zoubin gatsby ucl ac uk show possible extend hidden markov models countably infinite number hidden states 
theory dirichlet processes implicitly integrate infinitely transition parameters leaving hyperparameters learned data 
hyperparameters define hierarchical dirichlet process capable capturing rich set transition dynamics 
hyperparameters control time scale dynamics sparsity underlying state transition matrix expected number distinct hidden states finite sequence 
framework natural allow alphabet emitted symbols infinite consider example symbols possible words appearing english text 
hidden markov models hmms popular methods machine learning statistics modelling sequences speech proteins 
hmm defines probability distribution sequences observations symbols fy invoking sequence unobserved hidden discrete state variables fs basic idea hmm sequence hidden states markov dynamics independent observations independent variables model defined terms sets parameters transition matrix ij th element jjs emission matrix iq th element 
usual procedure estimating parameters hmm baum welch algorithm special case em estimates expected values matrices corresponding counts transitions emissions respectively expectation taken posterior probability hidden state sequences 
standard estimation procedure model definition hmms suffer important limitations 
maximum likelihood estimation procedures consider complexity model making hard avoid underfitting 
second model structure specified advance 
motivated part problems attempts approximate full bayesian analysis hmms integrates optimises parameters 
proposed approximate bayesian integration variational methods conditioning single hidden state sequence 
start point view basic modelling assumption hmms data generated discrete state variable take values unreasonable real world problems 
formulate idea hmms countably infinite number hidden states 
principle models infinitely parameters state transition matrix 
obviously sensible optimise parameters theory dirichlet processes dps implicitly integrate leaving just hyperparameters defining prior transition dynamics 
idea dps define mixture models infinite number components previously explored 
simple form dp turns inadequate hmms 
extended notion dp stage hierarchical process couples transitions different states 
stressed dirichlet distributions extensively priors mixing proportions smooth gram models finite alphabets differs considerably model 
knowledge studied inference discrete infinite state hmms 
review dirichlet processes section basis notion hierarchical dirichlet process hdp described section 
explore properties hdp prior showing generate interesting hidden state sequences emission model infinite alphabet symbols 
infinite emission model controlled additional hyperparameters 
section describe procedures inference gibbs sampling hidden states learning optimising hyperparameters likelihood evaluation infinite state particle filtering 
experimental results section conclude section 
properties dirichlet process examine detail statistics hidden state transitions particular state number hidden states finite equal transition probabilities th row transition matrix interpreted mixing proportions call imagine drawing samples fc discrete indicator variable take values kg proportions 
joint distribution indicators multinomial kronecker delta function iff count number times drawn 
see happens distribution indicators integrate mixing proportions conjugate prior 
give mixing proportions symmetric dirichlet prior positive concentration hyperparameter dirichlet restricted simplex mixing proportions sum 
analytically integrate prior yield applied mechanism described section state trajectories prior visit state twice new state previous transitions dp choose randomly infinitely states transitioning new state probability 
probability particular sequence indicators function counts fn conditional probability indicator setting indicators denoted jjc counts th indicator removed 
note self reinforcing property choose popular state 
key property dps heart model expression take limit number hidden states tends infinity jjc kg represented unrepresented combined number represented states infinite finite 
interpreted number pseudo observations kg strength belief symmetric prior 
infinite limit acts innovation parameter controlling tendency model populate previously unrepresented state 
hierarchical dirichlet process hdp consider modelling row transition emission matrices hmm dp 
key results previous section form basis hdp model infinite hmms 
integrate infinite number transition parameters represent process finite number indicator variables 
second dp natural tendency existing transitions proportion previous usage gives rise typical trajectories 
sections describe detail hdp model transitions emissions infinite state hmm 
hidden state transition mechanism imagine generated hidden state sequence including time building table counts ij transitions occured far state ij 
state impose state dp parameter counts entries th row prefer reuse transitions follow typical trajectories see jjs ij ij kg note probabilities sum dp finite probability ij selecting transitions 
case model defaults second different dp parameter counts vector refer default dp associated counts oracle 
defaulted oracle dp probabilities transitioning jjs kg represented kg new state infinite model time infinite number indistinguishable unrepresented states available infinitesimal mass proportional ii ij ij self transition oracle ij ij existing transition existing state new state left state transition generative mechanism 
right sampled state trajectories length time horizontal axis hdp give examples modes behaviour 
explores states sparse transition matrix 
multiple interacting trajectory segments 
switches different states 
strict left right transition dynamics long linger time 
oracle probability proportional entirely new state transitioned 
mechanism visiting new states infinitely available 
transition set ij ij transitioned state oracle dp just described addition set 
transitioned new state size increase 
self transitions special probability defines time scale dynamics hidden state evolves 
assign finite prior mass self transitions state third hyperparameter model 
visited hdp self transition count initialised full hidden state transition mechanism level dp hierarchy shown decision tree form 
alongside shown typical state trajectories prior different hyperparameters 
see just hyperparameters wealth types possible trajectories 
note controls expected number represented hidden states influences tendency explore new transitions corresponding size density respectively resulting transition count matrix 
controls prior tendency linger state 
role oracle fold 
serves couple transition dps different hidden states 
newly visited state previous transitions existing states oracle necessarily knowledge represented states created transition new state probability 
consulting oracle new states finite probability transitioning represented states 
second role oracle allow states influential commonly transitioned 
emission mechanism emission process identical transition process respect concept analogous self transition 
need introduce hyperparameters emission hdp 
state transitions keep table counts iq number times state emitted symbol number times symbol iq iq iq existing emission existing symbol new symbol oracle left state emission generative mechanism 
middle word occurence entire alice novel word assigned unique integer identity appears 
word identity vertical plotted word position horizontal text 
right exp evolution number represented states vertical plotted iterations gibbs sweeps horizontal learning ascending descending sequence requires exactly states model data perfectly 
line represents initialising hidden state random sequence containing distinct represented states 
hyperparameters optimised 
emitted emission oracle 
applications training sequence expected contain possible observation symbols 
consider occurence words natural text shown middle alice novel 
upper envelope demonstrates new words continue appear novel 
property dp expected number distinct symbols words increases logarithm sequence length 
combination hdp hidden states emissions may able capture somewhat super logarithmic word generation alice 
inference learning likelihoods sequence observations sets unknowns infinite hmm hidden state sequence fs hyperparameters defining transition emission 
note states observations implicitly integrated infinitely transition emission parameters 
making analogy non parametric models gaussian processes define learned model set counts fn optimised hyperparameters describe approximate gibbs sampling procedure inferring posterior hidden state sequence 
describe hyperparameter optimisation 
lastly calculating likelihood introduce infinite state particle filter 
algorithm summarises learning procedure 
instantiate random hidden state sequence fs st 
gibbs sample hyperparameter settings count matrices observations 
update count matrices reflect new may change number represented hidden states 


update hyperparameters hidden state statistics 

goto step 
gibbs sampling hidden state sequence define results removing transition emission counts contributed define similar items related transition emission oracle vectors 
exact gibbs sweep hidden state takes operations hdp generative process changing affects probability subsequent hidden state transitions emissions 
computation reasonably approximated basing gibbs update state fs total counts order facilitate hyperparameter learning improve mixing time gibbs sampler sample set auxiliary indicator variables fo alongside binary variable denoting oracle generate fs respectively 
hyperparameter optimisation place vague gamma priors hyperparameters derive approximate form hyperparameter posteriors treating level separately 
expressions posterior accurate large expressions exact js ii ij js ek iq js js number represented states transitioned state including similarly number possible emissions state oe number times oracle transition emission processes calculated indicator variables fo solve maximum posteriori map setting hyperparameter example map obtained solution equation gradient techniques newton raphson map map iq map map infinite state particle filter likelihood particular observable sequence symbols involves intractable sums possible hidden state trajectories 
integrating parameters hmm induces long range dependencies states 
particular dp making transition transition sequence standard tricks dynamic programming 
furthermore number distinct states grow sequence length new states generated 
chain starts distinct states time possible distinct states making total number trajectories entire length sequence 
hidden states hmm satisfy markov condition integrating parameters induces long range dependencies 
approximation motivated way 
consider sampling parameters posterior distribution jy parameter matrices depend count matrices 
markov property probability depends computed considering effect states 

shape inverse scale parameters 
propose estimating likelihood test sequence learned model particle filtering 
idea start number particles distributed represented hidden states final state marginal training sequence may fall new states 
starting set particles fs tables training sequences fn recursive procedure specified jy 
compute js particle 
calculate jy 

resample particles 

update transition emission tables particle 

sample forward dynamics js may cause particles land novel states 
update 
goto 
log likelihood test sequence computed log discrete state space probability mass concentrated represented states feasible particles 
synthetic experiments exp discovering number hidden states applied infinite hmm inference algorithm ascending descending observation sequence consisting concatenated copies 
parsimonious hmm models data perfectly exactly hidden states 
infinite hmm initialised random hidden state sequence containing distinct represented states 
right show number represented states evolves successive gibbs sweeps starting variety initial cases converges occasionally exploring 
exp expansive sequence length generated state symbol hmm transition emission probabilities shown top left 
exp compressive sequence length generated state symbol hmm transition emission probabilities shown bottom left 
exp exp infinite hmm initialised hidden state sequence distinct states 
shows successive gibbs sweeps hyperparameter learning count matrices infinite hmm converge resemble true probability matrices shown far left 
discussion shown level hierarchical dirichlet process define nonparametric bayesian hmm 
hdp integrates transition emission parameters hmm 
advantage longer necessary constrain hmm finitely states observation symbols 
prior hidden state transitions defined hdp capable producing wealth interesting trajectories varying hyperparameters control 
necessary tools infinite hmm linear time approximate gibbs sampler inference equations hyperparameter learning particle filter likelihood evaluation 
different particle apply assume test sequence immediately follows training sequence 
true transition emission probability matrices exp true transition emission probability matrices exp far left pair hinton diagrams represent true transition emission probabilities generate data experiment permutation hidden states lighter boxes correspond higher values 
top row exp expansive hmm 
count matrix pairs fn mg displayed sweeps gibbs sampling 
bottom row exp compressive hmm 
similar top row displaying count matrices sweeps gibbs sampling 
rows display single gibbs sweep reduced size clarity 
synthetic data shown infinite hmm discovers appropriate number states required model data structure emission transition matrices 
important emphasise count matrices infinite hmm resemble point estimates hmm parameters better thought sufficient statistics hdp posterior distribution parameters 
believe problems infinite hmm nature ability automatically determine required number hidden states superior conventional treatment hmms associated difficult model selection problem 
results promising limited synthetic data hope explore potential model real world problems 
authors david mackay suggesting oracle morris perl expertise 
antoniak 
mixtures dirichlet processes applications bayesian nonparametric problems 
annals statistics 
ferguson 
bayesian analysis nonparametric problems 
annals statistics march 
mackay 
ensemble learning hidden markov models 
technical report cavendish laboratory university cambridge 
mackay peto 
hierarchical dirichlet language model 
natural language engineering 
neal 
markov chain sampling methods dirichlet process mixture models 
technical report dept statistics university toronto 
rabiner juang 
hidden markov models 
ieee acoustics speech signal processing magazine 
rasmussen 
infinite gaussian mixture model 
advances neural information processing systems cambridge ma 
mit press 
stolcke omohundro 
hidden markov model induction bayesian model merging 
hanson cowan giles editors advances neural information processing systems pages san francisco ca 
morgan kaufmann 
