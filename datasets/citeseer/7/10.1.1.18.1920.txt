robust scheduling bag tasks applications task replication daniel da silva cirne francisco universidade federal de grande ao de os ao em inform atica av 
apr gio veloso grande pb brazil dsc br scheduling independent tasks heterogeneous environments grids trivial 
scheduling plan kind environments usually needed prediction information host speed host load task size network load 
kind information available dif obtain 
propose approach kind prediction information delivers performance 
approach uses task replication cope dynamic heterogeneous nature grids depending information machines tasks 
results show task replication deliver stable performance minimal additional resource consumption 

increase availability powerful computers high speed networks way deal computation changing 
advances network technology possible interconnect geographically dispersed resources high speeds 
fact opened possibility large number resources scattered world executing parallel applications called grid computing 
course applications equally suitable run computational grid 
due high communication latency grid environments exhibit today loosely coupled parallel applications better candidates run grids applications need intensive communication synchronization 
fact say bag tasks applications suitable kind application current grid environments 
type application composed independent tasks executed order need inter task communication 
note important bag applications including data mining massive searches key breaking parameter sweeps monte carlo simulations fractals calculations mandelbrot image manipulation applications tomographic reconstruction 
despite better suitability bag tasks applications computational grids ensuring applications achieve performance grids trivial task 
grids typically heterogeneous shared users complicate scheduling 
due widely distributed nature grids information system typically scarce imprecise hard obtain complicates scheduling 
due difficulties scheduling applications grids target considerable effort years :10.1.1.46.3287
propose task replication ensure performance bag tasks applications running grids despite limited poor information machines compose grid tasks compose application 
fact approach information machines tasks 
approach seen extension workqueue scheduler task replication idle hosts grid 
hosts execute replicas remaining tasks 
replica complete provides task output 
replicas killed 
shall see approach generates stable performance application heterogeneous dynamic environments depend information grid application wastes small amount cycles 
remaining sections structured follows 
section describe problem scheduling bag tasks applications grids 
section solution queue replication approach 
section show experimental results scheduling algorithms performance 
section close concluding remarks 

scheduling bag tasks applications grids scheduling independent tasks grids simpler tightly coupled parallel applications difficult due dynamic behavior intrinsic resource heterogeneity exhibited grids 
grid environments typically composed shared resources contention created applications running simultaneously resources causes delays degrades quality service 
resources grids heterogeneous may perform way applications 
achieving performance kind situation usually requires performance prediction information scheduling plan 
usually difficult obtain information entire grid due grid wide distribution 
information available part grid due administrative restrictions 
existing scheduling solutions bag tasks applications classified static dynamic 
static schedulers perform allocation task processor execution starts 
dynamic adaptive schedulers scheduling decisions application execution 
representative static schedulers bag tasks applications largest task 
needs types information schedule tasks properly task size host speed host load 
algorithm time available ba host initialized tasks ordered descending way size 
largest task allocated 
task allocated host provides better completion time ct tba task allocated host tba value corresponding host incremented 
scheme initial host load machine speed tries balance load hosts respect total application size allocated 
problem load host changes execution 
unloaded host assigned compute large task heavily loaded time task execution arrives compromise application 
negative point algorithm needs information host load task size host speed 
illustrate dynamic scheduler consider queue algorithm 
queue approach need kind prediction information task scheduling 
approach scheduler manages queue tasks distributed processors soon available 
completion tasks processors send back results integrated final result 
scheduler starts sending task available host 
host finishes task scheduler assigns task host provided tasks processed 
idea approach tasks assigned fast machines slow machines small load 
great advantage queue depend performance information 
problem arises large task allocated slow machine schedule 
note queue differ static dynamic amount information required 
needs information machines speed load tasks size execution time 
queue need information run 
note numerous efforts area scheduling bag tasks applications 
example james compare scheduling algorithms 
results showed continual adaptive algorithm better jobs high degree symmetry mean 
execution times easily predictable better come serve algorithm 
dynamic scheduling heuristics studied maheswaran 
studies revealed choice mapping heuristics depends parameters structure heterogeneity tasks machines arrival rate tasks 

queue replication due difficulty consistently obtaining performance information grid machines application tasks decided implement scheduling algorithm performance prediction information 
call solution queue replication basically adds task replication classic queue algorithm 
strategy queue replication algorithm similar queue algorithm 
difference replication approach common queue algorithm number hosts greater number remaining tasks tasks replicated assigned idle hosts 
idea set replicated tasks original task copies finish considered normal execution task question copies killed hosts available 
worst case total execution time application equal simple workqueue cases replication approach better shortly see 
improvement performance occurs task replicated assigned faster host completed original task 
replicas chance replicated task assigned faster host grows 
negative point approach killed copies consume cpu resources vain 
empirical evidence extra consumption cpu power exceed mean original cpu demand 
performance improvement obtained maximum replication duplication 
approach tries minimize problem scheduling independent tasks heterogeneous environments avoiding dependence kind information task size processor performance 
kind information helpful scheduling plan hard obtain due distributed nature grids 
usually difficult obtain accurate predictions computing networking resources 

experimental results principal objective experiments evaluate performance different scheduling algorithms computing environments varying degrees heterogeneity machines tasks 
performed experiments compare performance different scheduling heuristics bag tasks applications 
algorithms evaluated queue replication approach largest task queue 
static algorithm relies heavily performance information 
queue dynamic algorithm depend performance information 
see section detailed description algorithms 

simulation environment run experiments toolkit 
toolkit provides basic functions simulation distributed applications grid environments 
built study scheduling algorithms resource management policies computational grid environments 
important assumption transfer times negligible dealing small input output data 
means tasks cpu bound large amounts data previously staged grid common practice data grid applications 
experiment number machines randomly picked uniform distribution denoted 
known speed machines practically duplicates year simulate heterogeneity machines years technique 
speed machines varies accordingly uniform distribution hm possible values hm 
smaller values represent lower speed bigger values represent higher speed 
note hm controls grid heterogeneity 
particular hm means grid homogeneous 
number tasks simulation randomly chosen uniform distribution denoted 
time execution machine speed task varies accordingly uniform distribution ht possible values ht 
behavior machines seen 
smaller values ht represent low heterogeneity ht implies tasks size bigger values represent higher degrees heterogeneity 
load host simulated traces obtained nws measurements actual systems 
traces contain free cpu function time 
simulator uses traces machines experiment behave similar real machines 
experiment consists simulations 
algorithms queue replication replication replication simulated set machines tasks 
denote maximum amount replication allowed 

result analysis related works application completion time main measure compare different scheduling heuristics 
completion time obtained simulations normalized application size grid power vary experiment 
higher application size implies 
higher grid power implies performance higher speed 
normalized completion time values considered 
divide jobsize factor influence 
multiply eliminate grid power final results 
symbolically jobsize shows simulation results different machine heterogeneity levels 
hm average results ht 
machines speed hm workqueue outperforms favors fastest machines adapts better run time speed load machines execution starts 
machine heterogeneity increases queue performance degrades performance maintains 
higher heterogeneity affects queue large task allocated slow machine execution completion time higher 
algorithms replication approach better performance maintained performance machine heterogeneity grows 
note replication increases substantially performance application 
shows simulation results different task heterogeneity levels 
ht average results hm 
workqueue increases performance task hetero machines heterogeneity workqueue replication replication replication 
machine heterogeneity grows favored intrinsic adaptability 
fast machines tend designated execution greater number tasks machines heavily loaded due contention loaded machines take care 
maintains quite stable level performance task assignment execution situation initially fast machine slower due contention may occur 
shows algorithms replication approach better performance maintained performance machine heterogeneity grow 
increase replication level lead high improvement performance 
figures shows cpu wasted time replicated tasks cancelled application execution comparison application size 
shows results different machine heterogeneity 
increase machine heterogeneity consequently increase grid power possibility task assigned fast host finish quickly grows 
time wasted replicas 
shows results function task heterogeneity 
increase task heterogeneity consequently increase tasks heterogeneity workqueue replication replication replication 
task heterogeneity task sizes possibility task replicas large grows 
large task replicas assigned slow hosts time wasted 
results show wasted cpu time compared time necessary complete tasks small 
means approach proposed able substantially increase application performance expense minimal increase resources consumption 
machines heterogeneity lost lost lost 
cpu wasted time considering machine heterogeneity tasks heterogeneity lost lost lost 
cpu wasted time task heterogeneity 
proposed task scheduling heuristic computational grids task replication 
approach targets bag applications independent tasks 
solution kind performance prediction information 
scheme similar classic queue hosts go idle compute replicas running tasks 
idea set task replicas finish considered normal execution task question copies killed free hosts 
simulated thousands grids applications compare performance approach studied algorithms large task queue 
simulation results previous section showed replication scheme propose delivers stable performance minimal increase resource consumption 
improvements grid model including realistic network traffic cope file transfers intensive applications staged data 
try simulation perfect algorithm performance comparison replication approach 
study emergent behavior caused multiple instances scheduler grid 
abramson giddy 
high performance parametric modeling nimrod killer application global grid 
casanova simulation evaluate scheduling heuristics class applications grid environments 
technical report rr ecole normale superieure de lyon 
casanova heuristics scheduling parameter sweep applications grid environments 
heterogeneous computing workshop pages 
plank wolski 
data staging effects wide area task farming applications 
foster kesselman 
grid blueprint new computing infrastructure 
lilja 
dynamic scheduling techniques heterogeneous computing systems 
concurrency practice experience pages 
hamscher evaluation job scheduling strategies 
grid computing proceedings st ieee acm international workshop grid computing grid th international conference high performance computing pages 
iverson 
dynamic competitive scheduling multiple dags distributed heterogeneous environment 
th ieee heterogeneous computing workshop hcw pages 
james 
scheduling independent tasks metacomputing systems 
technical report university adelaide 
talbi geib 
building scheduling parallel adaptive applications heterogeneous environments 
ieee international workshop cluster computing 
khan jones 
comparison multiprocessor scheduling heuristics 
international conference parallel processing pages 
maheswaran ali siegel dynamic matching scheduling class independent tasks heterogeneous computing systems 
heterogeneous computing workshop 
plank beck internet backplane protocol storage network 

grail sdsc edu projects 
cirne combining workstations supercomputers support grid applications parallel tomography experience 
proceedings hcw heterogeneous computing workshop 
wolski 
dynamically forecasting network performance network weather service 
cluster computing 

