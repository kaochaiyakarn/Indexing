automated construction classifications conceptual clustering versus numerical taxonomy michalski robert ieee trans 
pattern analysis machine learning volume pami july 
transactions pattern analysis machine intelligence vol 
pami 
july automated construction classifications conceptual clustering versus numerical taxonomy michalski nd robert stepp method automated construction classifications called conceptual clustering described compared methods numerical taxonomy 
method arranges objects classes rep certain descriptive concepts classes defined solely similarity metric priori defined attribute space 
specific form method conjunctive conceptual clustering descriptive concepts statements involving rela tions selected object attributes optimized assumed global criterion clustering quality 
method implemented program cluster tested numerical taxonomy methods exemplary problems construction classification popular microcomputers reconstruction classification selected plant disease categories 
experiments majority numerical taxonomy methods produced results difficult interpret arbitrary 
contrast conceptual clustering method produced results simple interpretation corresponded solutions pre people 
index terms theory cluster theory conceptual clus tering data analysis inductive inference knowledge acquisition learning observation learning teacher numerical taxonomy pattern recognition theory formation 
usually viewed process partitioning collection objects measurements observations groups similar objects numerical measure similarity 
approach clustering raises fundamental problems kind similarity measure cluster objects numerical similarity objects principle constructing clusters 
questions discussed answers substantially different ones traditional techniques 
area cluster analysis closely related field numerical taxonomy similarity objects typi cally determined proximity measure multidimensional space spanned prior defined set object attributes 
clusters defined collections elements points space intracluster proximities high intercluster proximities low 
research cluster analysis primarily concerned manuscript received revised february 
supported part national science foundation mc part office naval re search 
authors department computer science univer sity illinois urbana il 
devising various object proximity measures developing efficient algorithms utilizing measures 
surveys measures sokal anderberg diday simon 
approach clustering significant limitations 
clusters determined groups objects close fixed pt assumed attribute space may lack simple conceptual interpretations 
reason similarity measure typically considers attributes equal importance tion relevant relevant irrelevant 
consequently dental agreement values sufficient number irrelevant attributes objects different major ways may classified similar 
approach mech anism selecting evaluating attributes process generating clusters 
mechanism gener ate new attributes may adequate clustering initially provided 
important limitation conventional methods produce con ceptual description clusters 
problem cluster interpretation simply left data analyst 
serious drawback data analysts typically interested determining clusters formulating meaningful descriptions 
traditional techniques concerned ways employed humans clustering objects 
observations people cluster objects indicate tend formulate carefully selected attri possible attributes cluster objects basis attributes 
cluster contains objects similar sense score similarly important attributes 
descriptions clusters formally expressed logical conjunctions relations attributes 
different clusters expected descriptions different values selected attributes 
short people tend cluster objects categories characterized nonintersecting conjunctive concepts 
brings related limitation traditional methods take consideration gestalt concepts linguistic constructs people describing object collections 
concepts may characterizations configuration objects shaped shaped idea clustering objects categories described ieee michalski automated classifications single concepts specifically conjunctive concepts con 
conceptual clustering methodology computer implementation introduced michalski 
subsequently expanded michalski stepp 
purpose summarize main ideas conjunctive conceptual clustering method compare techniques numerical taxonomy 
describes conjunctive conceptual clustering program cluster successor earlier program cluster presents results applying numerical taxonomy program implementing different techniques clustering problems 
ii 
specification clustering problem section discusses various components clustering problem specified data analyst computer clustering method 
obl ects clustered attributes typically objects clustered come experimental study phenomenon described specific set attributes variables selected data ana 
attributes may measured different scales nominal ordinal interval ratio absolute 
simple case may distinguish qualitative attributes measured nominal ordinal scale quantitative attributes measured remaining scales 
measurements subject problem dependent transformations may reduce precision quantitative attributes ot replace subranges values qualitative properties numerical size may replaced characterizations small size medium size large size 
attributes selected data analyst relevant clustering problem 
conventional approaches selection attributes treated separate prelim step 
conjunctive conceptual clustering method attribute selection performed simultaneously formation clusters 
method selects attributes viewpoint assumed criteria allow simply characterize individual clusters terms available concepts 
principle grouping objects clusters objects grouped clustering method principle 
traditional principle grouping objects clusters utilizes numerical measure object similarity usually reciprocal distance measure 
conceptual clustering objects assembled clusters represent single concepts linguistic terms simple logical functions defined terms 
conjunctive conceptual clustering described objects grouped clusters characterized logical products relations selected object attributes conjunctive concepts 
relations may include disjunction properties disjunction involves values attribute 
type disjunction called internal 
tire concepts internal disjunction represent typical characterizations object classes 
example concept objects small red green blue spot 
definition discussion conjunctive concepts internal disjunction section ii 
type cluster structure collection objects goal clustering divide collection certain meaningful subsets 
subsets clusters denote description subset general description ai satis fied objects ei unobserved objects 
relationships clusters cluster descriptions different types struc tures commonly distinguished literature 
partition structure set clusters union set descriptions disjoint implies clusters disjoint 
overlapping structure set clusters descrip tions intersect 
hierarchical structure multilevel hierarchy clusters level represent partition initial set clusters lower level elements partitions parent clusters level higher 
method described generates partition structure hierarchical structure clusters 
overlapping structure generated method described stepp 
cluster representation scheme purpose cluster representation scheme simply generally characterize objects cluster 
conjunctive conceptual clustering uses cluster schemes single representative object selected cluster seed cluster conjunctive statement describes objects cluster 
conjunctive statement called logical complex expression variable valued logic system vl suppose xt xn variables selected rep resent objects 
assume variable assigned domain dom xt specifies possible values variable take object col lection clustered 
number values dr domains assumed finite represented generally dom 
distinguish nominal linear structured variables domains unordered linearly ordered tree ordered sets respectively 
examples nominal variables color blood ype 
examples linear variables rank size quantity 
example structured variable shape values may triangle rectangle pentagon polygon represents general concept parent node nodes representing triangle rectangle tree structured domain 
description space spanned variables called event space 
point event space vector specific values variables xn 
event description object collection clus ieee transactions pattern analysis machine intelligence vol 
pami july tered called observed event 
events called un observed events 
relational statement selector form xi ri ri list elements domain variable xt linked internal disjunction denoted stands relational operator selector ix ri ix rl interpreted value elements ri value element rt 
case linear variables notation selector simplified relational operators examples selector variables values represented linguistic terms length greater color blue red size medium weight 
length color blue red size medium weight 
logical product selectors called logical complex complex 
set objects satisfy selectors complex called complex set complex 
complex description complex 
example complex height tall color blue red length size medium weight 
operation nr denoted implied concatenation selectors describes objects tall blue red length greater medium size weight 
set objects con corresponding complex 
distinction complexes sed permit application logical set theoretic operators respectively whichever convenient 
distinction unimportant term complex prefix 
collection objects constitutes complex collection precisely described complex 
possible describe collection objects complex complex allowed describe additional objects permitted generalized description collection 
example events el blue large round red medium round described complex color blue red size medium shape round 
complex covers unobserved events red large round blue medium round form introduced variable valued logic system 
distinct 
number unobserved events covered complex called absolute sparseness complex 
set complexes absolute sparseness set defined sum complexes 
addition absolute sparseness introduce type sparseness projected sparseness set com 
type sparseness applicable clus tering set pairwise disjoint complexes 
complexes pairwise disjoint exist pair complexes selectors variable disjoint 
variables involved selectors called discriminant variables clustering 
projected sparseness clustering sum determined event space spanned just discriminant variables 
example observed events complexes color blue size large shape round 
color red size projected respectively pace spanned discriminant variables color size assuming size takes values small medium large 
oa clustering quality problem judge quality clustering difficult universal answer 
indicate major criteria 
descriptions formulated clusters classes simple easy assign objects classes differentiate classes 
criterion lead trivial arbitrary classifications 
second criterion class descriptions fit actual data 
achieve precise fit description may complex 
consequently demands simplicity fit conflicting solution find balance 
number measures introduced ing quality clustering 
cluster uses combined measure include elementary criteria fit clustering events simplicity commonality disjointness discrimination index 
fit clustering data computed different ways denoted 
negative total absolute sparseness clustering negative sum absolute complexes clustering 
measure negative projected sparseness clustering 
reason negative values increase degree match sparseness decreases 
simplicity clustering defined negative complexity sum costs attributed selector complexes 
possible selector cost func michalski si epp automated construction classifications tion number elements list 
selectors elements complex elements smaller cost 
simple measure complexity com puted number selectors contained complexes constant selector cost function gives selector cost 
commonality clustering total number properties shared events clusters 
commonality measured finding total number selectors appear complexes 
criterion analogous traditional clustering criterion maximizing similiar ity number shared properties events cluster 
disjointhess clustering measured sum degrees disjointness pair complexes clustering 
degree disjointhess pair com number selectors complexes variable values intersect 
example pair complexes color red size small medium shape circle color blue siz medium large degree disjointhess selectors intersect nonintersecting selectors underlined 
criterion promotes clusterings classes having differing properties analogous criterion ing maximal distance clusters methods clustering 
discrimination index clustering number variables singly discriminate clusters variables having different values cluster description 
definitions criteria crease criterion value improves quality clustering 
relative influence criterion specified lexicographical evaluation functional lef 
lef defined sequence criterion tolerance pairs rl cs ci elementary criterion se lected list ri tolerance threshold re 
step clusterings eval criterion cr score best range defined threshold retained 
retained clusterings evaluated criterion threshold similarly 
process continues set retained clust reduced singleton best clustering sequence pairs exhausted 
case retained clusterings equivalent quality respect lef may chosen arbitrarily 
lhe selection elementary criteria ordering specification tolerances data analyst 
ii 
method implementation section describes algorithm conjunctive con ceptual clustering implemented program cluster successor program cluster 
algorithm consists clustering module hierarchy complexes str fig 

illustration sta 
building de described sections iii ii respectively 
operation fundamental procedures nid described sections iii operation operation transforms set events complexes single complex covering events complexes 
variable set values variable takes events complexes determined 
sets variable generated complex 
example el 
complex ca xt 
complex minimum sparseness absolute projected complexes covering events complexes 
procedure star eo event event set eo eo set maximally general complexes covering event covering event eo 
words set maximally general descriptions event intersect event set eo 
fig 
presents star event events denoted dimensional space spanned linear variables 
star consists complexes aa 
complex reduced complex explained 
algorithm follows theoretical stars defined subjected major modifications 
minimize sparseness complexes stars second bound stars select certain number best complexes context dependent criterion 
modification performed complex maximally general respect property exist complex property ieee ons pattern analysis machine intelligence vol 
july algorithm described second algorithm described section iii 
complexes stars elo maximally general may describe objects way 
algorithm generates star maximally reduces sparseness complex file preserving coverage observed events 
example complex fig 
reduced obtained complex steps procedure follows 
elementary stars determined elementary star event event ei variables different values identified 
suppose loss generality variables xl xs ei rt rs rn 
complexes star ri maximally general complexes cover cover number complexes elementary star ei 
complete star determined star generated setting logical product ei el eo disjunction com elementary star 
mul 
complexes performed absorption laws disjunction irredundant complexes obtained 
multiplication carried steps step disjunction complexes disjunction selectors elements consecutive elementary stars 
set complexes resulting disjunction 
complexes leo reduced simplified sparseness complex star reduced possible uncovering observed events 
done performing observed events contained complex 
obtained complexes generalized simplified 
arid procedure procedure transforms set complexes set disjoint complexes disjoint clustering 
input complexes nid disjoint procedure leaves unchanged 
steps procedure follows 
core complexes determined observed events covered complex set placed multiply covered event list list 
list empty complexes weakly intersecting intersection area contains unobserved events 
case procedure terminates indication combination complexes weakly intersecting clustering 
complex replaced observed events contained complex list singly covered 
obtained called core complexes 
best host complex determined event list event selected list added core complexes generalizing complex extent necessary cover event 
generalization performed applying operator determine star seed termination clustering quality improving 
ql fig 

flowchart clustering module 
event complex 
result modified complexes obtained 
replacing core complexes initial set corresponding modified complex different ways collection clusterings obtained 
clusterings evaluated assumed clustering quality criterion see section 
complex best clustering covers event list considered best host event 
best clustering retained remaining ones eliminated 
repeating operation event list set disjoint com obtained union covers observed events original set complexes 
event added complex causing result intersect complexes event placed exceptions list 
clustering module basic algorithm underlying implementation clustering module introduced flowchart fig 

purpose described follows 
collection events number clusters desired criterion clustering quality nd disjoint clustering collection events op criterion clustering quality lef 
stepp automated construction classifications describe straightforward exhaustive search version algorithm show version modified increase efficiency 
version algorithm 
full search version clustering algorithm de scribed merely provide insight difficulty problem theoretical value 
proceeds follows 

initial seeds determined collection events events initial seeds selected 
seeds step seeds selected certain rules see step 

stars constructed seeds seed ei reduced star rg eo constructed procedure eo set remaining seeds 

optimized clustering disjoint cover built selecting ad mode lying complexes stars combination complexes created selecting complex star tested see contains intersecting complexes 
complexes modified procedure nid disjoint 

termination criterion evaluated iteration obtained clustering stored 
subsequent iterations clustering stored scores better pre stored clusterings lef see section ii 
algorithm terminates specified number iterations produce better clustering number defined termination criterion described 

new seeds selected new seeds selected sets observed events contained complexes gener ated clustering seed complex 
seed selection techniques 
technique selects central events defined events nearest geometrical centers complexes 
technique stemming principle selects border events defined events farthest centers 
ties central border events broken favor events seeds 
technique selecting central events repetitively consecutive iterations long clusterings improve 
improvement ceases border events selected 
selecting seeds new iteration begins step 
clustering algorithm generates complexes describing individual clusters determines complexes score evaluation criteria lef 
algorithm stops satisfied 
termination criterion pair parameters base standard number iterations algorithm performs probe number addi 
iterations performed iteration produced improved cover 
general structure algorithm called dynamic clustering method 
computationally costly part algorithm principle states border near hit event truly belongs cluster selected seed produce clustering contains events central event seed 
fig 

exhaustive search tree 
construction optimized clustering seed events step 
illustration assume seeds selected collection step stars remaining seeds remaining seeds generated 
fig presents complexes stars branches search tree 
branches root represent complexes star branches second level repeated times represent complexes star rn combination complexes con taining complex star corresponds path tree 
combination may contain inter complexes procedure nid applied result disjoint clustering 
clusterings ordered quality criterion lef best selected 
path rank ordered pro search procedure 
strategy determining clustering seeds simple unfortunately inefficient solving interesting practical problems 
due fact stars may contain complexes 
vari ables seeds star may contain complexes complexes elementary stars needed compute complete star 
complexes search tree way branching node leaves 
absorption laws defined set theory usually eliminate redundant complexes star may large 
artificial intelligence research various heuristic search procedures offers various possibilities reducing search 
solve problem adopted known ideas developed new ones 
result search procedure called path pro search techniques 

bounding stars procedure number complexes star bounded fixed integer assures search tree way branching 
bounded star contains just arbitrary complexes initial star best ones 
step star generation multiplication set complexes elementary star see star algorithm complexes reduced arranged descending order assumed clustering quality criterion lef 
complexes retained multiplication step 
operation performed star generation final star ieee transactions pattern analysis machine vol 
pam 

july rn complexes 
stars obtained called bounded reduced stars denoted leo 
elementary criteria measure global properties clustering properties just single complex disjointhess 
consequently evaluating complex de node search tree root complex evaluated context complexes asso ciated path root node 
bounding star gain significantly efficiency give assurance obtained clustering optimal 
significant loss clustering obtained iteration contributes seeds iteration precise ex pression important 

generating stars dynamically necessary evaluate complexes context previously selected com 
bounding star done differently node search tree 
cluster uses lazy strategy star generated needed expand node path explored 

searching order path rank mentioned complexes bounded star arranged descend 
ins order lef 
search tree branch best complex assigned branch index branch best complex assigned branch index index rn 
path index path root leaf sum branch indexes path 
paths root leaf represent potential clusterings investigated ascending order path index 
path investigated path index path containing best complexes star 
paths considered path index 
paths 
paths increasing path index generated evaluated search termination criterion applied 
criterion consists parameters search base search probe 
search base number paths expanded evaluated 
search probe number additional paths considered 
path processed nid complexes transformed disjoint clustering quality criterion evaluated 
new clustering better previous clustering saved search 
probe number additional paths explored 
probing fails find better clustering search terminates 

tapering search tree bound stars decreased increase path index 
search tree fully developed side containing higher quality complexes 
fig 
shows example search tree generated cluster 
tree modification tree fig 
resulting application techniques 
fig 
maximum bound set 
root expanded constructing star seed seeds complexes az decreasing order quality deter mined lef 
branches representing complexes assigned branch indexes respectively 
node attached branch expanded 
star fig 

path ordered search tree cluster 
seed seeds generated creating complexes 
branches corresponding complexes assigned branch indices respectively 
path having lowest path index denoted heavy lines fig 
considered 
associated clustering ct processed nid result saved best far 
path considered 
associated clus tering crew processed nid evaluated 
better previous clustering saved 
order ex path second path path index star seed seeds generated 
contains com ct clustering associated path evaluated 
assuming termination criterion parameters search base search probe evaluation scores shown fig 
tree search terminates investigating fourth path path exhausts probing finding better path evaluation score best clustering 
building module hierarchy building module uses clustering module determine hierarchy clusters 
performs loops iterative recursire 
iterative loop repeats clustering module sequence values order determine value desirable clustering obtained 
approach computationally acceptable practical applications interesting hierarchies relatively small number branches value level 
loop applies iterative process node hierarchy 
step process exe root representing initial event set clus ters conjunctive descriptions determined 
consecutive steps repeat operation nodes representing clusters obtained previous step 
hy continues grow top continue growth criterion fails met 
criterion requires fit clusters descriptions level hierarchy better pre vious level 
order determine optimal value node modify clustering quality criterion compare clusterings different numbers com 
criterion reflect dependency fit clustering data value stepp automated construction classifications mp microprocessor ram size 
type structured type linear type structured domain values domain values domain values bytes tv color tv built 
bom 
type linear type linear domain values domain values ik bytes keys lfl hewlett packard proprietary fig 

variables describe microcomputers 
fig 

structured domain tile variable mp number clusters increases fit measured tive sparseness increase smaller complexes smaller sparseness 
hand increasing increases complexity clustering undesirable 
simple criterion takes consideration tradeoff require product total sparseness achieve minimum value experimentally de parameter balancing relative effect sparse ness number clusters solution 
iv 
comparison approaches described conjunctive conceptual clustering method compared various numerical taxonomy methods exemplary problems dealing constructing classification popular microcomputers second dealing reconstructing classification selected soybean diseases 
exemplary problem determining classification microcomputers problem develop meaningful classification popular microcomputers 
microcomputer described terms variables shown fig 

mp display type structured variables domains shown figs 
respectively 
descriptions microcomputers consideration fig 

programs applied solve problem implements techniques numerical taxonomy cluster implements conjunctive conceptual clustering 
obtained results described corresponding sec tions follow 
display type ext 
terminal tv color tv built fig 

domain variable display type 
results problem principle clustering applied objects high nu similarity placed cluster objects low similarity placed different clusters 
numerical taxonomy program organizes events hierarchy dendrogram clusters reflecting sim consecutively larger groups objects 
similarity techniques spanning data transformations numerical similarity measures schemes merging individual objects clusters 
selections available 
data transformation technique normalization unit intervals standardization values expressed terms standard deviations 
similarity measure product moment correlation simple matching coefficients reciprocal euclidean distance 
merging criterion unweighted average linkage weighted average linkage 
particular technique specified symbolically letters denoting specific choices data transformation similarity measure merging criterion 
example cba denotes combination standardized data similarity measure simple matching coefficients unweighted average linkage merging criterion 
method generates hierarchy top level represents complete collection objects tips represent single objects 
dendrograms constructed bottomup form top level clusters entire dendrogram generated 
done dendrogram cut apart appropriate level produce desired number clusters 
dendrograms produced cut clusters different partitionings produced 
representative dendrogram produced num tax shown fig 

fig 
dashed lines indicate dendrogram cut apart form clusters 
accompanying dendrogram logical descrip tion 
descriptions produced inductive learning program accepts input collection groups clusters objects generates simplest discriminant characterization group 
generated descriptions form single complex logical disjunction complexes 
fig 
shows dendrogram produced ieee tra pattern analysis intelligence vol 
pami 
july apple ii display color tv ram sk rum mp display color tv ram rom mp vic display tv ram rom mp display tv ram rom ik mp keys zenith hs built ram rom mp keys horizon display ram rom mp keys 
tr display tv ram rom mp keys ss fig 


hp display built ram rum mp hp keys ohio scl 
series display tv ram rom mp keys zenith bm iu ram rom mp keys ohio sci 
challenger display tv ram rom mp keys trs ii ia ram rom mp keys technique aab data product 
moment correlation weighted average linkage 
similar dendrograms obtained techniques abb aaa aba form dendrogram identical group similarity scores slightly dif ferent 
dendrogram cut parts clusters fl 
descriptions produced clusters shown fig 
arbitrary 
example cluster described ram 
keys description suggests cluster composed kinds computers ram 
keys raises question reason placing computers cluster 
tho dendrogram cut clusters clusters 
descriptions clusters involve entirely new variables type microprocessor type display ap pear arbitrary unrelated descriptions obtained cluster case 
results problem cluster principle clustering applied cluster objects arranged groups concisely circumscribed con statements optimized assumed global criterion clustering quality lef section iii 
program cluster data told different evaluation criteria 
lef specified criterion maximize disjointness clusters tolerance maximize com tolerance 
clustering obtained lef shown fig 

second lef specified criterion maximize fit clustering events tolerance maximize simplicity cluster descriptions tolerance 
number clusters form determined automatically parameter level hierarchy sec ond level 
clustering obtained lef shown fig 

third lef specified criterion second lef parameter hierarchy levels 
clustering obtained lef shown fig 

logical statements produced cluster conjunctive may quite long 
shortened previously mentioned program done michalski stepp fed construction classifications similarity wa cut indicated form tl clusters cluster descriptions generated program aq ah iram keys ram kill dl imp hp ik imp oc bp rom lk sk built imp hp rom lk sk built fig dendrogram produced experiment clustering techniques aba hpi rom di play ta ke sx challenger fig classification microcomputers generated cluster number clusters levels clustering quality lef maximize obtain descriptions clusters produced 
way simplify descriptions define categories variables common variables take value clus ter discriminant variables take different values clusters 
simplify descriptions common variables removed 
clustering fig level hierarchy 
structure obtained imposing binary branching level tree 
arbitrary choice useful hierarchical structure obtained compared den produced conventional numerical taxonomy techniques 
hierarchies produced cluster constrained manner 

fl level fi second level vic om ki ohio sci 
lk display bo keys 
rom ilk ask ke mk fig 
classifications microcomputers generated cluster automatic determination lhe clusters cluster ing quality criterion lef fit simplicity pa shown transactions pattern analysis intelligence 
vol 
pami july program cluster find conceptual clustering predetermined hierarchical form find optimized structure automatically determining number clusters level 
level hierarchy shown fig 
clus ter split microcomputers clusters type microprocessor 
choice variables conceptually differentiate clusters 
ing clustering lef 
case cluster composed microcomputers utilizing form microprocessor denoted generalized value includes 
cluster contains microcomputers utilizing microprocessor belong family 
second level hierarchy cluster partitioned mp cluster microcomputer display type 
level cluster part variables microprocessor type amount rom memory display type number keys keyboard 
conceptual difference hp systems stands clearly 
clustering shown fig 
cluster de optimized number clusters form level hierarchy 
number determined finding clustering lowest value sparseness fi 
large value causes program demand great improvement fit incremental increase reasonable practice larger values top hierarchy smaller values nearer tips hierarchy 
second level evaluated 
level cluster contains events limit reasonable values sec ond level events second level cluster average 
optimized number clusters part hierarchy level 
second level clusters mp branch hierarchy program determined ranges num bers keys 

fit data 
cluster uses closing interval generalization form interval values linearly ordered variables 
step name interval values produced 
example names low range middle range highest applied intervals express magnitude number keys keyboards microcomputers 
clustering hierarchy shown fig 
contains levels 
level cluster split groups finding value criterion sparseness minimal 
criterion selects level clusters level clusters 
value determine optimized value second level cluster 
ings level node 
values second level clusterings level clusters contain event 
third cluster contains event 
hierarchy shown fig 
reveals underlying con ceptual structure collection microcomputers 
aided ata plant local variables condition leaves sm af ze cke ioe color fig 

multivalued variables describe eases soybean disease 
background knowledge represented structure domain variable mp cluster microprocessor types hp important classifying microcomputers 
categories generalized values microprocessor type cover families respectively 
level mp cluster subdivided clusters take different values variables display type number keys 
variables sufficient discriminate clusters level clustering discrimination index 
clusters stemming mp cluster variables discriminate clusters pair variables display keys pair display rom taken sufficient provide complete discrimination 
hierarchical clustering clearly reveals unique nature hp microcomputer 
values variables mp keys rom unique 
dendrograms generated produced techniques baa bba bab bbb yielded partitioning data clusters conceptually appealing 
numerical taxonomy techniques produce dendrograms predicted ad vance 
indicated experiments involving sets data 
example numerical taxonomy tech 
niques led clusterings simple conceptual descriptions failed produce simple descriptions problem michalski stepp diday 
important result revealed study measure numerical similarity consis leads dendrograms having simple conceptual 

contrast conceptual clustering generates clusters simple conceptual interpretations cases 
exemplary problem ii 
reconstructing classification soybean diseases problem reconstruct classification selected soybean diseases 
cases soybean diseases characterized multivalued variables shown fig 

michalski stepp automated construc ion classifications sta ce ss 
os vt 
di denotes hc jth eec fig 

dendrogram cases soybean diseases linkage euclidean distance en formed dat 
di di di di 
di di di di ds 
ds io iy di cases drawn populations population representing soybean diseases di stem root rot rot rot 
ideally clustering method partition cases groups corresponding diseases 
test applied program cluster numerical taxonomy techniques example cluster cases 
results problem fig 
shows typical dendrogram produced program dendrograms obtained technique see dendrogram separates correctly cases diseases cases diseases somewhat intermixed 
fig 
cluster marked contains cases diseases 
obtained dendrograms cba cbb cca ccb involving standardized data product moment correlation simple matching scores average weighted average linkage precisely reconstructed correct classifica tion cases 
output pro vide description clusters formed 
results problem cluster program cluster applied problem maximizing fit evaluation criterion lef 
cluster partitioned disease cases disease categories described clusters terms characteristics symptoms ieee ons pattern analysis machine intelligence vol 
pami 
july range determined ltl occurrence july october decay firm dry sh zth ding mg absent range determined plant normal oe norma normal second node brown normal august september sever years expert fig 

description cluster disease stem obtained cluster variables having values left column described plant variables having values column 
fig 

discriminant characteristics soybean disease cases produced cluster 
disease expressed form conjunctive statement produced disease categories corresponded exactly actual soybean diseases descriptions produced cluster agreed symptoms indicated plant diseases 
fig 
presents complete complex cluster disease category 
middle column contains values variables cluster describe cluster 
right hand column fig 
presents values variables expert plant describe disease diagnosis 
description disease determined cluster contains symptoms disease specified plant values time occurrence precipitation lesion color determined cluster supersets values mentioned plant 
description produced cluster involves variables plant mention 
fig 
shows table number sparseness parameter cpu time clusters tom cyber see fig 

summary evaluation criterion scores soybean disease clusterings 
values discriminant variables cluster derived descriptions produced cluster 
measure total sparseness solution judge best number clusters form 
data clustering soybean disease cases summarized fig 

increases sparseness decreases data events partitioned smaller complexes fit data better 
hand increasing undesirable raises complexity clustering 
measure reflects tradeoff sparseness parameter balances influence versus sparseness 
fig 
shows values parameter 
experiment strong correlation cpu time parameter fact may indicate algorithm operates efficiently number clusters formed agrees natural organization data 
clusterings obtained cluster depend components assumed criterion clustering quality 
possibly argue equivalent obtain ing different clusterings different methods 
ing object similarity 
important dif ferences regard conjunctive conceptual clustering method traditional methods 
difference conceptual clustering provides data analyst simple conceptual description gen erated clusters 
consequently easy experiment choice clustering quality criterion determine clusterings suitable problem tion 
second difference clustering quality criterion measure similarity clear simple relationship clusters generated components represent elementary criteria fit clusters data simplicity cluster descriptions summary method conjunctive conceptual clustering analyzed compared number clustering techniques numerical taxonomy 
major difference method numerical taxonomy methods performs clustering basis mathematical measure object similarity basis concept membership 
specifically clusters groups objects characterized simple fitted conjunctive descriptions 
collection cluster descriptions optimizes predefined global clustering quality criterion 
experiments performed far shown method produces clusters tend match solutions satisfactory people 
experi ments numerical taxonomy methods resulted clusters stepp automated construction cations satisfactory regard 
numerical taxonomy methods produced clusters majority cases arbitrary inadequate viewpoint human interpretation 
explained noting numerical taxonomy program equipped knowledge human conjunctive concepts concepts knowingly produce clusters corresponding concepts 
viewpoint traditional clustering methods conceptual interpreted approach uses certain measure object similarity quite different kind 
new kind similarity measure takes consideration distance objects conventional clustering methods relationship objects importantly relationship predetermined concepts conjunctive descriptions 
price concept dependent similarity measure significantly greater computational complexity method consequently run time clustering program 
example dendrogram produced implemented fortran example required ms processor time cyber clusterings produced cluster implemented pascal example required processor time 
comparison totally appropriate produces clusters cluster produced clusters descriptions 
greater computational complexity necessarily significant disadvantage method 
clusterings obtained useful practical computational cost little relevance especially prices computer technology declining 
experience shows researchers presently available clustering techniques concerned amount computational time expended difficulty interpreting results analysis 
important characteristic method limitation advantage depending problem hand specifically oriented clustering problems nominal ordinal variables 
noted method handle types variables properly quantized 
major current limitation method conjunctive clustering traditional methods clusters objects variables defined input data 
limitation overcome process constructive induction incorporates cluster descriptions new variables derived certain functions initial ones 
method conjunctive conceptual clustering adds new dimension research cluster analysis potential useful new toot researchers analyzing data 
acknowledgment authors wish prof department genetics university illinois providing numerical taxonomy program comparative analysis clustering methods 
anderberg cluster analysis applications 
new york academic 
diday simon clustering analysis communication cybernetics vol 

new york springer verlag pp 

diday sidi clustering pattern recognition proc 
th nt 
conf 
pattern miami beach fl dec pp 

michalski variable valued logic system proc 
int 
syrup 
multiple valued logic west univ wv may pp 

variable valued logic applications pattern recognition machine learning multiple valued logic com puter science ed 
amsterdam north holland pp 

pattern recognition rule guided inductive inference ieee trans 
pattern anal 
machine vol 
pami pp 

knowledge acquisition conceptual clustering theoretical algorithm partitioning data conjunctive concepts special issue knowledge acquisition induction lnt 
policy anal 
inform 
syst vol 
pp 

theory methodology inductive learning machine learning 
intelligence approach michalski carbonell mitchell eds 
palo alto ca tioga 
michalski learning told learning examples experimental comparison methods knowledge acquisition context developing expert system soybean disease diagnosis int 
policy anal 
inform 
syst vol 
pp 

michalski larson selection representative training examples incremental generation vl hypothesis underlying methodology description programs dep 
cornput 
sci univ illinois urbana rep 
michalski stepp revealing conceptual structure data inductive inference machine intelligence vol 
hayes michie 
pao eds 
chichester ellis new york 
application ai techniques structuring objects optimal conceptual hierarchy 
th int 
joint conf 
artificial intell vancouver canada aug pp 

michalski stepp diday advance data analysis clustering objects classes characterized conjunctive concepts invited chapter progress pattern recog nition vol 
kanal eds pp 

nilsson principles artificial intelligence 
palo alto ca tioga 
sokal principles numerical taxonomy 
san francisco ca freeman 
learning negative examples variable valued logic characterizations inductive program aq uni dep 
cornput 
sci univ illinois urbana rep july 
description user guide cluster prog am conceptual clustering dep 
cornput 
sci univ illinois urbana rep uiucdcs 
watanabe knowing guessing 
study inference information 
new york wiley 
winston artificial intelligence 
reading ma addison wesley 
algorithms pattern rec tion package applied programs proc 
th int 
conf 
pattern recognition kyoto japan 
michalski horn poland may 
studied warsaw technical universities received sc 
degree institute ph degree university 
associated institute auto ieee transactions pattern analysis machine intelligence vol 
pami matte control polish academy sciences warsaw worked research scientist subsequently leader pattern recognition group 
joined university illinois urbanachampaign computer science medical information science 
research interests include inductive learning expert systems databases plausible reasoning conceptual data analysis applications artificial intelligence medicine agriculture 
published research technical papers related subjects book machine learning 
appointed associate center advanced study university illinois 
robert stepp born lincoln ne 
april 
received sc 
degrees university respectively 
expecting ph degree university illinois urbanachampaign 
manager systems programming uni versity nebraska lincoln 
instructor computer science university illinois 
currently visiting research associate department computer science university illinois 
research interests include inductive learning expert systems conceptual data analysis computerized aids handicapped 
