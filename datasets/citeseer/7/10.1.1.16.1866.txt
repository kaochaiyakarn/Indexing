human oriented tracking human robot interaction christian terrence fong charles baur swiss federal institute technology epfl lausanne switzerland christian charles baur epfl ch robotics institute carnegie mellon university terry cs cmu edu order human robot interaction effective real world environments needs natural transparent 
achieve need facilitate direct proximal communication humans robots 
approach computer vision enable robots observe react human activity 
describe development real time computationally efficient vision modules human tracking human identification static gesture recognition 

robots continue play increasing role world working cooperation humans 
simple industrial tasks performed past robots called assist wide range activities health care office immediate proximity humans 
central success applications close effective interaction humans robots 
important continue enhancing autonomous capabilities neglect improving human robot relationship 
particular need develop techniques allow humans robots interact naturally effectively transparently 
objective develop computer vision methods facilitate proximal human robot interaction 
specifically want enable humans communicate directly robots movement gesture unencumbered user interface 
time want provide robots capability observe react human activity respond quickly appropriate way 
sections color stereo vision techniques human tracking human identification static gesture recognition 
designed techniques computationally efficient operate real time low power low cost processing hardware 

related great deal performed field human tracking particularly video surveillance applications 
methods rely static cameras permit background subtraction template matching 
approach combination camera geometry stereo vision color indexing detect localize humans 
gesture recognition widely studied means computer input robot control 
previous developed remote driving interface visual gesturing 
system color filtering stereo vision track classify hand motions remote driving 
described similar recognize static gestures order reduce processing requirements 
researchers begun investigating vision human robot interaction particularly regard detecting human head pose recognizing repeating motions cyclical hand gestures 
difference systems combine color stereo vision achieve better tracking identification 

approach architecture system architecture shown 
capture sub sampled images pair color ccd cameras perform color processing normalized color filtering histogramming area stereo correlation compute disparity map 
data primary system modules perform human tracking color identification static gesture recognition 
collectively modules enable single user interact mobile robot movement hand gestures 
human tracking 
locates humans stereo vision 
researchers emphasized skin color filtering human tracking prefer stereo largely invariant changes color background illumination 
employ color identification described guarantee person tracked time 
human identification 
research chosen focus single human single robot interaction 
multiple people scene need distinguish 
module color indexing 
method works computing dimensional color histogram image region contains greatest separation detected human background 
gesture recognition 
recognizes pre defined set static gestures 
discrete set postures simple geometrical model includes position user hands relative head 
sensor fusion depth color information order extract head hand pose robust manner 
output control robot motion activate behavior 
hardware system architecture mobile robot 
pioneer mobile robot 
pioneer steered capable traversing moderately rough natural terrain 
pioneer hardware microcontroller pentium computing wireless ethernet variety sensors sonar drive encoders differential gps magnetometer cameras 
pioneer camera mast imaging system 
pacific csc color ccd cameras mounted mast 
cameras equipped wide angle lenses deg connected 
capture process subsampled images pixels hz sri small vision system compute disparity maps 
guarantee robot locate humans wide area easily view head hands employ tilted camera configuration see 
geometry allows operate quickly needs search portion horizontal band image detect humans 
camera geometry primary disadvantage system distant objects tend appear captured images 
small images track nearby objects head hands size vary greatly distortion pose significant problems tracking 
perform correction computing disparity maps order obtain accurate depth information 

human tracking human tracking system stereo vision 
stereo offers advantages capable detecting partially occluded objects provides real world information object size pose velocity fairly immune effects shadow varying illumination camera dynamics 
stereo vision limitations 
stereo tracking human specific non human objects 
furthermore close objects may seen single object 
depth measurement non linear localization accuracy vary 
slice extraction address problems stereo tracker processes image data number steps 
disparity map computed stereo pair compute disparity histogram 
histogram typically contain number peaks call slices corresponding objects scene 
characterize slice terms peak height area width gradient 
area smaller threshold slice considered noise ignored 
slice lowest disparity furthest range taken background 
values threshold ignored 
slice highest disparity represents correlation error discarded 
disparity histogram slice extraction image noise common large number slices extracted 
initial segmentation perform additional processing connect close slices 
heuristic slice separation works 
segmentation slice extracted compute binary image perform segmentation recursive connected compound labeling algorithm 
output stage list objects blobs contains information object image plane distribution position 
area filtering algorithm remove image artifacts disconnected regions caused insufficient image texture stray pixels caused noise 
blobs close connected single blob 
segmentation object extraction combining histogram processing segmentation able partition scene layers background guaranteed contain object 
segmentation determine objects humans applying simple heuristics physical dimensions geometric constraints 
schema object extraction working layer characterize object terms pixel distribution disparity world coordinates 
perform final global scan overlapping objects 
objects overlap merge performed 
world coordinates greatly helps improve filter coherency robustness 
system uses pixel operations filtering performed slice peak blob object spaces 
human tracker fast achieving hz horizontal band processing mhz pentium hardware acceleration 

human identification module distinguishes different individuals color indexing 
color indexing proven efficient robust method detecting identifying colored objects 
implementation color histograms translation invariant vary slowly changing view angle scale occlusion 
normalized color histogram person detected compute histograms image region centered person mid section 
reduce effect varying illumination computation performed normalized colors red green 
additionally histogram normalized scale facilitate comparison 
normalized color histograms contains images person corresponding normalized green histograms 
images show person different scales different illumination observe histograms similar shape 
indicates able obtain positive match 
histogram intersection particular person match compare histograms intersection 
consider histogram function intersection interpreted minimum value point functions 
compute intersection simply select pixels color histograms 
obtain confidence value match complete correspondence normalize intersection number pixels template model histogram 
practice compute confidence values normalized color histograms calculate total match confidence averaging values 

gesture recognition locates head hand position skin color filtering 
compares relative positions set pre defined static gestures 
shows geometric model small set gestures robot motion control 
left human geometrical model right possible postures 
activated human stands front robot short period 
occurs searches human head position 
begins search horizontal body position returned 
tracks lower part body assume head located region vertical region 
designed look color blobs fall pre defined skin color locus 
fairly large skin color matching locus normalized red normalized green plane 
initial search fails blob horizontal body position search area widened entire image 
case largest skin colored blob taken head 
head position known looks person hands assumed located left right head 
head detection perform skin color search 
perform consistency checks verify head hand relationship distance angle physically possible 

results human tracking performance human tracker strongly correlated number parameters 
effectiveness slice extraction dependent experimentally determined thresholds area gradient separation 
segmentation phases trade resolution precisely object localized accuracy object segmented objects 
results tracking experiment 
shows tracker correctly distinguishes subjects separated partial occlusion overlap 
tracker performs subjects adjacent distance camera slice 
gesture recognition people tracking conservatively 
explicitly designed minimize false positive matches avoid inadvertently triggering incorrect action 
result users report gesture recognition responds slowly excessively precise hand positioning required 
shows gesture recognition results 
images module correctly identifies static gestures 
image gesture hand detected due saturation effects strong background illumination 
indicates skin color filtering inadequate robust gesture recognition 
better approach sophisticated tracking method combining color stereo 
gesture recognition human identification testing color histogram method works distinguishing multiple individuals 
top left image individual tracked highlighted rectangle 
top right bottom left images show second person entering scene approaching robot 
bottom right image contains people scene 
cases module successfully identifies correct person 
human identification lightning conditions may impact performance indexing normalized colors 
example identification accuracy match confidence generally better strong illumination muted dim lighting 
color differences particularly dark clothing background apparent lit scene 
additionally factors varying illumination shadows may influence performance color shifts 
current system compensate problems periodically updating color model histogram 

discussion principal challenge vision interaction designing algorithms robust dynamic environments 
scene characteristics background illumination may change significantly rapidly important rely single method perception 
example color filtering fast efficient delivers poor results strong moving shadows 
chosen combination color filtering color indexing stereo vision 
limited processing power possible design effective human oriented tracking algorithms 
key feature system minimizes computation advantage camera geometry histogramming advantage complementary perception color indexing assist stereo tracking 
module executes quickly system performs crowded changing environments 

ways current system improved 
achieved results small images high resolution images allow precise segmentation performed 
second area stereo correlation noisy 
sophisticated stereo algorithm incorporates global matching criterion color segmentation aid detection localization 
adding additional sensors infrared camera distinguish humans inert objects improve system robustness 
date obtained anecdotal evidence computer vision methods facilitate human robot interaction 
reasonable assume direct proximal communication desirable productive believe important obtain quantitative proof 
natural extension conduct formal user study study interpretation gestures movement improves hinders system usability 

acknowledgments bjorn contributions particularly implementing color indexing routines 
roland providing project administration epfl institut de production research hardware 

beymer konolige real time tracking multiple people continuous detection iccv 
fong advanced interfaces vehicle teleoperation collaborative control sensor fusion displays remote driving tools auton 
robots july 
localization approaching human mobile home robot ieee ro man 
legged mobile robot control observe human behavior ieee ro man 
konolige small vision systems hardware implementation th 
kortenkamp recognizing interpreting gestures mobile robot aaai 
skin locus cope changing illumination conditions color face tracking ieee 
swain ballard color indexing international journal computer vision 
robust tracking people mobile robotic agent git gvu georgia tech university 
triesch von der malsburg gesture interface human robot interaction face gesture 
neural network approach recognition pose motion gestures mobile robot th brazilian symp 
neural networks 
xu robot guidance hand gestures monocular vision ieee hong kong symposium robotics control 
