clustering boost text classification fang parthasarathy schwartz ohio state university contact srini cis ohio state edu years seen tremendous growth number text document collections available internet 
automatic text categorization process assigning unseen documents user defined categories important task help organization querying collections 
article consider problem classifying online papers specific journal geological sciences set expert defined categories 
evaluate general strategies variants thereof 
strategy na bayes popular text classification algorithm 
second strategy principle direction divisive partitioning unsupervised document clustering algorithm 
performance approaches quite new variants propose including involves combination approaches yield better results 

years amount online text data grown tremendously due popularity internet world wide web 
result overriding need provide effective content text retrieval search querying capabilities 
consider problem automatic text categorization means rapidly enable retrieval querying capabilities large scale 
automated text categorization supervised learning task involving assigning category labels pre defined new documents information learned labeled training data :10.1.1.11.6124
labeled training data involves manual categorization data subject experts 
large number learning approaches brought bear problem domain including statistical methods bayesian learning decision trees neural networks support vector machines 
evaluate performance methods automatic categorization articles published international journal geological sciences 
method consider na bayes method popular categorization method 
surprisingly observe domain expert addition labeling duties provides list keywords associated weighting performance algorithm greatly enhanced 
second method consider principle direction divisive partitioning unsupervised text clustering approach principal components analysis 
basically approach cluster labeled unlabeled data labeled documents cluster determine labels unlabeled documents 
consider new variants methods including combines 
hybrid approach involves keywords weights associated relatively pure clusters generated pddp seed na bayes classifier described 
evaluate performance methods variants papers considered mixture categories 
rest article organized follows 
sections describe na bayes pddp algorithms respectively 
section describe different classifiers evaluated experimental results 
section discuss results obtained additional features visualization 
outline directions section 

na bayes classifier basic idea na bayes methods joint probabilities words categories estimate probabilities categories document 
na aspect method fact dependencies words ignored conditional probability word category assumed independent conditional probabilities words category 
assumption necessary efficiency reasons 
describe approach formally notation 
assume text document described conjunction english words ai contains 
vj set user defined categories 
set labeled training documents category provided classifier 
training phase described new document described tuple words learner asked predict category new document 
bayesian approach classifying new document assign probable category fits vmap maximum posteriori map hypothesis words contained document 
vmap argmax vj bayes theorem rewrite expression vmap argmax vj vj estimating different vj terms fashion feasible exceptionally large set training data 
problem number terms equal number possible documents times number possible categories 
need see document training set times order obtain reliable estimates 
na bayes classifier simplifying assumption contained words conditionally independent category 
assumption reduces equation equation 
argmax vj ai vj denotes probability output na bayes classifier 
notice na bayes classifier number distinct ai vj terms estimated training data just number distinct words times number distinct categories smaller number estimate vj terms contemplated 
na bayes assumption conditional independence satisfied na bayes classification identical map classification vmap obtained equation 
assumption met case learning classify text na bayes classifier quite effective 
completing design learning algorithm requires choosing method estimating probability ai vj terms 
adopt estimate uniform priors equal size word vocabulary 
estimate ai vj nk vocabulary total number word positions training examples category vj nk number times word ai word positions vocabulary total number distinct words tokens training data 
adopt implementation algorithm proposed 
addition base implementation implement variant allows embed domain specific knowledge classifier 
domain knowledge embedded terms keywords associated particular category weights associated keyword 
essentially pre classified papers training data build collections words different weights domain expert experience data 
note na bayes classifier needs training papers topic classify unknown 
classifier dependent quality papers training set 
entire train classifier bag words deemed important expert classifier affected noise effects 

pddp principal direction divisive partitioning pddp unsupervised technique clusters related documents 
constructs binary tree node data structure holding documents associated node various quantities computed set documents pointers children nodes 
information stored node consists documents cluster associated node centroid mean vector leading singular value associated singular vector pointers children nodes 
scatter value stored node discussed 
pddp tree starts root cluster representing documents 
algorithm recursively splits leaf cluster children criterion satisfied 
document represented vector word counts 
vector scaled ensure values independent document length 
vectors documents clustered assembled term frequency matrix dm 
term frequency matrix mean vector centroid obtain principle direction hyper plane partition split documents node partitions 
decide stage node split choice try keep binary tree balanced splitting nodes level proceeding level 
doing resulting clusters imbalanced large clusters small clusters singletons 
pddp uses notion scatter determine best node split 
scatter value simply measure cohesive documents cluster 
execution time algorithm depends size term frequency matrix 
na bayes approach implemented variant base pddp algorithm distinct words documents build term frequency matrix limit words set words chosen domain experts problem hand 
variant reduces execution time algorithm significantly size term frequency matrix reduced significantly affecting quality results obtained shall see section 

experiments results data key journal water sciences called water resources research 
evaluated articles years 
basically major categories water sciences research precipitation groundwater river lake ocean articles articles involve mixture research topics 
stated training set papers roughly equal number category testing set papers evaluate classifier performance 
papers testing set domain experts identified papers hard classify borne classification results 
report classification accuracies entire test dataset hard subset test papers 
evaluated classifiers 
nb na bayes classifier served baseline evaluate nb variants 
classical approach uses training set documents evaluates classifier independent testing set 
performance classifier bad accuracy papers accuracy hard set correctly classified 

nb na bayes experts chosen keywords weighting second classifier evaluated variant described section 
sending pre labeled chosen papers training set experts chosen keywords associated weights seed classifier see 
experiment memory needed storing vocabularies words running time smaller efficient training papers pre labeled training papers created words 
accuracy classifier accuracy hard subset 

nb na bayes experts chosen keywords weights essentially nb weight assigned word 
primary purpose evaluating classifier quantify extra benefit weighting evaluate importance context nb approaches results showed accuracy baseline nb accuracy hard subset dropped nb papers testing set 
result underscores importance weighting classification performance 
groundwater saturated head heads storage net table line subsurface recharge discharge confining confined bed groundwater saturated head heads storage net table line subsurface recharge discharge confining confined bed 
bag words groundwater category selected experts 
weights assigned left weights right 
nb na bayes experts chosen keywords distribution weighting variant distribution expert provided keywords various categories determine weights words 
variant motivated fact words precipitation modeling relevant category largely different frequency distributions different categories 
frequency occurrence depend contextual interpretation words 
instance precipitation meaning rainfall precipitation category having chemical connotation groundwater category greater frequency occurrence precipitation category compared groundwater category 
marginal improvement classification accuracy evaluated hard subset increased nb papers testing set 

pddp experts chosen keywords experts chosen keywords build term frequency matrix 
pddp tree built term frequency matrix 
mentioned earlier storage requirements execution time algorithm storage requirements execution time algorithm words training set 
essentially clustering algorithm grouped test training data grew pddp tree 
compute classification accuracy leaf cluster looked labeled documents cluster classified documents cluster dominant class label 
accuracy algorithm compares best nb approaches 
interesting fact accuracy hard subset significantly better accuracy reported nb approaches 
generated tree viewed fang tree html 

pddp words training set testing set papers experiment words collected training set pre labeled documents words order build matrix 
seen leaf nodes results different pddp papers clustered pddp clustered pddp 
variant supervision required word selection 
accuracy algorithm best classifiers evaluated 
pddp accuracy hard subset significantly better accuracy reported nb approaches 
generated tree viewed fang tree html 
nb na bayes pddp words weighting experiment wanted evaluate improve performance na bayes bootstrapping information derived running pddp training data 
basically distinctive words chosen principal direction vectors pure nodes pddp tree generated training data 
pure node dominated categories 
weights assigned distinctive words relative frequencies calculated pddp 
bags collected words pddp tree associated weights embedded information na bayes classifier nb 
performance classifier clear improvement baseline nb 
accuracy hard subset improvement nb 
classifier slightly worse compared nb remember supervision required terms providing keywords weights associated categories 
experiment highlights fact integrating pddp nb boosts performance additional supervision required 
training words nb nb nb nb nb training set papers expert words weights expert words weights expert words dist weight pddp words weights accuracy testing set papers papers papers papers papers perform 
table 
summary na bayes classifiers 
pddp pddp words expert words words training set documents papers papers term freq matrix accuracy perform 
table 
summary pddp tree experiments 

discussion tables summarize results previous section 
results previous section training testing set results cross validated 
na bayes variants nb nb performed best 
clearly embed necessary domain knowledge keywords associated weights classification performance improves 
note results performance nb showed just identifying keywords associated weights crucial performance gain 
crucial advantage nb nb nb classifiers space time efficient build 
drawback nb nb extra supervision required identify keywords associated weights 
domain knowledge unavailable difficult quantify characterize best option nb requires additional supervision compared nb 
nb combines best worlds efficiency nb nb closely approximates accuracy nb nb require supervision nb 
pddp tree experiments evaluated impact keywords suggested domain expert generate word frequency matrix 
compared baseline approach words collected root documents 
case running time storage requirements reduced due size word frequency matrix 
execution times significantly lower performance classifier accuracy lower reduced word set 
classifiers evaluated classification accuracy pddp best 
sensitive crucial issue scalability 
papers added problem domain classification efficiency pddp methods going deteriorate rapidly nb methods true nb pddp applied training data 
problem pddp methods current form running experiment classify re run algorithm scratch 
course may able modify pddp algorithm identify hyper plane partition belongs able classify 
require modifications existing pddp implementation 
limitations nb preferred compared pddp approaches large scale text categorization problems 
screen shot node tree pddp 
color highlight pure nodes 
training set pre labeled pddp tree generated html format added coloring scheme labeled data better visualize evaluate performance tree 
different colors different categories 
viewing resulting pddp tree immediately identify cohesive pure nodes uniformity color labeled data 
evaluated performance classifiers papers considered involve mixture research areas 
combined topic papers selected evaluated 
nb classifiers basically identified categories identify mixture probabilities second infinitesimal 
pddp results slightly better sense mixture papers categorized nodes involve papers categories 
notion mixture hard capture pddp context 
certainly area needs investigation 
part ongoing currently carrying scalability measurements fully characterize understand various tradeoffs different methods 
plan incorporate results version document 
interested exploring text categorization methods domain 
addition plan explore impact word associations moving away na bayes assumption association rule mining classifier performance 
interesting avenue research may consider semantic information say wordnet improve classifier performance 
yang 
evaluation statistical approaches text categorization 
journal information retrieval 
tzeras hartman 
automatic indexing bayesian inference networks 
proc th ann int acm sigir conference research development information retrieval sigir pages 
apte damerau weiss 
text mining decision rules decision trees 
proceedings conference automated learning discovery workshop learning text web 
lewis ringuette 
comparison learning algorithms text categorization 
proceedings third annual symposium document analysis information retrieval sdair 
thorsten joachims 
text categorization support vector machines learning relevant features 
european conference machine learning ecml pages berlin 
springer 
tom mitchell 
machine learning 
mcgraw hill 
domingos pazzani 
independence conditions optimality simple bayesian classifier 
proceedings th international conference machine learning pp 

cestnik 
estimating probabilities crucial task machine learning 
proceedings ninth european conference artificial intelligence pp 

london pitman 
mccallum 
bow toolkit statistical language modeling text retrieval classification clustering 
www cs cmu edu mccallum bow 

moulinier 
learning bias issue text categorization problem 
technical report lip universite paris vi 
koller sahami 
hierarchically classifying documents words 
fourteenth international conference machine learning icml pages 
mccallum 
comparison event models naive bayes text classification 
aaai workshop learning text categorization 
douglas baker andrew mccallum 
distributional clustering words text categorization 
proceedings th ann int acm sigir conference research development information retrieval sigir pages 
fuhr lustig tzeras 
air rulebased multistage indexing systems large subject fields 
editor proceedings 
wiener pedersen weigend 
neural network approach topic spotting 
proceedings fourth annual symposium document analysis information retriever sdair pages nevada las vegas 
university nevada las vegas 
ng gob low 
feature selection perceptron learning usability case study text categorization 
th ann int acm sig conference research development information retrieval sigir pages 
salton 
automatic text processing transformation analysis retrieval information computer 
addison wesley 
yang pederson 
comparative study feature selection text categorization 
proc 
fourteenth international conference machine learning 
principal direction divisive partitioning boley data mining knowledge discovery 
unsupervised clustering fast scalable method large datasets boley borst mn cse report tr 
informal methods 
partitioning clustering web document categorization boley gini gross han hastings karypis kumar mobasher moore decision support systems 
agrawal srikant fast algorithms mining association rules proc 
th int conference large databases santiago chile sept 
