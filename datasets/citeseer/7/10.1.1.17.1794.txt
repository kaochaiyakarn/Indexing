spikes bumps artefacts generated independent component analysis insufficient sample size jaakko ricardo helsinki university technology laboratory computer information science box fin espoo finland hyvarinen jaakko ricardo hut 
www 
cs 
hut 
proj ects ica point independent component analysis blind source separation performed high dimensions insufficient sample size may lead generation source signals due learning overfitting 
source sig practically zero expect point single spike bump 
existence strong time correlations data increases probability occurence artefacts 
results essentially independent particular algorithm ica 

component analysis ica statis tical model observed data expressed linear transformation source signals independent components nongaussian mutually inde pendent 
may express model vector observed random variables sn vector independent components unknown constant matrix called mixing matrix 
exact conditions identifiability model 
methods estimation ica model proposed literature :10.1.1.131.165
performance algorithms usually analyzed terms consistency classical finite sample prop erties asymptotic mse robustness 
purpose point case insufficient sample sizes ordinary ica methods tend produce results characterized estimates source signals independent components single spike bump practically zero 
criteria ica algorithms interpreted measures space source signals unit variance possibly frequency content usually maximized spike bump signals 
form overlearning overfitting typical ica methods 
overlearning reduced appropriate dimension reduction 

spikes sparsity maximizing signals phenomenon consideration easily comprehensible consider extreme case sample size equals dimension data equal number independent components collect realizations columns matrix denote corresponding matrix realizations 
form 
note matrices square 
means changing values give val ues whatsoever elements case se overlearning classical case regression equal numbers data points parameters 
clear estimate obtained ica estimation depends little observed data 
example assume constrain estimates source signals uncorrelated unit vari ance assume densities source signals known supergaussian positively :10.1.1.131.165
constrained ml estimation consists finding wn maximizes measure estimates source signals 
example laplace distributions obtain argmax 
constrained give uncorrelated source signals unit variance 
easy prove minimized gives permutation sign change matrix source signals zero points points overlapping 
unconstrained maximum likelihood estimation constraint replaced penalty term form log means maxi slightly different characterized spiky source signals 
shown ica estimation insufficient sample size leads form overlearning gives source signals 
source signals characterized large spikes 
important fact shown experiments section similar phenomenon occur source signals time strong time dependencies 
cases sample size needed get rid overlearning larger source signals better characterized bumps low pass filtered versions spikes 
intuitive way explaining phenomenon consider signal constant blocks consecutive sample points 
means data con sidered having really sample points sample point simply repeated times 
case overlearning estimation procedure gives spikes width time points bumps 
cases overlearning reduced appropriate dimension reduction example prin component analysis pca 
projections contain noise unnecessary information omitted preprocessing step data length dimension ratio improved estimates may avoided 

experimental results sets experiments designed order illustrate results 
set shown fig 
generated signals illustrate basic phenomenon effects choice compression rate filtering 
second set experiments figs 
dealing real life medical applications 
experiments matlab code fixed point algorithm imple mented fastica package gradient descent algorithm maximum likelihood infomax estimation implemented package tony bell 
available world wide web 
results qualitatively similar packages 

artificial data positively signals sample points simulations depicted fig 

noisy mixtures produced normally distributed noise added weighted mixture separately 
variance added noise variance signals 
example perfect ica decomposition fig 
shows result applying fixed point gradient descent algorithms mixed signals 
approaches preprocessing whitening stage included compression data principal components 
evident algorithms able extract initial signals 
whitening small dimen sion reduction took whitened vectors see appearance dirac solutions extreme case kurtosis maximization fig 

algorithm fastica type plot components extracted 
gradient descent symmetric type show representative solutions extracted 
presents intermediate stage compression original mixtures took whitened vectors 
clear desired independent components revealed methods resulting vector noisier ones showed 
final example fig 
low pass fil tered mixed signals prior independent component analysis tap delay ma filter 
amount compression see loose original sources decompositions show bumpy structure corresponding low pass dirac delta outputs 
low pass filtering reduced information contained data estimation rendered impossible weak compression rate 

eeg meg data earlier shown fastica suited artefact removal electro fast ica bell sejnowski illustration importance choice compression rate filtering artificially generated data fixed point algorithm fastica matlab package gradient descent algorithm matlab code tony bell 
original positively signals ica decomposition preprocessing includes compression principal components 
poor low compression rate situation 
decomposition intermediate compression rate components retained 
results low pass filtered mixtures ic ss independent components meg data 
component left back right views field patterns generated components shown full line stands magnetic flux coming head dotted line flux inwards 
study fig 
whitening stage compression 
independent component decomposition auditory evoked fields reasonable compression rate compression 
field patterns corresponding ica decomposition recordings eeg meg respectively 
addition study ica wave decomposition auditory evoked fields 
section see study affects results reported papers 
extraction artefacts meg data reported reasonable compression rate obtaining results reproduced fig 

field patterns regressions component original data seen columns estimated matrix 
patterns help interpreting localizing sources independent signals ic ic clearly represent activity different sets muscles right temporal area 
closer look field patterns bumpy sig ic ic confirms structure estimates corresponding field patters physiologically meaningful 
matter fact increase number solutions type reducing compression rate whitening stage 
example compression performed 
see couple artefacts solutions obtained meaningless bumps 
clear illustration dangers poor choice compression rate depicted fig 

fig ure shows decomposition auditory evoked fields independent components 
components see contra responses brain train auditory stimuli 
compression data resulting decomposition shown fig 

note picture shown correspond extreme case compression 
seen previous example coexistence solutions bumps possible intermediate compression condition 
may difficult distinguish independent components corresponding meaningful solutions estimates shown fig 


showed typical effect overlearning overfitting ica algorithms 
consists producing estimates source signals zero single spike bump 
reducing dimension data pca way reducing overlearning 
course best way avoid overlearning larger data set 
overlearning especially probable produce case strongly time dependent signals 
showed relevancy results separation eeg meg signals bumps may erroneously interpreted meaningful signals 

amari cichocki yang 
new learning algorithm blind source separation 
advances neural information processing systems pages 
mit press cambridge ma 
bell sejnowski 
information maximization approach blind separation blind deconvolution 
neural computation 

cardoso laheld 
equivariant adaptive source separation 
ieee trans 
signal processing 
comon 
independent component analysis new concept 
signal processing 

family fixed point algorithms independent component analysis 
proc 
ieee int 
conf 
acoustics speech signal processing icassp pages munich germany 
hyv rinen 
unit contrast functions independent component analysis statistical analysis 
neural networks signal processing vii proc 
ieee workshop neural networks signal processing pages amelia island florida 
hyv inen oja :10.1.1.131.165
fast fixed point algorithm independent component analysis 
neural computation 
jutten herault 
blind separation sources part adaptive algorithm neuromimetic architecture 
signal processing 
rio 
extraction ocular artifacts eeg independent component analysis 

clin 
neurophysiol 
rio im gd hart oja 
independent component analysis identification artifacts recordings 
advances neural information processing systems pages 
mit press 
rio rel oja 
independent component analysis wave decomposition auditory evoked fields 
proc 
int 
conf 
artificial neural networks icann pages sweden 

