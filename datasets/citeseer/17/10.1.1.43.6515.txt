design artificial neural networks genetic algorithms review prospect ibrahim chris thornton cognitive computing sciences university sussex brighton bn qn email ibrahim cogs susx ac uk christ cogs susx ac uk april design artificial neural networks genetic algorithm useful terms automating optimising design finding biologically plausible models 
presents review state art research prospects area 
keywords genetic algorithms artificial neural networks 
research involving sort combination genetic algorithms ga artificial neural networks forth anns networks short growing 
area review state art 
presents review research prospects designing anns ga design artificial neural networks ann gas helpful terms main issues 
automates design network done hand trial error 
second process design analogous biological process ann blueprints encoded chromosomes develop evolutionary process 
designing networks hand may complex 
design sufficient task trial error risk missing promising architecture eliminated 
complex combinations performance criteria learning speed compactness generalisation ability noise resistance difficult optimize network design 
problem designing ann specific problem involves searching space architectures perform best meeting requirements problem 
search space problem may infinitely large un differentiable complex noisy deceptive multi modal 
schema theorem developed holland proved useful applications involving large complex deceptive search spaces 
evolutionary process genetic search help automate improve optimize ann design required produce complex behaviors 
major issue genetic design anns representation encoding strategy able capture potentially useful designs task hand excluding flawed meaningless ones 
terms genetic search means representation schema allow new meaningful valid network structures particular learning rule applied produced genetic operators crossover mutation 
cases representation said closed genetic operators 
referred structural functional problem 
possible network parameters include number layers number units layer number feedback connections allowed degree connectivity layer learning rate error term utilized learning rule 
gas applied neural networks different ways employ fixed network structure number nodes connections fixed connection weights evolutionary control see example designing structure network 
concerned researches category 
researches category concentrate distinctive approaches direct encoding generative encoding 
case direct encoding strategies architecture network directly encoded chromosome representation 
case generative encoding strategies sort grammar generates network architectures 
sections start describing direct encoding methods concentrate studies sort grammar generating anns 
research uses evolutionary design anns tool pursuing primary research interest 
conclude discussion research directions area 
direct encoding methods early strategies genetic ann design classified degree developmental specification degree specificity employed mapping genotype phenotype 
design strategies called weak loose representation genetic blueprints translated developmental machinery network phenotype 
strategies producing large networks efficiently 
impose severe constraint network search space 
represent layer network single gene facilitating application genetic operators regular networks 
face difficulty encoding detailed connections 
design strategies called strong capturing patterns connections smaller networks efficiently represent connections directly chromosome 
genesis system weak representation genesis blueprint representation network structure encoded bit string 
composed segments 
segment turn contains area projections connections 
areas representation show input output areas respectively 
segment fixed length bits specify area parameters aps projection specification fields psfs describe connections areas 
unknown number areas projections marked strings parsed network architectures crossover operations easily produce meaningful strings 
aps contains fields describe address identification area size number units 
addition dimension share parameters determine spatial organisation units 
representation genesis assume simple fully connected network structure psfs may determine specific unit connection 
psfs identity target area coded absolute target id relative address position target area relative current area mode 
dimension parameters allow connections localised area 
degree connectivity percent learning rate parameter back propagation coded psfs 
point crossover modified allow identification points referring markers blueprint 
variable length representation modified crossover allow broader space network architectures searched 
result complex architectures 
design strategy solve different problems digit recognition xor problem 
cases genesis produced reasonable networks showed improvements initial random structures 
results suggests representation genesis inadequate 
attention representation connectivity needed 
example typical chromosome contains concatenation parameters describing number layers size layers layers interconnected 
due abstraction larger nets encoded small chromosomes 
true particular group networks 
method fail encode modular architectures defined repeated groups neurons 
system strong representation system layered feed forward network units represented connectivity constraint matrix dimensions nx 
values matrix specified column row indices specifies nature constraint connection unit 
constraints indicated zero learnable learnable limited positive values learnable limited negative values 
rows matrix successively concatenated form bit string representation network 
shows example constraint matrix representing unit network input single output unit 
column th matrix specifies threshold biases units 
representation clearly defines layers network translation genotype phenotype easily interpreted 
crossover operator applied design strategy involves selecting random row constraint matrix swapping entries row parents 
simplest safest way applying crossover operator row contains basic building block single unit crossover produces valid network structure 
mutation operator involves simply moving values matrix choosing new constraint specified probability 
fitness evaluation success learning input output mapping specified task 
possible fitness function include criteria ability generalise size network particular task 
order evaluate fitness particular network constraint matrix initialised learnable connection values 
learnable connections small random weights 
network trained specific target mapping back propagation algorithm 
training total sum squared error derive fitness 
design strategy applied different tasks xor quadrant units bias units bit string encoding xor problem strong representation taken 
problem 
results shown genetic design discover successful architectural solutions faster learning tasks hand 
limited encode fixed number neurons 
gives chromosome length network units 
number units gets large search space big 
weights encoded crossover operation may result non functional springs structural functional problem pointed 
generative strategies kitano grammar encoding method system developed kitano employs different approach encoding ann architectures 
uses graph generation grammar encode regular connectivity patterns shorter chromosomes 
basically involves encoding set rules generate ann 
kitano argues previous design strategies encode ann configurations directly chromosome require longer chromosome length larger search space 
size networks grows time takes converge near optimal configuration increase 
suitable designing large networks 
methods assume rigid correspondence connectivity patterns generic information 
creates substantial difficulty encoding network repeated patterns complex internal structure 
biologically plausible respect morphogenesis neural system 
design strategy kitano grammar generates family matrices size elements contained matrices characters finite alphabet 
larger matrix developed rewrite rules corresponding characters 
translated connectivity matrix describes structure ann 
kitano grammar encoding method different previous methods structure network directly encoded chromosome 
method uses set re write rules encoded chromosome generate networks 
graph system extension lindenmayer system 
shows generation typical xor network kitano graph generation system 
followings rules developing connectivity matrix xor network 
starting initial state graph developed rule matching aaaa connectivity matrix ab cd initial cycle cycle cycle xor network generation xor graph taken 
cycle 










example cycle start symbol re written relevant rule 
symbol right hand side rule relevant rule processed 
connectivity matrix developed shows existence connection units non existence connection 
typical chromosome representing network parts variable constant part 
constant part change contains set static rules re write symbols 
genetic algorithm applied variable part acquire rules selection process 
constant part involved recombination mutation processes length variable part constitutes chromosome length 
parts divided fragments 
fragment bits representing rule bit represents left hand side rule rest represent right hand side rule 
example rule ab 
cd rules represented follows order ensure cell division take place chromosomes contain initial state 
variable part contains symbol generating rules range constant part contains pre encoded re write rules symbols 
grammar encoding system tested xor encoding problems back propagation learning rule feed forward networks 
results experiments showed grammar encoding method converges faster direct encoding methods 
creates regular network connections direct encoding methods normally 
means grammar encoding system shows better scaling property ability generate complex networks 
biologically plausible connectivity information encoded chromosome flexible manner 
grammar encoding method abstraction rules repeatedly produce patterns connections different parts network kitano experiment involve developing recurrent network 
scalability kitano characterized ability ga find larger network parameterised problem larger size 
tested encoder decoder problem 
gruau argues typical case number hidden units larger number input output units 
suggests challenging solve problem number hidden units logarithm number input neurons suggests theoretical experimental property scalability 
clear grammar encoding express architecture 
gruau cellular encoding method gruau developed cellular encoding ce system similar grammar encoding re writing symbols re writes cells 
matrix development rules applied cells network 
cell contains copy chromosome 
chromosome consists alphanumeric symbols program symbols provides instructions kind actions take place process development 
instructions contained chromosome may interpreted differently different cells 
depending information cell receives divide change internal parameters neuron 
system initial graph single non terminal unit contains default program symbols chromosome 
instructions chromosome carried gives birth cells program symbols 
eventually cell neuron creating ann structure 
different kinds program symbols corresponding instructions 
example division program symbol create cells cell 
done parallel denoted sequentially denoted 
typical sequential division child inherits input links connects second child weight 
second child inherits output link 
parallel division children inherit input output links parent cell 
program symbol value program symbol modify structure connections 
plus minus signs set value weights respectively 
symbols pause re writing process denoted process denoted causing cells generated neurons 
strategy biologically plausible efficient matrices 
language describe network structures elegant compact suitable genetic algorithms 
allows coding weights 
various properties strategy formalised gruau 
summarised follows 
completeness network encoded ce strategy 

compactness ann representations created ce manipulated ga minimal size 
ensures reduction genetic search space 

closure process ce closed ga produces meaningful structures acyclic recurrent neural networks reproduction process 

modularity larger decomposable networks code network concatenation codes subnetworks 
result formation building blocks different places typical ann structure 
implies regular ann structures 

scalability complexity problem reflected representation schema 
family anns encoded fixed size code 

power expression ce strategy encode architecture weights 
generative methods combination systems production rules ga design modular anns 
system uses systems basis re writing production rules constitute string representation network topologies 
chromosome encodes ann structure form production rules 
ga evolve population representations 
fitness population member determined residual error certain amount back propagation training 
system inspired kitano voigt 
approach stochastic system 
basic algorithm involves grammar encoding schema similar kitano production rules probability dependent 
aspect shown useful preventing generation large numbers redundant production rules 
network structure generated way kitano system sub networks iteratively randomly modified 
sub networks chosen probabilistic manner 
corresponds individual development process 
ga applied population individuals passed process 
strategy uses feed forward network structures back propagation learning rule 
fitness criterion applied interesting determined mixing classification error number training iterations number connections minimal maximal path length network structure 
generative method uses emergent modelling construct anns incremental comprehensive biologically plausible life cycle development plasticity natural selection genetic changes 
anns represented set production rules describing local behaviors 
organised hierarchically 
lowest level cells connections comes individual behavior top level environment encloses 
similar gruau approach starting single cell system controls division cells growth connections 
system works similar way knowledge systems 
strategy encode feed forward networks recurrent networks 
gas rule generation recombination limited 
designs quite number works anns created evolved part specific research interest 
adapt design strategies mentioned create 
example ann evolved find better solutions control problems 
flexible application carried variable number neurons units arbitrary links evolved species adaptation genetic algorithm saga extended form ga uses variable lengths genotypes 
approach suited generation highly recurrent neural networks 
example designing recurrent nets 
reinforcement learning methods employed evolutionary methods anns 
example larger multi layer network design evolved interaction learning adaptation individual evolution adaptation population observed 
fact quite number researchers concentrating relationship evolution learning 
works individual network structures representing learning evolved optimise adaptive behavior structure 
generation regular networks recursive algorithm 
strategy uses simulated annealing ga search technique 
muhlenbein proposes general framework applying genetic algorithms neural networks 
system ga indirectly designing neural networks 
applied sort structures encode neural networks 
research issues designing network architectures studies mentioned backpropagation learning rule train network 
interesting develop representation involve alternative learning models backpropagation 
increase difficulties determining structures parameters 
major research issues designing anns include 
develop encoding schema specify structure learning rule 
design process involve combination learning dynamics adjust architecture weights 
lead discovery new connectionist algorithms structure 

adaptation genetic operators construct meaningful networks 
attributes networks varied relative interest may change application 
require adaptation types nature ga parameter values rate crossover mutation designing network structures 
systems expect careful studies parameters computationally impractical 

vary fitness evaluation functions 
possible functions involve learning speed accuracy cost parameters size complexity network successful network learning task hand 
considerations main direction research network design focussing designing larger networks efficiently 
researches involve genetic design anns part particular research aim helpful 
serve empirical test proposed genetic ann design researches 
time provide new empirical ideas development genetic design 
ackley litman 
learning natural selection artificial environments 
second artificial life conference 
ackley litman 
interactions learning evolution 
langton editor artificial life ii 
addison wesley 
belew 
evolution learning culture computational adaptive algorithms 
complex systems 
belew mcinerney schraudolph 
evolving networks genetic algorithms connectionist learning 
langton editor artificial life ii 
santa fe institute 
kuiper 
designing modular artificial neural networks 
technical report dept computer science leiden university netherlands 
dolan 
parametric connectivity training constrained networks genetic algorithms 
schaffer editor proceedings third international conference genetic algorithms 
cecconi parisi 
evolving organisms reach objects 
meyer editor animals animats simulation adaptive behavior 
chalmers 
evolution learning experiment genetic connectionism 
touretzky editor connectionist models 
morgan kaufmann 
cliff harvey husbands 
incremental evolution neural network architectures adaptive behavior 
technical report csrp university sussex cogs 
dodd 
optimisation network structure genetic algorithms 
international neural network conference paris 
kluwer dordrecht 
meir 
effect learning evolution sexual populations 
complex systems 
goldberg 
genetic algorithms search optimization machine learning 
addison wesley 
frederic gruau 
cellular encoding genetic neural network 
technical report tr de informatique du ecole normale superieure de lion 
frederic gruau 
genetic synthesis boolean networks cell re writing developmental process 
whitley schaffer editors combination genetic algorithms neural network 
ieee computer society press 
frederic gruau whitley 
cellular developmental neural networks interaction learning evolution 
technical report de informatique du ecole normale superieure de lion 

voigt born 
evolutionary structuring artificial neural network 
technical report tr technical university berlin evolution techniques laboratory 

voigt born 
structuring neural networks generative grammars 
seminar 
berlin springer verlag 
harp samad guha 
genetic synthesis neural networks 
schaffer editor proceedings third international conference genetic algorithms 
harvey 
adding species adaptation genetic algorithms basis saga 
technical report csrp university sussex cogs 
harvey 
evolutionary robotics saga case hill selection 
technical report csrp university sussex cogs 
harvey 
saga cross mechanics recombination species variable length genotypes 
technical report csrp university sussex cogs 
hinton nowlan 
learning guide evolution 
complex systems 
holland 
adaptation natural artificial systems 
university michigan press ann arbor usa 
cliff harvey husbands 
issues evolutionary robotics 
technical report csrp university sussex cogs 
koza rice genetic generation weights architecture neural network 
pages 
bergman 
evolution data processing abilities competing automata 
rodney editor computer simulation brain science 
cambridge university press 
hiroaki kitano 
designing neural networks genetic algorithms graph generation system 
complex systems 
lindenmayer 
mathematical models cellular interactions development 
theoretical biology 
lindenmayer 
developmental systems cellular interactions language grammars 
theoretical biology 
maynard smith 
learning guides evolution 
nature 
miller todd hegde 
designing neural networks genetic algorithms 
schaffer editor proceedings third international conference genetic algorithms 
miller todd 
exploring adaptive agency theory methods simulating evolution learning 
touretzky editor connectionist models 
morgan kaufmann 
sharp 
preliminary analysis recursively generated neural networks 
john denker editor neural networks computing 
american institute physics 
sharp alpert bradley 
recursively generated neural networks 
ieee 
montana davis 
training feedforward neural network genetic algorithm 
technical report bbn systems technologies 
muhlenbein 
limitations multi layer perceptrons networks step genetic neural networks 
parallel computing 
muhlenbein 
dynamics evolution learning genetic neural networks 
pfeifer editor connectionism perspective 
elsevier science publishers north holland 
nolfi elman parisi 
learning evolution neural networks 
technical report crl uni 
california 
parisi nolfi cecconi 
learning behavior evolution 
varela editors european conference artificial life 
schaffer whitley eshelman 

whitley schaffer editors combination genetic algorithms neural network 
ieee computer society press 

massively parallel evolution recurrent networks approach temporal processing 
varela editors european conference artificial life 
todd miller 
exploring adaptive agency ii simulating evolution learning 
meyer editor animals animats simulation adaptive behavior 

emergent modeling method artificial neural networks 
phd thesis university tokyo 

adaptive neural architectures growth control 
dagli shin editors intelligent engineering systems artificial neural networks pages 
asm press new york 

emergent construction adaptive neural architectures 
heuristics journal knowledge engineering 
whitley hanson 
optimizing neural networks faster accurate genetic search 
schaffer editor proceedings third conference genetic algorithms 
whitley schaffer 
combination genetic algorithms neural network 
ieee computer society press 
whitley starkweather 
genetic algorithms neural networks optimising connections connectivity 
parallel computing 
whitley dominic das 
genetic reinforcement learning multilayer neural networks 
belew booker editors proceedings fourth international conference genetic algorithms 
wieland 
evolving controls unstable systems 
touretzky editor connectionist models 
morgan kaufmann 

