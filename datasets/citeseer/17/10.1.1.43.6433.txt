benchmarking filesystems diane tang tr benchmarking filesystems thesis diane tang computer science partial fulfillment honors requirements degree bachelor arts harvard college cambridge massachusetts april benchmarking filesystems chapter background motivation different types benchmarks benchmarks chapter existing benchmarks bad ugly system configuration examining benchmarks benchmarks specint tpc andrew bonnie iostone pete chen self scaling benchmarks nfs benchmarks laddis chapter filesystem benchmark criteria functionality chapter approach benchmarking filesystems fsbench suite filesystem micro benchmarks phase optional initial measurements phase ii non optional initial measurements phase iii spatial locality phase iii logical locality phase iii meta data times phase iv meta data part benchmarking filesystems phase iv readahead phase iv concurrency summary workload characterizer summary chapter benchmark fsbench results ffs lfs characterizing workload predictions testing prediction chapter extending fsbench workload generator benchmarking filesystems acknowledgments appendix appendix fsbench command line options appendix fsbench creating hierarchies appendix fsbench flushing caches appendix aging filesystems benchmarking filesystems widely researched areas operating systems filesystem design implementation performance 
research involves reporting performance numbers gathered variety different benchmarks 
problem results existing filesystem benchmarks inadequate suffering problems ranging scaling advancing technology measuring filesystem 
new approach filesystem benchmarking 
methodology designed help system designers understand improve existing systems help users decide filesystem buy run 
usability benchmark separated parts suite micro benchmarks run filesystem workload characterizer 
results separate parts combined predict performance filesystem workload 
purpose separation functionality fold 
system designers filesystem perform diverse workloads characterizing workload independently designers better understand required filesystem 
micro benchmarks tell designer needs improved workload characterizer tells designer improvement affect filesystem performance workload 
separation helps users trying decide system run buy may able run workload systems consideration need separation 
implementation methodology suffer problems seen existing benchmarks scales technology tightly specified helps system designers 
benchmark drawbacks accurately predict performance filesystem workload limiting applicability useful system designers users trying decide system buy 
belief general approach additional time manipulate prediction algorithm 
benchmarking filesystems chapter background motivation number papers area indication research interest filesystems research interesting research topics operating systems today 
looking operating system conference proceedings osdi november usenix june sosp december papers published sorted manner file systems including distributed file systems papers listed distributed systems including distributed file systems distributed shared memory papers listed memory systems including distributed shared memory systems papers performance issues distributed file systems distributed shared memory mobile computing security approximately papers published operating systems relates filesystems half amount relate performance issues 
surprising papers performance numbers back claims 
benchmarking filesystems filesystem papers examine modification existing filesystem design implementation new filesystem performance crucial issue 
researchers trying show ideas yield better performance status quo particular workload 
variety different mechanisms prove assertions higher performance simulation especially system implemented hand waving idea wonderful 
haven measurements benchmarks 
benchmarks typically suite programs containing performance gathering mechanism run user level yield results compare different systems 
benchmarks commonly method determining performance improvements 
example current debate filesystem research concerns filesystem design best fast file system ffs log structured file system lfs 
researchers argue gains lfs due asynchronous writes layout data meta data disk ffs augmented clustered reads writes competitive 
benchmarks debate include modified version andrew benchmark tpc suite micro benchmarks defined discussed section 
benchmarks filesystem research papers problems 
standard benchmark processor design research specint specfp predominate 
filesystems closest standard andrew benchmark researchers original version modified version ousterhout 
researchers write benchmarks original lfs rosenblum wrote suite micro benchmarks 
seltzer tried reproduce results rosenblum description write version 
lack standardization sharing comparing results different projects papers difficult impossible 
secondly existing benchmarks measure filesystems inadequate regardless designed 
problems include scaling technology measuring filesystem measuring part filesystem yielding useful results results help user determine system perform different workload point system designer possible areas improvement 
thesis focuses determining functionality required filesystem benchmark defining benchmark 
rest chapter presents background information needed thesis 
chapter examines existing benchmarks chapter lays criteria judge filesystem benchmark functionality required 
chapter presents proposed benchmarking methodology implementation chapter presents example benchmark 
chapter concludes thesis points directions 
different types benchmarks benchmarks may categorized ways 
way categorize benchmark synthetic application benchmark way macro micro benchmark 
application benchmarks consist programs utilities user 
example specint consists applications including compiler lisp interpreter spreadsheet 
synthetic benchmarks hand model workload executing various operations mix consistent benchmarking filesystems target workload nfs benchmarks laddis allow user input target mix operations percentage workload consist create getattr 
synthetic benchmarks flexible application benchmarks usually larger number parameters allow scale better technology increase number different workloads model 
problem synthetic benchmarks measure real 
results questionable operations completed synthetic benchmark take amount time real application 
synthetic benchmark add overhead exist real application real application incur overhead modeled benchmark 
answer question conventional wisdom far disregards problem 
second way categorize benchmark macro benchmark micro benchmark 
macro benchmarks measure entire system usually model workload synthetic application benchmarks 
micro benchmarks measure specific part system thought subset synthetic benchmarks artificial try model real workload whatsoever 
example micro benchmark create micro benchmark original lfs timed long system took create files 
micro benchmarks major problems 
easy distort results micro benchmarks 
standard suite micro benchmarks researchers write set show improved aspect system performance 
shown improvement detracts aspects system performance 
main problem micro benchmarks complete real model real workload mix operations result different behavior operation repeated 
micro benchmarks excellent pointing potential areas improvement system 
benchmarks different types benchmarks different reasons benchmarks reason having different requirements 
lucas stated reasons obtain performance numbers selection evaluation system best performance monitoring tweak system improve performance performance projection idea system perform 
states benchmarks excellent selection evaluation adequate performance monitoring insufficient performance projection 
looking lucas statements really audiences different requirements benchmarks 
audience consists customers looking buy system care system perform best workload 
audience spawned benchmarks iostone see chapter yield number final result 
type benchmark fairly useless customers workload approximates benchmark target workload result relative comparisons 
system designers comprise audience benchmarks point possible areas improvement current system design new system benchmark yields number audience 
benchmarking filesystems general customers need macro benchmarks system designers need combination macro microbenchmarks 
customers probably prefer application benchmarks matching workloads easier 
system designers probably tend prefer synthetic benchmarks greater control flexibility 
case updated spec benchmarks released spec new multiprocessor benchmarks available microprocessor report september 
howard kazar menees nichols satyanarayanan sidebotham west scale performance distributed file system acm transactions computer systems february 
gray benchmark handbook database transaction processing systems 
morgan kaufmann publishers 
lucas jr performance evaluation monitoring computing surveys september 
mckusick joy leffler fabry fast file system unix acm transactions computer systems august 
molloy 
anatomy benchmark performance evaluation review 
nelson lyon keith laddis multi vendor vendor neutral nfs benchmark conference january 
ousterhout aren operating systems getting faster fast hardware 
proceedings usenix summer technical conference june 
rosenblum ousterhout design implementation log structured file system acm transactions computer systems february 
seltzer smith balakrishnan chang padmanabhan file system logging versus clustering performance evaluation proceeding usenix technical conference 
benchmarking filesystems chapter existing benchmarks bad ugly different ways categorize benchmarks different audiences benchmarks chapter analyzes existing benchmarks help benchmark designers decide 
benchmark purpose supposed measure compared measured 
actual analysis benchmarks system configuration utilities determine benchmarks measure described 
system configuration testbed analyzing benchmarks machine sake 
running benchmarks monitoring utilities sake single user mode minimize extraneous activity 
sake configuration described table disks described table 
note seagate disk times quoted seek times table 
difference due fact reads head need close surface writes 
note multiple disks machine single scsi controller 
sake fast processor benchmark measures filesystem entirely cpu bound 
similarly main disk seagate st relatively fast today technology bottle neck intensive applications 
sake virtual memory benchmark page extensively 
size buffer cache large especially comparison machines allow buffer cache grow dynamically stressing cache difficult benchmarks 
benchmarking filesystems examining benchmarks unix utilities gather statistics system resources benchmarks time 
reports statistics subsystem number sectors transferred second milliseconds seek 
reports statistics virtual memory subsystem including data number page faults second number system calls second 
full listing fields see appendix time reports total elapsed time total time spent user mode process total time spent system mode 
run concurrently benchmark time insure benchmark significantly affected statistics gathering utilities output time running benchmark compared output time running benchmark concurrently 
benchmarks benchmarks analyzed chapter specint andrew file system benchmark tpc bonnie benchmark iostone self scaling benchmark nfs benchmarks laddis 
benchmark designed different purpose mind filesystem benchmarks learn lesson applicable benchmarking general 
brief description benchmark classifications table 
system name processor operating system main memory buffer cache block size bytes disks maximum bus bandwidth sake pentium mb mb sd seagate st sd dec rz mb table sake configurations model number capacity formatted cache size track seek average seek maximum seek spindle speed seagate st mb kb ms ms ms ms ms ms rpm dec rz mb kb ms ms ms rpm table disk statistics benchmarking filesystems specint system performance evaluation cooperative spec released new benchmark suites measure cpu integer performance specint measure cpu floating point performance specfp 
benchmark suites replace original criticized benchmark released designed measure relative speed computer system cpu intensive floating point integer applications 
applications intended computationally intensive graphics network intensive 
specint specfp numbers published manufacturers processors hp dec sun 
numbers consumers help decide system buy researchers help determine technology superscalar super pipelined yield best performance time 
due difficulty obtaining fortran compiler examine specint 
different applications compose suite listed table 
graphs discussions system usage resulting running applications times plots graph plot run 
stated information obtained running benchmark synthetic application macro micro brief description specint suite applications designed measure cpu integer performance 
andrew suite composed entirely unix utilities designed model workload generated system developers 
tpc database benchmark modeling bank 
bonnie suite consisting micro benchmarks designed model intensive applications 
iostone filesystem benchmark modeling workload various filesystem analyses 
self scaling subsystem benchmark parameterizes subsystem parameters measuring predicting performance terms parameters 
difficult classify benchmark macro micro benchmark gives information subsystem perform specific aspects subsystem 
nfs benchmark designed measure nfs server performance modeling workload input mix operations 
table benchmarks brief description classification benchmarking filesystems simultaneously benchmark 
note runs executables input files output files statistics gathered seagate disk sake 
people spec question specint measures mainly cpu factors paging activity requests affect final results 
people spent great deal time develop market spec benchmark suite comes surprise specint fact measure cpu performance 
applications cpu bound time spent completing user cpu operations 
little paging activity paging occur demand paging gcc application paging activity 
half applications disk cpu bound 
reason apparent contradiction disk activity observed sake ffs consists mainly asynchronous writes disk eqntott creates output file mb size compress creates mb files gcc creates files totalling mb size 
note operating systems dos writes synchronous operations affect specint performance 
specint results time needed run benchmarks 
benchmarks cpu bound system resources subsystem significantly affect results specint measure cpu integer performance 
cpu benchmark usually yield filesystem benchmark majority filesystem calls asynchronous writes stress system reflect filesystem performance 
downside specint benchmark really help user decide system buy 
workloads consist processes running concurrently situation cpu sole factor determining performance operating system plays crucial role 
application description espresso minimizes boolean functions 
written li lisp interpreter input program solves queens problem 
interpreter written input program lisp 
eqntott translates boolean equation truth table 
written compress performs data compression mb file adaptive lempel ziv coding 
written sc performs computations unix spreadsheet 
written gcc consists gnu compiler converting preprocessed files optimized sun assembly code 
written table applications specint benchmarking filesystems 
specint statistics espresso shows espresso cpu bound user cpu bound 
increases system cpu usage match spikes correspond reading writing input files output files course run espresso executed times input file 
peak seek times shown average seek time seagate disk 

specint statistics li espresso shows li user cpu bound 
slightly substantial system cpu usage due fact output written character time putc 
small spikes correspond block output file written disk ffs data written disk asynchronously full block written 
peak seek times correspond average seek time seagate disk 
percent cpu utilized time seconds percent bandwidth time seconds milliseconds seek time seconds usr cpu usr sys cpu percent cpu utilized time seconds percent bandwidth time seconds milliseconds seek time seconds usr cpu usr sys cpu benchmarking filesystems 
specint statistics eqntott shows eqntott user cpu bound 
system cpu usage attributable system calls write mbyte output file corresponds disk utilization 
despite substantial disk utilization eqntott cpu bound demonstrating asynchronous operations seriously affect cpu performance 

specint statistics compress previous benchmarks compress cpu bound system cpu usage attributable dealing output files mb files 
eqntott substantial disk utilization affect cpu performance severely due asynchronicity writes 
lack activity seconds due gathering statistics benchmark execution showing system steady state 
steady state exists graphs due short execution time compress state emphasized percent cpu utilized time seconds percent bandwidth time seconds milliseconds seek time seconds usr cpu usr sys cpu percent cpu utilized time seconds percent bandwidth time seconds milliseconds seek time seconds usr cpu usr sys cpu benchmarking filesystems 
specint statistics sc see sc cpu bound higher system cpu usage attributable writes screen redirected files disk 
seek times reflect files fairly close average seek time slightly ms 
specint statistics gcc gcc essentially cpu bound despite significant disk utilization 
eqntott compress numbers due composition disk operations consisting mainly asynchronous writes 
seek times average ms higher variance reflects usage files close due layout policy ffs 
tpc group companies joined form transaction processing performance council tpc 
purpose tpc standardize benchmark data processing industry benchmarks proposed tp sufficiently imprecise different vendors loopholes improve performance rating 
november tpc released tpc percent cpu utilized time seconds percent bandwidth time seconds milliseconds seek time seconds usr cpu usr sys cpu percent cpu utilized time seconds percent bandwidth time seconds milliseconds seek time seconds usr cpu usr sys cpu benchmarking filesystems tightly specified version benchmark 
august released tpc tp 
essentially tpc tpc terminal interactions tpc pure database benchmark tpc measures line transaction processing 
tpc simulates bank databases transactions accounts transactions teller transactions branch logging transactions 
transaction withdrawal deposit requires account branch teller databases updated reflect new account balance history record appended history file 
implementation seltzer support transaction processing file systems 
tpc run times database account records teller records branch records history records totalling approximately mbytes data 
run completed transactions 
databases error log sd seagate log file mbytes shared memory files mbytes lock files sd dec 
shows results runs 
tpc problems database benchmark problems relating suitability filesystem benchmark discussed 
tpc measure filesystem functionality data benchmark essentially meta data operations files opened mmap closed 
data benchmark tpc complete measuring random access patterns read modify write 
sense database benchmark random records existing databases modified means tpc useful workload typically database users 
tpc database benchmark useful group 
despite faults tpc scales simply increasing size databases number transactions 
presenting performance function load user predict system perform workload access patterns different load better tpc just gave single number final result 
benchmarking filesystems 
tpc results comparison cpu utilization graph disk utilization graphs shows alternation disk usage cpu usage 
disk utilization sd databases high access pattern sd random determined high seek times 
disk utilization higher sd contains log file shared memory files comparing graphs seen utilization high random access pattern determined 
context switches comparison seen data access pattern read modify write pattern 
andrew andrew benchmark developed cmu designed compare performance andrew file system afs distributed filesystems 
supposed model workload system designers generate designed representative workload benchmarking purposes designed provide way time compare performance different distributed filesystems especially penalty paid remote accesses server 
andrew consists phases 
creating file directory hierarchy percent cpu utilized time seconds time seconds milliseconds seek sd time seconds context switches second time seconds percent bandwidth sd time seconds milliseconds seek sd time seconds usr cpu usr sys cpu benchmarking filesystems 
copying files hierarchy 
examining new copy stat note phase reads meta data 

reading new copy grep note phase reads data 

compiling copy shows statistics running concurrently benchmark 
matching graphs output andrew observations copy entire hierarchy buffer cache 
rise system cpu utilization corresponds increase number system calls completed showing accesses files copied hierarchy satisfied cache 
compile phase benchmark takes thirds running time 
phase benchmark cpu bound 
despite fact andrew benchmark designed purpose filesystem benchmark 
main problems andrew 
andrew scaled technology fixed size data set small stressed system developed longer 
secondly andrew entirely cpu bound filesystem bound 
kernel build level hierarchy totalling approximately mbytes roughly characteristics compile phase andrew look back gcc specint suite shows cpu bound 
kernel build graphs show disk traffic probably due synchronous reads necessary read source include files disk synchronous reads satisfied cache andrew 
compiles cpu bound majority disk operations consist asynchronous writes output files result compiles typical system designers component filesystem benchmarks 
andrew output consists long phase takes complete 
phase measures meta data write throughput phase measures data meta data read write throughput distinction 
phase consists meta data reads satisfied attribute buffer cache phase consists mainly data reads satisfied buffer cache 
final phase consists data reads writes reads satisfied cache writes asynchronous 
breaking output phases presenting time phase get idea different parts file system perform buffer cache bandwidth minimum size buffer cache throughput meta data writes 
phases consist type operation way determine percentage time spent doing phases yield information 
system workload usually consists users user doing different things benchmark predicting performance filesystem real workload consisting system development 
modifications andrew exist simulate multi user environment standard 
benchmarking filesystems 
andrew benchmark statistics note phases distinct shaded time needed complete 
shows phases creating hierarchy copying files benchmark wait disk complete synchronous meta data operations 
corresponds higher disk utilization seen 
notice number context switches increases period reflecting process waiting operations complete 
phases show high system cpu utilization increase number system calls system calls completed rapidly implying file accesses phases satisfied cache 
compile phase dominated user cpu usage substantial disk utilization reflects asynchronicity disk operations 
seek time reflects disk utilization seek time high benchmark reads directory writes 
lull middle corresponds phases accesses satisfied buffer cache compile phase averages ms seek 
percent cpu utilized time seconds system calls second time seconds context switches second time seconds percent bandwidth time seconds milliseconds seek time seconds usr cpu usr sys cpu benchmarking filesystems 
kernel build statistics shows compile essentially cpu bound fairly high percentage system cpu usage handle writing output files 
note despite substantial disk utilization build cpu bound reflecting asynchronicity disk operations 
seek time averages ms bonnie bonnie benchmark written tim bray designed measure bottlenecks filesystem 
bonnie workload file system activity observed caused bottlenecks intensive applications specifically text database done connection new oxford english dictionary project university waterloo 
bonnie benchmark consists tests test consists loop small fit instruction cache paging swapping benchmark run 
tests 
create new file open stream associated file write file stream character time putc close file fclose stream 
note fopen fclose data buffered stdio data sent filesystem entire block written 

open file created test read block file read dirty word block round robin algorithm seek back block write block back write repeat read seek write sequence entire file closing file close 

recreate file open write file block time write close file close 

open existing file open stream associated file read file character time getc close stream fclose 

open existing file read file block time read close file close 

spawn children 
child opens file seeks random spot reads block place file block time writes back disk write 
parent tells children 
percent cpu utilized time seconds percent bandwidth time seconds milliseconds seek time seconds usr cpu usr sys cpu benchmarking filesystems user choose size file defaults mbytes number children defaults 
user careful choose file size large entire file fit buffer cache testing disk access cache access 
shows statistics running concurrently bonnie sake seagate disk shows statistics sake dec disk 
bonnie essentially disk benchmark finding peak read write throughput file system provide disk long disk takes complete random seek 
tests test throughput layout fast requests processed filesystem disk files laid 
tests test data buffer exists system filesystem stdio blocks data read written filesystem disk 
dos example write synchronous data buffered 
tests check filesystem detect sequential read start reading ahead data 
test measures average seek time processes seeking random spots file disk file large spread part disk 
bonnie excellent measuring peak read write throughput disk discovering filesystem features buffer cache sequential layout files readahead bonnie filesystem benchmark lacking tests filesystem meta data performance example 
despite major failing bonnie measuring presenting results clearly 
number measures aspect system aspect different aspects number table shows results running bonnie different systems 
example similar ratios character throughput block throughput sake shows reads writes buffered block time large differential probably reflects clustered reads writes 
interleave rotdelay sake optimized reading writing readahead probably occur inferred fact read throughput slightly higher write throughput 
hand probably interleave set optimize system char throughput kb cpu util block throughput kb cpu util rewrite kb cpu util char input kb cpu util block input kb cpu util 
random seek cpu util 
sake seagate sec sake dec sec sec sec table results running bonnie different platforms 
rows results running bonnie sake disks 
sun lx running sunos alpha axp running osf 
benchmarking filesystems reading 
different ratios rewrite test dec seagate disk sake reflect different disk speeds dec disk rpm handle read write rotations seagate disk rotates fast loses rotation read write due time needed operating system handle interrupt 
different cpu usage dec seagate disk attributable different rotation speeds disk dec disk rpm needs time complete request loops generate requests loop fast leading lower cpu usage 

bonnie statistics sake sd graphs show clear demarcation tests 
shows high cpu utilization tests due looping needed write read character time 
despite high cpu utilization disk utilization throughput high due data buffered block time 
system cpu usage dominates cpu utilization needed process bonnie data requests 
asynchronicity writes corresponding synchronicity reads reflected number context switches really low writing tests high reading tests test consists reads mixed writes 
bursts seek time reflect rotation lost read write test 
percent cpu utilized time seconds percent bandwidth time seconds context switches second time seconds milliseconds seek time seconds usr cpu usr sys cpu benchmarking filesystems 
bonnie statistics sake sd comparing seagate disk dec disk dec disk noticeably slower versus rpm probably fragmented resulting poorer file layout 
ratio times test showing main difference disk 
notice bursts test test relatively shorter dec disk reflecting rotations lost read write 
iostone iostone developed group researchers university california davis compare performance different filesystems just throughput tries account aspects filesystem disk disk caches file system structure cpu overhead 
workload modeled iostone file system analyses 
iostone creates synthetic filesystem hierarchy completes series requests simulating locality original analysis bsd filesystem erases filesystem 
precise iostone phases 
creates files sizes ranging bytes kbytes spacer files total files kbytes placed midst files 
creating files reads spacer files flush buffer cache 
creates random permutation files 

goes random permutation file permutation iostone opens file randomly chooses read write file reads writes file kb blocks file smaller closes file 
repeats process times random permutation 

deletes files 
benchmark measures time needed complete phase returns number second calculated dividing normalizing constant time measured 
broke iostone phases create phase phase pass permutation phase passes permutation phase delete phase phase 
shows statistics runs iostone sake 
different phases drops zero graphs 
percent cpu utilized time seconds milliseconds seek time seconds time seconds usr cpu usr sys cpu benchmarking filesystems iostone problems 
andrew iostone scale fixed size data set small 
result iostone cpu bound bound dataset buffer cache disk activity asynchronous data writes 
furthermore reading spacer files necessarily flush buffer caches especially dynamically sized buffer caches buffer cache flushed final result reflect distortion 
iostone scale model flawed 
iostone claims emulate workload typical unix workstation creates target file system hierarchy flat real file system hierarchies rarely flat 
workload measures consists mainly data operations 
hand typical workload consists meta data operations data operations 
hand iostone yields number number measures data operations minimize confusion 
iostone uses process access files workstations usually processes running simultaneously 
order files accessed random accesses files sequential 
measurement papers iostone show access patterns files sequential 
flawed workload model means customer iostone determine workload perform system 
iostone major failings yields number questionable number really measures 
phase measured phase consists data reads writes meta data reads open close 
reading spacer files may flush buffer cache flush attribute cache depending size attribute name cache means meta data reads satisfied cache 
iostone essentially measures data throughput dependent part file layout 
number returned system designer ideas relatively bad performance due cache cache size disk file layout furthermore result sensitive buffer cache size 
table iostone results different cache sizes numbers averaged runs 
data set spacer files fit buffer cache iostone performance plateaus showing lack scalability 
total running time low iostone stable high standard deviation see table 
improve iostone filesystem workload models changed reflect reality purpose written 
changed scales reducing areas instability increasing applicability 
cache size sec std 
dev 
run time std 
dev 
mb mb mb mb mb table results running iostone sake different buffer cache sizes 
benchmarking filesystems 
iostone statistics different phases shading lines zero 
cpu activity consists system fielding file system calls 
note sharp jump system cpu usage number system calls phase implying system calls completed quickly means data accesses fulfilled buffer cache 
result phase takes approximately amount time phase 
note disk utilization increases number context switches decreases phase due disk operations asynchronous writes reads mixed writes 
see phase consists reads writes seek time slightly higher implying collisions backtracking different read write requests 
note average seek time course run ms implying files spread disk 
pete chen self scaling benchmarks peter chen developed self scaling benchmark designed point system designer possible areas improvement scale measure wide range subsystems workloads able compare results systems 
benchmark runs different workloads system workload created varying parameters size data set number processes running concurrently average size request nearest block percentage opera percent cpu utilized time seconds system calls second time seconds context switches second time seconds time seconds milliseconds seek time seconds usr cpu usr sys cpu benchmarking filesystems tions reads percentage operations sequential 
results terms parameters examine results determine area system improved compare performance different systems different parameter values 
benchmark phases 
finds focal vector point parameter stable far away sudden changes performance 
intuitively focal vector representative typical value applicable wide range workloads 
focal vector identified benchmark generates graphs plotting throughput function parameter remaining parameters focal point value 
graphs chen introduces idea predictive performance 
claims focal vector generally applicable shape graph applicable parameters focal values 
workload characterized terms parameters workload performance predicted scaling graphs 
running benchmark executables sake seagate drive test directory sake dec drive 
filesystems share buffer cache 
graphs comparison graphs show benchmark stress target system sd determines system performs levels just peak performance 
benchmark scalable tightly specified reproducible descriptive prescriptive system 
filesystem overlap system overlap sufficient 
workload model system data operations filesystem data meta data operations 
result predict performance filesystem workload point system designer areas improvement disk scheduling buffer cache size 
criteria stated chen thesis benchmark filesystem benchmark 
benchmarking filesystems 
self scaling benchmark statistics key point take away unclear graphs benchmark just test peak performance determines subsystem performance entire range workloads gathering data better predictions 
nfs benchmarks laddis created measure performance sun nfs servers due popularity networked filesystem 
generates series nfs requests single client single server measure server performance 
systems refined called 
problem benchmarks limited single client single client fully stress server 
group companies joined form laddis benchmark stress nfs server 
unfortunately able obtain laddis version 
version parent process children processes 
parent process spawns synchronizes children collects final statistics checks consistency 
child tries simulate workload target mix nfs operations target average interarrival time requests 
parent children run client client client test server performance 
usr cpu usr sys cpu percent cpu utilized time seconds bandwidth sd time seconds msec seek sd time seconds bandwidth sd time seconds msec seek sd time seconds benchmarking filesystems allowing user set number children target mix calls target load model different client workloads 
major shortcoming designed measure server performance client performance client stress server matter processes running client 
laddis improves allowing multiple clients generates load input mix operations input file access distribution 
laddis potential effective benchmark scaling number clients load client presenting results graphically showing performance server varies load 
laddis limited nfs servers 
analysis chapter shows current benchmarks inadequate measuring filesystem performance suffer problems benchmarks measure subset filesystem functionality typically data throughput 
metadata operations usually ignored constitute large percentage requests filesystem 
running utility monitors packets sent server shows majority requests sent server meta data requests 
benchmarks measure peak performance happens real workload running system 
benchmarks scale technology stress today systems yesterday systems 
trying model specific workload system development scientific calculation benchmarks modelling actual workload useful narrow group widely 
benchmarks meaningless results predict performance system realistic workloads point system designers possible areas improvement 
table summarizes flaws benchmarks examined chapter 
rest thesis concentrates defining constitutes filesystem benchmark defining benchmark meets criteria 
benchmark measuring filesystem peak performance scaling technology lack general applicability meaningless results specint andrew tpc bonnie table benchmark flaw summary benchmarking filesystems anon measure transaction processing power datamation april 
baker hartman kupfer shirriff ousterhout 
measurements distributed file system proceedings th symposium operating systems 
blackwell harris seltzer 
heuristic cleaning algorithms log structured file systems proceedings usenix technical conference 
berkeley software distribution 
bsd system manager manual 
california reilly associates 
berkeley software distribution 
bsd user manual 
california reilly associates 
bray bonnie source code netnews posting 
case 
updated spec benchmarks released spec new multiprocessor benchmarks available microprocessor report september 
chen patterson 
new approach benchmarks adaptive evaluation predicted performance ucb computer science dept university california berkeley march 
gee hill smith 
cache performance spec benchmark suite ieee micro august 
gray 
benchmark handbook database transaction processing systems 
morgan kaufmann publishers 
howard kazar menees nichols satyanarayanan sidebotham west 
scale performance distributed file system acm transactions computer systems february 
hu 
measuring file access patterns unix performance evaluation review 
acm sigmetrics 
levine gray kiss kohler 
tpc tpc obsolete 
draft 
iostone self scaling nfs benchmarks benchmark measuring filesystem peak performance scaling technology lack general applicability meaningless results table benchmark flaw summary benchmarking filesystems mckusick joy leffler fabry fast file system unix acm transactions computer systems august 
molloy 
anatomy benchmark performance evaluation review 
nelson lyon keith laddis multi vendor vendor neutral nfs benchmark conference january 
ousterhout trace driven analysis unix bsd file system operating systems review december 
proceedings th symposium operating systems principles 
park becker 
iostone synthetic file system benchmark computer architecture news june 
seltzer 
file system performance transaction support memorandum 
ucb erl january 
callahan 
network file server performance benchmark proceedings usenix summer technical conference 
smith 
sequentiality prefetching database systems acm transactions database systems 
smith 
analysis long term file patterns application file migration algorithms ieee transactions software engineering se 
keith 
laddis generation nfs file server benchmarking proceedings usenix summer conference june 
benchmarking filesystems chapter filesystem benchmark criteria functionality chapter focused existing benchmarks inadequate 
benchmarks bad 
specint example benchmark measures claims measure bonnie example benchmark results clearly user extraneous information obscuring data 
self scaling benchmark excellent filesystem benchmark measured filesystem 
goodness criteria chen laid judging systems adapted filesystems 
chen states benchmark prescriptive point system designers possible areas improvement 
bound benchmark measure system example cpu 
scalable advancing technology 
comparable different systems 
general applicable wide variety workloads 
tightly specified loopholes clarity needs reported 
criteria modification bound filesystem bound apply filesystem benchmarks 
fact criteria applied benchmarking methodologies 
criteria judging filesystem benchmarks need clarification definition filesystem bound 
needs measured 
filesystems may thought terms operations user sees create read write mkdir way looking big picture filesystem types operations data meta data 
data operations involve user data meta data operations deal control structures filesystem 
ffs meta data consists inodes indirect blocks free map directories 
benchmarking filesystems third way best benchmark writer think terms filesystem functionality filesystem responsible 
decisions designing filesystem meta data filesystem control structures 
blocks allocated file 
meta data placed relation data 
model locality 
example ffs tries spatial logical locality placing blocks single file near placing files directory close 
files named 
algorithm pathname resolution 
caching caches maintained lru versus random caching algorithms determining data flushed disk 
disk scheduling done 
reads writes clustered 
requests pulled disk queue rescheduled 
disk space managed free map blocks versus sectors 
method minimize disk space fragmentation 
semantic guarantees user 
example create system call returns user file exist disk 
filesystem recover crash 
recover 
long take recover 
filesystem handle multiple users accessing changing file 
filesystem provide protection user data 

designers filesystem need solve problems filesystem benchmark needs able measure solution works 
filesystem benchmark determine performance gain due clever algorithm filesystem versus clever disk 
final issue benchmark writer needs address concerns metric evaluating system 
common metric throughput operations completed certain amount time 
throughput usually expressed kbytes second second general second 
users care latency long takes operation 
user cares long system takes respond keyboard stroke list directory long wait 

typically latency expressed average amount time needed complete operation 
throughput latency common metrics definitely ones 
metrics include reliability security efficiency disk space usage throughput latency general 
chen patterson 
new approach benchmarks adaptive evaluation predicted performance ucb computer science dept university california berkeley march 
mogul leading astray third workshop workstation operating systems april 
benchmarking filesystems chapter approach benchmarking filesystems chapter examined current benchmarks determine writing benchmark chapter laid criteria judging filesystem benchmark defined functionality benchmark responsible 
rest thesis uses basis propose new approach benchmarking filesystems implementation 
approach benchmarking divides benchmark separate parts suite micro benchmarks run filesystem tested workload characterizer 
part generates set statistics set characterizing filesystem set characterizing target workload 
performance workload filesystem predicted sets statistics 
motivation approach target system designers users looking buy system 
system designers idea micro benchmarks point possible areas improvement workload characterizer tells designer improvement worth making 
intuitive example point improving create performance create constitute significant percentage workload 
suite micro benchmarks complete measure filesystem functionality system designers determine improvement impacts negatively aspects system 
users trying decide system buy install constitute audience targeted approach 
ideally run workload systems consideration decide system yield best performance 
method usually possible probably systems test workload benchmark 
separating filesystem characterization workload characterization approach results micro benchmarks published similar benchmarking filesystems specint specfp results customers published statistics results workload characterizer determine system best 
rest chapter discusses approach implementation detail 
note name entire benchmark including suite micro benchmarks workload characterizer fsbench name suite filesystem micro benchmarks 
fsbench suite filesystem micro benchmarks fsbench phases optional initial measurement phase mandatory initial measurement phase micro benchmarks optional extended micro benchmarks phase system designers 
optional initial measurement phase measures throughput seek time reads writes underlying hardware device 
phase optional filesystems benchmark executable test required 
write tests optional case filesystem test overwritten 
mandatory initial measurement phase estimates sizes buffer cache attribute cache name translation cache 
estimates choose file hierarchy sizes phases 
main micro benchmark phase measurements needed comparison workload characterizer results 
extended micro benchmark phase follows measurements system designers customers need 
table gives overview fsbench 
purpose measuring disk separately filesystem help separate performance gains due intelligent disk performance gains attributable intelligent filesystem results phase name brief description disk measurements measures read write throughput seek time character operations go buffer cache block operations go block device device filesystem test 
ii cache sizing sizes buffer cache attribute cache name translation cache iii spatial locality data micro benchmark measures filesystem block allocation policy single file writing reading overwriting single file random sequential access patterns 
iii logical locality data micro benchmark measures filesystem block allocation policy files logically related directory writing reading overwriting files accessing files creation order random order iii iv metadata time meta data micro benchmark measures common meta data operations creating deleting files making removing directories reading attributes files directories 
part benchmarks belong phase iii part belong phase iv see section 
iv metadata part meta data micro benchmark tries pinpoint possible areas improvement meta data operations precisely iv readahead data micro benchmark tries find degenerate read access patterns determine readahead algorithm filesystem behaves properly iv concurrency tries determine types operations data meta data file versus files conflict 
table fsbench overview benchmarking filesystems estimating cache sizes start benchmark consistent known state 
micro benchmarks separated separate phases facilitate usability 
describing measurement detail things noted 
fsbench merely cut complete suite micro benchmarks 
chapter suggests possible enhancements suite including temporal locality benchmark match spatial logical locality benchmarks 
secondly fsbench written system call interface port posix compliant system 
results thesis bsd compiled tested sunos osf 
numbers section result running fsbench sake seagate sd disk stated 
see section system specifications 
phase optional initial measurements purpose phase measure disk results phase phase iii compared determine overhead filesystem imposes 
phase optional read tests requires filesystem test means filesystems preferably disks needed 
read measurements raw disk bandwidth seek time disk bandwidth seek time 
difference accesses raw character device dev rsd go filesystem buffer cache normal block device dev sd 
seek tests determine long takes seek random location read bytes raw device bandwidth test reads mb kb blocks current typical maximum transfer size disk device bandwidth test reads mb filesystem block size typically kbytes 
size disk specified user see appendix complete list user options entire disk measurement scales disk features 
measurements writes measurements reads reading disk tests write disk 
run tests user customize scripts benchmark uses mount filesystem 
run write tests script create new filesystem customized 
measurements table results running read tests sake seagate disk disks sake contained needed data write tests run 
disk rotates rpm average kbytes track able transfer data approximately mbytes sec 
allowing operating system interrupt time assuming driver allow order reads expected bandwidth mbytes sec approximately twice result seen 
reason believe controller driver sake may fault substantially higher bandwidth obtained ncr controller driver robert morris switched controllers day 
substantially lower bandwidth transfers block device explained smaller transfer size expected bandwidth kbyte transfer rotation kbytes sec 
benchmarking filesystems phase ii non optional initial measurements phase estimates size buffer cache attribute cache name translation cache 
sizes flush caches determine file hierarchy sizes micro benchmarks phases iii iv scale 
estimate size buffer cache binary search algorithm 
starting file size mbytes file written read sequentially 
time needed read block file cache times measured size file filesystem blocks 
time needed read random permutation blocks file measured 
times skew factor cache size file 
time read random permutation greater cache smaller file size 
binary search narrow size cache size doubled maximum bound exists algorithm terminates minimum maximum bounds blocks 
skew factor mentioned account possible timing differences accesses measured 
value equals timer granularity gettimeofday size file blocks 
time granularity defaults ms environment variable hz set set timer granularity equals hz 
point measurement obtain upper bound cache size gettimeofday measure accesses thought accesses time returned timer granularity bound timer skew bound access skew time measurement accesses times timer granularity 
algorithm works dynamically sized buffer caches buffer cache virtual memory unified main memory 
run system single user mode minimal extraneous activity buffer cache take pages virtual memory active processes virtual memory maximum size buffer cache reached 
point pages taken virtual memory clean need written disk 
algorithm tested alpha running osf initial size buffer cache significantly smaller maximum size algorithm find maximum size buffer cache 
find size attribute cache algorithm minor differences file size timing accesses blocks file distinct files time read attributes test measurement kbytes sec kbytes sec msec seek msec seek table disk measurements sake seagate disk benchmarking filesystems measured 
timing reads block file time stat file read measured random permutation blocks file random permutation files 
similarly find size name translation cache distinct files distinct different paths directories 
see appendix algorithms create hierarchies 
algorithms tested sake results table 
fact estimated size attribute cache larger actual size problem algorithm aiming overestimate anyway 
currently algorithms determine cache exists 
situation currently loop forever 
real operating systems dos usually caches currently big problem 
algorithms improved include case increase benchmark applicability 
problem sizing caches independent 
depending filesystem inodes attribute cache may buffer cache accessed approximately amount time 
skew sizing attribute cache problem solvable flushing buffer cache measurements 
major interdependence attribute name translation cache 
attribute cache larger name translation cache pathnames fit name cache pathname resolution time skew sizing attribute cache 
similarly name translation cache larger attribute cache inode access time skew sizing name cache 
attribute cache larger name cache second problem occur problem occur attribute cache orders magnitude larger name translation cache fewer directories sizing attribute cache sizing name translation cache distinct files distinct directories 
phase iii spatial locality phase initial measurement phases set micro benchmarks 
microbenchmarks phase test block allocation single file sequential random access patterns 
benchmarks measurements time needed initially write file write block allocation time time needed read file time needed overwrite file 
benchmark file read written sequentially benchmark different random permutations blocks file measurements defeating system save previous access pattern 
buffer cache flushed measurement taken see appendix caches flushed 
expected results benchmarks cache estimated size actual size buffer bytes bytes attribute inodes inodes name translation names names table cache size estimated actual benchmarking filesystems throughputs random access benchmark lower throughputs sequential access benchmark 
throughputs sequential access benchmark high percentage disk bandwidths see section filesystem imposes significant overhead keep track file 
write allocate throughput lower overwrite throughput filesystem need extra time allocate blocks indirect blocks initially writing file 
filesystem optimized writes write bandwidth significantly higher read bandwidth filesystem optimized reading read bandwidth significantly higher write bandwidth 
results running benchmarks table 
expected random access pattern bandwidths lower sequential access pattern bandwidths bandwidths sequential access pattern close see table 
difference attributable overhead necessary keep track file inodes indirect blocks 
unexpectedly sequential read bandwidth lower sequential write bandwidth significantly lower implying filesystem optimized reading writing 
bonnie shown sake filesystem aggressive readahead due incorrectly set parameters filesystem rotational delay read bandwidth higher write bandwidth bonnie 
unexpected result write allocate bandwidth higher overwrite bandwidth 
reason unexpected results increased fragmentation filesystem fsbench comparison fragmentation system bonnie due mechanisms space disk delete fragmentation resulting killing kill benchmark directory delete 
result synchronous read takes time due increased seek time writes asynchronous need find read modify indirect blocks 
note chapter results benchmark turn expected 
access pattern name bandwidth std dev 
read disk bandwidth sequential write allocate kbytes sec read kbytes sec overwrite kbytes sec random write allocate kbytes sec read kbytes sec overwrite kbytes sec table results spatial locality data benchmarks averaged trials 
benchmarking filesystems phase iii logical locality third micro benchmark data benchmark testing blocks allocated files logically related files directory 
benchmark files created initially written equals files range size bytes size buffer cache file size buffer cache files half size buffer cache forth bytes 
files placed directories algorithm laid appendix different file sizes distributed randomly directories 
creating initially writing files directory randomly chosen file directory created written manner creation order files directory known creation order 
complex method try avoid unrealistically optimal placement directories attributes file blocks happen benchmark just created files directory moving 
basis created measurements taken time open close files time open read close files time open write close files 
note file open time measurements caches flushed measurement 
measurements taken different access patterns creation order directories alphabetical random order directory random order 
results running benchmark sake table 
result glance unexpected write bandwidth lower read bandwidth especially asynchronicity writes fragmentation filesystem lack aggressive readahead sake 
file opened previous closed synchronous meta data read wait asynchronous writes queued earlier complete making asynchronous writes appear synchronous yielding lower final bandwidth 
unexpected result different access patterns essentially throughput write throughput creation order access pattern noticeably higher random pattern 
expected access pattern name total time std dev 
measurement read disk bandwidth creation order open close msec read msec kbytes sec write msec kbytes sec random directory open close msec read msec kbytes sec write msec kbytes sec random open close msec read msec kbytes sec write msec kbytes sec table results logical locality data benchmark 
total size data set mbytes spread files 
floor log benchmarking filesystems result random access pattern lower bandwidth random directory bandwidth turn lower bandwidth creation order bandwidth due increased overhead needed increasing randomness required translate name find file inode find file data 
reason pattern seen attributable fragmentation filesystem 
expected pattern seen results running fsbench ffs chapter 
previous spatial locality benchmarks similar bonnie benchmark similar iostone problems iostone fixed 
benchmark scalable realistic filesystem hierarchy 
separates reading versus writing data quantifies portion time due meta data versus data access measuring open close time separately 
benchmark perfect lacking example complete set access patterns inter file intra file 
phase iii meta data times benchmark benchmark phase iii designed measure common meta data operations create open delete unlink mkdir rmdir 
user results combined results workload characterizer described section predict performance workload filesystem system designer numbers rough pointers possible areas improvement 
pointers accurate possible benchmark running user level go far pinpointing problems kernel 
measurements benchmark times needed create files stat files creation random orders delete files creation random order directories stat directories creation random orders remove directories creation random orders 
measurements repeated sync operation 
time needed complete sync measured determine system call overhead value benchmark size attribute cache multiplied number repetitions user specifiable see appendix larger number files accurate final result 
results expected benchmark depend entirely filesystem implemented 
filesystem large meta data structures synchronous meta data writes perform poorly comparison filesystem small meta data structures asynchronous meta data operations 
ideally benchmark coupled information semantic guarantees filesystem 
example ffs create call returns user process user guaranteed file exists disk 
lfs guarantee see chapter chapter 
additional information user may get win performance potential loss reliability 
results running benchmark table 
comparing results sync deduced meta data operations involve synchronous requests 
results show substantial overhead required deal directories files allocating blocks directory file writing disk checking directory empty 
difference sequential random operations reflects additional time needed name translation finding inodes searching directory file results possible improvement find way reduce overhead benchmarking filesystems directory operations 
designer decide optimization done optimizing code changing fundamental meta data structures 
phase iv meta data part benchmarks phase iv designed help system designers pinpoint possible problems metadata operations precisely previous meta data benchmark section 
specifically try isolate attribute inode create time directory create time attribute access time name lookup time timing different meta data operations subtracting appropriate overlaps 
benchmark determines long takes allocate physical space new inode corresponding control structure 
measurements taken time needed create new files time needed stat files time needed create hard links files link file file stat link created 
measurement caches flushed base hierarchy read stat reach consistent start state 
initially thought time desired just create time hard link time initial stat creating file creating hard link require inode directory inode directory file written create having extra time needed allocate phase name total time elapsed std dev 
throughput iii create msec creates sec stat files sequential msec stats sec stat files random msec stats sec delete sequential msec deletes sec delete random msec deletes sec mkdir msec sec stat sequential msec stats sec stat random msec stats sec rmdir sequential msec sec rmdir random msec sec iv sync msec syncs sec create sync msec creates sec delete sequential sync msec deletes sec delete random sync msec deletes sec mkdir sync msec sec rmdir sequential sync msec sec rmdir random sync msec sec table results meta data time benchmark files directories benchmarking filesystems inode 
synchronous meta data read file attributes link time higher create time 
synchronous read needed factored time needed allocate space new inode equals create time stat time link time 
similarly time needed allocate space new directory equals time needed directory minus time needed create file extra stat needed inode create time 
caches flushed base hierarchy read measurements 
cases equals inode cache size times number repetitions user specifiable see appendix 
value underlying idea larger number files directories accurate final result 
benchmarks inode access time name lookup time interdependent difficult impossible isolate 
problem system call stat involves pathname translation attribute access 
problem occurs trying size attribute cache name translation cache see section 
putting needed attributes attribute cache needed translations name translation cache subtracting extra cache access time lower bound name lookup inode access time respectively 
implementation benchmark attribute access time dependent name translation time 
name lookup aspects translating entire pathname finding file directory benchmark uses different hierarchy aspect name lookup directory uses hierarchy distinct files pathname translation uses hierarchy distinct paths see appendix algorithms create different hierarchies 
note filesystems handle aspects uniformly 
benchmark average attribute name translation cache sizes attributes fit attribute cache translations needed may necessarily fit name lookup cache name lookup directory pathname translation 
assumption attribute cache larger name cache 
hierarchy files consists distinct isomorphic hierarchies files links files hierarchy 
basis measurements reading stat links creation alphabetical order reading links randomly directory reading links randomly 
measurement name cache flushed file attributes read inode cache stat 
number files smaller size attribute cache hard links read attributes cache pathname translation name cache directories read 
paths fit name cache part benchmark measures time needed find specific name directory file buffer cache different access patterns 
hierarchy distinct directories hard link directory file previous hierarchy 
hierarchy time read random permutation hard links measured 
name cache flushed files read attribute cache measurement 
case directory file may cache benchmark measures time needed read multiple directory files disk find name 
inode access benchmark uses results hierarchy name lookup benchmark 
inode access benchmark times needed read attributes files hierarchy distinct files benchmarking filesystems creation random order measured 
measurement caches flushed 
times measured lookup names creation random order respectively subtracted obtain lower bound inode access time 
results running benchmarks sake table 
seen time needed create hard link higher time create file accounting time needed read inode 
result suggests possibilities benchmark accounting operation needed create hard link creating hard links area improvement 
area improvement indicated results directory create time expected previous meta data benchmark 
operations needed create file needed creating directory take time rest time spent directory specific operations allocating space directory file writing directory file 
interesting result name lookup accounts higher percentage time accessing inodes sequentially randomly 
expect name translation random access pattern takes longer sequential access pattern correspondingly account higher percentage inode access time 
additional seeks needed locate inodes disk random access pattern dominate 
looking directories takes time looking files unsurprising translations parent directories hierarchy files fit cache hierarchy directories 
benchmark name total time std dev 
throughput derived results create msec creates sec creating hard link requires time creating file stat msec stats sec hard link msec sec create msec creates sec making directory takes times time creating directory 
mkdir msec sec name lookup sequential msec lookups sec name lookup accounts time required accessing inodes sequentially time accessing inodes randomly 
random dir msec lookups sec random level msec lookups sec random msec lookups sec inode access sequential msec stats sec see name lookup 
random msec stats sec table results second meta data benchmark files directories files directories benchmarks 
benchmarking filesystems phase iv readahead data benchmark phase iv looks degenerate cases filesystem readahead detracts improves performance 
example seltzer smith running benchmark reads random kbyte blocks file 
filesystem test performing block size kbytes 
result kbyte read invoke readahead random pattern second kbyte read slowing randomly placed kbyte block 
benchmark times reading blocks file patterns 
different block sizes half filesystem block size filesystem block size times filesystem block size 
size file equals size buffer cache times number repetitions user specifiable see appendix 
buffer cache flushed test pattern consistent start state 
expected result throughput increase gap size decreases regardless block size 
gap size decreases number blocks readahead increase cost reading ahead unnecessary block amortized 
shows results running benchmark sake 
unsurprisingly shape curves expected 
interesting result oscillations kbyte block case oscillations depend readahead invoked block block read kbytes kbyte block bandwidth higher second kbytes unneeded block read 
readahead bandwidths different block gap sizes phase iv concurrency micro benchmark tests filesystem handles concurrent processes making requests benchmarks described sections 
benchmarks run isolation results basis comparison results benchmark running concurrently 
percent bandwidth gap size percent bandwidth gap size percent bandwidth gap size kbyte blocks kbyte blocks kbyte blocks benchmarking filesystems benchmark starts just children runs combinations benchmarks 
children maximum number children user specifiable defaults different combinations benchmarks run user specifiable defaults 
results running benchmark children table table 
large file data benchmarks spatial locality sequential random access patterns lose run benchmarks 
sequential access benchmark loses bandwidth reading just able readahead blocks seeks files directories mixed 
meta data benchmarks lose run large file data benchmarks reasons 
caches flushed meta data benchmarks just buffer cache result part data benchmark timed result run benchmark interfering flushing cache 
note flushing buffer cache data benchmark affect meta data benchmark flushing buffer cache meta data benchmark affect data benchmark 
secondly especially sequential access benchmark read throughput drastically lower seeks mixed due disk activity 
process management issue 
process benchmark run interruptions 
processes benchmark block benchmark run especially reads mentioned get queued disk accesses get slowed 
affect benchmarks file reasons data benchmark running concurrently cache flushing benchmark affecting result data benchmark meta data benchmark secondly spreading files different directories see appendix seeking different parts disk going leading original lower throughput 
hold children case 
better way test concurrency compare times needed run entire benchmark comparison benchmarks 
due death sake able tested 
table concurrency results children 
numbers average percentage result running benchmark see previous sections 
number benchmark row second column 
abbreviations spatial locality sequential access spatial locality random access logical locality name lookup 
benchmarking filesystems summary micro benchmarks test aspects filesystem design block allocation files readahead policy meta data operations name lookup concurrent accesses filesystem 
stated cut complete suite benchmarks test filesystem functionality design laid chapter 
chapter possible extensions fsbench 
fsbench tries adhere guidelines benchmarking approach stated chapter 
meet criteria specified chapter scalable measures filesystem functionality tightly specified comparable filesystems running operating system hardware prescriptive 
targets system designers users trying decide system buy dividing micro benchmarks phases actively acknowledging split audience facilitating usability 
fsbench perfect 
describing workload characterizer combined micro benchmarks yields generally applicable benchmark problems implementation fsbench discussed 
problem fsbench unix oriented fsbench assumes filesystems hierarchical directory structure support hard links buffer attribute name translation caches 
assumptions hold filesystems 
logistical problem fsbench time needed run rudimentary set benchmarks 
sake fairly fast disk today technology benchmark took approximately day run number repetitions set 
times long time needed run chen self scaling benchmark 
large amount time required run benchmark mainly due time needed flush caches meta data benchmarks ffs meta data operations synchronous 
problem severe appears numbers published complete set benchmarks need run 
situation researcher probably dedicated test system conduct experiments anyway 
tweaking performance appropriate micro benchmark child child child percentages table concurrency results children 
abbreviations 
benchmarking filesystems run takes time 
sure tweak adversely affect aspects system entire suite run 
problem fsbench occurs run new filesystem 
clean filesystem placement files directories attributes optimal occur fragmented filesystem exist 
solution problem age filesystem 
simple method appendix keith smith harvard working accurate method age filesystems 
workload characterizer second part benchmark workload characterizer generate statistics target workload 
results combined statistics gathered filesystem fsbench 
currently workload characterizer consists perl script requires input nfs trace generated modified version 
trace formats accommodated writing wrapper script transform input trace format required modifying current scripts handle input trace format 
workload generator workload characterizer useful tool users trace workload may want analyze performance projected workload 
chapter previous workload generators new idea workload generator discussed 
statistics gathered workload characterizer script percentage calls reads writes creates deletes lookups 
percentage reads sequential random percentage writes sequential random average number open files standard deviation average logical snapshot output running ls traced filesystem incorporated statistics file patterns files referenced directory versus files referenced filesystem hierarchy gathered 
purpose workload characterizer benchmarking approach generally applicable 
suite micro benchmarks suffice determine performance system real workload 
combining results suite microbenchmarks fsbench statistics generated workload characterizer described components form complete filesystem benchmark help system designers find possible areas improvement system predict performance filesystem workload useful users trying decide system run 
difficult part goal discovering way combine sets results yield accurate prediction performance filesystem workload 
idea thesis calculation similar determine average number cycles instruction cpi processor 
cpi calculation number cycles required instruction multiplied percentage instruction occurs sum different benchmarking filesystems instructions equal average number cycles instruction 
similarly predict workload perform filesystem calculations meta data operation operation occurs workload percentage multiplied throughput measured meta data benchmark 
multiplied throughput sequentially stat ing files deletes throughputs random pattern lookups throughput randomly stat ing directories throughput randomly stat ing files averaged throughput randomly stat ing directories logical snapshot number directories number files explicitly determined 
data operations percentage reads percentage sequential reads percentage disk bandwidth attained sequential read file percentage random reads percentage disk bandwidth attained random read file similarly writes data operations average number open files percentage reads percentage disk bandwidth attained reading files random order percentage writes percentage disk bandwidth attained writing files random order 
logical snapshot percentage reads writes fall different access patterns explicitly determined 
general logical snapshot different access patterns files file determined 
note incorporating logical snapshot implemented due time constraints 
characterization maps performance different aspects filesystem usage target workload 
way system bad meta data performance perform database workload databases single large files 
reason percentage disk bandwidth attained actual throughput data reads writes factor underlying hardware 
summary chapter filesystem benchmarking approach consisting separate components suite micro benchmarks workload characterizer 
approach actual implementation fsbench plus perl script described 
recall chapter criteria judge filesystem benchmark prescriptive filesystem bound scalable comparable generally applicable tightly specified 
benchmark fulfills criteria 
scales measuring cache sizes take forever run generally applicable separation workload filesystem results presents comparable prescriptive 
tightly specified running conditions report format stated 
main failing benchmark complete fsbench needs extended measure cache behavior example workload characterizer needs take account different access patterns single file different files 
benchmarking filesystems seltzer smith balakrishnan chang padmanabhan file system logging versus clustering performance evaluation proceeding usenix technical conference 
benchmarking filesystems chapter benchmark chapter presents example benchmark previous chapter 
parts experiment running fsbench different filesystems ffs lfs characterizing target workload predicting filesystem better workload testing prediction 
system experiment virtual mhz sparcstation running experimental bsd lite kernel lfs fixes ordered blocks vnodes fragments extensions support journaling filesystem 
disk fujitsu exa gbyte rpm disk ms average seek time kbyte disk cache 
note ffs lfs underlying operating system hardware 
base configuration differences performance ffs lfs due solely design implementation filesystems 
base configuration comparisons questionable performance differences attributable aspects operating system 
fsbench results ffs lfs table presents results running initial disk measurements fujitsu disk virtual 
note write bandwidth block device low write synchronous requires rotations rotate appropriate position write kbyte block expected bandwidth kbytes sec approximately twice seen 
reason explain behavior write write verify just write 
table presents results running fsbench filesystem running ffs lfs disk sd 
note ffs kbyte blocks kbyte fragments lfs kbyte blocks fragments 
filesystem test aged algorithm outlined appendix benchmarking filesystems ffs results observations name read measurement write measurement kbytes sec kbytes sec kbytes sec kbytes sec msec msec msec msec table initial disk measurement results benchmark measurement result ffs result lfs spatial locality sequential access write allocate kbytes sec kbytes sec read kbytes sec kbytes sec overwrite kbytes sec kbytes sec spatial locality random access write allocate kbytes sec kbytes sec read kbytes sec kbytes sec overwrite kbytes sec kbytes sec logical locality creation order read kbytes sec kbytes sec write kbytes sec kbytes sec logical locality random dir 
read kbytes sec kbytes sec write kbytes sec kbytes sec logical locality random read kbytes sec kbytes sec write kbytes sec kbytes sec metadata time create creates sec creates sec stat sequential stats sec stats sec stat random stats sec stats sec delete sequential deletes sec deletes sec delete random deletes sec deletes sec mkdir sec sec stat sequential stats sec stats sec stat random stats sec stats sec rmdir sequential stats sec sec rmdir random stats sec sec table results fsbench benchmarking filesystems sequential read bandwidths high due aggressive readahead policy setting filesystem parameters optimize reads 
virtual rotational delay set 
logical locality benchmark note original expectation bandwidths decrease increasing randomness met 
remember asynchronous writes benchmark mixed synchronous meta data reads aggressive readahead write bandwidths substantially lower read bandwidths 
directory operations take time name lookup time minimal removing directories access pattern sequential versus random significantly impact throughput 
surprising ffs layout policy putting different directories different cylinder groups putting files directory cylinder group 
comparison observations lfs results writes asynchronous filesystems better throughput numbers lfs due reasons 
largest file mbytes smaller files logical locality benchmark meta data throughput impacts performance 
increase throughput lfs corresponds increase meta data write throughput data write throughput sequential lfs necessarily ffs logical locality benchmark 
importantly file hierarchies spread files different directories hurts ffs performance helps lfs performance differences disk layout algorithms ffs aims logical locality lfs exploits current temporal locality 
write performance improves read sequential performance decreases mainly clustered reads turned due oversight noticed late 
random read performance decreases significantly due different block sizes 
ffs kbyte block lfs kbyte block 
result reading file randomly required seeks lfs ffs 
logical locality benchmark random write bandwidths approximately reflecting fact lfs need find overwrite previously allocated blocks 
meta data write numbers higher reflecting asynchronicity operations 
result impact name lookup seen throughput removing directories random order 
data read performance meta data read performance general decreased 
partially due turning clustered reads 
exception degradation performance stat ing directories random order performance similar stat ing files random order 
reason exception lies layout policy lfs ignores logical locality aims temporal locality 
result directories created directories inodes placed close disk leading fewer seeks yielding better performance 
note performance stat ing directories sequential order worse stat ing files sequentially 
due turning clustered reads interleaving inodes directory files disk 
benchmarking filesystems characterizing workload workload experiment nfs trace filesystem traffic gathered system group harvard course days october 
trace consists accesses server dedicated nfs server network appliances 
modified version utility watches ethernet nfs requests gather trace 
normally just increments counters gather statistics modified log nfs requests 
traces originally blackwell find better heuristics decide invoke cleaner lfs 
note original trace gbytes data requests 
disk virtual gbyte size data set approximately tenth size original randomly chosen original data set trace pared appropriately 
results running scripts trace checkpointing requests table 
origin trace nfs surprising requests meta data requests majority meta data requests read requests 
surprising ratio reads writes ratio sequential random writes comparison earlier studies 
read write ratio understandable trace trace requests nfs server result read requests fulfilled client caches captured 
sequential random ratio writes requests just trace capturing earlier requests conjecture borne decrease percentage random writes rest trace 
number random writes higher expected may effect resulting randomly chosen data set 
predictions statistics section mapping algorithm described chapter presents predictions information 
general lfs outperform ffs factor lfs finish trace time takes ffs finish running trace 
actual shape curves predictions 
ffs lfs curves plotting actual time needed complete trace roughly shape 
secondly higher performance prediction factors second third requests filesystems finish requests faster series requests 
benchmarking filesystems number requests sequential reads random reads reads sequential writes random writes writes avg 
open files std 
dev creates deletes lookups table workload characterization benchmarking filesystems prediction ffs lfs performance testing prediction predictions section tested running trace ffs lfs 
performance metric time needed complete operations trace 
running trace consists phases creating base hierarchy aging hierarchy completing operation trace filesystem 
creating base hierarchy difficult logical snapshot filesystem taken trace began 
result perl script written determine inode numbers trace mapped directories ones mapped files associated operations 
sizes files determined finding maximum offset requested size encountered 
mapping inode number directory file hierarchy randomly created modified versions algorithms described appendix names pre determined putting files level hierarchy files randomly placed directories 
artificial hierarchy put new filesystem aged algorithms described appendix run trace hierarchy operations trace mapped actual filesystem calls getattr lookup stat setattr chmod timestamps original trace ignored prediction factor number requests ffs lfs benchmarking filesystems way determining requests dependent ones 
result assumption requests interdependent operation began soon previous completed 
presents results running trace compares predicted ratios performance actual ratios 
seen prediction algorithm 
manage predict lfs perform better ffs predict actual ratio 
problem mapping function different operations meta data data weighted differently uses actual throughput uses percentage throughput attained data reads weighted twice file performance inter file performance 
due time constraints mapping function thoroughly considered manipulated 
believe right approach appropriate adjustments mapping function observations performance filesystems accurately predicted 
performance ffs lfs trace time complete sec number requests ffs lfs benchmarking filesystems comparison predicted performance actual performance baker hartman kupfer shirriff ousterhout 
measurements distributed file system proceedings th symposium operating systems 
blackwell harris seltzer 
heuristic cleaning algorithms log structured file systems proceedings usenix technical conference 
performance ratio ffs lfs number requests actual predicted benchmarking filesystems chapter existing benchmarks measure filesystems inadequate lacking full functionality scalability general applicability possibly presenting results meaningless format 
thesis tried point wrong current benchmarks determine criteria judge benchmarks needed functionality filesystem benchmark propose implement benchmarking methodology meets goals 
goal thesis partially succeeded 
hand prescriptive scalable tightly specified 
measures filesystem functionality previous benchmarks complete see section extensions 
comparable different filesystems running operating system extended see section comparable systems 
unfortunately generally applicable moment prediction algorithm tuned correctly 
result benchmark useful system designers better understand system tune system prediction algorithm accurate looking benchmark decide system buy wait release 
prediction algorithm essential system designers anyway compare systems directly compare results fsbench determine differences filesystems probably caused performance results 
determine aspects system change order improve performance just look directly results fsbench workload characterizer get idea 
accurate comparison systems needed benchmark fails give rough idea 
approach ruled thoroughly investigated 
benchmarking filesystems possible directions improving prediction algorithm include enhancing fsbench writing workload generator extending benchmark entire operating system 
extending fsbench stated previously fsbench merely rudimentary suite filesystem micro benchmarks 
possible extensions fsbench include initial disk measurements discover disk caching algorithm temporal locality micro benchmark micro benchmark determine filesystem cache management disk scheduling queuing micro benchmark extension fsbench distributed filesystems 
purpose discovering disk caching algorithm help determine performance gain due clever filesystem due clever disk 
scsi disks today complex track buffers cache data read requests 
seagate disk sake example recognize sequential access pattern start reading ahead sectors 
random access pattern hand disk bother expend additional overhead needed readahead 
disks dec disk harvard alpha put passes underneath head track buffer 
robert morris wrote try determine disk caching policies finding track track seek times 
iterates different gap sizes 
gap reads random sector disk measures time needed read sector gap disk determine sector gap track buffer see example 
unfortunately benchmark simplistic determine disk caching policy different access patterns may evoke different caching policies 
just importantly mapping result filesystem performance non trivial 
extension fsbench discover data aged cache 
micro benchmark complete task written takes unreasonable amount time complete 
current benchmark measurements file size estimated size buffer cache 
measures long takes change write byte filesystem block iterating blocks file times number repetitions see appendix 
time fsync file blocks buffer cache clean second measurement fsync returns dirty blocks file written disk 
measurement repeated times try increase accuracy final average 
main loop iterates loop takes time 
loop time needed change byte sleep seconds fsync file measured repeated block file times 
time approximately time measured change byte file time fsync clean file data flushed cache 
case blocks file upper bound approximately update daemon flushes dirty data buffer cache disk run 
benchmark works takes long practical 
information combined information average lifetime files determine set correctly 
fsbench extended include temporal locality benchmark match existing spatial logical locality benchmarks write analog readahead microbenchmark 
example benchmark append file write file sleep minutes write file read file 
filesystem ignores temporal locality ffs reading file sequentially yield benchmarking filesystems result matter file written 
filesystem exploits temporal locality lfs reading file sequentially difficult 
purpose write analog readahead microbenchmark test filesystem disk scheduling algorithm look degenerate write patterns 
example pattern write blocks overwrite block see requests queued disk dequeued 
particular example give desired answer system writes asynchronous 
extension discussed enhance fsbench measure distributed filesystems 
microbenchmark measure network rpc latency needed method determining data lost 
extensions include latency test security benchmark crash recovery benchmark 
output 
graph determined sectors immediately sector read cached track track seek time approximately milliseconds 
result random pattern 
example sectors read time disk start reading ahead sectors 
scsi disks complex complex benchmark needed try understand behavior 
milliseconds gap size benchmarking filesystems workload generator area devise workload trace generator generate input workload characterizer described chapter real input trace difficult impossible obtain 
generator take input parameters values easily obtainable users size filesystem depth number files number directories average number running processes 
previous workload generation includes cmu workload model distributed file servers university saskatchewan 
designed generate filesystem traces system call model models workload combining micro models micro model models file patterns application 
problems capture inter application dependencies saving files editor compiling difficult model different workloads underlying micro models written non trivial task 
canada generates workload models distributed file servers specifically nfs parameters frequency distribution requests server percentage requests reads request interarrival time distribution file referencing behavior files touched distribution sizes read write requests 
looks promising currently useful nfs workload generation generally applicable 
trying attain holy grail workload generation 
idea somewhat similar projects mentioned 
idea hierarchical statistical generator 
lowest level hierarchy consist suite models modeling different file access pattern 
example pattern system binary probably create write close open read close repeated temporary file access pattern probably create write delete 
level modeling generates filesystem requests file 
level generates workload trace combining different file traces file level model choose requests level choose access pattern start file directory 
division labor modeling simpler model responsible fewer parameters 
realistic inter file dependencies incorporated example application open read close source files directory source tree creating writing closing object files executables target directory 
level added top level generate load distributed file system level combine client workloads generate server workload 
see overview approach 
top levels hierarchy difficult implement generator 
combine traces need assumptions client server 
requests interdependent require example assumption response time machine independent requests require assumption 
determining requests dependent filesystem response time cpu speed determining appropriate inter arrival time non trivial 
idea successful advantages previous methods 
filesystem system call level model filesystem ffs lfs nfs afs 
scalable load client number clients size filesystem simply increasing benchmarking filesystems size name space second level hierarchy 
importantly fairly representative reality modeling inter file dependencies application inter application dependences 
example user editing files window save files going window compile files 
unfortunately idea tested conjecture possible solution holy grail workload generation 
overview hierarchical statistical generator path discussed method characterize operating system just filesystem 
problem research papers aspect operating system compared different operating systems 
example original lfs ffs sunos lfs sprite different operating systems compared show lfs performed better ffs general 
situation question arises performance gain attributed aspect sprite filesystem 
fsbench extended measure entire operating system cross platform comparisons alleviate questions 
aspects virtual memory system tends closely linked filesystem process management need measured interdependencies discovered accounted 
bunt synthetic workload model distributed system file server performance evaluation review june 
server model client model client model combines different client traces 
chooses access pattern file 
file model file model file model chooses request file 
benchmarking filesystems ebling satyanarayanan extensible file generator proceedings acm sigmetrics conference measurement modeling computer systems may 
rosenblum ousterhout design implementation log structured file system acm transactions computer systems february 
benchmarking filesystems acknowledgments margo seltzer thesis advisor mike smith brad chen members thesis committee keith smith know filesystems robert morris smart person cliff young trevor blackwell thomas friends james gwertzman fellow thesis writer parents erik benchmarking filesystems appendix table summarizes table summarizes 
information see bsd system manager manual published reilly associates 
field description tin number characters read terminals past seconds tty number characters written terminals past seconds sps disk sectors transferred second averaged past seconds tps disk transfers second averaged past seconds disk milliseconds average seek including implied seeks rotational latency percentage cpu time user mode past seconds ni percentage cpu time user mode running processes sy percentage cpu time system mode id percentage cpu time idle mode table seconds total times outputs line fields 
benchmarking filesystems field description number processes run queue number processes blocked resources paging number processes runnable short sleeper avm number active virtual pages belonging processes running run seconds fre number virtual pages free list flt number page faults second averaged past seconds re number page reclaims second averaged past seconds number pages attached averaged past seconds pi number pages paged averaged past seconds po number pages paged averaged past seconds fr number pages freed second averaged past seconds de number pages anticipated short term memory shortfall averaged past seconds sr number pages scanned clock algorithm averaged past seconds disk number disk operations second paging usually split available drives number device interrupts including clock interrupts averaged past seconds sy number system calls averaged past seconds cs cpu context switch rate switches interval averaged past seconds percentage cpu time spent user mode sy percentage cpu time spent system mode id percentage cpu time spent idle mode table seconds total times outputs line fields 
benchmarking filesystems appendix fsbench command line options command line options running fsbench described table 
required option working directory benchmark 
initial benchmarks run device name size need specified scripts need customized 
benchmark allowed write raw disk specified script needs customized 
option specifies number repetitions required accuracy option 
determine repetitions benchmark run determine size files number files 
idea larger number repetitions longer fsbench takes run accurate final result options currently implemented trivial add options allow user specify various cache sizes running phase ii options specify subset micro benchmarks run 
possible extension separate number times benchmark repeated multiple cache sizes various benchmarks 
way cache size multiple option increase scalability benchmark 
benchmarking filesystems option argument default description tells benchmark directory run tests 
tells benchmark run phase tells benchmark device run initial disk measurements sd 
option required phase run 
tells benchmark large device specified 
option required phase run 
tells benchmark allowed run write tests phase tells benchmark maximum number child processes spawn concurrency test phase iv 
tells benchmark number different combinations micro benchmarks concurrency test phase iv 
tells benchmark times run benchmark 
tells benchmark run phase iv 
table command line options fsbench benchmarking filesystems appendix fsbench creating hierarchies fsbench functions create filesystem hierarchies creates hierarchy distinct files creates hierarchy distinct paths distinct directories parameter passed function 
functions created files directories placed directory large name lookup time directory disproportionately large 
hierarchy distinct files files placed level hierarchy lowest level hierarchy 
rule files directories allowed directory 
number levels hierarchy equals ceiling log total number files 
value easily changed user specifiable 
creating hierarchy distinct directories similar differences 
entire hierarchy consists directories files 
secondly determining depth hierarchy number files width level hierarchy desired depth hierarchy total number directories 
rule allowing maximum files directories parent directory applies 
benchmarking filesystems appendix fsbench flushing caches caches sized fsbench flushed reliably phases iii iv 
flush buffer cache file times estimated size buffer cache written read number repetitions specified user defaults 
writes reads sequential 
flush attribute cache hierarchy times estimated size attribute cache distinct files stat 
flush name translation cache hierarchy times estimated size name cache distinct directories stat 
note underlying assumption cases read put cache 
benchmarking filesystems appendix aging filesystems run benchmark trace chapter filesystem represent real filesystem steps taken 
logical snapshot filesystem ls constructed algorithms appendix put disk iterating tree directory file created initially written size parsed snapshot 
filesystem aged manner 
half files deleted random order files recreated random order 
quarter files eighth files fourth files 
process repeated times 
determine aged filesystem utility written keith smith calculates fragmentation score percentage blocks optimally sequentially allocated length free extents left disk 
utility works ffs 
statistics gathered maximum number contiguous blocks filesystem block size filesystem fragment size rotational delay number free blocks number free fragments total number blocks allocated data files total number extents blocks average extent length blocks benchmarking filesystems percentage blocks optimally allocated number free blocks total number extents blocks average size free extent total number blocks allocated total number extents blocks average size allocated block extent determine algorithm worked snapshot existing filesystem put clean filesystem aged 
resulting fragmentation score calculated compared score original filesystem 
results table 
disk approximately twice size disk original filesystem actual fragmentation artificial filesystem comparable worse 
indication disk larger number free blocks higher correspondingly average free extent length larger 
result due fact ffs tries place files cylinder group parent directory minimizing number extraneous cylinder groups touched 
note algorithm help harm lfs performance 
help lfs meta data placed blocks file close files created deleted entirety 
hand meta data may near corresponding data 
parameter original artificial blocks data number extents average extent length percentage blocks optimally allocated free blocks number extents average extent length allocated blocks data meta data number extents average extent length table filesystem aging statistics 
