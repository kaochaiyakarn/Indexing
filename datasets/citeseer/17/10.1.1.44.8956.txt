binary decision diagrams network workstations rajeev ranjan robert brayton alberto sangiovanni vincentelli email brayton eecs berkeley edu department electrical engineering computer sciences university california berkeley ca usa success binary decision diagram bdd synthesis verification algorithms depend ability efficiently manipulate large bdds 
algorithms manipulation large binary decision diagrams bdds network workstations 
provides collection main memories disks effectively create manipulate large bdds 
efficient memory resources completing execution reasonable amount wall clock time extension breadth technique manipulate bdds 
bdds partitioned nodes set consecutive variables assigned workstation 
experimental results demonstrate capability approach point potential impact manipulating large bdds 
manipulation boolean functions important operations areas computer aided design logic synthesis testing checking sequential equivalence design verification efficiency logic function manipulations depends data structure representing boolean functions 
reduced ordered binary decision diagram robdd canonical directed acyclic graph representation boolean functions 
robdd henceforth referred bdd representation compact functions encountered practice 
canonicity compactness properties bdd led widespread usage area logic synthesis testing 
application bdd extended symbolic computation include symbolic simulation reachability analysis bdd formal design verification 
bdd representation suffers drawback size bdd required represent complex logic circuit large 
results large computation memory requirements 
problems tackled fronts 
reducing computation time kimura parallel algorithm construct bdds uses shared memory multiprocessor divide tasks performed parallel processors 
shared memory machine allows single global hash table maintain canonicity 
proposed breadth manipulation approach uses vector processor exploit high vectorization ratio long vector lengths performing bdd operation level level basis 
increasing available memory size bdd exceeds main memory bdd nodes swapped hard disk 
conventional depth bdd results random accesses memory leading large number page faults 
page access time order tens milliseconds large number page faults lead impractical amount wall clock time time spent processor doing useful quite small 
proposed breadth implementation approach regularize memory accesses leads fewer page faults 
result bdds large size nodes handled 
improved breadth algorithm enables manipulation bdds nodes 
propose technique manipulate bdds network workstations 
provides large amount collective memory resources main memories disks 
collective memory resources provide potential manipulate large bdds 
advantage approach compared existing ones fold 
approaches require special computing hardware shared multiprocessor vector processor part existing infrastructure 
secondly approaches limited memory available particular machine 
network workstations available memory increases significantly 
rest organized follows 
explain relevant attributes network workstations section bdd algorithm section 
explaining characteristics available resources algorithmic requirements propose new bdd algorithm network workstations section 
implementation details section 
experimental results section 
draw outline direction section 
network workstations network workstations computing resource uses building block entire workstation 
building blocks interconnected local area network ethernet fddi switched ethernet atm 
network workstations large computer system solve large scale problems attractive uses existing infrastructure opposed buying dedicated scalable parallel computer server shared memory multiprocessor machine 
system upgraded faster processors faster network larger capacity drams larger capacity disks network workstations leverage enhancements 
understand nature computing resource exploit fully match requirements bdd algorithms 
existing computing infrastructure year old technology may consist network workstations mhz processor kb cache mb main memory mb disk space 
takes microseconds access data main memory milliseconds move page memory disk main memory 
software overhead latency local area network order milliseconds bandwidths mbits second ethernet mbits second fddi network 
clear discussion time taken access data disk network times time access data main memory 
years networks expected faster terms latency software overhead bandwidth 
ratio time access remote memory involves network transaction vs time access main memory expected order 
qualitative analysis important implication distributing bdd nodes workstation memories 
developing distributed bdd algorithms message passing model computation assumed reasons closely resembles underlying architecture easy availability robust message passing software public domain 
message passing programming model cost communication explicit programmer worry resource management sending receiving messages orchestration collection processes spread workstations 
bdd algorithms implement bdd algorithms message passing model need design distributed bdd data structures 
important understand requirements bdd algorithms uniprocessor help guide design decision distributing data scheduling interprocessor communication 
conventional depth recursive bdd manipulation algorithm performs boolean operation traversing operand bdds path path basis see results extremely memory access pattern 
random memory access pattern spatial locality translates severe page faulting behavior bdd fit available main memory 
df op op terminal case op return result computed table entry op return result top variable df op op fx gx df op op equals return result find add unique table insert computed table op result endif return result depth bdd manipulation algorithm access main memory workstation involves network transaction aforementioned disk access behavior depth algorithm translates large number network transactions distribution bdd nodes main memories 
expensive access data network compared workstation main memory attempt depth manipulation algorithm meet limited success 
breadth iterative algorithm see figures attempts regularize memory access pattern traversing operand bdds level level basis customized memory allocator allocates bdd nodes specific variable id page 
result bdd constructed level level possible perform certain isomorphism checks constructing bdd 
redundant nodes created apply phase see result bdd eliminated bottom reduce phase see 
obviate need access bdd node determine variable id lookup table returns variable id bdd node pointer 
memory access pattern servicing request apply reduce phases regularized processing sorted order 
bf op op terminal case op return result min id minimum variable id max id number variables create request insert request queue min id top apply phase bf apply op min id max id bottom reduce phase bf reduce max id min id return request node forwarded breadth bdd manipulation algorithm bf apply op min id max id id min id id max id id process request queue variable id id request queue id empty request unprocessed request request queue id process request determining terminal case op fx gx result id minimum variable id fx gx result find add fx gx request queue id request result terminal case op result id minimum variable id result find add request queue id request result breadth bdd manipulation algorithm apply observations guide implementation breadth search algorithm 

need mechanism determine variable id bdd node pointer accessing bdd node 

processing request specific variable id apply phase need access bdd nodes variable id bf reduce max id min id id max id id min id id variable id id process request queue request queue id empty process request request unprocessed request request queue id request forwarded request 
request forwarded request 
request equals request forward request request bdd node request 
request unique table id forward request bdd node insert request unique table id key request request breadth bdd manipulation algorithm reduce 
forwarding mechanism allows temporary creation redundant nodes facilitate creation request workstation servicing request workstation 
binary decision diagrams network workstations issues issues need implement breadth bdd manipulation algorithm 
node distribution distribute bdd nodes workstations network 
number nodes assigned workstation proportional memory resources available workstation 
high overhead latency accessing remote memory performing network transaction implies performing large number communications involve small messages result unacceptably high performance penalty 
distribution results exchanging information level bdd node satisfactory 
naming bdd nodes uniquely identify bdd node regardless resides network regardless workstation address space belongs 
single address space bdd node uniquely identified pointer need extend pointer mechanism generalized address bdd node 
variable id determination determine variable id bdd node generalized address 
breadth algorithm need determine variable id bdd pointer avoid random access bdd node 
bdd node index lookup table solution proposed unattractive case reasons workstation need maintain private copy lookup table determine variable id generalized address nodes bdd private copy updated time workstation allocates page memory generalized address augment bit address space may necessary implement node index lookup table hash table array 
designed generalized addressing scheme works conjunction partitioning scheme solve aforementioned problems resulting compact representation bdd nodes 
solutions node distribution breadth algorithm constructs result bdd level time accessing operand bdd nodes level level basis natural choice decomposition bdd partition levels 
number nodes partition bdd section proportional amount memory resources workstation flexibility determining location number levels partition 
example bdd section closer root nodes levels bdd section halfway root leaf nodes 
naming bdd nodes assigning nodes set consecutive variables workstation possible determine workstation bdd node resides knowing variable id variable id memory address tuple serve generalized address uniquely identifies node bdd 
variable id determination pair workstation number memory address represent generalized address uniquely identifies node bdd 
reason choosing variable id memory address tuple represent generalized address constraint specific partitioning scheme solve variable id determination problem free 
choice generalized address results compact representation bdd node 
partitioning scheme mechanism determine variable id need address issue perform computations related bdd sections assigned workstation 
servicing request apply phase may result creation request top variable id belongs workstation 
newly created request specific top variable id serviced workstation owns bdd section containing variable id request generated source workstation processed destination workstation long source workstation receives correct generalized address result processing request easy matter forwarding mechanism apply phase source workstation forwarding generated request generalized address 
request node gets generated source workstation shadow request node gets processed destination workstation call shadow node forwarding 
shadow nodes node creates shadow node processed apply phase accessing remote memory 
shadow node forwarding concept set request belong set consecutive variables assigned processor processed accessing remote memories 
mechanism shadow node forwarding helps separate computation communication collection sequential processes 
separation helps simplify development bdd package 
algorithm manipulation bdds 
breadth bdd manipulation algorithm obtained suitable modifications apply reduce phase breadth algorithm single address space 
assignment bdd sections imposes total order workstations 
workstation receives set request predecessor workstations apply phase 
apply phase modified process request bdd op op terminal case op processor id min id minimum variable id create request insert request queue min id proc id proc id bf apply recv proc id set requests bf apply op var id var id proc id processor id proc id bf apply send proc id proc id num processors proc id processor id proc id bf reduce recv proc id result bf reduce var id var id proc id processor id proc id id proc id bf reduce send proc id return result bf bdd algorithm variable ids belong workstation 
set generated shadow requests sent appropriate successor workstations processing 
workstation waits receive successor workstation generalized address shadow request gets forwarded 
performs modified request variable ids belong workstation 
reduce phase workstation sends set generalized addresses predecessor workstations 
procedure viewed top apply phase followed bottom reduce phase distributed bdd partitioned set sections set consecutive levels 
graphical representation concept illustrates algorithm 
communication serves glue hold computations performed different memories shadow node forwarding concept 
apply reduce phases processor pi ws ws ws apply phase receive request nodes processors pk send request nodes processors pk reduce phase process request nodes send forwarded results processors pk receive forwarded results processors pk process request nodes bdd manipulation algorithm implementation data structures bdd generalized address represents tuple variable id memory address bdd node represents generalized addresses bdd nodes 
bdd node pointer link bdd node hash chain 
utmost importance compact representation bdd node 
minimum requirement size bdd node bit memory pointers bytes bytes pointer bytes bytes representing generalized addresses 
custom memory manager page fits bdd nodes belong variable id custom memory manager aligns bdd node quad word boundary possible tag bits memory pointers see 
memory pointers require complement bit leaving total bits count internally mark status course bdd operation 
pointer pointer pointer complement pointer bit internal count bits bdd node data structure reduce phase bdd node obtained request node forwarded 
overload request data structure bdd node data structure request data structure limited bytes 
apply phase request represents operand bdd nodes generalized address requires bytes 
allow operand operations 
operand operations ite simulated combination operand operations necessary 
implementation issues issues unique breadth implementation 

shadow request duplication shadow request may multiple shadow request different workstations 
multiple shadow request identified request processed single request gets processed resulting generalized address sent workstations shadow request 

count management nonlocal bdd nodes request simplified accessing remote memory important create new shadow request process appropriate workstation count node unique table maintained correctly 
reduce phase redundant node generalized addresses point node successor workstation need adjust count remote bdd node 
achieved delayed evaluation avoid communication successor workstations completion request phase workstation 
delayed evaluation performed garbage collection step count remote nodes adjusted appropriately 

caching shadow request vs line issue remote requests shadow request cached need network transaction shadow request created apply phase 
high network overhead latencies may acceptable 
may change communication overlapped computation low latency low overhead networks pipeline small messages available 
experimental results heterogenous network workstations computing environment perform experiments 
environment contains approximately workstations mb mb available main memory mb mb available disk space mips processor 
pvm parallel virtual machine software provide communication workstations cluster bdd operation 
software permits network heterogeneous unix computers single large parallel computer providing user level routines send receive messages clusters workstations 
evaluate performance integrated bdd package sis 
order systematically analyse performance algorithms increase bdd size series sub networks examples nodes uniprocessor scheme scheme page faults elapsed time secs maximum page faults elapsed time secs theta theta theta theta theta theta table exploiting collective main memories iscas benchmark 
suitably taken sub networks benchmark shared bdd sizes outputs roughly multiple 
instance examples creating bdd outputs involve creating nodes 
subsections describe experiments highlight salient features approach 
exploit collective main memories main emphasis approach exploit collective main memory available workstations 
lead page faults reduced wall clock time complete computation 
observe phenomenon virtual machine consisting workstations 
results table 
table observe small bdds performance uniprocessor outperforms multiprocessor factor 
reason small examples result significant number page faults single processor network transaction overhead incurred multiprocessor approach resulted large elapsed time 
number bdd nodes increase causing uniprocessor implementation page fault enormously multiprocessor scheme outperforms uniprocessor scheme 
exploit collective disk space table indicates potential manipulating large bdds 
experiment increased number elapsed time nodes ws ws ws theta theta theta theta theta theta theta table bdds multiple workstations 
complete due disk space limitation data collected due time constraint bdd nodes manipulated increased extent fit disk space single workstation 
observe able manipulate bdds larger size collective disks workstations 
analysis experiments previous subsections results demonstrate key advantages manipulating bdds exploiting collective main memory improved performance collective disk space build large bdds 
note time taken manipulate bdds large 
monitored elapsed time algorithm large part elapsed time due network transaction 
performance approach significantly dominated penalty incurred message transfers 
hope ongoing research community includes asynchronous transfer mode parallel file server active message passing result low network latency overhead 
approach take advantage performance enhancements achieved research community 
algorithm manipulation binary decision diagrams bdd network workstations 
provides collection main memories disks effectively create manipulate large bdds 
breadth manipulation technique exploit memory resources efficiently 
prototype implementation points potential impact approach manipulating large bdds 
effectiveness approach demonstrated experiments 
serves proof concept approach 
development stage need add features support assortment bdd operations 
furthermore expect carry multitude optimizations various steps improve computational efficiency 
apart adding necessary features bdd package garbage collection quantification routines plan extend current package features 
utilizing computation power current approach computations carried processor time 
exploited memory resources workstations network 
plan extend approach utilize parallel computation power offered 
achieved pipelined processing request apply reduce phase 
pipelined scheme request processed processor concurrently 
processor need wait collect request predecessor processors apply phase successor processors reduce phase 
result improved computation time processing requests 
drawbacks scheme line issue remote requests result significant increase network transaction 
observed section performance approach network latency overhead 
ii result duplication effort due inability recognize request processed apply phase 
consequently increase requirements amount reduce operation 
need investigate benefits approach view drawbacks 
plausible solution adopt scheme extremes issue remote requests group 

dynamic load balancing current scheme variable indices statically distributed processors 
disadvantage number nodes certain levels grow large leads uneven distribution bdd nodes 
better approach dynamically change distribution set variables processors balance number nodes processor 
akers 
binary decision diagrams 
ieee trans 
comput june 
anderson culler patterson 
case network workstations 
technical report ucb erl electronics research lab univ california berkeley ca nov 

efficient breadth manipulation binary decision diagrams 
proc 
intl 
conf 
computer aided design pages nov 
aziz 
cheng kam krishnan ranjan singhal 
wang brayton sangiovanni vincentelli 
bdd environment formal verification 
proc 
design automation conf pages june 
bryant 
graph algorithms boolean function manipulation 
ieee trans 
comput aug 
bryant 
methodology hardware verification logic simulation 
journal association computing machinery apr 
burch clarke mcmillan dill 
sequential circuit verification symbolic model checking 
proc 
design automation conf june 
coudert madre 
verification sequential machines symbolic execution 
sifakis editor proc 
workshop automatic verification methods finite state systems volume lecture notes computer science pages june 
geist beguelin dongarra jiang manchek sunderam 
pvm user guide manual 
oak ridge national laboratory sept 
kimura clarke 
parallel algorithm constructing binary decision diagrams 
proc 
intl 
conf 
computer design pages nov 
mcmillan 
symbolic model checking 
kluwer academic publishers 

breadth manipulation boolean functions vector processing 
proc 
design automation conf pages june 

breadth manipulation large binary decision diagrams 
proc 
intl 
conf 
computer aided design pages nov 
singh lavagno moon stephan brayton sangiovanni vincentelli 
sis system sequential circuit synthesis 
technical report ucb erl electronics research lab univ california berkeley ca may 
touati lin brayton sangiovanni vincentelli 
implicit state enumeration finite state machines bdd 
proc 
intl 
conf 
computer aided design pages nov 
