trawling web emerging cyber communities ravi kumar prabhakar raghavan sridhar rajagopalan andrew tomkins ibm almaden research center harry road san jose ca usa 
ravi sridhar tomkins almaden ibm com web large number communities groups content creators sharing common interest manifests set interlinked web pages 
commercial web directories contain order communities particular interest emerging communities little representation fora 
subject systematic enumeration emerging communities web crawl call process trawling 
motivate graph theoretic approach locating communities describe algorithms algorithmic engineering necessary find structures subscribe notion challenges handling huge data set results experiment 
keywords web mining communities trawling link analysis 
overview web known explicitly defined communities groups individuals share common interest web pages popular 
consider instance community web users interested porsche cars 
explicitly gathered resource collections yahoo recreation automotive models porsche devoted 
communities manifest newsgroups resource collections directories yahoo 
infoseek 
examples include popular topics major league baseball somewhat visible community phone card collectors 
explicit nature communities easy find simply matter visiting appropriate portal newsgroup 
estimate explicitly defined communities web today 
results suggest distributed chaotic nature content creation web resulted implicitly defined communities 
implicitly defined communities focus level detail typically far fine attract current interest resources large portals develop long lists resource pages 
viewed way methods developed identify web communities far nascent stage systematic institutionalized ontological efforts 
preview kinds communities extract web may underscore point community turkish student organizations community centered oil spills coast japan community people interested japanese pop singer 
reasons systematically extracting communities web emerge 
communities provide valuable possibly reliable timely date information resources user interested 
second represent sociology web studying gives insights intellectual evolution web 
portals identifying distinguishing communities target advertising precise level 
implicit communities outnumber explicit ones order magnitude appears defined manual effort successfully identify bring order implicit communities especially number continue grow rapidly web 
argue communities emerge web individual participants aware existence 
question automatically recognize identify communities clearly pass radar screen human ontological effort 
subject explicit identification large number implicit communities analysis web graph 
search resource gathering algorithms asked find pages specified topic 
scan web crawl identify instances graph structures indicative signatures communities 
analysis entails combination algorithms algorithmic engineering aimed enumerating occurrences subgraph signatures web 
call process trawling web 
process developing algorithm system process insights fine structure web graph emerge report 

related prior link analysis number search engines retrieval projects links provide additional information regarding quality reliability search results 
see instance kleinberg chakrabarti chakrabarti 
brin page bharat henzinger 
link analysis popular search tool 
focus article link analysis different purpose understand mine community structure web 
information foraging information foraging paradigm proposed pitkow rao 
authors argue web pages fall number types characterized role helping information forager find satisfy information need 
thesis recognizing annotating pages type provides value add browsing foraging experience 
categories propose finer hub authority view taken kleinberg clever project 
algorithms appear scale sizes interesting 
web database view web semi structured database advanced authors 
particular lore see abiteboul websql see mendelzon mihaila milo graph theoretic relational views web 
views support structured query interface web lorel websql respectively evocative similar sql 
advantage approach interesting queries including methods hits expressed simple expressions powerful sql syntax 
associated disadvantage generality comes computational cost prohibitive context 
lore websql examples projects space 
examples qs konopnicki shmueli carriere kazman weblog lakshmanan sadri subramanian parasite spertus 
data mining traditional data mining research see instance agrawal srikant focuses largely algorithms inferring association rules statistical correlation measures dataset 
notion trawling differs literature ways 

interested finding structures relatively rare graph theoretic signatures communities seek number handful single community 
contrast data mining tools look patterns support confidence 

exhaustive search solution space infeasible efficient methods priori agrawal srikant query flocks tsur market baskets distinct items orders magnitude items web pages case 

relationship exploit citation effectively join web points relation transposed version web pointed relation 
size relation potentially larger original points relation 
need methods implicitly original points relation computing citation relation explicitly 
algorithmic memory bottleneck issues graph computations addressed henzinger raghavan rajagopalan 
focus developing notion data streams model computation data secondary memory streamed main memory relatively static order 
show relationship problems theoretical study communication complexity 
relationship mainly derive impossibility results 
gibson kleinberg raghavan describe experiments web spectral methods extract information communities web 
non principal eigenvectors matrices arising kleinberg hits algorithm define communities 
give evidence non principal eigenvectors citation matrix reveal interesting information fine structure web community 
eigenvectors provide useful information contexts search clustering purely text corpora see deerwester relatively computationally expensive scale web 
addition need complete interesting structures left undiscovered 
second issue necessarily show long communities missed 
complementary issue false positives problematic 
contrast results indicate find coincidental false positives 
survey database techniques web relationships see florescu levy mendelzon 

strongly connected bipartite subgraphs cores websites part community frequently 
known recognized communities happens times competitive reasons sites share point view 
companies competing space sprint instance point 
instances second kind pages opposite sides thorny social issue gun control abortion rights 
case emerging communities happens third mundane reason 
pages point frequently simply creators aware presence 
linkage related pages established different phenomenon occurs repeatedly citation 
instance www swim org church html www kr search church korea html www com church contain numerous links korean churches pages trawling 
citation concept originated bibliometrics literature see instance white mccain 
main idea pages related frequently referenced 
assertion true web linking indicative academic discourse essential navigational element 
sprint example case ibm microsoft corporate home pages 
hand pages frequently cited 
thesis citation just characteristic developed explicitly known communities early indicator newly emerging communities 
words exploit citation web graph extract communities taken shape web participants realized formed community 
property distinguishes web interest 
linkage web represents implicit endorsement document pointed 
link entirely reliable value judgment sum collection links reliable accurate indicator quality page 
systems hits google clever recognize exploit fact web search 
major portals apparently linkage statics ranking functions text ranking functions linkage statistics relatively harder spam 
left mathematical version intuition developed 
web communities characterized dense directed bipartite subgraphs 
bipartite graph graph node set partitioned sets denote directed edge graph directed node node bipartite graph dense possible edges 
mathematically pinning density proceed hypothesis dense bipartite graphs signatures web communities contain core core complete bipartite subgraph nodes nodes recall complete bipartite graph node sets contains possible edges vertex vertex 
note deviate traditional definition allow edges leave values unspecified 
core small sized complete bipartite subgraph community 
find community finding core core find rest community 
second step finding community core done instance algorithm derived clever algorithm 
describe step detail 
focus rest novel aspect algorithms finding community cores efficiently web graph potential pitfalls process 
algorithms heavy aspects web structure emerged developed algorithms system explain proceed 
state fact random bipartite graphs 
derive precise hypothesis hypothesis applies web communities really modeled random graphs 
focus qualitative aspects imprecise hypothesis specific quantitative parameterization 
fact letb random bipartite graph edges directed set nodes set nodes random edges placed vertex vertex uniformly random 
exist functions high probability contains nodes nodes forming complete bipartite subgraph 
proof standard exercise random graph theory omitted details spelling values high probability derived easily 
instance easy show probability 
argue distribution links web community proceed hypothesis 
hypothesis random large dense bipartite directed subgraph web surely core 
glaring imprecision hypothesis meant dense large random bipartite subgraph 
answering question precisely require developing random graph model web 
second source imprecision phrase surely 
leave unspecified appropriate values state hypothesis largely motivate finding large numbers web communities enumerating cores web graph experiments validate approach 
note community may multiple cores fact emerges experiments 
note cores seek directed set pages hyperlink set pages assumption links set pages 
intuitively pages created members community focusing believe valuable pages community core contains 
reason refer pages contain links fans pages referenced centers community centers 

web structure modeling course designing algorithm web graph community cores discovered interesting phenomena guided algorithmic choices 
detail section 
description data source 

data source resources data source copy web alexa archives state internet 
crawl year half old consequently somewhat date 
purposes interesting data set allows discover communities emerging web year ago compare state web today communities better developed 
interesting consequences inherent resilience process relatively easy track today community fossil core extract year half old copy web pages core may longer exist 
revisit theme 
raw web crawl consisted terabyte web data tape 
data text html source represented content web pages average page containing kbytes text 
compared current size web see bharat broder volume data significantly smaller 
difference impediment implementing methods entire web point 
experimentation done single ibm pc intel mhz pentium ii processor memory running linux 
total running time experiment weeks 

fans step algorithm scan data set summarize identities content potential fans 
purpose pinpoint notion potential fan 
may view fans specialized hubs extensive resource lists discovered algorithms hits clever 
looked outputs clever search results created series taxonomy creation experiments 
analyzed hubs results looking syntactic principled notion characterizes hubs 
reliable characteristic hubs contained non nepotistic links resources 
non nepotistic links mean links pages sites 
chose syntactic definition potential fan page potential fan page links different websites 
purposes definition website field url 
original web pages approximately pages extracted tapes potential fan pages 
pages retained sequence hyperlinks occurring page discarding information 
keeping objective purely link information experiment 
conjecture content text information identify interesting communities content analysis communities suggested graph structure turn coincidences 
reasons done current experiment 
want study far go linkage information efficiency improvements retaining link information pages significant experiment feasible scale entire web 
began thesis moderate values say range cores identified graph analysis fact correspond real communities coincidences results show belief amply cores spurious 
henceforth speak operations fan pages think fan page sequence links devoid content 
point trawling process set potential fans remaining contention implies set potential centers remaining contention links listed current set potential fans 
folding page content trawling interesting issue subject ongoing research almaden research center 

mirrors shingles existing communities mirrored repeatedly fans centers 
extent inevitable testament value resource pages bring pages community 
surprisingly mirrors yahoo 
pages owned avatars yahoo 
phenomenon observed previously broder content web easy copy reproduce minor variations 
pages reproduced slightly modified forms instance claimed author different copy 
broder propose method identify eliminate duplicates adopt apply sequence links page entire page 
method constructs number local hashes web page compares smallest hash values called shingles detect duplication 
broder argue hash function number shingles chosen carefully high probability exact exact duplicates detected 
hand different pages accidentally accused duplication 
case approximate mirroring preserves links say fatal 
page approximately mirrored say times produce large spurious core core large number links preserved 
say potential fans approximately duplicated fashion spurious communities real ones 
consequently choose aggressive mirror elimination strategy 
number shingles maintain small page 
relatively small local window links compute shingles 
aggressive choices shingle algorithm parameters probably result distinct pages misidentified mirrors detects mirrors near mirrors reliably 
able effectively deal problem posed near mirrors generating spurious communities 
pages chosen potential fans mirror elimination removed pages refers number potential fans number potential centers remaining roughly times number potential fans stages 
natural question strategy overly aggressive 
convince examined hand sample deleted pages case deleted page mirror page 
duplicates due idiosyncrasies crawl 
instances urls foo com foo com clearly treated distinct 
problem plethora yahoo 
pages 
instances yahoo 
pages copies 
instance pages crawl content 
www com shop shop mo htm www shop shop mo htm www shop shop mo htm www der shop shop mo htm mirror deletion hope especially constraints memory hierarchies efficiently enumerate cores classical relational approach say sql statement database web equivalent websql 
denote number pages remaining size core lead running time grew roughly prohibitive larger 
essential better exploit detailed characteristics web graph prune data eliminating potential fans proved belong community describing process 
inferring understanding characteristics fascinating study web graph interest right 

degree distribution approach trimming data resulted analysis degrees web pages 
distribution page degrees remarkably simple law seen 
chart includes pages degree 
integer larger chance page degree 
unusually popular pages www yahoo com potential fans pointing excluded 
chart suggests simple relation degree values probability densities 
seen remarkably linear log log plot slope curve close 
allows state empirical fact 
indegree distribution 
empirical fact probability page degree roughly precise exponent slightly larger 
purposes close 
elementary probability see chance page degree proportional 
pruning centers degree argued earlier known established communities typically contain relatively dense bipartite cores 
reasons algorithms hits clever broad topic queries significant web presence terms number pages address topic 
large dense bipartite graphs contain instances small cores looking 
creates implementation problem algorithm list possible cores web graph stuck situation cores corresponded high level communities physics leave needle haystack problem find distinguish emerging new 
pruning degree simple method addressing potential problem 
delete pages highly referenced web home pages web portals yahoo 
altavista 
pages presumably referenced variety reasons having single emerging community safely eliminated consideration 
hand retain raise odds discovering spurious communities pages various subjects may contain links sites just creators convenience 
eliminate potential centers pages degree greater carefully chosen threshold issue particular choice posit pages listed web directory yahoo 
relatively uninteresting point view 
pages belong communities developed explicitly known 
note directory services listing explicitly known communities yahoo list pages 
approximate order magnitude number pages web today 
chance page known part explicitly known community 
empirical fact node degree larger 
exact constants turn critical calculation shows correct value 
conservatively set prune pages degree larger consideration centers 

trawling algorithms system far described preliminary processing steps data interesting phenomena degree distributions web graph 
turn details trawling cleaned data communities goal output non overlapping maximal set cores 
data potential fans remaining links potential centers 
potential fans afford enumeration algorithm form subsets potential fans subsets potential centers check core induced 
resort number additional pruning algorithms eliminate data 
simultaneously retain property pruned nodes links part unidentified core 
reducing data order magnitude fashion resort enumeration 
critical requirement algorithms phase 
algorithms implementable small number steps step data processed stream disk stored back processing disk 
main memory carefully 
operation employ sorting dataset efficient operation platforms 

iterative pruning looking cores clearly potential fan outdegree smaller pruned associated edges deleted graph 
similarly potential center degree smaller pruned corresponding edges deleted graph 
process done iteratively fan gets pruned centers points may degrees fall threshold qualify pruning consequence 
similarly center gets pruned fan points degree fall threshold qualify pruning 
obvious way kind pruning small datasets fails dataset large fit main memory 
case dataset large fit main memory 
represent url bit hash value 
avoid collision require bits 
edge web graph occupy bits storing source page destination page pair 
machines main memory 
allows represent edges main memory order magnitude small experiment scaled web 
necessary design pruning algorithms efficiently stream data secondary main memory 
luckily iterative pruning process reducible sorting repeatedly 
sort edge list source stream data eliminating fans low degree 
sort result destination eliminate centers low degree 
sort source destination reach point fans centers eliminated iteration 
fact necessary repeatedly sort suffices remember index memory pruned vertices generally pass pruned vertices hold main memory 
data sets containing identical data case edges sorted source sorted destination 
alternately scan data sets identifying pruning pages meet degree outdegree threshold 
hold index set vertices pruned iteration memory 
results significant improvement execution time calls sorting routine 
fact form pruning reduced computation data stream sorting significant 
impossible pruning method required indexing edges source destination 
index necessarily live disk accesses prove expensive due non locality disk access 
designing method streams data efficiently main memory relatively simple case iterative pruning 
considerably challenging pruning strategy sophisticated case inclusion exclusion pruning strategy describe 

inclusion exclusion pruning pruning strategy call inclusion exclusion pruning useful property step eliminate page contention discover output core 
name inclusion exclusion step include community exclude page contention fan center establishing part core 
important benefit pruning step represents useful progress discovering community pruning data 
note algorithm implementable relying holding data main memory 
fans resp 
centers choose inclusion exclusion pruning degrees resp 
degrees equal threshold resp 

relatively easy check nodes part core 
consider fan degree exactly denote set centers points 
core fans pointing center 
small values index fans centers check condition quite easily 
computation simply computing size intersection sets checking cardinality avoid having indices main memory 
notice need simultaneous access indices 
reason eliminate fans degree worry centers degree edge list sorted source id detect fans degree output fan set centers adjacent 
index destination id generate set fans pointing centers compute intersection sets 
somewhat careful investigation reveals intersection computations batched require index 
linear scan edges sorted source find fans degree exactly fans fit memory index edges sourced fan destination id 
stage memory index centers center contains fans adjacent degree exactly clearly smaller index contains edges adjacent fans degree exactly maintain set vertices corresponding fan edges indexed 
recall retained fan adjacent exactly centers 
allows consider dual condition equivalent condition 
fact centers adjacent denote neighborhood set fans point part core intersection sets size fact determine fans chosen qualify part community 
fan qualifies output community output 
case prune fan 
turns condition fact verified efficiently batching fans 
exactly 
maintain set corresponding fan goal computation set corresponding fan intersection sets specified fact 
stream edges sorted destination 
destination check small index 
fan outdegree exactly adjacent 
edges adjacent meaningless current pass 
assume index 
degree fan adjacent intersect set fans adjacent set corresponding intersected 
recall edges sorted destination available contiguous sequence scan 
batched run set required verify fact vertices sets size corresponds fans cores belong 
case output community immediately 
case prune optionally prune fans belong community output 
get interesting fact 
inclusion exclusion pruning reduced passes dataset separated sort operation 
statements apply pruning steps point theorem graph unidentified cores eliminated pruning steps 
theorem running time pruning steps linear size input plus number communities produced steps 
theorem states set cores generated far complete cores missed 
desirable property especially false positives produced 
results section show suffer problem 
theorem shows algorithms point output sensitive running time linear size input grows linearly size output 
words spend constant time input item read constant time core produce view constants independent size input 

core generation filtering inclusion exclusion pruning step generates number cores 
instance set fans form community core 
community question turns inspection student organizations universities 
brown edu students students org html wings buffalo edu sa resources msa html cc utexas edu students msa links links html table shows number cores output inclusion exclusion pruning various values communities fixed value largely disjoint due way inclusion exclusion pruning done 
trawling extracted communities summing communities 
number cores 
number non nepotistic cores 
table number cores 
filtered away nepotistic cores 
nepotistic core fans core come web site 
underlying principle fans core come web site may artificially established community serving ends commercial single entity spontaneously emerging web community 
purpose definition web site 
site contains fields instance yahoo com www ibm com site left site fields www yahoo uk field dropped 
column table represents number non nepotistic cores 
seen number nepotistic cores significant overwhelming month old crawl 
half cores pass test 
expect number cores current web significantly higher 

finishing inclusion exclusion pruning step left unpruned edges looking cores case largest number unpruned edges left 
afford enumerate remaining cores existing techniques briefly describe final step 
build cores iteratively identify core enumerating fans 
fix value note proper subset fans core forms core smaller size 
fact diminished size dataset allows run priori algorithm agrawal srikant follows 
fix start cores 
simply set vertices outdegree construct cores checking fan cites center core 
compute cores likewise checking fan cites center core 
plots number resulting cores function subgraph remaining pruning step 
note contrast pruning algorithm algorithm output cores 
normalized count cores includes non overlapping cores cores may overlap cores 
number cores upper bound total number disjoint cores size greater remaining inclusion exclusion pruning 
number cores remaining pruning 
curiously number smaller comparable number cores inclusion exclusion step 
note approximately potential communities dataset fact results section show appears virtually cores correspond real communities coincidental occurrences complete bipartite subgraphs 
dataset year half old safe conjecture communities web today 

evaluations communities section describe preliminary evaluations communities system step rely manual inspection study communities result 
longer run need mechanized process dealing communities 
raises significant challenges information retrieval research 
manual inspection picked random sample cores cores cores list 

worked month old crawl question studied community cores discovered recoverable today web 
fossil community core fan pages exist web today 
surprise community cores recoverable communities today web 
communities random sample roughly 
rest alive 
prevailing estimates half life web pages months surprising fan pages corresponding community cores significantly longer lived 
indicator value resource collections web consequently robustness methods 
communities 
question studying communities 
give flavor communities identify examples 
deals japanese pop singer 
fans community 
web jp link html hawk ise ac jp student person hobby html noah mtl tokyo ac jp hobby html example deals australian fire brigade services 
fans community 
maya eagles bbs net au mp html homepage net html cs uni sb de links html extensive annotated list communities find viewed reliability 
question fraction live cores cogent covered single characterizable theme 
cores surprisingly reliable 
cores coincidental cores collection fan pages cogent theme unifying 
amounts just cores 
scale web usage link information expect far larger fraction accidental communities 
appears careful pruning steps paid 
sample results extrapolate fraction coincidences account cores 
words estimate extracted communities alive cogent today web 
recoverability 
core part community 
communities recover today community core extracted 
method purpose run clever search engine community core fans exemplary hubs text query 
details done see chakrabarti 
kumar 
table shows output clever top hubs authorities run cores turns australian fire 
extensive list 
authorities hubs nsw rural fire service internet site new south wales fir ial australian links nsw fire sutherland rural fire service information network cfa county fire authority re brigade home page national ted children ho 
new south wales fir ial australian links internet connexions info fire departments 
information network welcome 
fire safety serv 
australian page world famous server dens 
county fire brigade australian fire services links new south wales fir es station fir mp canada section brigade bush fire home page point rural fire brigade golden square fire brigade fire trails 
home page fire safety directory guises creek home page 
departments th 
table community australian fire 
quality 
communities unknown explicit ontological efforts 
sampled communities yahoo 
reconstructed crawl yahoo 
today form whatsoever 
remaining yahoo 
today cases yahoo 
url listing process frequently yields 
interpret finding measure reliability trawling process communities emerging months ago emerged 
communities appears third level yahoo 
hierarchy average level yahoo 
communities deep current yahoo 
tree 
believe trawling current copy web result discovery communities explicit 
open problems 
dominant open problems automatically extracting semantic information organizing communities useful structure 
interesting problem successive copies web tracking sociology emerging communities 

agrawal srikant rakesh agrawal ramakrishnan srikanth 
fast algorithms mining association rules proceedings vldb sept santiago chile 

abiteboul serge abiteboul quass jason mchugh jennifer widom janet weiner 
lorel query language semistructured data 
international journal digital libraries april 

bharat broder krishna bharat andrei broder 
technique measuring relative size overlap public web search engines 
proceedings th international world wide web conference brisbane australia pages 
elsevier science april 

bharat henzinger krishna bharat monika henzinger 
improved algorithms topic distillation hyperlinked environments 
proceedings st sigir conference melbourne australia 

brin page sergey brin larry page 
anatomy large scale hypertextual web search engine 
proceedings www brisbane australia april 

broder andrei broder steve glassman mark manasse geoffrey zweig 
syntactic clustering web 
proceedings sixth international world wide web conference april pages 

carriere kazman carriere kazman searching visualizing web connectivity proc 
th international world wide web conference 

chakrabarti soumen chakrabarti byron dom david gibson jon kleinberg prabhakar raghavan sridhar rajagopalan 
automatic resource compilation analyzing hyperlink structure associated text 
proceedings th world wide web conference 

chakrabarti 
soumen chakrabarti byron dom david gibson ravi kumar prabhakar raghavan sridhar rajagopalan andrew tomkins 
experiments topic distillation 
proceedings acm sigir workshop hypertext information retrieval web melbourne australia 

deerwester deerwester dumais landauer furnas harshman 
indexing latent semantic analysis 
journal society information science 

florescu levy mendelzon daniela florescu alon levy alberto mendelzon 
database techniques world wide web survey 
sigmod record 

gibson kleinberg raghavan david gibson jon kleinberg prabhakar raghavan 
inferring web communities link topology 
proc 
th acm conference hypertext hypermedia 

henzinger raghavan rajagopalan monika henzinger prabhakar raghavan sridhar rajagopalan 
computing data streams 
ams dimacs series special issue computing large datasets 
technical note digital equipment systems research center palo alto ca may 

kleinberg jon kleinberg 
authoritative sources hyperlinked environment 
proceedings th acm siam symposium discrete algorithms soda january 

konopnicki shmueli david konopnicki oded shmueli information gathering world wide web ql query language qs system 
transactions database systems september 

kumar ravi kumar prabhakar raghavan sridhar rajagopalan andrew tomkins 
human effort semi automated taxonomy construction 
submitted publication 

lakshmanan sadri subramanian laks lakshmanan sadri iyer subramanian 
declarative approach querying world wide web 
post icde workshop research issues data engineering ride 
new orleans february 

mendelzon mihaila milo mendelzon mihaila milo 
querying world wide web journal digital libraries pp 


pirolli pitkow rao pirolli pitkow rao 
silk sow ear extracting usable structures web proceedings acm sigchi conference human factors computing 

spertus ellen spertus 
parasite mining structural information web 
proc 
th international world wide web conference 
tsur dick tsur jeffrey ullman serge abiteboul chris clifton rajeev motwani nestorov rosenthal query flocks generalization association rule mining 
proceedings acm sigmod conference management data 

white mccain white mccain bibliometrics ann 
rev info 
sci 
technology elsevier pp 

ravi kumar received ph computer science cornell university research staff member ibm almaden research center 
research interests include randomization complexity theory information processing 
prabhakar raghavan received ph computer science university california berkeley 
research staff member ibm research thomas watson research center yorktown heights ny almaden research center san jose california 
consulting professor computer science department stanford university 
research interests include algorithms randomization information retrieval optimization 
author book randomized algorithms numerous technical papers 
served editorial boards program committees number journals conferences 
sridhar rajagopalan received tech 
indian institute technology delhi ph university california berkeley 
spent years dimacs postdoctoral fellow princeton university 
research staff member ibm almaden research center 
research interests include algorithms optimization randomization information coding theory information retrieval 
andrew tomkins received bsc mathematics computer science mit phd cmu 
works ibm almaden research center principles methodologies group 
research interests include algorithms particularly online algorithms disk scheduling prefetching pen computing ocr world wide web 
