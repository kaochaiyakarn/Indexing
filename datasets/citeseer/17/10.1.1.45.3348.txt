university pennsylvania founded benjamin franklin institute research cognitive science corpus approach language learning eric brill ircs report university pennsylvania walnut street suite philadelphia pa december site nsf science technology center research cognitive science corpus approach language learning eric brill dissertation department computer information science faculties university pennsylvania partial fulfillment requirements degree doctor philosophy mitchell marcus supervisor dissertation mark steedman graduate group chairperson fl copyright eric brill people deserve helping progress mother finishing dissertation 
doctor delivered filling pages pages names ll say big generic deserve aren mentioned name 
advisor mitch marcus deserves great deal constant support encouragement 
enthusiasm helped research lot fun 
committee steve abney gleitman aravind joshi mark liberman feedback significant shaping dissertation 
allowing graduate 
believe men women sacrificed years defend bill rights constitution deserve special commitment freedom thought expression exist 
parents love education early age provided driving force pursue degree belief doubt question learn 
met lu arrived university pennsylvania 
managed keep sane years penn friendship deserve biggest 
iii corpus approach language learning eric brill supervisor mitchell marcus goal computational linguistics discover method assigning rich structural annotation sentences simple linear strings words meaning readily extracted structurally annotated sentence sentence structural information 
structure allows depth check formedness sentence 
phases assigning structural annotations knowledge base created second algorithm generate structural annotation sentence facts provided knowledge base 
knowledge bases created manually language experts 
knowledge bases expensive create effectively structurally parsing sentences highly restricted domains 
goal dissertation significant progress designing automata able learn structural aspects human language little human guidance 
particular describe learning algorithm takes small structurally annotated corpus text larger unannotated corpus input automatically learns assign accurate structural descriptions sentences training corpus 
main tool automatically discover structural information language corpora transformation error driven learning 
distribution errors produced imperfect annotator examined learn ordered list transformations applied provide accurate structural annotation 
demonstrate application learning algorithm iv part speech tagging parsing 
successfully applying technique create systems learn lead robust trainable accurate natural language processing systems 
contents iii iv structural descriptions language learning structural information natural language understanding human language learning structural annotation 
extracting meaning sentence sentence formedness language modelling corpus annotation robust portable natural language processing systems process automated language learning structural linguistics discovering morpheme word boundaries discovering word classes discovering significant morpheme strings corpus learning annotating corpus part speech labels learning lexical information learning phrase structure vi areas transformation error driven learning applied natural language word zipf law overview transformation learning system lexical information word classes finding tag word results learning context triggered transformations improve accuracy results phrase structure building tree nonterminals unlabelled algorithm results manually tagged text results automatically tagged text labelling nonterminal nodes transformation postprocessing transformation learning works penn treebank part speech tags excluding punctuation old english part speech tags original brown corpus tags vii penn treebank nonterminals bibliography viii list tables initial tagging accuracy function training corpus size 
summary accuracy lexical learning 
wall street journal tagging results 
wall street journal tagging results larger lexicon adding sentences 
top word tagging errors wall street journal 
tagging brown corpus 
comparing learning methods atis corpus 
wsj sentences wsj sentences 
wsj sentences length 
comparing approaches crossing bracket measure comparing approaches sentence accuracy brown corpus sentences length 
brown corpus sentences length 
accuracy tagging training test corpora 
crossing bracket accuracy wsj sentences length 
transformations labelling nonterminals 
top labelling errors 
ix list figures structural information 
general framework corpus learning 
distributional error driven learning 
learning transformations applying transformations data census zipfian distribution transformation scores 
word similarities brown corpus word similarities parental speech word similarities voyager corpus unknown words vs training corpus size entropy vs training corpus size perl pseudocode learning simple transformations 
dividing corpus running experiments 
transformations wsj corpus 
unknown word tagging accuracy applying transformations 
unknown word tagging accuracy applying pruned transformations 
transformations penn treebank brown corpus 
transformations original brown corpus 
transformations old english corpus 
unknown word tagging accuracy applying transformations 
contextual transformations wsj 
top tagging errors wall street journal 
contextually triggered transformations brown corpus penn treebank tags 
contextually triggered transformations brown corpus original brown corpus tags 
contextual transformations old english corpus 
old english tagging results 
allowable structural transformations 
triggering environments 
triggering environments 
learned transformations 
results atis corpus starting right linear structure results atis corpus starting random structure results wsj corpus distribution sentence lengths wsj corpus 
learned transformations bracketing old english 
transformations learned prepositional phrase attachment 
transformations learned prepositional phrase attachment noun classes 
comparing results pp attachment 
xi chapter structural descriptions language learning structural information natural language part person knowledge language consists knowing assign structural description sentences 
included knowledge awareness word phrase classes language members class relationships hold classes 
instance english speaker may aware linguistic labels tacitly aware just linear structure sentence boys eat 
shows structural information tacitly known english speakers short sentence 
english speakers know eat noun phrase third person singular boys plural form boy boy noun words boys form noun phrase words boys eat constitute sentence 
classes relationships hold language superficial 
existence appears fairly transparent classes roughly follow understood semantics syntactically surface apparent 
words classes relationships described extent recourse deep semantic analysis need detailed structural description 
annotated information fairly superficial 
boys eat verb det sing rd sing np plur plur vp rd sing sentence noun sing boy plur animate structural information 
example absolutely correct semantic definition noun person place thing fair criterion membership class nouns basis understand origination class 
number classes relationships existence transparent 
pinker discusses class verbs 
verb gave undergone 
john gave painting museum 
john gave museum painting 
note donated semantically similar gave donated undergo 
john donated painting museum 
john donated museum painting 
people able ascertain verb heard undergo dative shift 
productivity indicates merely people assign words class verbs see example verb 
pinker argues subtle semantic properties determine verbs belong class 
addition subtle word classes research modern syntax uncovered restrictions structural relationships hold sentence 
example relationship surface apparent examine trace effect 
characterize permits sentences permit 
think john likes 
think john likes 
think fell 
think fell 
explanation offer phenomenon involves assumption wh words move sentence form question leave invisible trace position moved 
question formed base sentence think john likes 
moves front sentence leaves trace 
traces allowed appear restricted positions sentence 
appear positions governed real word 
order governed fairly complex structural relationship hold trace word governs 
relationship holds hold 
concentrate automating learning superficial structural information 
determine extent information part speech word particular context skeletal phrase structure sentences discovered automatically 
complex description needed fully explain phenomenon ask extent phenomenon explained captured simple analysis surface structure 
example certainly cases see example information theoretic corpus techniques learn complex phenomena surface apparent 
particular discuss methods setting word order parameter distributional measures corpus structural annotation minimal assumptions knowledge language prior learning 
proper part speech tag word context depends deep analysis 
quantify extent case find lower bound building program tags simple surface structure information checking tagger perform natural text 
phenomena wish explore comprise language picture comprise significant interesting portion 
language understanding involves mastering superficial highly idiosyncratic rules language 
testament superficial knowledge quirk colleagues compiled page book entitled comprehensive grammar english language records superficial facts english book doubt incomplete 
understanding human language learning report research program generative share primary goal explanation language learned important clear differences approaches 
approaches address language learning focus approaches quite different 
generative interested exploring nature language uncovering language universals properties held natural languages 
search universals interest step differentiating essence natural language idiosyncrasies particular language 
search universals may provide explanation child learns language 
commonly believed language learning proceed purely inductive process priori knowledge target grammar 
roots belief outlined include 
poverty stimulus quantity quality evidence environment conducive learning 

complex non surface apparent grammatical constraints 
course reason book attributed failure authors finding true concise description language 

knowledge language appears shared diverse languages 
principles parameters approach offered model child come acquire skills allow language productively 
model language divided parts core periphery 
periphery contains information learned unique particular language irregular morphology idioms 
core contains innate linguistic universals 
account differences languages rules constraints core parameterized 
rule pro drop 
english subject sentence necessary imperative sentences spanish subject optional 
account people working principles parameters model assume innate constraint underspecified stating language drop subject sentence 
learn language learn peripheral facts find proper settings parameterized core constraints 
principles parameters model accounts ability learn language despite poverty stimulus simple sentence act trigger properly setting parameter complex rule 
explains complex language constraints come known constraints innate need learned 
weakness approach current form lend algorithmic implementation 
dissertation explore language learning addressing different problem 
focus research find algorithmic approaches successful learning information necessary allow accurate productive structural analysis sentence 
sense empirically investigating poverty stimulus argument applies learning superficial phenomena investigated thesis 
people studying principles parameters exploring facts language accounted innate linguistic constraints setting explore facts language learnable applying learning algorithm entirely true 
describes attempt providing algorithmic account learning formalism 
point superficial 
sample language 
sorts phenomena approaches attempt explain motivations choosing phenomena different 
principles parameters researchers search phenomena cast universals search phenomena think may learnable analyzing corpus 
structural annotation 
structural annotation useful computational linguistics number reasons including extracting meaning sentence checking formedness sentence language modelling annotating corpora research tools 
briefly discuss applications turn 
extracting meaning sentence marcus argues possible extract meaning sentence general obtaining syntactic information 
alternate approach assume meaning sentence obtained recourse syntactic structure 
problems approach 
example gives sentence postman bit dog 
interpretation sentence word meaning world knowledge sentence interpreted dog doing biting 
knowing simple sentence noun phrase encoding actor appears verb get correct interpretation 
simple semantic template matching approach fail complex sentences keyword matching uncover relationships words sentence 
hand relationships discovered structural analysis sentence 
template matching augmented positional information inadequate phrases move base forms 
examining pitfalls system tries extract meaning sentence referring structural descriptions marcus states purpose process understanding human language determine meanings utterances syntactic structures appear necessary way 
theories compositional semantics proposed montague assumption semantic rules tied syntactic rules 
uncovering syntactic structure sentence necessary precursor understanding sentence semantic theories 
sentence formedness structural descriptions sentences allow better formedness checking done unannotated string words 
take example sentences ffl john mary 
ffl called john mary 
ffl called john mary structural annotation checking subject verb agreement verb difficult 
sentences verb preceded string words john mary 
skeletal bracketing provided examples agreement easily checked 
likewise information bracketing phrasal heads necessary check semantic constraints imposed matrix verb subject 
example sentences know ice cream melt opera 
enforce semantic constraint subject verb melt sentences know skeletal bracketing shown head subject 
ffl ice cream eaten opera singer 
ffl 
ate ice cream watched opera singer 
structural annotation allows complete formedness check sentence 
checking formedness useful number applications 
give example speech recognition systems recognizer outputs list best guesses passed parser filter sentences formed 
accurately formedness assessed better systems rely filtering bad sentences best lists perform 
true spelling checkers system outputs set possible answers permitted filter eliminate certain proposed answers syntactic grounds 
system probabilistic model just output sentence highest probability filtering allows system take certain structural relations consideration built probabilistic model 
language modelling language modelling involves assigning probability string words 
language models real time speech recognition predict word stream language appeared stream rank alternate theories uttered filtering outputting probable theory 
successful language models gram models basing probability word probability preceding words classes words 
language models context free grammars decision trees proposed 
speech understanding system translates utterance singer sang lot sound language system decide final word sentence arias areas language model help indicating aria context 
bigram model trained text opera news indicate areas follow arias gram model needed capture relationship sang arias 
structural model may able recognize arias areas head object verb sang 
hope eventually language model structural description language stream provide powerful framework solely unannotated string words 
course necessarily case structure aid word prediction cheap source structural annotation allow avenue research explored fully 
corpus annotation growing desire annotated corpora lately researchers addressing different issues linguistics computational linguistics 
linguists structurally annotated corpora study number linguistic phenomena 
uses tagged corpora study vp ellipsis 
niv uses syntactically annotated corpus develop theory humans resolve syntactic ambiguity parsing 
taylor tagged bracketed corpora middle english old english studying diachronic linguistic phenomena 
computational linguistics researchers annotated corpora train stochastic part speech taggers parsers 
structurally annotated corpora gold standard different parsers objectively compared 
currently researchers limited existing annotated corpora structural descriptions provided corpora sentences successfully annotated existing taggers parsers 
system automatically annotate corpus language little human labor required greatly enhance progress researchers corpora 
adequate annotation accuracy level obtained automated procedures automated annotator bootstrap process manually annotating corpus 
shown manually correcting output automated tagger results greater speed accuracy manually annotating scratch :10.1.1.14.9706
number researchers corpus computational linguistics believe size available annotated corpora current limiting factor creating accurate natural language processing systems 
case cycle automatically annotating corpus manually correcting retraining automatic annotator larger corpus provide fast mechanism providing large annotated corpora 
robust portable natural language processing systems difficult impossible manually encode information language necessary robust system capable automatically annotating text structural description 
system effective great deal morphological lexical syntactic information available 
large part due highly idiosyncratic behavior language manually creating sources information difficult task 
providing structural information system implicitly specify grammar symbol names meanings set allowable rules relations information encoded 
instance decided grammar context free decision type nonterminals syntactic semantic combination level specificity categories actual categories 
descriptive language resulting grammar language specific may domain specific 
process encoding linguistic information clear descriptive language grammar adequate substantial recoding convert information form consistent new grammar type carried 
addition settling adequate descriptive language grammar faced problem writing grammar rules linguistic knowledge module 
typically sources inspiration discovering pieces knowledge need encoded introspection trial error 
introspection involves thinking facts phenomena learned important linguistic training manually recording information way available computer parsing 
trial error involves finding sentence system fails adding sufficient information allow processing sentence 
methods shortcomings 
addition labor intensive complicated interaction various linguistic knowledge modules interaction different facts single module 
large amount information interactions various facts expanding knowledge base tricky endeavor 
goal system provide set facts method combining information allows greatest coverage target corpus means clear methods introspection trial error converge grammar 
lack success date building robust parser see indication methods 
system automatically extracts linguistic generalizations annotated corpus strong advantages introspection trial error 
automating development knowledge base greatly reduce total development time system 
second statistical property learner allows learner better quantify import different linguistic facts weigh different facts principled way driven goal high coverage biased linguistic training order sentences system fails 
system analysis corpus uncover generalizations weigh import different phenomena indicated large data analysis may apparent person attempting hand code grammar 
successful parsers written specific constrained domain usually including great deal domain specific information 
addition difficult create manually resulting language processing systems expensive port new languages new domains 
trainable system allow inexpensive porting new domains may consist completely different grammar specification set rules 
may viable method providing system necessary knowledge language system learn information analyzing annotated unannotated sample corpora 
degree automatic training necessity building robust portable systems 
degree systems trained corpus succeed remains seen 
hope shed light question 
process automated language learning interested studying learning process 
case systems learn solution building robust natural language processing systems process automated language learning deserves study 
different ways try construct language learner 
selforganizing language learner proposed language modelling 
method combining large manually constructed grammar statistical information obtained large corpus discussed 
take different approach starting small structurally annotated corpus larger unannotated corpus corpora learn ordered list transformations accurately annotate fresh text 
undertaking learn extent approach viable approach compares approaches currently examined 
lays general framework corpus learning research carried 
learning system described begins start state 
start state annotated corpus text input arrives state 
state ordered list transformations particular learning module 
learner defined set allowable transformations scoring function learning search method carried learning 
currently greedy search learning modules 
stage learning learner finds transformation application corpus results best scoring corpus 
learning proceeds corpus results applying learned transformation 
continues transformations application results improvement see 
ordered list transformations learned new text annotated simply applying transformation order entire corpus see 
number interesting properties framework worth keeping mind comparing approach approaches language learning ffl little linguistic knowledge language specific knowledge built system 
corpus state start state boys ate boys ate det pl noun vb np general framework corpus learning 
ffl learning statistical weakly 
ffl state completely symbolic 
ffl small annotated corpus necessary learning succeed 
learning modules currently implemented ffl learning part speech word 
ffl learning contextual information disambiguate words part speech 
ffl learning bracketing structure sentences 
ffl learning assign nonterminal labels bracketing structure 
ffl learning improve prepositional phrase attachment 
particular describe single simple learning method transformation error driven learning create ffl syntactic text outperforms best known statistical grammar induction method inside outside algorithm 
ffl part speech tagger outperforms statistical taggers markov models 
ffl prepositional phrase attachment program outperforms statistical methods score statistics 
ffl nonterminal node performs despite fact little information labelling 
variables system level specificity start state types transformation templates degree annotation input corpus 
assume minimal assumptions variables start state little linguistic knowledge simple language general transformations small annotated corpus 
prespecified easier port corpus different domain different language 
way results obtained lower bound performance may enhanced larger corpora built knowledge language 
general framework allows experimentation variables study various adjustments affect learning better delineating pieces structural knowledge language learned framework 
possible directions worth exploring annotating input corpus varying degrees types phrase boundary information various linguistic assumptions bar theory prespecified start state 
possible problem line research arises lack understanding true structure sentence correct structure exists 
structural description simple phrase boy question 
unclear phrase projection noun boy making noun phrase projection determiner making determiner phrase 
clear picture correct structure sentences hope progress system capable learning information necessary assign structural descriptions 
question answered context current state art language processing 
reality far ambitious goal creating system accurately automatically provides extremely rich structural description arbitrary sentences 
current level sophistication state art sentence processors progress currently hampered lack detailed understanding structure sentences 
reported experiment run large coverage parsers number sentences containing fewer fourteen words 
generous definition correctness parse correct needed accuracy delimiting identifying obvious constituents noun phrases prepositional phrases clauses rough correctness assigning part speech labels noun labelled unannotated corpus weaker initial assumption reasons explained decided provide learner small annotated corpus better guide learning 
verb 
parsers scored correct scored 
great room improvement basic level structure little need currently worried researchers agree proper analysis complex constructs 
progress currently evaluated comparing performance system correct performance correctness defined manually annotated corpus skeletal structure 
possible time progress halt 
problem crude annotation comes closer solved researchers turn elaborate structural annotation possible pitfalls 
may case approaches described dissertation adequate uncovering expressing subtle facets structure 
progress crude annotation progress understanding subtle facets difficult create properly annotated corpora train learner judge progress 
thesis exploration power simple corpus analysis tool language discovery 
ways parallels harris american school linguistics review past distributional analysis automated discovery structural facts language 
chapter structural linguistics prominence structural linguistics modern generative syntax goals parallel goals modern computational linguistics 
research communities structural description language goals labor motivations goal different 
relationship briefly examine past done structural linguistics 
sampson franz boas father linguistic 
boas interested determining structure number different languages 
providing accurate description language primary goal 
boas thought research done determine relationship languages structural similarity 
boas held view similar whorf structure language influences person behavior saw language study important peculiar characteristics languages clearly reflected views customs peoples world page 
view gave import studying structure individual languages isolation fundamentally different focus modern study particular language hopes learning human language general 
boas believed human languages richly arbitrarily diverse approaching problem describing language preconceived linguistic notions fruitful lead wrong analyses 
linguistic facts easily rise consciousness method analysis necessary elicit facts 
proposed form distributional analysis 
example linguist analyzing english determine noting sounds mail nail convey different meaning 
boas followed leonard bloomfield 
bloomfield worked uncovering descriptions unfamiliar languages 
boas bloomfield believed studying unfamiliar language extremely careful allow preconceived notions creep study 
bloomfield says page useful generalizations language inductive generalizations 
features think ought universal may absent language accessible 
features instance distinction verb noun words separate parts speech common languages lacking 
fact features rate widespread worthy notice calls explanation adequate data languages shall return problem general grammar explain similarities divergences study comes wil speculative inductive 
bloomfield heavily influenced logical 
logical room theories simple sensory data 
bloomfield believed linguist introspection way gathering linguistic data rely actual utterances gathered field 
bloomfield elaborated boas method distributional information corpus actual utterances draw language 
studying behavior elements corpus draw forms grammar unfamiliar language 
thing lacking bloomfield formal algorithmic description extract structural information corpus 
computers prominent weakness significant 
harris attempted describe idea language analysis sufficient rigor conceivably written computer program 
harris developed rules linguist doing field uncover structure unfamiliar language 
addition hope eventually automating process harris troubled lack rigor analysis linguists carried data collected field 
hoped providing set procedures linguist analysis lack rigor overcome 
important emphasize harris putting forth theory grammar claiming theory language learning developing tools linguist computer help build theory structural description language 
course sorts things linguist discover influenced tools tools outlined harris commits particular class language theories 
methods harris proposed layered discover morphemes phonemes word classes morphemes higher level structure words word classes 
methods observation set environments different elements 
describe different discovery procedures posed harris 
discovering morpheme word boundaries harris proposed method discover morpheme boundaries word word boundaries sentence 
procedure sentence input transcribed phonemes letters 
prefix sentence number phonemes follow computed 
procedure carried number allowable phonemes gradually decreases word included prefix 
word morpheme boundary reached number allowable phonemes greatly increases 
morpheme distributionally morpheme prefix greater variation appear morpheme 
computing value sentence forward backward directions peaks correspond word morpheme boundaries 
procedure carried directions robust 
harris ran algorithm break words morphemes tried words 
algorithm run forward direction distinguished di dis proper prefix words 
running algorithm backwards proper decomposition 
distributionally respect follow embody 
harris ran algorithm words dictionary english compute number letters precede follow prefix suffix 
presumably access large dictionary doing field little known language 
dictionary proceed ways 
sufficiently large corpus obtained word list built corpus numbers computed word list 
informant available informant queried number possible completions think particular prefix 
method corpus may possible find morphemes word boundaries known find word breaks phonemic transcription 
harris states corpus needed analysis prohibitively large 
discovering word classes harris motivation grouping words classes building structural description language avoid having repeat identical grammar rules different similar words 
grouping similar words grammar expressed economically 
discovery procedure layered learn complex classes relationships presume discover morphemes language studied classification proceed known morphemes 
harris proposes words occur environments classed environment simply context word appears 
instance word boy appear environment fastest won race 
word pairs completely identical regard set environments appear constraint weakened allow words classed sufficiently large percentage environments shared 
classification procedure classes set allowable environments word class roughly significant distributional distinction words different classes 
word classification procedure completely automatic 
impossible obtain corpus utterances sufficiently large contain environments word classed appear approximation techniques employed 
possible approximation technique linguist search short environments differentiating classes small set suffixes 
linguist successfully identify diagnostic environments familiar language studied access informant 
discovering significant morpheme strings american find number suggestions immediate constituent analysis performed sentence 
seymour charles suggested measure somewhat similar entropy tool breaking sentence phrases 
proposes greater potential variety environment greater number possible morpheme substitution classes immediately follow string morphemes greater magnitude structural break separates morpheme follows 
determine strongest break sentence hungry boy ate query informant determine number different word classes follow hungry hungry boy note different entropy measure take account probabilities word classes appearing context 
structural linguistics informant provides binary answer indicating entity appear particular environment 
extracting information corpus estimate probability entity appearing environment 
method finding phrase boundaries similar proposed harris determining morphemes language 
different approach immediate constituent analysis suggested harris wells 
wells incorporates expands ideas harris discuss wells 
possible automatically 
different word class sequences substitutable words sentence sequence occur occur 
example wells gives word class sequence tom dick mutually substitutable 
word class sequences wells calls expansion mutually substitutable structurally diverse contains morphemes word class sequence said expansion exists expansion 
immediate constituent analysis carried attempting break sentence word sequences expansions 
get problem having access distributional possibilities corpus harris suggests linguist construct testing frames word class 
testing frames environments linguist deems representative particular class 
testing frames chosen word sequences naturally appear testing frames particular word class 
harris example procedure equate sequence adjective noun word class noun instance boy fool appear testing frame don procedures discovery procedure morpheme word boundaries developed point implemented tested computer 
procedures relied intelligence active intervention linguist decide best questions ask informant decide specific environments searched corpus utterances 
instance discussion word classes suggests determining similarity looking words identical distributional behavior short environments looking words appear precisely sentences 
harris notes weakness approach 
method may prove adequate 
languages may impossible devise procedure determining short environments limits set differentiating ones various substitution classes 
select ing diagnostic environment get class containing see certain 
select un environment obtain class certain clear precisely meant structural diversity 
see en ing follow 
obtain different classifications morphemes 
described dissertation address learning structural information language structural linguists developed procedures elicit informants 
informant annotated small randomly selected sample language learning automatic 
field linguist working informant essence access intensional distribution language discovered extensional distribution observed small naturally occurring sample annotated text 
expanded idea distributional analysis novel way examining distribution entities corpus naive guess structure language analysis distribution errors carried discover transformations eliminate annotation errors 
distributional hypothesis states lexical features syntactic phenomena manifest way observed surface apparent distributional behavior 
hypothesis false techniques sort outlined thesis completely successful 
extent distributional hypothesis holds judged success failure approaches hypothesis tested empirically just far distributional techniques go 
chapter corpus learning advent large line corpora fast computers great deal excitement years trying automatically extract linguistic knowledge text corpora 
movement essence appropriately adapted age fast computers cheap storage devices 
extent algorithms succeed extracting useful information empirical question 
issues distributional information sufficient size corpus needed access information knowledge language needs built learner noise corpus harmless solved intuition experimentation answer questions 
years number surprising successes demonstrated strength methods demonstrating weaknesses inherent approach 
review results 
annotating corpus part speech labels need annotated corpora grown past years 
number corpora words tagged part speech readily available heavily natural language researchers 
tools automatically tag text parts speech successful 
tools tag text having people correct mistakes manually resulted fast accurate tagging large amounts text :10.1.1.14.9706
bit circular building larger corpora provides training material build accurate automatic annotators applications require annotated input build larger annotated corpora 
part speech tagging involves assigning word proper part speech context word appears 
instance sentence different part speech tags 
modal pronoun verb determiner noun 
pieces information needed tagging 
lexical information indicates possible parts speech particular words possibly including indication likelihoods different labels 
contextual information indicates particular tag appropriate particular context 
number systems built quite effective accurately tagging text 
effective statistical markov model taggers 
general classes statistical taggers trained tagged text trained untagged text 
underlying model set part speech states state generating different words different probabilities 
instance generate sentence dog model determiner state word emitted move noun state word dog emitted move verb state emit word 
string words goal uncover sequence states generated string 
tagger trained tagged text state transitions visible transition probabilities emit probabilities easy estimate training corpus 
taggers described trained tagged text 
large corpus tagged text set lexical contextual probabilities estimated 
lexical probabilities jt probability word part speech tag 
words probability word labelled verb corpus word eat 
contextual probabilities computed jt gamma jt gamma gamma depending size context window 
markov models see 
system trained new text tagged assigning string tags maximizes jt jt gamma sentence 
optimal tagging easily computed dynamic programming 
second set stochastic taggers require tagged text training 
underlying model assumed hidden markov model case training difficult set state transitions generate training corpus longer visible 
tagged corpus necessary large dictionary necessary determine permissible part speech tags words 
line dictionary available language corpus tagged tags dictionary mapped desired set tags great deal human labor required provide necessary training material 
taggers described type :10.1.1.109.179
baum welch algorithm train model trained model tagging fresh text 
clear approach training untagged text provides effective portable method tagging 
example performance comparable obtained taggers trained tagged corpora obtained 
obtain performance large dictionary part speech inflectional information needed number higher order procedures manually built manual error analysis 
addition results quoted lexical information obtained training test set clear obtain accuracy comparable taggers trained tagged text 
number attempts rule tagging 
rule taggers date back far availability fast computers large corpora taggers able tag extremely high accuracy 
part speech tagging rules discovered automatically sophisticated parser 
rules state parser processing word tagged 
simple rule tagger described 
decision tree tagging 
approaches contextual information disambiguate known set allowable part speech tags 
problem arises word encountered part speech information known 
statistical taggers deal smoothing way empirical probability estimate zero lead errors 
problem current successful approaches tagging handle unknown words way completely portable 
church complex procedure classifying unknown words including frequency dependent procedure detecting proper nouns domain dependent procedure classifying words dashes list abbreviations large list informative suffixes great deal additional information 
kupiec provides list closed class tags assumes external dictionary list closed class items 
addition provides set derivational inflectional suffixes trains probabilistic method determining part speech trained dictionary corpus unannotated text 
probabilistic procedure employed unknown words 
procedure requires informative set affixes provided cues 
chapter discuss transformation learner automatically learns tag unfamiliar words prior language specific knowledge 
interesting note taggers obtain roughly performance trained tested comparable corpora controlling variables size dictionary amount morphological information 
variables significantly effect performance factoring sure measuring success tagging method merely success extra information provided 
light comparable performance achieved taggers described simpler 
example contextual information captured fewer rules compared leaf decision tree table tens thousands contextual probabilities 
learning lexical information distributional techniques useful helping lexicographer uncover lexical information words able think introspection 
developed techniques mutual information measure cooccurrence elements compares chance 
mutual information events defined log appear chance occur chance predict 
occur chance predict 
expect clouds rain positive rain negative numbered day rain zero 
shown mutual information statistic uncover lexical information 
compute mutual information strong powerful words occur words associated press newswire 
list highest scoring neighbors strong powerful shown 
strong strong strong believer strong second place strong powerful legacy powerful tool powerful storms powerful minority powerful neighbor similar list computed word pairs relationships immediate neighbor 
instance nouns classified mutual information verbs argument 
list lexicographer uncover subtle differences words may thought aid list 
semi automated procedure described learning classes objects subdomain enter subject verb object relationship 
procedure needs reliable parser great deal human intervention 
describes procedure extracting verb subcategorization information unannotated text 
verb subcategorization frames finds include direct object direct object clause direct object infinitive clause infinitive 
procedure works parser written needs human supervision 
list verbs extracted corpus 
done simple automaton assumes word verb adjacent pronoun proper name lack case 
verb finding algorithm case filter states noun phrase get case english occur small number possible positions sentence immediately left tensed verb right main verb right preposition 
system list prepositions recognize noun phrases determine noun phrase get case verb detect verbs corpus 
noun phrases trivial detect pronouns proper names easily detected noun phrases considered 
automata built manually detect number different subcategorization frames easily detected unambiguous instances frames 
method proved effective extracting verbs detecting prespecified set subcategorization frames verb appear 
accuracy detecting instances subcategorization frames mentioned ranged 
apply technique new language new verb extraction program written new automata recognize subcategorization frames 
learning phrase structure automatically learning information accurately assign phrase structure analysis sentences topic number papers 
number papers school structural linguistics addressed issue 
mutual information called interword predictability discover phrases suggested crucial insight local minima interword predictability correlate phrase boundaries 
idea elaborated tested large corpus 
simulated annealing parse sentence 
scoring function defined take tree structure input score quality tree 
set moves defined includes changing nonterminal label node restructuring tree 
parsing carried simulated annealing move search space hope high scoring tree 
distributional analysis techniques similar described automatically learn scored context free rules 
score rule noun determiner noun receives score distributional similarity words immediately left right single part speech noun part speech pair determiner noun 
parsing carried repeatedly reducing pair tags single tag way maximizes similarity items involved reduction 
statistics calculated possible subtrees contained structurally annotated training corpus 
finding optimal highest probability combination subtrees result parser requiring exponential time monte carlo technique find guess optimal combination subtrees parsing fresh text 
inside outside algorithm method training stochastic context free grammars 
extension baum welch algorithm training stochastic finite state automata 
number papers explored potential algorithm automatically learn grammar 
probabilistic context free grammar begins initial possibly random probabilities 
algorithm estimation maximization algorithm iteratively changes rule probabilities increase probability training corpus 
algorithm guaranteed find locally optimal assignment rule probabilities globally optimal assignment 
shown inside outside algorithm bracket text high accuracy weak initial knowledge grammar 
inside outside algorithm convert grammar written linguist probabilistic grammar hope probable parse correct parse 
tutorial inside outside algorithm see 
thesis discuss error driven approach learning grammar bracketing text 
approach works naive parser learning set transformations applied output parser parsing accurate 
show method achieves performance comparable achieved inside outside algorithm 
interesting thing approach attempts grammar induction resulting grammar purely symbolic learning process weakly 
areas chapter touched research programs extracting various sorts linguistic information corpora 
areas include machine translation word sense disambiguation word clustering pronoun resolution :10.1.1.13.9919
chapter transformation error driven learning applied natural language section describe framework learning effectively applied number language learning problems 
call framework transformation error driven learning 
learning paradigm see unannotated text system 
system uses prespecified initial state knowledge annotate text 
initial state level sophistication ranging annotator assigns random structure mature hand crafted annotator 
described initial state difficult state knowledge obtain trivial algorithm contains information derived automatically corpus 
module tries find part speech tag unrecognized word initial state system assumes word noun 
part speech contextual disambiguation module initial state system assigns word tag estimated small annotated training corpus 
phrase structure bracketing module initial state system assigns right linear structure final punctuation attached high input sentences 
prepositional phrase attachment prepositional phrases attached low 
nonterminal node labelling node labelled tag dominate daughters default tag string daughters seen training corpus 
important observations initial state annotators dissertation 
clear extremely simple create contain language specific knowledge 
start state knowledge turns language specific easily parameterized 
instance left branching bracketing may prove effective start state right branching bracketing languages 
start state parameterized small amount annotated text needed determine proper parameter setting 
learner highly portable 
second initial state annotators perform terribly 
manually creating system mature linguistic knowledge system begins naive initial state learns linguistic knowledge automatically corpus 
text annotated initial state annotator compared true annotation indicated annotation assigned manually annotated training corpus 
different manually annotated corpora penn treebank original brown corpus experiments english manually annotated corpus old english :10.1.1.14.9706
note main expense writing training learning programs learning paradigm creating small annotated corpus 
fortunately learning methods require great amount annotated text learning 
words annotated text experiments 
small corpus significant cost time informant annotate training corpus 
research powerful transformations hopefully allow comparable performance smaller training corpus 
addition process manually annotating sped repeatedly annotating small amount text training automatic annotator text having automatic annotator annotate new text manually correcting output automatic annotator 
faster correct annotation errors annotate scratch :10.1.1.14.9706
possibly cut half 
currently lexical contextual modules trained separate annotated corpora 
behavior unknown words training contextual module similar fresh text 
way accomplishing training corpora overlap greatly reducing total annotated text requirements system 
unannotated text initial state annotated text truth learner rules distributional error driven learning 
comparing output naive start state annotator true annotation indicated manually annotated corpus learn errors produced naive annotator 
transformations learned applied naively annotated text better resemble manual annotation 
set transformation templates specifying types transformations applied corpus prespecified 
learning modules described dissertation transformation templates simple contain deep linguistic knowledge 
number transformation templates small 
transformation templates contain uninstantiated variables 
instance template change tag previous tag variables 
possible instantiations specified templates defines set allowable transformations 
application transformations adversely affect quality annotation resulting divergence manually annotated treebank result accurately annotated corpus 
learner searches transformation application result greatest improvement annotation quality easily measured applying transformation comparing resulting annotations manually annotated treebank 
best transformation recorded ordered set learned transformations applied training corpus 
learning continues learner find best transformation corpus annotation results applying learned transformation training corpus 
learning stops effective transformations meaning transformations improve performance improve performance threshold 
outlines learning process 
example initial corpus errors comparing annotated corpus gold standard manually annotated corpus 
time possible transformations tested 
transformation transformation applied time applied corpus resulting new corpus corpus 
errors corpus 
transformation obtained applying transformation corpus obtained initial state annotator results corpus errors 
third transformation results annotated corpus errors 
corpus lowest error rate transformation learned transformation learning continues corpus corpus resulting applying transformation corpus 
show transformation error driven learning effective learning method number structural language learning tasks including part speech tagging prepositional phrase attachment parsing 
measure success guide learning coarse grained measure probably lead successful learning 
instance learning bracketing transformations measure function brackets 
means small change affect measure 
coarse grained measure learning number bracketed sentences training corpus precisely match bracketing manually annotated corpus measure sufficiently sensitive minor bracketing changes adequately guide search 
currently explored learning method obtaining ordered list transformations greedy algorithm stage adds transformation highest success score 
control strategies search look ahead greater transformation strategies dealing large search space simulated annealing genetic algorithm 
transformation error driven learning pieces knowledge need prespecified start state annotation algorithm set transformation templates 
prespecified knowledge cheap create 
created cost porting different domain language obtaining small annotated corpus 
start state transformation templates completely general interaction learner training corpus results domain language specific knowledge obtained 
learning completed new text annotated simply passing start state annotator applying learned transformations order 
corpus obtained applying initial state annotator 
transformation applied entire corpus resulting corpus 
second transformation applied corpus list transformations exhausted 
corpus errs corpus errs corpus errs corpus errs corpus errs corpus errs learning transformations corpus corpus corpus applying transformations transformation error driven learning degenerate instance means ends analysis 
gps general problem solver probably earliest successful implementation means ends analysis system 
gps set rules specified 
rules parts preconditions satisfied trigger rule effect carrying rule 
search strategy employed gps complex learner 
gps problem decomposed set easier problems way better enable system lessen difference current state desired state 
transformation learner decomposes problem getting naive annotation proper annotation set subproblems iteratively biggest improvement step possible 
general means ends analysis states saved backtracking employed 
progress forward direction current state goal backwards goal current state 
addition transformations learned transformation learner rules gps prespecified 
technique employed learner similar decision trees 
decision tree trained set preclassified entities outputs set questions asked entity determine proper classification 
tree built finding attribute distribution highest entropy training set asking question attribute splitting training set attribute value recursively reapplying procedure resulting subset 
natural language decision trees applied language modelling part speech tagging 
crucial difference training decision trees training transformation learner training decision tree time depth tree increased average amount training material available node new depth halved binary tree 
transformation learning entire training corpus finding transformations 
addition transformations ordered transformations dependent outcome applying earlier transformations 
instance previous word tagged infinitival preposition may cue determining part speech word 
initially word reliably tagged corpus proper tag cue unreliable 
transformation learner delay positing transformation triggered tag word transformations resulted reliable tagging word corpus 
transformation learner considerably simpler decision tree learning simpler mathematical techniques requiring smoothing pruning trees 
addition resulting learned information compact transformation learning 
example application part speech tagging decision tree tagger described outputs tree leaves transformation learner outputs list fewer transformations 
decision list similar decision tree restricted binary branching right linear 
words decision list set statements form 
questions classifications default classification apply questions decision list answered positive 
main difference decision list ordered set transformations transformation apply single triggering environment 
transformation error driven learning set transformations learned application order completely specified deterministic 
different approaches annotation 
parsing context free grammar algorithm examine different possible combinations rules find set rules generate sentence 
statistical part speech tagging dynamic programming find highest probability path set states 
approach assigns structural annotation input sentences including sentences exhibiting phenomena observed training corpus noisy input 
approach works assigning default annotation structure sentences altering structure triggering environments 
different parsing grammar set rules account relationship tokens input fail parse sentence covered grammar 
proposals handling sentences covered grammar discussed 
example see 
error driven learning succeed case set ordered transformations learned application significantly improves performance accuracy obtained simply start state information 
case transformation application proves fruitful learning process prove fruitful text training corpus 
error driven learning computationally feasible easy apply set operations recognize set triggering environments 
run time learning algorithm jnj number allowable transformation operations number possible triggering environments jnj training corpus size large set operations environments learning computationally infeasible 
chapters detail error driven learning successfully applied number domains including part speech tagging prepositional phrase attachment parsing 
help ideas described section briefly outline error driven part speech tagger developed discuss detail chapter 
system initial state algorithm tags word probable tag isolation guessing procedure unknown words 
allowable operations form change part speech tag predefined set part speech tags 
set triggering environments includes 
current word 
previous word tagged 
word tagged transformation tagger learning fewer transformations obtains tagging accuracy comparable state art stochastic taggers spite fact resulting knowledge base considerably smaller entirely 
understand success error driven learning examine rank frequency distributions 
particular stage learning training set instance explained learning algorithm data driven empirical run time considerably better theoretical upper bound 
tagger tag word changed word tagged training corpus 
particular operation triggered particular environment little information gleaned transformation improve performance new text 
general instances observe effect transformation information effect transformation fresh text 
rank frequency plot relatively flat meaning instances transformations applied training corpus error driven learning probably prove fruitful 
error driven learning systems examined rank frequency plot highly skewed 
turn examination zipf law empirical observation rank frequency plot different language phenomena different languages highly skewed 
word zipf law zipf law empirical observation different domains rank element divided frequency occurrence element constant 
instance city populations obey zipf law mean populous city population second largest city population third largest 
reproduced demonstrates phenomenon actual city census data 
zipf observed law hold frequency data number disparate areas including city populations word frequencies texts written various languages 
attributed phenomenon called principle effort 
subsequent zipf claim uncovering universal property human nature number publications demonstrated zipf law necessary consequent assuming source language frequency data taken simple stochastic process 
george miller elegantly puts suppose acquired dozen monkeys chained produced long random sequence characters 
suppose defined word monkey text assuming training text fresh text come source 
city rank population rank population gamma new york chicago los angeles philadelphia detroit houston baltimore cleveland st louis milwaukee francisco dallas data census sequence letters occurring successive spaces 
suppose counted occurrences words just way zipf counted occurrences real words meaningful texts 
plot results manner find exactly zipf curves monkeys human authors 
zipf curve mean highly skewed rank frequency curve statement true 
assuming characters plus space probability particular word length monkeys type different words probability different words aa ab zz probability 
sufficient note empirically zipf law roughly hold linguistic frequency data sorts different languages 
plotting rank versus frequency different domains including words word bigrams part speech bigrams part speech sequences noun phrases resulting graph highly skewed high frequency types accounting large percentage total tokens large number types occur infrequently 
distributional techniques explored dissertation approximating true distributional behavior element triggering environments error reducing transformations observed behavior large corpus 
instances element corpus accurate approximation 
zipf law tells difficulty drawing distributional observation elements element type interested word phrase 
addition indicating elements occur low frequency deduce great number elements allowable occur corpus 
difficult know element corpus indicates element permitted language permitted just occur sample corpus 
ignoring problem approaches dealing 
smoothing techniques better approximate probability low probability events 
second approach distributional techniques dependent low probability environments 
transformation learner takes approach 
concerned accuracy measured tokens types zipf law advantage 
small percentage words appear corpus appear high frequency high frequency words account large percentage total tokens corpus 
consider experiment 
take equal portions french english text new text repeatedly moving word picked randomly text new text 
give text somebody knows english french ask take word appearing mixed text label word french english 
person picked randomly correct 
provide person list probable words english french accuracy obtained 
word list extended words accuracy possible 
person asked build dictionary listing words appearing text english french accuracy percentage sentence car ate car tokens types 
correct dictionary entries assuming text size words giving lists words give accuracy 
give concrete example zipfian behavior natural language corpus brown corpus percent word types account percent word tokens 
percent word types occur fewer times corpus 
percent word types occur fewer times percent occur 
rank frequency plots transformation number versus transformation score training set test set highly skewed reason transformation learner effective 
score received training corpus plotted function transformation number showing highly skewed zipfian distribution 
transformations learning unknown word information wall street journal 
experiment specifics score described 
skewed rank frequency curve error reducing transformations results number properties learner 
training test set long tail low frequency events corpora 
events low frequency occur exclusively training corpus test corpus 
event triggering environment occurs training corpus harmless overtraining result system learn transformations remedy error specific sample corpus 
occurs different form example triggering environment leads beneficial transformation corpus detrimental harmful overtraining result 
problem resolved lessened second training corpus prune transformations 
nature learner overtraining harmful transformation learning learning paradigms applied corpus learning instance see 
stage learning transformation learner learns transformation results greatest error reduction 
seen graphs chapters accuracy typically improves information character level morphological information probability information character pair occurrences significantly increase accuracy 
corpus words containing samples different genres written english 
transformation number score zipfian distribution transformation scores 
rapidly applying transformations rate improvement declining transformations applied 
assuming training test sets generated source probability transformation results high improvement training corpus specific particular sample corpus smaller probability occurring low improvement transformation 
overtraining occur generally occurs low improvement transformations contribute final structure 
low improvement transformations arise overtraining necessarily result performance degradation 
triggering environments transformations occur test corpus resulting change occur low frequency typically resulting random change transformation due overtraining positive change 
event occurs test corpus low frequency event 
low frequency incorrectly processing result great performance degradation 
negative side events truly exhibit zipfian distribution doubling size training corpus roughly half number unseen events test corpus 
behavior result ceiling achievable performance method 
luck performance ceiling bounds usable system performance 
expressive set transformations complicated search strategy lift performance ceiling 
note zipf distribution respect certain descriptive language describing events 
possible learner tail distribution switch different descriptive language redistribute residual errors way zipf 
chapter overview transformation learning system main goal dissertation propose particular corpus learning algorithm evaluate effectiveness learning structural information natural language 
harris structural linguists developed programs aid field linguist uncovering structural information language programs language learning systems 
advent fast computers availability annotated line corpora worthwhile reconsidering corpus learning algorithms real language learners 
developed learning algorithm believe quite successful learning considerable amount structural information language 
building programs comprise learning system follow harris layered approach addressing learning word classes learning phrase structure 
done part mapping words classes help get sparse data problem phrase structure learning 
describe weakly supervised transformation error driven learning method learning necessary information accurately tag words appropriate word class tag particular context 
steps process 
lexical information learned guess tag word 
small corpus annotated parts speech larger unannotated corpus training 
words seen annotated corpus lexicon built indicating tag 
annotated unannotated corpus automatically learn set transformations tagging words covered lexicon 
second contextual cues learned improving tagging accuracy 
method described parsing text word class information discovered 
parsing module error driven learning 
parsing broken steps bracketing information learned second information learned label nonterminal nodes 
structure output parsing module fed modules decrease errors 
module prepositional phrase attachment module increase accuracy learner task 
final goal project train different learning modules unannotated free text assigned proper structural annotation 
aiming structure proper platonic sense attempt match structure provided manually annotated corpus 
provides objective way evaluating success different learning modules 
module evaluated independently effectiveness lexical modules measured accuracy phrase structure modules trained text annotated transformations learned lexical modules 
language learning modules operate various structural levels share thing common 
learn structure tool transformation learning 
learning paradigm system begins language naive state 
system repeatedly compares output proper output learns transformations output better resemble correct output 
cases set allowable transformations extremely simple 
parts transformations transformation environment triggers 
modules learner triggering environments simple 
example bracketing module necessary property learning paradigm true learning modules described dissertation 
transformation triggered part speech single word pair contiguous words 
simple transformations small training corpora try increase portability system 
system built information adequately trained relatively small corpora system easily annotate corpus little time person annotate small training corpus 
goal produce system readily adapted new task minimal human supervision 
field corpus natural language processing highly empirical 
difficult impossible give formal explanations performance technique applied natural language corpus 
part little known underlying structure natural language 
success method demonstrated empirically 
careful attempts empirically demonstrate performance system 
testing training carried corpus know merely method happens corpus corpus 
partially address concern tested learning procedure number different corpora 
tested genre wall street journal brown corpus atis corpus part speech tags penn treebank tagging original brown corpus tagging languages english old english 
discuss details different learning modules 
touch certain obvious problems explicitly implicitly training developing test data methodology flaw takes away possibility making claims system capturing generalizations 
chapter lexical information chapter describe method tagging large corpus infinite stream text small corpus 
words tagged text large corpus untagged text training material 
steps process 
set part speech tags 
probably done manually fairly easily provide tool aid person choosing set tags 
step central part thesis interesting useful 
second step involves learning lexical information 
step set transformations rules discovered applied word order find word part speech 
appears case tagging word corpus tag result fairly high tagging accuracy 
step learning information word types 
trying learn tag words learn set transformations contextual information correct errors tagging 
information level word tokens 
example learned lexical phase modal contextual phase learn particular word appearing immediately right word noun 
able reliably classify words necessary step automatically annotating corpus phrase structure 
phrase structure learning done word classes serious sparse data problems arise viewing corpus merely string words abstracting away general classes 
mapping words classes english old english corpora examined 
necessary generalization overcoming sparse data 
likewise rule stating determiner noun combine noun phrase easier learn large number lexical pair rules required word class information available 
providing words syntactic labels useful information syntactic tree transformation phrase structure learner converts syntactic tree labelled tree nonterminal nodes labelled 
reliable part speech tagger useful tool isolation 
part speech tags aid systems spelling correctors speech recognition generation systems 
instance speech system properly pronounce word record know word noun verb 
number fairly reliable part speech taggers developed may ask bother exploring possibility creating part speech tagger minimal human supervision 
shown tagger trained corpus perform worse different corpus 
experiment run tagger trained wall street journal tested muc corpus corpus texts terrorism latin america 
training testing done muc corpus 
training testing type corpus resulted reduction error training testing different types corpora 
wishes precise tag set tagger trained apply tagger exact type text training tagger trained minimal human supervision unnecessary 
wishes different tag set apply tagger different corpus tagger different language tagger retrained 
currently training accurate tagger requires great deal human labor 
example tagger described program includes ffl statistics gathered words manually tagged text 
ffl rules discovered experimentation dealing hard tagging distinctions proper noun vs common noun 
ffl manually encoded list dates proper nouns titles states 
ffl module dealing hyphenated words 
ffl retrain tagger significantly different corpus extremely tedious 
addition requiring large amount manually tagged text additional rules turn corpus specific rewritten 
propose tagger easy train smaller annotated corpus needed training procedure automatically learns appropriate transformations corpus tagged 
corpus specific language specific information need specified 
means cost terms human effort needed retrain tagger different tag set corpus language minimal 
word classes tagger built tag set specified 
strong evidence set possible classes distinguished language unbounded 
thought classes noun verb fundamental language 
wrote quoted language wholly fails distinguish noun verb particular cases nature distinction may elusive 
different parts speech 
imperatively required life language 
lakoff describes language class fire dangerous thing exists 
class ancient folklore society 
processing corpus automobile subdomain sense specify class automobile names general text specific class may inappropriate 
set possible word classes unbounded prespecified truly portable natural language processing system 
classes language particularly sublanguage learned 
section demonstrate semi automatic method determining set appropriate word classes particular corpus 
note classifying certain method described subsection determining set classes words stage merely finding set classes words assigned 
paths pursued chosen pursue fully automatic word class discovery decoupling word class discovery word classification 
chosen pursuing amount manual labor necessary semi automatic method small see need fully automatic system 
approach attempted believe decoupling advantage intelligently small amount human supervision guide learning process way lead intuitive classes :10.1.1.13.9919
possible disadvantage approach evaluation measure possibly counterintuitive humans set classes results greatest reduction entropy adding human intuition may mislead learner 
goal learning module aid human choosing set part speech tags 
word similarity tree built frequently occurring words corpus 
tree built initially making word node repeatedly combining similar pair nodes single node words reduced just node 
regions tree tend correspond word classes 
looking similarity tree help person decide set appropriate part speech tags 
hypothesis words syntactically semantically dissimilar difference manifest syntax lexical distribution idea suggested 
idea amenable automation assuming distributional information local environments accurately characterize distributional behavior word 
particular information probabilities words occurring immediately particular word distributional characterization 
number different similarity measures 
chose relative entropy known kullback leibler distance :10.1.1.14.5452
kullback leibler distance probability distribution probability distribution defined necessary accomplish done rapidly human introspection 
human scratch probably require linguistic knowledge familiarity corpus processed 
earlier versions appear 
jjq log divergence defined div div jjq qjjp words left probability word occurring immediately left right lef right defined likewise 
define similarity sim gamma div right right div left left sim ranges sim 
problem encountered probability estimates zero 
get small percentage probability mass redistributed ensure probability estimates greater zero 
build similarity tree 
initially word node 
repeatedly combine similar nodes node node remains 
node similarity defined average similarity words nodes 
frequently occurring words brown corpus shows pairs deemed closest distributionally sim measure 
classes words brown corpus word pairs seen fewer times considered probability zero 
word bigrams brown corpus occur frequency greater 
ignoring low frequency bigrams greatly reducing computation time affect word pair similarity results 
means issues providing probability estimates observed frequencies zero need addressed 
experiment run corpus roughly words transcribed utterances addressed parents young children 
similar pairs corpus listed 
list see word lists different method effective cases grouping word pairs give kind number find take get take find get take men children give take men people face head came went get find give get sense kind time day may word similarities brown corpus share features 
significant results obtained parental speech corpus noisier brown corpus containing false starts typos fragments run ons 
experiment run voyager corpus corpus consisting mainly short questions cambridge boston 
version corpus fewer words total 
frequently occurring words chosen similarity tree built words 
shows word pairs similar distributionally corpus 
example sublanguage classes note walk get considered similar voyager corpus consider words similar normal unconstrained language 
voyager corpus get mean mean get point point sense get synonymous walk 
method looks somewhat promising shown extract useful set classes automatically resulting similarity trees 
kendall central harvard inman squares 
dolphin legal restaurants 
marriott charles hotels 
pearl magazine streets 
massachusetts western avenues 
mark ross show tell door table okay oh ok okay head mouth oh ok okay ok oh ok cause put take bring give mouth nose word similarities parental speech kendall central show tell inman central dolphin legal inman harvard marriott charles pearl magazine intersection address walk go closest nearest library walk get massachusetts western get go magazine broadway kendall harvard central harvard mit near inman kendall station square far long word similarities voyager corpus number attempts automatic word classification approach similar described section 
words classed distribution subject verb object relationships 
method succeed need able accurately parse text analyzed prior word classification 
classification method described requires structural information 
attempt classify words immediate neighbors 
similar definition environment system different measures similarity 
ran small scale experiment running learning procedure basic english sentences simple introductory english language text containing total different words 
method proposed kiss fully automatic 
manually chooses set words clustered 
experiments left open question techniques succeed free text 
describes method classifying words distributional similarity words adjacent word environments :10.1.1.13.9919
attempt find assignment words classes results smallest loss average mutual information immediately adjacent word classes corpus 
number important differences algorithm algorithm 
thing algorithm words compared distributional similarity respect adjacent words 
algorithm words grouped compared way 
words compared corpus words reduced word classes 
mapping words classes benefit making sparse data problem distributional comparisons precise 
method uses high frequency observations sparse data problem 
algorithm classification sensitive word frequency 
calculating reduction average mutual information 
high frequency words may grouped lower frequency words similar doing results greater average mutual information 
system word pairs list frequently occurring words weighed equally 
addition method computationally expensive 
compute divergence words high frequency environments 
calculate mutual information entire corpus recalculate time pair words mapped class 
approaches clustering indicate great deal information gleaned local environments clear approach outperform approach guided small amount human supervision 
important emphasize believe clustering method described succeed finding useful set word classes correctly assigning words corpus classes 
view clustering procedure way eliciting classes salient corpus 
classes established procedure outlined chapter assign words classes 
similarity tree automatically created word classes relevant particular corpus correspond particular regions similarity tree 
expect procedure result tree meaningful areas tree aid human glean useful set word classes corpus 
set classes semi automatically derived step learn classes word belong rules governing word class disambiguation 
method accomplishing described section 
addition aiding creation set part speech tags similarity trees serve function 
part speech phrase structure learning modules sparse data problem 
sparse data problem certain modules employ transformation learning 
instance attachment module described transformations head noun phrase verb phrase 
assume head noun phrase noun part speech tags provide additional information 
transformations particular words sparse data problems may encountered 
solution problem manually created lexical hierarchy wordnet allow transformations words word classes word belongs 
drawback approach manually created hierarchies expensive time consuming create 
alternative method avoiding sparse data involves creating distributional similarity tree nouns corpus 
unique feature name associated nodes tree 
word feature word descendent node labelled feature name gammax 
transformations allowed class names particular words 
results classes ignore nodes distance root mod appropriate finding tag word step building tagger try find tag word 
number ways view problem 
concrete address specific problem small tagged corpus larger untagged corpus try accurately tag large untagged corpus 
example corpus words tag informant tag small subset corpus learning procedure tag rest 
words large untagged corpus occur tagged corpus initially tag tag indicated tagged corpus 
words learn cues help automatically guess part speech 
transformation error driven learning 
unknown words big problem part speech tagging especially building lexicon small corpus 
show graph percentage tokens test set lexicon built training set various sized training corpora wall street journal 
lexicon built words text fewer word tokens new text training text 
lexicon built corpus words word tokens new text included training text 
number different part speech tagging systems addressed problem unknown words 
interested system easily trained retrained new domains languages discuss methods great deal domain dependent knowledge built 
probabilistic method tagging unknown words discussed 
methods fairly similar size training corpus tokens unseen unknown words vs training corpus size size training corpus entropy unknown tags entropy vs training corpus size describe algorithm 
tagger markov model tagger trained tagged text 
known words jt estimated corpus 
assume large training corpus assumption unknown words tagged open class penn treebank part speech tags 
note assumption system training set smaller may cover closed class words 
entropy tag distribution unknown words greater small corpus build lexicon large corpus 
entropy tag distribution unknown words gamma tags log graphed function training corpus size wall street journal samples previous 
unknown words addressed attempting tag trigram model adding unknown open class tags training carried words tagged text wall street journal 
words general lexical information regarding class unknown words contextual probabilities combined general lexical information disambiguate 
results accuracy tagging unknown words 
try lexical probability unknown words jt unknown capital endings capital feature possible settings endings set manually chosen suffixes 
results accuracy large training corpus 
demonstrate approach significantly outperforms statistical method tagging unknown words trained smaller training corpus obtains comparable performance large corpora 
different statistical approach taken determining class unknown words 
informant listed open class tags corpus 
open class tag small list exemplar words 
exemplar words build distributional fingerprint open class vector probability words appearing immediately class exemplar words corpus 
unknown words classified comparing distributional fingerprint open class assigning class similar 
similarity measure relative entropy 
transformation approach significantly outperforms distributional approach classifying unknown words 
transformation system lexicon initially built small manually annotated corpus 
want keep corpus small possible minimize amount person needs put able ignore issue encountering words appear lexicon 
initial state transformation learner assumes seen words default label part speech tag 
default label set explicitly state training corpus size experiments table error rates known words unknown words knowledge percentage unknown words function corpus size 
frequently occurring tag measured word types training corpus 
set transformation templates prespecified defining types cues indicate assumed tag word altered 
currently templates ffl change tag deleting prefix jxj results word 
ffl change tag characters word ffl change tag deleting suffix jxj results word 
ffl change tag characters word ffl change tag adding character string suffix results word jxj 
ffl change tag adding character string prefix results word jxj 
ffl change tag word appears immediately left right word 
ffl change tag character appears word 
ffl transformations modified say change tag templates extended handle languages infixes allowing transformation change tag character string appears internal word 
note transformation templates trigger determined unannotated text 
trigger applies particular word type computed words word pairs occurring large unannotated training corpus 
note bigram statistics characterize words 
approach taken different reasons processing efficiency constrained frequently occurring words arbitrarily set experiments described 
systems statistical information word pair cooccurrence 
information boolean value particular bigram seen training corpus 
similar distributional environments theory harris 
harris states sum total allowable short environments entity licensed appear may way classify words linguist find diagnostic environments test word belongs particular class 
essence providing automatic procedure discovering diagnostic environments 
order transformation learner fully specified define evaluation measure search ordered list transformations 
small annotated corpus corpus measure effect carrying particular transformation 
somewhat careful results applying transformation evaluated 
evaluate results token basis results skewed favor higher frequency words 
high frequency words treated unknowns probability words occurring training corpus relatively high 
avoid problem success measured type basis token basis 
means effect transformation tagging word equal consideration effect word upside 
transformation says change common tag word trigger holds word score word annotated corpus freq gamma freq freq current trigger holds word current currently tagged frequencies calculated small manually tagged corpus 
function measures type improvement results carrying transformation 
learn ordered set transformations find transformation best score add transformation list apply transformation corpus find best transformation transformed corpus transformations score best transformation drops threshold 
run time learning algorithm jnj number allowable transformation operations number possible triggering environments jnj training corpus size number word types annotated lexical training corpus 
fortunately apply possible transformation learning iteration 
learning data driven 
theoretical upper bound number transformations tested significantly greater number transformations examination triggered occurrence corpus 
example wall street journal sample sentences part speech tags 
tag pairs trigger transformations transformations examined search data driven 
reality part speech tag bigrams occur sample corpus 
sample text unique characters possible suffixes length 
suffixes length occur sample corpus 
shows short perl pseudocode program iteratively finds best transformation assuming allowable transformation template tag word letter method learning essentially modules describe pseudocode detail 
transformations positive score search best transformation current state corpus 
possible tag possible word update score changing tag letter word examined 
scoring completed scores tag letter pairs examined pair best score recorded best transformation 
transformation applied corpus process freq number times tagged training corpus 
continues 
procedure data driven sense theoretically check tag letter pairs really pairs containing letter occurring corpus 
difference theoretical actual run time significant dealing sparsely distributed phenomena letters word 
ordered list transformations learned transformations applied order words fresh text test corpus occur training corpus large unannotated corpus determine transformation trigger applies particular word 
upper bound placed run time carrying single transformation run time linear respect size unknown word list corpus annotated transformation list 
function transformation list size jt unknown word list size jnj run time jt jnj 
results assess accuracy learning module tested different english corpora corpus old english 
different part speech sets penn treebank tags brown corpus wall street journal original brown tag set brown corpus tag set derivative penn treebank tags derived eric haeberli tony old english corpus :10.1.1.14.9706
wall street journal wall street journal corpus set stories wall street journal sorted chronological order 
corpus follows total sentences words 
training done sentences testing done sentences 
provided buffer sentences training testing set minimize proximity effects 
lexical part speech information learned annotated subset corpus lexical training corpus consisted sentences words corpus 
contextual eric haeberli tony annotating old english corpus 
combined files created rich 
stores best transformation 
bestscore bestscore stores score best transformation 
start arbitrary nonzero setting get program going 
nn np list part speech tags wordlist stdin annotated training corpus word list 
bestscore bestscore foreach tag undef transformation foreach word wordlist characters split word characters characters get letter word 
tag score word tag alter score transformation involving currently processed tag letter 
key val transformation go recorded transformations find best score 
temp split ns key tag temp letter temp val bestscore bestscore val change tag letter ggg print nn perl pseudocode learning simple transformations 
annotated test corpus annotated lexical training corpus annotated contextual training corpus unannotated training corpus entire corpus dividing corpus running experiments 
information learned contextual training corpus consisted second sentences corpus see 
lexicon built indicating tag words annotated lexical training set sentences 
tokens test set appear training set tagging words learned tag results accuracy 
unknown words initially assumed singular nouns 
gives tagging accuracy unknown words measured tokens types 
transformation scores computed annotated lexical training corpus trigger information particular string word entire unannotated training corpus 
total transformations learned 
list learned transformations 
transformation states tag word changed plural noun 
second transformation states tag word changed common see appendix listing description penn part speech tags 
noun proper noun seen large unannotated corpus sentence 
second transformation applies words tagged common nouns default plural nouns result transformation 
second transformation applies singular common nouns plural common nouns appear sentence 
interaction transformations number interesting 
transformations combined state word letter second letter tagged plural noun 
obvious transformations approximated learned transformations ffl word begins capital letter proper noun 
ffl word contains characters word number 
transformation templates currently sufficiently expressive capture information concisely 
transformations applied list unknown words test corpus accuracy improving initial tagging accuracy unknown words tagged singular common nouns final accuracy 
graph accuracy function transformation application number seen 
investigated possibility pruning transformation list 
transformations pruned applying second training corpus deleting transformations application resulted lower accuracy 
doing resulted transformations application test set resulted accuracy slightly lower unpruned transformation list 
results applying pruned transformations test corpus seen 
applying unpruned list transformations result performance improvement result performance degradation result change 
applying pruned list transformations result performance improvement result performance degradation result change 
pruned list results marginally worse performance fewer bad transformations 
unfortunately number effective transformations deleted pruning 
experiments done training word classifier threshold chosen change tag condition 
nns suffix nn np appear start sent 

vbn suffix ed 
cd appear right 
vbg suffix ing 
jj character appears word 
jj adding suffix ly results word 
rb suffix ly 
np appear right nn vb appear right nn cd character appears word nn jj appear right nn np character appears word 
np character appears word vb nn appear right 
np character appears word nns vbz appear right 
np character appears word nn np character appears word 
np prefix nn np character appears word nn np character appears word nn jj suffix nn cd character appears word 
np prefix nn np character appears word nns nn suffix ss np appear left jj nn appear left 
np appear left transformations wsj corpus 
transformation learning continued score learned transformation met threshold 
threshold set experiments chapter 
threshold chosen prior testing picked somewhat arbitrarily 
higher threshold advantage learning transformations high probability useful lessening amount overtraining 
higher threshold advantage speeding run time 
rank frequency distribution errors highly skewed 
instance transformations learned wall street journal transformations scores range range range 
higher threshold hurt performance throwing away effective low frequency transformations 
threshold threshold set accuracy transformations obtained unpruned transformation list slight improvement performance significant reduction number transformations 
threshold automatically determined running trained annotator held training set threshold set zero determining threshold value results highest accuracy 
annotated training corpora train lexical tagger explore effect training corpus size accuracy 
effect doubled size lexical training set sentences sentences 
larger training corpus increased percentage known words test set 
known word accuracy remained 
transformations learned tagging unknown words resulting unknown word tagging accuracy compared trained sentences 
total accuracy type lexical information rose part due accurate tagging unknown words part due lower percentage unknown words test set 
doubling size lexical training corpus sentences resulted unknown word tagging accuracy total accuracy 
see table 
keep mind results obtained prior token contextual information 
compared results results cited tagging unknown words lexical probabilities jt unknown capital endings transformation number accuracy unknown word tagging accuracy applying transformations 
training corpus unknown wd 
total size sents 
accuracy accuracy table initial tagging accuracy function training corpus size 
transformation number accuracy unknown word tagging accuracy applying pruned transformations 
unknown words described 
state suffixes system listed 
implemented algorithm suffixes list 
testing training carried corpora experiments 
lexical probabilities accuracy unknown words obtained 
sophisticated probability estimate unknown words accuracy compared accuracy transformation approach 
extended suffix list suffixes reran experiment obtaining accuracy unknown words 
note transformation approach obtains higher accuracy contextual information probabilistic approach approach resulting transformation annotator completely symbolic 
language specific information built transformation learner 
statistical approach assumptions include hyphen tagging cue proper nouns indicated combination capitalization position sentence suffixes indicators word class 
transformation approach information prespecified learned 
section improve unknown word accuracy known word accuracy context triggered transformations 
brown corpus experiment ran penn treebank tagged brown corpus 
sentences corpus randomly shuffled 
sentences words lexical training set second sentences words contextual training set sentences words testing entire unannotated corpus unannotated training corpus 
word tokens test corpus appear lexical training corpus 
known words test corpus tagging tag indicated lexical training corpus results accuracy 
initially tagging unknown words singular common nouns results unknown word accuracy 
difference accuracy probabilistic method quoted accuracy obtained implementation due smaller training set train implementation 
transformations learned application test set results unknown word accuracy 
list learned transformations shown 
changing learning score threshold results higher accuracy fewer transformations 
particular doing results transformations accuracy 
ran stochastic tagger stochastic unknown word recognition extended suffix list 
resulted unknown word accuracy lower accuracy obtained transformation learner despite fact contextual token information transformation learner 
differences transformations learned wall street journal learned brown corpus worth noting 
transformation indicating word right dollar sign number useful transformation wall street journal transformation number brown corpus transformation number 
probably due fact business tends transformation brown corpus states word appear right word past tense verb learned trained wall street journal 
ran experiment brown corpus original brown corpus part speech tags 
original brown corpus tag set considerably larger penn treebank tag set 
brown corpus penn treebank tags occur original brown corpus tags occur 
corpus randomly shuffled divided annotated lexical training corpus sentences words annotated contextual training corpus sentences words test corpus sentences words 
tokens test corpus occur lexical training corpus 
lexical transformations learned tagging unknown words resulting accuracy unknown words 
accuracy known words 
changing transformation finding threshold results unknown word accuracy transformations 
fact accuracy greater penn treebank tags probably due fact fewer tags choose 
see appendix description tag set 
change tag condition 
nns suffix 
np appear start sent 

vbn suffix ed 
jj adding suffix ly results word 
rb suffix ly 
vbg suffix ing nn vb appear right 
vbd appear right 
jj character appears word 
cd character appears word 
np character appears word 
np character appears word nn jj suffix ic nn jj appear right 
np character appears word nns nn suffix ss 
np character appears word 
np character appears word 
cd appear right jj nn appear left transformations penn treebank brown corpus 
change tag condition 
nns suffix 
vbn suffix ed 
jj adding suffix ly results word 
vbg suffix ing 
ly suffix ly nn np appear start sent 

vb appear right nns np character appears word 
vbd appear right 
jj suffix ble 
cd character appears word 
jj suffix ic np nn appear left 
np appear right nns nn suffix ss 
jj suffix np nn appear right nn jj appear right jj nn adding suffix results word nn np prefix transformations original brown corpus 
show transformations learned 
eighth transformation change tag plural common noun possessive proper noun appears word appears training original brown corpus tags penn treebank tags 
penn treebank words america america 
ran stochastic tagger training test sets large suffix list obtaining unknown word accuracy lower obtained transformation approach 
old english step better understanding general learner really tested corpus old english 
corpus helsinki corpus english texts diachronic contains varied collection written old english 
originally planned middle english rigid spelling conventions old english language amenable learning algorithm 
old english similar ways modern languages german 
quite different modern english 
old english morphological cases marked endings article adjective noun 
articles adjectives nouns marked gender 
old english word order modern english 
generally verb occurs final position subordinate clauses second position main clauses 
complements adjuncts rigid order modern english 
access word unannotated corpus words manually tagged 
done annotated corpus divided lexical training contextual training testing 
annotated corpus small allowed training sets overlap 
training corpus contained words divided lexical training corpus words contextual training corpus words 
test corpus contained words 
word tokens test set occur lexical training set 
training lexical part speech tagging module transformations learned 
shows learned transformations 
initially unknown words tagged singular common nouns nn 
graph accuracy function transformation number test corpus seen 
reason unusual shape curve compared smoother curves obtained english corpora bit mystery 
initial accuracy obtained tagging unknown words nouns 
reason significantly higher english corpora smaller tag set old english differentiate proper nouns common nouns distinguish singular plural nouns 
tag set old english appendix 
applying transformations accuracy obtained 
transformations pruned discarding resulted decrease accuracy applied contextual training corpus reduced transformation list transformations application test set resulted slightly higher accuracy 
threshold transformation scores raised eric haeberli providing linguistic details old english 
manual tagging done eric haeberli 
change tag condition 
vt appear right ne 
vt suffix 
vt suffix 
nn appear right 
vn suffix vn nn deleting suffix results word 
rb suffix 
vt suffix ode 
vt suffix 
vn suffix 
vt appear right nn jj appear right swi de 
vbn suffix ed 
vbg suffix ende 
nn appear right nn vt deleting prefix results word nn vt deleting prefix results word 
nn appear right nn vt prefix 
vt suffix st transformations old english corpus 
unpruned list transformations accuracy obtained transformations 
table summarize results section obtained prior contextual token information 
note experiments done small training corpora portability important issue 
shown taggers trained domain tag high accuracy tested different domain think tagger requiring millions words tagged text training practical real world situations part speech tagger desired 
section results larger training corpora 
known words tagged tag indicated lexical training corpus 
unknown words tagged assigning default tag applying learned transformations 
notice prior incorporating context triggered transformations transformation number accuracy unknown word tagging accuracy applying transformations 
unknown known method corpus words words total lexical transformations wsj probabilistic tagging wsj lexical transformations brown penn tags probabilistic tagging brown penn tags lexical transformations brown orig tags probabilistic tagging brown orig tags lexical transformations old english table summary accuracy lexical learning 
transformation approach significantly outperforms probabilistic approach tagging unknown words relatively small training corpora 
implement stochastic tagger run old english corpus truly portable transformation tagger list significant affixes old english knowledge tagging cues necessary run stochastic tagger corpus 
learning context triggered transformations improve accuracy learning tag words appearing small annotated lexical training corpus method predicting tag unfamiliar words step contextual cues disambiguate word tokens 
transformation learner 
describe transformation part speech tagger 
tagger works tagging word probable part speech estimated large corpus annotated text automatically learning small set contextually triggered transformations improve tagging performance 
doing similar decision tree learning decision tree sparse data problems abound binary decision tree level deeper tree half training material average level 
evidence domain tagging methods comparable error rates see 
demonstrated fewer symbolic contextual transformations performance obtained comparable stochastic taggers capture contextual information tens thousands contextual probabilities smoothing techniques overcoming problem estimated probabilities zero 
particular tagging accuracy external dictionary trained brown corpus tested held test set dictionary derived entire brown corpus 
give example transformation system capture contextual information concisely look transformation number says tag changed vbp vb previous tags modal 
express terms contextual probabilities need statistics grams form ffl md vb ffl md vbp ffl md vb ffl md vbp ffl md vb ffl md vbp part speech tag 
large set statistics method smoothing handle grams occurring training corpus capture information comparable single transformation relative counts different grams vb vbp 
small annotated corpus needed learning context triggered transformations large annotated corpus words training tag tagger procedure tagging unknown words 
addition tagger included manually created rule distinguishing common nouns proper nouns 
tagger weakness taggers portable 
described different earlier transformation tagger ways 
uses tag information learned module discussed section requiring significantly human labor preparing training material 
second specific assumptions built learner tagger 
built assumptions types cues anticipate reflected set transformation templates 
specific information cues distinguishing proper common nouns learned 
system portable 
addition transformation tagger described tagging word test set seen training set changed word tagged training corpus 
training corpus smaller assume sort closure reached training corpus set allowable tags words 
templates context triggered transformation learner ffl change tag previous word tagged previous word tagged word tagged preceding words tagged preceding words tagged preceding words tagged word words tagged transformation module lexical information contextual information module uses score token performance type performance 
contextual module discovers transformations applied word tokens particular environments lexical module discovers transformations transformation list easily extended words word classes different properties words 
word triggering environments added method advantage stochastic taggers relationships words word tag word explicitly captured transformation framework change tag previous word done current statistical approach words mapped tags tag sequence information making underlying words 
applied word types regardless context 
note way bigram information compared stage tagging 
stage tag information learned transformations involving bigrams state tag changed word seen particular word 
phase learning tag changed particular instance word particular word 
score transformation simply token tagging accuracy resulting applying transformation 
score transformation tag tag measured number times transformation applies word tagged currently tagged positive change minus number times transformation applies word currently correctly tagged negative change 
greedy search carried discover set transformations best scoring transformation added transformation list learning iteration 
training run time unknown word learning module jnj number allowable transformation operations change tag tags number possible triggering environments jnj training corpus size 
module training corpus size number word tokens word types 
applying contextual transformations takes jt jnj time jt size transformation list jnj number word tokens tagged 
results wall street journal contextual training corpus learning contextual transformations 
corpus tagged lexical start state described previous section 
annotator parts listing words tag words seen annotated lexical training corpus procedure list transformations tagging words occurring corpus 
lexical information initially tag contextual training corpus 
contextual transformation learner run corpus 
list contextual transformations learned table 
total transformations learned 
table show tagging accuracy applying contextual transformations compare results results obtained probabilistic approach described 
transformation approach performs slightly worse statistical tagger known words sentences lexical contextual training corpora sentences significantly better unknown words 
percentage unknown words decreases training corpus increases statistical approach somewhat outperform transformation approach larger corpora 
instance reran experiments lexical contextual training corpora adding lexicon built additional sentences 
results experiment shown 
experiment transformation tagger performed slightly worse stochastic tagger 
hope extending transformation list lead improvement performance known words 
current set transformations appears transformation system significantly outperforms stochastic tagger small corpus words obtains slightly better performance trained words obtains slightly worse performance words training material 
transformation tagger contains absolutely prespecified corpus specific information relies external aids dictionaries affix lists 
results quoted literature stochastic taggers trained larger training samples penn treebank 
accuracy obtained training words 
lexicon closed sense built training test set unknown words 
accuracy obtained training words 
achieved results competitive results quoted literature stochastic taggers trained large corpora 
significant tagger completely symbolic able capture information tagging concisely 
stochastic tagging lexicon contains entries form training larger corpora transformation tagger probably improved significantly constraining rules change tag word tagged training corpus 
sentences include test set 
unknown word known word accuracy accuracy total sentence lexical contextual training corpora lexical transformations lexical contextual transformations probabilistic small suffix list probabilistic big suffix list sentence lexical contextual training corpora lexical transformations lexical contextual transformations probabilistic big suffix list table wall street journal tagging results 
word tag word tag pairs seen training corpus 
transformation lexicon contains lexical entry word form word tag indicating common tag word training corpus 
contextual information concise wall street journal tagging experiments contextual information expressed trigram probabilities stochastic tagger expressed transformations transformation tagger 
noted transformation tagger currently environment window words trigram tagger environment words 
extend trigram gram tagger order larger context result exponential increase number contextual probabilities exponential increase run time tagger 
table top word tagging errors shown result lexical contextual transformations applied 
error result fact double dash encountered annotated lexical training corpus appear test corpus 
example second frequent lexical error appears result change tag condition nn vb previous tag vbp vb previous tags md nn vb previous tag md vbd vbn previous tags vbp vbn vbd previous tag np vbd vbn previous tags vbz vbn vbd previous tag pp pos vbz previous tag pp vb vbp previous tag nns vbp vb previous tag vb vbp previous tag pp jj nn surrounding tags dt vbd vbn previous tag vbd vb nn previous tags dt wdt surrounding tags nn vbz nn vbp previous tag pp np nn surrounding tags start nns nns np tag np rbr jjr tags nns vbd vbn previous tags vb contextual transformations wsj 
unknown word known word accuracy accuracy total lexical contextual transformations probabilistic table wall street journal tagging results larger lexicon adding sentences 
produces government dubious legitimacy consequences perverse top tag confusions shown 
confusion adjectives nouns accounts total error 
part due difficulty human annotators choosing appropriate tag words compound nouns american indians 
show randomly chosen sentences test corpus 
tagging errors shown highlighted form word system tag correct tag 

miller np np np vbz filed vbn suit nn dt physicians nns group nn wdt sold vbn vbd shirts nns vbg pp miller np lite np ad nn campaign nn texas np 

cc dt nns vbp emerged vbn jjr cd months nns dt departure nn cd pp founding vbg nn partners nns leonard np green np 

jj activities nns vbp rb appear vbp vb meet vb dt standard nn set vbn dt endowment nn pos statement nn principles nns cc objectives nns wdt mandated vbn vbd dt organization nn md rb pick vb cc choose vb dt democratic jj competitors nns countries nns jj competition nn vbz possible jj 

dt derivative jj market nn new issue jj activity nn slowed vbd dt busy jj session nn wednesday np cd real jj estate nn mortgage nn investment nn conduits nns totaling vbg cd cd vbd priced vbn 

cc pp md rb put vbn vb rb rb jj federal np jj money nn rb pp vbd pp solve vb dt problem nn 

dt dt result vb nn pp vbp especially rb keen jj providing vbg wheelchair nn ramps nns lifts nns signers nns deaf nn jj people nns cc readers nns dt blind jj nn 

np np np np repeated jj vbd pp pp offer nn nn yesterday nn nn pp pp said vbd vbd np np np np called vbn vbd tell vb vb pp pp dt dt management nn nn restructuring nn nn 

dt rb np np vbz rb vbn able jj achieve vb dt hoped jj cash flow jj nn boost nn despite replacing vbg cd nn management nn firing vbg cc retiring vbg cd employees nns selling vbg jjs western jj np union np np pos telecommunications nn nns assets nns cc cutting vbg cd cd annual jj operating vbg nn costs nns 

np np replied vbn vbd pp vbd rb interested jj vbn dt hostile nn jj attempt nn 

dt main jj reason nn dt split jj nn vbd vb dt stock nn rbr attractive jj dt retail nn jj buyer nn says vbz elliott np np horowitz np dt nn pos executive nn jj vice nn president nn cc chief nn financial jj officer nn 

cc pp joint jj appearance nn dt speaker nn appeared vbd vb part nn dt effort nn harness nn vb wp momentum nn dt party nn md capture vb dt nn jj power nn dt jj movement nn 

rb np np said vbd tensions nns asia np vbp rising vbg rb falling vbg 

dt carrier nn pos new jj owner nn alfred vbn np np took vbd control nn np august np vbg dt cd cd buy nn jj industry nn observers nns figured vbn vbd europe np pos airbus jj np np vbd dt inside nn jj track nn winning jj vbg plane nn orders nns np 

pleasant np jj neighborhoods nns sit vb vbp rolling vbg hills nns 

cc rb pp vbp vbd cd years nns poverty nn says vbz ed np jones np dt retired vbn tennessee np nn cc dt member nn dt commission nn 

np vbd pp stay vb ex md rb vb rb rb jj vbp vb 

initially rb sony np vbd said vbd pp md rb complete vb dt purchase nn np peters np dt matter nn vbd resolved vbd vbn 

clearly np rb dt nn vbz going vbg show nn vb improved vbn operating vbg nn profit nn having vbg delivered vbd vbn dt impressive jj cd jets nns dt period nn 

pp current jj nn suggests vbz rb dt sharpest jjs financial jj minds nns jj dt np np cc pp drexel np partners nns jj md stumble jj vb dt face vb nn dt revolution nn technology nn 
occurred tagged word total error training set jj wdt rb jjr rbr earlier rb jj dt rb jj nn virus nn jj chief jjr rbr jj np western rb nn jj executive rbr jjr vbg nn operating pos vbz nn rb back rb ago nns nn basis jjs rbs table top word tagging errors wall street journal 

contrast vbp nn dt big jj np board np pos number nn companies nns remained vbd dt steady jj cd cc dt nasdaq np pos roster nn vbn vbd cd 
brown corpus table show results learning lexical contextual transformations brown corpus 
results obtained penn treebank part speech tags original brown corpus tags 
penn treebank tags contextual transformations learned 
contextual transformations shown 
brown corpus tags transformations learned 
transformations learned brown corpus tags shown 
tag tagged total error nn jj jj nn vbn vbd rb nns vbz jj jj np vbd vbn vbg nn nn vbg np jj jjr rbr nn np jj vbn nn vbp vbz nns nn rb np nn rb jj wdt top tagging errors wall street journal 
unknown word known word tag set accuracy accuracy total lexical transformations penn lexical contextual penn statistical tagging penn lexical transformations brown lexical contextual brown statistical tagging brown table tagging brown corpus 
sets transformation approach significantly outperforms statistical approach unknown words corpus performs marginally worse known words 
old english training old english contextual transformations learned shown 
table showing resulting accuracy seen 
accuracy somewhat lower accuracy obtained english corpora 
number reasons 
smaller corpus half size training corpora lexical learning experiments annotated training corpora overlapped 
overlapping problem means contextual transformation learner learning corpus corpus learned transformations applied corpora overlap fewer unknown words contextual training corpus overlapped 
old english word order order independent transformation triggered tag appearing certain number words side particular word prove effective 
old english corpus typographical errors manual annotation english corpora 
despite problems encouraged level accuracy obtained language english 
change tag condition nn vb previous tag vbn vbd previous tag pp vb vbp previous tag pp nn vb previous tag md vbp vb previous tags md vbn vbd previous tag np vb nn previous tag dt vbd vbn previous tag vbd vbd vbn previous tags vb vbp vb previous tags vbd vbn previous tag vbz vb vbp previous tag nns pos vbz previous tags pp nns vbz tag dt nn nbp previous tag pp vbg nn surrounding tags dt rbr jjr tag rb jj surrounding tags dt nn vb nn previous tag jj vb nn previous tag nn contextually triggered transformations brown corpus penn treebank tags 
change tag condition tag vbn vbd previous tags start sent vb nn previous tags nn vb previous tag vbd vbn previous tags nn vb previous tags md vbn vbd previous tag np tag np vbn vbd previous tag pps tags nns vbd vbn previous tags tag pp vbn vbd previous tag vbd vbn previous tags previous tag vb vbd vbn previous tags hv vbd vbn previous tags vbd vbn previous tags vb nn previous tags tag contextually triggered transformations brown corpus original brown corpus tags 
change tag condition dt nn tag dt rb tag vt rb pr surrounding tags rb np dt rb tag pr ne cc tags nn pdt dt tag nn rb pr surrounding tags np dt pr tag np dt surrounding tags pr nn nn previous tag start contextual transformations old english corpus 
unknown word known word accuracy accuracy total lexical transformations lexical contextual transformations old english tagging results 
chapter demonstrated transformation error driven learning effectively tag text 
transformations learned guess tag unknown words 
contextual transformations tag words context appear 
transformation approach shown outperform known statistical approach tagging training small corpora obtain comparable performance larger corpora despite fact information stored compactly probabilities tagging smoothing probabilities unobserved events needed 
addition language specific corpus specific knowledge hardwired transformation tagger making highly portable 
system simply extended providing learner additional transformation templates 
demonstrated absolutely changes program tag old english simply providing small tagged corpus larger untagged corpus training material 
chapter phrase structure turn attention word classes phrase structure 
number proposals came american structural linguistics school field linguist determine phrase structure sentences unfamiliar language 
described approaches earlier section 
approaches require trained linguist working informant tease structural information sentence 
field linguist permitted ask informant sense giving access infinite corpus linguistic information learned 
wanted determine extent possible learn phrase structure information finite preferably small sample corpus 
describe module learning system automatically learns phrase structure small corpus annotated skeletal brackets part speech tags input 
learning module able assign phrase structure analysis sentences tagged parts speech high accuracy 
proposals automatic phrase structure learning statistics gathered large corpora 
statistic mutual information find phrase boundaries 
key idea papers position words relatively low mutual information strings course input sentences need manually tagged 
tagged minimal resource tagger described previous section available taggers sufficient training material available 
reported 
left strings right phrase boundary 
defines function score quality parse trees move set uses simulated annealing heuristically explore entire space possible parses sentence 
distributional analysis techniques applied large corpus learn context free grammar 
rules form part speech tags 
score rule distributional similarity measured relative entropy adjacent word distributions single tag left hand side pair tags right hand side rule 
rule pronoun determiner noun score pronoun noun phrase distributionally similar 
methods tested way allows readily compared methods 
statistics calculated possible subtrees contained structurally annotated training corpus 
monte carlo technique combine subtrees parsing fresh text 
technique shown effective corpus constrained domain may possible scale effectively parse richer domains 
addition see method performed worse transformation approach trained small corpora experiments 
promising results date inside outside algorithm train stochastic context free grammars 
inside outside algorithm extension finite state hidden markov model applied successfully areas including speech recognition part speech tagging 
number papers explored potential inside outside algorithm automatically learn grammar 
inside outside algorithm context free rule probabilities incrementally altered way increases probability training corpus 
algorithm guaranteed converge locally optimal set rule probabilities respect training corpus probability guaranteed find globally optimal set 
inside outside algorithm assign probabilities symbolic grammar written learn grammar automatically 
initial grammar consisting possible binary rules particular set nonterminals built rule assigned random probability 
inside outside algorithm applied adjust probabilities 
building tree nonterminals unlabelled describe new technique grammar induction transformation error driven learning 
common parsing techniques nonterminals added bracketing phase completed added concurrent bracketing 
addition apart parsing problem simpler subproblems added advantage bracketing module trained text nonterminal information 
algorithm works naive state knowledge phrase structure 
repeatedly comparing results parsing current state proper phrase structure sentence training corpus system learns set ordered transformations applied reduce parsing error 
believe technique advantages methods phrase structure induction 
advantages include system simple easily extended requires small set transformations high degree accuracy achieved small training corpus necessary 
trained transformational parser completely symbolic bracket text linear time respect sentence length time compared time context free grammar parsing 
addition tokens sentence considered parsing method prove considerably robust cfg approach faced noise unfamiliar input 
describing algorithm results compare results results automatic phrase structure induction 
results obtained training system corpus annotated part speech tags lexical contextual learning modules described previous section 
shown nonterminals necessary sense context free grammar skeletal generating system set trees nonterminal labels tree rewriting rules generates set strings 
algorithm learning algorithm trained small corpus partially bracketed text annotated part speech information 
learner begins naive initial state knowing little phrase structure target corpus 
particular initially known english tends right branching final punctuation final punctuation 
transformations learned automatically transform output naive parser output better resembles phrase structure training corpus 
set transformations learned system capable sentences tagged parts speech manually tagged text output automatic part speech tagger returning binary branching structure nonterminals unlabelled 
initial state parser initially parser operates assigning right linear structure sentences 
exception final punctuation attached high 
sentence dog old cat ate incorrectly bracketed dog old cat ate parser initial state obviously bracket sentences great accuracy 
experiments naive initial state knowledge sentences parsed assigning random binary branching structure final punctuation attached high 
parser easily extended deal branching languages having number simple alternative start states right branching left branching random branching 
step learning start state parse training corpus choose start state results best initial state score 
corpus bracketed nonterminal labels available ask just collect statistics context free rules node expansions annotated corpus 
shown grammar produced way ineffective fact performing worse assigning right linear structure input sentences 
output systems described 
note necessarily naive start state 
system postprocessor improve performance parser output parser structural transformations stage involves learning set transformations applied output naive parser sentences better conform proper structure specified training corpus 
list possible transformation types prespecified 
transformations involve making simple change triggered simple environment 
current implementation twelve allowable transformation types ffl lef parenthesis lef part speech tag ffl lef parenthesis tags carry transformation adding deleting parenthesis number additional simple structural changes take place preserve balanced parentheses binary branching 
give example delete left paren particular environment operations take place assuming course left paren delete 
delete left paren 

delete right paren matches just deleted paren 

add left paren left constituent immediately left deleted left paren 

add right paren right constituent immediately right deleted paren 

constituent immediately right immediately left rule fails apply 
structurally transformation seen follows 
wish delete left paren right constituent appears subtree form initial state learning corrective transformations 
naive start states consistent desire produce portable system capable annotating little human supervision training process 
right rightmost terminal dominated nonterminal 
phi phi phi phi yy carrying operations transform subtree phi phi phi phi yy sentence dog initially bracketed naive parser dog transformation delete left paren right determiner applied structure transformed correct bracketing dog add right parenthesis right yy yy subtree form phi phi phi phi yy input sentences labelled parts speech 
steps carried add right paren 
add right paren 

delete left paren matches newly added paren 

find right paren match just deleted paren delete 

add left paren match added right paren 
results structural change deleting left paren right particular structure 
applying different transformations may result structure transformation different triggering environment 
significant triggering environments may better generalizations having transformation triggered number different environments system find effective triggering environment training 
applying transformation add right paren right noun bracketing dog result correct bracketing dog twelve transformation templates broken allowable structural transformations triggered different simple environments 
shows allowable structural operations applied subtree nonterminals 
different possible triggering environments transforming subtree left structure right structure 
say subtree transformed 
immediately subtree immediately 
transformations result structural change 
add left paren left 
allowable structural transformations 

add right paren left 

add left paren right 
add right paren right 

delete left paren left 

delete left paren right 

add left paren 

add right paren 

delete left paren 
words triggers transforming tree 
value 








triggering environments 








transforming tree structure shown triggering environments 
















triggering environments 
learning transformations learning proceeds follows 
sentences training set parsed naive parser assigns right linear structure sentences attaching final punctuation high 
possible instantiation twelve transformation templates particular transformation applied naively parsed sentences 
resulting structures scored measure success compares parses correct structural descriptions sentences provided training corpus 
transformation resulting best scoring structures summed entire corpus transformation ordered set transformations learned 
transformation applied right linear structures learning proceeds corpus improved sentence bracketings 
procedure carried repeatedly training corpus transformations application reduces error parsing training corpus 
best transformation structures output parser current state 

transformation applied output resulting bracketing corpus parser current state 
state parser defined naive initial state knowledge plus transformations currently learned 

transformation added ordered list transformations 

go 
set transformations learned effectively parse fresh text 
parse fresh text text naively parsed transformation applied order naively parsed text 
run time learning algorithm jnj number allowable transformation operations number possible triggering environments jnj training corpus size 
pairing transformation operation environment learner scan entire corpus apply operation triggering environment encountered 
course discussed earlier actual training run time considerably theoretical bound due data driven nature algorithm 
function transformation list size jt corpus size jnj run time trained annotator jt jnj 
nice feature method different measures bracketing success learning proceed way try optimize specified measure success 
training inside outside algorithm stochastic grammar trained maximize probability training corpus hope result grammar parses fresh text way consistent linguistic intuition 
transformation learning tighter relationship measure guides learning final measure success 
measure chosen experiments measure described variation measure arose various meetings parser evaluation 
measure percentage constituents strings words matching parentheses sentences output system cross constituents penn treebank structural description sentence 
example system outputs big dog ate penn treebank bracketing sentence big dog ate constituent big judged correct constituent dog ate 
show transformations run training wall street journal corpus initially bracketed right linear initial state parser 
number add delete left right paren environment delete left left nn delete left left nns add right left delete left nnp nnp delete left right dt add right left delete right left nns delete right nn nn delete left jj jj delete left right add right nn delete left left pos add right nnp delete left cd cd delete left nnp nnp delete left jj jj add right left add right left add right left delete left left learned transformations 
transformations transformation number extract noun phrases right linear initial structure 
bracketing initial state word leftmost terminal phrase containing entire remainder sentence right 
transformations effectively remove singular plural common nouns structure bracket preceding constituent 
sentence cat initially run done training sentences length 
total learned transformations shown 
bracketed dt cat nn vbd 
applying transformation bracketing second transformation bracketing cats replacing cat result cat left parenthesis proper nouns second proper noun bracketed constituents follow preceding proper noun 
fourth transformation fixes 
sentence general motors profitable initially bracketed general nnp motors nnp profitable applying fourth transformation convert structure general motors profitable example demonstrates interaction ordering transformations 
sentence fastest car won initially bracketed dt fastest jj cars nns won vbd transformation apply sentence number resulting fastest cars won applicable transformation number application results fastest cars won transformation applied transformations applied sentence correct structure produced 
transformation number results fact number usually follows dollar sign lexical items bracketed 
transformations result fact comma indicator preceding phrase terminated 
transformation carried environment multiple listings transformation required transformation applied multiple times 
sentence called gone initially bracketed pp called vbd pp left applicable transformation number application results called left applicable transformation number application results correct structure called left results manually tagged text experiment ran training testing done texas instruments air travel information system atis corpus 
table compare results obtained transformation error driven learning results cited inside outside algorithm corpus 
accuracy measured terms percentage constituents test corpus described 
system tested training set learn set transformations applying transformations test set scoring resulting output 
approach see estimate variance result single run learning applying transformations 
doing compute confidence interval experiment sigma 
experiment transformations learned compared context free rules probabilities inside outside algorithm experiment 
significant obtained comparable performance training corpus large train inside outside algorithm 
experiments described results calculated test corpus way training learning algorithm developing system 
method training accuracy corpus sentences inside outside transformation learner table comparing learning methods atis corpus 
applying learned transformations test corpus sentences crossing constituents fewer crossing constituents fewer 
training testing done atis corpus sentences test set parsed exactly correctly difficult task training sentences 
training sentences accuracy approximately 
addition unclear technique effectively corpora structurally varied complex 
mean sentence length test corpus 
graphed percentage correct function number transformations applied test corpus 
transformation number increases overtraining occurs 
current implementation learner transformation added list results positive net change training set 
learning procedure transformations affect small percentage training sentences 
small counts reliable large counts reliably assume transformations improve performance test corpus 
way overtraining set threshold specify minimum level improvement result transformation learned 
possibility additional training material prune set learned transformations 
ran experiment determine performance achieved dropped initial right linear assumption 
training test sets sentences initially assigned random binary branching structure final punctuation attached high 
regular structure case right linear case transformations transformations total 
transformations applied test set bracketing accuracy results atis corpus starting right linear structure resulted 
graph shown 
atis corpus structurally fairly regular 
determine algorithm performs complex corpus ran experiments wall street journal 
results experiment table 
accuracy measured percentage constituents test set cross penn treebank constituents 
corpus experiments sentence length mean sentence length 
corpus experiment sentence length mean length 
expected performance degrades somewhat sentence length increases 
table show percentage sentences test corpus sentences length initial right linear parser achieves accuracy 
sentences length accuracy achieved sentences length accuracy 
experiments carried wall street journal test set randomly selected set sentences 
results atis corpus starting random structure crossing constituents percentage small number crossing constituents 
table show standard deviation measured different randomly chosen training sets sample size randomly chosen test sets sentences accuracy function training corpus size sentences length 
graph showing parsing performance wsj run trained sentence training corpus training testing sentences length shown 
experiment done inside outside algorithm train contextfree grammar partially bracketed wall street journal corpus 
experiment sentences length initial right linear parser parses sentences crossing errors fewer errors fewer 
sentences length sentences parsed crossing errors fewer fewer 
sent 
training length corpus sents transformations accuracy table wsj sentences sent 
training length corpus sents error error error sents sents sents table wsj sentences 
atis corpus possible binary context free rules initially allowed random probabilities initially assigned rule 
comparison approach approach shown tables 
inside outside experiment carried sentences length transformation approach carried sentences length 
inside outside experiment grammar probabilistic context free rules trimmed rules changing performance 
symbolic transformations learned transformation experiment 
table transformation learner training std 
corpus sents correct dev 
table wsj sentences length 
shown outperform inside outside algorithm parsing accuracy measured terms crossing brackets 
applying method estimate variance result single training testing run confidence interval obtained sigma 
table accuracy measured percentage sentences crossing bracket violations 
applying method estimate variance sentence accuracy gives confidence interval sigma 
believe significant comparable performance obtained considering transformation approach weakly statistical learner integer addition comparison done learning completely symbolic parser parse linear time 
method training sents 
transforms accuracy inside outside transformation table comparing approaches crossing bracket measure method sentence accuracy inside outside transformation table comparing approaches sentence accuracy ran experiment wsj sentences length starting random binary branching structures final punctuation attached high 
experiment transformations accuracy resulting applying transformations test set 
show sentence length distribution wall street journal corpus 
table table show results running bracketing algorithm penn treebank bracketing brown corpus 
run different randomly chosen training test set 
test set contained sentences 
slightly lower crossing bracket accuracy corpus compared wall street journal results wsj corpus due varied nature corpus 
ran experiment old english corpus 
training test set sentences 
sentences words long 
total transformations learned 
initially assigning right branching structure test set resulted accuracy 
applying transformations bracketing accuracy improved 
fifteen learned transformations shown 
results automatically tagged text numbers allow compare transformation learner systems trained tested comparable corpora results assumption test data tagged fairly reliably manually tagged text experiments experiments 
parsing free text sentence length distribution sentence lengths wsj corpus 
assume text tagged accuracy human annotator 
automatic tagger tag text parsing 
address issue ran experiment randomly induced tagging error rate error rate human annotator 
errors induced way preserve unigram part speech tag probability distribution corpus 
experiment run sentences length training set sentences test set sentences 
resulting bracketing accuracy compared accuracy training corpus 
accuracy degraded small amount training corpus part speech tags suggesting high parsing accuracy rates achieved tagging input done automatically part speech tagger 
ran experiments different randomly selected training testing training run corpus sents number correct table brown corpus sentences length 
training run corpus sents number error error error sents sents sents table brown corpus sentences length 
sentences length wall street journal 
penn treebank part speech tags training corpus test corpus 
training corpus tags taken penn treebank test corpus tags obtained automatically tagging corpus tagger described previous chapter 
training test set automatically tagged 
results applying tagging transformations training test corpora shown table 
tagging accuracy corpora worse achieved previous section ran statistical tagger corpora comparison tagging accuracy 
apparently shorter sentences difficult taggers corpora restricted sentences length previous corpora 
cases transformation tagger outperformed stochastic tagger 
bracketing results shown table 
encouraged performance degradation significant automatically tagging compared text 
randomly chosen sentences experiment 
case number add delete left right paren environment delete left left nn add right right nn add right left add left left add left right vt add right right vt add right left add left right vt add left right add right left add right left add left left pr delete left rb rb add right left delete left right pr learned transformations bracketing old english 
output bracketing program listed penn treebank bracketing listed second 
crossing brackets marked star 
takes stock weak shareholder gets recovery takes stock weak shareholder gets recovery expects resume full operations today expects resume full operations today years strong funds says years strong funds says latest report compares modest increase july machine orders year earlier latest report compares modest increase july machine unknown word known word total method corpus accuracy accuracy accuracy transformations test statistical test transformations train statistical train transformations test statistical test transformations train statistical train table accuracy tagging training test corpora 
experiment tags training tags testing correct human human human automatic automatic automatic human human human automatic automatic automatic table crossing bracket accuracy wsj sentences length 
orders year earlier latest report compares modest orders year earlier 
goal boost circulation level considered significant advertisers goal boost circulation level considered significant advertisers jones ran senate democrat lost incumbent sen don jones ran senate democrat lost incumbent sen don auto paint shop fire sent evil looking cloud black smoke air auto paint shop fire sent evil looking cloud black smoke air boiler room salesman investments oil gas wells rare coins boiler room salesman investments oil gas wells rare coins board scheduled meet tuesday board scheduled meet tuesday ignore condition ignore condition example bracketing errors arising failure clause comma 
second sentence error prepositional phrase attachment error 
third sentence bracketing errors arising crossing matching quotes 
number meta rules learned manually coded information matching parentheses quotes significantly improve performance 
fourth sentence error prepositional phrase attachment error 
sixth sentence error attaching clause including comma preposition verb ran 
seventh sentence errors due prepositional phrase attachment 
eighth sentence errors due prepositional phrase attachment arising difficult coordinate structure 
addition meta rules addressing particular parsing problems prepositional phrase attachment coordination lead significant system performance improvements 
section discuss transformation prepositional phrase attachment postprocessor 
section described new approach learning grammar automatically parse text 
method obtain high parsing accuracy small training set 
learning traditional grammar ordered set structural transformations learned applied output naive parser obtain binary branching trees unlabelled nonterminals 
experiments shown parses conform high accuracy structural descriptions specified manually annotated corpus 
attempts automatic grammar induction rely heavily statistics training resulting grammar learner weakly statistical 
training integers needed mathematical operations carried integer addition integer comparison 
resulting grammar completely symbolic 
learners inside outside algorithm attempt find grammar maximize probability training corpus hope grammar match grammar provides accurate structural descriptions transformation learner readily desired success measure learning 
plan experiment types transformations 
currently transformation learned list applied appropriate environment 
transformation applied environment appear transformation list 
possible extension set transformation types allow transformations form add delete paren times possible particular environment 
addition transformation applied triggering environments sentence strictly right left left right 
doubling list transformations allow transformation apply direction prove effective 
expand system allow non binary branching structure transformation adds deletes structure added doing require sophisticated measure guide learning process 
plan experiment scoring functions control strategies finding transformations system postprocessor grammar induction systems learning transformations improve performance 
addition plan incorporate lexical information learner 
currently lexical information part speech tag word 
lexical information incorporated allowing transformations frequently occurring words 
words labelled features transformations features addition part speech tags 
hope paths lead trainable accurate parser free text 
section describe method labelling nonterminal nodes syntactic tree 
parser transformational grammar output parse tree nonterminal labels separate algorithm applied tree label nonterminals 
labelling nonterminal nodes tree bracketed step label nonterminal nodes 
error driven learning learning label nonterminals 
currently node labelled solely labels daughters 
unlabelled tree labelled bottom fashion 
addressing problem labelling unlabelled tree output previous section addressed slightly different problem 
problem assign tag node properly bracketed tree proper labels daughter nodes 
problem easily evaluated solving significant step solving problem labelling output transformation 
experiment penn treebank bracketed wall street journal corpus 
training sets training set sentences training set test set sentences 
total nonterminal symbols occurred training test sets 
experiment initial state annotator assigned label noun phrase nodes 
transformations learned improve accuracy 
transformation templates 
change node label daughter 

change node label adjacent daughters 
transformations learned training set total transformations learned 
initially assigning label noun phrase nonterminal nodes incorporating feature lexicon learner discussed section 
rich providing corpus processing tools running experiment 
nonterminal need daughter 
transformation number tag daughter includes pp vp vp vbd vp vb vp vbn vp vbg vp vbz vp sbar pp np sbar vp vbp vp cc whnp wdt sbar whnp vp cc vp whnp wp adjp jjr table transformations labelling nonterminals 
test set resulted accuracy 
applying learned transformations test set resulted accuracy 
shows learned transformations 
transformations number similar transformations entire list capture general rule coordination 
appears transformation change label vp daughter particularly effective appearing transformation 
second transformation applied transformations follow undo second transformation side effect 
transformation applies number times remedy 
naive start state 
nonterminal node assigned tag daughters indicated second training set training set 
unseen daughter sequences tagged default tag noun phrase 
transformations learned applying start state annotator training set test set initial state accuracy listing penn treebank nonterminal labels appendix labelled daughters total error cumulative error np np vp sbar sbarq whnp sbar pp advp np vp adjp vbn advp rb np advp adjp jj np sbar pp np pp pp advp pp table top labelling errors 

applying transformations resulted accuracy 
total transformations learned 
shows errors test set transformations applied 
common error results certain np vp structures np 
example shown system incorrectly labels loan guarantees approved yesterday 
np size pp np np loan guarantees vp approved yesterday encouraged accuracy obtained simple learning algorithm local environments recourse lexical information 
hopefully adding richer environments word daughter nonterminal left lead accurate nonterminal 
bracketing text labelling nonterminals produce labelled parse trees linear time respect sentence length 
runs jnj jt jnj length sentence jt number bracketing transformations 
nonterminal runs jnj jt transformations tried nonterminal node 
parsing run time jnj jt jnj jt jnj jt 
transformation postprocessing sentence annotated processed modules attempt correct particular structure types information previously applied learning modules improve annotation accuracy 
example postprocessor done transformation prepositional phrase attachment module 
previous bracketing module lexical information part speech tags able resolve prepositional phrase attachment high accuracy 
sample output shown seen prepositional phrase attachment common errors bracketing 
postprocessor set allowable transformations allows movement prepositional phrases different attachment locations 
prepositional phrase attachment module discussed learns transformations corpus tuples form matrix verb head object noun phrase preposition head noun phrase governed preposition example see boy hill 
sentences conform pattern wall street journal corpus tuple formed 
tuples randomly split training samples test samples 
experiment attachment choice prepositional phrases object noun matrix verb 
initial state annotator prepositional phrases attached object noun 
attachment predicted right association 
allowable transformations ffl change attachment location done philip resnik 
extracted philip resnik tool written rich 
tuples extracted automatically mistakes manually pruned 
case attaching verb better start state corpora decision parameterized 
change tag condition year amount put month buy transformations learned prepositional phrase attachment 
members power set members 
total transformations learned 
show transformations learned 
initial accuracy prepositional phrases attached object noun test set 
applying transformations accuracy increases 
experiment transformations triggered words groups words 
surprising spite inevitable sparse data problems performance achieved 
couple ways address sparse data problem 
case mapping words part speech help 
semantic class information necessary 
method manually constructed semantic hierarchy described 
word expanded list classes occurs transformations triggered words word classes 
approach build word similarity tree described previous chapter assign node similarity tree unique name allow transformations triggered words node names 
node name feature feature word descendent node labelled gammax 
incorporated idea semantic information way 
wordnet noun hierarchy noun training test set replaced set containing noun name class noun appears 
transformation set modified asking noun ask member noun class set 
method proposed wordnet conjunction corpus obtain class statistics 
method simpler boolean values indicate classes word member 
transformation approach classes generalize way approach classes unable expect fewer transformations necessary 
case 
training testing carried samples previous experiment 
total transformations learned 
applying transformations test set resulted accuracy 
show transformations learned noun classes 
class descriptions surrounded square brackets 
transformation states noun describes time member time class attached verb time modify verb leave meeting hour noun 
experiment demonstrates feature lexicon trivially incorporated learner extending transformations allow word features 
hindle rooth score statistics measure strength lexical associations preposition noun preposition verb attach prepositional phrases scores 
scores estimated set sentences prepositional phrase attached verb object noun 
superset training instances transformation method includes sentences noun phrase fragments verbs 
corpus reasons run time efficiency transformations making classes permitted 
change tag condition time measure quantity amount abstraction group grouping put written communication thing buy transformations learned prepositional phrase attachment noun classes 
bracketed heuristic guess proper prepositional phrase attachment 
train sentences prepositions ap newswire quote accuracy algorithm reimplemented tested training test set experiments 
doing resulted attachment accuracy 
training set expanded include entire wall street journal corpus including unambiguous attachments excluding test set 
accuracy improved larger training set significantly lower accuracy obtained transformation approach 
technique described attach prepositional phrases semantic similarity estimated wordnet accuracy obtained training test sets 
semantic approach conjunction method described hindle rooth backing hindle rooth method semantic method resulted accuracy lower results obtained transformations 
score approach reran disallowing transformations 
doing resulted accuracy 
see 
technique estimate variance result obtained transformation learner word classes 
resulted confidence interval accuracy sigma 
previously mentioned extending learner trivial task 
near intend incorporate information subject head wordnet class information verb learner 
attachment heuristics needed structurally bracketed corpus extract training test sets 
really upper bound performance purposes comparing transformation approach transformation method extended large amount extra training material obtain result 
proximity effects favorably bias score results larger training corpora 
sentences extracted size source corpus chance test sentence training sentence coming paragraph story greater increasing chance words seen training corpus appearing test corpus 
method accuracy transforms scores transformations transformations transformations classes comparing results pp attachment 
transformation learning works factors ultimately contribute success failure error driven learning set transformations set triggering environments contexts 
transformations need sufficiently powerful allow improper annotations transformed proper annotations 

transformations learnable 
learning proceeds counting observe effect carrying particular context stage annotation observation learn transformation effective 
system successful extent exist convert poorly annotated sentence correctly better annotated sentence transformations sufficiently general learned 
learnable exist set triggering environments transformation reliable indicators transformation applied occur frequently easily training corpus 
fortunately zipf law holds transformations learned different learning modules described 
words rank frequency ratio transformations highly skewed 
small number transformations extremely effective meaning easily reliably observed training corpus go long way reducing error test corpus 
simplicity learner may lot success 
concrete take bracketing example 
parameters probabilistic context free grammars rules probabilities interdependent 
iteration inside outside algorithm entire grammar considered 
transformation learner stage learning thing find best transformation stage learning 
learner simpler task iteration finding single transformation finding set rule probabilities rules related complex ways 
example learner learn particular stage learning comma phrase break 
inside outside algorithm direct piece information easily learned 
simple effective cues bounds specified transformation templates transformation learner easily find 
true part speech tagging learner mechanism concisely capture local tagging cues resort brute force recording statistics 
addition linguistic entities obey zipf law entity types seen training corpus account large percentage entity tokens test corpus 
example transformations learned effectively bracket noun phrases training corpus high accuracy rate achieved noun phrases test corpus 
chapter demonstrated transformation error driven learning applied effectively learn bracket sentences syntactically 
demonstrated learner learn assign nonterminal labels unlabelled syntactic tree 
showed prepositional phrase improve parsing accuracy employing lexical information parsing zeroing improving parsing accuracy respect particular phenomenon 
chapter thesis described new approach corpus language learning called transformation error driven learning 
learning paradigm text initially naively annotated ordered list transformations learned application improves annotation accuracy 
demonstrated approach outperforms established statistical approaches part speech tagging text bracketing prepositional phrase attachment demonstrating label nonterminal nodes unlabelled syntactic tree 
performance achieved despite fact transformation learner extremely simple algorithm weakly statistical structural information learns captured succinctly typically case statistical decision tree natural language learning systems 
transformation learner easily extended simply adding transformation templates 
template useful transformations learned particular template 
possible adverse affect adding transformations result finding local maximum learning blocks application useful transformations resulting degradation performance 
advantage simple system problem easily detected 
learner postprocessor output human annotator different automatic annotator simply changing start state 
counts collected compared sophisticated statistical relationships calculated 
simple start states thesis sophisticated start state transformations learned patch weaknesses annotation method 
algorithm extremely simple development time fast 
absolutely language specific corpus specific knowledge hard coded annotation procedure annotator completely portable 
addition shown minimal human supervision form small annotated training corpus method trained annotate text high accuracy 
set transformations learned method applying transformations explicitly 
annotating transformations need search set rules simply apply transformation order 
transformation annotation runs time linear respect length input 
number advantages having simple algorithm learning structural information effectively applying information annotate text 
occam razor originally voiced william occam states simpler explanation preferred complex 
learning procedure described simpler statistical counterparts ways learning algorithm simpler application algorithm simpler learned information stored compactly 
simple hidden parameters procedures crucially affect performance hinder ability replicate results experiment learner 
statistical natural language learning possible hidden factors include method dealing relative frequencies zero handling computer overflow underflow threshold values number iterations 
complexity mathematics learning procedures puts reach people computational linguistics community 
approach straightforward simple easy implement allowing concentrate issue language issue statistics 
potential parameter threshold value transformation score learned 
performance system respect parameter described bit formally 
easily observed learning set transformations threshold set zero 
text annotated transformation list 
threshold value effect setting threshold easily observed measuring performance point transformation applied scored threshold training 
parameter need fixed set automatically computer 
start state transformation templates scoring function listed learning algorithm transformation application algorithm completely specified 
addition transformation approach added advantage algorithm successful number different structural annotation tasks 
number exciting directions continued 
interesting attempt apply learning technique tasks machine translation inducing predicate argument structure 
tasks attempted experiment different transformation templates control strategies 
hope thesis demonstrated potential error driven learning addressing wide range problems natural language processing 
appendix penn treebank part speech tags excluding punctuation 
cc coordinating conjunction 
cd cardinal number 
dt determiner 
ex existential 
fw foreign word 
preposition subordinating conjunction 
jj adjective 
jjr adjective comparative 
jjs adjective superlative 
ls list item marker 
md modal 
nn noun singular mass 
nns noun plural 
np proper noun singular 
nps proper noun plural 
pdt 
pos possessive 
pp personal pronoun 
pp possessive pronoun 
rb adverb 
rbr adverb comparative 
rbs adverb superlative 
rp particle 
sym symbol 

uh interjection 
vb verb base form 
vbd verb past tense 
vbg verb gerund participle 
vbn verb past participle 
vbp verb non rd person singular 
vbz verb rd person singular wdt wh determiner 
wp wh pronoun 
wp possessive wh pronoun 
wh adverb appendix old english part speech tags 
auxiliary verb 
auxiliary verb tensed 
cc coordinating conjunction 

dt determiner 
jj adjective 
ne negation 
nn noun 
pdt 
pn pronoun 
pr preposition subordinating conjunction 
rb adverb 
rp particle 

uh exclamation 
vbg participle 
vbn past participle 
vn main verb 
vt main verb tensed appendix original brown corpus tags 
sent 
left paren 
right paren 
dash 
coma 
colon 
open quotes 
close quotes 
appended 
abl pre qual 
abn pre quant 
abx pre quant 
ap post det 
art 

bed 

beg 
bem am 
ben 
ber 

cc conj 
cd number 
cs 

dod 

dt sing deter 
dti deter quant 
dts pl deter 
det dbl conj 
ex 
hv 

having 
prep 
jj 
jjr comp 
jjs super 
super 
md aux 
nn sing noun 
nn poss sing noun 
nns pl noun 
nns poss pl noun 
np prop noun 
np poss prop noun 
nps poss pl prop noun 
nr adv noun 
od ord number 
pn nom pron 
pn poss nom pron 
pp poss pers pron 
pp sec poss pers pron 
ppl sing pron 
pl pers pron 
obj pers pron 
pps rd sing nom pron 
nom pron 
ql qual 
post qual 
rb adv 
rbr comp adv 
rbt super adv 
rn nom adv 
rp adv particle 
inf 
uh 
vb verb 
vbd past verb 
vbg pres part gerund 
vbn past part 
vbz verb 
wdt wh 
wp poss wh pron 
obj wh pron 
wps nom wh pron 
wh qual 
wh adv appendix penn treebank nonterminals adjp adjective phrase 
phrasal category headed adjective including comparative superlative adjectives 
example expensive 
advp adverb phrase 
phrasal category headed adverb including comparative superlative adverbs 
examples aux auxiliary verb phrase 
conjp coordinate phrase 
intj interjection neg negative np noun phrase 
phrasal category includes constituents depend head noun 
pp prepositional phrase 
phrasal category headed preposition 
prt particle phrase 
simple declarative clause introduced possibly empty subordinating conjunction wh word exhibit subject verb inversion 
sbar clause introduced possibly empty subordinating conjunction 
sbarq direct question introduced wh word wh phrase 
sinv inverted declarative sentence subject follows verb 
sq part sbarq excludes wh word wh phrase 
vp verb phrase 
phrasal category headed verb 
whadvp wh adverb phrase 
phrasal category headed wh adverb whnp wh noun phrase 
noun phrase containing things wh determiner book daughter consisting wh pronoun 
wh prepositional phrase 
prepositional phrase containing wh determiner means necessary constituent unknown uncertain type 
question mark enclosing constituent question mark preceded left parenthesis means parser unable decide attach constituent 
bibliography abney 
english noun phrase sentential aspects 
unpublished mit dissertation 
bahl brown desouza mercer 
tree statistical language model natural language recognition 
readings speech recognition 
baker 
trainable grammars speech recognition 
speech communication papers th meeting acoustical society america 
baum 
inequality associated maximization technique statistical estimation probabilistic functions markov process 
inequalities 
black abney grishman harrison hindle ingria jelinek klavans liberman marcus roukos santorini strzalkowski 
procedure quantitatively comparing syntactic coverage english grammars 
proceedings fourth darpa speech natural language workshop pages 
black jelinek lafferty magerman mercer roukos 
history grammars richer models probabilistic parsing 
proceedings st annual meeting association computational linguistics 
columbus ohio 
black jelinek lafferty mercer roukos 
decision tree models applied labeling text parts speech 
darpa workshop speech natural language 
black lafferty roukos 
development evaluation broad coverage probabilistic grammar english language computer manuals 
proceedings th annual meeting association computational linguistics 
newark de 
bloomfield 
language 
holt new york 
blumer ehrenfeucht haussler warmuth 
occam razor 
information processing letters volume 
boas 
handbook american indian languages part 
smithsonian institution washington 
bureau american bulletin 
bod 
annotated corpus stochastic grammar 
proceedings european acl 
breiman friedman olshen stone 
classification regression trees 
wadsworth brooks 
brent 
automatic acquisition subcategorization frames untagged text 
proceedings th annual meeting association computational linguistics berkeley ca 
brill 
discovering lexical features language 
proceedings th annual meeting association computational linguistics berkeley ca 
brill 
simple rule part speech tagger 
proceedings third conference applied natural language processing acl trento italy 
brill 
automatic grammar induction parsing free text approach 
proceedings st meeting association computational linguistics columbus oh 
brill 
automatic grammar induction parsing free text approach 
proceedings arpa human language technology workshop princeton 
brill 
transformation error driven parsing 
proceedings third international workshop parsing technologies tilburg netherlands 
brill haeberli 
adventures tagging old english 
manuscript 
brill kapur 
information theoretic solution parameter setting 
technical report institute research cognitive science university pennsylvania number ircs 
brill magerman marcus santorini 
deducing linguistic structure statistics large corpora 
proceedings darpa speech natural language workshop pages 
brill marcus 
automatically acquiring phrase structure distributional analysis 
darpa workshop speech natural language 
brill marcus 
tagging unfamiliar text minimal human supervision 
proceedings fall symposium probabilistic approaches natural language 
american association artificial intelligence aaai 
brill resnik 
transformation approach prepositional phrase attachment 
technical report department computer information science university pennsylvania 
forthcoming 
briscoe 
robust stochastic parsing inside outside algorithm 
workshop notes aaai statistically nlp techniques workshop 
brown cocke della pietra della pietra jelinek lafferty mercer 
statistical approach machine translation 
computational linguistics 
brown lai mercer 
word sense disambiguation statistical methods 
proceedings th annual meeting association computational linguistics berkeley ca 
brown della pietra della pietra mercer :10.1.1.13.9919
class gram models natural language 
computational linguistics 
cardie 
corpus acquisition relative pronoun disambiguation heuristics 
proceedings st annual meeting association computational linguistics 
carroll charniak 
learning probabilistic dependency grammars labelled text 
proceedings fall symposium probabilistic approaches natural language 
american association artificial intelligence aaai 
charniak 
parser 
academic press 
parsing natural language king editor 

immediate constituents expansion analysis 
word 
chomsky 
aspects theory syntax 
mit press cambridge 
chomsky 
language problems knowledge 
manuscript 
church 
stochastic parts program noun phrase parser unrestricted text 
proceedings second conference applied natural language processing acl 
church gale hanks hindle 
parsing word associations typical predicate argument relations 
proceedings international workshop parsing technologies 
cover thomas 
elements information theory 
wiley sons new york 
cutting kupiec pedersen sibun 
practical part speech tagger 
proceedings third conference applied natural language processing acl trento italy 
derose 
grammatical category disambiguation statistical optimization 
computational linguistics 
ernst newell 
gps case study generality problem solving 
academic press 
quirk comprehensive grammar english language 
longman london 
fong 
computational properties principle grammatical theories 
phd thesis department electrical engineering computer science mit 
francis kucera 
frequency analysis english usage lexicon grammar 
houghton mifflin boston 
garside leech sampson 
computational analysis english corpus approach 
longman london 
goldberg 
genetic algorithms search optimization learning 
addisonwesley 
grishman hirschman 
discovery procedures sublanguage selectional patterns initial experiments 
computational linguistics 
editors 
studies zipf law 
dr bochum 
quantitative linguistics vol 

haigh sampson adn atwell 
project april progress report 
proceedings annual meeting association computational linguistics buffalo 
hammersley 
monte carlo methods 
chapman hall 

algorithm vp ellipsis 
proceedings th annual meeting association computational linguistics 
harris 
morpheme utterance 
language 
harris 
structural linguistics 
university chicago press chicago 
harris 
phoneme morpheme 
language 
harris 
string analysis language structure 
mouton hague 
godfrey doddington 
atis spoken language systems pilot corpus 
proceedings darpa speech natural language workshop 
hindle 
acquiring disambiguation rules text 
proceedings th annual meeting association computational linguistics 
hindle 
noun classification predicate argument structures 
proceedings th annual meeting association computational linguistics pittsburgh pa 
hindle rooth 
structural ambiguity lexical relations 
proceedings th annual meeting association computational linguistics berkeley ca 
hirschman grishman sager 
grammatically automatic word class formation 
information processing management 

review mathematical theory communication claude shannon warren weaver 
language 
holder editor 
franz boas handbook american indian languages powell indian linguistic families america north mexico 
university nebraska press lincoln ne 
editors 
null subject parameter 
foris dordrecht 
jelinek 
continuous speech recognition statistical methods 
proc 
ieee 
jelinek 
impact processing techniques communication 
dordrecht 
impact processing techniques communication ed 
jelinek lafferty mercer 
basic methods probabilistic context free grammars 
technical report ibm yorktown heights 
technical report rc 
joshi levy 
phrase structure trees bear fruit thought 
american journal computational linguistics 
kimball 
principles surface structure parsing natural language 
cognition 
kirkpatrick gelatt vecchi 
optimization simulated annealing 
science 
kiss 
grammatical word classes learning process simulation 
psychology learning motivation 
klein simmons 
computational approach grammatical coding english words 
jacm 
kullback 
information theory statistics 
john wiley sons new york 
kupiec 
robust part speech tagging hidden markov model 
computer speech language 
lakoff 
women fire dangerous things categories reveal mind 
university chicago press chicago 
lari young 
estimation stochastic context free grammars inside outside algorithm 
computer speech language 
saito 
nature proper government 
linguistic inquiry 
levy joshi 
skeletal structural descriptions 
information control 
macwhinney snow 
child language data exchange system 
journal child language 
magerman marcus 
parsing natural language mutual information statistics 
proceedings eighth national conference artificial intelligence aaai 
mandelbrot 
information theory statistical structure language 
london 
communication theory jackson ed 
marcus 
theory syntactic recognition natural language 
mit press 
marcus 
inadequate theories human language processing 

talking minds study language cognitive sciences carroll miller eds 
marcus santorini marcinkiewicz :10.1.1.14.9706
building large annotated corpus english penn treebank 
appear computational linguistics 
meteer schwartz weischedel 
empirical studies part speech labelling 
proceedings fourth darpa workshop speech natural language 
miller 
wordnet line lexical database 
international journal lexicography 
newell simon 
human problem solving 
prentice hall 
niv 
resolution syntactic ambiguity case new subjects 
proceedings th annual meeting cognitive science society 
pereira schabes 
inside outside reestimation partially bracketed corpora 
proceedings th annual meeting association computational linguistics newark de 
pereira tishby lee 
distributional clustering english words 
proceedings st annual meeting association computational linguistics 
pinker 
learnability cognition 
mit press cambridge 
quinlan 
induction decision trees 
machine learning 
quinlan rivest 
inferring decision trees minimum description length principle 
information computation 
rabiner 
tutorial hidden markov models selected applications speech recognition 
readings speech recognition 
waibel lee editors 
resnik 
semantic classes syntactic ambiguity 
arpa workshop human language technology 
rivest 
learning decision lists 
machine learning 
robins 
noun verb universal grammar 
language 
rosenfeld huang schneider 
application cluster detection text picture processing 
ieee transactions information theory 

specifying subject 
linguistic inquiry 
sampson 
schools linguistics 
stanford university press 
sampson 
stochastic approach parsing 
proceedings coling bonn 

language 
new york 
schabes roth osborne 
parsing wall street journal inside outside algorithm 
proceedings european acl netherlands 
seneff 
tina natural language system spoken language applications 
computational linguistics 
sharman jelinek mercer 
generating grammar statistical training 
proceedings darpa speech natural language workshop 
simon 
class skew distribution functions 
biometrika 

probabilistic procedure grouping words phrases 
language speech 
taylor 
penn parsed corpus middle english syntactically annotated database 
georgetown university roundtable languages linguistics pre session corpus linguistics 
thomason editor 
formal philosophy selected papers richard montague 
yale university press 
viterbi 
error bounds convolutional codes asymptotically optimal decoding algorithm 
ieee trans 
inform 
theory 
wall schwartz 
programming perl 
reilly associates 
wells 
immediate constituents 
language 
whorf 
language thought reality selected writings benjamin lee whorf 
mit press cambridge 
wonnacott wonnacott 
introductory statistics business economics 
wiley 
zipf 
selected studies principle relative frequency language 
harvard university press 
zipf 
psycho biology language 
houghton mifflin 
zipf 
human behavior principle effort 
hafner new york 
