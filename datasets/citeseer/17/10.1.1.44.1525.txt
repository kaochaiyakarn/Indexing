defacto design environment adaptive computing technology pedro phillip duncan john mary hall rajeev jain ziegler 
lack high level design tools hampers widespread adoption adaptive computing systems 
application developers master wide range functions high level architecture design timing actual control data signals 
describe defacto design environment aimed bridging gap tools adaptive computing bringing parallelizing compiler technology synthesis techniques 
adaptive computing systems incorporating configurable computing units ccus fpgas offer significant performance advantages conventional processors tailored particular computational needs application template matching monte carlo simulation string matching algorithms 
unfortunately mapping programs adaptive computing systems extremely cumbersome demanding software developers assume role hardware designers 
developing applications systems requires low level vhdl coding complex management communication control 
tools application developer designed narrowly focused single application specific configurable architecture require new programming languages computing paradigms 
absence general purpose high level programming tools adaptive computing applications hampered widespread adoption technology currently area accessible small collection specially trained individuals 
describes defacto design environment developing applications mapped adaptive computing architectures 
user defacto develops application high level programming language possibly augmented application specific information 
system maps application adaptive computing architecture consists multiple fpgas coprocessors conventional general purpose processor 
defacto leverages parallelizing compiler technology stanford suif compiler 
existing compiler technology directly applicable department electrical engineering systems university southern california los angeles ca email usc edu information sciences institute university southern california admiralty way marina del rey ca 
email isi edu angeles design systems 
street suite san jose ca 
email duncan angeles com domain adaptive computing environments new challenges compiler particularly requirement defining selecting functionality target architecture 
design environment adaptive computing leverage cad techniques manage mapping configurable computations actual hardware 
defacto combines compiler technology cad environments techniques specially developed adaptive computing single system 
remainder organized sections 
section overview defacto 
section describes system level compilation stanford suif compiler 
section presents design manager tool brings system level compiler commercial synthesis tools 
system overview target architecture defacto consists single general purpose processor gpp multiple configurable computing units ccus 
ccu access memory communicate gpp ccus data control channels 
architecture general purpose processor responsible orchestrating execution ccus managing flow data control application execution 
architecture description language describe specific features communication channels number channels ccu bandwidth topology connections ccus amount number ports ccu ccu logic capacity 
architecture specification defacto evaluate possible program partitioning strategies 
application specification analyze transform partition estimation module generators design manager code translation commercial synthesis place route controller native compiler matlab suif tcg architecture description domain specific annotations precision timing input values fig 

defacto compilation flow outline outlines flow information defacto environment 
input defacto consists application specification written high level language matlab augmented domain application specific annotations 
annotations include variable precision arithmetic operation semantics timing constraints 
defacto system level compiler represented analyze transform partition box converts application specification suif intermediate representation 
translation system level compiler preserves application specific pragmas programmer included 
systemlevel compiler analyzes input program opportunities exploit parallelism 
compiler generates representation parallelism communication 
representation consists partitioning tasks input program specifying execute ccus execute gpp capturing communication control tasks 
compiler derived feasible program partitioning generates source code executes gpp hdl representation vendor neutral hardware description language portions computation execute configurable computing units 
portion translated machine code gpp native compiler portions computation execute ccus provides input design manager subsequently commercial synthesis tools generate appropriate bitstreams representing configurations 
code partitioning phase iterative system level compiler interfaces design manager component 
design manager responsible determining partition computation gpp ccus feasible resources allocated ccu fit hardware resources 
purpose design manager additional tools estimation module generator components 
estimation tool responsible estimating hardware resources computation requires module generator uses set parameterized library modules implement predefined functions 
optimization algorithm controls flow information defacto system 
optimization goal derive complete design correctly implements application constraints imposed architecture platform minimizes execution time avoids reconfiguration meets timing constraints specified programmer 
compiler iterates selection partitions program transformations satisfied hardware resource constraints application timing constraints subject semantics original program 
system level compiler defacto system level compiler goals identify computations potential yield performance benefits executing ccu 
partition computation control gpp ccus 
manage data storage communication multiple ccus 
identify opportunities configuration reuse time space 
compiler analysis produces annotated hierarchical source program representation call task communication graph tcg specifying parallel tasks associated communication 
subsequently representation refined partition computation control ccus gpp identify communication storage requirements 
refined representation input design manager 
describe compiler identifies exploits transformation opportunities simple code example depicted left 
loop accumulation mask sum mask sum loop energy computation th sum coeff th loop thresholding bias var value var var var var var var value var var var value var value var var fig 

example program hierarchical task communication graph tcg right shows tasks tcg generated example code 
highest level hierarchy single task encompasses entire computation 
task accounts outer loop body 
level tasks represent statements simple compound loop body statements nested loops 
loops possible derive functions representing loops computations depicted functions 
compiler analysis phase annotates tcg level representation data dependence privatization information 
example compiler annotate sum th safely private iteration loop values variables flow iteration 
task level data dependence privatization annotations help phases compiler relax scheduling constraints execution computation 
example code generation phase explore parallelism pipelining execution iterations task 
identifying configurable computing computations compiler identifies parallel loops including vector style simd computations general parallel loops follow multiple threads control pipelined parallel loops existing array data dependence analysis privatization reduction recognition techniques 
addition parallelization analyses defacto compiler exploit partial evaluation constant folding special arithmetic formats generate specialized versions loop body 
example loop corresponding task performs sum reduction successive application associative operator set values produce single value producing value sum variable 
commutativity associativity addition operator compiler execute order accumulations sum variable 
tasks easily parallelizable loop carried dependences iterations loops access mutually exclusive data locations 
locality communication requirements representation data dependence information gathered program particular loop level nest compiler evaluates cost associated movement data possible improvement execution tasks ccus 
multi ccu architecture data partitioning analysis determine partitions data accommodated result minimal communication synchronization 
data partitions subject additional constraint corresponding tasks access data fully implemented single ccu 
compiler logical view communication channels determine impact bandwidth partitioning performance size 
example configurable machine provides bandwidth bits ccus transfer rate mbps compiler constraints define partitioning 
th sum mask coeff gpp ccu ccu ccu fig 

data computation partition example code example possible split data arrays columns variable sum iterations outer loop assigned different ccus consecutive blocks performed concurrently 
illustrates possible data computation partitioning code example 
represented configuration associated set hardware functions generating control partition final program implementation operate correctly control mechanism 
control keeps track data needed certain component time data available certain computation 
system control dual role communication computation coordinator 
communication coordinator control takes form finite state machine fsm indicating data movement ccus gpp 
computation coordinator control takes represented fsm indicating ccu configuration task computation occur 
effect control captures task scheduling 
actual implementation fsms distributed ccus initially hdl format gpp code 
configure ccus send arrays mask ccus wait sum compute th send th ccus wait array fig 

gpp control fsm representation part partitioning process system level compiler annotate tcg indicate tasks run ccu gpp 
compiler starts automated generation control tcg generate corresponding fsms ccus gpp 
gpp fsm task shown 
gpp control implemented set library routines architecture specific 
library consists low level interrupt handlers communication synchronization routines associated target architecture 
complete system level compiler role control generation translates control information gpp calls send receive wait library inserts gpp code 
compiler generates hdl ccus control fsms 
hdl behavioral synthesis phase control generation 
configuration reuse analysis reconfiguration time current reconfigurable devices slow order tens milliseconds minimizing number reconfigurations computation requires important optimization 
example code possible reuse portion hardware executes task task 
data inputs loop bodies different functions structurally 
example information may captured tcg relabelling task task 
identifying common configuration reuse part solution 
compiler uses dependence analysis information bring statement reordering portions code common configurations 
strategy aims minimizing total number configurations 
design manager design manager provides abstraction hardware details system level compiler guides derivation final hardware design computation communication storage control 
cases pre defined configurable computing platform available ccus storage elements sram communication paths known priori 
case main responsibilities design manager map computation storage communication high level task abstractions pre defined characteristics 
design manager operates modes designer implementer 
initial partitioning phase design manager assists system level compiler estimating feasibility implementing specific tasks executed ccu 
working tandem estimation tool design manager reduces number time consuming iterations logic synthesis ccu place 
feasible partitioning design manager provides feedback system level compiler guide optimization design possibly resulting new partitioning 
feasible design identified design manager enters second mode operation implementer 
phase design manager interfaces behavioral synthesis tools providing hdl target specific inputs culminating generation fpga configuration bitstreams 
example tcg need define physical location point time arrays accessed data communicated storage appropriate ccu 
address mapping issues platform independent manner 
computation data mapping provide feedback system level compiler partitioning phase design manager collaborates estimation tool optionally module generator component 
design manager uses hdl associated task group tasks input behavioral synthesis tool monet generate rtl hdl description provides hdl representation estimation tool 
system level compiler specifies hdl module binding design manager invoke corresponding module representation order generate rtl hdl 
representation captured details computation data movement specified tcg 
response design manager request estimation tool returns timing sizing estimate 
design manager returns estimates compiler help guide efforts find partitioning satisfies constraints current 
example compiler partitioned data columns arrays compiler allocated array memory ccu 
illustrates conceptual partitioning computation identifies memories ccu hold data design manager captures storage mapping rtl hdl ccu 
estimates system level constraints design manager generates fpga configuration bitstreams 
estimation tool design manager gives estimation tool specific task rtl hdl expects estimation tool return pieces information estimated configurable logic block clb count timing threshold information specific fpga technology 
estimates consider routing specified task placement 
line estimation manager maintains table useful estimates allow expedient estimation 
mem clb ccu mem clb ccu mem cpu gpp mask sum th coeff channel channel channel channel channel sum th fig 

computation communication mapping ccu architecture communication mapping system level compiler uses virtual communication channels design manager implements physical communication channels required data communication ccus gpp memory elements 
data communication tasks mapped predefined interconnect target architecture 
channels implemented part pipelined execution functions assigned different ccus channels require buffering 
case design manager add hardware handshaking circuits configuration specification 
design manager generates circuits temporarily store data local memory ship ccu memory 
example bit channel ccus bit words communicated ccus tcg specification design manager implement serial parallel converter ccu port communicate values parallel 
hand bit signals need communicated design manager implements parallel serial converter multiplexer ccu port 
example columns array need sent ccus units compute updates addition design manager physical communication channels exist adjacent units maximum performance rely gpp buffer scheme 
storage mapping system level compiler specifies data computation takes place communication data 
specify data stored 
mapping data existing memories corresponding addresses ccus creating storage ccus responsibility design manager 
note compiler generates partitioning estimates take consideration circuits control logic storage circuits design manager adds 
initial iteration compiler produces best guess partitioning fit available ccus design manager estimates cost control storage ccu provide feedback feasibility 
compiler specifies initial storage data gpp memory result previous configuration ccu part data dependence annotations associated partitions 
system control initiates execution tcg data needed chip ccu 
priori defined models data may stored chip difficult generalize synthesis storage 
storage design linked control design communication channel design 
communication channels feed data ccu transfer results ccu back gpp 
example design decision involved suppose tasks ccu need operate matrix data tasks executed sequentially sub matrices data theta byte window image 
suppose tcg specifies parallel execution computation data sub matrix 
case essential access sub matrices sequentially external storage store ccu 
overview defacto design environment implementing applications adaptive computing systems 
defacto system uniquely combines parallelizing compiler technology synthesis automate effective mapping applications reconfigurable computing platforms 
project early stages focused necessary components system required functionality 
system level compiler uses parallelization locality analysis partition application general purpose processor ccus 
design manager maps compiler partitioning actual configurations fpga including required communication storage control ccus gpp 
key distinguishing feature defacto designed architecture independent retargetable 

research supported darpa contract hughes fellowship 
authors wish john students contributions design system 

buell arnold splash fpgas custom computing machine ieee symposium fpgas custom computing machines computer society press los alamitos ca 

gokhale stone napa compiling hybrid risc fpga architecture ieee symposium fpgas custom computing machines computer society press los alamitos ca april 

hall maximizing multiprocessor performance suif compiler ieee computer ieee computer society press los alamitos ca dec 

polychronopoulos kuck guided self scheduling practical scheduling scheme parallel computers acm transactions computers vol 
pp 
dec 

anderson lam global optimizations parallelism locality scalable parallel machines proceedings acm sigplan conference programming language design implementation pldi pp 
acm press ny july 
article processed macro package llncs style 
