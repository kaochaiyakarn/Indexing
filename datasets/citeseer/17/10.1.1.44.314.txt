appeared parallel computing 
parallel algorithms hierarchical clustering clark olson computer science department cornell university ithaca ny cs cornell edu hierarchical clustering common method determine clusters similar data points multidimensional spaces 
algorithms known problem 
reviews important results sequential algorithms describes previous parallel algorithms hierarchical clustering 
parallel algorithms perform hierarchical clustering distance metrics described 
optimal pram algorithms log processors average link complete link centroid median minimum variance metrics 
optimal butterfly tree algorithms log processors centroid median minimum variance metrics 
optimal asymptotic speedups achieved best practical algorithm perform clustering single link metric log processor pram butterfly tree 
keywords 
hierarchical clustering pattern analysis parallel algorithm butterfly network pram algorithm 
clustering multidimensional data required fields 
popular method performing clustering hierarchical clustering 
method starts set distinct points considered separate cluster 
clusters closest metric 
repeated points belong hierarchically constructed cluster 
final hierarchical cluster structure called dendrogram see simply tree shows clusters step 
dendrogram easily broken selected links obtain clusters desired cardinality radius 
representation easy generate store concentrate determination clusters merge step 
metric determine distance pairs clusters 
individual points euclidean distance typically 
clusters points number metrics determining distances clusters 
distance metrics broken general classes graph metrics geometric metrics 

graph metrics 
consider completely connected graph vertices points wish cluster edges cost function euclidean supported part national science foundation iri iri 
dendrogram shows clusters merged hierarchically 
distance points 
graph metrics determine intercluster distances cost functions edges points clusters 
common graph metrics ffl single link distance clusters minimum cost edge points clusters 
ffl average link distance clusters average edge costs points clusters 
ffl complete link distance clusters maximum cost edge points clusters 

geometric metrics 
metrics define cluster center cluster cluster centers determine distances clusters 
examples include ffl centroid cluster center centroid points cluster 
euclidean distance cluster centers 
ffl median cluster center unweighted average centers clusters form 
euclidean distance cluster centers 
ffl minimum variance cluster center centroid points cluster 
distance clusters amount increase sum squared distances point center cluster caused clusters 
useful clustering metrics usually described lance williams updating formula 
distance new cluster cluster bd jd gamma table gives coefficients lance williams updating formula metrics described 
time algorithms exist perform clustering metrics 
metric described lance williams updating formula performed log time 
reviews important sequential algorithms discusses previous parallel algorithms hierarchical clustering 
optimal algorithms hierarchical clustering intercluster distance metrics parallel architectures 
sequential algorithms important results sequential hierarchical clustering algorithms summarized 
additional results 
section describes results 
algorithms represent distance clusters represent nearest neighbor cluster metric single link gamma average link jij jij jjj complete link centroid jij jij jjj gamma jij jjj median gamma minimum variance jij jkj jij jjj jkj gamma jkj jij jjj jkj table parameters lance williams updating formula various clustering metrics 
number points cluster 
function cluster single link input point set fi ng compute 
fi ng compute 
repeat gamma times determine minimized 
clusters update necessary 
efficient algorithm perform single link clustering 
single link median centroid metrics clustering single link metric closely related finding euclidean minimal spanning tree set points require computational complexity minimal spanning tree easily transformed cluster hierarchy 
algorithms exist find euclidean minimal spanning tree algorithms impractical dimensionality cluster space 
gives practical algorithm single link metric 
computing arrays storing requires time 
arrays computing closest clusters performed time examining cluster nearest neighbor 
clusters simply store clusters update arrays 
single link metric property clusters cluster nearest neighbor nearest neighbor 
call agglomerative nearest neighbor property property 
see 
property allows update arrays time single link metric yielding time algorithm 
perform clustering metrics updating step complicated property hold 
determining new nearest neighbors metrics requires time 
centroid median metrics day nearest neighbors set clusters agglomeration 
property holds nearest neighbors remain new cluster place clusters form 
edelsbrunner shown number clusters need determine new nearest neighbor bounded function min constant 
metrics algorithm requires iteration update arrays time 
note algorithm requires space store pairwise distances single link metric 
centroid median metrics store cluster centers space generate distances needed 
sibson gives time algorithm single link case requiring space gives similar algorithm perform complete link clustering 
metrics satisfying reducibility property metrics satisfy reducibility property perform clustering time computing nearest neighbor chains 
reducibility property requires clusters new cluster closer cluster clusters 
formally distance constraints hold clusters distance ae ae ae ae cluster ae minimum variance metric graph metrics satisfy property ideal metrics algorithm 
centroid median metrics satisfy reducibility property see 
algorithm provides approximate algorithm cases order examining points change final hierarchy 
gives algorithm 
algorithm works nearest neighbor chain pair mutual nearest neighbors 
see 
amortizing cost determining nearest neighbors seen centroid median metrics satisfy reducibility property 
case clusters center new cluster closer previous clusters 
algorithm requires time space clustering techniques cluster centers 
perform clustering graph theoretical metrics keeping array intercluster distances increasing space requirement 
general metrics metric modified intercluster distances determined time lance williams updating formula clustering performed log time algorithm 
algorithm priority queues determine nearest neighbor cluster 
implemented heaps generated time 
iteration loop determine closest pair clusters time examining head priority queue 
create new priority queue cluster remove cluster queue update distance cluster queue 
step requires log time performed times 
total time required log 
previous parallel algorithms authors previously examined parallel algorithms hierarchical clustering 
addition parallelizing partitional clustering algorithms popular type clustering 
see example 
rasmussen willett discuss parallel implementations clustering single link metric minimum variance metric simd array processor 
implemented parallel versions algorithm prim minimal spanning tree algorithm ward minimum variance method 
parallel implementations algorithm ward minimum variance algorithm decrease time required serial implementation significant constant factor speedup function cluster reducible metrics input point set pick random 

repeat gamma times repeat 
determine gamma 
gamma clusters 


algorithm efficiently perform clustering metrics satisfy reducibility property 
algorithm reducible metrics determines clusters merge nearest neighbor chain 
function cluster general input point set point generate priority queue distances point 
repeat gamma times determine closest clusters clusters update algorithm perform clustering efficiently general case 
achieved 
parallel implementation prim minimal spanning tree algorithm achieves log time sufficient processors 
li fang describe algorithms hierarchical clustering single link metric node hypercube node butterfly 
algorithms parallel implementations kruskal minimal spanning tree algorithm run log time hypercube log butterfly fact algorithms appear fatal flaw causing incorrect operation 
algorithm processor stores distance cluster cluster 
clusters omit updating step determining distances new cluster clusters 
step added algorithms straightforward manner times required algorithms increase 
driscoll described useful data structure called relaxed heap shown applied parallel computation minimal spanning trees 
relaxed heap data structure manipulating priority queues allows deleting minimum element performed log time decreasing value key performed time 
data structure allows parallel implementation dijkstra minimal spanning tree algorithm log time log processors pram number vertices graph number edges 
bruynooghe describes parallel implementation nearest neighbors clustering algorithm suitable parallel supercomputer 
step algorithm dispatches tasks determine nearest neighbor cluster parallel pair reciprocal nearest neighbors parallel 
achieve speedup algorithm cases cases require gamma iterations require time 
worst case complexity sequential algorithm 
parallel algorithms section discusses parallel implementations metrics prams 
algorithms cluster responsibility processor 
clusters processor lower number takes responsibility new cluster 
processor longer clusters responsibility idle 
single link metric parallel version algorithm efficiently perform clustering single link metric pram 
intercluster distance nearest neighbor arrays easily computed time number processors 
iteration loop find minimum nearest neighbor distances 
indexes clusters broadcast 
processor updates distances clusters responsible new cluster 
property holds single link metric update nearest neighbors efficiently 
nearest neighbor new cluster determined finding cluster minimum distance 
function minimal spanning tree input point set pick random 
distance points repeat gamma times find minimum 
add minimal spanning tree 
minimal spanning tree min 
efficient algorithm determine minimal spanning tree set points butterfly 
log processors processor responsible log clusters perform broadcast minimization operations log time pram 
entire algorithm requires log time log processors optimal 
algorithm efficient butterfly tree distance new cluster clusters stored processor requiring time update step 
case variant parallel minimal spanning tree algorithm driscoll see 
log processors loop requires log time find minimum log time butterfly tree 
minimal spanning tree easily transformed cluster hierarchy 
shows trees built algorithms 
centroid median metrics single link pram algorithm centroid median metrics small modifications 
pair clusters need determine new nearest neighbor clusters clusters nearest neighbor 
day edelsbrunner shown clusters specific cluster nearest neighbor metrics 
write indexes clusters need new nearest neighbors queue processor 
iterate queue broadcasting index cluster determining new nearest neighbor minimization operation 
perform algorithm log time log processors pram butterfly tree 
minimum variance metric minimum variance metric parallel version algorithm 
perform inner loop determining nearest neighbor cluster times step dominates computation time 
log processors simply store location center cluster processor find nearest neighbor log pram butterfly tree performing minimization minimal spanning tree built differently algorithms 
shown point set cases 
pram algorithm generates forest trees closest clusters step 
butterfly algorithm generates single tree adds closest cluster step 
distance cluster question clusters processor responsible 
algorithm requires log optimal 
average complete link metrics average complete link metrics pram algorithm minimum variance metric keep explicit array intercluster distances 
array updated log time agglomeration 
algorithm achieve optimality average complete link metrics butterfly tree case specify processor stores distance 
processor stores distances clusters responsible distances cluster stored processor able update array efficiently 
subsection gives best known algorithm case 
general metrics general metrics bound number clusters may particular cluster nearest neighbor 
addition nearest neighbor chain algorithm metric may satisfy reducibility property 
case employ parallel variant algorithm metric new intercluster distance determined constant time old intercluster distances lance williams updating formula 
processor processor distribution values processors 
example shows case 
straightforward distribution skewed distribution values 
create priority queue time single processor log time processor pram update priority queue agglomeration step requires log time 
algorithm requires log time processor pram sequential algorithm general metrics required log time optimal 
algorithm naively local memory machines store distances single cluster processor cluster require single processor step 
new storage arrangement facilitate implementation see 
skewed storage arrangement processor stores distance clusters mod case processor update values agglomeration cluster responsible 
updating data structure requires updated distance function intercluster distances lance williams updating formula stored processor result determined stored 
need perform permutation routing steps collect information appropriate processors 
general permutation routing butterfly requires log time worst case need consider possible permutations corresponding gamma pairs clusters merge compute deterministic log time routing schedules line 
schedules indexed numbers clusters merged 
efficient parallel algorithm general algorithms butterfly network require computing routing schedules line sufficient memory store schedules processor 
summary considered parallel algorithms hierarchical clustering intercluster distance metrics parallel computer architectures 
table summarizes complexities achieved 
addition results discussed time algorithms processor network distance metric time processors single link average link complete link sequential centroid median minimum variance general log log pram single link butterfly centroid log log tree median minimum variance pram average link log log complete link general butterfly average link log log complete link best known complexity derives time find euclidean minimal spanning tree computed gammaa log gammaa time gammad gamma algorithm impractical purposes 
best practical algorithms time 
table summary worst case running times various architectures 
crcw prams exist metric general case 
achieved optimal efficiency metric pram single link centroid median minimum variance metrics butterfly tree 
due nature average link complete link metrics hypothesize optimal parallel performance possible parallel architectures local memory 

mathematical theory connecting networks telephone traffic 
academic press 
bruynooghe 
parallel implementation fast clustering algorithms 
proceedings international symposium high performance computing pages 
day edelsbrunner 
efficient algorithms agglomerative hierarchical clustering methods 
journal classification 

efficient algorithm complete link method 
computer journal 
dijkstra 
note problems connection graphs 
numerische mathematik 
driscoll gabow tarjan 
relaxed heaps alternative fibonacci heaps applications parallel computation 
communications acm november 
kruskal 
shortest spanning subtree graph traveling salesman problem 
proceedings american mathematical society 
lance williams 
general theory classificatory sorting strategies 
hierarchical systems 
computer journal 
li fang 
parallel clustering algorithms 
parallel computing 
murtagh 
survey advances hierarchical clustering algorithms 
computer journal 
murtagh 
multidimensional clustering algorithms 
physica verlag 
olson 
parallel algorithms hierarchical clustering 
technical report ucb csd computer science division university california berkeley january 
prim 
shortest connection networks generalizations 
bell system technical journal 
ranka sahni 
clustering hypercube multicomputer 
ieee transactions parallel distributed systems april 
rasmussen willett 
efficiency hierarchical agglomerative clustering icl distributed array processor 
journal documentation march 
rivera ismail zapata 
parallel squared error clustering hypercube arrays 
journal parallel distributed computing 

algorithm hierarchical clustering minimum spanning tree 
computer journal 
sibson 
optimally efficient algorithm single link cluster method 
computer journal 
ward jr hierarchical grouping optimize objective function 
journal american statistical association 
yao 
constructing minimum spanning trees dimensional space related problems 
siam journal computing 
zapata 
parallel fuzzy clustering fixed size hypercube simd computers 
parallel computing 
