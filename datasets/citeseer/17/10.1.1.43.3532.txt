tiling multidimensional iteration spaces multicomputers ramanujam dept electrical computer engineering louisiana state university baton rouge la usa 
email max ee lsu edu sadayappan dept computer information science ohio state university columbus oh usa 
cis ohio state edu addresses problem compiling perfectly nested loops multicomputers distributed memory machines 
relatively high communication startup costs machines renders frequent communication expensive 
motivated method aggregating number loop iterations tiles tiles execute atomically processor executing iterations belonging tile receives data needs executing iterations tile executes iterations tile sends data needed processors 
synchronization allowed execution tile partitioning iteration space tiles result deadlock 
show equivalence problem finding partitions problem determining cone set dependence vectors 
approach partitioning iteration space deadlock free tiles communication volume minimized 
addition discuss method optimize size tiles nested loops multicomputers 
differs approaches tiling method optimizing grain size tiles multicomputers 
multicomputers distributed memory message passing machines attractive due scalability flexibility performance suffer lack adequate programming support tools 
parallelizing compilers machines received great attention 
addresses problem compiling nested loops multicomputers 
message passing paradigm employed machines program development significantly different conventional shared memory machines 
requires processors keep track data distribution communicate explicitly moving data messages 
addition current technology communication overhead order magnitude larger author research supported part louisiana educational quality support fund contract rd 
tiling multidimensional iteration spaces multicomputers oct corresponding computation 
relatively high communication startup costs machines renders frequent communication expensive 
turn calls careful partitioning problem efficient scheduling computations communication 
motivated concern method partitioning nested loops scheduling multicomputers view matching optimizing granularity resultant partitions 
nested loops common large number scientific codes execution time spent loops 
nested loops amount computation involved executing single iteration may offset communication startup overhead processors may spend time interprocessor communication executing computations 
result method aggregating number loop iterations tiles tiles execute atomically processor executing iterations belonging tile receives data needs executing iterations tile executes iterations tile sends data needed processors 
synchronization allowed execution tile partitioning iterations tiles result deadlock 
perfectly nested loop executed multicomputer execution communication costs tile shape size chosen optimize performance addition tiles assigned processors minimize communication costs reduce processor idle times 
show equivalence problem finding partitions problem determining cone set dependence vectors 
approach partitioning iteration space deadlock free tiles communication volume minimized 
tremendous advances years area intelligent routing mechanisms efficient hardware support interprocessor communication multicomputers 
techniques reduce communication overhead incurred processor nodes incident path pair communicating processors turn greatly simplifies task mapping partitions processors 
address mapping problem 
presents new approach determine valid tiles minimize communication volume result tiling 
addition discuss method optimize tile size execution nested loops 
discussion background material related section 
sections show equivalence problems finding deadlock free partitions problem determining set extreme vectors set dependence vectors linear programming formulation 
sections method linear programming minimizing communication volume nested loops 
section presents technique optimize tile size summarize discuss avenues research section 
background dependences thorough parallelization program critically depends precisely compiler discover data dependence information 
dependences imply precedence constraints computations satisfied correct execution 
algorithms exhibit regular data dependences certain dependence patterns occur repeatedly duration computation 
tiling multidimensional iteration spaces multicomputers oct statements necessarily distinct enclosed perfectly nested loops 
data dependences determine iterations loops executed concurrently 
flow dependence exists statement statement computes writes value subsequently sequential execution read flow dependence implies instances execute nest levels executed sequentially 
note loop nest levels need contribute dependence 
anti dependence exists reads value subsequently modified output dependence exists writes value subsequently written iteration space graph isg dependence relations represented iteration space graphs isg 
nested loop index set nodes isg points dimensional discrete cartesian space directed edge exists iteration defined iteration defined dependence exists statements loop constituting iterations dependences occur practice constant distance dimension iteration space 
cases vector gamma called distance vector 
algorithm number dependence vectors dependence vectors algorithm written collectively dependence matrix 
addition types dependence mentioned type dependence known control dependence 
control dependence exists statement conditional jump statement conditional jump statement controls execution statement 
data dependences flow dependence inherent computation 
multicomputers data transfer synchronization achieved message passing flow dependences correspond communication anti output dependences removed standard transformations 
discuss flow dependences 
dependence analysis discussed 
extreme vectors results number theory integer programming set distinct dependence vectors find set vectors say dependence vector expressed nonnegative linear combination vectors 
set vectors referred extreme vectors 
extreme vectors necessarily unique fact advantage choice tile shapes partitions sections 
related compiling programs multicomputers number research groups focused compiling programs multicomputers augmented user defined data decomposition :10.1.1.38.1547
tiling multidimensional iteration spaces multicomputers oct rice working interactive parallelization tools multicomputers provide user feedback interplay data decomposition task partitioning performance programs 
koelbel address problem automatic process partitioning programs written language called user specified data partitions 
group led kennedy rice university studying similar techniques compiling version fortran enhanced data decomposition specifications called fortran distributed memory machines intel ipsc show transformations improve performance 
rogers pingali method sequential program data partition performs task partitions enhance locality 
zima discuss superb interactive system semi automatic transformation fortran programs parallel programs machine loosely coupled hierarchical multiprocessor 
related tiling memory optimizations callahan discuss loop unroll jam context register allocation arrays 
chen describe crystal functional language addresses issue programmability performance parallel supercomputers 
gallivan gannon discuss problems associated automatically restructuring data moved local memories case hierarchical shared memory machines 
series theorems enable describe structure disjoint sub lattices accessed different processors information correct copies data local memories write data back shared address space modifications complete 
addresses automatic derivation transformations 
context hierarchical shared memory systems irigoin method divides iteration space clusters referred supernodes goals vector computation node data re partition parallelism partitions 
procedure works new data dependence abstraction called dependence cones 
address problem automatically choosing partitions 
king ni discuss grouping iterations execution multicomputers number conditions valid tile formation case dimensional iteration spaces 
mace proves problem finding optimal data storage patterns parallel processing shapes problem np complete limited dimensional arrays addition efficient algorithms derived shapes problem programs modeled directed acyclic graph dag derived series parallel combinations tree subgraphs 
schreiber dongarra discuss method choosing subset dependence vectors extreme vectors tiling 
wolf lam propose algorithm improving data locality loop nest compound transformations 
wolfe discusses technique referred iteration space tiling divides iteration space loop computations tiles blocks size shape traversing tiles results covering space 
optimal tiling memory hierarchy finds tiles data tile fit highest fastest level memory hierarchy exhibit high data reuse reducing total memory traffic 
addition context loop unrolling partitioning iteration space graphs discussed nicolau 
approaches attempt explicit minimization communication 
tiling multidimensional iteration spaces multicomputers oct tiling multidimensional iteration spaces mentioned relatively high communication startup costs distributed memory machines renders frequent communication expensive 
example message startup time intel ipsc takes transfer double precision floating point number neighboring nodes communication set access local memory takes negligible time 
focus collecting iterations tiles tile executes atomically intervening synchronization communication result able amortize high message startup cost larger messages expense processor idle time 
tile defines atomic unit computation comprising number iterations 
synchronization communication necessary execution tile 
imposes constraint partitioning iteration space tiles result deadlock dependence cycles tiles 
keep code generation simple necessary tiles identical shape size near boundaries iteration space 
equivalence tiling planes extreme vectors tiles dimensional spaces defined families parallel hyperplanes planes gamma dimensional hyperplane 
tiles defined near boundary iteration space tile subset iteration space 
shape tiles defined families planes size tiles defined distance separation adjacent pairs parallel planes families 
example gamma gamma gamma gamma endfor endfor shows iteration space graph defined loop example 
distance vectors gamma 
tiles isg defined families lines 
shows tiles size theta isg 
case arbitrary dependence graphs clustering tasks atomic collections result deadlock 
sarkar formulated condition absence deadlock case convexity constraint heuristic derives deadlock free convex partitions arbitrary dag 
irigoin conditions iteration space graphs 
tiles iteration spaces legal dependence vectors crossing boundary pair tiles cross tile source iterations dependence vectors tile sink 
ensuing discussion assume dependence matrix nested loop rank number dependence vectors vector defines family hyperplanes dimensional space delta delta delta xk tiling multidimensional iteration spaces multicomputers oct isg tiling example tiling multidimensional iteration spaces multicomputers oct various values tile boundary defined vector perpendicular 
dimensions vectors hk vector perpendicular ith boundary define legal tiles delta set dependence vectors 
define equivalent condition delta gamma dimensional planes boundary perpendicular condition 
form dimensional tiles dimensional iteration space assuming dependence matrix theta matrix columns dependence vectors rank vectors perpendicular tile boundaries linearly independent 
denote theta matrix rows vectors hk rank order define tiles 
restate condition matrix notation lets describe succinctly relation tile boundaries vectors perpendicular extreme vectors cast problem finding tile boundaries terms finding extreme vectors vice versa 
condition states dimensions vectors hk vector perpendicular ith boundary define legal tiles delta set dependence vectors 
matrix notation hd 
tiling condition implies tiles legal ij entries nonnegative 
matrix notation tiles defined dimensional tiles linearly independent means rank nonsingular 
result inverse matrix exist 
dependence matrix written gamma ij entry nonnegative relation implies dependence vector column matrix expressed nonnegative linear combinations columns matrix gamma columns gamma extreme vectors definition set dependence vectors constitute columns matrix tiles defined set extreme vectors set dependence vectors set valid tiling planes set vectors perpendicular tiling planes 
note unique 
section show linear programming formulation problem finding lower triangular unit diagonal 
integer matrix determinant sigma referred unimodular matrix inverse unimodular matrix unimodular matrix 
algorithm section finds unimodular gamma integral 
tiling multidimensional iteration spaces multicomputers oct extreme vectors dimensional iteration spaces dimensional iteration spaces extreme vectors subset dependence vectors 
algorithm described finds extreme vectors time number dependence vectors 
components dependence distance vector distance outer loop distance inner loop 
find ratio dependence vectors including signs 
vectors highest lowest values vector form set extreme vectors 
note vector extreme vector 
vector choose vector smallest value 
largest smallest values time 
case higher dimensional iteration spaces subset dependence vectors need extreme vectors 
illustrated example example gamma gamma gamma gamma gamma gamma endfor endfor endfor loop distance vectors gamma 
choice distance vectors extreme vectors fourth vector expressed nonnegative linear combination vectors fourth lie positive hull 
case extreme vector set consists vectors gamma dependence distance vectors 
contrast example dependence vectors form set extreme vectors example gamma gamma gamma gamma gamma gamma endfor endfor endfor distance vectors gamma gamma 
note form set extreme vectors 
tiling multidimensional iteration spaces multicomputers oct valid extreme vectors imperative languages fortran dependence distance vector valid vector nonzero component positive 
dimensions set distance vectors columns matrix gammae set valid extreme vectors sufficiently large dimensions columns matrix gammae gammae set extreme vectors 
consider example 
distance vectors gamma 
case gamma gamma valid set extreme vectors 
general dimensions find matrix form delta delta delta gammae delta delta delta gammae delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta gammae gamma columns matrix form valid set extreme vectors dependence vector expressed nonnegative linear combinations columns matrix nonsingular entries gamma gamma ij gamma matrix gamma valid rows gamma define legal deadlock free tiles 
example dimensional iteration spaces matrix gammae gammae gammae valid set extreme vectors 
inverse gamma tiling multidimensional iteration spaces multicomputers oct set extreme vectors dependence matrix written ed ij entries nonnegative 
matrix notation gamma exists written gamma gamma ij written gamma delta gamma ith row gamma jth column rows gamma tile boundaries rows linearly independent 
synchronization accompanying data transfer tiles required dependence iterations belong different tiles 
tiles separated tile boundaries defined dependence vector case cross tile boundary tiles 
nonzero entry say ij implies communication incurred due jth dependence vector poking ith tile boundary 
amount communication tile boundary defined ith row function sum entries ith row transformed dependence matrix tiling minimal communication results previous sections formulate problem finding tiling planes linear programming problem finding transformation constraint rows tiling planes columns gamma spanning extreme vectors 
diagonal entries lower triangular entries integers theta theta delta delta delta theta tile defined region iteration space enclosed set feasible solutions delta delta communication volume theta theta delta delta delta theta tile communication volume gamma tiling multidimensional iteration spaces multicomputers oct proportional formulate problem finding set valid tiling planes minimizes communication volume linear programming problem find theta matrix minimized subject constraints dimensional tile size theta theta delta delta delta theta defined region iteration space enclosed set feasible solutions delta delta values aspect ratios tile 
communication volume theta theta delta delta delta theta tile communication volume gamma case rational entries lower triangular matrix normalized rows entries row integers gcd determinant equal discussion expression communication volume cases reader referred section 
rest assume delta delta delta stated 
loop nest example dependence matrix gamma problem finding communication minimal tiling planes extreme vectors finding matrix form hd gamma tiling multidimensional iteration spaces multicomputers oct nonnegative entries sum minimized 
problem minimize subject gamma solutions transformation extreme vectors columns gamma gamma gamma second solution transformation extreme vectors columns gamma gamma gamma case note columns gamma dependence vectors 
discuss difficult example dependence vectors form separate cones 
set dependence vectors need find matrix tiling multidimensional iteration spaces multicomputers oct minimized subject minimal solution means section discuss communication minimal extreme vectors dimensional iteration spaces 
extreme vectors minimal communication spaces matrices derived section unimodular 
important consequence tiles derived applying sequence elementary loop transformations loop interchange skewing reversal followed strip mining 
non unimodular loop transformations tiles matrices determinant procedure described complex deriving appropriate step sizes loops transformed 
case dimensional iteration spaces method finding extreme vectors transformation matrix necessarily lower triangular determinant need cases 
example dependence vectors gamma extreme vectors gamma case transformation matrix gamma determinant 
transformational view need find nonsingular matrix tiling multidimensional iteration spaces multicomputers oct hd gamma gamma nonnegative entries 
optimal solutions linear programming problems occur simplex vertices corners feasible region 
shows constraints feasible region 
corners feasible region set constraints gamma 
require nonsingular determinant nonzero gamma second simplex point considered 
solution gamma 
general need consider simplex vertices matrix nonsingular 
choice depends communication volume topic ensuing discussion 
set tiling planes integers determinant ad gamma bc intersection families lines need point iteration space 
defines family lines ax different values theorem banerjee book page follows value equation integer solution gcd divides value say means point iteration space lies line ax value point iteration space lies family lines gcd divide values implies gcd 
point iteration space lies intersection lines ax cx dy specific values assume gcd gcd ad gamma bc 
matrix refer det ad gamma bc gamma exists gamma ad gamma bc gammab gammac ax cx dy write need find minimum value intersection ax cx dy point iteration space find minimum value find point integers satisfies written gamma gamma tiling multidimensional iteration spaces multicomputers oct feasible solutions problem finding communication minimal tiling planes tiling multidimensional iteration spaces multicomputers oct gamma gamma gamma det gammab gammac det gammac gcd gamma gamma zero follows multiple det smallest value det det nonsingular matrix theta tile defined set feasible solutions delta delta delta delta det set feasible solutions delta delta det delta delta det prime possibilities 
det prime ways defining theta tile 
generalizes easily higher dimensional iteration spaces 
sum entries ith row transformed dependence matrix case dimensional iteration spaces communication volume incurred due tiles defined det tiles defined delta delta delta delta det tiles defined delta delta delta delta tiling multidimensional iteration spaces multicomputers oct aspect ratios communication volume det det iteration spaces simplex vertex vertex defines distinct transformation det nonzero need evaluate communication volume choose simplex vertex corner minimizes communication volume 
scheduling tile space graph tiles defined section dimensional iteration space 
dependence vectors isg define tile space dependence graph tsg indicates dependences precedence constraints tiles 
assume tile size larger magnitude dependence vector tile size dimension larger largest corresponding components dependence vector 
assumption leads ffl source sink dependence vector crosses tile boundary neighboring tiles ffl legal tiles satisfy convexity condition 
dependence vectors tile space dependence graph tsg tuples component 
gamma tiles tile depend 
lamport derived method scheduling loop iterations represented indices points iteration space finding family parallel hyperplanes indices lying hyperplane executed simultaneously 
refer family hyperplanes scheduling hyperplane 
scheduling tiles scheduling hyperplane satisfy conditions hyperplane theorem 
scheduling hyperplane dimensional vector components equal satisfies said conditions 
allocation tiles processors general may tiles number processors 
tiles allocated interprocessor communication minimized computation load balanced time 
note allocation scheme significant impact execution time 
discuss specific tile allocation scheme nested loops 
method generation tiles derivation ensures tile space graph dependences orthogonal directions 
choosing allocations tiles directions communication direction 
advantage scheme consideration dimensional tsg mapped gamma dimensional torus easily maps popular interconnection topologies multicomputers 
studying impact mapping dimensional tsg dimensional torus gamma 
interplay load balance communication depends tile size tile allocation scheme discussed 
tiling multidimensional iteration spaces multicomputers oct optimizing tile size computation defined dimensional isg size theta theta delta delta delta theta tiles defined sides size orthogonal axes tile space results partitions iteration space 
show results assuming unlimited number processors 
assume tiles allocated processors described previous subsection 
size tile assumed theta theta delta delta delta theta addition assume 
communication setup cost packet cost data transmission note costs normalized respect cost executing single iteration 
communication cost model comm theta length cost sending values iteration tile boundary processor executes neighbor tile gamma optimal tile size minimizes cost execution tiles 
derive expression optimal tile size solving zeros derivative cost respect nodes executed tile cost execution tiles time kn gamma gamma gamma setting dt dl get dt dl kn kl gamma wc gamma gamma gamma kn gamma gamma gamma assuming 
data transmission cost word negligible opt gamma theta gamma wc opt similar results derived overlapped communication model 
derive analytical results opt 
setting dt dl get wc gamma equation solved analytically 
cases values machine parameters problem parameters optimal value obtained numerical methods 
tiling multidimensional iteration spaces multicomputers oct tile boundaries induce tile space graph identified wavefront schedule valid scheduling hyperplane case nested loops dependence matrices rank optimal schedule unlimited processors available loop execution 
summary dealt compiler support parallelizing programs coarse grain multicomputers considered class programs expressible tightly nested loops regular dependence structure 
relatively high communication startup costs machines renders frequent communication expensive 
studied effect clustering communication ensuing loss parallelism performance propose method aggregating number loop iterations tiles tiles execute atomically 
execution tiles atomic important dividing iteration spaces loops tiles result deadlock 
showed equivalence problem finding partitions problem determining extreme vectors cone set dependence vectors 
approach partitioning iteration space deadlock free tiles communication volume minimized 
technique optimize tile size multicomputers 
investigating impact tiling distribution variables induce dependences 
progress problem deriving communication minimal tiling linear dependences lu decomposition nested loops 
studying tiling minimize task scheduling overhead parallel execution loops shared memory machines 
abramowitz 
handbook mathematical functions 
dover publications new york 
allen 
dependence analysis subscripted variables applications program transformations 
ph dissertation department mathematical sciences rice university houston texas april 
allen kennedy 
automatic translation fortran programs vector form 
acm trans 
programming languages systems vol 
pp 


theorem minkowski polyhedral monoids aggregated linear diophantine systems 
optimization operations research proc 
workshop university bonn october lecture notes economics mathematical systems vol 
pages springer verlag 
fox kennedy kremer 
interactive environment data partitioning distribution 
proc 
th distributed memory computing conference charleston carolina pages april 
banerjee 
dependence analysis supercomputing kluwer academic publishers boston ma 
tiling multidimensional iteration spaces multicomputers oct banerjee 
unimodular transformation double loops 
advances languages compilers parallel processing nicolau eds pitman london pp 

callahan kennedy 
compiling programs distributed memory multiprocessors 
journal supercomputing vol 
oct pp 

callahan carr kennedy 
improving register allocation subscripted variables 
proc 
acm sigplan conf 
programming language design implementation pp 
june 
chen choo li 
compiling parallel programs optimizing performance 
journal supercomputing pp 

chen choo li 
theory pragmatics compiling efficient parallel code 
technical report yaleu dcs tr yale university december 
gallivan jalby gannon 
problem optimizing data transfers complex memory systems 
proc 
acm international conference supercomputing st malo france pp 

gannon jalby gallivan 
strategies cache local memory management global program transformations 
journal parallel distributed computing vol 
october pp 

kennedy koelbel kremer tseng 
overview fortran programming system 
tech 
report rice comp tr department computer science rice university march 
irigoin 
supernode partitioning 
proc 
th annual acm symp 
principles programming languages san diego ca jan 
king ni 
grouping nested loops parallel execution multicomputers 
proc 
international conf 
parallel processing vol 
pp 
ii ii 
king chou ni 
pipelined data parallel algorithms part ii design 
ieee trans 
parallel distributed systems vol 
pages october 
koelbel mehrotra van 
semi automatic process partitioning parallel computation 
international journal parallel programming vol 
pp 

koelbel mehrotra van 
supporting shared data structures distributed memory machines 
proc 
second acm sigplan symposium principles practice parallel programming ppopp sigplan notices vol 
pages march 
koelbel 
compiling programs nonshared memory machines 
ph thesis csd tr purdue university november 
tiling multidimensional iteration spaces multicomputers oct kremer bast zima 
advanced tools techniques automatic parallelization 
parallel computing vol 
pp 

kuck kuhn padua wolfe 
dependence graphs compiler optimizations 
proc 
acm th annual symposium programming languages williamsburg va jan pp 

lamport 
parallel execution loops 
communications acm vol 
feb pp 

mace 
memory storage patterns parallel processing 
kluwer academic publishers boston ma 
nicolau 
loop quantization generalized loop unwinding technique 
journal parallel distributed computing vol 
oct pp 

padua wolfe 
advanced compiler optimizations supercomputers 
communications acm vol 
dec pp 

rogers pingali 
process decomposition locality 
proc 
acm sigplan conference programming language design implementation portland jun pp 

rogers 
compiling locality 
ph thesis cornell university august 
ramanujam sadayappan 
tiling iteration spaces multicomputers 
proc 
international conference parallel processing vol pages august 
ramanujam 
compile time techniques parallel execution loops distributed memory multiprocessors 
ph thesis ohio state university dept comp 
inf 
sci september 
ramanujam 
linear algebraic view loop transformations interaction 
parallel processing scientific computing sorensen editor siam press march 
ramanujam 
unimodular non unimodular transformations nested loops 
technical report tr department electrical computer engineering louisiana state university baton rouge la december 
sarkar 
partitioning programs macro dataflow 
proc 
acm conf 
lisp functional programming pages august 
sarkar 
partitioning scheduling parallel programs multiprocessors 
pitman london mit press cambridge massachusetts 
schreiber dongarra 
automatic blocking nested loops 
technical report university tennessee knoxville tn august 
schrijver 
theory linear integer programming 
wiley interscience series discrete mathematics optimization john wiley sons new york 
tiling multidimensional iteration spaces multicomputers oct wolf lam 
data locality optimizing algorithm 
proc 
acm sigplan conf 
programming language design implementation pp 
june 
wolfe 
optimizing supercompilers supercomputers 
ph thesis department computer science university illinois urbana champaign report october 
wolfe 
iteration space tiling memory hierarchies 
parallel processing scientific computing ed 
siam philadelphia pa pp 

wolfe banerjee 
data dependence application parallel processing 
international journal parallel programming vol 
pp 

wolfe 
optimizing supercompilers supercomputers pitman publishing london mit press 
wolfe 
iteration space tiling 
proc 
supercomputing reno nv nov pp 

zima bast 
superb tool semi automatic mimd simd parallelization 
parallel computing vol 
pp 

zima chapman 
supercompilers parallel vector supercomputers 
acm press frontier series 
