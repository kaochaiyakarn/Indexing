emotion speech recognition application call centers andersen consulting willow rd il petr ac com describes experimental studies vocal emotion expression recognition 
study deals corpus short utterances expressing emotions happiness anger sadness fear normal state portrayed non professional actors 
evaluation part corpus extracting features training backpropagation neural network models 
statistics pitch second formants energy speaking rate selected relevant features feature selection techniques 
neural network recognizers ensembles recognizers created 
recognizers demonstrated accuracy normal state happiness anger sadness fear 
total average accuracy 
second study uses corpus telephone messages varying length seconds expressing normal angry emotions recorded eighteen non professional actors 
utterances creating recognizers methodology developed study 
recognizers able distinguish states includes anger happiness fear calm includes normal state sadness average accuracy 
ensemble recognizers part decision support system prioritizing voice messages assigning proper agent response message 
architecture system discussed 
study explores people computers recognizing emotions speech 
monograph expression emotions animals humans written charles darwin century darwin 
milestone psychologists gradually accumulated knowledge field 
new wave interest risen attracting psychologists artificial intelligence specialists 
reasons renewed interest technological progress recording storing processing audio visual information development non intrusive sensors advent wearable computers urge enrich human computer interface point click sense feel invasion computers lifelike agents supposed able express understand emotions elliot 
new field research ai known affective computing identified picard 
research recognizing emotions speech hand psychologists done experiments suggested theories reviews years research van scherer 
hand ai researchers contributions areas emotional speech synthesis murray arnott recognition emotions dellaert agents decoding expressing emotions 
motivation project motivated question recognition emotions speech business 
potential application detection emotional state telephone call center conversations providing feedback operator supervisor monitoring purposes 
application sorting voice mail messages emotions expressed caller 
orientation study solicited data people professional actors 
focus negative emotions anger sadness fear 
target telephone quality speech khz rely voice signal 
means exclude modern speech recognition techniques 
achieve objectives decided stages research development 
objectives stage learn people recognize emotions speech find features speech signal useful emotion recognition explore different mathematical models creating reliable recognizers 
results stage promising start second stage objective create real time recognizer call center applications 
research stage create evaluate corpus emotional data evaluate people performance select data machine learning 
decided high quality speech data stage 
corpus emotional data asked colleagues record short sentences expected ll right tomorrow birthday getting married week 
sentence recorded times time subject portrayed emotional states happiness anger sadness fear normal state 
subjects recorded sentences twice different recording parameters 
subject recorded utterances yielding corpus containing utterances utterances emotional state 
utterance recorded close talk microphone utterances recorded khz bit rest utterances khz bit 
people performance data selection creating corpus designed experiment find answers questions people special training portray recognize emotions speech 
kinds emotions easier harder recognize 
implemented interactive program selected played back utterances random order allowed user classify utterance emotional content 
subjects took part evaluation stage participated recording stage earlier 
table shows performance confusion matrix 
rows columns represent true evaluated categories respectively example second row says utterances portrayed happy evaluated normal true happy angry sad afraid 
see easily recognizable category anger easily recognizable category fear 
lot confusion going sadness fear sadness state happiness fear 
mean accuracy agrees results experimental studies scherer van 
table 
performance confusion matrix category normal happy angry sad afraid total normal happy angry sad afraid left half table shows statistics evaluators emotional category 
see variance anger sadness significantly emotional categories 
means people better understand express decode anger sadness emotions 
right half table shows statistics actors subjects portray emotions 
interesting see comparing left right parts table ability portray emotions total mean stays approximately level ability recognize emotions total mean variance larger 
corpus utterances selected nested data sets include utterances recognized emotion cent subjects 
refer data sets 
sets contain number items 
see utterances corpus recognized subjects 
number increases data set corresponds level concordance decoding emotion speech 
look distributions utterances emotion categories data sets notice close uniform distribution normal state happiness anger sadness fear 
data sets higher level concordance anger begins gradually dominate proportion normal state happiness sadness decreases 
interestingly proportion fear stays approximately level data sets 
analysis suggests anger easier portray recognize easier come consensus anger table 
evaluators actors statistics evaluators statistics actors statistics category mean median min max mean median min max normal happy angry sad afraid feature extraction studies field point pitch fundamental frequency main vocal cue emotion recognition 
acoustic variables contributing vocal emotion signaling scherer vocal energy frequency spectral features formants usually formants considered temporal features speech rate pausing 
approach feature extraction enrich set features considering derivative features lpc linear predictive coding parameters signal features smoothed pitch contour derivatives dellaert 
study estimated acoustical variables fundamental frequency energy speaking rate formants bandwidths bw bw bw calculated descriptive statistics 
ranked statistics feature selection techniques picked set important features 
speaking rate calculated inverse average length voiced part utterance 
parameters calculated statistics mean standard deviation minimum maximum range 
additionally slope calculated linear regression voiced part speech line fits pitch contour 
calculated relative voiced energy proportion voiced energy total energy utterance 
altogether estimated features utterance 
relief algorithm kononenko feature selection 
ran relief data set varying number nearest neighbors ordered features sum ranks 
top features maximum standard deviation range mean bw mean bw mean energy standard deviation speaking rate slope maximum energy maximum energy range range range 
investigate sets features influence accuracy emotion recognition algorithms formed nested sets features sum ranks 
set includes top features maximum speaking rate second set extends features slope maximum third set includes top features 
computer recognition recognize emotions speech tried approaches neighbors neural networks ensembles neural network classifiers set experts 
nearest neighbors 
method estimates local posterior probability class weighted average class membership nearest neighbors 
data set database cases comparison test set 
ran algorithm number features 
best average accuracy recognition reached features average accuracy anger higher feature sets 
recognizers performed poor fear 
neural networks 
layer backpropagation neural network architecture element input vector nodes hidden sigmoid layer nodes output linear layer 
train test algorithms data sets 
sets randomly split training utterances test subsets 
created neural network classifiers trained different initial weight matrices 
approach applied data set feature set gave average accuracy distribution emotional categories normal state happiness anger sadness fear 
ensembles neural network classifiers 
ensemble consists odd number neural network classifiers trained different subsets training set bootstrap aggregation breiman cross validated committees techniques 
ensemble decision majority voting principle 
ensemble sizes 
shows average accuracy recognition ensembles neural networks data set sets features neural network architectures neurons hidden layer 
see accuracy happiness stays different sets features architectures 
accuracy fear relatively low 
accuracy anger starts feature set increases feature set 
accuracy sadness varies achieves maximum feature set 
average total accuracy 
set experts 
approach tried idea 
training neural network recognize emotions build set specialists experts recognize emotion combine results classify sample 
train experts layer backpropagation neural network architecture element input vector nodes hidden sigmoid layer node output linear layer 
subsets data set training test sets classes example angry non angry 
average accuracy emotion recognition approach fear neuron neuron architecture 
accuracy non emotion non angry non happy 
important question combine opinions experts obtain class sample 
simple natural rule choose class expert value closest 
rule gives total accuracy neuron architecture neuron architecture 
approach rule selection outputs expert recognizers input vectors new neural network 
case give neural network opportunity learn appropriate rule 
accuracy normal happy angry 
accuracy emotion recognition data set 
explore approach layer backpropagation neural network architecture element input vector nodes hidden sigmoid layer nodes output linear layer 
selected best experts generated dozens neural network recognizers 
presents average accuracy recognizers 
total accuracy stays node architectures 
average accuracy sadness high 
unfortunately turned accuracy expert recognizers high increase accuracy recognition 
general approach ensembles neural network recognizers outperformed chosen implementation stage 
development pieces software developed second stage erg emotion recognition game er emotion recognition software call centers dialog emotion recognition program 
program developed demonstrate results research 
second software system full prototype industrial solution computerized call centers 
third program just adds different user interface core er system 
developed demonstrate real time emotion recognition 
shall describe briefly sad afraid total er system 
implementation systems matlab small amount code 
accuracy normal happy angry sad afraid total 
set experts performance learned rule 
nu nu er emotion recognition software call centers goal 
goal development software create emotion recognizer process telephone quality voice messages khz bit part decision support system prioritizing voice messages assigning proper agent respond message 
recognizer 
surprise anger identified important emotion call centers 
account importance anger scarcity data emotions decided create recognizer distinguish states includes anger happiness fear calm includes normal state sadness 
create recognizer corpus telephone messages varying length seconds expressing normal angry emotions recorded eighteen non professional actors 
utterances automatically split second chunks evaluated labeled people 
creating recognizers methodology developed study 
created ensembles neural network recognizers feature inputs node architectures 
average accuracy ensembles recognizers lies range achieves maximum feature input node architecture 
system structure 
er system part new generation computerized call center integrates databases decision support systems different media voice messages mail messages www server information space 
system consists processes wave file monitor voice mail center message 
wave file monitor reads seconds contents voice message directory compares list processed messages new message detected processes message creates files summary file emotion description file 
summary file contains information numbers describe distribution emotions message length percentage silence message 
emotion description file second chunk message data describe emotional content chunk 
process reads summary files processed messages sorts account emotional content length criteria suggests assignment agents return back calls 
generates web page lists current assignments 
voice mail center additional tool helps operators supervisors visualize emotional content voice messages 
research explored people computers recognize emotions speech 
drawn results 
decoding emotions speech complex process influenced cultural social intellectual characteristics subjects 
people perfect decoding manifest emotions anger happiness 
second anger recognizable easier portray emotion 
important emotion business 
anger numerous variants example hot anger cold anger bring variability acoustical features dramatically influence accuracy recognition 
third pattern recognition techniques neural networks proved useful emotion recognition speech creating customer relationship management systems 
scherer acoustic profiles vocal emotion expression 
journal personality social psychology 

van characteristics recognizability vocal expression emotions 
netherlands foris 
breiman bagging predictors 
machine learning 
generation affect synthesized speech 
proceedings meeting american voice input output society 
darwin ch expression emotions man animals 
chicago university chicago press 
original published 
dellaert polzin th waibel recognizing emotions speech 
icslp 
elliot autonomous agents synthetic characters 
ai magazine 
hansen salomon neural network ensembles 
ieee transactions pattern analysis machine intelligence 

kononenko estimating attributes analysis extension relief 
de raedt bergadano eds 
proc 
european conf 
machine learning 

murray arnott simulation emotion synthetic speech review literature human vocal emotions 
acoust 
society america 
munro doyle improving committee diagnosis resampling techniques touretzky mozer eds 
advances neural information processing systems 
cambridge mass mit press 
picard affective computing 
mit press 
scherer vocal clues emotion encoding decoding 
emotion 
life communication agent emotion sensing character mic feeling session character muse 
proc 
ieee conference multimedia 

