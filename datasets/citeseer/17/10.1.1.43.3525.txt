natural language engineering 
printed united kingdom fl cambridge university press developing general models usability paradise marilyn walker candace kamm diane litman labs research park avenue florham park nj usa received february design methods performance evaluation major open research issue area spoken language dialogue systems 
presents paradise methodology developing predictive models spoken dialogue performance shows evaluate predictive power generalizability models 
illustrate methodology develop number models predicting system usability measured user satisfaction application paradise experimental data different spoken dialogue systems 
measure extent models generalize different systems different experimental conditions different user populations testing models trained subset corpus test set dialogues 
results show models generalize systems approximation general performance model system usability 
development methods evaluating comparing predicting system performance major open research issue area spoken language dialogue systems 
proposed paradise paradigm dialogue system evaluation general integrative framework evaluating walker 
paradise addressed research goals ffl support comparison multiple systems multiple versions system doing domain tasks 
ffl provide method developing predictive models usability system function range system properties 
ffl provide technique making generalizations systems properties system impact usability really matters users 
previous conducted number system comparisons application paradise experimental dialogues collected different systems annie voice dialing messaging kamm walker kamm litman elvis accessing email walker walker toot accessing online train schedules litman litman pan 
focuses predictive power generalizability models 
develop number models predicting system usability measured user satisfaction 
measure extent models generalize different systems different experimental conditions different user populations testing models trained subset corpus test set dialogues 
experimental corpus consists annie elvis toot dialogues totaling hours speech 
structure follows 
review paradise evaluation framework section 
section describes annie elvis toot systems experimental setup collecting corpus dialogues 
section presents results developing predictive models user satisfaction testing models subsets corpus 
discuss results suggest areas 
paradise state art evaluating prior proposal paradise framework evaluate terms battery subjective objective metrics 
metrics focused task completion transaction success 
performance component technologies speech recognizer performance sparck jones galliers hirschman ralston pallett 
subjective metrics included measures user satisfaction shriberg ratings generated dialogue experts cooperative system utterances bernsen 
motivation paradise problems arise battery metrics 
different metrics may contradict 
example danieli gerbino compared train timetable systems danieli gerbino version higher transaction success rate produced fewer inappropriate repair utterances version produced dialogues approximately half long 
report higher transaction success length dialogue critical performance tradeoffs acceptable 
second order generalizations different systems performing different tasks important know multiple factors impact performance users perceptions system performance depend dialogue strategy tradeoffs factors efficiency usability accuracy galliers 
paradise framework derives combined performance metric dialogue system weighted linear combination task success measure dialogue costs 
order specify factors go combined performance metric paradise posits particular model performance illustrated general models usability efficiency measures measures minimize costs qualitative success maximize task maximize user satisfaction fig 

paradise structure objectives spoken dialogue performance 

model proposes system primary objective maximize user satisfaction 
task success various costs associated interaction contributors user satisfaction 
dialogue costs types dialogue efficiency quality 
efficiency costs measures system efficiency helping user complete task number utterances completion dialogue 
dialogue quality costs intended capture aspects system may strong effects user perception system number times user repeat utterance order system understand utterance 
applying paradise dialogue data requires dialogue corpora collected controlled experiments users subjectively rate satisfaction 
addition components model task success interaction costs automatically logged system hand labeled 
paradise model posits performance function derived applying multivariate linear regression user satisfaction dependent variable task success dialogue quality dialogue efficiency measures independent variables 
modeling user satisfaction function task success dialogue cost metrics intended lead predictive performance models values user satisfaction predicted basis number simpler metrics directly measured system logs need extensive experiments users assess user satisfaction 
order predictive developing qualitative cost measures measured automatically active area research hirschman pao walker hirschman 
walker kamm litman paradise reality models derived experiments set systems user populations generalizable systems user populations 
reports results applying paradise different systems order show generalizations systems user populations 
experimental design experimental setup experiments applying paradise similar experimental setup 
experiment human subjects carried dialogue dialogue systems 
system implemented general purpose platform phone spoken dialogue systems kamm 
platform consisted speech recognizer supports barge user interrupt system speaking 
provided audio server voice recordings text speech tts interface computer running system telephone network module application specific functions modules specifying application grammars dialogue manager 
dialogues obtained controlled experiments 
annie experiments designed evaluate effect novice versus expert user populations impact short tutorial novice user population kamm 
elvis experiments designed evaluate effect different dialogue strategies managing initiative presentation information walker walker conduct experiments applying reinforcement learning dialogue elvis system learn experience dialogue strategies optimal walker 
toot experiments designed evaluate effects task difficulty cooperative versus literal response strategies litman 
toot experiments studied effect user adapted interaction conjunction different initiative confirmation dialogue strategies litman pan 
experiments required users complete set application tasks conversations particular version system 
paradise tasks characterized terms particular items information user find system 
set tasks designed representative typical tasks domain 
experiments annie designed comparable elvis users annie experiments performed tasks elvis 
user perform tasks sequence difference conversations system 
examine effect short tutorial users performed additional task part tutorial interaction starting experimental tasks 
example email access task annie elvis ffl working home morning plan go directly meeting go 
kim said send message telling general models usability meeting find meeting time meeting place 
complete task annie users accessed email linearly navigating email folder dialogue referring expressions message jump back messages heard 
annie prompts pre recorded annie switch prerecorded prompts text speech reading message headers bodies messages 
sample dialogue illustrating completion task version elvis shown sample dialogue 
elvis users ask hear summary inbox ask go ahead read messages 
reading messages initiated users prompted message selection criteria allowed select messages content specifying values sender subject field 
users select message directly needing linearly navigate folder possible users elvis complete task efficiently 
elvis utterances realized text speech 
annie 
get messages 
message 
message michael evaluation technical memo 
user message 
message 
message kim interviewing antonio 
interview 
go lunch 
kim 
monday march rd 

message 
message 
message kim meeting today 
meeting morning 
see kim 
user done 
fig 

sample dialogue annie system toot user performed tasks sequence 
task represented scenario user find train satisfying certain constraints system retrieve process online train schedules 
sample dialogue toot system task scenario 
dialogue illustrates mixed initiative implicit confirmation dialogue strategy 
ffl try find train going new york city philadelphia sunday pm 
find exact match find closest departure time 
please write exact departure time train total travel time 
experiments resulted dialogues annie system dialogues elvis system dialogues toot system total dialogues consisting hours speech 
walker kamm litman hi elvis 
new unread messages inbox 
say read summarize say help options 
summarize 
top level inbox kim message lunch message meeting today 
michael message evaluation group meeting 
noah message call tomorrow message interviewing antonio 
owen message agent personality 
read 
select sender subject order arrival 
sender 
sender 
kim 
messages kim message interviewing antonio message meeting today 
message titled interviewing antonio 
user message 
message kim meeting today 
meeting morning 
see kim 
done 
fig 

sample dialogue elvis hi schedule system 
toot 
may help 
get train philadelphia new york 
heard say go new york 
want leave 
sunday 
heard say leave sunday 
time want leave 
pm 
heard say leave pm 
want find trains philadelphia new york sunday pm 

am going get train schedule 
fig 

sample dialogue toot system data collection discuss detail metrics logged hand labeled experiments systems 
previously specific recommendations metrics consider active area research walker hirschman polifroni hirschman pao danieli gerbino bernsen 
metric task success dialogue efficiency dialogue quality previously proposed literature easily incorporated paradise framework 
metric experiments combination dialogue quality efficiency measures mainly focus measures automatically logged computed 
different methods collect data dialogues recorded dialogue manager logged system dialogue behavior number measures discussed general models usability users filled web page forms task task success user satisfaction measures 
measures summarized described detail 
ffl dialogue efficiency metrics elapsed time system turns user turns ffl dialogue quality metrics mean recognition score timeouts rejections helps cancels raw timeout rejection help cancel normalized ffl task success metrics task completion survey ffl user satisfaction sum tts performance asr performance task ease interaction pace user expertise system response expected behavior comparable interface 
fig 

metrics collected spoken dialogues 
dialogue efficiency metrics calculated dialogue recordings system logs 
length recording calculate elapsed time seconds interaction 
measures number system turns number user turns calculated basis system logging said heard user say 
dialogue quality measures derived recordings system logs hand labeling 
number system behaviors affect quality resulting dialogue automatically logged 
included number timeout prompts timeouts played user didn respond quickly expected number recognizer rejections rejects system confidence understanding low said sorry didn understand 
user behaviors system perceived affect dialogue quality logged included number times system played context specific help messages believed user said help helps number times system reset context returned earlier state believed user said cancel cancels 
recordings check users system utterances labeled state basis 
measure dialogue quality recognizer performance dialogue calculated terms concept accuracy 
recording user utterance compared logged recognition result calculate concept accuracy measure utterance hand 
concept accuracy measure semantic understanding system word word understanding 
example utterance read messages kim contains concepts read function sender kim selection criterion 
system understood walker kamm litman ffl system easy understand conversation 
tts performance ffl conversation system understand said 
asr performance ffl conversation easy find message wanted 
task ease ffl pace interaction system appropriate conversation 
pace ffl conversation know say point dialogue 
user expertise ffl system sluggish slow reply conversation 
system response ffl system way expected conversation 
expected behavior ffl conversation system voice interface compare touch tone interface voice mail 
comparable interface ffl current experience system get email think system regularly access mail away desk 
fig 

user satisfaction survey elvis annie experiments 
user said read concept accuracy 
mean concept accuracy calculated dialogue conjunction asr rejections compute mean recognition score dialogue 
goal generate models generalize systems tasks thought important introduce metrics generalize 
efficiency metrics generalize elapsed time complete task depends difficult task research suggested dialogue quality metrics generalize litman raw counts task specific 
normalized dialogue quality metrics dividing raw counts total number utterances dialogue 
resulted timeout rejection help cancel metrics 
web page forms basis calculating task success user satisfaction measures 
users reported perceptions completed task comp 
provide objective evidence fact completed task filling form information acquired system 
order calculate user satisfaction users asked evaluate system performance user satisfaction survey 
survey probed number different aspects users perceptions interaction order focus user task rating system shriberg responses converted 
supports alternative way calculating task success objectively kappa statistic compare information users filled key task walker 
earlier results indicated user perception task success better predictor satisfaction simply perceived task success measured comp 
general models usability table 
performance measure means dialogue different 
measure si mi exps fixed adapt comp user turns sys turns timeouts timeout helps help rejects reject elvis system initiative 
elvis mixed initiative 
annie experts 
annie novices tutorial 
annie novices 
toot non adaptable toot 
adaptable toot 
elapsed time 
mean recognition score 
user satisfaction 
jack love 
sample survey 
surveys identical comparable interface question eliminated toot survey 
surveys multiple choice survey response mapped range 
values responses summed resulting user satisfaction measure dialogue ranging 
results applying paradise table summarizes experimental corpus dialogues terms experimental conditions metrics collected 
section reports results ffl training models predict user satisfaction multivariate linear regression ffl testing models different systems different experimental conditions different user populations determine extent generalize 
walker kamm litman table 
testing predictive power different models 
training set training se test set test se annie annie elvis elvis toot toot elvis toot elvis annie novices annie experts training set train model 
amount variance user satisfaction training set accounted trained model 
fold cross validation estimate value reported mean standard error se shown 
characterization test set 
amount variance user satisfaction test set accounted trained model 
summary results testing training predictive models table 
model discussed trained performing stepwise multivariate linear regression set dialogues user satisfaction dependent variable metrics discussed shown table independent variables 
model describe training set indicate performance trained model training set describe test set indicate performance trained model test set 
table lists factors significant predictors user satisfaction models 
trained models system random dialogues system 
results system rows table showing degree model able predict user satisfaction training set column labeled training 
tested model trained random corpus particular system predict user satisfaction remaining dialogues system 
results rows table suggest toot model generalizes readily model fits elvis annie somewhat worse 
examined models trained combined data systems 
row table gives results training random dialogues combined corpus testing remaining dialogues 
rows table fold cross validation estimate training testing values represent means standard errors se shown 
rest table values obtained single training set separate held test set 
discuss detail predictive capability model dependent size training set fewer annie dialogues corpus 
general models usability table shows model predictor user satisfaction test set accounting variance examined models trained random systems elvis predict user satisfaction users systems annie toot 
results test shown rows table 
surprisingly elvis model accounts variance user satisfaction toot toot data sets accounting variance toot elvis test set 
elvis model accounts variance user satisfaction annie data set 
turn question models trained user population generalize different type user population 
examined ways 
group expert users participated annie experiments 
users annie system months regular basis 
users participated experiments novice users familiar limitations spoken dialogue systems 
dialogues dialogues expert users remaining dialogues collected novice users 
trained model dialogues novice users tested dialogues experts 
results shown table novices row 
results show models trained novice users easily generalize expert user population 
correlation predicted values actual values novice model accounts variance user satisfaction expert population 
second speech recognition performance varies great deal user user important assess models trained annie elvis toot generalize systems speech recognition performance better 
order examine question selected dialogues mean recognition score better dialogues 
dialogues equal train model predicting user satisfaction tested dialogues 
results shown row table show model accounts variance test data 
surprising contribution user satisfaction large model trained rest corpus 
table shows factors significant predictors user satisfaction trained models factors column ordered degree contribution 
annie system model recognizer performance task success comp largest contributors user satisfaction followed percentage dialogue turns rejections reject system asked user repeat paraphrase just said 
models annie experiments reflect fact population users deliberately varied experiments 
annie experts annie period months considerable experience spoken dialogue systems 
annie model reported row shows percentage requests help significant predictor user walker kamm litman table 
factors predictive power different models 
training set factors annie help comp elvis comp reject toot comp reject comp reject help novices comp reject help timeout comp reject help timeout training set train model 
significant predictors order contribution 
training set size mean squared 
model fit function training set size fig 

model fit function training set size 
tion reflecting fact users needed help significantly users typically lower satisfaction system 
examined training set size affects performance applying crossvalidation combined data systems 
trained random samples dialogues tested unseen dialogues 
plots model fit function amount data train model 
shows model fit starting level training set size approaches dialogues 
mean training dialogues greater mean training dialogues error bars model fits overlap suggesting larger corpora may increase predictive power models 
general models usability discussion introduced paradise framework evaluating spoken language dialogue systems hoped apply empirical approach developing general models system usability 
proposed user satisfaction measure system usability possible develop models predicting usability learning range metrics predictors user satisfaction 
focused developing general models predicting user satisfaction experimental data collected different 
results showed model developed dialogues annie accounted variance training data variance test data model developed dialogues elvis accounted variance training data variance test data model developed dialogues toot accounted variance training data variance test data 
words performance model unseen dialogues comparable performance training set 
showed general model trained dialogues combined systems accounted variance user satisfaction model accounted variance user satisfaction unseen dialogues 
words performance general model trained data statistically indistinguishable test set training set 
tested extent model trained system elvis predict user satisfaction systems annie toot 
tests showed elvis model account variance user satisfaction toot variance user satisfaction annie 
elvis model better predicting user satisfaction toot random unseen elvis dialogues predictive power annie data worse model trained annie dialogues 
suggests general factors predict user satisfaction shared models developed systems finding supported fact models share predictive factors shown table 
examined extent dialogues trained user population generalize dialogues collected user populations 
tested models trained dialogues novices dialogues experts 
novice models predict user satisfaction expert population 
shows important carry longitudinal studies users gain experience system general models trained sample dialogues including expert novice users 
results weaker tested models trained dialogues users experienced walker kamm litman average recognizer performance dialogues users experienced excellent recognizer performance 
results reported contribute goal developing general models system usability ways extended 
useful repeat analysis large corpus cross system dialogues collected participation evaluations walker hirschman 
second important extend techniques dialogues collected field studies opposed controlled experimental environment described examining differences dialogues collected predefined scenarios particular user dialogues collected user asked define task 
important determine possible achieve better model fits reported 
model fits range elvis model accounts variance user satisfaction toot model accounts variance user satisfaction 
possibility larger dialogue corpora help suggests larger dialogue corpora may automatically improve models 
result may misleading fair amount homogeneity dialogue systems examined 
varied tasks interaction style dialogue strategies systems built platform applied similar approaches dialogue manager specification 
possible avenues improving models user satisfaction 
line attack investigating modeling techniques powerful linear models tree models improve predictive performance 
second may possible develop number additional metrics predicting user satisfaction generalize systems walker hirschman 
results suggest users highly attuned quality interaction efficiency challenge develop metrics assess quality interaction reliably hand labelled automatically measured 
example field just develop metrics assess quality system strategies presenting information providing context sensitive help 
danieli 

field trials italian arise train timetable system 
interactive voice technology telecommunications applications pages 
bernsen 

principles design cooperative spoken human machine dialogue 
international conference spoken language processing icslp pages 
friedman olshen stone 

classification regression trees 
wadsworth brooks monterey california 
danieli gerbino 

metrics evaluating dialogue strategies spoken language system 
proceedings aaai spring symposium empirical methods discourse interpretation generation pages 
hirschman dahl mckay norton 

general models usability class proposal automatic evaluation discourse 
proceedings speech natural language workshop pages 
hirschman pao 

cost errors spoken language system 
proceedings third european conference speech communication technology pages 
jack foster 

intelligent dialogues automated telephone services 
international conference spoken language processing icslp pages 
kamm litman walker 

novice expert effect tutorials user expertise spoken dialogue systems 
proceedings international conference spoken language processing icslp 
kamm narayanan 

evaluating spoken dialog systems telecommunication services 
th european conference speech technology communication eurospeech pages 
litman pan 

empirically evaluating adaptable spoken dialogue system 
proceedings th international conference user modeling 
litman pan walker 

evaluating response strategies web spoken dialogue agent 
proceedings acl coling th annual meeting association computational linguistics pages 
litman walker kearns 

automatic detection poor speech recognition dialogue level 
proceedings th annual meeting association computational linguistics acl pages 
love foster jack 

identifying salient usability attributes automated telephone services 
international conference spoken language processing icslp pages 
pallett 

performance assessment automatic speech recognizers 
res 
natl 
bureau standards 
polifroni seneff glass hazen 

evaluation methodology telephone conversational system 
proc 
international conference language resources evaluation granada spain pages pp 

ralston 

perception comprehension speech 
bennet greenspan editors applied speech technology pages 
crc press 
shriberg wade price 

human machine problem solving spoken language systems sls factors affecting performance user satisfaction 
proceedings darpa speech nl workshop pages 
sparck jones galliers 

evaluating natural language processing systems 
springer 
walker hindle 

say evaluating spoken language interface email 
proceedings conference computer human interaction chi pages 
walker hindle 

evaluating competing agent strategies voice email agent 
proceedings european conference speech communication technology eurospeech 
walker narayanan 

learning optimal dialogue strategies case study spoken dialogue agent email 
proceedings th annual meeting association computational linguistics coling acl pages 
walker hirschman 

evaluation darpa communicator spoken dialogue systems 
proc 
second international conference language resources evaluation athens greece 
walker litman kamm 

paradise general framework evaluating spoken dialogue agents 
proceedings th annual walker kamm litman meeting association computational linguistics acl eacl pages 
