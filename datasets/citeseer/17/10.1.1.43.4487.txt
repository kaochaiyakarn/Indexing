addressing curse imbalanced training sets sided selection miroslav kubat stan matwin department computer science university ottawa louis ottawa ontario canada csi ca adding examples majority class training set detrimental effect learner behavior noisy unreliable examples majority class overwhelm minority class 
discusses criteria evaluate utility classifiers induced imbalanced training sets gives explanation poor behavior learners circumstances suggests solution simple technique called sided selection examples 
general topic learning examples described pairs vector attribute values corresponding concept label 
simplicity consider problems positive negative attributes continuous 
fisher task received plenty attention statisticians researchers artificial neural networks ai ml 
typical scenario assumes existence training set agent induces classifier performance assessed independent testing set 
interesting complication arises training set imbalanced sense classes say positive examples heavily underrepresented compared class 
encountered real world applications detection fraudulent telephone calls fawcett provost spotting unreliable telecommunications customers singh norton rare medical diagnosis thyroid disease uci repository 
extremely imbalanced classes prevail information retrieval filtering tasks lewis catlett 
pointed authors classifier performance applications kind expressed terms average accuracy percentage testing examples correctly recognized system 
domain studied lewis catlett examples positive retrieval system achieve accuracy denying presence requested document 
system accuracy close useless benefit classifiers similar domains assessed appropriate criteria 
informally user expects induced classifier perform positive negative examples class cost 
section gives brief overview possible options gives reasons criterion experiments geometric mean delta gamma accuracies observed separately positive examples negative examples gamma section discusses reasons results learning sparse positive examples viewed perspective criterion 
way provide grounds solution described sequel 
project detection oil spills satellite borne radar images kubat holte matwin faced relatively novel problem 
training set unbalanced positive examples extremely rare dozens oil compared hundreds 
having observed performance common learning systems significantly worsened number negatives exceeded reasonable limits advocated studies techniques tailored type domains reported experience program shrink developed kubat holte matwin 
program induces classifiers form simple network tests 
tests form properly selected subintervals attributes domains 
pursue quite different strategy 
table confusion matrix columns represent classes assigned classifier rows represent true classes 
guessed negative positive true negative performance learner drops abundant negative examples simply select reasonably sized subset negative examples 
turns needs necessary adapt existing technique known statistics quite time large ignored applications machine learning dealing imbalanced classes catlett pazzani fawcett provost lewis catlett 
particular adapted technique tomek links tomek removes examples majority class leaving examples minority class untouched 
call sided selection 
details section 
section reports experiments investigating merits sided selection framework nearestneighbor classifier decision tree generator 
experience oil spill task supplemented experiments domains similar characteristics including benchmark domains 
curse imbalanced training sets evaluation criteria formulate criteria performance systems statisticians confusion matrix table fields characterize classification behavior system 
instance number correctly classified negative examples number misclassified positive examples 
performance criteria couched terms numbers traditional accuracy inappropriate needs calculated acc information retrieval community prefers precision recall geometric mean quantities delta reaching high values precision recall high equilibrium 
authors lewis gale combine precision recall elaborate function called measure 
error rate negatives accuracy positives roc curve useful measure information criterion suggested analyzed kononenko bratko 
swets discusses measure reflects fact classifier deliberately biased classes extent bias accuracy positive examples increased cost accuracy negative examples gamma relation quantities captured called roc relative operating characteristics curve horizontal axis measures error rate negative examples vertical axis measures accuracy positive examples 
example shown 
informally curve shows extent accuracy positive examples drops reduced error rate negative examples 
larger area roc curve higher classification potential system 
kubat holte matwin geometric mean accuracies measured separately class delta gamma delta measure relates point roc curve idea maximize accuracy classes keeping accuracies balanced 
instance high low gamma result poor measure consistent requirements customer oil spill domain 
concrete choice critical considerations sequel believe metrics metrics sensitive needs class 
especially criterion discussed length kononenko bratko deserves attention convenient properties 
sparseness positive examples complicates learner task case extremely rare positives abundant negatives hurt 
offers intuition explains behavior nearestneighbor rule nn circumstances 
picture shows positive examples negative examples decision surface priori unknown learner 
reader see positive example negative nearest neighbor 
generalized number negative examples noisy domain grows number positives constant likelihood nearest neighbor example negative 
positive examples misclassified 
infinitely negative examples finite number sparse positive examples nn classifier experiences gamma unacceptable 
reasonably sized training sets situation partially rectified nearest neighbors single 
large training sets large positive negative examples harmful effect negative examples prevails 
similar inferred principles bayesian classifiers 
denote gamma priori probabilities positive negative class respectively denote gamma probability density functions positive negative class point pure bayesian classifier ignoring costs labels positive example gamma gamma 
inequality hardly satisfied learning task depicted gamma ae rarely gamma 
solution high costs positive examples small cost associated negative examples gamma 
classifier assign positive class gamma gamma gamma classifier problems properly estimate smooth density function positive class 
clear determine values gamma learning prior learning 
induction decision trees suffer 
decision trees known universal classifiers dichotomy points general position dimensional continuous space realized sufficiently large decision tree 
case positive example eventually represented branch tree 
sufficiently negative examples sparse positive examples positive regions arbitrarily small 
tree overfits data similar effect case nn classifier 
pruning tree answer main problem 
pruning regions contain examples classes 
commonplace policy associate leaf label class majority corresponding region 
applications rare positive examples regions containing mixed positives negatives labeled negative potential effect branches deemed positive algorithm appropriately modified 
course situation improved finding best pruning constant say means properly designed cross validation technique cart breiman 
address core problem positive example surrounded negative examples regions labeled negative 
sided sampling learning highly imbalanced training sets received attention neural network community 
common solutions duplicate training examples create new examples corrupting existing ones artificial noise increase learning rate example underrepresented concept 
realm machine learning problem addressed various ways weighing training instances pazzani introducing different costs positive negative examples gordon perlis windowing bootstrapping catlett sung poggio heterogeneous sampling lewis catlett forcing learner focus specific relationships certain attributes 
note problem different pure scarcity data discussed dietterich lathrop 
mentioned strategy chosen particular study learner select repre subset negative examples 
training set balanced drawbacks discussed previous section diminish 
selection techniques studied statistical literature hart gates tomek addressed machine learning researchers aha kibler albert zhang skalak lewis gale floyd warmuth 
focus papers mainly reduction training set size underlying algorithms instrumental particular problem 
requirement learner keeps positive examples rare wasted danger noisy prunes negative examples 
heuristics applied detect reliable examples 
illustrated fact negative examples roughly divided groups 

suffer class label noise instance point bottom left corner 

borderline examples close boundary positive negative regions 
borderline examples unreliable small amount attribute noise send example wrong side decision surface 

redundant part taken examples 
case examples upper right corner 

safe examples worth kept classification tasks 
redundant examples harm correct classifications increase classification costs 
shows happens training set borderline noisy examples removed 
illustrates reduction removal redundant negative examples 
examples picture training set nn rule bayesian classifier decision tree generator run serious problem 
intelligent agent try eliminate borderline examples examples suffering noise 
easily detected concept tomek links tomek 
idea put follows 
take examples different concept label 
denote ffi distance pair called tomek link example exists ffi ffi ffi ffi 
examples participating tomek links borderline noisy 
attempt reduce number redundant examples cast task creating consistent subset training set definition set 
training set borderline noisy negative examples 
training set removal redundant negative examples 
table algorithm sided selection examples 

original training set 

initially contains positive examples randomly selected negative example 

classify nn rule examples compare assigned concept labels original ones 
move misclassified examples consistent smaller 

remove negative examples participating tomek links 
removes negative examples believed borderline noisy 
positive examples retained 
resulting set referred consistent nn rule correctly classifies examples note training set consistent subset 
particular problem objective necessarily create smallest possible set negative examples reasonably shrinks 
variant technique invented hart 
start negative positive examples placed nn rule examples attempt re classify training examples misclassified added table summarizes procedure 
number redundant negatives reduced creating subset consistent training set 
system removes negative examples participate tomek links 
way noisy borderline examples discarded leads new training set experiments experimental setting task experiments demonstrate applications imbalanced training sets sided sampling improves behavior existing learners 
particular nn selected widespread known performance 
wanted compare results classifier induced training examples set results classifier induced sets redundant examples removed redundant borderline noisy examples removed 
obtain statistically reliable results circumstance scarce positive examples specific variant fold cross validation technique 
training set divided subsets equal size manner ensured proportion positive negative examples stratified sampling 
possible choices gamma subsets union gamma subsets training induced classifier tested remaining subset 
results averaged 
domains experimental testbeds roughly divided groups 
group formed data major projects originally motivated research oil spill detection sleep classification 
represent difficult learning tasks information provided attributes insufficient successful classification 
attributes probably irrelevant 
data files come oil spill detection project table characterization experimental data 
attributes continuous domain classes 
file attrib 
pos neg oil oil kr br vw veh reported kubat holte matwin 
refers set satellite images time preprocessed different image processing method 
positives rare domains perfectly fit problem definition section 
data files kr br come earlier research authors kubat pfurtscheller 
training set imbalanced number positive examples small 
negative examples known belong different subclasses 
apart domains followed common practice machine learning community experimented data files uci repository murphy aha researchers replicate experiments results 
adapt data needs defined task learning distinguish selected class classes 
specifically glass domain task learn class vowels domain vw task learn class vehicles domain veh task learn class 
testbeds summarized table 
domain table gives number attributes number positive examples number negative examples value defining fold crossvalidation technique 
benchmark domains veh discarded randomly examples just ensure subsets contain exactly proportion positive negative examples ensured number positive examples number negative examples divided integer number 
results discussion training set delete examples participate tomek links 
re move redundant examples prohibitively expensive 
algorithm described section relatively cheap capable removing redundant examples 
preliminary experiments revealed performance induced classifier largely unaffected choice redundant examples removed 
results summarized tables 
table divided parts 
gives results achieved training examples second part pertains situation removal redundant negative examples third part pertains case system removed negative examples participating tomek links 
values tables obtained fold crossvalidation technique values individual domains see table 
better illustrate learners behavior tables give results terms accuracy positive examples accuracy negative examples gamma geometric means values delta gamma reader see removal redundant negative examples significantly reducing number stored examples guarantee performance gain 
cases nn oil oil performance dropped removal redundant negatives solve main problem poor accuracy positive examples 
abundant negative examples borderline region bias classifier negative class 
examples removed set accuracy measured different classes examples positive negative balanced value improves domains wide margin 
extreme behavior oil ii domain difference performance set set behavior nn oil domain improvement 
comparison columns tables give average accuracy acc reader see values acc express alarming 
accuracy achieved set higher values indicate utility real world setting dubious instance missing positive examples oil domain 
table summarizes performance benchmark domains indicating limitations technique 
vehicles domain nn significantly profited sided sampling 
glass domain sampling technique leads modest improvement nn table results oil ex 
progr 
gamma acc nn nn nn table results oil ii ex 
progr 
gamma acc nn nn nn table results kr ex 
progr 
gamma acc nn nn nn table results br ex 
progr 
gamma acc nn nn nn table results observed benchmark domains vw veh nn nn nn causing performance drop 
detailed examination revealed domain yield disproportionate values gamma situation call sided sampling 
similar behavior observed vowels domain nn experienced improvement 
suggest algorithm applied 
look values gamma balanced 
prohibitively low carry sided sampling 
real world tasks learner avail just positive examples virtually unlimited number negative examples 
case classification accuracy testing set useful criterion 
alternative criteria selected performance geometric mean percentage positive examples correctly recognized gamma percentage negative examples correctly recognized 
common learning algorithms nearestneighbor rule induction decision trees misled number negative examples exceeds certain limits 
behavior pertains fundamental principles learners explained 
sensitivity imbalanced distribution examples mitigated selection techniques discard negative examples lie borderline region noisy redundant 
investigated impact simple selection techniques adapted remove negative examples keeping positives 
name sided selection 
experiments addressed class problems believe similar approach frame multiclass learning 
research partially supported due rob holte useful comments early versions 
sleep data research belong department medical informatics technical university graz austria recorded classified fonds zur der wissenschaftlichen forschung project 
due gert pfurtscheller kind permission data 
aha kibler albert 

instancebased learning algorithms 
machine learning breiman friedman olshen stone 

classification regression trees 
wadsworth international group belmont ca catlett 

test flight 
proceedings th international workshop machine learning pp san mateo ca morgan kaufmann brown beck schneider 

neural network training unequally represented classes 
dagli shin 
eds intelligent engineering systems artificial neural networks asme press new york dietterich lathrop lozano perez 

solving multiple instance problem rectangles 
appear artificial intelligence singh norton 

learning goal oriented bayesian networks telecommunications management 
proceedings international conference machine learning icml pp 
bari italy morgan kaufmann fawcett provost 

combining data mining machine learning effective user profile 
proceedings nd international conference knowledge discovery data mining pp 
portland aaai press floyd warmuth 

sample compression learnability vapnik chervonenkis dimension 
machine learning gates 

reduced nearest neighbor rule 
ieee transactions information theory gordon perlis 

explicitly biased generalization 
computational intelligence hart 

condensed nearest neighbor rule 
ieee transactions information theory kononenko bratko 

information evaluation criterion classifier performance 
machine learning kubat holte matwin 

learning negative examples abound 
proceedings th european conference machine learning ecml prague kubat pfurtscheller 

ai approach automatic sleep classification 
biological cybernetics lewis catlett 

heterogeneous uncertainty sampling learning 
proceedings th international conference machine learning icml pp 
new brunswick new jersey morgan kaufmann lewis gale 

training text classifiers uncertainty sampling 
proceedings th annual international acm sigir conference research development information retrieval murphy aha 

uci repository machine learning databases machine readable data repository 
technical report university california irvine pazzani merz murphy ali hume brunk 

reducing misclassification costs 
proceedings th international conference machine learning icml pp 
new brunswick new jersey morgan kaufmann quinlan 

programs machine learning 
morgan kaufmann san mateo skalak 

prototype feature selection sampling random mutation hill climbing algorithms 
proceedings th machine learning conference new brunswick morgan kaufmann sung 
poggio 

learning human face detection cluttered scenes 
proceedings th international conference computer analysis images patterns prague swets 

measuring accuracy systems 
science tomek 

modifications cnn 
ieee transactions systems man communications smc zhang 

selecting typical instances instancebased learning 
proceedings th international machine learning workshop pp 
san mateo ca morgan kaufmann 
