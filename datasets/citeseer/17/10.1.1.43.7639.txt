optimizing ml run time code generation peter lee mark leone school computer science carnegie mellon university pittsburgh pennsylvania cs cmu edu cs cmu edu describe design implementation compiler automatically translates ordinary programs written subset ml code generates native code run time 
run time code generation values invariants exploited compile time yielding code superior statically optimal code 
cost optimizing generating code run time prohibitive 
demonstrate compile time specialization reduce cost run time code generation order magnitude greatly affecting code quality 
benchmark programs examined exhibit average cost cycles instruction generated run time 
describe experience prototype system run time code generation 
system called fabius compiler takes ordinary programs written subset ml automatically compiles native code generates native code run time 
dynamically generated code efficient statically generated code optimized runtime values 
furthermore fabius optimizes code dynamically generates code partial evaluation techniques completely eliminating need manipulate intermediate representation code run time 
results extremely low overhead average cost run time code generation instructions executed generated instruction 
program benefits run time code generation little trouble finding realistic programs run significantly faster factor run time code generation 
research sponsored part advanced research projects agency title fox project advanced languages systems software arpa order 
issued esc ens contract 

views contained document authors interpreted representing official policies expressed implied advanced research projects agency government 
appear acm sigplan conference programming language design implementation philadelphia may 
cases ml programs compiled fabius outperform corresponding programs 
example bsd packet filter interpreter bsd operating system kernel uses fast selection network packets behalf user processes runs nearly faster typical inputs translated ml compiled fabius 
describes early experience fabius compiler particular emphasis low level optimization code generation issues 
brief discussion previous approaches run time code generation 
describe running example compilation strategies implemented fabius 
course possible catalog design decisions example illuminate key problems insights implementation techniques 
results bad evaluating fabius benchmark programs 
focus initially programs matrix multiplication network packet filtering 
showing results programs illustrate potential technology 
discuss briefly performance benchmarks mention particular lessons learned 
describe current related detail conclude number directions research 
previous approaches informal principle time space tradeoff tradeoff general purpose special purpose programs 
general purpose programs desirable necessary applications 
simple example consider choice general numerical analysis routine written specially sparse inputs 
special version faster cases inputs dense 
generality usually incurs penalty run time performance programmers take trouble write efficient specialized programs possible 
unfortunately possible predict ahead time specialized versions 
course tradeoffs old computer programming idea attacking generalpurpose programs generate special purpose code run time 
example ken thompson implemented search algorithm compiled user supplied regular expression executable finite state machine form native code ibm 
program general accepted regular expression fast generated special purpose code quickly 
run time code generation led notable performance improvements areas operating systems method dispatch object oriented systems instruction set simulation graphics applications 
emergence highly distributed web computing applications demand software general purpose safe highly composable 
trend prompted increased interest runtime link time optimization code generation way regain performance advantage enjoyed specialpurpose monolithic systems :10.1.1.117.6702
additional arguments run time code generation summarized keppel colleagues general purpose dynamic compilation despite increasing attention researchers done relatively little automate optimize process run time optimization compilation 
existing approaches quite effective applications specialized require significant effort part programmer 
standard approach provide programming support constructing representations programs run time invoking optimizing compiler transform representations native code 
approach relatively easy implement systems dcg approach shown useful interesting applications 
dcg programmer write program constructs intermediate code trees invokes compiler back translate optimized native code dynamically linked executed 
lisp systems long provided programmer support style programming expressions eval 
advantage expressions programmer specify construction lisp terms source level intermediate code trees 
similar features implemented extension standard ml :10.1.1.14.4810
engler colleagues added support style run time code generation top dcg system called results :10.1.1.18.5716:10.1.1.35.6058
better approach design programming language run time code generation performed programmer assistance 
example implementation self system provides run time compilation type specialized versions methods simply postponing aspects optimization compilation run time 
problem basic approach cost code generation run time high point improvements gained delaying compilation run time eliminated cost run time compilation 
example dcg reported overhead generating instruction run time instructions instruction generated 
templates possible reduce cost run time code generation pre compiling possible code generated run time 
previous focused templates sequences machine instructions containing holes place values 
code generated simply copying templates instantiating holes values computed run time templates may concatenated effect loop unrolling function inlining 
systems approach great success pike reiser compiler massalin pu synthesis kernel :10.1.1.119.4056
templates imposed significant burden programmers 
templates code instantiates typically constructed manually non portable error prone 
explored automatic derivation templates programs written higher level languages 
example tempo system uses gcc create machine code templates corresponding portions ordinary programs classified dynamic binding time analysis 
chambers colleagues adopt similar approach multiflow compiler generate templates programmer delimited dynamic regions modula programs 
major drawback templates severely limit range optimizations may applied run time 
template fixes particular instruction schedule chooses fixed encodings instructions precludes optimizations run time code motion instruction selection 
possible pre compile alternative templates code sequence choose run time knowledge approach attempted practice 
furthermore instantiating templates involves certain amount overhead template essentially low level intermediate representation code sequence 
instructions copied template code generation table lookup required locate instantiate holes 
shall demonstrate interpretive overhead largely eliminated 
specialized code generators advocate general approach reducing cost run time code generation ideas literature partial evaluation 
partial evaluator function called mix historical reasons takes code argument function value argument returns optimized code result partially applying mix fx result optimization code specialized function fx argument computes result repeating computations depend similar way partial evaluation reduce cost performing specialization code generation run time 
text function known compile time run time computation fx optimized specializing mix compile time mix mix mix result code specialized code generator mix called generating extension compute fx overhead processing text retaining optimizations 
essence code pre compiled away needed argument supplied 
fabius compiler partial evaluator create specialized run time code generators generating extensions manipulate templates intermediate representation code run time 
similar approach employed tcc compiler 
contrast tcc fabius achieves run time code generation completely ordinary ml programs depending language extensions systematic known techniques heuristics partial evaluation 
include memoization specialization unfolding static conditionals static values dynamic contexts 
fabius compiler previously high level overview approach call deferred compilation :10.1.1.35.6058
main goals deferred compilation minimize costs run time code generation allowing wide range optimizations statically dynamically generated code 
goal fabius compiler determine feasibility approach provide way test various design choices 
fabius compiles pure order subset ml integers reals vectors user defined datatypes 
chose language primarily reasons 
involved general project investigate practicality ml systems programming specifically network protocols 
special interest optimization ml programs 
second ml provides support expressing staged computations way usefully exploited run time code generation 
function type 
applied argument may profitable generate optimized code result simply building closure 
current language order allow function definitions currying express staging compile functions run time code generators 
restriction pure subset ml fundamental approach merely eliminates need analyze evaluation order dependencies simplifies implementation 
lack mutable data structures avoids need analysis sharing aliasing furthermore allows run time optimizations copy values freely 
simple example shall simple example integer dot product function demonstrate fabius constructs specialized runtime code generators 
dot product vectors simply sum products corresponding elements 
ml typically implemented tail recursive auxiliary function follows fun dotprod loop length loop sum sum loop sum sub sub compiler named quintus fabius roman general best known defeat second war 
primary strategy delay confrontation repeated small attacks eventually led victory single decisive conflict 
auxiliary function loop parameterized vectors index length vectors accumulating parameter sum tallies result 
dot product operation especially attractive candidate run time code generation frequently innermost loop long running numerical computations 
matrix multiplication example implemented nested loop outer loops select vector matrix inner loop computes dot product 
vector selected outermost loop compute dot products may profitable create specialized function vector 
see clearly potential code improvement suppose value vector fixed 
loop index depends length fixed loop completely unrolled 
constant propagation constant folding eliminate computation sub 
subscripting ml requires bounds checking optimizations yield substantial benefit 
sparse simple reduction strength eliminates multiplication addition subscripting sub zero 
optimizations performed run time values computed 
step taken fabius identify early computations performed statically generated code late computations appear dynamically generated code 
difficult task automate requires global knowledge implicit staging computations program 
moment fabius relies programmer provide simple hints allow local analysis uncover required information 
syntactically hints declaring functions take arguments curried form 
curried function applied argument referred early argument invokes code generator create specialized function parameterized remaining late arguments 
fabius employs dependency analysis extend classification function parameters body function producing annotation subexpression early late 
example dot product function annotated follows indicates early annotation underline indicates late annotation fun dotprod loop length loop sum sum loop sum sub sub note curried definition express staging computation loop function 
variables specified early parameters depend length conditional test early 
function applications early annotations taken indication inlined run time 
determining treatment function calls subtle problem discuss 
see details :10.1.1.35.6058
particular staging analysis difficult bindingtime analysis initial division program inputs supplied programmer :10.1.1.35.6058
annotating program fabius compiles register transfer language containing early late annotations turn translated representation annotated mips assembly code 
annotated mips code dot product loop shown 
interests clarity substituted symbolic register names omitted early annotations 
loop beq sll shift scale index addu compute address lw fetch number sll shift scale index lw fetch immed 
offset mult prod add sum sum prod addi loop move result sum ra return code specialized run time code generator 
early instructions simply executed late instructions emitted dynamic code segment explained 
example supplied vector dot product function dynamically created lw mult prod add sum sum prod lw mult prod add sum sum prod lw mult prod add sum sum prod move result sum code generated single pass relatively simple code generator extremely efficient :10.1.1.117.6702
loop operations early generated code completely unrolled 
operations involving vector performed code generator elements appear immediates emitted code 
index early byte offsets access hard wired generated code 
emitting native code emitting instructions quite simple 
fabius adds initialization code compiled program allocate dynamic code segment dedicated register called code pointer cp tracks address available word 
late instruction translated code constructs native encoding instruction writes dynamic code segment advances code pointer 
example simplifications omitted code subscript checking run time instruction selection single pseudo instruction multiplication requires multiple instructions implement mips 
untagged integers examples see section 
astute reader may notice code optimal improved slightly common subexpression elimination better pointer arithmetic 
efficiency multiple updates code pointer basic block coalesced 
add sum sum prod emitted follows li instruction encoding sw cp write code segment cp cp advance code pointer notice intermediate representation required run time 
course emitting code immediately executing involves subtle interactions system instruction prefetching mechanism discuss section 
cost code emission instructions instruction generated additional overhead incurred run time instruction selection described memoization mechanism discussed section 
loading bit immediate value usually requires cycles mips instruction encoding copied template 
doing slightly complicated pointer template maintained register 
emitted instructions fixed encoding 
example load instruction lw immediate offset specified value 
emitted follows lui upper half opcode load half offset sw cp cp cp mips restricts immediate values bits encoding valid value relatively small 
section describes fabius employs run time instruction selection determine instructions 
run time instruction selection benefit run time code generation viewed kind run time loop invariant removal execution frequency early computations reduced way achieved compile time optimizations 
benefit run time code generation arises early values late computations 
cases optimizations yield code superior statically optimized code 
preceding dot product example immediate offset load instruction load value correct byte offset element specified bit immediate value 
code generated load offset register requires instructions mips followed register register addition load 
fabius translates lw code shown 
fabius implements number similar forms runtime instruction selection 
course benefits optimizations weighed cost experience cost quite low intermediate representation manipulated benefit significant 
example run time strength reduction greatly improves performance dot product li scale addu unsigned comparison li fit bits 
beq srl get upper half lui load upper half andi get lower half load lower half addu lw lw specialized run time instruction selection sparse input completely eliminating computation sum sub sub sub zero 
demonstrate section optimization allows performance general purpose ml implementation matrix multiply compete favorably code designed specifically sparse matrices 
instruction caching prefetching unfortunately modern cache architectures designed run time code generation mind 
memory systems employ separate data instruction caches invalidate cached instructions memory writes occur assumed self modifying code rare 
run time code generators created fabius modify existing code crucial able reuse code space 
invalidating updating instruction cache necessary ensure remains coherent memory 
coherency mechanisms vary portability appear major concern 
cost invalidation varies widely 
decstation flushing instruction cache requires kernel trap plus approximately nanoseconds byte flushed 
fortunately relatively easy amortize cost 
fabius generated code generators modify existing code necessary flush individual words instruction cache new instructions written 
code garbage collected freed space invalidated single operation 
encountered technical challenges related instruction caching 
example shown earlier sections run time constants commonly propagated run time generated code appear immediate values 
pointers heap allocated structures may propagated garbage collector update invalidate code referenced data copied different location 
difficult mips bit pointer split bit immediate values location dynamically generated code unpredictable 
instruction prefetching complicates matters programs compiled fabius interleave code generation execution generated code 
instructions usually cached line line basis locations immediately preceding run time generated function may cached executed 
instructions appear locations may written cache incoherent 
fabius solves problem aligning newly generated function start instruction cache line 
issues section mention additional complexities encountered implementation fabius 
due space constraints little hint solutions adopted possible alternatives 
dot product example shown previously quite misleading simplicity 
example treatment function calls simplified inlining tail recursive call loop function merely compiled jump start code generator 
curried applications inlined compiled calls memoized code generator second address returned call 
memoization currently implemented procedure log records entry points previously optimized code values optimize 
efficiency values compared pointer equality determine code reused 
strategy causes unacceptable duplication effort benchmarks structurally equivalent values fail match 
pass run time code generation fundamental approach 
demonstrated fabius able completely eliminate overhead processing intermediate code run time hard wiring optimizations instruction encodings run time code generators 
approach compromises ability generate high quality code 
example surprisingly difficult avoid creating jumps jumps generating code conditionals run time 
desirable optimizations instruction scheduling difficult accomplish single pass structure code determined dynamic inlining 
improved register usage benefit run time code generation bears mention 
symbolic register names obscures effect preceding examples observed considering live ranges 
early late instructions textually adjacent occupy different live ranges may overlapping register assignments 
example dot product loop fabius assigns variables register 
currently register assignments determined compile time instruction encodings easy construct run time 
practice defeats advantages run time inlining registers free call site may unavailable 
fabius forced insert spill code inlined code benchmarks examined 
propose efficient solution problem :10.1.1.35.6058
preliminary results evaluate performance fabius experimented number small medium sized benchmark programs 
current fabius prototype dimension time fabius rtcg fabius dense special purpose dense conventional fabius sparse special purpose sparse oe time multiply theta matrices dense sparse garbage collector measurements report reflect cost reclaiming data code space 
reasons discussed section implemented tagging scheme integers pointers 
note issues probably small effect measurements 
example garbage collection code heap unnecessary packet filter benchmark absence little consequence 
issues discussed section 
executed benchmark programs unloaded decstation equipped timing board providing accurate mhz memory mapped clock 
machine run single user mode transient loads caused occasional variation execution times 
minimize effect selected minimum elapsed time observed iterations benchmark trial 
matrix multiplication implemented simple integer matrix multiplication routine ml dot product function described section evaluated performance run time code generation dense sparse matrices 
comparison purposes evaluated performance matrix multiplication algorithms implemented conventional nested loop order special purpose algorithm indirection vectors suited sparse matrices lack predictable characteristics 
ml implementation purely functional dynamically dimensioned arrays implemented immutable dimensional vectors subscript operation included bounds checks 
implementations statically allocated dimensional arrays bounds checking compiled gcc version optimization 
input matrices contained untagged pseudo random bit integers sparse matrices zero non zero elements randomly located 
compares execution times including time spent generating code ml code compiled code dense sparse matrices 
run time code generation ml code nearly twice slow conventional code mainly array bounds checking 
run time code generation significantly improved performance dense sparse inputs small inputs 
dense input fabius generated code matched performance special purpose code slower conventional code theta matrices 
sparse input fabius generated code factor faster conventional code theta matrices slower special purpose code 
similar improvements observed floating point matrix multiply 
time spent generating managing code run time insignificant representing percent execution time 
cost run time code generation recovered small matrices break point theta dense matrices breakeven point sparse matrices 
average instructions required generate instruction run time 
space usage significant 
dot product function created run time required kilobytes better scheduling reduce 
efficient reuse code space clearly requirement total memory footprint megabyte large matrices 
packet filtering packet filter procedure invoked operating system kernel select network packets delivery user level process 
avoid overhead context switching packet packet filter kernel resident 
kernel residence distinct disadvantage difficult user level processes specify precisely types packets wish receive packet selection criteria quite complicated 
useless packets may delivered result consequent degradation performance 
commonly adopted solution problem parameterize packet filter selection predicate dynamically constructed user level process 
selection predicate expressed syntax safe easily verified programming language trusted kernel 
approach substantial overhead selection predicate reinterpreted time packet received 
run time code generation eliminate overhead interpretation compiling selection predicate trusted native code 
generally run time code generation allow kernel efficiently execute agents supplied user level processes avoiding context switches 
approach investigated :10.1.1.117.6702
investigate feasibility idea implemented bsd packet filter language fabius compared performance bpf kernel resident interpreter implemented 
interpreter shown simple ml function called eval parameterized filter program network packet variables encode machine state 
note eval curried applied filter program program counter result function parameterized machine state packet 
matrix multiply example eval written ordinary ml function explicit indication run time code generation fact legal ml program specification staging computations currying arguments 
fabius compiles eval run time code generator evaluates operations involving filter program instruction decoding generates code operations involving packet data machine state 
example consider filter program selects packets ethernet type field specifies ip packet ld accum 
gets th pkt word 
rsh shift yielding type field 
eth ip ip packet 
ret accept 
ret mips code generated packet filter run time move slt offset pkt size 
beq lw accum 
gets th pkt word 
srl shift yielding type field 
move eth ip beq ip packet 
move reject 
move accept 
li indexing error 
jr ra code quite optimal run time code generator failed eliminate jumps targets jumps 
demonstrate interesting runtime optimizations ffl beneficial optimization kind run time loop invariant removal operations involving packet filter program counter instruction fetching decoding performed code generator 
symbolic register names added clarity contains accumulator pointer packet number words packet result register temporary 
delay slots omitted filled nop instructions 
ffl run time constant propagation embedded values filter program load offset shift amount eth ip constant immediates run time generated code 
ffl run time constant folding occurred load offset run time constant code generator folded index scaling implicit pkt sub 
resulting byte offset load immediate instruction 
ffl run time inlining eliminated tail recursive calls eval 
jumps performed code generator generated code 
larger packet filter programs show similar improvements 
compares execution times fabius packet filter implementation including time spent generating code bpf implementation packet filter selects non fragmentary tcp ip packets destined telnet port 
packet filter parse ip header length may vary determine location tcp destination port 
reliably compare execution times obtained sample packet traces eavesdropping busy cmu network averaged execution times traces precaution abnormal packet mixes 
modified bpf interpreter read packets trace files compiled optimization executed user mode 
timings reported exclude time required read packets trace files 
demonstrates time spent generating code run time quickly fabius implementation broke bpf approximately packets 
packets execution time reduced 
time spent generating code brief totalling ms instrumentation revealed run time code generator executed average instructions instruction generated 
run time generated code required average process packet bpf averaged packet 
space usage insignificant 
syntax packet filter program occupied words implementations fabius implementation generated instructions run time 
run time code generator performed small amount heap allocation words required run time generated code 
stack usage insignificant tail recursive calls compiled jumps 
additional benchmarks briefly summarize experience additional benchmark programs written ml 
benchmarks trivial size line function determining set membership significant widespread ml programs 
represent real world applications program determines dimensional structure rna molecules 
shows execution times benchmarks varying input sizes input size seventh benchmark varied 
interest brevity simply compare performance fabius generated code run time code generation curried uncurried functions respectively report details space usage generally val eval int vector int 
int int int vector int vector 
int fun eval filter pc mem pkt val pc pc pc length filter val instr filter sub pc val opcode instr 
load packet word immediate offset accumulator 
opcode ld abs val filter sub pc length pkt eval filter pc pkt sub mem pkt 
jump accumulator equals immediate 
opcode filter sub pc eval filter pc instr 
andb mem pkt eval filter pc instr andb mem pkt packet filter interpreter bsd packet filter language comprised risc instructions simple machine accumulator index register small scratch memory 
machine safe confining memory packet data scratch memory forbidding backwards jumps 
instructions encoded pairs bit words 
word specifies bit opcode optionally pair bit branch offsets 
second word specifies immediate value alu operations memory indexing 
number packets time ms gcc fabius run time code generation packet filter rtcg rtcg time dimension conjugate gradient time ms regexp matching attempted matches time ms association list lookup attempted lookups time ms set membership membership tests time game life guns time insertion sort words sorted additional benchmarks li tmp beq arg tmp li tmp beq arg tmp li tmp beq arg tmp 
signal error 
li result li result li result jr ra executable association list low 
total cost run time code generation varied benchmark relative cost low averaging roughly cycles generated instruction 
benchmark iterative solver sparse linear systems equations adapted 
conjugate gradient method finds solutions systems equations form ax square symmetric positive definite matrix point values 
program amenable run time code generation coefficient matrix multiplied gradient direction vector iteration varies 
system equations input tri diagonal graph demonstrates run time code generation able exploit sparsity yielding fold speedup system equations 
cost run time code generation low performance smaller systems equations superior statically optimized code 
demonstrates improvement obtained regular expression matching algorithm run time code generation 
thompson compiler regular expressions program simple backtracking interpreter 
fabius compiled code generator regular expression creates finite state machine native mips code 
input regular expression describing words containing vowels order matched lines usr dict words 
significant speedup observed small input sizes cost run time code generation recovered matches fold speedup attained matches 
association lists common data structure ml programs symbol tables mapping keys type values 
looking value association list time consuming memory accesses required fetch key entry head list match additional memory access required locate entry 
demonstrates run time code generation amortize overhead multiple lookups performed association list 
fabius automatically compiles curried lookup function code generator essence creates executable data structures require memory accesses sample lookup code generated run time contained 
task determining set membership suited run time code generation repeated membership tests set require duplicate effort amortized 
demonstrates effect run time code generation simple curried membership function written ml shows performance improvement observed commonly ml benchmark conway game life adapted uses set record locations living cells :10.1.1.117.6702
run time code generation improve performance course 
promising application considered insertion sort repeatedly chooses string head list compares rest strings list lexically greater 
lexical comparison function curried fabius compiles code generator performs subscripting operations string comparison loop yielding nest comparisons involving constant characters 
demonstrates optimizing lexical comparison function run time improve performance despite input requires repeated comparisons sort case reverse sorted prefix usr dict words 
practice lexical comparisons examine characters string time spent generating code remaining characters wasted 
experimented benchmark floating point intensive program attempts determine dimensional structure portions rna molecules constraint satisfaction backtracking search 
step search investigates possible placements nucleotide checking placements violate certain constraints specified input program 
constraint checking step unnecessary nucleotides generalpurpose nature program allow property exploited compile time optimizations 
fabius create specialized search function performs constraint checking truly necessary 
doing desired effect execution time reduced approximately percent problem size fixed 
appears due peculiar property problem domain nucleotides require constraint checking possible placements overhead eliminated run time code generation large cost run time optimization 
significant improvements low cost run time code generation means comparable performance possible 
greatly reduces risk automating staging decisions compiler 
implemented approach run time code generation principled practical 
ml allows compiler perform run time optimizations little effort part programmer 
facilitates substantial partial evaluation techniques optimize optimization process 
keeping cost run time code generation low appears critical languages ml typical programs manipulate large data sets easily amortize cost incurred general purpose run time compiler 
experimentation required fully evaluate progress far identified numerous areas research 
currently extending prototype fabius compiler support richer source language including mutable data structures higher order functions 
plan investigate feasibility run time register assignment scheduling run time optimizations 
postponed implementing major component fabius system tagging scheme integers pointers advances type directed compilation 
existing ml compilers commonly tags distinguish integers pointers support efficient garbage collection approach undesirable side effects integers restricted bits numerous tagging operations involved arithmetic operations 
til compiler project shown principled types compile time run time permits ml code compiled tag free monomorphic code 
focused efficiently compiling code ignored problem tagging 
experience benchmark programs led technology usable foolproof 
high level programming language greatly reduces programmer effort required run time code generation difficult programmer predict program behavior 
memoization expensive ineffective heuristic employ control run time inlining occasionally leads specialization specialization 
advances type theory suggested mechanism providing better feedback programmers :10.1.1.28.4059
ultimately feasibility deferred compilation demonstrated larger realistic programs 
encouraging see prototype fabius achieve results 
agesen type feedback vs concrete type inference comparison optimization techniques object oriented languages 
oopsla conference object oriented programming systems languages applications october 
appel compiling continuations :10.1.1.117.6702
cambridge university press new york 
appel macqueen separate compilation standard ml :10.1.1.14.4810
pldi conference programming language design implementation june pp 

auslander philipose chambers eggers bershad fast effective dynamic compilation 
pldi conference programming language design implementation may 
bershad savage pardyak sirer becker fiuczynski chambers eggers extensibility safety performance spin operating system :10.1.1.117.6702
symposium operating system principles december pp 

harper lee signatures protocol stack systems application standard ml 
conference lisp functional programming june 
bondorf danvy automatic recursive equations global variables data types 
sci 
comput 
programming september 
chambers eggers auslander philipose mock pardyak automatic dynamic compilation support event dispatching extensible systems 
workshop compiler support system software february 
chambers ungar customization optimizing compiler technology self dynamically typed object oriented programming language 
pldi conference programming language design implementation june pp 

cmelik keppel shade fast instruction set simulator execution profiling 
tech 
rep department computer science engineering university washington june 
consel el general approach run time specialization application popl symposium principles programming languages january pp 

davies pfenning modal analysis staged computation :10.1.1.28.4059
popl symposium principles programming languages january pp 

deutsch schiffman efficient implementation smalltalk system 
popl symposium principles programming languages salt lake city january pp 

draves compiler generation interactive graphics 
dagstuhl seminar partial evaluation february 
engler vcode retargetable extensible fast dynamic code generation system 
pldi conference programming language design implementation may 
engler hsieh kaashoek language high level efficient machineindependent dynamic code generation :10.1.1.18.5716:10.1.1.35.6058
popl symposium principles programming languages january pp 

engler proebsting dcg efficient retargetable dynamic code generation system 
conference architectural support programming languages operating systems asplos vi october acm press pp 

engler wallach kaashoek efficient safe application specific message processing 
technical memorandum mit lcs tm mit laboratory computer science march 
feeley lapalme multilisp solving constraint satisfaction problems application nucleic acid structure determination 
lisp symbolic computation 
ungar optimizing calls run time type feedback 
pldi conference programming language design implementation june 
jones gomard sestoft partial evaluation automatic program generation 
prentice hall 
keppel portable interface fly instruction space modification 
conference architectural support programming languages operating systems april pp 

keppel eggers henry case runtime code generation 
tech 
rep department computer science engineering university washington november 
keppel eggers henry evaluating runtime compiled value specific optimizations 
tech 
rep department computer science engineering university washington november 
leone lee lightweight run time code generation :10.1.1.35.6058
pepm workshop partial evaluation semantics program manipulation june technical report department computer science university melbourne pp 

massalin synthesis efficient implementation fundamental operating system services 
phd thesis department computer science columbia university 
massalin pu threads input output synthesis kernel :10.1.1.119.4056
acm symposium operating systems principles pp 

mccanne berkeley packet filter man page 
bpf distribution available ftp ftp ee lbl gov mccanne jacobson bsd packet filter new architecture user level packet capture 
winter usenix conference january usenix association pp 

mogul rashid accetta packet filter efficient mechanism user level network code 
acm symposium operating systems principles november acm press pp 

updated version available dec wrl research report 
pike reiser hardware software trade offs bitmap graphics 
software practice experience february 
poletto engler kaashoek tcc template compiler workshop compiler support system software february pp 

pu black consel cowan inouye walpole zhang optimistic incremental specialization streamlining commercial operating system 
symposium operating systems principles december 
tarditi morrisett cheng stone harper lee til type directed optimizing compiler ml 
pldi conference programming language design implementation may 
thompson regular expression search algorithm 
communications association computing machinery june 
volanschi muller consel safe operating system specialization rpc case study 
workshop compiler support system software february 
wainwright sexton study sparse matrix representations solving linear systems functional language 
journal functional programming january 
