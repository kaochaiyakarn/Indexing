locally weighted learning control christopher atkeson andrew moore stefan schaal college computing georgia institute technology atlantic drive atlanta ga cga cc gatech edu cc gatech edu www cc gatech edu fac chris atkeson www cc gatech edu fac stefan schaal fax carnegie mellon university forbes ave pittsburgh pa cs cmu edu www cs cmu edu hp html atr human information processing research laboratories seika cho soraku gun kyoto japan june lazy learning methods provide useful representations training algorithms learning complex phenomena autonomous adaptive control complex systems 
surveys ways locally weighted learning type lazy learning applied control tasks 
explain various forms control tasks take affects choice learning paradigm 
discussion section explores interesting impact explicitly remembering previous experiences problem learning control 
keywords locally weighted regression loess lwr lazy learning memory learning commitment learning forward models inverse models linear quadratic regulation lqr shifting setpoint algorithm dynamic programming 
necessity self improvement control systems apparent fields robotics factory automation autonomous vehicles impeded complexity inventing programming satisfactory control laws 
learned models complex tasks aid design appropriate control laws tasks involve decisions streams information sensors actuators data relatively plentiful 
tasks may change time multiple tasks may need performed 
lazy learning methods provide approach learning models complex phenomena dealing large amounts data training quickly avoiding interference multiple tasks control complex systems atkeson 
describes ways lazy learning techniques applied control tasks 
learning control important distinction representational tools lookup tables neural networks databases experiences structured representations call learning paradigms define representation training data comes training data modify representation exploratory actions performed related issues 
difficult evaluate representational tool independently paradigm vice versa 
successful robot learning algorithm typically composed sophisticated representational tools learning paradigms 
describe representational tool locally weighted learning atkeson different tasks different learning paradigms different results 
defining paradigms learning control complex systems useful identify separate components indirect model adaptive control system modeling exploration policy design 
component modeling process forming explicit models task environment 
approaches describe form explicit world models 
moore atkeson explore advantages disadvantages approaches form explicit models versus avoid forming models 
modeling process equated function approximation representational tool fit training data set 
focusing modeling component leaves important questions unanswered 
example training data come new training data collected addressed exploration component 
question identified model select actions addressed policy design control law design component 
aim survey implications locally weighted regression lazy learning technique modeling component part control system 
lazy modeling techniques implemented discussed exploring related issues exploration policy design 
policy design exploration components lazy sense modeling component exploit capabilities lazy modeling lazy modeler job easier 
focus lazy learning learning control 
review lazy learning expect reader read companion collection atkeson borrow terminology notation 
form lazy learning focus locally weighted learning experiences explicitly remembered predictions generalizations performed real time building local model answer particular query input function output desired 
motivation focussing locally weighted learning accurate function approximator methods multi layer sigmoidal neural networks radial basis functions regression trees projection pursuit sion statistical nonparametric regression techniques global regression techniques lazy learning techniques avoid negative interference 
primary characteristics learning control robot data comes continuously distribution data changes robot learns changes performance task 
locally weighted learning easily learns real time continuous stream training data 
avoids negative interference exhibited modeling approaches locally weighted learning retains training data lazy learning methods atkeson 
approach modeling complex functions typical task process dynamics collection simple local models 
benefit local modeling avoids difficult problem finding appropriate structure global model 
key idea lazy learning form training set local model query 
approach allows select training set relevant experiences nearby samples weight experiences relevance query 
form local model function query point taylor series models function neighborhood point 
local model predict output function query 
answering query local model discarded 
new local model created answer query 
leads benefit lazy modeling control delay choice local model structure structural parameters query answered different choices subsequent queries atkeson 
locally weighted learning represent nonlinear functions simple training rules single global optimum building local model response query 
allows complex nonlinear models identified trained quickly 
currently polynomials local models 
polynomial local models linear parameters estimated calculate parameters linear regression 
fast training continuous learning stream new input data possible 
true lazy learning transfers computational load lookup process experience linear parameter estimation process lookup locally weighted learning fast real time robot learning atkeson 
cross validation choose appropriate distance metric weighting function help find irrelevant input variables terms local model 
fact performing cross validation evaluation lazy learning expensive processing single query atkeson 
cheap cross validation search model parameters routine explored procedures take advantage atkeson maron moore moore moore lee 
extended locally weighted learning approach give information reliability predictions local linearizations generated local density distribution data estimate local variance atkeson schaal atkeson 
allows robot monitor skill level protect ignorance designing robust policies guide exploratory behavior 
attractive feature locally weighted learning flexibility 
explicit parameters control smoothing outlier rejection forgetting processes 
modeling process easy understand easy adjust control atkeson 
see explicit representation specific memories speed convergence improve robustness autonomy optimization control algorithms atkeson moore schneider 
frustrating watch robot repeat mistakes slight improvement attempt 
goal learning algorithms described improve performance rapidly possible little training data possible data efficiency 
related locally weighted learning increasingly control 
explored locally weighted regression robot control modeling time series compared lwr neural networks methods 
connolly compared different approximation schemes neural nets kohonen maps radial basis functions local fits simulated robot inverse kinematics added noise showed local polynomial fits accurate methods 
van der 
learned robot kinematics local linear models leaves tree data structure 
tadepalli ok apply local linear regression reinforcement learning 
baird klopf apply nearest neighbor techniques weighted averaging reinforcement learning thrun thrun sullivan apply similar techniques robot learning 
connell utgoff interpolated value function locally weighted averaging balance inverted pendulum pole moving cart 
peng performed cart pole task locally weighted regression interpolate value function 
aha salzberg explored nearest neighbor locally weighted learning approaches tracking task robot pursued caught ball 
mccallum explored lazy learning techniques situations states completely measured 
farmer apply locally weighted regression modeling prediction chaotic dynamic systems 
huang uses nearest neighbor weighted averaging techniques cache simulation results accelerate movement planner 
outline article organized types control tasks sections examine progression control tasks increasing complexity 
chosen tasks implemented lazy learning part learning controller 
type task show lazy learning models interacts parts learning control paradigm described 
tasks provide implementation details 
progression control tasks outlined table 
temporally independent tasks include forms setpoint process control economic importance 
describe versions temporally dependent tasks include trajectory tasks process control transients vehicle maneuvers 
conclude discussion benefits drawbacks lazy learning context 
table control tasks explored 
symbols mathematics described entries explained corresponding sections 
task task specification goal example sec 
temporally independent desired output choose control trajectory fx choose devil sticking dynamic regulation matrices minimize cost ffix ru devil sticking ii dynamic regulation unspecified setpoint choose setpoint minimize cost devil sticking iii nonlinear optimal control cost function find control policy minimize sum costs puck temporally independent tasks simplest class tasks consider environment provides outcome represented vector function action vector choose state vector observe choose random noise 
noise task choose expected outcome expectation operator probability theory 
function known task 
section describe lazy learning learn model 
relationships modeled lazy learning techniques including forward models inverse models policies value functions 
discuss policies value functions context temporally dependent tasks sections 
sections describe inverse forward models 
control inverse models inverse model uses states outcomes predict necessary action atkeson miller gamma function specifies directly action take state specify happen state action 
lazy learner represent inverse model database experiences arranged input vectors experience concatenation state outcome vectors 
corresponding output action needed produce outcome state 
database trained adding new observed states actions outcomes 
learned inverse model provide conceptually simple controller temporally independent tasks 
action chosen current state desired outcome 
database implementing inverse model 
index database 
closest match database interpolation nearby experiences weighted average locally weighted regression approach 
stored experiences close current situation method choosing actions randomly select action 
distance threshold task dependent set user 
strength inverse model controller conjunction lazy learning learning aggressive repeated attempts achieve goal action applied incrementally adjusted version previous action action lazy learner predicts directly achieve required outcome 
monotonic relationship sequence actions chosen closely related secant method conte de boor numerically finding zero function 
see ortega discussion multidimensional generalization secant method 
inverse model represented locally weighted regression trained initially feedback learner atkeson 
commonly observed problem inverse model vector space actions different dimensionality outcomes inverse model defined 
problems result mapping misleading noisy observations 
learning stuck permanent pockets inaccuracy reduced experience 
illustrates problem non monotonic relation actions outcomes misinterpreted inverse model 
inverse model interpreted data correctly locally weighted averaging led incorrect actions moore jordan rumelhart 
subsequent sections temporally dependent tasks discuss action selected inverse function aggressive 
control forward models forward model uses states actions predict outcomes miller mel moore jordan rumelhart allows prediction effects various actions mental simulation prescribe correct action take 
action behavior chosen true function inverse model prediction true relation shown thick black line non monotonic 
outcome desired shown value action suggested produces outcome differs desired 
worse new data point added intersection thick black line vertical arrow change inverse model near mistake repeated indefinitely 

database implementing forward model 
arrange memory base input vectors data point concatenation state action vectors 
corresponding output actual outcome observed state action pair executed real world 
forward model trained observations states actions outcomes 
model control requires single lookup 
actions chosen line numerical inversion forward model requires searching set actions find predicted achieve desired output 
computation identical numerical root finding empirical model 
number root finding schemes applicable desirability depending dimensionality actions complexity function amount time available perform search ffl grid search generate available actions sampled uniform grid action space 
take action predicted produce closest outcome ffl random search generate random actions action predicted produce closest outcome ffl order gradient search perform steepest ascent search initial candidate action action give desired output press 
finding local gradient empirical model easy locally weighted regression atkeson 
part computation locally weighted regression model forms local linear map available 
may write prediction local ffix ffiu affix nd order terms vector matrices obtained regression ij ij gradient ascent iteration gamma defined equation 
approach may stuck local minima initial grid search random search may provide set starting points gradient searches 
ffl second order gradient search newton method iterate action desired output press 
approximate solution newton method gives better solution gamma gamma defined equation 
newton method stable order gradient search approximate solution available search methods local linear model structure correct region including current action best action produces estimate best action iterations 
partial derivative matrix singular action space state space differ dimensionality robust matrix techniques pseudo inverse applied invert press 
forward model minimize criterion penalizes large commands errors search robust gamma gamma ru matrices allow user control components error important 
combining forward inverse models inverse model provide initial starting point search forward model gamma evaluated lazy forward model data provided close newton method refinement 
close local linear model may fit aggressive newton step may move away goal 
exploration temporally independent learning nice feature approaches described far normal operation perform exploration reducing need human supervision external guidance 
experiments chosen greedily exact points desired output predicted forward model guaranteed provide useful data 
action wrongly predicted succeed resulting new data point change prediction forward model state action helping prevent error repeated 
early stages learning may action predicted give desired outcome 
simple experiment design strategy choose actions random 
effective choose data points uncertainty inherent prediction considered achieve desired outcome 
considerably reduce exploration required moore cohn 
temporally independent task order explore efficacy lazy learning methods control temporally independent tasks previously described approaches implemented robot shown moore moore 
equipment consists small theta pool table spring actuated cue rotary joint control stepper motor cameras attached datacube image processing system 
sensing visual camera looks cue stick looks table 
cue stick cue ball implementation start shot position 
shot proceeds follows 
start attempt object ball ball want sink pocket placed random position half table opposite cue stick 
random position selected computer avoid human bias 

camera table obtains centroid image coordinates object ball object object constitute state 
controller uses inverse model followed search forward model find action predicted sink object ball nearer pockets far table 
action specified wish view cue just prior shooting 
shows view cue camera process 
cue centroid object ball image shown vertical line coincides chosen action cue object shown cross 
robot 
foreground cue stick attempts sink balls far pockets 
view cue camera aiming 
cue centroid object ball image shown vertical line coincides chosen action cue object shown cross 

shot performed observed overhead camera 
image shot overlaid tracking balls shown 
outcome defined cushion position cushion object ball collides 
point 
independent success failure memory base updated new observation object object cue object time progresses database experiences increases hopefully converging expertise dimensional manifold state space corresponding sinking balls placed arbitrary positions 
learning begins explicit knowledge calibration robot pool table cameras having object ball view overhead camera assumption relationship state action outcome reasonably repeatable 
implementation representation forward inverse models locally weighted regression outlier removal cross validation choosing kernel width atkeson 
inverse forward models forward model searched steepest ascent 
early shots success predicted uncertainty moore 
shots control choice running sun seconds 
implementation demonstrates important points 
precision required modeling component 
cue action extremely precise success 
locally weighted regression provided needed precision 
graph number successes trial number shows performance robot time 
shot number trajectory balls tracked overhead camera 
indicates cushion position cushion object ball collides 
shot pocket missed 
frequency successes versus control cycle task 
number successes averaged previous shots shown 
sinking ball requires better accuracy choice action world contains discontinuities random outliers data due visual tracking errors encouraging experiences robot reached success rate 
informal assessment performance success rate high possible ball placed random positions virtually difficult 
unfortunately evidence anecdotal students built robot mit champion better 
second point non uniformity training data distribution due implicit exploration process 
function learned inputs output surprising achieved sufficient accuracy data points 
reason aggressive non uniformity training data distribution training data clustered state action pairs get ball close pocket 
lazy learner expend resources exploring representing bad shots 
optimizing performance criterion goal temporally independent learning optimize particular criterion achieve particular outcome 
lazy learning represent cost function directly speed search maxima minima moore schneider 
linear local model estimate derivatives gradient quadratic local model estimate second derivatives hessian cost function current point optimization procedure 
estimates order gradient search newton search uses estimates second derivatives 
constraints output included optimization process 
temporal dependence temporally independent tasks considerably easier choose actions temporally independent temporally dependent tasks choice action effect states 
need consider effects current action states indirectly performance 
section consider temporally dependent tasks opportunity choose suboptimal actions short term obtain desirable states improve performance long term 
temporally independent tasks provide opportunity increase knowledge available controller order improve performance 
differ batch learning tasks new training data available action choice action depends inferences earlier training data affects training data available decisions 
modifying actions increase knowledge greedily pursue desired outcome responsibility exploration component controller 
temporally dependent tasks complex class learning control tasks occur assumption temporal independence removed may influenced 
useful case explore outcome state task may regulate state predefined desired value called setpoint sequence trajectory states control approach performing temporally dependent tasks successful techniques previous section ignore temporal dependence 
step control chooses actions expectation cause immediate state desired state 
assuming state attainable step action may chosen paying attention states decisions performance 
implementation control devil sticking control lazy learning models explored implementing juggling task known devil sticking schaal atkeson 
center stick back forth 
shows sketch devil sticking robot 
juggling robot uses top joints perform planar devil sticking 
hand sticks mounted robot springs 
implements passive catch 
center stick bounce hits hand stick requires active illustration devil sticking sketch devil sticking robot 
position change due movement joint respectively indicated small sketches 
throwing motion robot 
simplify problem center stick constrained boom move surface sphere 
small movements center stick movements approximately planar 
boom provides way measure current state center stick 
task state predicted location center stick hits hand stick held nominal position 
standard equations flight center stick map flight trajectory measurements task state 
dynamics throwing devil stick parameterized state action variables resulting dimensional input output model hand 
time robot catches throws devil stick generates experience form current state action performed robot state center stick results 
initially explored learning inverse model task control attempt eliminate error hit 
hand inverse model form gamma hit system looked command predicted nominal impact state desired result state gamma inverse model learning lazy learning locally weighted regression successfully train system perform devil sticking task 
juggling runs hits achieved 
system incorporated new data real time databases hits 
lookups took milliseconds lookups performed flight center stick flight duration approximately 
queries incorporated measurements flight center stick accurate predictions state task 
system required substantial structure initial training achieve performance 
system started manually generated command appropriate open loop performance task 
control parameter varied systematically explore space near default command 
global linear model initial data linear controller model generate initial training set locally weighted system approximately hits 
learning small amounts initial data possible 
furthermore learning just inverse model prone get stuck poor levels performance repeat mistakes reasons discussed previous section 
eliminate problems experimented learning inverse forward models 
command generated inverse model evaluated forward model data 
produces local linear model locally weighted regression procedure produce estimates derivatives forward model respect commands part estimated parameter vector 
derivatives find correction command vector reduces errors predicted outcome forward model 
delta gamma process command refinement repeated forward model longer produces accurate predictions outcome happen query forward model requires significant extrapolation current database 
distance nearest stored data point crude measure validity forward model estimate 
investigated method incremental learning devil sticking simulations 
outcome meet expectations sufficient initial data setpoint algorithm 
see reasons 
similar pure inverse model approach inverse forward model acts step controller tries eliminate error time step 
step control applies large commands correct deviations setpoint especially presence state measurement errors 
workspace bounds command bounds devil sticking robot limit size allowable commands 
large control actions may accurate robust 
case devil sticking large control action tended cause center stick fly random direction learned hit 
second dimensional input space large experiences uniformly randomly distributed space data near particular point robust inverse forward model 
ingredients added devil sticking controller 
controller 
plan attain goal multiple control actions 
discuss control approaches keep commands small section 
second control increase data density current region state action space order arrive desired goal state 
discuss control approaches tightly coupled exploration section 
dynamic regulation section discuss reformulation temporally dependent control tasks avoid problems encountered implementation lazy learner robot control control 
theoretical point view possible return desired setpoint trajectory step attempt require actions infinite magnitude cause size required actions grow limit 
step control fail non minimum phase systems pole balancing example cannon 
systems move away goal approach 
case cart pole system cart initially move away target position pole direction cart motion target 
maneuvering avoids having pole fall backwards cart moves target 
controller perform robustly uses smaller magnitude actions returns correct state trajectory larger number steps 
idea posed precisely language linear quadratic regulation lqr long term quadratic cost criterion minimized penalizes state errors action magnitudes gamma gamma ru ffix ru matrices elements set tradeoff size action components error components 
example identity matrices sum squared state errors sum squared action components minimized 
control laws implies amount lookahead 
lqr control assumes time invariant task performs infinite amount lookahead 
predictive receding horizon control design techniques look steps ahead time action chosen 
techniques allow larger state errors reduce size control signals compared methods 
linear part lqr approach local linearization forward dynamics task 
take advantage locally linear state transition function provided locally weighted regression equation ffix ffix affix bu assume equilibrium point linear dynamics ffix affix bu optimal action respect criteria equation linear dynamics equation obtained solution matrix equation called equation 
assuming locally linear model provided locally weighted regression correct optimal action gamma pb gamma obtained setting running iteration convergence gamma br gamma gamma result obvious visual inspection follows reasonably elementary algebra calculus introductory controls text 
recommend 
provide simplified self contained derivation appendix long term cost starting state ffix turns ffix 
note linear function state equation linear quadratic regulation useful robustness compared controllers underlying linear models imprecise 
implementation dynamic regulation devil sticking ii linear quadratic regulation controller design permitted successful devil sticking 
require manual generation training data estimate matrices local linear model local linear model reliable robot complete policy control law vicinity local linear model 
aggressiveness control law controlled choosing matrices set adjusted learning 
drawback lqr implementation need manual search equilibrium point 
robot needed told nominal hit send devil stick hand 
continuum reasonable equilibrium points formulation required arbitrary selection 
furthermore experimenter know advance set equilibrium points actual machine manual search equilibrium points difficult task dimensional action space 
section describes new procedure search equilibrium points 
dynamic regulation unspecified setpoint learning task considerably harder desired setpoint known advance optimized achieve higher level task description 
setpoint task manipulated learning improve exploration 
done shifting setpoint algorithm ssa schaal atkeson 
ssa attempts decompose control problem separate control tasks different time scales 
fast time scale acts dynamic regulator trying keep controlled system chosen setpoint 
slower time scale setpoint shifted accomplish desired goal 
ssa uses local models lazy learning viewed approach exploration regulation tasks information quality predictions provided lazy learning 
experiment design shifting setpoints major ingredient ssa statistical self monitoring process 
current location input space obtained sufficient amount experience measure confidence rises threshold setpoint shifted direction goal confidence falls minimum confidence level 
new setpoint location learning system collects new experiences 
shifting process repeated goal reached 
way ssa builds narrow tube data support knows world 
data builds basis success regulator controller 
subsequently learned model sophisticated control algorithms planning exploration 
dynamic regulation unspecified setpoint devil sticking iii ssa method tested devil sticking juggling task schaal atkeson 
case steps 

regardless poor juggling quality robot hits trial ssa robot repeat initial actions small random perturbations cloud data collected state action space hand 
illustration 

point data cloud hand candidate setpoint corresponding hand trying predict output input locally weighted regression 
point achieving narrowest local confidence interval setpoint hand linear quadratic regulator calculated local linear model estimated locally weighted regression 
means controllers amount data setpoints quickly increased quality local models exceeded statistical threshold atkeson 

point setpoints gradually shifted goal setpoints statistical confidence predictions local model fell threshold 

ssa iterated collecting data new regions workspace setpoints shifted 
procedure terminated goal reached leaving ridge data state action space 
right left data density throw left throw right goal state ight hand right left juggling fails local model region right left right left goal state left hand illustration ssa algorithm collects data space sparse data hits high local data density due local control region increased data density way goals due shifting setpoints ridge data density goal reached 
ssa tested noise corrupted simulation real robot 
attempt juggle devil stick called trial consists series left right handed hits 
series trials begins lazy learning system initial state referred run 
measure performance number hits trial 
simulation takes average trials setpoint hand moved close hand setpoint 
slightly better performance real robot 
point breakthrough occurs simulated robot rarely drops 
time data points hits collected memory 
real robot learning performance qualitatively simulated robot 
due stronger nonlinearities unknown noise sources actual robot takes trials accomplish steady juggling pattern 
show typical learning runs actual robot 
show averages learning runs averaged runs show gradual increase performance individual learning run show sudden increases performance 
peak performance robot consecutive hits minutes continuous juggling 
limits linear quadratic regulation control laws linear quadratic regulator designs useful task requires operation outside locally linear region 
lqr controller may unstable 
number hits trial trial number run run ii run iii learning curves devil sticking runs 
example dimensional system dimensional action local linear model origin matrices theta dimensional problem 
optimization criteria equation equations gives goal moving origin linear control law unstable larger actions large 
means lqr optimal action increases error ffix error larger 
limitation linear quadratic regulation motivates explore full dynamic programming policy design approaches described section 
compares lqr control law control law full dynamic programming model optimization criteria 
note shifting setpoint algorithm provide initial training data complex approaches 
nonlinear optimal control general control design accommodate general formulation cost function criterion optimize move local control laws small number local models global control laws local models 
need learn just local model task local models task distributed task space 
discuss general formulation cost functions 
cost function step known controller task minimize expressions max fl fl lim attractive aspect formulations generality 
previously described control formulations special cases 
example quadratic step cost defined viewed local quadratic model 
state solid line optimal action dynamic programming dp nonlinear model dashed line optimal command lqr design single linear forward model origin 
cases optimization criterion lqr dp control laws agree small lqr control law linear take account nonlinear dynamics task large delayed rewards nature tasks means actions choose time affect quality immediate reward affect subsequent states doing affect rewards attainable 
leads computational difficulties general case 
large literature learning control problems years general name reinforcement learning 
overviews may sutton barto watkins barto moore atkeson 
restrict discussion applications lazy learning problems 
proceed learning empirical forward model 
generalpurpose solution obtained discretizing state space multidimensional array small cells performing dynamic programming method bellman bertsekas tsitsiklis value iteration policy iteration produce things 
value function mapping cells minimum possible sum costs starts cell 

policy mapping cells optimal action take cell 
value iteration conjunction learning world model 
extremely computationally expensive 
fixed quantization level cost exponential dimensionality state variables 
dimensional state space action space grid resolution states actions value iteration pass require evaluations forward model 
computationally intensive version perform cycles value iteration update memory base 
expensive forms dynamic programming normally perform value iteration trial example section incremental parallel process sutton moore atkeson peng williams 
simulation example puck illustrate form learning means simple simulated example 
depicts frictionless puck bumpy surface objective drive hill goal region minimum number time steps 
state dimensional lie region gamma gamma 
denotes horizontal position puck 
action dimensional represents horizontal force applied puck 
actions constrained gamma 
goal region rectangle gamma 
surface puck slides height function puck dynamics gamma gh 
equation integrated hx simulation time step 
gravity region near center hill maximum rightward thrust insufficient accelerate slope 
goal region hill top strategy proceeded greedily choosing actions thrust goal get stuck 
clearer state transition diagram 
puck state components position velocity 
hairs show state puck thrust rightwards maximum legal force 
center state space thrust applied puck velocity decreases eventually slides leftwards 
optimal solution puck task depicted initially thrust away goal gaining negative velocity far left diagram 
thrusts hard right build sufficient energy reach top hill 
explored implementations adaptive controllers lazy learning techniques 
ffl implementation grid conventional discretization 
conventional reinforcement learning strategy discretizing state space grid theta cells forward model value function 
reinforcement learning mg goal position frictionless puck acted gravity horizontal thruster 
puck get goal quickly possible 
bounds maximum thrust 
goal position velocity state transition diagram puck constantly thrusts right maximum thrust 
goal start position velocity minimum time path start goal puck hill 
optimal value function shown background dots 
shorter time goal larger black dot 
notice discontinuity escape velocity 
trial trial trial trial trial grid lwr trials implementations puck controller 
algorithm chosen efficient possible terms data needed convergence working fixed discretization 
transitions cells experienced system remembered discrete state transition model 
learning algorithm similar dyna sutton full value iteration carried discrete model time step 
exploration achieved assuming unvisited state cost zero 
action onedimensional discretized levels gamma gamma ng 
ffl implementation lwr lazy forward model 
second implementation transitions cells filled predictions locally weighted regression forward model 
implementation discrete transitions physically experienced stored transition table extrapolation actual experiences 
lazy model supported higher resolution representation areas experiences collected 
value function represented table implementations 
experimental domain simple empirical behavior demonstrates important point 
lazy forward model combination value iteration dramatically reduce amount actual data needed learning 
graphs trajectories experiments shown 
steps trial implementations shown 
best possible number steps trial 
implementation locally weighted regression forward model learns faster terms trials implementation grid 
lazy model implementation requires approximately orders magnitude fewer steps order reach optimal performance 
example trial grid implementation executed total steps optimal required trials combined lazy forward model implementation executed suboptimal steps 
include random noise simulation numbers deterministic 
spikes due severe nonlinearity problem small errors policy may lead puck failing energy get goal 
case puck slides back perform orbit start point state space reaching goal 
lack random sensor actuator noise conventional discretization trial steps lazy forward model trial steps top steps trial grid forward model 
bottom steps trial lwr forward model 
note difference vertical scales 
problem unrealistically easy approaches 
expect benefits lazy model standard grid model carry stochastic case 
computational costs kind control considerable 
necessary gather data part state space generalization occurs model simple form value iteration requires multidimensional discretization computing value function 
researchers investigating methods reducing cost value iteration model learned 
moore mahadevan atkeson 
exploration approach described explicitly explore 
learned model contains serious errors part state space wrongly looks visited real system model updated 
hand want system explore part state space explicitly supposed advantage lazy learning function approximation ability generalize parts model explicitly performing action 
resolve dilemma number useful exploration heuristics idea worth exploring little confidence empirical model sutton kaelbling moore atkeson cohn 
lazy learning models pros cons lazy learning models leads new forms autonomous control 
control algorithms explicitly perform empirical nonlinear modeling simultaneously designing policies strong commitment model structure controller structure advance 
parametric modeling approaches polynomial regression multi layer sigmoidal neural networks projection pursuit regression strong commitment model structure new training data global effect learned function 
locally weighted learning assumes local smoothness 
section discusses strengths weaknesses local lazy modeling approach context control 
stanfill waltz provide similar discussion lazy approaches classification 
benefits lazy learning models ffl automatic empirical local linear models 
locally weighted linear regression returns local linear map 
performs job engineer trying empirically linearize system region interest 
difficult neural net representations provide local linear map approximators straightforward nearest neighbor original version cmac albus miller reliable estimation local gradients predicted surfaces smooth 
additionally input data distribution non uniform shown linearizations returned locally weighted learning accomplish low bias estimate true gradient fewer data points required low bias prediction query hastie loader 
ffl automatic confidence estimations 
locally weighted regression modified return confidence interval prediction 
done heuristically local density data providing uncertainty estimate moore making sensible statistical assumptions schaal atkeson cohn 
case shown empirically dramatically reduce amount exploration needed uncertainty estimates guide experiment design 
cost estimating uncertainty locally weighted methods small 
nonlinear parametric representations multi layer sigmoidal neural networks adapted return confidence intervals mackay pomerleau approximations required computational cost larger 
worse parametric models global polynomial regression predict confidence statistically typically assuming true world perfectly modeled set parameter values 
assumption violated confidence intervals difficult interpret 
ffl adding new data lazy model cheap 
lazy model adding new data point means simply inserting data base 
ffl shot learning 
lazy models need repeatedly exposed data learn 
consequence rapid learning errors repeated eliminated quickly approaches incrementally update parameters 
nonlinear parametric models trained exposing model new data point jordan jacobs storing data database cycling training data repeatedly 
case data collected training effect data point small 
leads slower learning real robot movements take time increased wear tear robot industrial process controlled 
case lazy learning approach adopted evaluate relative benefits complex simple local models 
ffl non linear danger local minima function approximation 
locally weighted regression fit wide range complex non linear functions finds best fit directly requiring gradient descent 
dangers model learner stuck local optimum 
contrast training nonlinear parametric models get stuck local minima 
control law design algorithms surveyed stuck moore jordan rumelhart 
inverse model method stuck non monotonic highly noisy systems 
shifting setpoint algorithm stuck principle occurred practice 
ffl avoids interference 
lazy modeling insensitive task currently learning data distribution changes 
contrast nonlinear parametric models trained incrementally gradient descent eventually forget old experiences concentrate representational power new experiences 
drawbacks lazy learning models consider disadvantages lazy learning may encountered circumstances point promising directions addressing 
ffl lookup costs increase amount training data 
memory computation costs increase amount data 
memory costs increase linearly amount data generally problem 
algorithm avoids storing redundant data greatly reduce amount memory needed discard data selected predictive usefulness redundancy age atkeson 
computational costs serious 
fixed amount computation single processor process limited number training data points 
solutions problem atkeson database structured relevant data points accessed close approximations output predicted locally weighted regression obtained explicitly visiting point database 
surprisingly large number algorithms available doing kd trees preparata shamos omohundro moore grosse quinlan omohundro deng moore 
ffl curse dimensionality problem lazy learning control 
curse dimensionality exponential dependence needed resources dimensionality learning planning approaches 
methods discussed far handle wide class problems 
hand known strong constraints class functions approximated learning input dimensions successfully approximate particular function entire space potential inputs data set unrealistically large 
apparently serious problem multivariate control locally weighted learning raises question examples worked 
happily quite difficult think useful tasks require system accurate model entire input space albus 
robot say degrees freedom possible get significantly different configuration entire lifetime 
tasks require high accuracy low dimensional manifolds input space thin slices manifolds 
cases may clumps desired goal value stationary tasks 
example devil sticking robot needs gain highly accurate expertise vicinity stable juggling patterns 
common task involves system spending life traveling number important trajectories highways state space case expertise need clustered regions 
general curse dimensionality may dangerous tasks solution lies low dimensional manifold thin slice number state variables control inputs times larger 
event expect performance locally weighted regression method dimensionality problem increases locally weighted learning global necessary emulate global models global local particular directions emulate projection pursuit models distance function set choose projection direction example multiple projection directions multiple distance functions additive locally weighted fits friedman stuetzle 
expect locally weighted learning degrade gracefully problem dimensionality increases 
ffl lazy learning depends having representations selected 
representational choices choices elements state control vectors dramatically speed learning learning possible 
feature selection scaling algorithms crude form choosing new representations atkeson 
solved representation problem locally weighted learning machine learning approaches depend prior representational decisions 
explored methods lazy learning learn task models control emphasizing forward inverse learned models 
implementations lazy models 
section discussed detail pros cons lazy learning specific choice model learner 
little doubt advances converted general purpose software packages benefit robotics process control 
understood considerable way full autonomy 
human programmer decide state action variables problem task specified class control task engineering real time systems sensors actuators required 
human take responsibility safety supervision system 
stage problem relative effectiveness learning control measured proportion human effort eliminated heavily dependent issues 
appendix simple linear quadratic regulator derivation appendix provides simplified self contained lqr control readers wish understand ideas equations 
assume scalar state action assume desired state action zero 
assume linear dynamics ax bu constants 
define minimum possible sum costs starting state assuming time step assume system stops time stopping cost qx steps cost qx ru gamma qx ru qx assuming un gamma chosen optimally 
defined inductively qx arg min qx ru principal optimality says best bet minimal costs minimize step cost step plus minimum possible costs steps 
prove induction quadratic quadratic coefficient dependent pn ffl base case pn equation 
ffl inductive step assume ll prove remains algebra 
equation replace ax bu equation arg min qx ru ax bu inductive assumption arg min qx ru ax bu simplify new variables ff fi fl arg min ffx fix flu ff fi ab fl minimize equation respect differentiate set zero bracketed expression giving fix flu optimal action 
gamma fi fl minimizes equation ffx fl equation ffx fix gammafi fl fl gammafi fl ff gamma fi fl fi fl ff gamma fi fl shown ff gamma fi fl inserting back substitutions equations equations gammap ab gamma assuming gamma steps remaining compute cost go state set iterate assignment gamma pb pb total gamma times 
gamma large converges constant value proven 
gives cost go value function px assuming system run forever 
acknowledgments support atkeson schaal provided atr human information processing research laboratories 
support atkeson provided air force office scientific research national science foundation presidential young investigator award 
support schaal provided german scholarship foundation alexander von humboldt foundation 
support moore provided science engineering research council nsf research initiation award iri research gift 
aha salzberg 

learning catch applying nearest neighbor algorithms dynamic control tasks 
proceedings fourth international workshop artificial intelligence statistics pages ft lauderdale fl 
albus 

brains behaviour robotics 
byte books mcgraw hill 
atkeson 

local models control movement 
touretzky editor advances neural information processing systems pages 
morgan kaufmann san mateo ca 
atkeson 

local trajectory optimizers speed global optimization dynamic programming 
hanson cowan giles editors advances neural information processing systems pages 
morgan kaufmann san mateo ca 
atkeson moore schaal 

locally weighted learning 
submitted artificial intelligence review special issue lazy learning 
baird klopf 

reinforcement learning high dimensional continuous actions 
technical report wl tr wright laboratory wright patterson air force base ohio 
kirk af mil baird papers index html 
barto bradtke singh 

learning act real time dynamic programming 
artificial intelligence 
barto sutton watkins 

learning sequential decision making 
gabriel moore editors learning computational neuroscience pages 
mit press cambridge ma 
bellman 

dynamic programming 
princeton university press princeton nj 
bertsekas tsitsiklis 

parallel distributed computation 
prentice hall 
cannon 

dynamics physical systems 
mcgraw hill 
cohn ghahramani jordan 

active learning statistical models 
tesauro touretzky leen editors advances neural information processing systems 
mit press 
connell utgoff 

learning control dynamic physical system 
sixth national conference artificial intelligence pages seattle wa 
morgan kaufmann san mateo ca 
conte de boor 

elementary numerical analysis 
mcgraw hill 
deng moore 

multiresolution instance learning 
proceedings international joint conference artificial intelligence montreal 
morgan kaufmann 
farmer 

predicting chaotic time series 
physical review letters 
farmer 

exploiting chaos predict reduce noise 
lee editor evolution learning cognition pages 
world scientific press nj 
available technical report la ur los alamos national laboratory los alamos new mexico 
farmer 

predicting chaotic dynamics 
kelso schlesinger editors dynamic patterns complex systems pages 
world scientific nj 
friedman stuetzle 

projection pursuit regression 
journal american statistical association 
connolly 

comparison neural network scattered data approximations inverse manipulator kinematics example 
neural computation 
grosse 

loess multivariate smoothing moving squares 
ward editors approximation theory vi 
academic press 
hastie loader 

local regression automatic kernel carpentry 
statistical science 
huang 

planning dynamic motions search tree 
ms thesis university toronto graduate department computer science 
www dgp utoronto ca people psh home html 
jordan jacobs 

learning control unstable system forward modeling 
touretzky editor advances neural information processing systems pages 
morgan kaufmann san mateo ca 
jordan rumelhart 

forward models supervised learning distal teacher 
cognitive science 
kaelbling 

learning embedded systems 
mit press cambridge ma 


neural model adaptive hand eye coordination single postures 
science 
mackay 

bayesian model comparison backprop nets 
moody hanson lippman editors advances neural information processing systems pages 
morgan kaufmann san mateo ca 
mahadevan 

enhancing transfer reinforcement learning building stochastic models robot actions 
machine learning proceedings ninth international workshop 
morgan kaufmann 
maron moore 

hoeffding races accelerating model selection search classification function approximation 
advances neural information processing systems pages 
morgan kaufmann san mateo ca 
mccallum 

instance utile distinctions reinforcement learning hidden state 
prieditis russell pages 
mel 

murphy connectionist approach vision robot motion planning 
technical report university illinois urbana champaign 
miller 

real time application neural networks sensor control robots vision 
ieee transactions systems man cybernetics 
moore 

acquisition dynamic control knowledge robotic manipulator 
proceedings th international conference machine learning 
morgan kaufmann 
moore 

knowledge knowledge intelligent experimentation learning control 
proceedings seattle international joint conference neural networks 
moore 

variable resolution dynamic programming efficiently learning action maps multivariate real valued state spaces 
birnbaum collins editors machine learning proceedings eighth international workshop 
morgan kaufmann 
moore 

fast robust adaptive control learning forward models 
moody hanson lippman editors advances neural information processing systems pages 
morgan kaufmann san mateo ca 
moore atkeson 

prioritized sweeping reinforcement learning data real time 
machine learning 
moore hill johnson 

empirical investigation brute force choose features smoothers function approximators 
hanson judd petsche editors computational learning theory natural learning systems volume 
mit press 
moore lee 

efficient algorithms minimizing cross validation error 
cohen hirsh editors proceedings th international conference machine learning 
morgan kaufmann 
moore schneider 

memory stochastic optimization 
proceedings neural information processing systems conference 
omohundro 

efficient algorithms neural network behaviour 
journal complex systems 
omohundro 

efficient function constraint classification learning 
lippmann moody touretzky editors advances neural information processing systems pages 
morgan kaufmann san mateo ca 
ortega 

iterative solution nonlinear equations variables 
academic press 
peng 

efficient memory dynamic programming 
prieditis russell pages 
peng williams 

efficient learning planning dyna framework 
proceedings second international conference simulation adaptive behavior 
mit press 
pomerleau 

reliability estimation neural network autonomous driving 
robotics autonomous systems 
preparata shamos 

computational geometry 
springer verlag 
press teukolsky vetterling flannery 

numerical recipes cambridge university press new york ny 
prieditis russell editors 
twelfth international conference machine learning tahoe city ca 
morgan kaufmann san mateo ca 
quinlan 

combining instance model learning 
machine learning proceedings tenth international conference 
saitta editor 
thirteenth international conference machine learning 
morgan kaufmann san mateo ca 
schaal atkeson 

robot juggling implementation memory learning 
control systems magazine 
schaal atkeson 

assessing quality local linear models 
cowan tesauro alspector editors advances neural information processing systems pages 
morgan kaufmann 
stanfill waltz 

memory reasoning 
communications acm 


stochastic optimal control 
john wiley sons 
sutton 

learning predict methods temporal differences 
machine learning 
sutton 

integrated architecture learning planning reacting approximating dynamic programming 
proceedings th international conference machine learning pages 
morgan kaufmann 
tadepalli ok 

scaling average reward reinforcement learning approximating domain models value function 
saitta 
www cs orst edu research publications html 
thrun 

learning th thing easier learning 
advances neural information processing systems nips 
www cs cmu edu afs cs cmu edu web people thrun publications html 
thrun sullivan 

discovering structure multiple learning tasks tc algorithm 
saitta 
www cs cmu edu afs cs cmu edu web people thrun publications html 
van der groen van het 

locally linear nested network robot manipulation 
proceedings ieee international conference neural networks pages 
ftp ftp uva nl pub computer systems aut sys reports ps gz 
watkins 

learning delayed rewards 
phd 
thesis king college university cambridge 


algorithmic logical models automatic synthesis robot action 
phd dissertation university ljubljana ljubljana slovenia yugoslavia 


new methods machine learning construction integrated associative memory knowledge bases 
editors proceedings th mediterranean electrotechnical conference volume ii pages ljubljana slovenia yugoslavia 
ieee catalog number ch 


geometric learning nonlinear modeling control forecasting 
proceedings ieee international symposium intelligent control pages glasgow scotland 
ieee catalog number ch 


comparing predictions neural networks memory learning 
proceedings icann international conference artificial neural networks pages paris france 
