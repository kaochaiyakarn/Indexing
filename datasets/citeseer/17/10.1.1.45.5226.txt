adaptive resource allocation complex real time applications daniela rosu karsten schwan georgia institute technology atlantic drive atlanta ga daniela schwan cc gatech edu ee gatech edu rakesh jha honeywell technology center technology drive minneapolis mn jha src honeywell com git cc september resource allocation high performance real time applications challenging due applications data dependent nature dynamic changes external environment limited resource availability target embedded system platforms 
challenges may met adaptive resource allocation ara mechanisms promptly adjust resource allocation changes application resource needs risk failing satisfy timing constraints 
advantage application adaptation capabilities ara eliminates need sizing real time systems meet worst case application needs 
proposes model describing application adaptation capabilities runtime variation resource needs 
proposes satisfiability driven set performance metrics capturing impact ara mechanisms performance adaptable real time applications 
relevance proposed set metrics demonstrated experimentally synthetic application designed represent time critical applications systems 
college computing georgia institute technology atlanta georgia funded part darpa honeywell technology center contract 
contract 
nsf equipment cda cda ecs 
adaptive resource allocation complex real time applications daniela rosu karsten schwan georgia institute technology atlantic drive atlanta ga daniela schwan cc gatech edu ee gatech edu rakesh jha honeywell technology center technology drive minneapolis mn jha src honeywell com resource allocation high performance real time applications challenging due applications nature dynamic changes external environment limited resource availability target embedded system platforms 
challenges may met adaptive resource allocation ara mechanisms promptly adjust resource allocation changes application resource needs risk failing satisfy timing constraints 
advantage application adaptation capabilities ara eliminates need sizing real time systems meet worst case application needs 
proposes model describing application adaptation capabilities runtime variation resource needs 
proposes satisfiability driven set performance metrics capturing impact ara mechanisms performance adaptable real time applications 
relevance proposed set metrics demonstrated experimentally synthetic application designed represent time critical applications systems 

motivation 
resource management problems real time embedded applications exacerbated dynamic changes external environments restrictions resource availability 
solving problems worst case needs analysis typically viable excessive resource estimates resulting complex application behavior 
adaptive methods adjust resource allocation changes application needs insure satisfiability real time constraints 
contributions 
describes evaluates models mechanisms adaptive resource allocation ara context high performance embedded applications 
consider applications data dependent behavior driven event streams composed multiple possibly parallel interacting components 
runtime changes event rates importantly data content events cause significant changes resource needs various application components 
applications difficult closely estimate worst case event processing communication needs 
class applications includes radar systems robot control target recognition multi object tracking hypothesis testing 
ara mechanisms promptly adjust resource allocation changes application resource needs risk failing satisfy application timing constraints 
runtime adjustments constraint application adaptation capabilities eliminate need sizing real time systems meet worst case application needs 
describes novel model capturing application adaptation capabilities 
model specifies resources needed normal execution transfer application acceptable configurations 
addition describe new model capturing application resource needs runtime variation 
real time nature applications targeted research propose evaluate ara mechanisms impact satisfiability applications real time constraints 
submit essential consider latencies ara mechanisms respond changes application needs attempting restore satisfiability real time constraints 
quality ara decisions evaluated respect fast application returns acceptable performance performance steady state compared imposed application real time requirements 
response identifies elements contribute effectiveness ara methods detecting changes resource needs making resource allocation decisions 
assumptions experimental environment 
assumes multi machine environment single complex application 
result performance perturbations produced dynamics application external environment changes resource availability due failures explicit removals additions 
explicit admission control guarantees sufficient resources meeting application initial needs 
models heuristics proposed evaluated context centralized ara controller 
online monitoring performed mechanisms described 
experiments conducted synthetic application running cluster workstations 
application designed honeywell context high performance applications 
related research 
previous described frameworks mechanisms facilitate creation online adaptation heuristics real time applications including mechanisms runtime monitoring adaptation enactment mechanisms ensure reliable execution applications maintain high application throughput 
comparison focus define new frameworks define models methods frameworks analyze effect adaptive applications 
extensive research addressed problem dynamic resource allocation real time non real time domains 
methods developed studies fit target application model model assumes resource needs time constrained task generated type event may vary execution application 
variability prevents periodic task model performance requirements fixed application execution worst case needs considered 
prevents sporadic task model real time non real time domains high overhead resource allocation actions task arrival 
resource reallocation triggered runtime variation received attention 
previous schemes proposed real time non real time domains consider transitory effects adaptation mechanisms satisfiability application performance constraints 
primary interest attain optimal steady state performance 
overview 
remainder identify application ara model driving research section 
section important components application model ara described application resource usage model application adaptation model 
section identifies specific ara performance criteria derived real time nature target applications 
section demonstrate experiments relevance criteria identify methods help improve ara performance 

real time applications ara application model 
research targets reactive high performance applications meet defined real time constraints dynamic execution environments 
application consists multiple interacting components capable executing distributed environment consisting parallel machines embedded system components signal processors user interface stations workstations 
components sequential parallel tasks resource needs may data dependent varying changes rate content data inputs 
response components programmed adapt resource needs runtime changes execution mode algorithms specific attributes level parallelism communication protocols 
application execution driven event streams produced external environment application 
event stream processed fixed set components fixed precedence constraints described communication graph 
input pattern stream may vary changes execution environment 
communication parallel modules application component called intra communication communication neighbors communication graph called inter communication 
assume event intra communication happens event processing happens burst event processing 
command control communications intelligence application performance requirements defined constraints respect event rate latency component relative completion times 
timing constraint specific rate burst bounds 
radar ctrl 
search engage missile detect track init intercept 
track hz sec hz sec radar input missile tracing missile control sensor actuator app 
component 
radar application sample application 
sample application driving research phased array radar system 
presents part system described 
detection track init track computationally intensive tasks suited parallel implementation 
time processing communication needs vary number characteristics amplitude direction dwells 
nature computation tasks adapt changing internal levels parallelism 
main event streams radar system input radar input missile tracking device missile control requirements 
timing constraints concern necessary event rates processing latencies 
instance required rate radar input hz required missile control rate hz 
additional constraints second bound latency detect ing potential missile engaging search control second bound execution engage 
radar system applications concerned processing signals sensor suite forming hypotheses assessing situation appropriate response data observed processed period time 
examples multi hypotheses tracking image understanding 
front applications consists signal processing stages computational needs predictable independent signal values 
computations back depend semantic content signal values heavily data dependent 
specific resource allocation problems 
application model raises interesting resource allocation problems 
event stream execution viable option long term resource allocation 
alternatively short term resource allocation dynamic real time scheduling decisions prone add large overhead event processing particular individual application components parallel tasks executing distributed environment 
second worst case allocation may appropriate target applications 
context data dependent resource needs difficult evaluate worst case needs sufficient accuracy ensure safe execution acceptable resource utilization 
example radar system see resource needs track init highly data dependent vary number dwell returns selected threshold ambiguity spurious tracks 
similarly communication needs track determined number hostile tracks forwarded engage vary changes external environment 
worst case needs application depend worst case execution scenarios hard evaluate 
solution problems adaptive resource allocation ara 
advantage application adaptation capabilities ara permits long term resource reservations accommodating runtime changes resource needs 
adaptive resource allocation 
ara resource management paradigm takes advantage application runtime adaptation capability order accommodate dynamic resource needs satisfy system goals respect performance resource utilization 
context target application model goal ara insure time performance requirements application satisfied 
ara infrastructure satisfy types resource requests explicit implicit 
explicit request issued application new component arrival application deems necessary adjust resource usage 
implicit request issued ara infrastructure changes component resource usage considerably increase likelihood failing satisfy application performance requirements 
implicit requests explicit ones satisfied adjustments resource allocation application components decided ara infrastructure 
adjustments called automatic explicitly requested application 
performed prevent violations application performance constraint application component specific adaptation capabilities 
example automatic adjustment may performed due lack resources new application component accommodated components allocations reduced 
similarly automatic adjustment may triggered unexpected change execution environment causes change resource needs accommodated current configuration 
example change input data content causes increase event processing time particular component 
change require extending component level parallelism order meet required event rate 
alternative approach resource management infrastructure satisfy explicit requests provide application information observed resource usage 
information application decide adjustments resource needs 
contrast approach resource management attempts move part burden making adaptation decisions application resource management infrastructure 
similar approach taken previous 
benefits approach reduction application perturbation plus fact unexpected changes application resource needs receive fast response 
due resource management infrastructure fast access necessary information related resource availability current resource usage patterns application components 
drawback compared application level decisions ara decisions may fail produce appropriate resource assignment particular situation 
likewise ara may result resource allocation changes necessary achieving acceptable application performance 
models mechanisms embedded ara infrastructure mitigate potential drawbacks 
monitoring enactment component module detection enactment inter communication link intra communication link ara controller application internal model allocation decision 
centralized ara controller order achieve functionality ara infrastructure include mechanisms collecting information application resource usage resource availability detecting significant variations application resource usage inferring cause observed variations assessing necessity automatic adjustment resource usage making decisions automatic adjustments resource allocation notifying application significant changes resource usage notifying application resource providers changes resource allocation assisting enactment changes 
ara knowledge application characteristics 
characteristics described application model internal ara infrastructure 
structure application components event streams communication graphs performance requirements model describes application component acceptable configurations instances resource allocation permit component perform correctly runtime variation resource usage 
model interpret monitored information estimate system performance expected changes resource allocation guide decision heuristics 
model provides functionality critical mitigating ara infrastructure potential drawbacks respect appropriateness decisions minimizing execution overheads mechanisms 
performance ara determined appropriateness resource allocation decisions delay responds unexpected changes application behavior 
short response time helps reduce duration intervals application fails satisfy performance constraints 
delayed ara decisions large decision times decisions high enactment overhead help application cope immediate performance constraints 
ara functionality provided module called ara controller 
module may distributed centralized architecture 
depicts centralized controller similar experiments 
controller interaction application restricted monitoring allocation enactment 
sections address internal application model performance evaluation ara infrastructure significantly impact manner ara help adaptive application cope unexpected changes resource usage restrictions resource availability 

internal application model section describes research 
propose models describe application resource usage adaptation capabilities 
models part application model internal ara infrastructure ffl resource usage model rum describes application expected computational communication needs runtime variation 
ffl adaptation model am describes application acceptable configurations terms expected resource needs application specific configuration overheads 
rum ara decision making process evaluate current application resource needs determine performance requirements satisfied 
am permits ara controller decide appropriate resource allocation adjustments incurring negotiation overhead case resource management solutions support runtime adaptations 
addition knowledge configuration overheads permits ara controller understand evaluate tradeoffs alternative adaptation strategies 

resource usage model background 
resources available application nodes communication links 
node characterized speed mips mflops size local memory 
node uses scheduling policy able guarantee resource reservations provide feedback application actual resource usage proposed 
communication link provides unidirectional connection nodes 
characterized protocols reliable fifo unreliable known available bandwidth cost operations point constant message overhead byte overhead 
simplicity currently consider uniprocessor nodes 
shared memory multi processors modeled sets nodes equally distributed memory resources connected high speed communication links 
model formulation 
rum describes resource needs component event stream pair 
pair called component 
component described internally parallel task multiple cooperating modules independent point view resource allocation 
component resource needs described models static rum dynamic rum 
static rum describes expected computation communication needs dynamic rum captures runtime variation needs respect static rum 
parameters static rum ffl parallelism level ffl execution time ffl intra communication protocol ffl maximum outgoing intra communication message size ffl total number outgoing intra communication messages ffl total amount outgoing intra communication data ffl inter communication protocol ffl total number outgoing inter communication messages ffl total amount outgoing inter communication data ffl processor speed factor 
set inter communication related parameters defined separately successor communication graph 
static rum specified application part explicit request resources 
parameters may estimated traditional approaches algorithm analysis code profiling 
processor speed factor describes performance node profiling 
parameter static rum assumed largest value corresponding parameters component modules 
equivalent assuming modules identical resource needs pair modules identical module incoming intra communication sum messages sent modules 
dynamic rum refers parameters static rum vary runtime due unexpected changes input data content 
model described ffl execution factor ffl total amount intra component data factor ffl maximum intra component message size factor ffl total amount inter component data factor 
factor represents ratio static rum specifications maximum monitored value corresponding metric application specific time interval 
dynamic rum maintained ara controller monitoring data received application 
model discussion 
static rum easily extended describe needs module application component include resource types memory 
static rum ara infrastructure obtain estimate component computation communication needs 
may information information event input pattern component deadline perform resource schedulability analysis reservations 
component computation needs include execution time communication related computation 
estimated number operations total amount data transferred 
communication needs result directly model 
contrast typical real time connection models ignore intra communication burst influences memory requirements nodes network routers 
node needs may described adding memory parameter static rum network specifying maximum message size large cover maximum burst 
dynamic rum permits ara controller appropriate automatic adjustments observed resource needs larger specified application 
situation may occur static rum describe worst case needs possible estimate accurately programmer decided possibly due small likelihood runtime behavior worst case needs arise 
information needed maintain dynamic rum obtained low monitoring overhead instrumentation communication library 
related 
resource usage model introduced improves deficiencies real time task models previous research permit low complexity description parallel component :10.1.1.17.2497
models parallel application component described set tasks precedence constraints fixed computation communication needs operations occurring task event execution 
require parallel component decomposed multiple small granularity tasks leads significant increases ara decision making overheads 
ara approach advocates rum reduced levels detail low decision overheads able provide estimates application performance 
rum improves previous parallel task models load balancing task assignment problems describe communication needs time taken perform 
providing detailed description rum better estimate communication related resource needs terms multiple resource types heterogeneous environment 

adaptation model background 
adaptive application component acceptable configurations 
general overhead instantiating new configuration application independent application dependent part 
part includes overheads starting new parallel module reserving resources host network 
application dependent part henceforth adaptation overheads determined reconfiguration procedures 
assume overheads primarily due state transfers initializations significant switching configurations different levels parallelism 
model formulation 
adaptation model describes acceptable configurations corresponding adaptation overheads component event stream pair 
acceptable configuration described configuration id ara infrastructure notify application changes resource allocation static rum specifies resource needs described section adaptation overheads describe module start shut procedures 
procedure adaptation overhead described amount state transferred execution time excluding communication 
adaptation model specified application explicit request resources 
application component acceptable configurations may described 
ara assumes static configurations adaptation model compatible sense describe resource needs solving problem different configurations 
model discussion 
knowledge acceptable configurations permits automatic adjustments component resource usage negotiation 
adaptation overhead permits ara infrastructure estimate enactment overheads effects application performance 
related 
model different schemes allow application specify set acceptable configurations resource request time description adaptation overheads 
current model permit specification value particular configuration brings application 
motivated current goal ara satisfy application performance requirements concern application value 
mission level information may easily added model 

models section briefly describe rum adaptation model ara controller see section 
adaptation model dynamic rum 
application requests initial resource allocation specifying adaptation model 
ara controller receives request current resource availability chooses acceptable configuration performs corresponding reservations notifies application 
runtime component described current rum 
current static rum corresponds acceptable configuration selected allocation decision 
current dynamic rum maintained current static rum monitoring information 
performance requirements satisfied considered close acceptable threshold ara controller may decide adjust application resource allocation 
decision component static acceptable configurations scaled corresponding dynamic rum parameters 
component experiences current usage larger current static rum scaled static describe needs larger initial specifications prone better fit application current behavior 
current needs component lower specifications scaled static describe reduced needs enabling ara controller evaluate amounts unused resources providing components applications better service 
decision process adaptation overhead considered evaluating impact resource allocation satisfiability immediate performance constraints 
purpose parameter describing amount state transferred scaled dynamic rum factor memory needs 
estimation computational needs 
process making resource allocation decisions computational communication needs estimated selected static rum current dynamic rum factors 
expected computational needs expect cpu component module derived see table notations 
assumptions 
node shared multiple application components 
important restriction provided edf scheduling policy resources available 
outgoing intra communication requirements module symmetric 
true static dynamic may easily extended 
components communication cost ff fi input output operations identical 
heterogeneous communication technology intra component communication ff fi correspond costly communication link 
assumption inter component communication 
message latency wire small ignored 
formula describes expect cpu derived expected execution formula computational needs related handling expected communication intra component formulas inter component formulas communication 
expect exec dynamic exec static static exec node characteristics actual processor speed factor fixed message overhead communication link ff byte overhead communication link fi static rum parallelism level static execution time static exec total number outgoing intra communication messages static total amount outgoing intra communication data static total number outgoing inter communication messages destination static total amount outgoing inter communication data static processor speed factor static dynamic rum execution factor dynamic exec total amount intra component data factor dynamic total number outgoing intra communication messages dynamic total amount inter component data factor destination dynamic total number outgoing inter communication messages dynamic table 
notation expect dynamic static expect dynamic static expect dynamic static expect dynamic static expect cpu expect exec static gamma ff intra expect fi intra expect ff expect fi expected computational needs evaluated schedulability analysis corresponding resource information related stream inter arrival rate 
separate analysis done streams component processing 

ara performance characterization formulation suitable resource usage adaptation models contribution research 
second contribution proposal satisfiability driven approach evaluating performance ara infrastructure 
contrast optimality driven approaches past research 
context real time application claim reactivity ara infrastructure important optimality decisions 
addition ara decision instance equally important application consider appropriate measure ara performance averages large set instances 
experiments show delays adjusting resource allocation changes application behavior increase time interval application exhibiting unacceptable performance 
optimal decisions associated large decision enactment overheads decision making increases likelihood failing satisfy application timing constraints 
instance heterogeneous distributed system optimal minimization latency may require migrating application components appropriate nodes 
reallocation decision may appropriate enactment events acceptable deadlines 
focusing satisfiability application performance requirements evaluate performance ara infrastructure short ara performance response single variation application behavior increases risk violating performance requirement called critical variation 
specifically consider metrics see ffl reaction time interval occurrence critical variation completion correcting reallocation enactment bound reaction recovery enactment completion time acceptable upper performance performance metric time time laxity 
metrics ara performance ffl recovery time interval enactment completion restoration acceptable performance level ffl performance laxity difference required performance steady state performance reallocation 
ara controller expected exhibit low reaction time low recovery time large performance laxity 
metrics reflect performance ara mechanisms 
recovery time performance laxity relate quality ara reallocation decision reaction time captures effectiveness detection decision enactment mechanisms 
proposed set metrics relevant real time application 
large reaction recovery times increase time interval application performance constraints satisfied 
low performance laxity increases risk failing satisfy constraints 
experiments section demonstrate relevance reaction time metric 
metrics listed completely describe ara performance 
specifically performance laxity measure transitory effects reallocation reaction time recovery time reflect steady state improvements 
addition trade offs exist focusing performance laxity vs reaction time 
optimal performance laxity may result reaction times exceed acceptable delays due high decision enactment overheads 
interested characterizing ara performance long interval time reaction time recovery time may estimated maximum values performance laxity minimum value instances critical variations 
interesting issue ara infrastructure performance necessity automatic adjustments 
perturbation induced application unnecessary adjustment increases risk failing meet performance constraints 
assess necessity adjustment requires knowledge evolution system typically available 
instance singular spike cpu needs trigger increase cpu resource allocation corresponding component 
include set metric capturing necessity consider designing ara mechanisms primarily related detection state assessment 
related 
previous studies considering automatic ara adjustments real time applications interested steady state usually seeking attain optimal performance 
mechanisms goal maximize value system equivalent optimizing steady state performance 
proposes algorithms optimal resource allocation decisions trade optimality short decision times 
evaluates ara performance loss application performance respect performance enabled ideal ara infrastructure instantaneous detection optimal decision overheads 
contrast submit satisfying application performance requirements important achieving optimal application performance 

factors ara reaction time section consider detection reallocation decision mechanisms show design affect reactivity ara controller consequently satisfiability application performance requirements 
addition experiments show reaction time important performance metric improved ara reaction time implies improved application performance 
experimental results reported study obtained synthetic distributed application designed honeywell context high performance applications 
application performs cluster eleven ultrasparc model workstations mpi interface mbit switched ethernet links 
application consists multiple communicating components connected acyclic graph communication links 
component adapt execution span number processors 
share nodes node executing program 
component module executes steps receive message module component immediate predecessors execute computation intra communication pattern specific component send message module component immediate successors 
sink source 
synthetic application example experiments synthetic application pipeline configuration see 
events type 
produced periodically source consumed sink processed intermediate components 
component step consists exchanging message modules component computing amount time depends component parallelism level speedup coefficient exchanging messages 
stochastic model emulate step data dependent variation computation communication needs 
enactment performed event boundaries 
moment performing resource exchanges determined state closest predecessor components participating resource exchange component release request resources completing event completed coordinating predecessor 
method minimizes enactment overhead requires synchronization resource donors receivers components communicate 
context synthetic application adaptation overhead small identical components 
acceptable limit particular performance metric upper bound derived corresponding performance constraint 
experiments acceptable burst set 
detection signal triggers automatic adjustment 

detection section address effects detection method ara performance 
respect detection method evaluated soon occurrence critical variation signaled trustworthiness ratio signaled variations critical 
prompt detector implies rapid detection low ara reaction time 
detector trustworthiness related necessity allocation adjustment detector lower likelihood making unnecessary adjustment 
latency secs event id effects early detection acceptable limit detection enactment component approach direct approach 
effects metric evaluation method early detection requires prompt detector 
order observe impact early detection experiment methods latency evaluation 
method called direct approach uses observed value metric second method called component approach uses value predicted execution times component event critical path 
second method characterized higher sampling rate monitoring information received component interest compared method sampling occurs component path completed event processing 
difference results component approach direct approach 
addition difference particularly significant event path long terms latency critical variation occurs early path 
experiment component execution time increases component approach enables better performance due shorter reaction times 
detector component prediction performance metric interest decomposed independent metrics 
method enables higher sampling rate consequently increased likelihood early detection effectiveness depends accuracy application models detector observed values independent application models integrated ara controller 
latency secs event id effects detection technique latency acceptable limit unnecessary detection sobel detection variation driven threshold driven 
vs trustworthiness important trustworthiness performance constraints violated 
order understand effects trustworthy detector experiment detectors see threshold driven detector checks current sample metric interest acceptable limit variation driven detector checks significant variation metric interest occured 
variation driven detector similar sobel detector edge detection computer vision 
detector threshold detector employs smoothing techniques eliminate effect noise uses range samples sample interest 
unfortunately techniques result poor 
threshold driven detector hand prompt untrustworthy sensitive noise 
benefit prompt detection demonstrated shows see event id number events failing latency constraint larger variation driven detector smoothing size sample range size 
hand trustworthy detector detect changes application behavior immediately cause performance constraints violated increase risk situation 
experiment change execution time causes latency get acceptable limit see event id signaled variation driven detector triggers reallocation reduces latency acceptable threshold 
threshold driven detector detecting similar changes distinguish spike steady variation 

reallocation decisions section address effects considering enactment overheads application state specific incremental heuristics ara decision making 
latency secs event id effects enactment overhead acceptable limit detection sph enactment enactment sph 
influence enactment overhead reallocation heuristics aware enactment overheads result improved performance 
depicts latency variation decision heuristics distinct awareness enactment overheads single pair heuristic sph tries accommodate critical variation node involving components result lower enactment overhead involving components 
second fair decrease heuristic ignores enactment overhead uses involving multiple components tries fair reducing number nodes available different application components 
accommodate increase component computation needs see sph decides node transfer component decides node transfer components heuristics lead similar steady state performance 
enactment overhead msecs larger sph msecs 
number events failing latency requirements larger heuristic accounting enactment overhead 
application state driven incremental decisions reduce reaction time 
incremental decisions improve ara performance take advantage current resource allocation 
show combining incremental decision algorithms heuristics aware current application state permits achieve better performance compared scratch state independent methods 
experiment simple incremental decision algorithm repetitively selects pairs potential receiver donor components tests performance metric constraints improved node transfer 
time taken produce acceptable reallocation depends order components selected effectiveness ordering criterion varies state application 
experiment ordering criteria current execution time ce expected execution time variation reallocation ev 
ce ranks component current execution time donors increasing order receivers decreasing order 
ev ranks donors increasing order expected increase execution time may occur releasing node receivers decreasing order expected reduction execution time may occur assigned node 
criteria decide reallocation decisions types application states rate critical latency critical state 
rate critical state primary goal reallocation reduce maximum execution time system 
receiver bottleneck component largest execution time donor may component provided resulting maximum execution time satisfies acceptable event rate constraints 
ce ordering helps focus immediately components highest lowest execution times 
experiment acceptable pair ce ordering testing receiver donor pair msecs ev ordering testing pairs msecs 
note experiment takes approx 
msecs test pair rest reported time spent ara mechanisms parts decision procedure 
expect overhead test pair larger complex application structures timing requirements complex latency maximum achievable event rate considered 
latency critical situation primary goal improve sum execution times components event critical path 
best solution attainable reallocation involving components low enactment select receiver component expected largest reduction execution time donor component expected lowest increase execution time 
pair selected ev ordering 
experiment acceptable pair ev ordering testing pair msecs ce ordering testing pairs msecs 
ordering criteria experimented enable minimal decision overhead different system state 
latency secs event id effects predicted variation acceptable limit execution time detection enactment variation ramp prediction prediction 
effects deciding predicted performance short term prediction resource needs improves effectiveness decisions 
method improving performance ara decisions consider short term application specific prediction 
approach permits reallocation decisions better fit application needs completion enactment 
consider instance ramp increase computation needs see 
able predict computation needs transition period enables decision mechanisms predicted value intermediary ones 
shows difference performance reallocation observed needs increased conservative estimation computation needs increase reallocation correct prediction ramp variation 
prediction allows eliminate reallocation improving stability system 
experiment 
summarize experiments show ara performance improved considering application characteristics current state choosing methods detection allocation decision 
addition application specific prediction combined information provided dynamic permits better accommodate needs application 

contributions considers problem adaptive resource allocation ara high performance real time applications executing dynamic environments 
applications consist multiple parallel tasks data dependent resource needs 
contributions ffl application resource usage model captures characteristics parallel real time tasks required making reallocation decisions situations observed performance larger specified values 
ffl adaptation model enabling automatic resource allocation adjustments ability evaluate enactment overheads 
ffl experimental demonstration importance focusing response time resource allocation mechanisms optimality decisions real time constraints satisfied 
ffl novel set performance metrics evaluating ara performance focuses satisfiability application timing constraints 
metrics reaction time recovery time performance laxity 
ffl identification factors related detection decision mechanisms influence satisfiability application timing constraints 
factors early detection enactment overhead application state driven incremental decision heuristics prediction 
models heuristics proved useful context processor reallocation adaptive synthetic application designed represent time critical applications systems 
plan apply types adaptive applications including complex distributed computer vision application 
plan integrate insights mechanisms broader framework resource management destined systems multiple real time applications coexist ara mechanisms described conjunction online negotiation mechanisms 
abdelzaher atkins shin 
qos negotiation real time systems application automated flight control 
real time technology applications symposium 
ferrari 
tenet real time protocol suite design implementation experiences 
ieee acm transactions networking vol feb 
bestavros 
load profiling distributed real time systems 
journal information sciences 
schwan 
comparison adaptation algorithms increasing reliability real time software 
real time systems symposium 
schwan 
dynamic adaptation real time software 
acm transactions computer systems may 

partitioning problems parallel pipelined distributed computing 
ieee transactions computers jan 
brooks 
robust layered control system mobile robot 
ieee journal robotics jan 
canny 
computational approach edge detection 
ieee transactions pattern analysis machine intelligence nov 

chang shin 
optimal load sharing distributed real time systems 
journal parallel distributed computing pp 
chatterjee 
distributed pipeline scheduling analysis heterogeneous multi resource real time systems th international conference distributed computing systems 
cheng hwang agrawala 
schedulability oriented replication periodic tasks distributed real time systems 
th international conference distributed computing systems 
eager lazowska zahorjan 
efficiency parallel systems 
ieee transactions computers mar 
eager lazowska zahorjan 
adaptive load sharing systems 
ieee transactions software engineering may 
schroeder schwan martin vetter 
high performance communication distributed laboratories 
th international conference parallel distributed computing systems oct 
huang 
wan 
supporting mission critical multimedia applications 
rd ieee international conference multimedia computing systems 
jeffay bennett 
rate execution abstraction multimedia computing 
th international workshop 

automated meta control adaptable real time software 
real time systems journal appear 
jha schwan rosu 
adaptive resource allocation embedded parallel applications 
rd int 
conference high performance computing 
jones leach draves barrera 
modular real time resource management operating system 
th workshop hot topics operating systems pages may 
jones rosu rosu 
cpu reservations time constraints efficient predictable scheduling independent activities 
th acm symposium operating systems principles 

kang gerber 
performance design distributed real time systems 
ieee real time technology applications symposium jun 
liu 
lin 
shih 
algorithms scheduling imprecise computations 
ieee computer vol pages may 
marzullo wood 
making real time reactive systems reliable 
th european sigops workshop 
mccann zahorjan 
processor allocation policies message passing parallel computers 
acm sigmetrics 
mercer savage tokuda 
processor multimedia operating systems 
ieee int 
conference multimedia computing systems 
metzger jha au amin kumar 
parallel benchmark suite preliminary results 
supercomputing 
watson 
real time system scenarios 
real time systems symposium 
nicol reynolds 
optimal dynamic remapping data parallel computations 
ieee transactions computers feb 

park 
dynamic partitioning multiprocessor systems 
international journal parallel programming 
sevcik 
benefits memory constrained multiprocessor scheduling 
performance evaluation review 
ramamritham stankovic 
dynamic task scheduling hard real time distributed systems 
ieee software vol 
jul 
rosu schwan 
improving protocol performance dynamic control communication resources 
nd ieee international conference engineering complex computer systems 
:10.1.1.45.5226
decentralized decision making adaptive task sharing 
nd ieee symposium parallel distributed processing 
schwan weide 
high performance operation system primitives robotics real time control systems 
th symposium reliability distributed software 
sevcik 
characterization parallelism applications scheduling 
performance evaluation review vol 
may 
stankovic 
integrate precedence constraints shared resources real time scheduling 
ieee transactions computers vol 
pages dec 
tucker gupta 
process control scheduling issues multiprogrammed shared memory 
th acm symposium operating systems principles 
volz mudge gal 
ada programming language robot manufacturing cells 
ieee transactions systems jun 
zhou schwan akyildiz 
performance effects information sharing distributed multiprocessor real time scheduler 
real time systems symposium 
