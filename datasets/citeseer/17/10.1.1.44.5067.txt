image recognition gaze direction adaptive methods axel christian robert rae ritter ag neuroinformatik technische fakultat universitat bielefeld postfach bielefeld uni bielefeld de 
human machine interfaces gaze recognition greatly simplify handling computer applications 
existing systems problems changing environments different users 
solution adaptive components trained online ii detect common facial features eyes nose mouth gaze recognition 
step adaptive color histogram segmentation method roughly determines region interest including user face 
region hierarchical recognition approach detect facial features 
stage system feature positions estimate gaze direction detailed analysis eye region 
achieve average precision ffi gaze pan ffi tilt angle user looks computer screen 
system runs rate frame second common workstation 
motivation years computer graphics performance increased rapidly 
today possible visually explore multi dimensional data landscapes interactively computer screen 
unfortunately modern input devices mice space mice hardware solutions intuitive convenient fulfill demand easy systems 
gesture interfaces may key interaction factor human computer interface design facilitate usage complex software advanced graphics visualization tools 
evaluation head eye actions significantly contribute realization powerful easier man machine interfaces 
existing eye tracking hardware unpleasant wear expensive designed highly precise results 
situations interested estimating approximate gaze direction user controlling basic graphical actions zooming rotating translating object 
view objects computer screen different perspectives changing gaze point 
correspondence sent 
interesting application eye tracking system control graphical user interfaces gui 
different ways implement system respect user capabilities eye movements input common guis implementing special designed eye user interfaces 
eye tracker satisfy demands eye interface see problems eye movements input stream control see discussion 
simple applications show technical performance system 
today multimedia computers equipped video conferencing camera frame grabber computer vision implement gaze tracking system 
aim developing system determines gaze direction depending head eye orientation 
previous subject shown challenging task changing lighting conditions different users limited computing resources 
authors working subject report problems 
previous system strongly user dependent want overcome limitation common facial features eyes nose mouth addition holistic information head posture gaze recognition 
system architecture hardware setup system consists sgi workstation indigo high impact frame grabber indigo video active camera sony built tracking function 
camera pan tilt video camera image processing technology 
provides possibility keep moving target objects certain size constantly field view 
tracking process color cues 
camera placed computer screen advantage eyes nostrils clearly visible see fig 

fig 

hardware setup modules recognition approach 
module identifies location user face skin color segmentation sec 

face region seek conspicuous facial features nose mouth eyes sec 

second module hierarchical neural network architecture works user independent 
third module uses features compute head orientation estimate gaze direction detailed analysis eye region sec 

module user dependent neural network adapted new users fast online training procedure 
face tracker active camera built tracking mechanism allows keep user head image moves outside field view 
tracking process camera keep face exactly middle image need precise localization approach 
exact face region image detected passive tracking module combines color segmented image movement information 
enclosing rectangle face calculated fast cluster algorithm 
determine face region intensify skin colored pixels 
required color classification carried accumulating color values correspond different faces general color map details see 
entries general color map normalized values 
session copy general color map automatically adapted actual face color near estimated nose position 
done decreasing entries certain factor ii setting entries nose region initial general color map 
fig 
shows example sequence image intensification adapting color map 
bright pixels correspond high values color map represent skin colored regions 
process intensification starts unspecific general color map background pixels classified skin color 
steps color map adapted face clearly segmented background 
adaptation process restarts problem occurs detecting proper face region 
fig 

adaptation color map image sequence 
facial feature detection human head postures differ extremely features reliably identified wide range viewing angles 
suitable facial features nose mouth eyes 
specialized neural nets local linear map type see find correct position eyes nose 
locations nets verified networks 
image region correspond facial feature new image taken processing starts 
fig 
shows structure facial feature detection stage 
step eye region hierarchical approach determination gaze direction 
mouth corner positions verification nose position eye positions fig 

facial feature detection 
image feature extraction 
image feature extraction deliver low dimensional easy classify vector means robustness affine transformations changes illumination noise 
previous systems locally applied set gabor filters corresponding image region 
filters specific general image structures contrast wave length orientation edges 
main problem obtain filter parameters facilitating recognition task 
feature extraction method motivated known eigenface approach 
locally convolve set filter kernels facial regions 
filter kernels choose eigenvectors typical facial features similar different persons 
response filters represent typical characteristics facial regions applied locally achieve robust fast feature extraction 
detect eyes calculate vectors various images eyes different locations 
higher accuracy sets eye position varies smaller fine set bigger region coarse set 
fig 
shows example filter set final gaze recognition stage 
choose similar feature extraction approach nose detection locally convolving obtained various linearly scaled face regions face regions theta grid points 
results dimensional feature vector 
pixel values transformed interval fig 

gaze direction 
size theta pixels 
part feature classification task done feature extraction 
assume characteristics resulting feature vectors lead high specificity easier classification 
local linear map 
classification local linear provides efficient alternative multi layer perceptron nonlinear function approximation 
nonlinear function approximated set locally valid linear mappings details see 
matrix input space output space units fig 

architecture llm network dimensional input vector output vector ir net gamma winner node ng number nodes 
input output weight vectors node respectively 
theta jacobian matrix belongs best match node min kx gamma llm net trained supervised learning scheme ff examples adaptation equations deltaw ffl ff gamma deltaw ffl gamma ff gamma net delta delta deltaw deltaa ffl gamma delta gamma gamma ff gamma net delta ff gamma ffl ffl ffl adaption step sizes 
nose detection 
nose reliable feature detect 
visible due camera position screen 
near center face region search nostrils 
choose approach fig 

red channel nostrils brighter regions face 
additionally gray value low compared parts face region 
doing achieve nose detection rate test images 
fig 

nose detection method 
original image 
red channel image 
product red channel inverse gray channel 
pyramid multiplied cluster center 
product theta region interest extracted 
remaining mismatches determine nose position iterative correction scheme neural networks 
networks trained estimate position nose differently sized image regions 
starting center face cluster network estimates rough correction dimensional feature vector described 
new point second network improves position 
third net determines position nose fig 

fig 

nose position improvement starting theta grid points 
llm network output positions connected starting points lines 
improvement net left nets center nets consecutively right 
tests show average localization error pixels pixels direction network sequence 
resulting normalized root mean square error nrmse respectively 
test results include estimated positions wrong positions rejected verification scheme 
verification position form information position color brightness information verification position form information llm networks improve position precisely determine gaze direction search mouth eyes read new image llm net fig 

nose detection 
verification nose position done examining image structure nose region applying specially trained nose recognition network fig 

input features net scalar products estimated nose region 
tests verification network show classification rate test images different users different lighting conditions 
improve recognition rate additionally look typical intensity characteristics nose dark nostrils surrounded brighter regions 
modules accept position nose region features searched image rejected 
nose position landmark greatly simplifies detection remaining facial features mouth eyes focus processing small subregion entire image 
mouth detection 
features mouth corners searched subsampled region interest theta nose 
simple filter kernels convolved region obtained green channel see fig 

highest values result image taken mouth corners 
fig 

cells filter kernels theta detection mouth corner right left corner left center 
typical mouth region green channel right resolution face theta pixels 
method described normally works problems occur mouth open deformed 
accuracy achieved far sufficient estimating eye location mouth nose positions 
eye detection 
positions nose mouth corners provide initial guess eye coordinates 
choose approach similar nose detection 
eye detection done neural networks trained regions different size fig 
left 
network calculates rough position refined second specialized network 
results obtained approach visualized fig 
center right 
fig 

training regions eye networks left 
improvement eye position applying llm network starting theta grid points center second llm network right 
including distance vector nose estimated eye position feature set reduce error 
fig 
left visualizes system error theta responses 
fig 
right shows reduced error additionally distance vector 
table compares errors coarse fine llm network 
shows refinement pixels direction networks distance vector 
eye verification network similar nose verification appended 
feature vector llm network consists scalar products estimated image region theta pixels vectors 
network wrongly rejects correct eyes accepts tex try llm number knots nrmse tex try llm number knots fig 

error eye position theta eigenvectors left distance nose actual estimated eye position additionally right 
training error try training error tex test error test error incorrect eye positions means recognition rate approximately 
eye positions high reliability processing eye direction 
table 
error reduction additionally activating fine eye network 
networks consist llm nodes 
llm nets mode nrmse rmse nrmse rmse coarse test coarse fine test additionally check constellation nose mouth corners eyes sensible 
constellation facial features encodes head orientation 
fig 
shows tracking eye nose mouth corners head movement sequence front background containing high contrasts 
seen final target points accurately located upper row pictures images depicted user included training data sets various networks system 
lower row pictures shows critical issues occlusion nose eyes determined correctly ii occlusion verification detects mismatch image accepted iii red object disturbing nose detection nose accepted iv time neural network iteration scheme improves nose position 
recognition gaze direction integrate head eye orientation determine gaze direction user 
know eye positions cut eyes step see fig 

images representing eyes cornea provide input llm net specialized estimating gaze direction 
fig 

top row facial feature detection image sequence user included training process 
rectangles mark face cluster evaluated face tracker 
bottom row response partial occlusions left presence distractors right 
feature vector generated approach 
head posture included feature vector nose eye distance vectors 
net output gives gaze direction 
information available control cursor movements computer screen 
fig 

typical eye region extracted camera image 
previous results indicated possible determine gaze direction restrictions 
gaze recognition stage user dependent special training different lighting conditions users necessary 
drastically increasing training material possible active camera 
additionally lamp produce specular highlight user eye 
authors described solution useful better recognition results 
specular highlight center region interest theta pixels exactly eye see fig 

feature extraction set see fig 
nose eye vectors results dimensional feature vector llm network 
network nodes trained examples representing gaze directions user fixating theta grid computer screen 
tests slightly different image set user fixating grid images 
system average test er ror pixels nrmse direction pixels nrmse direction 
corresponds angular error ffi ffi respectively 
tests shown llm network trained theta different gaze directions able generalize theta directions see fig 

llm network easily adapted actual user slightly changed lighting conditions fixating just positions screen 
test example correct position net response test example correct position net response fig 

applying gaze net trained theta directions test samples theta net left coordinates right coordinates 
fig 
show usability system real world scenario 
user sits front monitor draws shape house gaze control 
precision achieved far insufficient tiny control elements buttons window selection 
tested system graphic system showing object different perspectives controlled user gaze direction 
fig 

houses drawn screen changing gaze directions 
finishing house gaze remains point 
pattern left copies drawn gaze center right theta pixels 
system works frame rate frame second currently slow compared head mounted eye trackers 
implemented real time system facial feature detection 
user eye remain region interest head movements permitted 
results fast system frames second evaluate small region interest 
accuracy decreases difficult remain region interest demonstrates usability systems including facial feature detection frame rate 
summary outlook combining approach described architecture substantial number specialized recognition networks results verified additional stage achieve high robustness recognition accuracy entire system 
demonstrated important effect correction stage estimation nose eye position 
quantitative statistical evaluation tracking accuracy indicates described system track eye mouth nose features quite reliably generalizes previously unseen users 
implemented facial feature tracking system currently contains recognition networks 
may fairly high number evaluation network mapping computationally processing time frame grabbing preprocessing 
training done moderate computational resources llm networks trained significantly faster multi layer perceptrons 
accurate tracking facial features provides robust reliable low dimensional features llm network estimating head orientation 
determine absolute gaze direction eye region analyzed network feature vectors 
result gaze recognition system average error ffi gaze pan angle ffi tilt angle user looks computer screen 
stage system user lighting dependent easily adapted new situations 
approaches gaze recognition geometric models human face 
implies common face geometry different users hard deal variable camera parameters 
furthermore model approach sufficient recognition head orientation exact eye direction 
hand holistic features color eye image regions precise robust 
approach combines geometry facial features ii holistic information eye region 
subtasks neural networks adapted new users environments 
results robust precise fast video gaze recognition system 
shown system works real world conditions achieves frame rate image second 
plan extensions system robust intrusive 
main drawbacks existing eye tracking system lamp eye 
order attain convenient usability plan implement network centers eye region fitting ellipse iris 
address problem head position invariance want include active camera gaze recognition stage 
requires gather training examples user face 
achieve fast training procedure online re calibration improved 
important step robustness context information past images include prediction scheme 
described ideas hopefully possible control applications eye movements lead natural convenient human machine interface 
baluja pomerleau non intrusive gaze tracking artificial neural networks 
advances neural information processing systems nips ed 
cowan tesauro alspector morgan kaufmann publishers san francisco ca 
keeping eye interface potential eye control graphical user interfaces 
proceedings hci cambridge university press august 
jacob eye tracking advanced interface design 
virtual environments advanced interface design ed 
barfield oxford university press new york usa third edition pages 
ritter mittels 
informatik ed 
springer verlag berlin heidelberg pages 
schiele waibel gaze tracking face color 
int 
workshop automatic face gesture recognition zurich switzerland june 
gee cipolla determining gaze faces images 
image vision computing volume number december butterworth heinemann pages 
ballard controlling computer facial aspect 
ieee trans 
systems man cybernetics vol 
april pages 
yacoob davis computing head orientation monocular image sequence 
proceedings nd intl 
conf 
automatic face gesture recognition killington vermont usa 
von mit 
phd thesis universitat bielefeld technische fakultat september 
turk pentland eigenfaces recognition 
journal cognitive neuroscience vol 
pages 
pentland moghaddam starner turk view modular eigenspaces face recognition 
proc 
ieee computer soc 
conf 
computer vision patt 
recog pages 
ritter learning self organizing map 
artificial neural networks vol 
pages 
rae ritter facial feature detection neural networks 
proceedings international conference artificial neural networks pages 
