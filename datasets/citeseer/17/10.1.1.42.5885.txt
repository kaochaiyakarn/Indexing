proceeding th annual international symposium microarchitecture nov dec ann arbor mi dynamic rescheduling technique object code compatibility vliw architectures thomas conte department electrical computer engineering north carolina state university raleigh north carolina lack object code compatibility vliw architectures severe limit adoption generalpurpose computing paradigm 
previous approaches include hardware software techniques drawbacks 
hardware techniques add complexity architecture software techniques require multiple executables 
presents technique called dynamic rescheduling applies software techniques dynamically intervention operating system 
results demonstrate viability technique illinois impact compiler tinker architectural framework 
lack object code compatibility generations vliw architecture raised objection general purpose computing paradigm 
program binary compiled vliw generation guaranteed execute correctly generations gamma reasonable value means installed software base binaries built family vliw generations 
economic implications problem enormous efficient solution necessary vliw architectures succeed 
classes approaches problem reported literature hardware approaches software approaches 
hardware approaches include split issue proposed rau fill unit proposed melvin patt extended franklin 
techniques provide compatibility expense hardware complexity potentially impact cycle time 
typical software approach statically recompile vliw program object file 
approach requires generation multiple executables poses difficulties commercial copy protection system administration 
proposes new scheme called dynamic rescheduling achieve object code compatibility vliw generations 
dynamic rescheduling applies limited version software scheduling time page faults requiring additional hardware support 
making practical requires support compiler isa operating system fast algorithm rescheduling 
topics discussed detail 
results suggest dynamic rescheduling potential effectively solve compatibility problem vliw architectures 
vliw compatibility problem addr ld st cycle latency cycle latency ialu ialu mul cycle latency cycle latency cycle latency scheduled code original vliw machine 
compatibility problem illustrated example 
shows example vliw schedule machine integer alus page unit multiply load store 
latencies units shown 
assume represents generation machine 
shows generation vliw multiply load latencies changed cycles respectively 
old schedule guaranteed execute correctly machine due flow dependence operations addr ld st ready cycle latency cycle latency ialu ialu mul ready ready cycle latency cycle latency cycle latency vliw machine incompatibility due changes functional unit latencies shown arrows 
old latencies shown parentheses 
operations produce incorrect results new latencies operations shows schedule machine includes additional multiplier 
latencies fus remain shown 
code scheduled new machine execute correctly older machines scheduler moved operations order take advantage additional multiplier 
particular operations moved 
trivial way adapt schedule older machines 
case downward incompatibility generations 
situation different generations machines share binaries file server compatibility requires mechanism adjust schedule different set binaries generation 
scheme guarantee correct execution vliw binary generation machine suffice solve compatibility problem 
solution efficient order viable 
implemented addr ld st ready cycle latency cycle latency ialu ialu mul ready cycle latency cycle latency cycle latency mul ready cycle latency downward incompatibility due change vliw machine organization trivial way translate new schedule older machine 
generation ensure upward compatibility generations 
organization remainder follows 
section describes relevant terminology previous done area 
dynamic rescheduling technique described detail section 
section presents experimental evaluation technique 
ends concluding remarks section 
related terminology terminology originally rau introduced discussion follows 
vliw architectures horizontal machines wide instruction word consisting operations ops 
ops issued execution cycle 
vliw programs latency cognizant meaning scheduled knowledge functional unit latencies 
vliw architecture runs programs termed non unit assumed latency architecture 
unit assumed latency ual architecture assumes unit latencies functional units 
superscalar architectures ual 
scheduling models programs equals model lessthan equals lte model 
equals model schedules vliw architecture eration takes exactly specified execution latency 
contrast lte model schedules assuming operation may take equal specified latency 
equals model produces slightly shorter schedules lte model mainly due register reuse 
lte model simplifies implementation precise interrupts provides binary compatibility latencies reduced 
scheduler back compiler dynamic follow lte scheduling model 
previous working principle hardware techniques support object code compatibility vliw machines shown 
similar perform run time scheduling hardware 
difference schedule superscalar dynamic scheduling hardware ual scheduling hardware dynamically scheduled vliw processor schedule 
scheduled code old architecture parallel execution run time run time dynamically reschedule hardware hardware approach compatibility 
rau hardware technique called split issue dynamic scheduling vliw processors 
order handle programs provides hardware capable splitting op op pair read execute destination writeback 
read execute uses anonymous register destination destination writeback copies destination read execute destination specified original op 
read execute operation issued available cycle provided dependence resource constraints 
destination writeback operation scheduled issued latest cycle issue cycle read execute original operation latency gamma 
ensure destination writeback operation issued read execute completes support form hardware flags provided 
splitting operations issuing correct time order preserves program semantics correct program execution guaranteed 
concept fill unit originally proposed melvin patt extended 
originally aimed achieving compatibility adapted fulfill goal 
special hardware consisting shadow cache technique 
works follows processor routinely executes ual program operation stream 
concurrent execution fill unit compacts operations vliw 
newly formed stored shadow cache 
operation requested fetch unit available shadow cache operations containing operation issued 
formation new fill unit terminated branch instruction encountered 
limitation hardware approaches scope scheduling limited window ops seen run time available ilp relatively exploited compiler 
schemes may result cycle time stretch phenomenon due considering vliw paradigm superscalar generation machines 
static recompilation prevalent software technique illustrated 
entire program line take advantage sophisticated compiler optimizations attain superior performance 
alternatively complete recompilation program may avoided maintaining multiple copies program various target architectures partitioned object file 
appropriate module scheduled installation time 
main drawback methods involve extra step achieve code compatibility 
introduces deviation normal development process developer routine installation process user 
related issue potential copy protection violations 
software licensing done copy basis having multiple specialized copies program user plans machine may expensive proposition 
problem storage space parallel execution run time run time statically reschedule compile scheduled code old architecture rescheduling program line compatibility 
ments multiple copies may excessive 
problems suggest compatibility line recompilation may easy 
related interest techniques migrate software new machine architecture 
ebcioglu describe detail effort gain performance advantage translating running old cisc object code risc superscalar vliw machines 
binary translation digital equipment migrate vax vms environment newer alpha architecture documented 
apple computers technique emulation migrate software compiled motorola powerpc 
insignia solutions effort emulating intel architectures modern risc machines 
short survey related techniques issues 
dynamic rescheduling dynamic rescheduling illustrated 
program executed machine generation scheduled dynamic invoked 
exact sequence events follows os loader reads program binary header detects generation mismatch 
page program loaded execution page fault handler invokes dynamic module 
page version information retained part process table entry process 
parallel execution run time run time dynamically reschedule software time page fault scheduled code old architecture dynamic rescheduling 
execution current host 
process repeated time new page fault occurs 
translated pages saved swap space replacement 
pages executed life span program rescheduled 
knowledge architectural details executable vliw generation necessary dynamic operate retained executable image 
dynamic rescheduling poses interesting problems reduce effectiveness run time technique 
rest section discusses problems detail presents solutions 
assumes code scheduled vliw machine logically organized sequence scheduling structures called superblocks hyperblocks 
construction superblocks hyperblocks shown figures respectively 
implementation dynamic rescheduling algorithm uses tinker architecture 
tinker parametric vliw architecture hewlett packard laboratories 
features tinker designed specifically solve problems faced dynamic rescheduling 
example tinker provides block bit op mark entry point merge point hyperblock superblock 
information define scope rescheduling 
examples section 
discussions follow acyclic scheduled code considered 
software pipelining incompatible techniques detailed discussion dynamic rescheduling software pipelined loops scope 
page br br br br br counts profile data example superblock formation 
note superblocks hyperblocks single entry multiple exits side entrances 
general hyperblocks provide larger scope ilp superblocks 
br br set br example hyperblock formation 
problems solutions changes code size dynamic rescheduling algorithm constructs new schedule old schedule knowledge old new machine organizations execution latencies functional units 
new schedule may grow larger size due insertion empty cycles may shrink size due deletion empty cycles old schedule 
insertion deletion empty cycles introduces variation code size 
phenomenon illustrated assumes simple machines having integer alu ialu fp add fp multiply load store branch predicate comparison units 
op assumed bytes wide 
number nops upper left ialu ialu load store br nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop load latency increases ialu dependent takes cycles bytes total load store br nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop nop ialu nop nop nop nop nop nop nop nop nop nop nop nop nop nop bytes total extra nops page size change due ops 
sample schedule 
code rescheduled machine having ialu increased load latency number nops rescheduled code resulting code size increase gamma bytes 
example illustrates change size program cause overflow underflow page boundary 
easy practical handle changes page boundaries run time 
changes code size due rescheduling avoided 
problem solved efficient encoding provided tinker see 
fields tinker op header bit pause 
op header bit signifies new called header op 
indicates type functional unit op execute bypassing need nops 
pause field header op encodes number empty cycles follow current 
meaning attached value pause non header op 
op encoding tinker hides nops ensures code rescheduling basic block trigger code size changes 
shows rescheduled code previously shown encoded page original code header bit pause rescheduled code example tinker encoding scheme 
op fixed format bit word 
format includes header bit pause fields eliminate need nops code 
tinker 
noted size code changed nops squeezed field empty cycles squeezed pause field 
code size remains bytes total machines 
speculative code motion problems introduced speculative code motion rescheduling illustrated example 
problem caused incorrect execution code due target invalidation 
example op target branch code 
ops speculatively moved branch beq originally op motion invalidates target incoming branch 
second problem caused code may necessary undo effects code motion 
example outgoing branch beq taken effects speculating ops may need undone inserting code target branch 
target may lie page turn may memory resident 
target lies current page code insertion cause overflow code page boundary 
reasons generation beq beq branch target invalid page page may need code undo effects problems problems introduced speculative code motion 
code avoided rescheduling 
solve problem dynamic rescheduling algorithm takes advantage property superblocks hyperblocks unique entry point top block side entrances merge points 
superblock hyperblock page rescheduled individually 
compiler page size cognizant forms hyperblocks superblocks guaranteeing span page boundaries 
speculation happen outside superblock hyperblock branch target invalidation eliminated 
second problem solved performing speculation initial compilation confining rescheduling basic blocks speculation rescheduling 
limit opportunity expose ilp parallel vliw architecture 
dynamic rescheduling performs limited speculation requires code 
support compiler saves live set info branch program object file see section 
rescheduling detects op modifies register live set branch cancels move 
op modifying member live set moved require generation code 
register file changes better hardware implementation techniques allow registers advanced eration providing opportunity reduce register pressure 
traditional allow change register file size isa interesting consider possibility 
perspective dynamic rescheduling technique change poses additional problems 
code rescheduled machine different register file architecture perform register re allocation 
spill code generated process causing increase code size 
violate requirement page size change run time 
dynamic rescheduling algorithm currently assumes register file architecture change generations 
additional object file information review information included object file support dynamic rescheduling 
version vliw architecture code scheduled encoded header object file information architecture number latency functional unit type 
block boundaries hyperblocks superblocks marked hyperblock bit ops 
live register sets branch code included allowed perform speculative code motion code hazard 
live sets organized non loadable segment object file interfere layout code data segments 
live segment read needed 
increase size object file due live sets concern especially program known contain large number branch instructions 
address concern table presents live set sizes measured branch instructions benchmarks 
benchmark minimum maximum live set sizes shown 
clever encoding efficiently store information object file 
live set small byte encoded register list constructed 
set large bit vector encoding 
dynamic rescheduling algorithm withstand changes register file architecture limited way 
increase number registers change compiler subroutine calling conventions handled algorithm generation spill code 
true programs originally scheduled machine smaller register file rescheduled machine larger register file vice versa 
table live set sizes branches various benchmarks 
liveout set size benchmark branches min max average cccp compress eqn eqntott espresso lex tbl wc yacc average operating system support pieces mechanism invokes dynamic scheduling algorithm constitute os support technique 
mentioned earlier section example detection machine generation mismatch os loader invocation dynamic page fault handler time page faults machine architecture database maintained os tables 
part os plays crucial role file system buffer cache 
buffer cache routinely holds pages past 
standard mechanism available modern operating systems directly helps amortize cost rescheduling time page accesses 
penalty rescheduling incurred page access life span program 
dynamic rescheduling algorithm section briefly describes core dynamic rescheduling algorithm 
adapted simulation algorithm order execution processors described 
assumed vliw program latency cognizant 
algorithm full knowledge functional unit latencies original machine called old machine machine program rescheduled called new machine 
old machine new machine assumed lte equals machines 
main data structures keep track data dependencies ops scoreboard registers helps determine flow output dependencies register usage matrix keeps track anti dependencies 
resource constraints page handled resource usage matrix 
memory accesses modeled accesses single loads stores source sink register respectively 
ensures relative ordering altered rescheduling 
pass implementation rescheduling follows 
step build dependence graph hyperblock consideration 
second step perform list scheduling 
approach slow suitable line compatibility 
dynamic rescheduling takes single pass approach implicitly builds dependence information scoreboard register usage matrix schedules ops knowledge fu latencies 
main control structure algorithm shown appendix 
experimental evaluation methodology set benchmarks evaluation dynamic rescheduling shown table 
benchmarks specint suite compress espresso eqntott unix text processing utilities tbl eqn development tools lex yacc language processor cccp 
set benchmarks chosen represents typical non numeric workloads various 
benchmarks spec represent workloads commonly today industry characterize compare performance machines 
table benchmarks evaluation 
benchmark description cccp pre processor eqn equation formatter lex scanner generator yacc parser generator tbl table formatter compress compression decompression utility eqntott truth table generator logic circuits espresso pla optimization tinker machine models termed tinker evaluation 
results floating point benchmarks implement rescheduling software pipelined loops 
comparing dynamic rescheduling results unfair case comparison performance scheduling acyclic code 
tinker model functional units represents hypothetical generation vliw architecture 
organization fu latencies shown table 
table shows organization fu latencies tinker 
difficult draw direct comparisons tinker roughly equivalent issue order execution superscalar due ialu units 
similarly tinker roughly equivalent issue superscalar 
table tinker machine model 
fu number units fu latency integer alu load store branch fp add fp mul predicate unit table tinker machine model 
fu number units fu latency integer alu load store branch fp add fp mul predicate unit dynamic rescheduling algorithm implemented tool called october 
october designed interact impact framework university illinois 
impact frontend compiles benchmarks profiles optimizes code hyperblock formation presents code october suitable intermediate format 
part method order evaluate dynamic rescheduling technique described follows 
part intermediate code benchmark scheduled machine model tinker tinker tinker scheduler 
profiled order find worst case estimate execution time benchmark terms number cycles 
called native mode execution program 
experiment measured number unique page accesses benchmark frequency access page code 
second part code scheduled native mode execution rescheduled october machine model 
execution time estimate page rescheduled code generated described 
time estimate indicates performance rescheduled code account rescheduling overhead incurred october 
part termed overhead experiment 
third part october compiled scheduled machine model part benchmark 
input benchmark pages taken random benchmarks 
performance october benchmark find average time reschedule page tinker tinker 
cycles executing tinker cycles tinker 
combined number unique page accesses step estimate total number execution cycles rescheduling overhead 
execution time overhead experiments stretched termed overhead experiment 
order compare performance achieved parts speedup single unit single issue processor model called base model calculated 
defined speedup number cycles execution estimated experiment number cycles execution estimated base model 
parts assumed page size bytes 
results table measurements unique page accesses 
benchmark tinker native tinker native cccp compress eqn eqntott espresso lex tbl wc yacc avg rounded experiments described run benchmark figures 
shows speedups rescheduling tinker code tinker rescheduling overhead overhead rescheduling overhead overhead compares speedup achieved native mode execution cccp compress eqn eqntott tbl yacc page size speedup tinker overhead tinker overhead tinker native performance dynamic rescheduling tinker tinker 
tinker native 
presents corresponding numbers rescheduling tinker code tinker 
seen overhead speedup compares quite native 
exception compress tinker tinker limitations placed speculation rescheduling restrictive 
performance rescheduled code overhead included overhead figures overhead results expected 
reflects effectiveness dynamic rescheduling run time technique 
performance compares suggesting technique effective cases 
notable exceptions cccp tbl case penalty due overhead quite high 
phenomenon explained observing unique page access counts table identical number time page faults 
cccp tbl relatively short running benchmarks time page page size cccp eqn espresso tbl yacc speedup tinker overhead tinker overhead tinker native performance dynamic rescheduling tinker tinker 
page faults higher compared execution time benchmarks 
implies dynamic rescheduling may execute short running programs efficiently 
overhead reduced long running programs short running programs providing segment executable file cache translated pages runs 
operating system maintain segment updating program exit 
table suggests size pages table smaller sized tables may perform acceptably depending placement replacement policies page cache updates 
caching scheme improve performance dynamic rescheduling overhead performance overhead performance 
topic currently studied authors 
concluding remarks technique guarantee vliw vliw object code compatibility generations need hardware multiple executables 
relies limited version software scheduling applied time page faults 
technique requires support compiler isa operating system fast algorithm rescheduling 
results suggest dynamic rescheduling potential effectively solve compatibility problem vliw architectures 
area includes dynamic rescheduling cyclic code schedules modulo scheduled loops development translated page cache described 
anonymous referees excellent comments suggestions 
gratefully acknowledge support impact group university illinois urbanachampaign 
particular richard hank john gyllenhaal patiently answering queries 
members tinker group sanjeev banerjia sergei kishore menezes 
research supported intel national science foundation mip 
appendix algorithm input cycle execution step resolve resource constraints 
op writes back cycle stored op see step get op look resource usage matrix determine trc op update update set cycle op trc page step update scoreboard reserve destination registers latencies execution old schedule 
op initiates cycle reserve dest operand ops scoreboard latency set writer destination operand op step dependence checking 
initialize op op op store op superscalar vs vliw comp 
arch 
news vol 
pp 
mar 
rau dynamically scheduled vliw processors proc 
th ann 
international symposium microarchitecture austin tx pp 
dec 
melvin patt hardware support large atomic units dynamically scheduled machines proc 
th ann 
international symposium microarchitecture san diego ca pp 
dec 
franklin fill unit approach multiple instruction issue proc 
th ann 
international symposium microarchitecture san jose ca pp 
dec 
ebcioglu architectural framework heterogeneous instruction set architectures computer vol 
pp 
june 
sites chernoff marks robinson binary translation comm 
acm vol 
pp 
feb 
koch emulating powerpc macintosh proc 
microprocessor forum oct 
emulating dos windows risc environments proc 
microprocessor forum oct 
cmelik keppel shade fast instruction set simulator execution profiling fast simulation computer architectures conte eds boston ma kluwer academic publishers 
hwu mahlke chen chang warter hank holm superblock effective structure vliw superscalar compilation journal supercomputing vol 
pp 
jan 
mahlke lin chen hank effective compiler support predicated execution hyperblock proc 
th ann 
int 
symp 
microarchitecture portland pp 
dec 
tinker machine language manual 
department electrical computer engineering north carolina state university raleigh nc 
schlansker rau hpl architecture specification version tech 
rep hpl hewlett packard laboratories technical publications department page mill road palo alto ca feb 
conte systematic computer architecture prototyping 
phd thesis department electrical computer engineering university illinois urbana illinois 
chang mahlke chen warter hwu impact architectural framework multiple instruction issue processors proc 
th ann 
international symposium computer architecture toronto canada pp 
may 
page 
