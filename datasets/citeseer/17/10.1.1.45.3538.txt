combining active learning inductive logic programming close loop machine learning bryant muggleton page sternberg department computer science university york york yo dd uk 
department engineering mathematics computer science speed scientific school university ky biomolecular modelling laboratory imperial cancer research fund lincoln inn fields london wc px uk 
cs york ac uk edu sternberg uk machine learning ml systems produce human comprehensible hypotheses data typically open loop direct link ml system collection data 
describes alternative closed loop machine learning 
related area active learning ml system actively selects experiments discriminate contending hypotheses 
closed loop machine learning system selects carries experiments learning domain 
ase progol closed loop machine learning system proposed 
ase progol ilp system progol form initial hypothesis set 
devise experiments select competing hypotheses direct robot perform experiments analyse experimental results 
ase progol revise hypotheses repeat cycle unique hypothesis remains 
knowledge attempt robot carry experiments selected active learning real world application 
knowledge discovery biological chemical domains pharmaceutical industry increasingly overwhelmed large volume data 
generated internally side effect screening tests combinatorial chemistry externally sources human genome project 
industry predominantly knowledge driven 
instance knowledge required computational chemistry identification determining biological function sequence analysis 
computer science point view knowledge requirements industry give higher emphasis knowing declarative descriptive knowledge knowing procedural prescriptive knowledge 
mathematical logic preferred representation declarative knowledge knowledge discovery techniques required generate logical formulae data 
inductive logic programming ilp muggleton raedt bratko muggleton provides approach 
applied ilp prediction protein secondary structure muggleton sternberg mutagenicity king srinivasan structure activity king discovery finn protein fold analysis 
predictive accuracy central performance measure data analytical techniques generate procedural knowledge neural nets decision trees performance ilp system determined accuracy degree insight provided 
ilp hypotheses easily stated english exemplified diagrammatically 
allows cross checking relevant biological chemical literature 
importantly allows expert involvement human background knowledge refinement final dissemination discoveries wider scientific community 
comparative trials ilp systems provided significant chemical biological insights data analysis techniques 
statement importance line research royal society sternberg sternberg emphasised aspect joint human computer collaboration scientific discoveries 
science activity human societies 
belief computer scientific discovery support strong integration existing social environment human scientific communities 
discovered knowledge add build existing science 
authors believe ability incorporate background knowledge re learned knowledge comprehensibility hypotheses marked ilp particularly effective approach scientific knowledge discovery 
closed loop machine learning machine learning systems produce human comprehensible hypotheses data typically open loop direct link machine learning system collection data 
intend investigate alternative closed loop machine learning systems 
related area active learning cohn lin shaw ritter machine learning system actively selects experiments discriminate contending hypotheses 
closed loop machine learning system selects carries experiments learning domain 
particular plan test hypotheses 
hypothesis closed loop machine learning efficiently converges accurate hypotheses 
hypothesis closed loop machine learning systems physically realised robotics successfully applied discovery task functional genomics 
test hypotheses develop ilp system ase progol active selection experiments progol 
ase progol progol muggleton form initial hypothesis set 
devise experiments select competing hypotheses direct robot perform experiments analyse experimental results 
ase progol revise hypotheses repeat cycle unique hypothesis remains 
knowledge attempt robot carry experiments selected active learning real world application 
ase progol system design genomic data obtained industrial scale 
complete genomes dozen sequenced coli yeast cerevisiae 
genomes organisms process sequenced sequencing human genome due completed year 
analysis data needs methods obtaining 
closed loop machine learning approach doing 
focus genome research moving problem identifying biological functions genes known functional genomics 
problem important known function new genes identified sequencing multi oliver 
functional genomics recognised central deeper understanding biology exploitation biology medicine agriculture biotechnology general 
functional genomics appropriate application test ase progol relational representations appropriate problem progol successful related types problems previously see section access necessary domain expertise problem important automation essential application robotic technology commonly genomics 
partners project expertise applying robotics functional genomics 
ilp system progol muggleton particular advantages 
progol performs complete search user defined hypothesis space capable returning hypotheses space meet user defined criteria attaches posterior probability estimation hypothesis data fact progol search driven probability estimates progol complete search computationally tractable forms hypothesis space expect encounter 
active learning proposed ase progol approach related study active learning 
active learning assumes set candidate hypotheses associated prior probabilities set possible experiments associated costs 
aim active learning choose series experiments minimises expected cost eliminating hypotheses 
early fedorov introduced theory provides optimal solution problem 
note fedorov theory optimal experiments aims directing choices sequences experiments 
confused instance sequential analysis wald aimed minimising number randomly chosen experiments required distinguish hypotheses 
approach active learning differs ways cohn lin shaw ritter 
previous approaches neural net parametric representations intrinsically comprehensible logic programs purposes feeding back final theory see human scientists ii able direct logically encoded biological background knowledge 
large amount knowledge available project 
related discussed relationship closed loop learning closely related area active learning 
lines research related closed loop learning active learning 
version space select training instances robotic discovery reinforcement learning membership query algorithms computational learning theory systems collaborate human users 
section discusses areas turn 
version spaces important advantage version spaces described tom mitchell ph thesis mitchell potential ability version space direct presentation training instances obtain informative instances 
assuming hypotheses priori equally mitchell notes best training instance implied covered exactly half hypotheses 
discovering label example positive negative eliminate half hypotheses version space mitchell 
manner version space propose optimal experiments 
mitchell lead followed extent significant papers described paragraphs 
case closed loop learning knowledge mitchell utgoff banerji original lex system mitchell 
lex inductively learned control rules guide application operators symbolic integration 
addition lex generalizer module version space learner solver module lex included problem generator module propose new integration problems 
problem generator sought propose problems attempted yield help fourth module critic additional data learning 
manner problem generator proposed experiments solver carry critic produce additional data 
lex shortcomings closed loop learner 
limitation robotic systems day closed loop learning attempted application domain symbolic integration experimentation require interacting real world 
second experiments integration problems examples integration steps possible attempt generate optimal nearly optimal experiments version space 
subramanian feigenbaum closely followed mitchell proposal generating experiments subramanian feigenbaum 
started assumption version space consisting equally hypotheses noted problem generating optimal experiments np hard 
attempted find constraints inherent domains problem tractable 
focused ability factor version space 
example concept red wedge factorable red wedge 
general conjunctive propositional logic concepts concepts described vector feature values factorable manner 
factoring relational concepts ilp difficult addressed 
subramanian feigenbaum discussed briefly mentioned applications approach blocks world problem circuit design 
research version spaces ignored issue experimentation focused computational complexity 
restricted languages mitchell compact set set representation version space size exponentially larger example set 
hirsh mishra pitt showed interesting operations version spaces performed merely maintaining data computing entire version space set set hirsh 
requirement representation restricted way consistency problem solved polynomial time possible useful version space operations performed polynomial time 
unfortunately operations performed polynomial time manner precisely ones required proposing experiments 
determine experiment needed example able determine version space converged contains concept hirsh mishra pitt note accomplished consistency 
worth noting research computational learning theory community query committee similarities version space approach seung proposing experiments 
committee essentially set reasonable hypotheses queries experiments chosen consistent roughly half hypotheses 
queries computational learning theory discussed subsection 
robotic discovery reinforcement learning closed loop learning involves robots perform experiments closed loop learning related robotic discovery reinforcement learning 
specifically careful choice experiments related directed exploration thrun 
thrun identifies strategies directed exploration thrun ffl counter investigate explored regions state space consistency problem representation answer question particular set labeled examples contain hypothesis consistent labeled examples 
ffl recency investigate explored regions ffl error investigate regions state space estimated high error strategies closely linked cohn atlas ladner active learning approach selective sampling learner specifically requests examples region uncertainty cohn turn obvious similarities version space approach proposing experiments 
similarity key issues robotic discovery reinforcement learning diverge closed loop learning 
thrun highlights important tradeoff exploration analogous experimentation exploitation previously learned knowledge context robot navigation neural network learning tradeoff doesn appear closed loop learning 
tradeoff studied detail moore atkeson propose prioritized sweeping successful heuristic approach balancing exploration exploitation moore atkeson 
kearns singh related algorithm explicit explore exploit algorithm provably produces near optimal return number actions total computation time bounded polynomial relevant task specific parameters kearns singh 
key distinction closed loop learning reinforcement learning eventual payoff reinforcement learning comes exploitation learned knowledge learning goal closed loop learning 
closed loop learning exhibit tradeoff exploration experimentation exploitation 
result algorithms prioritized sweeping directly applicable closed loop learning 
robotic discovery closely related approach closed loop learning fox burgard thrun active localization fox 
localization problem robot estimating position sensor data 
approach localization robot controls various effectors efficiently localize 
specifically employed greedy approach analogous proposed mitchell described 
approach actions generated maximizing expected decrease uncertainty measured entropy 
results speak approach 
note localization problem general np hard practice robot able localize greedy strategy 
membership queries computational learning theory field computational learning theory long recognized powerful pac learning algorithms obtained addition passively receiving labeled examples learner actively pose membership queries 
example deterministic finite state machines pac learnable general pitt warmuth pac learnable membership queries 
membership query learning algorithm asks oracle label particular example 
spite power algorithms membership queries algorithms rarely practice seldom access oracle queries 
success closed loop learning yield successful automation oracles membership queries domains 
collaborative systems learning apprentice system kodratoff tecuci performs kind experiment asks user question 
crucial differences closed loop learning approach 
obvious difference requires resources attention knowledge user closed loop machine learning definition require user intervention 
second real responsibility selection experiments 
attempts solve problems provided user solve problem asks user solution 
summary section surveyed areas know dealing robot experimentation learning experimentation 
knowledge line research outlined attempt fully automated experimentation knowledge discovery natural science domain 
date active learning explored exclusively neural network parametric estimation approaches 
case scientific discovery important able produce theories easily understood debated human scientists 
ilp successfully generate theories past muggleton king sternberg king finn 
case finn multiple hypotheses consistent data 
circumstances active learning provides way discriminating contending hypotheses 
approach attempt follows learnable equivalence membership queries angluin 
implement active learning ilp system carry suggested experiments laboratory robots 
robotics technology necessary available clear scientific commercial need closed loop machine learning functional genomics 
tom dietterich tom mitchell sebastian thrun helpful answers questions regarding related 
supported partly esprit long term research action ilp ii project epsrc gr closed loop machine learning epsrc gr experiments machine learning epsrc advanced research fellowship held muggleton 
uk smith kline generous support 
angluin 
learning regular sets queries counter examples 
information computation 
bratko muggleton 
applications inductive logic programming 
communications acm 
cohn atlas ladner 
improving generalization active learning 
machine learning 
cohn jordan 
active learning statistical models 
journal artificial intelligence research 

yeast genome project learn 
trends genetics 
fedorov 
theory optimal experiments 
academic press london 
finn muggleton page srinivasan 
discovery inductive logic programming system progol 
machine learning 
fox burgard thrun 
active markov localization mobile robots 
appear robotics autonomous systems 
multi life genes 
science 
ritter 
active learning local models 
neural processing letters 
hirsh mishra pitt 
version spaces boundary sets 
proceedings th national conference artificial nce aaai pages menlo park ca 
aaai press 
kearns singh 
near optimal reinforcement learning polynomial time 
jude shavlik editor proceedings fifteenth international conference ma chine learning san mateo ca 
morgan kaufmann 
king muggleton lewis sternberg 
drug design machine learning inductive logic programming model structure activity relationships analogues binding 
proceedings national academy sciences 
king muggleton srinivasan sternberg 
structure activity relationships derived machine learning atoms bond connectives predict mutagenicity inductive logic programming 
proceedings national academy sciences 
kodratoff tecuci 
techniques design learning apprentice 
buchanan wilkins editors readings knowledge acquisition learning pages 
morgan kaufmann san mateo ca 

lin shaw 
active training backpropagation neural networks learning experimentation methodology 
annals operations research 
mitchell 
version spaces approach concept learning 
phd thesis stanford university cs hpp 
mitchell utgoff banerji 
learning experimentation acquiring redefining problem solving heuristics 
mitchell michalski carbonell editors machine learning artificial intelligence approach chapter pages 
morgan kaufmann 
mitchell 
generalisation search 
artificial intelligence 
andrew moore christopher atkeson 
prioritized sweeping reinforcement learning data time 
machine learning 
muggleton 
inverse entailment progol 
new generation computing 
muggleton king sternberg 
protein secondary structure prediction logic machine learning 
protein engineering 
muggleton de raedt 
inductive logic programming theory methods 
journal logic programming 
oliver 
dna sequence biological function 
nature 
leonard pitt manfred warmuth 
minimum consistent dfa problem approximated polynomial 
journal acm 
seung opper sompolinsky 
query committee 
proc 
th annu 
workshop comput 
learning theory pages 
acm press new york ny 
srinivasan muggleton king sternberg 
theories mutagenicity study order feature induction 
artificial intelligence 
sternberg king lewis muggleton 
application machine learning structural molecular biology 
philosophical transactions royal society 
sternberg lewis king muggleton 
modelling structure function enzymes machine learning 
proceedings royal society chemistry discussions 
subramanian feigenbaum 
factorization experiment generation 
proceedings fifth national conference artificial ence aaai pages philadelphia pa 
morgan kaufmann 
thrun 
role exploration learning control 
white editors handbook intelligent control neural fuzzy adaptive approaches 
van nostrand reinhold florence ky 
muggleton sternberg 
protein fold recognition 
page editor proc 
th international workshop inductive logic programming ilp lnai pages berlin 
springer verlag 
wald 
sequential analysis 
john wiley new york 
