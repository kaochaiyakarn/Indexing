comparison approaches continuous hand gesture recognition visual dialog system peter manfred lang institute human machine communication munich university technology 
munich germany fmor lgg technik tu muenchen de continuous hand gesture recognition requires detection gestures video stream classification 
continuous recognition solutions models hmms compared 
approach uses motion detection algorithm isolate gesture candidates followed hmm recognition step 
second approach single stage hmm spotting method improved new implicit duration modeling 
strategies tested continuous video data containing different types gestures embedded random motion 
data derived usability experiments application providing realistic visual dialog scenario 
results show improved spotting method contrast motion detection approach successfully suppress random motion providing excellent recognition results 

gestures efficient communication modality everyday situations 
study optimize possible gestures human machine interaction visual dialog system exclusively gestural commands developed see fig 
sec 

central task system temporal segmentation classification image sequences 
hmm recognition isolated image sequences works satisfactorily see suggests add independent motion detection achieve temporal segmentation 
advantage approach low additional computational cost implemented detection image features see sec 

course kind motion detected efficiency approach measured realistic dialog scenario see secs 

second approach integrated hmm spotting method introduced 
tests synthetically connected gesture material small size cat user visual input camera visual output monitor 
feature extraction motion detect 
hmm isolated rec 
hmm spotting scene editor st approach nd approach system overview proved ability ignore non meaningful indicate meaningful movements 
time newly improved spotting algorithm see sec 
applied true continuous video data tested stage solution see sec 


visual dialog application visual dialog application gesture scene editor 
editor allows create dimensional objects change position orientation destroy 
certain object attributes color size varied 
orientation observation distance scene changed 
objects scene editor manipulated indirectly editor contains graphically represented agent supposed communication partner 
agent receives gestural directives user interprets carries desired actions certain extent independently 
actions internal state application represented graphical animations appearance changes 
complex actions gen erating destroying objects changing attributes assigned graphical objects scene 
consequence actions consistently selected grabbed scene object 

description algorithms 
spatial segmentation feature extraction previous tests showed hand shape provides information distinguish image sequences 
hand shape obtained segmentation method trained skin color 
segmented binary images transformed hu moment invariants 
order differences successive images dh difference shape areas da centers mass form feature vector time da dh dh mean value standard deviation feature vector elements calculate unbiased normalized feature vector comparable elements gamma feature vector basis motion detection isolated recognition continuous spotting process 

approach motion detection hmm isolated recognition differential feature vector elements reflect motion shape changes image sequence 
absolute value feature vector built differential elements defined motion value image sequence time da dh dh indicate coherent segment motion motion value certain motion threshold thres bmin subsequent images sequence 
motion segment reached motion value stays threshold thres emin images 
necessary gestures contain short motion pauses turning points 
minimum total length motion segment lmin minimum distance detected motion dmin help find motion segments possible gesture candidates 
semi continuous left right structured hmms classify motion segments 
specific probability density functions log states hmms defined codebook mixture density functions prototypes calculated training data 
transition probabilities loga describe sequence states 
training recognition viterbi algorithm 
recursively accumulates maximizes called local score hmm state max gamma classify motion segment score accumulation starts time results final score state respective models detected motion 
final maximum likelihood decision provides best matching model result gestural meaning assigned detected motion segment 

approach hmm spotting spot gestures continuous video stream features fed hmms time step 
prevent output score increasing decreasing permanently local scores normalized respective viterbi path lengths 
reason local path lengths stored local scores normalized viterbi algorithm formulated max gamma delta gamma gamma gamma index best 
methods trigger new paths state examined 
optimal results obtained new path length starts permanently 
output score respective model start increase appropriate gesture appears decrease gesture ended 
consequently peaks output score indicate possible gesture 
smoothing process peak detection rules necessary reliable peak detection requiring variables sb se define smoothing interval pb pe peak detection interval 
relative rejection threshold rel model dependent absolute maximum minimum output scores minimum temporal peak distance dist help suppress irrelevant peaks 
local path length manipulated allowing simple duration modeling 
estimated average duration hmm gamma gamma gamma ii approximation eq 
necessary left right model transition probability state 
functional category number variations displace rotate tilt change size release point trigger action table gesture catalog new normalization length function defined ae delta gamma result viterbi paths artificially extended longer average model duration normalization function parameter greater 
indirectly helps shorter viterbi paths grow score longer paths reduced 
normalization length function diminish error rate significantly see sec 


wizard oz experiments test data description scene editor see sec 
tested wizard oz experiments employing human wizard recognize gestures control scene editor remotely 
experiments test persons invented different gestures operate editor 
frequently gestures selected forming catalog basis tests see table 
training test material contained continuous video sequence minutes length containing gestures single person 
motion jpeg compressed version video takes gigabyte disk space contains images rate fields second 
image size color segmentation process see sec 
theta pixels 
camera mounted table observing desk area user monitor 
area large perform gestures hands 
video contains gestures times 
gestures labeled hand allowing train models evaluate recognition process 
versions gesture cut train models isolated gestures 
recognition continuous data consequently containing gestures known training unknown gestures 

evaluation criteria parameter settings motion segment reaches time considered correctly detected lies detection interval sigma images manually labeled gesture 
interval chosen large sure obtain gesture candidate subsequent classification 
detection rate ratio correctly detected motion segments total number valid gestures 
false detected rate represents relative number wrongly detected motion segments 
multiple detection rate mult relative number motion segments repeatedly assigned gesture 
similar definition gesture ends time defined correctly recognized system indicates time lies interval sigma images temporal recognition delay gamma recognition rate ratio correctly recognized gestures total number valid gestures 
multiple recognition rate mult measures correctly repeatedly recognized gestures 
average recognition delay correctly recognized gestures 
false accept rate measured fa kg number wrongly accepted gestures number key gestures hour hmm spotting parameters extensively varied empirically find optimal recognition results 
optimal parameters result tables maximum order smoothing interval parameters sb se peak detection interval parameters pb pe minimum temporal peak distance dist number hmm states isolated recognition spotting 

experimental results 
motion detection isolated recognition motion detection parameters see sec 
determined numerical optimization process 
different optimization strategies emphasizing maximum maximum combined minimum mult minimum mult see table 
appropriate detection results demonstrate possible gestures detected high multiple detection rate tolerated see table 
classification results motion segments prove high multiple detection rate results high false recognition rate obviously motion segments correctly recognized see table 
motion detected gestures 
number different key gestures see table 
bmin lmin thres emin dmin mult table optimal setting motion detection parameters thres bmin emin lmin dmin detection results mult optimization strategies mult rel sp rel table recognition results mult motion detection parameter settings spotting sp 
spotting spotting motion detection isolated recognition recognition rate higher false accept rate see table 
remaining multiple detection rate demonstrates spotting method hardly disturbed random motion close actual gestures 
applying score threshold false accept rate halved acceptable recognition rate 
recognition delay images corresponds system reaction time seconds insignificant visual dialog application 
spotting results improved normalization function parameter raised see eq 
table 
increasing rejection threshold diminishes false accept rate significantly recognition rate reduced slightly 
constant recognition rate false accept rate improved 

stage stage approach continuous hand gesture recognition compared 
realistic visual dialog scenario provided video data containing typical mixture meaningful und non meaningful motion catalog different gestures 
results proved stage hmm spotting method far superior straight forward stage combines independent motion detection isolated hmm recognition 
spotting improved introducing new implicit duration modeling 
rel mult mult rel table recognition results spotting mult different rel 

hwang lipreading color motion video 
icassp atlanta vol 
pp 


hu visual pattern recognition moment invariants 
ire trans 
inform 
theory vol 
pp 
feb 
huang jack hidden markov models speech recognition 
edinburgh university press 
lang feature extraction methods consistent spatio temporal image sequence classification hidden markov models 
icassp munich vol 
pp 

lang universal hmm approach image sequence classification 
icip santa barbara usa vol 
pp 

lang integral stochastic approach image sequence segmentation classification 
icassp seattle usa vol 
pp 

lang spotting dynamic hand gestures video image sequences hidden markov models 
appear proceedings icip chicago usa 
starner pentland visual recognition american sign language hidden markov models 
international workshop automatic face urich pp 

yamato ohya ishii human action time sequential images hidden markov model 
ieee comp 
vision pattern recog 
pp 

