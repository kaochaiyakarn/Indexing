adaptive importance sampling estimation structured domains luis ortiz computer science department brown university box providence ri usa leo cs brown edu leslie pack kaelbling artificial intelligence laboratory massachusetts institute technology technology square cambridge ma usa ai mit edu sampling important tool estimating large complex sums integrals highdimensional spaces 
instance importance sampling alternative exact methods inference belief networks 
ideally want sampling distribution provides optimal variance estimators 
methods improve sampling distribution systematically adapting obtain information samples 
stochastic gradient descent method sequentially updating sampling distribution direct minimization variance 
stochastic gradient descent methods minimization typical notions distance current sampling distribution approximations target optimal distribution 
validate compare different methods empirically applying problem action evaluation influence diagrams 
interested computing quantities involving large sums expectations uncertain structured domains 
instance belief inference bayesian networks bns requires sum marginalize remaining variables interest 
similarly order solve problem action selection influence diagrams sum variables observed time decision order compute value different action choices 
represent uncertainty structured environments bn 
bn allows compactly define joint probability distribution relevant variables domain 
provides graphical representation distribution means directed acyclic graph dag 
defines locally conditional probability distribution relevant variable represented node graph state parents graph 
decomposition help evaluation sums 
due factors regarding connectivity graph general sufficient allow efficient computation exact value sums interest 
sampling provides alternative tool approximately computing sums 
sampling methods proposed alternative exact methods problems 
particular importance sampling see geweke applied problem belief inference bns fung chang shachter peot action selection ids see charnes shenoy ortiz kaelbling 
simpler form importance sampling distribution prior distribution bn resulting setting value evidence 
noted early sampling distribution far optimal sense provides estimates larger variance necessary shachter peot 
instance optimal sampling distribution case belief inference sample unobserved variables posterior distribution observed evidence 
knew distribution know answer belief inference problem 
modifications proposed improve estimation simple importance sampling distribution discussed information obtained samples fung chang shachter peot shwe cooper 
propose methods systematically sequentially update importance sampling distribution 
view updating process learning separate bn just sampling 
learning objective minimize error criterion 
stochastic gradient method results direct minimization variance estimator respect importance sampling distribution error function 
stochastic gradient methods result minimizing error functions typical measures notion distance current sampling distribution approximations optimal sampling distribution 
definitions introducing notation 
denote dimensional random variables capital letters denote multi dimensional random variables bold capital letters 
instance denote multi dimensional random variable denote components 
xn th dimensional random variable 
small letters denote assignments random variables 
instance means component denote set possible values take set possible values take denote capital letters nodes graph 
denote pa parents node directed graph 
introduce notation useful description methods 
denote operator sum possible values individual variables forming zn function variables expression stands function variables results setting values assignment letting values remain unassigned 
words 
notation means variable formed variables form 
xn 
zn 
note assuming set variables forming forming disjoint 
notation means random variable distributed probability distribution bayesian network bn graphical probabilistic model represent uncertainty structured domains 
compactly represents joint probability distribution relevant variables system interest 
uses directed acyclic graph dag represent relationship relevant variables 
node graph represents variable 
model defines local conditional distribution pa node variable parents pa graph 
joint distribution pa 
instance define bn graph 
inference problem bns computing posterior probability assignment subset variables example bayesian network influence diagram 
evidence subset variables system 
assume variables discrete sample spaces possible values variable take finite 
general set variables interest assignment remaining variables 
problem want compute probabilities kind 
local decomposition joint distribution leads evaluation sums large number variables 
general problem intractable cooper 
influence diagram id probabilistic model decision making uncertainty 
think id bn decision utility nodes added 
instance example bn build id shown 
square decision node 
diamond utility node 
potentially different joint distributions variables action choice available 
assume simplicity single decision node graph 
joint distribution variables action choice assigned decision variable pa decision associated decision node function parent nodes graph 
access value variables time making decision 
similarly utility associated utility node function parent nodes graph 
assume finite number discrete action choices 
problem select best strategy function mapping possible value parents decision node action choice 
best strategy strategy highest expected utility 
variables parents decision node remaining variables 
problem obtaining optimal strategy reduces obtaining assignment action maximizes value associated action assignment 
note computing value requires evaluation sum 
reasons previous problem belief inference bns exact computation value intractable general 
importance sampling importance sampling provides alternative exact methods evaluating sums 
quantity interest real function turn sum expectation expressing probability distribution satisfying 
call importance sampling distribution 
define weight function allows express 
obtain unbiased estimate obtaining samples 
computing estimate 
apply technique problem belief inference bns 
typically pa pa pa implies pa note defining importance sampling distribution prior distribution bn 
obtain samples distribution sampling variables partial order defined dag local conditional distribution original bn variable 
obtain samples variable traversing nodes graph sampling variable corresponding get node variable evidence set sample 
assign value evidence assignment resulting samples assignments variables evidence set prior distribution bn 
call method resulting importance sampling distribution traditional method 
context belief inference method called likelihood weighting lw weight function likelihood sample weighted likelihood 
similarly apply technique context action selection ids evaluate 
general pa pa particular example 
important property estimator variance weights associated importance sampling distribution 
var recall definition assume positive function 
derive optimal minimum variance importance sampling distribution proportional 
weights zero variance case weight function output value interest note need avoid letting small respect increase variance 
matter fact var value implies importance sampling distributions sufficiently fat tails 
adaptive importance sampling traditional method uses importance sampling distribution prior distribution bn far optimal sense higher variance necessary 
case evaluating actions ids completely ignores potentially useful information utility values 
try learn optimal importance sampling distribution adapting current sampling distribution obtain samples 
view adaptive process learning distribution variables sum specifically importance sampling distribution 
particular view process learning bns samples just sampling 
expression optimal distribution equation particular factorization function different estimation problems deduce order able represent distribution graphically bn need add arcs connect pair nodes parents observations utility nodes connected 
doing increase size model particularly cases local conditional probabilities utilities smaller compact parametric representation noise 
deal issue concentrate problem learning bn structure original bn id 
need update local conditional probability distributions obtain samples 
parameterize importance sampling distribution set parameters 
indicator function pa condition pa agrees value assigned 
express importance sampling distribution pa pa ijk ijk pa 
ijk ijk 
note representation uses assumptions global local parameter independence typically bns 
weight function parameterized defined 
learning criteria update rules subsections different methods updating sampling distribution 
update rules gradient descent 
time update parameters follows 
update rule denotes learning rate step size rule denotes gradient error function appropriately projected satisfy constraints 
methods differ define 
discussion denote samples 
drawn 
gather samples estimate different sampling distributions combine get unbiased estimate 
sufficient weight weighting function independent obtained just samples sampling distribution 
instance estimator unbiased long independent letting produce unbiased estimate 
weight experiments 
general give weight importance sampling distributions smaller variances 
assuming variance decreases increasing sequence note sample variance time appealing necessarily lead unbiased estimator independent 
consider general strategies minimizing variance directly minimizing distance global approximations optimal sampling distribution minimizing distance empirical distribution optimal sampling distribution local approximations 
strategies find express partial derivatives form gradient ijk pa ijk function depends error functions 
note expectation 
methods update parameters estimating value partial derivatives evaluated current setting parameters ijk pa ijk minimizing variance directly noted optimal importance sampling distribution estimating minimizes variance 
objective derive stochastic gradient update rule parameters importance sampling distribution 
error function var var corresponding function gradient var 
note definition yields unbiased estimate gradient 
gradient expectation particular function case evaluate function exactly 
obtain unbiased estimate sampling 
minimizing variance indirectly approximate global minimization recall optimal importance sampling distribution estimating equation 
update rules subsection motivated idea reducing notion distance current sampling distribution optimal sampling distribution 
note really compute values optimal distribution requires knowing normalizing constant exactly value want estimate 
approximate optimal distribution current estimate follows 
consider error functions sum squared error versions kullback leibler divergence 
norm sum squared error function notion distance distributions error function corresponding function gradient approximation results defined equation approximation 
alternative commonly notion distance probability distributions kl divergence 
measure symmetric 
version kl divergence context error function kl log corresponding function gradient kl 
version kl divergence error function kl log corresponding function gradient kl log log 
symmetrized version kl error function kl kl kl 
obtain partial derivatives error function approximation accordingly 
heuristic local minimization empirical distribution update methods subsection motivated idea minimizing different notions distance current sampling distribution empirical distribution optimal importance sampling distribution build samples 
hope empirical distribution approximation optimal sampling distribution 
define empirical distribution parameterized locally follows ijk pn pa pn pa pa ijk ijk 
essentially defining empirical distribution samples samples define revert current distribution 
try minimize distance current sampling distribution empirical distribution locally 
similar case previous strategies find express partial derivatives form gradient error functions discussed subsection ijk ijk ijk ijk ijk function depends error functions 
methods update parameters estimating value partial derivatives evaluated current setting parameters ijk ijk ijk 
define local norm error function ijk ijk error function version kl kl ijk log ijk ijk kl ijk log ijk ijk obtain corresponding functions gradient ijk ijk ijk ijk kl ijk ijk ijk ijk kl ijk ijk log ijk ijk 
obtain update rule symmetrized version kl accordingly 
discussion update rules note update rules derived var clearly uses unbiased estimate gradient 
immediately apparent update rules kl kl unbiased estimates 
note magnitude components resulting gradients different suggested respective functions 
function var magnitude proportional squares weights 
magnitudes kl linear weights 
magnitude potentially smaller probability sample factor 
magnitude kl logarithmic weights 
assume positive weights positive 
var kl positive 
function positive 
similarly function kl positive log 
sampling distribution underestimates value overestimates value 
sign kl depends estimated value similarly magnitudes var kl kl related amount overestimation 
var kl magnitude larger sampling distribution underestimates overestimates 
kl logarithm brings amount underestimation scale 
note approximations kl kl zero addition kl zero 
conditions hold assumption positive 
note constrain distribution functions var kl kl unbounded bounded 
local error function leads update rule step size intuitive interpretation weighting current importance sampling distribution empirical distribution 
case kl update direction proportional ratio empirical distribution respect current importance sampling distribution 
hand kl update direction proportional logarithm ratio 
note kl defined ijk 
fix letting ijk pn pa ijk pn pa essentially imposing dirichlet prior parameters equal current probability values empirical distribution parameters 
interpret update rules local adding weights elements domain importance sampling distribution renormalizing 
version kl divergence respect empirical distribution adding weights 
add values relative amount underestimated overestimated magnitude distribution particular state 
underestimated add weights larger 
overestimated add weights smaller 
version kl divergence due logarithm function add weight underestimated subtract weight overestimated 
logarithm brings amount underestimation overestimation scale adds subtracts weight accordingly 
note approximating gradients var kl kl little sample obtain estimate gradient 
advisable method local heuristic empirical distribution optimal sampling distribution highly inaccurate 
update rules empirical distribution better take larger number samples updates 
note parameters change iteration 
related different variations importance sampling problems discussed see lin druzdzel 
methods belong class forward samplers sample distribution original structure bn 
self importance sampling shachter peot shwe cooper method closest methods proposed updates sampling distribution obtains information samples 
method update rule similar derived updates distribution obtaining empirical distribution update weighting empirical distribution sampling distribution shwe cooper 
update rule ijk ijk ijk ijk ijk ijk ijk framework think update rule resulting error function sis ijk ijk ijk ijk annealed importance sampling neal related technique tries obtain samples optimal sampling distribution 
understand user sets sequence distributions distribution optimal distribution typically defined markov chains 
move distribution anneal sequence converges optimal sampling distribution 
hope get independent sample distribution restart process try obtain independent sample 
uses independent samples obtain estimate 
notice traversal sequence distributions markov chains produces single sample 
technique general unaware applied problems considered 
currently investigating possible connections methods technique 
empirical results implemented adaptive importance sampling methods described 
learning rate value depends updating method 
need different values different methods differences magnitude gradients 
impose additional constraint parameters call boundary 
require ijk constant factor 
experiments 
sampling distribution fat tails avoiding extrema probability possibility infinite variance 
initialize parameters starting importance sampling distribution prior probability distribution original bn 
local conditional probability values satisfy boundary constraint change distribution 
mh mp os os mh mp graphical representation id computer mouse problem 
order satisfy constraint ijk project approximation gradients simplex local conditional probability distribution 
letting ijk ijk ijk 
note guarantee step projected direction parameters remain constraint space 
updating local conditional probability distribution respective parameters satisfy constraint find minimum step allow remain inside constraint space take step size gradient direction half distance current position parameter updating simplex closest point boundary gradient direction 
tested methods computer mouse problem ortiz kaelbling simple id shown 
added utility values ortiz kaelbling positive 
consider problem obtaining value vmp action observation mp 
evaluated method computing error mse true value expectation interest mp estimate generated adaptive sampling method 
results show methods achieve better mses fewer samples problem 
show results methods competitive 
denote var method minimization variance kl kls methods global minimization kl kl respectively 
update methods take number samples lw number samples lw var number samples lw var number samples lw var kl number samples lw var kl kls average mean squared error runs function number samples taken 
allow lw twice samples 
account update methods traverse graph iteration update parameters relevant sample taken 
compensate time allow estimate lw twice samples 
shows results 
graph shows average mse runs function total number samples taken times lw methods 
note var achieve better mses lw converge faster 
significance level state individually total number samples var individually better respect mse lw 
kls better lw 
ran methods including local heuristic methods 
competitive larger total number samples 
analysis necessary convey general observations 
believe general tradeoff setting 
note updates kl versions kl typically performs better kl 
believe error function kl defined respect optimal sampling distribution kl respect current sampling distribution 
kls perform better 
stable methods suggesting theoretical analysis currently undertaking 
possible reasons behavior variance gradient smaller cases error function bounded error surface smoother cases 
conjecture converges stationary point second result shows update methods lead importance sampling distributions smaller variance relatively quickly problem 
number samples lw number samples lw var number samples lw var number samples lw var kl number samples lw var kl kls average true variance weight function runs function total number samples taken 
shows graph true variance sampling distribution learned different update methods function total number samples 
horizontal line shows variance associated sampling distribution lw prior distribution original bn 
experiments carried single problem 
clearly extended variety larger problems indicate adaptive methods particularly minimize variance norm lead significant improvements efficiency sampling method computing large expectations 
acknowledgments dynamic weighting scheme recommendation section boundary section independently developed jian cheng marek druzdzel 
heuristics reported manuscript author saw working 
hauskrecht thomas hofmann kee kim thomas dean discussions feedback 
implementation uses functionality bayes net toolbox matlab murphy kevin murphy 
anonymous reviewers insightful comments 
luis ortiz supported part nsf graduate fellowship part nsf award sbr 
leslie pack kaelbling supported part ntt part darpa contract dabt 
john charnes prakash shenoy 
forward monte carlo method solving influence diagrams local computation 
school business university kansas working august 
gregory cooper 
computational complexity probabilistic inference bayesian belief networks 
artificial intelligence 
robert fung kuo chu chang 
weighting integrating evidence stochastic simulation bayesian networks 
proceedings fifth workshop uncertainty artificial intelligence pages 
john geweke 
bayesian inference econometric models monte carlo integration 
econometrica november 
yan lin marek druzdzel 
stochastic sampling search belief updating algorithms large bayesian networks 
working notes aaai spring symposium search techniques problem solving uncertainty incomplete information pages stanford california march 
stanford university 
available www pitt edu druzdzel publ html 
kevin murphy 
bayes net toolbox matlab 
available www cs berkeley edu bayes bnt html 
radford neal 
annealed importance sampling 
technical report department statistics university toronto toronto ontario canada september 
available www cs utoronto 
ca radford 
luis ortiz leslie pack kaelbling 
sampling methods action selection influence diagrams 
proceedings seventeenth national conference artificial intelligence 

ross shachter mark peot 
simulation approaches general probabilistic inference belief networks 
proceedings fifth workshop uncertainty artificial intelligence pages 
michael shwe gregory cooper 
empirical analysis likelihood weighting simulation large multiply connected medical belief network 
computers biomedical research 
