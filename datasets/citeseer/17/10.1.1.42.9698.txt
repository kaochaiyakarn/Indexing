adaptive data broadcast hybrid networks kostas cs umd edu nick roussopoulos nick cs umd edu john isr umd edu institute systems research university maryland immense popularity web world witnessing unprecedented demand data services 
time internet evolving information super highway incorporates wide mixture existing emerging communication technologies including wireless mobile hybrid networking 
advantage new technologies proposing hybrid scheme effectively combines broadcast massive data dissemination unicast individual data delivery 
describe technique uses broadcast medium storage frequently requested data algorithm continuously adapts broadcast content match hot spot database 
show hot spot accurately obtained monitoring broadcast misses observed direct requests 
departure broadcast systems rely efficient scheduling precompiled user profiles 
show proposed scheme performs effectively dynamic rapidly changing workloads 
extensive simulation results demonstrate scalability versatility technique 
world witnessing unprecedented demand data services 
immense popularity web generating exponential demand workloads satisfied existing internet capacity traditional data services material supported center satellite hybrid communication networks nasa national science 
nsf eec 
asc 
permission copy fee part material granted provided copies distributed direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment 
copy republish requires fee special permission endowment 
proceedings rd vldb conference athens greece scalability grows best linearly network bandwidth server capacity 
workloads observed course special events olympics elections requests peak periods 
traditional unicast point point connection oriented data services infrastructure developed meet demand network bandwidth server capacity underutilized wasted non peak periods 
hand internet evolving information super highway incorporates wide mixture communication technologies including wireless mobile hybrid networking kb bg 
environment new types information services surfacing practical solutions anticipated explosion user demands proposed fz 
services potential meeting workloads efficiently disseminate information connection mode number receivers significant performance degradation terms access latency 
major concern success systems broadcasting right set data data vigorous demand 
srb introduced hybrid system effectively combines broadcast massive data dissemination broadcast data push unicast request data delivery unicast data pull 
system built notion air caching available broadcast capacity temporary storage frequently requested data 
key issue identification database hotspots air cached small load broadcast misses left serviced usual way 
major obstacles data needs characterized predicted priori dynamic nature demand 
example emergency weather related situations may cause abrupt shifts demand 
techniques precompiled broadcast schedules applicable case 
second users receiving information broadcast channel passive sense communicate server acknowledge usefulness broadcast 
server lacks lot invaluable information actual data needs 
propose technique continuously adjusts broadcast content match hot spot database 
show hot spot accurately obtained monitoring broadcast misses observed direct requests 
departure schemes rely complete cases unavailable knowledge hits misses 
develop adaptive algorithm relies marginal gains probing identify intensively requested data 
show performance hybrid system surpass capacity unicast server orders magnitude assumption server capacity sufficient servicing cold set data 
holds performance hybrid system proposed independent total volume workload system exhibits significant scalability rapidly changing access patterns 
hybrid data delivery section develop simplified analytical model hybrid data delivery provide intuition illustrate involved trade offs 
model discuss broadcast unicast synergistically yield high data service rates 
hybrid model hybrid scheme exploit characteristics data delivery modes integrate way better matches clients demands 
objective deliver needed data minimum delay large numbers clients 
striving goal looking solutions range pure broadcast push server repetitively periodically broadcasts data items clients passive listeners requests 
repetition allows broadcast medium perceived special memory space 
major advantage accessed concurrently number clients performance degradation 
broadcasting attractive solution large scale data dissemination 
limitation accessed sequentially clients need wait data interest appear channel 
direct consequence access latency depends volume data broadcast fairly small 
pure unicast pull standard client server architecture requests explicitly server 
scheme scale capacity server network 
average data access time depends aggregate workload network load size database 
terms data push broadcast interchangeably terms data pull unicast response time number broadcast items pull push hybrid delivery trade consider database containing data items equal size assume demand item forms poisson process rate items numbered delta delta delta server modeled system services requests items mean service time 
addition server broadcast data channel rate assume reason server decides broadcast items offer rest demand 
define expected response time requests serviced server pull gamma gammal satisfied broadcast push ns half time required broadcast items 
expected response time hybrid system weighted average pull push plots representative example pull push function number broadcast items 
assumed total workload greater safe assumption large scale systems huge client populations 
henceforth refer system pull capacity 
thing note performance pull service pull exponentially affected imposed load 
evident little broadcasting volume requests server may increase capacity making service practically impossible left side graph 
stated formally response time pulled data consequently response time grows arbitrarily large ln gamma lm hand response time pushed data straight line growing proportionally volume broadcast data 
slope line determined size data available bandwidth broadcasting desirable 
obviously best performance look solutions area maintain proper balance data push pull 
practical considerations workloads discussion previous section suggests possible balance data delivery modes order obtain optimal response time 
optimal solution depends shape size imposed workload 
follows explore hybrid delivery practical perspective give qualitative answer combi skewed data access pattern nation broadcasting unicasting advantageous 
intuitively data broadcasting helpful content useful multiple receivers 
benefit twofold broadcast message server saves unicast messages sent individually second satisfied receivers avoid sending requests server 
hand broadcast data useful hardly receivers yield benefit harm performance occupying valuable bandwidth 
implies broadcasting effective significant commonality client population 
ideally detect exploit commonality 
consider example data set items assume get requested skewed access pattern 
clarity assume items sorted respective request rates 
discussion far clear looking optimal point draw line data pushed data left pulled 
area left head distribution represents volume requests satisfied broadcast 
shaded area right tail distribution represents volume explicit requests directed server 
model previous section response time depends area tail width head number broadcast items 
height head reflects savings broadcasting 
generally selection satisfy constraints tail maintained pull capacity 
head wide accommodate hot spot include rarely requested data 
constraint intuitive second deserves clarification critical practicality hybrid solution 
consider case tail long area small zero height 
represents large number items gets requested infrequently 
area larger pull capacity need move point right 
item contributes little total area optimal deep tail 
means quality broadcast content substantially assuming way satisfy receivers including lots rarely requested items yielding unacceptably high response time optimal model 
consequently workloads slightly increased pull capacity favorable solution inordinate broadcasting 
bearing mind consider cases optimal solution require broadcasting rarely requested data 
assumed pull capacity handle aggregate load imposed requests data 
assumption propose adaptive hybrid scheme near optimal way exploits broadcasting take load hot data server left tolerable load imposed infrequently requested data 
adaptive hybrid delivery section elaborate proposed adaptive hybrid delivery scheme 
approach mainly notion data caching 
conceptually treat available broadcast capacity global cache memory server clients 
typical cache memories air cache increase throughput terms requests serviced time unit adaptive changing workloads 
challenge making adaptive lies fact server information air cache hits simply acknowledged clients 
traditional cache management techniques cache hits lru mru applicable 
algorithm relies air cache misses indicated explicit requests data broadcast provide server tangible statistics actual demand 
interesting perplexity system misses better server statistics adapt hand hits broadcast satisfied clients 
vapor liquid frigid data item database define temperature corresponds request rate addition item possible states intuitive presentation borrow terminology analogy physical states water vapor items deemed heavily requested broadcast put air cache 
liquid items currently broadcast server received moderate small number requests justify broadcasting 
frigid items requested temperature practically dropped 
proposed adaptive scheme server dynamically determines state database items relying misses 
considered sparks regulate temperature state data 
specifically ffl vapor data retrieved air cache server get feedback actual temperature 
heated requests gradually cool eventually turn liquid 
duration cooling process depends temperature initially turned vapor 
ffl liquid data items continue requested turn vapor remain liquid depending intensity requests 
requested eventually freeze 
ffl frigid data items start requested turn liquid vapor depending intensity requests 
obviously long get requests remain frigid 
hardest part process distinguishing vapor liquid data focus 
distinction liquid frigid data items achieved buffer manager database system frequency replacement policy rd 
likewise server maintain liquid items main memory anticipating new requests near retrieve frigid items secondary memory necessary 
practice distinction frigid data plays important role terms overhead specially case frigid data largest part database 
default temperature server loaded tracking demand statistics safely ignore looking candidate vapor items 
repetitive data broadcasting order create effect caching air employ repetitive broadcast scheme 
contrary typical periodic broadcast schemes assume fixed schedule size content broadcast continuously updated better match workload 
heart approach queue stores vapor data 
server picks item broadcast head item gets broadcast removed head gets appended back tail time temperature multiplied predetermined reflect cooling process vapor data 
contents modified cycle identified vapor item specially assigned placeholder 
placeholder broadcast server re evaluates state data updates queue accordingly 
adaptation process described detail section pinpoints vapor items demoted liquid liquid items need promoted vapor 
vapor items selected demotion marked broadcast removed queue 
new vapor items placed tail queue 
new item tail assigned placeholder 
result repetitive broadcast scheme evolving size content 
integral part hybrid delivery scheme indexing air cache 
clients expected select data delivery paths server needs aware items forthcoming broadcast channel 
adopted simple technique uses signature list data identifiers queue index broadcast interleaved data 
clients examine index decide wait required item arrive explicit request 
broadcast frequency index adjusted trade overhead maximum time clients willing wait making decision 
note depending size number vapor items possible simple indexing scheme yield considerable overhead 
cases plan investigate elaborate indexing schemes bit vectors schemes proposed ivb ivb 
adaptation marginal gains section algorithm adapts contents broadcast 
mentioned adaptation process server needs kinds decisions vapor data cooled demoted liquid liquid data hot promoted vapor 
straightforward approach establishing absolute temperature thresholds applied state item depends aggregate workload relative temperature items 
account developed algorithm decisions expected marginal gain possible action 
expected marginal gain computed considering item promotion vapor state demotion liquid 
note cases computed similarly sign involved quantities 
avoid duplication presentation variable takes value gamma item vapor considered demotion liquid liquid considered promotion vapor 
computations model described section 
difference take account overhead broadcasting index 
additional variables aggregate request rate liquid data ll aggregate request rate vapor data lv number vapor items nv size index entry expected marginal gain dt weighted average marginal gains dt push dt pull define dlv dt push dt pull pull dlv gamma ll dl dl response time push pull dt dt push dt pull marginal gains depicts computations graphically 
ideally system try reach operate minimum point curve turns practice best thing 
explained fact left minimum point response time grows fast 
result dynamic workload probable small change bad effect system 
operating close minimum system unstable 
verified experiments srb 
force system operate suboptimal area right minimum safely avoiding instability 
achieve establishing small zero threshold angle tan gamma dt dlv actual algorithm updates contents vapor queue consists simple steps liquid vapor data temperature lower hottest liquid item 
respective marginal gains continues vapor items increasing order temperatures takes opposite direction long promotes liquid data vapor decreasing order temperature 
note vapor item demoted second step liquid item promoted third step 
possible vapor items get demoted step re promoted third 
data items sorted temperatures complexity algorithm order number items change state 
illustrates example algorithm works 
assume initially items vapor items liquid case response time demote promote example execution adaptive algorithm server clients liquid vapor server clients vapor vapor liquid demotion probing algorithm temperature lower liquid detects gain items skips second step 
third step promotes items demoted step 
temperature probing potential weakness described far artificial cooling vapor data 
introduced sole purpose giving server chance re evaluate temperature vapor data regularly expected reflect actual evolution data demand may result situation hot item demoted liquid 
happen server swamped hundreds thousands requests item 
adaptive algorithm eventually correct re promoting item reaction time lag may big cause serious performance degradation 
better explained time line events decision demote hot vapor item time decision reflected broadcast index reaches clients point requests item directed server 
item hot server decides vapor includes index broadcast received clients considering data transmission server inertia delays time re promote item interval substantial 
shaded area represents total request load wrong decision may generate 
cumulative penalty consecutive improper heavy system practically unusable 
section introduces temperature probing way preventing disastrous effects premature vapor data 
algorithm propose remedies potential errors double approach illustrated 
soon decision convert item vapor liquid heated misses item re promoted time creates small time window srb discuss maintain order low overhead hs distribution hs gaussian distribution limits expected number client requests demoted item provide server concrete information actual demand 
effect small number misses give server opportunity probe actual temperature data committing decision 
re promotion item server waits requests generated period order re evaluate item actual temperature 
due network inertia delay reevaluation depending result probing item demoted reinstated broadcast queue corrected temperature critical factor double approach probing interval 
short hardly requests generated help server re evaluation 
long essentially defeats purpose 
selected carefully preferably dynamically adjusted intensity workload 
reasons selection average request rate vapor data 
specifically set probing time theta nv lv nv lv inverse average temperature vapor data 
essentially probing window determines expected number misses generated probe allows system explicitly control total probing overhead 
experiments results simulation model order establish potential hybrid data delivery investigate involved trade offs built simulation model proposed system 
experiments assumed provided information collection self identifying data items equal size disk pages 
clients generate requests data satisfied broadcast server explicit request 
assumption modeled client population single module generates total workload stream independent requests data items 
exact number clients specified implicitly suggested aggregate request rate 
data access pattern different distributions gaussian figures 
ideal case clearly defined hotspot database 
second realistic time allows explicit customization parameters aggregate request rate rr aggregate request rate cold data width hot spot terms data items hs center hot spot order create effect dynamic workloads value parameters vary course experiment 
example changing value simulate workloads moving hot spots 
server simple data server model enhanced transmitter capable broadcasting functionality required implement adaptive algorithm 
modeled detail parameters cache size characteristics presentation interpretation results parameter system pull capacity corresponds maximum rate requests serviced 
depending experiment setup determined combination processing power server available bandwidth size data 
network want capture hybrid environments need specify characteristics communication paths broadcast channel downlink server clients clients server 
simplicity assume clients similar independent paths establishing point point connections server 
downlink hand shared resource server replies 
broadcast channel considered separate channel fixed specially allocated bandwidth 
note study far ignored communication errors 
static workloads set experiments static workloads demonstrate system adaptiveness 
reason provide solid base comparison easily determine optimal behavior hybrid delivery system 
graphs section include baselines comparison 
marked theory represents theoretically optimal model section 
second marked stripped version server adapt broadcasts periodically optimal set data obtained exhaustive search 
static workloads line ultimate performance goal system 
request rate reqs sec theory adaptive pure pull request rate reqs sec theory adaptive pure pull gauss fixed hot spot request rate reqs sec theory adaptive gauss expanding hot spot experiments section assumed broadcast downlink rates mbps uplink kbps 
correspond hybrid architecture hug 
database consists items kb size 
data size broadcast downlink capacities roughly items second 
assuming computing power server system pull capacity workload vary volume light rr heavy rr theta show behavior system different scales 
intend demonstrate assumptions discussed section approach performs close optimal exhibits high scalability 
significant performance property system response time depends size hot spot intensity workload 
results obtained ideal workload distribution 
show average response time function request rate rr 
size hot spot hs remained constant items values rr order highlight mentioned property 
contrast include performance pure pull system expected accommodate workloads higher capacity requests sec 
hand evident hybrid delivery approach scale workloads times heavier note horizontal axis logarithmic scale 
large values rr response time remains practically constant 
ideal separation hot cold data approach performs optimally matching theoretically minimum response time perfect server 
rr grows requests air cache hits average response time dominated performance hits 
obviously depends size hot spot size roughly equal half time takes broadcast 
load incurred air cache misses maintained pull capacity consistently yielding sub second responses 
order test system realistic workloads boundaries hot spot clearly defined performed set experiments gaussian distribution 
workload system parameters previous case 
results obtained fixed expanding hot spot sizes 
increasing values rr fixed hot spot achieved increasing accordingly skewness distribution decreasing standard deviation expanding hot spot constant standard deviation 
shows performance fixed hot spot see large workloads response time remains small 
time small distinguishable discrepancy system optimal 
reason system selected broadcast average items theoretical model suggest optimal 
artifact threshold sec 
urges adaptive algorithm slightly favor broadcasting 
contrary previous case algorithm detects outside optimal vapor set items hot considered promotion 
presents results experiment expanding hot spot 
baselines see optimal vapor set consequently optimal response time growing rr 
case system scales sense manages follow optimal performance closely 
tuning parameters section introduced important tuning parameters 
just keep system safe distance instability essentially knobs control adaptiveness overhead 
concentrate effects parameters 
established previous experiments selection dt dlv tan srb 
temperature probing introduced prevent detrimental consequences early vapor items needs carefully selected small big essentially probing effects probing 
section defined probing window dynamically adjusted average request rate vapor items 
way directly control number expected misses probe get average requests probe 
sec 
related probing carefully selected 
small value causes temperature vapor data drop quickly yielding frequent probing high overhead terms probed misses 
positive side small value allows system adapt faster changes demand 
large values opposite effect cause probing hinder adaptiveness system 
shows affects system performance different values 
experiment rest experiments gaussian access pattern rr requests sec hs items 
thing note probing system recover incorrect response time grows arbitrarily large 
small number probed misses sufficient correct temperatures vapor data allowing system operate close optimal 
increases volume probed misses 
rate happens depends frequency probing number items probed number vapor items 
point overhead probed misses big server handle leading slow responses 
words large probing causes problem supposed solve place 
naturally happens earlier probing frequent 
dynamic workloads set experiments dynamic workloads order evaluate adaptiveness system cases focus clients demand changes 
change modeled elimination hot spot generation new randomly selected part database 
process instant transient period tp minutes complete 
new hot spot persisted duration minutes 
easier interpretation results hot spots similar total workload remained constant 
obtained results function duration 
workload graphs dynamic left side smaller duration changes occur 
different values tp comparing fast white marks tp min gradual black marks tp min changes 
give results values cf cf determines adaptation speed system 
better comprehension results graph total average response time fig 
average response time pulled data fig 
average number vapor items fig 

experiments tan 
significant observation system adapts changing access patterns fig 

left side changes occur frequently response time remains small 
cases performance lies sec achieved static workload fig 

means server effective detecting shifts clients demand react promptly 
expected system adapts performs better smaller 
unexpected result shown system appears perform better abrupt changes tp min 
justified discuss system affected dynamic workloads 
changing hot spots performance impact pull fig 
push fig 
part system 
item suddenly hot generate large number requests server able react append air cache 
cumulative effect requests may cause significant build server input queue increase average response time pulled data 
build worse changes faster frequent 
see average pull response time increases changes occur left side hot spots heating faster white marks 
second transient periods server perceives hot spots old new 
order meet demand periods expand vapor set include 
explains average number vapor items increases duration decreases 
decreasing duration transient periods total time 
result server appears broadcasting average data 
note duration tp min workload continuously transient state server detects hot spots 
result size vapor set close double static case 
observe hot spot duration min cf tp min cf tp min cf tp min cf tp min hot spot duration min cf tp min cf tp min cf tp min cf tp min hot spot duration min cf tp min cf tp min cf tp min cf tp min dynamic workload phenomenon worse longer transient periods black marks server spends time broadcasting hot spots 
experiments average response time dominated broadcast accesses explains system appears perform better abrupt changes tp min 
notice effects adaptiveness system 
hand smaller value cf harms pull response time causes frequent probing misses fig 

hand limits unnecessary broadcasting reduces double hot spot phenomenon allows server detect faster loss interest vapor data fig 

consequently selected small causes tolerable probing overhead 
note probing overhead estimated controlled number vapor items 
possible employ self tuning strategy system 
words system monitor workload behavior results previous actions learn operating efficiently 
example series outcome may idea increase sample frequently 
strongest features approach proper combination parameters explicitly control fairly accurately adaptiveness system effectiveness probing incurred overhead 
related idea broadcasting pushing data information source large number receivers studied decade 
early done context systems aw won community information services gif specialized database machines bgh 
proliferation wireless communication mobile computing gained research ib fz commercial attention poi air 
terms research focus optimized broadcast schedules st optimized techniques data retrieval broadcast channel power efficiency considerations mobile environments ivb ivb 
hybrid data delivery employed boston community information system gif combined broadcast interactive communication provide tothe minute information entire metropolitan area 
prototype built field tested period years users 
major experiment users valued components hybrid architecture approach economic way building large scale information systems 
hybrid architecture proposed wd 
approach involved broadcast delivery periodically pushed request pulled data ad hoc partition data groups 
combination delivery modes considered 
particular augmented architecture broadcast disks allowing clients explicitly request data delivery broadcast channel 
explore efficacy back channel broadcast environment discuss involved trade offs 
closer adaptive techniques proposed iv 
iv proposes algorithm fairly static access probabilities assigns data bandwidth broadcast demand delivery modes way limits maximum expected response time predefined threshold 
consider mobility users cells cellular network propose variations adaptive algorithm statistically selects data broadcast user profiles registrations cell 
described adaptive technique hybrid data delivery takes advantage broadcast channels massive data dissemination unicast channels data demand satisfied 
discussed broadcast unicast synergistically yield high data service rates algorithm marginal gains broadcast probing broadcast content match hot spot database 
showed hot spot accurately obtained monitoring broadcast misses implicit knowledge actual usage broadcast data necessary 
major distinctions broadcast schemes dependent accurate comprehensive readily available statistics workload access patterns 
simulation experiments demonstrated scalability versatility proposed technique 
assumption server capacity sufficient servicing demand cold data performs close optimal 
important result performance hybrid system depends size hotspot volume workload 
shown adaptive scheme performs dynamic rapidly changing workloads 
adaptation speed incurred overhead explicitly tuned desired 
believe results far reaching implications suggest effective way deploying large scale wide area information systems 
lot interesting done near 
currently exploring different issues including client querying dealing data various sizes multi frequency broadcasting efficient indexing schemes overlapping data broadcast forecasting prefetching time data delivery 
acknowledgments michael franklin bj orn onsson flip korn yannis kotidis christos invaluable help 
bj orn semiautomatic results compiler proved great time 
acharya alonso franklin zdonik 
broadcast disks data management asymmetric communications environment 
proc 
acm sigmod conf pages may 
acharya franklin zdonik 
prefetching broadcast disks 
proc 
th intl 
conf 
data engineering pages february 
acharya franklin zdonik 
balancing push pull data broadcast 
proc 
acm sigmod conf pages may 
air 
live 
www com 
aw ammar wong 
design broadcast cycles 
perfomance evaluation december 
bg bell gemmell 
ramp prospects information dream 
cacm july 
bgh bowen gopal herman hickey lee mansfield 
architecture 
cacm dec 
datta kim kumar 
adaptive broadcast protocols support efficient energy conserving retrieval databases mobile computing environments 
proc 
th international conference data engineering pages april 
fz franklin zdonik 
dissemination information systems 
ieee data engineering bulletin september 
gifford baldwin berlin lucassen 
architecture large scale information systems 
proc 
th acm symposium operating system principles pages december 
gif gifford 
systems mass digital communications 
cacm feb 
herman gopal lee 
architecture high throughput database systems 
proc 
acm sigmod conf may 
hug hughes network systems 

www com 
ib imielinski badrinath 
wireless mobile computing challenges data management 
cacm october 
iv imielinski vishwanathan 
adaptive wireless information systems 
proc 
conf tokyo japan october 
ivb imielinski viswanathan badrinath 
energy efficient indexing air 
proc 
acm sigmod conf pages may 
ivb imielinski viswanathan badrinath 
power efficient filtering data air 
proc 
edbt conf pages march 
kb katz brewer 
case wireless overlay networks 
spie multimedia networking conference san jose ca january 

broadband home architectures access methods 
ieee network jan feb 
neil neil weikum 
lru page replacement algorithm database disk buffering 
proc 
acm sigmod conf pages may 
poi network 
www com 
rd robinson 
data cache management frequency 
acm sigmetrics conf pages may 
srb roussopoulos 
adaptive data broadcasting air cache 
st intl 
workshop satellite information services november 
srb roussopoulos 
adaptive data broadcast hybrid networks 
technical report institute systems research univ maryland apr 
st su tassiulas 
broadcast scheduling information distribution 
ieee infocom apr 
wd wong 
architecture performance large scale information delivery networks 
th intl 
teletraffic congress torino italy 
won wong 
broadcast delivery 
proceedingsof ieee december 
