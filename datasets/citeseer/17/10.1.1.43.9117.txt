parallel execution multiple pipelined hash joins hui hsiao ming chen philip yu ibm thomas watson research center box yorktown heights ny email watson ibm com study parallel execution multiple pipelined hash joins 
specifically deal issues processor allocation hash filters improve parallel execution hash joins 
scheme transform bushy execution tree allocation tree node denotes pipeline 
processors allocated nodes allocation tree concept synchronous execution time inner relations hash tables pipeline available approximately time 
addition approach hash filtering investigated improve performance 
performance studies conducted simulation demonstrate importance processor allocation evaluate various schemes hash filters 
simulation results indicate processor allocation allocation tree significantly outperforms original bushy tree effect hash filtering prominent number relations query increases 
parallelism recognized powerful costeffective means execute complex database operations imperative develop efficient solution procedures handle multi join queries parallel database systems 
query plan usually compiled tree operators called join sequence tree leaf node represents input relation internal node represents resulting relation joining relations associated child nodes 
categories query trees left deep trees right deep trees bushy trees called linear execution trees sequential join sequences 
significant amount research efforts elaborated developing join sequences improve query execution time 
reported explore sequential join sequences results reported sequential join sequences 
owing technology advances attracted increasing amount attention explore bushy trees parallel query processing 
combination analytical experimental results shed light complexity choosing left deep bushy trees 
integrated approach dealing intra operator inter operator parallelism greedy scheme various join methods corresponding costs consideration proposed 
heuristic approach deals query plan tree effective resource assignments bottom manner 
approach handle join sequence scheduling processor allocation parallel query processing devised 
hierachical approach proposed schedule execution multiple queries 
addition various query plans processing multi join queries shared architecture studied 
various join methods hash join focus research effort reported performance superior particularly presents opportunity pipelining 
pipeline hash joins composed stages associated join operation executed parallel processors 
stage inner relation build hash table 
pipelining shown effective reducing query execution time prior studies pipelined hash joins focused mainly heuristic methods query plan generation 
prior query plan generation static right deep scheduling dynamic bottom scheduling segmented right deep trees zigzag trees resorted simple heuristics allocate processors pipeline stages 
shown sort merge joins execution bushy trees outperform linear trees especially number relations query large 
far hash join concerned scheduling execution plan bushy tree structure complicated right deep tree structure 
particularly difficult achieve synchronization required execution bushy trees effect pipelining fully utilized 
reason prior studies pipelined hash joins focused right deep trees 
explore important issues processor allocation hash filters improve parallel execution hash joins 
note exploit opportunity pipelining hash join execution naturally identify execute group hash joins bushy tree way pipelining 
seen regrouping joins advantage pipelining execution dependency bushy tree intractable turn causes problem processor allocation complicated 
remedy devise scheme transform bushy execution tree allocation tree node denotes pipeline 
concept synchronous execution time processors allocated nodes allocation tree way inner relations pipeline available approximately time solving execution dependency parallel execution pipelined hash joins 
note method devised cope processor allocation execute multiple pipelines parallel confused processor allocation pipeline studied 
addition approach hash filtering investigated improve query execution time 
study hash filters improve execution joins 
note depending cost benefit hash filters various schemes determine hash filter generation 
performance studies detailed simulation conducted demonstrate importance processor allocation evaluate different schemes hash filters 
simulation results show processor allocation allocation tree significantly outperforms original bushy tree showing advantage performing proposed tree transformation deal execution dependency means pipeline performed input relations available 
processor allocation pipelined hash joins 
schemes hash filtering evaluated build hash filters inner relations emerges winner 
experimentally shown processor allocation general dominant factor performance effect hash filtering prominent number relations query increases 
rest organized follows 
preliminaries section 
schemes processor allocation hash filtering section 
section describes underlying system cost model 
performance studies various schemes conducted section simulation 
concludes section 
preliminaries jr denote cardinality relation jaj denote cardinality domain attribute query assumed form conjunctions equi join predicates 
focus execution complex queries queries involving relations 
notice complex queries frequent real applications due views 
architecture assumed performance study section multiprocessor system distributed memories shared disks containing database data 
barring tuple placement skew scheme developed applicable shared architecture disk accessible single node 
pipeline hash joins composed stages associated join operation 
relation hash join loaded memory build hash table called inner relation relation tuples probe hash table called outer relation 
detailed description advantage pipelined hash joins 
cpu costs executing query considered study 
cpu cost determined pathlength total number tuples processed multiplied number cpu instructions required processing tuple 
parameter cpu speed mips compute cpu processing time number cpu instructions incurred 
cost processing query determined disk service time page multiplied total number page 
appropriately vary cpu speed take consideration cpu bound bound query processing study impact processor allocation hash filtering cases 
detailed description cost hash joins system parameters section 
addition set application 
example hash filters 
assume simplicity values attributes uniformly distributed tuples relation values attribute independent 
cardinalities resulting relations joins estimated formula prior 
presence data skew modify corresponding formula accordingly affect relative performance schemes evaluated 
hash filter hf built relation attribute denoted hf array bits initialized 
set distinct values attribute corresponding hash function employed 
th bit hf set exists similar effect seen joining common attribute probing tuples hf removing non matching tuples reduce number tuples participate join 
join cost reduced 
illustrative example hash filters hf built applied corresponding hash function mod 
verified application hf reduced reducing join cost shall develop efficient scheme interleave bushy execution tree hash filters minimize query execution cost hash joins 
denote application hash filter generated attributed note reduction proportional reduction 
estimation size relation reduced similar estimating reduction projection corresponding attribute 
ae reduction ratio application cardinality estimated ae jr clearly determination ae depends size hash filter shown different attribute values may hashed hash entry 
pointed hashing jr different values hash filter bits similar experiment drawing balls different balls replacement 
proposition determine effect hash filters simulation follows 
proposition reduction ratio application ae formulated ae gamma gamma jr jaj jr jaj jaj set distinct values attribute number hash entries hash filter 
addition analysis assume number distinct values non filtered attribute remains hash filter application study 
algorithmic aspects section shall derive processor allocation scheme introduce methods generate hash filters bushy execution tree 
deriving utilizing allocation trees mentioned earlier exploit opportunity pipelining hash join execution identify execute sequence hash joins bushy tree way pipelining 
regrouping joins execution dependency bushy tree intractable 
consequently shall transform bushy execution tree allocation tree node denotes pipeline 
concept synchronous execution time processors allocated nodes allocation tree way inner relations pipeline available approximately time 
idleness processors minimized 
transform bushy tree allocation tree identify groups joins bushy tree pipelined 
allocation tree obtained original bushy tree merging group joins 
example suppose determine groups joins pipelined shown 
merging pipeline single node obtain corresponding allocation tree 
determine number processors allocated node pipeline allocation tree manner top 
clearly processors allocated pipeline associated root allocation tree say pipeline performed 
processors allocated pipeline root partitioned clusters assigned execute pipelines associated child nodes root allocation tree way pipelines completed approximately time 
words processors allocated input relations root pipeline say available time facilitate execution step partitioning processors root applied internal nodes allocation tree top manner pipeline assigned number processors 
specifically define cumulative execution costs node allocation tree sum execution costs pipelines subtree internal node 
pipeline associated node allocation tree ta set child nodes ta denote cost executing 
cumulative execution cost node denoted cw determined cw cw note cumulative execution cost pipeline determined original bushy tree built bottom 
important see achieve synchronous execution time partitioning processors node clusters child nodes take account cumulative execution costs child nodes individual execution costs 
denote set processors allocated perform pipeline represent number processors 
cw cw formally processor allocation scheme allocation tree described 
algorithm allocating processors bushy tree utilizing pipelined hash joins 
identifying pipelines bushy tree 
illustration allocation tree 
step join sequence heuristic applied determine bushy execution tree step bushy tree determine corresponding allocation tree ta merging relations pipeline 
step eq determine cumulative workload node ta bottom manner 
step eq allocate processors node ta top manner 
illustrative purpose total processors possible processor allocation allocation tree shown set numbers labeled nodes tree 
mentioned earlier numbers determined child nodes pipelines internal node completed approximately time 
worth mentioning number processors passed internal node lower level tree partitioned efficient execution pipelines sequential execution pipelines child nodes employed better performance 
note method described determine inter pipeline processor allocation execute pipelined hash joins 
clearly distribute processors stages pipeline important issue discussion scope 
readers interested processor allocation pipeline referred 
seen section processor allocation allocation tree outperforms original bushy tree 
result indicates difference pipelined hash join sort merge join far processor allocation concerned justifies necessity performing proposed tree transformation deal processor allocation pipelined hash joins 
interleaving bushy tree hf improve parallel execution hash joins employ hash filters reduce cost individual join 
note hash filter received time processing difficult achieve due nature parallel execution hash joins 
seen processor allocation algorithm meaning pipeline higher level allocation tree executed processors allocated offspring 
feature resolves timing constraint described processor allocation hash filter received late applied pipeline executed cluster processors avoiding incurring transmission hash filters processors 
methods conceivable generate hash filters 
example method generate apply hash filters bushy tree proceed normal execution 
scheme termed early generation denoted follows algorithmic form described 
algorithm interleaving bushy tree hf 
hf sender leaf node relation pipeline att set join attributes att oe scan att build hf 
send hf contains relation joining hf receiver leaf node receives hf join attributes applies hf filter non matching tuples 
inner relation building hash table starting tuple probing inner relations available 
conditional statement hf sender set att assures necessary hash filters generated applied relations 
seen relation scanned build hf attributes att relation receiving utilizing filters starts normal operations 
depending cost benefit hash filters schemes determine hash filter generation 
provide insights approach hash filtering extensive simulation conducted section evaluate various schemes hash filters 
owing nature hash joins generated advance hash filters built hash join operations reduce overhead associated 
specifically hash filters inner relations built phases outer relations built tuple probing phases 
approach referred scheme cg cg stands complete generation 
evaluated section hash filters generated inner relations reduce cost hash filter generation attaining desired reduction effect 
alternative denoted ig standing inner relation generation 
conventional approach hash filters denoted nf hash filters implemented comparison purposes 
system cost model section describe underlying system cost model experiments conducted study relative performance various processor allocation hash filtering schemes 
overview architecture assumed study multiprocessor system distributed memories shared disks containing database data 
assumed processor activates process relation scan read portion relation disk 
goal evaluate performance processor allocation hash filtering schemes variety complex query environments 
performance model consists major components request generator compiler executor 
request generator responsible generating query requests follows 
number relations query determined input parameter sn 
relation cardinalities join attribute cardinalities determined set parameters card card 
relation cardinalities query computed distribution function mean card deviation 
cardinalities join attributes determined similarly card 
predetermined probability edge join operation exists relations query graph 
larger larger number joins query 
note queries generated may disconnected query graphs 
loss generality queries connected query graphs study disconnected graphs discarded 
compiler takes query request request generator produces query plan form bushy tree 
bushy plan tree determined minimum cost heuristic described tries perform join minimal cost 
executor traverses query plan tree carries join operations parallel join sequence determined compiler 
depending hash filtering schemes simulated hash filters join attributes generated different stages query execution 
generated base relations hash filters applied base relations intermediate relations 
generated hash filter sent nodes processors perform join operation pipeline containing corresponding relation 
hash filter received applied corresponding base relation filter received start relation scan 
filter received usually applied intermediate relation generated pipelined join operation 
worst case hash filter may received time applying base intermediate relation case hash filter discarded 
dynamic nature bushy tree execution captured simulation 
pipelined hash join operation tuple outer relation successively probe hash tables multiple inner join relations pipeline pipelined join operation start inner relations pipeline completed building hash tables memory 
minimize processor idle time maximize performance benefit parallel query execution processors allocated joining relations way table building phase inner relations pipeline completed approximately time 
achieve number processors allocated join node determined top manner processors assigned parent node divided child nodes cumulative execution costs child nodes 
simulation model processor allocation done part query compilation 
query plan node experiment contains number processors allocated execute node addition information database profile 
note practice allocation processors join node deferred runtime provide flexibility 
schemes assigning processors join nodes comparatively studied 
scheme cumulative execution cost computed node query plan tree generated compiler 
processors allocated execute query plan node cumulative execution cost node 
scheme cumulative execution cost node computed sum execution cost joining relations associated child nodes plus cumulative execution costs child nodes described section 
cumulative execution cost leaf node defined cost scanning base relation 
henceforth shall refer processor allocation scheme bot standing original tree scheme 
second scheme grouping join nodes pipeline query plan tree transformed allocation tree 
cumulative workload computed node allocation tree processors allocated nodes allocation tree 
processor allocation scheme henceforth referred bat standing allocation tree scheme 
cost model model computes cpu costs executing query 
ease presentation assume node processor large physical memory hold hash tables inner relations pipeline memory time bucket overflow occur 
effect bucket overflow believed affect relative performance processor allocation schemes shall evaluate 
intermediate relation generated completed pipelined join operation assumed written disks 
intermediate relation pipelined join operation read disks time hash table corresponding join attribute built memory 
number cpu instructions executed read data page disk denoted read write data page disk denoted write cost extracting tuple page memory denoted tuple cost building hash table determined multiplying total number tuples processed number cpu instructions tuple needs table building build 
similarly cost probing hash table determined multiplying total number tuples processed number cpu instructions tuple needs tuple probing probe 
total cpu cost building hash table memory relation tuples including cost reading relation disks extracting tuples pages equal read theta size tuple theta build theta size number tuples page 
cpu cost carrying tuple probing phase join operation outer relation size tuples equal probe thetan independent inner relation size consequently execute pipeline joins total cpu cost equal size theta read theta tuple theta build theta probe inner relation size th join size outer relation join operation denotes outer probing relation size th join operation pipeline 
equal size result relation generated gamma th join pipeline 
note cost include intermediate relation disks pipelined join 
cost equal pn size theta write instructions added cpu cost listed pipelined join operations pipeline produces final result query 
cpu processing time executing query obtained dividing total number cpu instructions query cpu speed speed separating pathlength query cpu speed flexibility varying cpu speed query execution cpu bound bound studying impact hash filters cases 
cost reading respectively writing relation tuples determined disk service time page pio multiplied total number page read respectively written 
execute pipeline joins relations read disks total cost reading relations equal size theta pio intermediate relation generated pipelined join disks pipeline produces final result 
increases cost amount pn size theta pio pn denotes size result relation generated th join pipeline 
schemes generate apply hash filters cpu cost generating hash filter relation size computed multiplying hash cost applying hash filter relation size computed multiplying apply hash number cpu instructions required generate hash value input tuple set corresponding bit hash filter apply number instructions needed check attribute value tuple match filter bit set add tuple temporary relation joined 
note hash filter generation phase combined base relation scan join operation avoiding overhead hash filter generation ig cg schemes 
hand hash filters generated separated phase prior start join operation query scheme size additional relation required 
worth mentioning simulation model hash filters implemented bit vectors general fit memory minimizing extra required maintaining 
parameter setting select queries sizes queries relations 
set selections covers wide spectrum query sizes ranging simple way join way join 
query size query graphs generated mentioned section queries connected query graphs study 
conduct simulation referenced determine values simulation parameters 
table summarizes parameter settings simulation 
number processors system set speed processor assumed mips 
number cpu instructions reading writing page set extracting tuple page memory set 
applying hash function attribute build hash table hash filter assumed take instructions probing hash table probing hash filter filter non matching tuples assumed consume instructions 
page assumed contain tuples disk service time page read write assumed milliseconds 
size relation varies tuples attribute distinct parameters setting speed mips read write tuple build prob hash apply size tuples pio ms card tuples card sigma sigma uniform uniform table parameters simulation 
values 
distribution functions relation cardinality attribute cardinality assumed uniform 
simulation results simulation program coded action individual relation go join operation corresponding hash filter generation application simulated 
query simulation hash filtering schemes nf filter early generation ig inner generation cg complete generation applied execute query 
cpu cost cost total response time scheme obtained 
experiment carried stages 
stage studied relative performance different processor allocation schemes 
specifically explored benefit terms reduction query response time allocating processors join nodes allocation tree bat parallel database environment 
second stage fixed processor allocation scheme bat ran set experiments study relative performance different hash filtering schemes 
processor allocation exp processor allocation schemes performance bot bat processor allocation response time scheme nf number relations query original tree allocation tree response time nf scheme 
schemes evaluated experiment set number processors set 
number processors allocated execute join node determined processor allocation scheme employed 
shows average response times queries nf method bot bat allocation schemes 
deliberately turned hash filter application experiment demonstrate importance processor allocation multi processor database systems 
ordinate response time milliseconds abscissa denotes number relations query 
illustrated response time bat significantly lower bot queries evaluated clearly showing advantage performing proposed tree transformation 
bot scheme average response time join query involving relations sn seconds seconds case sn 
employing tree transformation processor allocation average response times sn sn bat reduced seconds seconds respectively showing improvement 
experiment shows bot processor allocation scheme demonstrated provide performance sort merge join methods perform pipelined hash join method 
note pipelined hash join join operation start hash tables pipeline materialized memory 
advantageous allocate processors join nodes way inner relations materialized time 
clearly achieved tree transformation devised section groups inner relations pipeline considers processor allocation 
nature pipelined hash joins consideration bat leads significantly better performance bot scheme 
hf schemes second stage simulation study processor allocation scheme fixed bat due superiority bot 
goal study effectiveness alternative hf schemes queries varying complexity 
described section scheme generates hash filters base relations start actual join operation applies hash filters base relations join operations 
scheme provides maximum reduction effect hash filtering hash filters available applied start join operation 
incurs highest overhead needs go extra round disk read base relations disks order generate hash filters 
ig designed minimize overhead associated hash filter generation cg designed maximize effect hash filtering 
ig hash filters generated inner base relations generated time inner relations read disks build hash tables memory 
consequently extra incurred ig overhead applying hash filter minimized 
cg hash filters generated base relations 
cg generates hash filters relation relation joined extra incurred 
note hash filters outer relations generated cg relations joined filters received time partner relations 
result generating number hash filters cg general applies fewer hash filters 
shown despite fewer applications hash filters cg outperform due timely generation hash filters better filtering effect saving cost 
exp low variance experiment relation cardinality ranges tuples attribute cardinality ranges 
average cpu cost cost response time experiment shown figures respectively 
figures show mips cpu queries pipelined hash join method bound 
ms page time setting assumes prefetching disk buffering reading track time 
experiment assumes process activated pro cpu cost number relations query nf ig cg cpu cost scheme 
io cost number relations query nf ig cg io cost scheme 
cessor relation scan 
note experiment cpu bound disk buffering parallel strategy activate multiple processes processor relation scan 
shows applying hash filters results significantly larger cpu cost method 
seen cpu cost cg slightly larger nf 
ig consumes approximately amount cpu resource nf 
experiment shows far cpu cost concerned benefit applying hash filter size reduction overshadowed cost generating applying hash filters cg 
note bucket overflow cpu cost hash join linearly proportional size input relations 
simulation assume intermediate relations disks pipelined join bucket overflow occur 
conse response time number relations query nf ig cg average response time scheme 
quently benefit reduction intermediate relation size appears pipelined join resulting smaller benefit applying hash filter 
intermediate relations disks applying hash filter favorable 
shows applying hash filters results slight performance improvement cost sn small sn 
improvement increases significantly number relations query increases 
number pipelines increases sn increases explained earlier benefit size reduction prominent 
seen cg performs best schemes evaluated nf outperformed schemes 
previously described cg ig incurs overhead generating applying hash filters 
hash filters generated applied cg size intermediate relation cg average smaller ig 
consequently cg provides lowest cost schemes evaluated ig second lowest 
applies hash filters schemes achieves maximum reduction effect 
scans base relations extra time build hash filters 
result total cost lower nf larger ig cg 
shows case sn total query response time reduced applying hash filters 
sn performance ig cg similar nf 
response time increases compared nf 
sn response time reduced response time original tree number relations query nf ig cg average response time scheme pn 
related nf ig cg improvement 
result clearly demonstrates ig cg effective methods reduce response time complex query execution pipelined hash join method especially sn large 
experiment shows extra system resource consumed outweighs benefit size reduction sn 
sn greater shows performance improvement nf reduction response time limited 
shows response time queries hf schemes bot processor allocation scheme 
indicated ig remains best scheme evaluated improvement nf response time sn 
compared shows benefit applying hash filter smaller bot bat 
bot processor idle time waiting peers complete preceding join operations contributes significant portion total response time result saving join execution time applying hash filter significant 
exp high variance experiment increased variance relation cardinality variance attribute cardinality 
changing variances relation attribute cardinalities effectiveness hash filters hash join operations varied cardinalities studied 
figures show respectively cpu cost cost response time scheme 
similar cpu cost number relations query nf ig cg cpu cost scheme high variance 
io cost number relations query nf ig cg io cost scheme high variance 
shows consumes cpu resource nf ig 
hand shows sn nf consumes disk resource cg 
indicated sn ig cg generate noticeable performance improvement nf 
sn applying hash filters improve response time ig scheme 
compared results exp figures indicate effectiveness applying hash filter stable variances relation cardinalities attribute cardinalities increase 
experiment shows ig best scheme schemes evaluated cg second 
explored important issues processor allocation hash filters improve response time number relations query nf ig cg average response time scheme high variance 
parallel execution hash joins 
performance studies conducted demonstrate importance processor allocation evaluate various schemes hash filters simulation 
simulation results showed processor allocation allocation tree significantly outperformed original bushy tree 
schemes hash filtering evaluated build hash filters inner relations emerged winner 
experimentally shown processor allocation general dominant factor performance effect hash filtering prominent number relations query increases 
bitton gray 
disk shadowing 
proceedings th international conference large data bases pages september 
boral alexander prototyping bubba highly parallel database system 
ieee transactions knowledge data engineering march 

chen 
hsiao yu 
applying hash filters improving execution bushy trees 
proceedings th international conference large data bases pages august 

chen 
lo yu young 
segmented right deep trees execution pipelined hash joins 
proceedings th international conference large data bases pages august 

chen yu 
wu 
scheduling processor allocation parallel execution multi join queries 
proceedings th international conference data engineering pages february 
dewitt gerber 
multiprocessor hash join algorithms 
proceedings th international conference large data bases pages august 
dewitt ghandeharizadeh schneider hsiao rasmussen 
gamma database machine project 
ieee transactions knowledge data engineering march 
dewitt gray 
parallel database systems high performance database systems 
comm 
acm june 
ganguly hasan krishnamurthy 
query optimization parallel execution 
proceedings acm sigmod pages june 
puech 
effect join operations relation sizes 
acm transactions database systems december 
hong stonebraker 
optimization parallel query execution plans xprs 
proceedings st conference parallel distributed information systems pages december 

hsiao dewitt 
performance study high availability data replication strategies 
proceedings st conference parallel distributed information systems pages december 
hua 
lo young 
including load balancing issue optimization multi way join queries shared database computers 
proceedings nd conference parallel distributed information systems pages january 
ioannidis kang 
left deep vs bushy trees analysis strategy spaces implication query optimization 
proceedings acm sigmod pages may 

lo 
chen ravishankar yu 
optimal processor allocation support pipelined hash joins 
proceedings acm sigmod pages may 
lu 
shan 
tan 
optimization multi way join queries parallel execution 
proceedings th international conference large data bases pages september 
lu tan 
shan 
join algorithms multiprocessor computers shared memory 
proceedings th international conference large data bases pages august 
roussopoulos kang 
pipeline join algorithm way semijoin program 
ieee transactions knowledge data engineering december 
schneider 
complex query processing multiprocessor database machines 
technical report tech 
rep computer science department university wisconsin madison september 
schneider dewitt 
performance evaluation parallel join algorithms shared multiprocessor environment 
proceedings acm sigmod pages 
schneider dewitt 
tradeoffs processing complex join queries hashing multiprocessor database machines 
proceedings th international conference large data bases pages august 
selinger astrahan chamberlin lorie price 
access path selection relational database management system 
proceedings acm sigmod pages 
srivastava 
optimizing queries parallel relational databases 
proceedings nd conference parallel distributed information systems pages january 
stonebraker katz patterson ousterhout 
design xprs 
proceedings th international conference large data bases pages 
swami 
optimization large join queries combining heuristics combinatorial techniques 
proceedings acm sigmod pages 
wilschut apers 
dataflow query execution parallel main memory environment 
proceedings st conference parallel distributed information systems pages december 
wolf turek 
chen yu 
scheduling multiple queries parallel machine 
proceedings acm sigmetrics conference may 
zait 
parallel query processing dbs 
proceedings nd conference parallel distributed information systems pages january 
