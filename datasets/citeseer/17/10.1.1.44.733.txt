functional programming january fl cambridge university press algorithm strategy parallelism trinder department computing science university glasgow glasgow uk hammond division computing science university st andrews st andrews uk 
loidl peyton jones department computing science university glasgow glasgow uk process writing large parallel programs complicated need specify parallel behaviour program algorithm compute result 
introduces evaluation strategies lazy higher order functions control parallel evaluation non strict functional languages 
evaluation strategies possible achieve clean separation algorithmic behavioural code 
result enhanced clarity shorter parallel programs 
evaluation strategies general concept shows model wide range commonly programming paradigms including conquer pipeline parallelism producer consumer parallelism data oriented parallelism 
unrestricted higher order functions capture irregular parallel structures 
evaluation strategies just theoretical interest evolved experience parallelising large scale parallel applications proved invaluable helping manage complexities parallel behaviour 
applications described detail 
largest application studied date lolita line natural language parser 
initial results show programs achieve acceptable parallel performance incurring minimal overhead evaluation strategies 
writing parallel programs hard write sequential programs considerably harder write parallel ones 
glasgow worked fairly large parallel programming projects slowly painfully developed methodology parallelising sequential programs 
essence problem facing parallel programmer addition specifying value program compute explicitly parallel programs supported uk epsrc engineering physical science research council aqua parade 
trinder specify machine organise computation 
aspects parallel execution program threads created execute processor transfer data remote processors synchronise threads 
managing aspects top constructing correct efficient algorithm parallel programming hard 
extreme rely compiler runtime system manage parallel execution programmer input 
unfortunately purely implicit approach fruitful large scale functional programs interested 
promising approach adopted researchers delegate management tasks runtime system allow programmer opportunity give advice critical aspects 
approach adopted glasgow parallel haskell gph simple extension standard non strict functional language haskell peterson support parallel execution 
gph runtime system manages parallel execution requiring programmer indicate values usefully evaluated parallel threads basic execution model lazy extent values evaluated 
term aspects program dynamic behaviour 
simple parallel programming model find code inserted order obtain better parallel performance 
realistic programs algorithm entirely obscured code describing dynamic behaviour 
evaluation strategies evaluation strategies lazy higher order functions separate concerns specifying algorithm specifying program dynamic behaviour 
function definition split parts algorithm strategy graph reduction allowing values defined manipulated 
algorithmic code consequently uncluttered details relating parallel behaviour 
primary benefits evaluation strategy approach similar obtained laziness separate different parts sequential algorithm hughes separation concerns algorithm dynamic behaviour easier comprehend modify 
evaluation strategies written language algorithm desirable properties 
ffl strategies powerful simpler strategies composed passed arguments form elaborate strategies 
ffl strategies defined types language 
ffl strategies extensible user define new application specific strategies 
ffl strategies type safe normal type system applies strategic code 
ffl strategies clear semantics precisely algorithmic language 
algorithm strategy parallelism evaluation strategies implemented gph number large scale parallel programs including data parallel complex database queries divide conquer linear equation solver pipelined natural language processor lolita 
lolita large comprising lines haskell 
experience shows strategies facilitate top parallelisation existing programs 
structure remainder structured follows 
section describes parallel programming gph 
section introduces evaluation strategies 
section shows strategies specify common parallel paradigms including pipelines producer consumer divide conquer parallelism 
section discusses strategies large scale applications 
section discusses related 
section concludes 
introducing parallelism parallelism introduced gph par combinator takes arguments evaluated parallel 
expression par haskell infix operator notation value dynamic behaviour indicate evaluated new parallel thread parent thread continuing evaluation say sparked 
thread necessarily created similar lazy mohr 
note par differs parallel composition process algebras csp hoare ccs milner asymmetric operation new parallel task created 
control sequencing important parallel language roe introduce sequential composition operator seq 
expression seq value 
corresponding dynamic behaviour evaluate weak head normal form whnf returning 
par seq projection functions vulnerable altered optimising transformations care taken compiler protect 
implementation compositions described fully trinder 
simple divide conquer functions consider parallel behaviour simple divide conquer program 
greater sparked thread continues evaluate 
shows process diagram execution 
node diagram function application arc data value case integer communicate invocations 
note seq higher precedence par 
trinder fig 

divide conquer process diagram par seq parallel quicksort realistic example write attempt introduce parallelism 

xs par par xs xs intention threads created sort lower higher halves list parallel combining results 
unfortunately parallelism threads gph terminate sparked expression whnf 
consequence threads sparked construct little useful terminating creating cons cell 
threads perform useful forcing function 
resulting program desired parallel behaviour process network similar complete lists communicated integers 

xs seq xs algorithm strategy parallelism parmap xn xn 
fig 

parmap process diagram xs par par xs xs data oriented parallelism quicksort examples divide conquer control oriented parallelism subexpressions function identified parallel evaluation 
parallelism alternative approach elements data structure evaluated parallel 
parallel map useful example data oriented parallelism example parmap function defined applies function argument element list parallel 
parmap 


parmap parmap xs fx par seq fx fx parmap xs definition works follows fx sparked recursing list returning constructor result list element sparked 
process diagram parmap 
function argument supplied parmap constructs data structure composed forcing function order ensure data structure constructed parallel 
evaluation degree parallelism dynamic behaviour examples show parallel function describe algorithm important aspects parallel machine organise trinder computation function dynamic behaviour 
gph components dynamic behaviour ffl parallelism control specifies threads created order par seq 
ffl evaluation degree specifies evaluation thread perform 
examples forcing functions describe evaluation degree 
evaluation degree closely related strictness 
evaluation degree value function program strictness value parallelism conservative expression reduced parallel program reduced lazy counterpart 
programs useful evaluate values speculatively 
evaluation degree may usefully strict lazy function 
examples code describing algorithm dynamic behaviour intertwined consequence opaque 
larger programs carefully tuned parallelism problem far worse 
strategies separate algorithm dynamic behaviour driving philosophy evaluation strategies possible understand semantics function considering dynamic behaviour 
evaluation strategies evaluation strategy function specifies dynamic behaviour algorithmic function 
order allow evaluation strategies specify degree algorithmic function result evaluated parameterised result algorithmic function 
strategy purpose define dynamic behaviour defined return unit type 
type strategy 
strategies controlling evaluation degree simplest strategies introduce parallelism specify evaluation degree 
simplest strategy termed performs reduction 
surprisingly useful evaluating pair element evaluated second 
strategy reduction whnf default evaluation degree gph strategy reduce value type whnf easily defined rwhnf strategy rwhnf seq algorithm strategy parallelism data value function value reduced normal form nf rnf 
wish define rnf operation list values type obvious solution haskell type class overload rnf operation 
nf whnf coincide base types integers booleans default method rnf rwhnf 
constructed types instance declared specifying reduce value type normal form 
instance relies element type class 
consider lists pairs example 
class rnf strategy rnf rwhnf instance 
rnf rnf xs rnf seq rnf xs instance 
rnf rnf seq rnf strategies strategy applied function 
expression projection retraction defined idempotent 
function defined lower precedence operator 

strategy 
seq note seq definition allows control timing results 
example sequential version quicksort return part result entire list sorted 
significant sort formed part pipeline example 
xs rnf xs xs combining strategies evaluation strategies just normal higher order functions combined full power language passed parameters composed function composition operator 
strategies seq par 
useful strategies higher order example strategy sequentially applies strategy element list 
strategy evaluates just spine list trinder rwhnf evaluates element list whnf 
analogous functions constructed type 
strategy 
strategy strat strat xs strat seq strat xs parallel strategies strategy specify parallelism sequencing evaluation degree 
strategies specifying control oriented parallelism par seq specify subexpressions function evaluated parallel order 
quicksort uses divide conquer control oriented parallelism version evaluation degree specified rnf 
subexpressions selected parallel evaluation xs strategy xs xs strategy result rnf par rnf par rnf result strategies specifying data oriented parallelism describe dynamic behaviour terms data structure 
example parlist similar applies strategy element list parallel 
parlist strategy 
strategy parlist strat parlist strat xs strat par parlist strat xs strategic functions particularly elegant result data structure describes parallelism 
parallel map just function parmap strategy 



parmap strat xs map xs parlist strat strat parameter determines dynamic behaviour element result list parmap parametric dynamic behaviour 
strategic functions viewed dual algorithmic skeleton approach cole 
relationship discussed section 
evaluation strategies parallel paradigms section demonstrates flexibility evaluation strategies showing express common parallel paradigms 
cover data oriented divide andconquer producer consumer pipeline parallelism 
algorithm strategy parallelism data oriented parallelism data oriented paradigm elements data structure evaluated parallel 
complex database queries realistic examples data oriented parallelism parmap 
basis query relation parts indicating part zero 
task list component parts part including sub components components 
date 
main sub quantity component component naive function explode lists components single part main 
full program generates bill material relation list tuples explodes sequence part numbers printing number parts explosion 
explode parts main parts main explode parts lo hi map length bom generate map explode bom lo hi program inherently data parallel explosion part dependent explosion part 
constructing bill material memory atypical query program realistic program read disk 
reason construction generate 
bill exists parts exploded parallel 
dynamic behaviour specified adding strategy lo hi map length strat bom generate map explode bom lo hi strat result rnf bom seq parlist rnf easy modify algorithm strategy changing algorithm may entail specifying new dynamic behaviour 
easy modify trinder strategy changing algorithm 
example calculate lengths parallel simply add seq parlist result strategy 
divide conquer parallelism divide conquer probably best known parallel programming paradigm 
problem solved decomposed smaller problems solved parallel recombined produce result 
example taken parallel linear equation solver wrote realistic medium scale parallel program loidl structure described section 
specification determinant square matrix ffl matrix jn ffl compute jn gamma det cancelling row column sum lpar parlist rnf lpar map determine jlo jhi determine pivot sign pivot det spar sign sign jlo pivot head mat 
mat jlo ihi jhi map newline tail mat det determinant mat parlist rwhnf mat seq det par comparison appendix contains sequential directly parallel versions function 
sight may obvious divide conquer program 
crucial observation determinant matrix size computed terms determinants matrices size 
strategy parlist rnf specifies determinant matrices size calculated parallel 
strategies determine 
spar sign specifies sign determinant calculated parallel conditional spar strategy corresponding par 
par spar 
pivot non zero second strategy 
specifies sub matrix mat constructed parallel determinant computed parallel result 
producer consumer parallelism common paradigm process consumes data structures produced process 
compiler example optimising phase consume algorithm strategy parallelism print fig 

producer consumer process diagram parse tree produced parser 
data structure thought buffer producer fills consumer empties 
simplicity assume buffer represented list consider just alternatives place buffer place buffer 
possible ways express producer consumer parallelism example order improve granularity producer compute element chunk list just single value 
place buffer order fill place buffer head demanded producer immediately evaluate second element 
effect producer speculatively assumes element list computation 
gives parallel behaviour free processor producer thread construct second element consumer consuming 
parallelism result time produce element similar time consume 
second element list acts element buffer 
simple function eagerly produces extra prime number eratosthenes algorithm 
uses simple strategy evaluate second element list parallel haskell lists enumerated parameter 
process diagram producer consumer parallelism simple producing process communicating buffer consumer 
show diagram program prints result invocation int 
strategy 
strategy strat xs null rest strat head rest par rest drop xs xs xs mod rwhnf place buffer provide place buffer producer initially evaluate elements head buffer list demanded evaluate nth element 
effect producer eagerly fills element buffer 
evaluating elements list parallel easily specified analogous 
unfortunately constructing nth element time head demanded specified strategy independent result 
strategy generating rest result built result 
function semantics identity lists dynamic behaviour spark nth element demanded 
trinder map map fac map fib fig 

pipeline process diagram analogous 
example database query function maps explode function range elements list 
list explosions acts element buffer 
integral 

strategy 
strategy strat strat xs strat xs strat par strat xs integral 

strategy 

strat strat rs strat rs par strat rs lo hi bom rnf result rnf result map explode bom lo hi pipelines pipelined parallelism sequence stream processing functions composed consuming stream values constructed previous stage producing new values stage 
generic pipeline combinator uses strategies describe simple pipeline stage constructs values type strategy applied result stage 
pipeline strategy 


pipeline strat inp inp pipeline strat inp fs pipeline strat fs spar strat inp list pipeline rnf map fib map fac map pipeline process diagram node stage arc connecting stage 
typically arc represents list stream values passing stages 
gives process diagram example 
large applications described section elaborate pipelines different types values passed stages stages may different strategies 
example back lolita top level pipeline follows algorithm strategy parallelism backend inp opts strat inp opts opts strat rwhnf parlist rwhnf inp par rwhnf parlist rwhnf rwhnf par rnf par rnf par rnf par rnf par rnf par rwhnf parlist rwhnf rwhnf par disadvantage strategies long pipelines intermediate structure named 
pipelines common introduced special combinators parameterised sequential parallel function application 
parameter specifies strategy argument 
achieve separation algorithm dynamic behaviour strategies second argument parameterised function application 
definition new combinators follows infixl 

strategy 



seq 

par defined similar combinators parameterised function composition 
pipelines expressed concisely retaining textual separation strategic algorithmic code 
backend inp opts rwhnf parlist rwhnf rwhnf opts rnf rnf rnf rnf rnf opts rwhnf parlist rwhnf rwhnf rwhnf parlist rwhnf inp trinder large parallel applications general written number medium scale parallel programs currently paralleling large scale program lolita lines 
section discusses evaluation strategies programs divide conquer pipelined data oriented 
methodology developing experiences described 
date parallel programming successful addressing problems regular structure large grain parallelism 
large scale applications number distinct stages execution speedups obtained stage successfully parallel 
resulting parallelism highly irregular 
understanding controlling dynamic behaviour large program hard 
major motivation investigating approach believe hard gain speedups large programs irregular parallelism languages require programmer control aspects parallelism thread creation placement synchronisation large applications evaluation strategies defined kinds modules 
strategies prelude types lists tuples integers defined strategies module 
strategies application specific types defined application modules 
currently strategies library types defined private copies library modules 
language support strategies automatically derived strategies constructed types greatly reduce amount code modified avoid problem reproducing libraries 
methodology emerging methodology parallelising large non strict functional programs outlined 
approach top starting top level pipeline parallelising successive components program 
stages machine independent 
approach uses ancillary tools including time profiling sansom peyton jones simulator hammond 
stages fully integrated gum parallel runtime system trinder 
crucial property parameterised simulate real architectures idealised machine example zero cost communication infinite number processors 
stages methodology follows 

sequential implementation 
start correct implementation inherently parallel algorithm algorithms 

top level pipeline 
non trivial programs number stages lex parse typecheck compiler 
pipelining output stage easy specify gains parallelism minimal change 
algorithm strategy parallelism 
time profile sequential application discover big computationally intensive pipeline stages 

big evaluation strategies 
possible introduce adequate parallelism changing algorithm algorithm may need revised introduce appropriate form parallelism divide conquer data parallelism 

simulate 
idealised simulator eliminates complexities real parallel implementation task migration communication times proving step program isn parallel idealised machine won real machine 
simulator easier heavily instrumented run workstation 

simulate second 
parameterised closely resemble gum runtime system particular machine forming bridge idealised real machines 
major concern stage improve thread granularity offset communication thread creation costs 

real machine 
gum runtime system supports performance visualisation tools 
seamless integration helps understand real parallel performance 
conventional start sequential program move immediately working target parallel machine 
proved highly frustrating development environments parallel machines usually worse available sequential counterparts crucial achieve speedups detailed performance information frequently available 
unclear poor performance due algorithms inherently sequential simply artefacts communication system dynamic characteristics 
lolita lolita natural language engineering system morgan developed durham university 
team interest parallelism partly means reducing runtime partly means increase functionality acceptable response time 
structure program bears resemblance compiler formed large stages ffl morphology combining symbols tokens similar lexical analysis ffl syntactic parsing similar parsing compiler ffl normalisation bring sentences kind normal form ffl semantic analysis ffl pragmatic analysis 
depending lolita final additional stage may perform discourse analysis generation text translation system perform inference text extract required information 
trinder immediate goal parallelising system expose sufficient parallelism fully utilise processor shared memory machine 
pipeline approach promising way achieve relatively small degree parallelism 
stage listed executed separate thread linked form pipeline 
key step parallelising system define strategies complex intermediate data structures parse trees communicate stages 
data oriented approach simplifies topdown parallelisation large system possible define parts parts data structure evaluated parallel considering algorithms produce data structures 
synt 
parsing semantic 
normalisation pragmatic 
back fig 

pipeline structure lolita critical issue lolita system avoiding generation unnecessary 
order achieve lolita heavy laziness example handling ambiguities parsing natural languages 
efficiency system depends computing information quality alternative parses parse trees 
avoids construction large superfluous data structures 
consequently strategy stricter necessary may increase parallelism parsing stage decrease performance 
currently simulate stage parallelising methodology 
far pipeline approach produced average parallelism 
lolita originally written consideration parallel execution fairly satisfied amount parallelism 
amdahl law gives upper bound speedup code inherently sequential 
apart specifying instances intermediate data structures achieve parallelisation necessary modify modules lolita functions module 
stage haven sub algorithms contain significant sources parallelism 
achieve parallelism plan consider parts pipeline 
firstly stages morphology syntactic parsing applied different parts text parallel 
sentences parsed simultaneously 
creates data parallelism part pipeline especially effective improving performance large inputs 
similarly semantic pragmatic analyses applied data parallel fashion different possible parse trees sentence 
parallelism increase performance system improve quality result 
analyses produce information put global context containing information semantics text 
creates additional algorithm strategy parallelism synt 
parsing semantic 
pragmatic 
normalisation semantic 
pragmatic 
normalisation synt 
parsing semantic 
pragmatic 
normalisation semantic 
pragmatic 
normalisation synt 
parsing semantic 
pragmatic 
normalisation semantic 
pragmatic 
normalisation back text stream parse forest parse tree sgml tree fig 

detailed structure lolita dependence different instances analysis 
lazy evaluation ensures completely analyses 
worthwhile expensive syntactic parsing stage 
shows detailed structure results 
code top level function 
clearly shows algorithm separated dynamic behaviour stage 
changes algorithm 
parmap describe data parallelism parsing stage 
parameterised function applications describe pipeline structure 
strategies parse prag special interest 
parse forest contains possible parses sentence 
semantic pragmatic analyses applied predefined number global parses 
strategy applied list results parlist demands score analysis element triple complete parse 
score decide parses choose result text analysis 
linear equation solver typical example parallel symbolic program 
uses multiple homomorphic images approach computer algebra algorithms lauer elements input matrix vector mapped images prime number system solved images result constructed combining solutions chinese remainder algorithm 
divide conquer structure depicted 
trinder opts inp global result morphology sgml inp global sentences global sgml parsing parmap rnf global sentences analysis parse prag opts global back result backend opts pick parse tree best score results semantic pragmatic analysis 
done speculatively 
parse prag opts global global take global map analyse analyse pt opts parlist rwhnf rnf rwhnf rwhnf pt global pipeline semantic pragmatic analyses parse global rnf rnf rnf sem rnf global rwhnf global parse backend inp opts rwhnf parlist rwhnf rwhnf opts rnf rnf rnf rnf rnf opts rwhnf parlist rwhnf rwhnf rwhnf parlist rwhnf inp fig 

top level function lolita application algorithm strategy parallelism 
ffl ffi fi fl cra pq pq zp zp zp zp zp zp ap bp ap bp xp xp forward mapping cramer rule lifting fig 

structure algorithm strategic code matrix determinant part solver section algorithm discussed loidl 
precise control dynamic behaviour required critical places program 
behaviour described combining generic strategies 
ffl algorithm described terms infinite list solutions homomorphic images 
initial segment list computed parallel educated guess homomorphic solutions needed 
depending solutions initial segment small number additional solutions computed 
ffl algorithm computes solutions combination step 
achieved initially evaluating elements result list checking result useful computing remainder 
accident set police accident records task discover accident places number accidents occurred 
criteria determine accident reports location 
accidents may location occurred junction number pair roads grid small radius trinder 
problem amounts partitioning set equivalence classes equivalence relations 
gph implementation trinder major phases forming top level pipeline 
reading parsing file accidents constructing combined relation indices accident relations forming partition 
little parallelism gained top level pipeline speedup value read index trees tree constructed 
far pipeline stages adequately processor target machine 
accidents read parallel separate files list lists accidents main cts readfile path accident show ioerror 

cts cts accidents map parse tuple cts strategy strategy parlist rnf partition speculatively computing equivalence classes accidents parallel 
accidents class duplicated 
chance wasting small mean class size approximately accidents 
additional parallelism obtained removing members equivalence classes accident set parallel determining equivalence classes rnf rest 
speculation benign amount performed speculative task small threads sparked 
set accident 
accident accident 
set set accident accs case length alist 
emptyset 
union rest strategy 
matches union accs matches alist take accs matches reachable chose accs reachable alist rest accs strategy result parlist rnf par rnf rest par result algorithm strategy parallelism middle stage constructs indices harder implement parallel 
problem indices trees top level pipeline blocked element root index tree consumed stage tree constructed 
current solution splits index sequence trees reducing bottleneck 
related different proposals ways specify parallelism functional languages 
space precludes describing proposal detail section concentrates approaches closely related evaluation strategies covering purely implicit approaches algorithmic skeletons coordination languages language extensions explicit approaches 
non functional approaches covered 
approach closely related class schedules hudak described section 
purely implicit approaches purely implicit approaches include dataflow languages id arvind ph nikhil haskell evaluation transformers burn 
data parallel languages nesl blelloch seen implicitly parallelising certain bulk data structures :10.1.1.40.6866
implicit approaches fixed underlying model parallelism 
evaluation strategies allow explicit control crucial aspects parallelism programmer describe behaviours different fixed model speculatively evaluating expressions 
evaluation transformers evaluation transformers exploit results strictness analysis structured data types providing parallelism control mechanisms tailored individual strictness properties burn 
evaluation transformer reduces argument extent allowed available strictness information 
appropriate transformer selected compile time giving efficient execution cost increase code size burn finne burn 
small number possible transformers lists standard point strictness domain see table repeated avoided recording extent data structure evaluated specialised transformer unevaluated needed part structure 
problem evaluation transformers sophisticated strictness analysis types defined greater number evaluation transformers needed greater code bloat 
specialised transformers defined compiler type complicating provision transformers programmer defined types 
contrast programmer control strategy trinder transf 
meaning strategy reduction reduce whnf rwhnf ets reduce spine list reduce list element whnf rwhnf table 
relationship evaluation strategies transformers particular context strategies programmable fixed strategies strictly general evaluation transformers 
particular programmer elect strategy strict function order obtain performance 
possible strictness analysis drive choice appropriate evaluation strategy circumstances 
aware relationship strictness domains structure certain strategies implement domains 
strictness information way strategies implicit 
data parallelism argued support provided task data parallelism 
shown kinds data oriented parallelism expressed evaluation strategies 
truly data parallel approaches nesl blelloch blelloch treat higher order functions scans folds compound expressions list array comprehensions single atomic operations entire structures lists arrays :10.1.1.40.6866
effect functions applied element data simultaneously data supplied functions 
approach suitable control parallelism massively parallel machines cm 
certain evaluation strategies seen control parallel implementations data parallel constructs targetted distributed memory shared memory machines massively parallel architectures 
dataflow dataflow languages functional id arvind ph nikhil variant haskell 
languages typically evaluation scheme lenient evaluation introduce parallelism implicitly 
evaluation scheme generates massive amounts fine grained parallelism small utilised efficiently conventional thread technology 
overheads small grain threads addressed hardware support 
explicit control provided evaluation strategies help programmer create larger grain threads 
algorithm strategy parallelism algorithmic skeletons defined cole cole algorithmic skeletons take approach implementing dynamic behaviour machine hard 
skeleton intended efficient implementation commonly encountered parallel behaviour specific machine 
effect skeleton higher order function combines sequential sub programs construct parallel application 
commonly encountered skeletons pipelines variants common list processing functions map scan fold 
general treatment provided related algorithmic skeletons number parallel paradigms 
skeletons strategies skeleton simply parallel higher order function straightforward write skeletons strategies 
parmap function section pipeline function section skeletons 
elaborate divide conquer skeleton concurrent clean function written follows 




bool 




bool 


arg threshold conquer divisible divide divisible arg arg conquer left right strategy lt rt divide arg left lt threshold conquer divisible divide right rt threshold conquer divisible divide strategy 
threshold arg rwhnf rwhnf left right rwhnf rwhnf left right possible strategies opposite way skeletons skeleton control function algorithm takes sequential subprograms arguments 
function strategies may specify algorithm parameterise control information take strategy parameter 
fact functions described take strategy parameter including parlist parmap pipeline 
imperative skeletons algorithmic skeleton approach clearly fits functional languages done functional context 
possible combine skeletons imperative approaches 
example compiler integrates algorithmic skeletons subset 
closures represent done purely functional setting compiler translates polymorphic higher order functions monomorphic order functions 
functions true dual skeletons lower level 
trinder performance resulting program close hand crafted application 
instantiation procedure fully general may possible adopt similar techniques compiling evaluation strategies order reduce overheads 
coordination languages coordination languages build parallel programs components computation model coordination model gelernter carriero 
evaluation strategies programs algorithmic behavioural aspect 
necessary computation models paradigm fact computation model imperative coordination language may declarative nature 
programs developed style structure sequential processes developed computation language composed coordination language 
best known coordination languages pcn foster taylor linda gelernter carriero 
adopt lower level approach evaluation strategies 
course possible introduce deadlock systems 
pcn composes tasks connecting pairs communication ports primitive composition operators sequential composition parallel composition choice composition 
possible construct sophisticated parallel structures divide conquer combined libraries reusable templates 
linda built logically shared memory structure 
objects tuples held shared area linda tuple space 
linda processes manipulate objects passing values sequential computation language 
common linda binding linda sequential evaluation performed normal functions 
scl darlington integrate coordination language approach skeleton approach providing system composing skeletons scl darlington 
scl basically data parallel language distributed arrays capture initial data distribution subsequent dynamic 
scl introduces kinds skeleton configuration elementary computational skeletons 
configuration skeletons specify data distribution characteristics elementary skeletons capture basic data parallel operations familiar higher order functions map fold scan computational skeletons add control parallel structures farms spmd iteration 
possible write higher order operations transform configurations manipulate computational structures example taken darlington rewritten haskell style partition function partitions sequential array parallel array sequential subarrays 
algorithm strategy parallelism partition 
array index 
index array index partition ii ii ii array bounds 
ii bounds similar integration provided language provides set skeletons common classes algorithm 
control abstraction approach certain parallels evaluation strategies described leblanc leblanc explicitly parallel imperative programs including explicit synchronisation communication explicit task creation 
evaluation strategies control abstraction approach separates parallel control algorithm 
control abstraction comprises parts prototype specifying types names parameters abstraction set control dependencies satisfied legal implementations control abstraction implementations 
implementation effectively higher order function parameterised closures representing units performed parallel 
closures invoked explicitly control abstraction 
implementations normal language primitives control abstractions 
purely functional context leblanc control dependencies correspond precisely evaluation degree strategy 
requirement implementations conform stated control dependencies equivalent setting requiring strictness preserved source source transformation involving evaluation strategy 
course standard requirement transformation non strict functional language 
compared described control abstractions lower level relying meta language capture essential notions closure control dependency directly encoded gph system 
avoid complications caused explicit encoding synchronisation communication cost efficiency 
leblanc applied technique prototype parallelising compiler 
report performance results compared hand coded parallel certain optimisations applied hand 
lends confidence belief evaluation strategies applied imperative parallel programs 
clear relationship control abstraction approaches 
fact control abstractions seen efficient implementation technique algorithmic skeletons 
trinder parallel language extensions providing completely separate languages coordination computation researchers extended functional language small distinct process control language 
simplest form gph simply set annotations specify process creation sophisticated systems kelly class schedules hudak support normal functional expressions part process control language 
annotations languages defined parallel annotations 
depending approach taken annotations may hints runtime system ignore directives obey 
addition specifying parallelism evaluation degree parallel program evaluation strategies annotation approaches permit explicit placement annotations 
early annotation approach similar gph burton burton defined annotations control reduction order function arguments strict lazy parallel 
thesis hughes hughes extends set second strict annotation reverses conventional evaluation order function argument evaluating function body argument 
clearly annotations expressed straightforward evaluation strategies directly gph 
simple beginnings led construction quite elaborate annotation schemes 
particularly rich set annotations defined hope implementation icl machine glynn glynn 
covered behavioural aspects data process placement simple partitioning sequencing 
compromise simplicity expressibility describe known set annotations provided concurrent clean 
basic concurrent clean annotation args sparks task evaluate args whnf remote processor continues execution locally 
task exported arguments args reduced nf 
equivalent strategy rnf args seq rwhnf args par 
concurrent clean annotations differ annotation degree evaluation placement parallel task 
gph delegates task placement runtime system direct strategic equivalent annotations perform explicit placement 
important annotations ffl args interleaves execution tasks local processor 
ffl location args executes new task processor specified location 
ffl par args evaluates args nf whnf 
equivalent strategy rnf args seq rnf args par 
ffl self args interleaved version par 
evaluation strategies concurrent clean annotations cleanly separate algorithm strategy parallelism dynamic behaviour algorithm 
language composing annotations sophisticated behaviours captured composing strategies described concurrent 
fact general problem annotation approach 
kelly provides separation algorithm parallelism similar evaluation strategies 
construct describe parallel control component program higher order functions structure process network 
evaluation strategies clause inhabits distinct value space algorithm fact comprises essentially values resolved compile time form static wiring system 
support dynamic process networks control strategies 
clean separation algorithm control achieved naming processes 
processes values manipulated clause 
corresponds closures capture computations evaluation strategy model 
example function defines pipeline 
syntax create anonymous process simply applies function labels argument 
arc indicates wiring connection processes 
chain creates chain wiring connections elements list 
result pipeline function concrete list functions argument composition functions turn initial value 
function application created separate process 
pipeline fs result result foldr 
id fs chain arc map fs arc fs arc head fs result para functional programming para functional programming hudak hudak hudak extends functional programming explicit parallel scheduling control clauses express quite sophisticated placement evaluation schemes 
control clauses effectively form separate language process control 
ease comparison evaluation strategies follow hudak syntax para functional programming haskell hudak 
hudak distinguishes kinds control construct schedules express sequential parallel behaviours mapped expressions specify process placements 
notions expressed sched constructs respectively attached directly expressions 
schedules order functional expressions schedules hudak introduces labelled expressions labels expression label syntax entirely equivalent expression 
primitive schedules demand labelled expression lab lab represents start evaluation lab lab represents trinder evaluation lab 
value may demanded times evaluated 
schedules combined sequential composition 
parallel composition 
common case schedule lab shorthand lab 
schedules execute parallel expression attached 
example sched 
dm dn requires complete evaluation demanded 
evaluating schedules parallel major difference evaluation strategy approach evaluation done control strategy 
second major difference schedules normal functional values control type system 
mapped expressions second kind para functional construct specify static dynamic process placement 
expression exp pid specifies exp executed processor identified integer pid 
special value self indicates processor id current processor libraries constructed build virtual topologies meshes trees example sort qt merge sort left self sort right self sort self sort self sort sub quadtree different neighbouring processor merge results current processor 
gph deliberately doesn address issue thread placement equivalent mapped expressions evaluation strategies 
class schedules class schedules hudak combine para functional programming monadic approach 
para functional schedules mapped expressions separate language constructs class schedules fully integrated haskell 
integration allows schedules manipulated normal haskell monadic values 
primitive schedule constructs combining forms similar provided para functional programming 
schedule demands value expression returning immediately suspends current schedule evaluated 
constructs type 
os sched 
similarly sequential parallel composition operations type os sched 
os sched 
os sched 
monadic type os indicate schedules may interact side effecting way operating system 
see causes loss referential transparency respect 
schedule construct hudak provide function sched type sched 
os sched 
equivalent algorithm strategy parallelism function 
sched function takes expression schedule executes schedule 
schedule terminates value returned value sched application 
evaluation strategy terms schedules replaced calls rwhnf affecting semantics para functional programs terminate 
evaluation strategies class schedules possible suspend value evaluating 
para functional schedules give rise deadlock situations expressed evaluation strategies 
trivial example sched compared evaluation strategies possible take advantage type system schedules type os sched parameterised type value scheduling 
clearly loss referential transparency expressions involving sched may evaluate times non 
value 
program terminates yields non 
value yield value 
fully explicit approaches explicit approaches usually lowest level parallel control providing sets basic parallelism primitives exploited build complex structures evaluation strategies 
approach typified multilisp halstead mul kranz provide explicit futures basic parallel control mechanism 
futures gph pars 
explicit level languages cml reppy require communication synchronisation specified 
constructs build higher level evaluation strategy approach closures laziness modelled function application conditionals knowledge attempt implement approach framework 
slightly higher level jones hudak worked commutative monads jones hudak allow operations process creation called fork captured standard state transforming monad 
approach provides essential building blocks needed support evaluation strategies disadvantage raising parallel operations monad level preventing clean separation algorithm behaviour observed evaluation strategies class schedules 
summary introduced evaluation strategies new mechanism controlling parallel evaluation non strict functional languages 
shown lazy evaluation exploited define evaluation strategies way cleanly trinder separates algorithmic behavioural concerns 
demonstrated result general expressive system common parallel programming paradigms captured 
outlined strategies large parallel applications noting facilitate top parallelisation existing code 
discussion required language support describing evaluation strategies exploited aspects haskell language design 
essential may modelled mechanisms 
example support higher order functions clearly needed strategies higherorder functions may take functional arguments 
lazy evaluation form clearly essential allows postpone strategy specification bindings data structure components evaluated order 
operationally laziness avoids recomputation values referred algorithmic code strategy 
studied detail control abstraction leblanc plus referred suggest characteristics lazy evaluation captured imperative language allow evaluation strategies wider context considered 
defining evaluation strategies taken advantage haskell type class overloading define general evaluation degree strategies rnf 
general adhoc overloading available number standard alternative approaches taken including ffl define set standard polymorphic evaluation degree operations ffl require evaluation degree operations monomorphic 
case support provided functions language constructs 
approach desirable taken limit user flexibility case require code duplication second 
additional control issues evaluation strategies specify aspects dynamic behaviour described 
aspect control thread granularity 
possible exploit load information example referentially transparent fashion simple thresholding techniques safely employed 
quicksort example sublists sorted sufficiently small evaluated sequentially subdivided parallel execution 
tests easily incorporated evaluation strategy avoids cluttering algorithmic code 
parallel programming paradigm expressed branchand bound parallelism 
expressed functionally semantic non determinism kind 
available haskell languages sisal feo provide non determinism precisely purpose 
algorithm strategy parallelism abuse strategies powerful language constructs evaluation strategies abused 
strategy evaluation degree greater strictness function controls may change termination properties program note class schedules defined normal language semantics 
similarly easy construct strategies undesirable parallelism strategy creates unbounded number threads 
strategies require additional runtime traversals data structure 
pathological cases accumulating parameters involved care taken avoid multiple traversals 
groups glasgow durham continue evaluation strategies write large parallel programs hope encourage 
initial performance measurements show strategic code efficient code ad hoc parallelism forcing functions measurements needed confirm true general 
framework reasoning strategic functions development 
proving strategic functions equivalent entails proving compute value evaluation degree parallelism sequencing 
evaluation degree strategic function determined adding laws par seq existing strictness analysis machinery hughes wadler projection analysis wadler hughes 
operational aspect parallelism sequencing harder reason 
set laws par seq idempotent uncertain best framework proving 
possible starting point partially order multisets provide theoretical basis defining evaluation order hudak anderson 
support evaluation strategies incorporated language 
compiler able automatically derive rnf type definition involved parallelising large application dramatically reduced replication libraries avoided 
form tagging closures runtime system reduce execution overhead strategies data structure need traversed strategy evaluation degree great strategies 
investigate strategies strict parallel languages 
strict functional languages provide mechanism postponing evaluation delay force functions 
question cost introducing explicit laziness outweighs benefits gained strategies 
long term goal support implicit parallelism 
strategies provide useful step goal 
learning great deal explicitly controlling dynamic behaviour hope learn sufficient automatically generate strategies dynamic behaviour large class programs 
promising approach strictness analysis indicate safe evaluate expression parallel granularity analysis indicate worthwhile 
may trinder possible combined implicit explicit approach program may adequately compiler programmer may small number crucial components 
arvind nikhil pingali structures data structures parallel computing toplas pp 

blelloch chatterjee zagha implementation portable nested data parallel language proc 
fourth acm conf 
principles practice parallel programming ppopp san diego ca may pp 

blelloch programming parallel algorithms cacm pp 

imperative language algorithmic skeletons efficient distributed computation proc 
th 
ieee intl 
symposium high performance distributed computing syracuse ny august pp 

burn interpretation parallel evaluation functional languages phd thesis imperial college london 
burn implementing evaluation transformer model reduction parallel machines functional prog pp 

burton annotations control parallelism reduction order distributed evaluation functional programs acm toplas april pp 

cole algorithmic skeletons pitman mit press 
leblanc parallel programming control abstraction acm toplas pp 

di orlando language technical report hpl psc hewlett packard laboratories pisa science centre december 
darlington guo yang parallel skeletons structured composition proc 
fifth acm conf 
principles practice parallel programming ppopp santa barbara ca july pp 

date database systems th edition addison wesley 
feo miller sisal proc 
denver april pp 

finne burn assessing evaluation transformer model reduction spineless machine proc 
fpca copenhagen pp 

gelernter carriero coordination languages significance cacm february pp 

flanagan nikhil design parallel functional language implementation proc 
icfp philadelphia penn may pp 

foster taylor compiler approach scalable concurrent program design acm toplas pp 

glynn watson annotations hope technical report ic fpr prog imperial college london 
halstead multilisp language concurrent symbolic computation acm toplas pp 

hammond loidl partridge visualising granularity parallel programs graphical winnowing system haskell proc 
high performance functional computing denver april pp 

algorithm strategy parallelism hoare communicating sequential processes prentice hall 
hudak para functional programming ieee computer pp 

hudak exploring para functional programming separating ieee software pp 

hudak para functional programming haskell parallel functional languages computing acm press new york addison wesley reading ma pp 

hudak anderson pomset interpretations parallel functional languages proc 
fpca springer verlag lncs september pp 

hughes design implementation programming languages thesis oxford university 
jones hudak implicit explicit parallel programming haskell research report yaleu dcs rr university yale august 
kelly functional programming loosely coupled multiprocessors pitman mit press 
glynn evaluation annotations hope glasgow workshop functional programming scotland springer verlag pp 

kranz halstead mohr mul high performance parallel lisp proc 
pldi portland june pp 

lauer computing homomorphic images computer algebra symbolic algebraic computation buchberger collins albrecht eds springer verlag pp 

loidl hammond partridge solving systems linear equations functionally case study parallelisation technical report dept computing science university glasgow 
milner communication concurrency prentice hall 
hudak class schedules virtual maps proc 
fpca la jolla ca june pp 

mohr kranz halstead lazy task creation technique increasing granularity parallel programs ieee transactions parallel distributed systems july pp 

morgan smith short translation meaning style lolita intl 
bcs conf 
machine translation years cranfield university november 
nikhil arvind hicks ph language proposal dec cambridge research lab tech 
rep 

smetsers van eekelen plasmeijer concurrent clean proc 
parle springer verlag lncs pp 

peterson hammond 
eds augustsson boutel burton fasel gordon hughes hudak johnsson jones peyton jones reid wadler report non strict functional language haskell version 
exploiting parallelism functional languages paradigm oriented approach machine models highly parallel computers dew lake 
eds oxford university press 
reppy cml higher order concurrent language proc 
pldi toronto canada june pp 

trinder roe parallel programming functional languages phd thesis dept computing science university glasgow april 
sansom peyton jones time space profiling non strict higherorder functional languages proc 
popl pp 

hallaron gross exploiting task data parallelism multicomputer proc 
fourth acm conf 
principles practice parallel programming ppopp san diego ca may pp 

trinder hammond mattson jr partridge peyton jones gum portable parallel implementation haskell proc 
pldi philadelphia penn may pp 

trinder hammond loidl peyton jones wu case study data intensive programs parallel haskell proc 
glasgow functional programming workshop scotland 
wadler hughes projections strictness analysis proc 
fpca september 
determinant appendix contains versions determinant function linear equation solver described section 
version left original sequential version 
right slightly cleaned version originally wrote function 
compared strategic version earlier lower level parallel version obscure difficult understand 
sequential version sum lpar lpar map determine jlo jhi determine pivot sign pivot det sign jlo pivot head mat 
mat jlo ihi jhi map newline tail mat det determinant mat direct parallel version sum lpar lpar jlo jhi fx par fx rest sign jlo mat jlo ihi jhi parmap newline tail mat pivot head mat 
det mat seq determinant mat case pivot 

sign pivot det fx sign par pivot det par rest 
