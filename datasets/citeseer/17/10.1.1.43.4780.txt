computational model word learning multimodal sensory input deb roy media mit edu media laboratory massachusetts institute technology ames street cambridge ma usa infants segment continuous streams speech discover words language 
current theories emphasize role acoustic evidence discovering word boundaries cutler brent de marcken wessels see bolinger 
test alternate hypothesis recorded natural infant directed speech caregivers engaged play pre linguistic infants centered common objects 
recorded visual context speech occurred capturing images objects 
analyzed data computational models processed acoustic recordings second model integrated acoustic visual input 
models implemented standard speech vision processing techniques enabling models process sensory data 
show visual context conjunction spoken input dramatically improves learning compared acoustic evidence 
results demonstrate power inter modal learning suggest infants may evidence visual non acoustic context aid speech segmentation spoken word discovery 
birthday infants word refer salient aspects environment including objects actions people 
learn words attending sights sounds sensations 
acquisition process complex 
infants successfully segment spoken input units correspond words language 
identify semantic categories correspond meanings words 
remarkably infants capable processes despite continuous variations natural phenomena noisy input provided perceptual systems 
presents computational model early word learning addresses interrelated problems segmentation fluent speech lexicon order discover spoken words categorization context corresponding referents words establishment correspondence spoken words contextual term word accordance webster dictionary speech sound combination sounds having meaning basic unit language human communication categories 
problems treated different facets underlying problem discover structure spoken visual model implemented standard speech vision processing techniques 
able learn microphone camera input roy roy 
model evaluate benefit inter modal structure problem speech segmentation word discovery 
gauge relative usefulness integrating visual context implemented uni modal system discovered words acoustic analysis access visual input 
evaluations demonstrate dramatic gains performance attained inter modal information leveraged 
results suggest infants benefit attending multimodal input earliest phases speech segmentation spoken word discovery 
differs previous computational models language learning 
gorin feldman siskind linguistic contextual input derived physical sensors relying human generated symbolic abstractions 
cell model learning audio visual input developed model cross channel early lexical learning cell summarized 
model discovered words searching segments speech reliably predicted presence visually occurring shapes 
input consisted spoken utterances paired images objects 
approximated input infant receive listening caregiver visually attending objects environment 
speech processor converted spoken utterances sequences phoneme probabilities 
built ability categorize speech phonemic categories similar abilities pre linguistic infants exposure native language 
rate hz processor computed probability past milliseconds speech belonged english phoneme categories silence 
phoneme estimation achieved training artificial recurrent neural network similar robinson 
network trained database phonetically transcribed speech recordings adult native english speakers seneff zue 
utterance boundaries automatically located detecting stretches speech separated silence 
visual processor developed extract statistical representations shapes images objects 
visual processor second order statistics represent object appearance suggested theories early visual processing julesz 
step edge pixels viewed object located 
pair edge points normalized distance points relative angle edge points computed 
distances angles accumulated dimensional histogram representation shape second order statistics 
dimensional shapes represented collection dimensional shape histograms derived particular view object 
gather visual data evaluation experiments robotic device constructed gather images objects automatically 
robot took images stationary objects various vantage points 
discuss learning audio visual input 
underlying model able learn combination input modes model dependent speech vision 
see roy details 
object represented shape histograms derived images taken arbitrary poses robot 
chi squared divergence statistic compare shape histograms measure shown object comparison schiele crowley 
sets images compared summing chi square divergences best matches individual histograms 
cell model 
camera images objects converted statistical representations shapes 
spoken utterances captured microphone mapped sequences phoneme probabilities 
short term memory stm buffers phonetic representations spoken utterances paired representations occurring shapes 
short term recurrence filter searches stm repeated sub sequences speech occur matching visual contexts 
resulting pairs speech segments shapes placed long term memory ltm 
filter mutual information searches ltm speech shape pairs usually occur rarely occur apart ltm 
pairings retained ltm rejected pairings periodically discarded garbage collection process 
phonemic representations multi word utterances occurring visual representations temporarily stored short term memory stm 
stm capacity utterances corresponding approximately words infant directed speech 
input fed model new utterance shape entry replaced oldest entry stm 
short term recurrence filter searched contents stm recurrent speech segments occurred matching visual contexts 
stm focused initial attention input occurred closely time 
limiting analysis small window input computational resources search memory unanalyzed sensory input minimized required cognitively plausibility 
determine matches acoustic distance metric developed roy compare pair potential speech segments drawn utterances stored stm 
metric estimated likelihood segment pair question variations similar underlying phoneme sequences represented word 
chi squared divergence metric described earlier compare visual components associated stm utterance 
acoustic visual distance small segment shape copied ltm 
entry ltm represented hypothesized prototype speech segment visual referent 
robot built capture images objects multiple vantage points 
schematic right shows degrees freedom imaging system including turntable rotating objects 
seen photograph left system designed synthetic character experiment notions embodied human computer interfaces see roy roy 
infant directed speech usually refers infant immediate context snow 
speaking infant caregivers rarely refer objects events location happened past 
guided fact long term mutual information filter assessed consistency speech shape pairs ltm 
mutual information mi random variables measures amount uncertainty removed regarding value variable value cover thomas 
mutual information measure amount uncertainty removed presence specific shape learner visual context observation specific speech segment 
mi symmetric measure converse true measured uncertainty removed occurrence particular speech segment visual context 
pairs high mi retained periodically garbage collection process removed hypotheses ltm encode associations high mi 
recur model learning acoustic input comparative purposes developed second model recur segmented speech acoustic information 
acoustic processing recur identical cell allowing compare evaluation data 
recur discovered words searching recurrent sequences speech sounds 
underlying idea model common current theories speech segmentation brent de marcken learner views language constructed underlying process concatenates words generate utterances 
noticing subsequences speech recur learner detect common words segment fluent speech word boundaries 
recur model 
acoustic waveforms recorded microphone converted phoneme probabilities 
utterances buffered short term memory stm provide input recurrence filter searches repeated sequences speech stm 
result set speech segments stored long term memory ltm 
second recurrence filter searches entries ltm repeated long spans time 
repetitions evidence segment represents word target language retained ltm 
garbage collection process periodically removes segments ltm fail pass long term recurrence filter 
infants search possible matches speech segments spoken utterances heard 
recurrence analysis require huge amounts memory verbatim speech demand impractical computational resources 
suggested theories human memory miller model eases resource requirements searching recurrent phonemic sequences short term window input 
model performed exhaustive search repeated segments stm time new utterance added 
recurrent speech sequences extracted stm copied ltm 
second recurrence detector compared ltm segments acoustic distance metric stm 
segments ltm similar speech segments ltm retained reliable word candidates 
periodically hypotheses match entries ltm removed garbage collection process 
evaluation evaluated models collecting speech images similar infant observe natural play caregivers 
model effectively put infant place test learn words similar infant expected learn 
study involving caregivers infants conducted gather corpus infant directed speech 
participants asked engage play centered types objects 
speech coupled sets images objects input model 
participants female responded classified advertisement placed local newspaper 
infants males female ranged age months 
participants asked interact naturally infants playing set age appropriate objects 
chose classes objects commonly named early infant speech huttenlocher smiley balls toy dogs shoes keys toy horses toy cars toy trucks 
total objects objects class obtained 
caregiver participated sessions play infants day period 
sessions participants provided set objects object classes 
order object sets provided randomized participants 
objects placed box marked box start session 
participants asked take object time play return box 
told teach infants words 
participants free choose order objects selected play duration play object 
speech recording session automatically segmented utterances 
robotic gather set images object various angles approximating infant saw play sessions 
set images captured object varying perspectives resulting database images 
utterance randomly selected images object play utterance recorded 
images paired utterance input models 
models run separately speech recordings caregiver 
caregiver model generated set output speech segments recur speech shape pairs cell 
testing models identical spoken input able determine value additionally providing visual context 
speech segment identified model evaluated measures accuracy 
measure assessed segmentation accuracy segment start english word boundaries 
measure assessed word discovery speech segment correspond single english word 
considered words attached articles inflections acceptable measure 
allowed initial final consonant errors measure measure 
measure segmentation accuracy posed extremely difficult challenge dealing acoustic data 
recur segment boundaries corresponded boundaries english words 
contrast segment boundaries extracted cell chosen actual words boundaries 
measure word discovery speech segments acquired cell single complete english words 
contrast performance recur dropped 
output cell measured semantic accuracy measure output speech segment pass measure get paired semantically appropriate visual prototype 
recur process visual data measure meaningfully applied output 
cell achieved measure 
result shows visual semantics derived context connected appropriate words significant number cases random guessing meaning speech segment yield maximum 
recall earlier set address problems early word learning word discovery contextual categorization establishing word context correspondences 
cell achieves unified framework 
speech segments corresponding prototypes spoken words extracted continuous speech 
visual prototypes corresponding words identified associated cases appropriate spoken words 
cell able learn spoken words visual multimodal sensory data 
comparisons acoustic recur model demonstrate benefit incorporating cross modal information word discovery process 
structure lead fold increase word discovery accuracy compared analyzing structure acoustic channel 
speech segmentation improvement larger fold 
result implications understanding language acquisition infants 
segment speech preparatory step acquiring sound meaning mappings efficient strategy combine segmentation process mapping process earliest stages language learning 
additional structure contextual channels may accelerate process early lexical acquisition 
think learning consisting discrete stages 
case learning early words natural alternatives come mind 
hand infants learn early concepts look spoken labels fit concepts 
hand learn salient speech sequences look referents 
model experiments verify closely knit process stages fact occur advantageous learner 
approach learner able leverage information captured structure streams input 
benefited greatly discussions alex pentland steven pinker allen gorin patel bernt schiele 
bolinger cue constraints word 
brent efficient probabilistically sound algorithm segmentation word discovery machine learning 
cover thomas elements information theory wiley interscience new york 
cutler segmentation problems rhythmic solutions 
gleitman landau editors acquisition lexicon chapter pages 
mit press cambridge ma 
de marcken unsupervised language acquisition ph thesis massachusetts institute technology 
wessels phonotactic knowledge infant speech perception perception psychophysics 
huttenlocher smiley early word meanings case object names language acquisition core readings bloom ed mit press cambridge ma 
julesz foundations perception university chicago press chicago 
williams stevens linguistic experiences phonetic perception infants months age science 
miller magical number plus minus limits capacity processing information psych 
rev 
robinson application recurrent nets phone probability estimation ieee trans 
neural networks 

roy jebara cassell pentland 

synthetic character guided perception emotion story 
visual proceedings siggraph los angeles ca 
acm siggraph 
roy learning words sights sounds computational model 
ph thesis massachusetts institute technology 
roy integration speech vision mutual information 
appear proc 
int 
conf 
speech signal processing istanbul turkey 
newport statistical learning month old infants science 
schiele crowley probabilistic object recognition multidimensional receptive field histograms proc 
th int 
conf 
pat 
recognition 
seneff zue transcription alignment timit database proc 
second symposium advanced man machine interface spoken language 
snow mothers speech research input interaction 
snow ferguson eds talking children language input acquisition 
cambridge university press 
developmental changes childhood perception non native speech sounds canadian psych 
