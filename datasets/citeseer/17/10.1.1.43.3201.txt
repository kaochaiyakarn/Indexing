empirical evaluation reinforcement learning spoken dialogue system satinder singh michael kearns diane litman marilyn walker labs park avenue florham park nj diane research att com report design construction empirical evaluation large scale spoken dialogue system optimizes performance reinforcement learning human user dialogue data 
formalisms markov decision processes mdps reinforcement learning rl standard approach ai problems involve agent learning improve performance interaction environment sutton kaelbling 
theory formalisms quite advanced applications limited exclusively problems control operations research game playing crites barto tesauro 
describe application rl different type problem mdp models system interaction population human users rl optimize system performance 
strategy dialogue database tts asr user block diagram representation spoken dialogue system 
adapted methods rl problem automatically learning dialogue policy spoken dialogue system sds 
different components sds shown block diagram form typical sds user speaks system real time telephone free form natural language order retrieve desired information back database component 
user speech interpreted automatic speech recognition asr component 
dialogue policy decides system say rl terminology action take natural language copyright fl american association artificial intelligence www aaai org 
rights reserved 
text speech tts component point dialogue 
welcome rlds 
may help 
open morning 
asr output open morning 
say interested 

near open morning 

please give feedback saying bad 

transcription example spoken dialogue njfun system 
dialogue happened go relatively short 
general dialogue length varied exchanges user system 
shows transcription sample spoken dialogue njfun system implemented provide telephone access database activities new jersey 
dialogue starting open ended greeting may help system lets user take initiative providing information activity interested 
user responses cases may relatively unconstrained 
contrast system take initiative saying restrictive phrase please tell location interested constraining user provide information location activity 
contrasting choices user system initiative superior may depend strongly properties underlying imperfect asr population users dialogue far 
choice initiative occurs repeatedly dialogue example class difficult design decisions 
traditional shall call monte carlo approach learning dialogue policies data pick set dialogue policies experts intuitively feel implement policy separate sds collect data representative human users sds standard statistical tests pick best dialogue policy system performance criterion reward measure choice say 
handful dialogue policies compared way cost time human subjects 
hand show system thousands dialogue policies may left experts excluded policies clearly suboptimal 
show methods rl wellsuited problem searching large space policies survive pruning experts 
high level rl methodology involves choice appropriate reward measures estimates dialogue state deployment initial training system generates deliberately exploratory dialogue data construction mdp model user population reactions different action choices system optimal dialogue policy model 
rl method data efficient monte carlo method evaluates actions function state evaluating entire policies 
rl applied dialogue system design previous research biermann long levin walker singh provides larger scale test ideas 
describe design implementation njfun system controlled experiments human users verifying rl methodology 
results describe provide empirical evidence properly applied rl quantitatively substantially improve dialogue system policy 
example main results rate task completion rose training system learned system 
companion litman describe basic system experiment focus details analyses relevant computational linguistics linguistic analyses learned policy novice versus expert performance 
system experiments help focus attention challenges spoken dialogue systems prevailing theory application rl 
include fact markov property guaranteed application modeling human users difficulty balancing need exploratory data need functioning training system inherent difficulty obtaining large amounts training data applications 
choices dialogue policy purposes asr viewed imperfect noisy sensor adjustable parameter language model grammar tuned influence types speech recognition mistakes 
addition perceived matches utterance asr returns score typically related log likelihood hidden markov model giving subjective estimate confidence matches 
score important interpreting asr results 
concentrate automating important types decisions faced dialogue policy design heavily colored asr facts 
type seen example choice initiative system point prompt user relatively open ended manner referred user initiative relatively restrictive manner system initiative 
second type choice investigate confirmation 
applied asr user utterance obtained value attribute interest instance town system decide confirm perceived utterance user 
example system chooses confirm location activity type activity time morning posit confirmation unnecessary high values asr confidence necessary low values proper definitions high low ideally determined empirically current state instance depending difficulty previous exchanges depend measure system success 
njfun system identified different dialogue states wanted learn take user system initiative prompt 
similarly identified different dialogue states wanted learn confirm asr perceived user utterance confirm 
actual prompts case hand coded learn choice initiative choice confirmation natural language utterances generate 
note genuine debate choices initiative confirmation dialogue system designers danieli gerbino haller mcroy smith walker precisely wish automate principled way process making choices basis empirical data 
rl dialogue policy design section describe methodology propose apply rl dialogue policy design 
section describe detail instantiation methodology njfun system 
order apply rl design dialogue policy necessary define state representation dialogues 
obvious impractical choice state transcript system log entire dialogue far include audio far utterances matched asr language models confidence scores returned asr quantities 
practice compress state possible representing states values small set features losing information necessary making decisions 
view design appropriate state space application dependent task skilled system designer 
choices state features system designer think terms state space appropriate actions take state 
states proper action take may clear instance greeting user start state querying database informational attributes instantiated 
states system designer may debate choice actions may best determined learning choices initiative confirmation 
mapping choice states particular action distinct dialogue policy 
assume system designer chosen particular reward function measured relative ease dialogue takes scalar values expectation user population maximized 
subject appropriate measures dialogue system success complex natural choices danieli gerbino walker including user satisfaction measures measures task completion sales figures commercial applications 
empirical results commit task completion reward measure optimization examine common reward measures 
methodology requires starting point designer choose state representation reward function large number states identify fixed number actions chosen 
suppose designer implements initial dialogue policy collects set dialogues sample user population 
dialogue course sequence alternating system user utterances terminated scalar reward delta delta delta notation indicates ith exchange system state executed action received reward state changed sequences estimate transition probabilities form js denotes probability transition state system state took action estimate probability simply number times dialogues system took arrived divided number times system took regardless state 
similarly estimate reward function maps states actions rewards 
reward functions examine rewards nonzero terminal states 
estimated reward function transition probabilities constitute markov decision process mdp model user population interaction system hopefully captures stochastic behavior users interacting system 
note order confidence model training data tried possible actions possible states preferably times 
words training data exploratory respect chosen states actions 
straightforward way ensuring exploratory training data take actions randomly 
approach take requires exceptionally careful designing actions allowed state order guarantee random choices result dialogue sensible human users 
keep mind exploration states appropriate action note mdp model best approximation 
small set state features problem hidden state partial observability richer pomdp model appropriate kaelbling 
leave pomdp models 
known fixed system designer 
approaches generating exploratory data possible 
final step determine optimal policy estimated mdp dynamic programming algorithm value iteration kaelbling implement policy learned dialogue policy 
extent estimated mdp accurate model user population final system maximize reward obtained users 
summary proposed methodology ffl choose appropriate reward measure dialogues appropriate representation dialogue states 
ffl ii 
build initial state training system creates exploratory data set 
despite exploratory system provide desired basic functionality 
ffl iii 
training dialogues build empirical mdp model state space 
ffl iv 
compute optimal dialogue policy mdp 
ffl reimplement system learned dialogue policy 
njfun system section describe functionality construction spoken dialogue system tested methodology 
back database system contained information interesting places visit new jersey 
database indexed keys activity type historic sites museums name new jersey town activity located morristown hours place open 
example liberty science center indexed activity type museum location jersey city hours am pm 
binned activities activity types distinct database entries goal njfun help user find database entries matching binding desired activity type location period day morning afternoon evening 
binding attributes may multiple database matches returned user 
system represents current state dialogue values different state features possible values meanings described high level state variables tell system attribute currently working obtained value attribute confidence value attempts get value attribute type asr grammar indication difficulties earlier portions dialogue 
note state representation interests keeping state space small deliberately ignores potentially helpful information dialogue support continuous system functionality extended number ways larger live database support followup questions users 
feature values explanation attribute attribute worked confidence low medium confirmed high asr confidence explicitly confirmed value value obtained current attribute tries times current attribute asked grammar open closed grammar history trouble previous attribute state features values 
far 
example state feature explicitly tracking average asr score user utterances far keep information previous attributes state space precisely defined provide detail policy class considered policy class obtained allowing choice system user initiative system needs ask attribute allowing choice confirming simply moving attribute system just obtained value attribute 
example state tries feature value attribute feature value means working activity type prompt user value attribute system choice uttering user initiative prompt may help system initiative prompt please tell activity type 
case choice system initiative system additional choice calling asr user utterance closed grammar intended just attribute open grammar may correctly recognize information offered attributes 
open grammar user initiative prompt choice closed grammar sense case 
example choices confirmation policy available states value feature immediately prompt user current attribute 
states confidence confirmed feature allow choice confirm attribute value obtained asr accept current binding move attribute 
call set deterministic mappings states system choice particular fixed choice policy class explored experiment 
total system course stores actual values previous attributes eventual database query influence dialogue policy way stored state features 
greater detail policy class companion litman 
number unique policies class approximately keeping rl methodology described goal compute implement approximately optimal policy large class basis rl applied exploratory training dialogues 
experimental methodology section describe detail controlled user experiments conducted 
section presents empirical results experiments 
experimental subjects fellow employees involved project 
subjects divided training population people test population people 
took precaution roughly balancing male female native non native experienced inexperienced fractions training test sets subsequent analyses indicated system performance depend significantly factors 
subjects told training test classification purpose experiments 
dictated step ii rl methodology built training version system state space action choices outlined preceding section random exploration 
mean state specified choice system actions training system chose randomly allowed actions uniform probability 
emphasize fact allowed choices designed way ensured dialogue generated exploratory training system intuitively sensible human user permitted successful completion task system intended perform 
important note multiple calls system see training users may effectively experienced multiple dialogue policies induced random exploration test users experienced single fixed deterministic policy 
designed set specific tasks participant complete training system test system 
task associated web page containing brief text description desired information participant obtain user survey common tasks training participants attempted complete tasks exploratory training system 
users generated total dialogues dialogues annotated objective binary task completion reward function 
system logs matched tasks user attempting possible directly compute system logs user completed task 
completed mean binding attributes activity type location time day exact values specified task description associated web page 
way training dialogue automatically labeled case survey questions formed basis subjective reward measures examined section 
total number dialogues theta users failed attempt tasks 
completed task gamma 
note definition task completion guarantees user heard database entries matching task specifications 
relaxations reward measure reward measures discussed section 
training dialogues labeled task completion build mdp rl methodology optimal policy mdp computed implemented deterministic dialogue policy test system 
test users carried experimental tasks test system 
primary empirical test proposed methodology course extent statistical significance improvement allegedly optimized measure task completion training test populations 
section devoted analysis test related tests 
results important results summarized rows row summarize performance binary completion reward measure discussed preceding section 
average value reward measure dialogues generated randomized training system recall range gamma average value measure dialogues learned test system improvement value standard sample test subject means 
reward measure train test delta value binary completion weak completion reuse gamma easy njfun understood say gamma web feedback gamma train versus test performance various reward measures 
column presents different reward measures considered see text detail second column average reward obtained training data third column average reward obtained test data fourth column shows difference test average train average positive number win negative number loss fifth column presents statistical significance value obtained standard ttest 
examine performance improvement closely related reward measure call weak completion 
weak completion attribute bound incorrect value instance place bound morristown specified task reward received 
attribute bound incorrect value reward equal number attributes correctly bound recall unbound variables assigned don care 
motivation refined measure reward indicates information desired contained database entries user non negative reward means information desired buried larger set irrelevant items smaller values reward 
second row show improvement weak completion training test training dialogue average weak completion recall range gamma test dialogue average 
large improvement time significant level 
note policy dictated optimizing training mdp binary completion implemented test system policy dictated optimizing training mdp weak completion implemented similar minor differences action choices 
policy emp 
mdp value 
avg 
value test gamma gamma gamma mixed gamma comparison standard policies 
compare test policy standard policies monte carlo method 
policy uses system initiative confirms policy uses system initiative confirms policy uses user initiative confirms policy uses user initiative confirms mixed policy varies initiative dialogue 
policy second column shows number consistent trajectories training data third column shows empirical average reward consistent trajectories fourth column shows estimated value policy learned mdp fifth column shows statistical significance value policy loss respect test policy 
policy test policy better significance near level difference significant 
results indicate improvement moving randomized training policy optimized policy natural ask optimized system compares systems employing dialogue policy picked human expert 
implementing number policies gathering dialogues comparing learned system time consuming emphasize improvement weak completion system designed optimize binary completion fielded single test system examined performance changes different reward measures 
expensive fact exactly methodology attempting replace training system provides convenient mathematically sound proxy 
training dialogues generated making random choices dialogue training set consistent policy policy class provides unbiased monte carlo trial 
easily verified formally 
consistent mean random choices dialogue agree dictated average rewards consistent training dialogues obtain unbiased estimate return compares performance learned test system binary completion reward measure fixed policies class common choices dialogue systems literature suggested dialogue system designers 
see cases learned policy outperforms standard policies near level significance case essentially tied 
surprisingly fixed policy fared best comparison similar policy learned 
addition optimizing large class policy choices considerably refined typical rl approach outperforms number natural standard policies 
discuss number reward measures optimize test system examined system improvement degradation 
measures considered far binary weak completion objective reward measures sense reward precisely defined function system log dialogue computed directly log 
contrast examined number subjective measures provided human user dialogue 
dialogue task accompanied web survey see asked user system reuse reward measure values worst best system easy easy reward measure values thought system understood said njfun understood reward measure values knew say point dialogue say reward measure values experience dialogue bad neutral web feedback reward measure values gamma respectively 
optimize subjective measures priori expectations improvement degradation shows find statistically significant changes mean direction measures 
observed curious move middle effect smaller fraction users extremely positive extremely negative things say test system training system 
firm explanation phenomenon consistency occurs varying degree subjective measures noteworthy 
briefly summarize 
empirical results demonstrated improvements optimized task completion measures complex spoken dialogue system please repeat give feedback conversation 
bad 
complete task get information needed 

conversation easy find place wanted 

conversation knew say point dialogue 

conversation njfun understood said 

current experience njfun njfun regularly find place go away computer 
user survey 
statistically significant changes number subjective measures interesting move middle effect 
corr 
slope inter 

policies coeff 
value test mdp accuracy 
generated deterministic policies randomly 
policy computed pair numbers estimated value mdp value trajectories consistent training data 
number consistent trajectories varied policy 
row policies second row policies consistent trajectories row policies consistent trajectories 
reliability empirical estimate policy increases increasing number consistent trajectories 
third column presents correlation coefficient empirical mdp values 
fourth column presents statistical significance correlation coefficient 
main result hypothesis sets values uncorrelated soundly rejected 
columns slope intercept resulting best linear fit sets values 
skeptic wonder simply fortunate mdp poor predictor value actions happened chosen policy chance 
closing evidence view offer results simple experiment randomly generated deterministic policies policy class 
policy training dialogues consistent compute unbiased monte carlo estimate expected binary completion return exactly done hand picked expert policies 
estimate paired value start state learned mdp 
mdp perfect model user population responses system actions monte carlo estimate simply noisy estimate correlation quantities significant course dependent number samples monte carlo estimate best fit linear relationship simply slope intercept normally distributed noise variable adjustable mean variance decreasing number consistent trajectories increases 
extreme mdp relation user population responses system actions uncorrelated best terms linear fit slope intercept ignore simply model noise 
results summarized indicate closer case 
random policies generated correlation positive rejected null hypothesis variables uncorrelated level significance furthermore squares linear fit gave slope coefficient close intercept close predicted idealized case 
detailed methodology rl design spoken dialogue system 
built large dialogue system methodology showed rl able effectively search large space dialogue policies size relatively small amount training dialogue data dialogues subjects 
learned policy outperformed training policy standard dialogue policies literature 
reported analyses verifying learned mdp reasonable model user population interaction njfun 
partially automate choice state features constructing mdp explore richer pomdp models additional empirical evaluation rl approach 
authors fan jiang substantial effort implementing njfun system esther levin roberto pieraccini help programming language eckert maintaining platform help watson david mcallester richard sutton esther levin roberto pieraccini numerous helpful conversations dialogue system design 
biermann philip long 

composition messages speech graphics interactive systems 
proc 
international symposium spoken dialogue pages 
crites barto 

improving elevator performance reinforcement learning 
proc 
nips pages 
danieli gerbino 

metrics evaluating dialogue strategies spoken language system 
proc 
aaai spring symposium empirical methods discourse interpretation generation pages 
haller mcroy eds 

special issue computational models mixed initiative interaction part user modeling user adapted interaction international journal vol 
nos 

haller mcroy eds 

special issue computational models mixed initiative interaction part ii user modeling user adapted interaction international journal vol 
nos 

kaelbling littman moore 
reinforcement learning survey 
journal artificial intelligence research pages 
levin pieraccini eckert 

learning dialogue strategies markov decision process framework 
proc 
ieee workshop automatic speech recognition understanding 
litman kearns singh walker 

automatic optimization dialogue management 
proc 
coling 
singh kearns litman walker 

reinforcement learning spoken dialogue systems 
proc 
nips 
smith 
evaluation strategies selectively verifying utterance meanings spoken natural language dialog 
international journal humancomputer studies pages 
sutton 

planning incremental dynamic programming 
proc 
ninth conference machine learning pages 
morgan kaufmann 
tesauro 

temporal difference learning 
comm 
acm pages 
walker narayanan 

learning optimal dialogue strategies case study spoken dialogue agent email 
proc 
coling acl pages 
