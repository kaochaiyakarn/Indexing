systematic extraction implementation divide conquer parallelism sergei university passau passau germany 
homomorphisms functions match divide andconquer paradigm computed parallel 
problems studied homomorphisms lists parallelism extraction finding homomorphic representation function parallelism implementation deriving efficient parallel program computes function 
systematic approach parallelism extraction proceeds generalization sequential representations traditional cons lists dual snoc lists 
non homomorphic functions maximum segment sum problem method provides embedding homomorphism 
implementation addressed introducing subclass distributable homomorphisms deriving parallel program schema time optimal hypercube architecture 
derivation equational reasoning bird meertens formalism guarantees correctness parallel target program 
approach illustrated function scan parallel prefix combination systematic methods yields folklore hypercube algorithm usually ad hoc literature 
motivation notation problem programming parallel machines managed put solid formal basis allows address correctness performance issues design process afterthought 
deals divide conquer parallelism studying functions called homomorphisms 
definition 
function defined lists homomorphism iff exists binary associative operation fi lists fi list concatenation 
intuitively means value concatenated list depends particular way combine operation fi values applied pieces list 
computations independent carried parallel viewed expressing known conquer paradigm 
examples homomorphisms simple functions summing elements list numbers complicated important functions scan prefix sums 
bird meertens formalism bmf functions including homomorphisms defined arbitrary composite types trees arrays equational reasoning deriving programs transformation :10.1.1.100.9674
higher order functions popular data parallel setting 
restrict non empty lists notation brevity definitions informal ff type lists elements type ff list concatenation ffi backward functional composition map map unary function map fx fx red fi reduce binary associative operation fi ff ff ff red fi fi fi fi 
backus fp construction zip fi combines elements lists equal length operation fi zip fi fi fi theorem bird :10.1.1.100.9674
function homomorphism iff factored composition red fi ffi map write hom fi unique homomorphism combine operation fi theorem provides standard parallelization pattern homomorphisms composition stages 
stage map totally parallel reduction computed parallel tree structure fi applied nodes 
main problems homomorphisms ffl parallelism extraction 
desirable able extract homomorphic parallelism function find corresponding combine operation fi satisfying property 
functions length construction simple scan function requires formal correctness proof intuition 
non homomorphic functions problem massage homomorphism 
ffl parallelism implementation 
reduction stage may inefficient functions yield lists direct implementation linear time complexity communication improved increasing number processor 
propose systematic approaches problems follows 
section consider sequential functional representations cons snoc lists show generalization terms extracting homomorphic representation 
section extends method functions illustrates known problem maximum segment sum 
section consider homomorphisms direct parallel implementation suffers high communication costs introduce subclass called dh distributable homomorphisms costs cut 
common parallel implementation schema dh derived mapped hypercube section 
illustrate scan function homomorphic representation extracted section section systematically adjusted dh format implemented hypercube yielding folklore algorithm usually ad hoc manner 
compare related section conclude 
extracting homomorphisms restrict finite non empty lists 
homomorphic representations list concatenation traditional functional programming constructors cons snoc 
delta cons attaches element front list delta snoc attaches element list 
definition 
list function called leftwards lw iff exists binary operation phi delta phi elements lists dually function rightwards rw iff omega delta omega phi omega may complicated functions lw rw 
fact proved meertens systematically gibbons 
theorem 
function homomorphism iff leftwards rightwards 
unfortunately pointed theorem provide way construct homomorphic representation function lw rw terms 
try rectify introducing new definition 
definition 
function called left homomorphic lh iff exists possibly non associative combine operation phi delta phi 
dual definition right homomorphic rh function obvious 
lh rh function lw rw function lw lh jaj delta ja ja gamma theorem 
function homomorphism combine operation fi hom fi lh rh combine operation 
function lh rh combine operation associative homomorphism combine operation 
proof see prove slightly stronger proposition 
example courtesy gibbons shows test associativity second part theorem necessary 
identity function id lists defined lh rh combine operation fi head init tail clearly homomorphism operation 
theorem suggests possible way find homomorphic representation construct cons definition function lh format dually find rh representation snoc lists prove combine operation associative 
simple method works example function length computing length list demonstrates 
example 
length 
cons definition length delta length length length 
length lh 
theorem associativity length hom 
example demonstrates method lh rh representations go smoothly 
example 
complicated example function scan associative operation fi list returns list running totals fi scan fi fi fi fi fi fi fi 
sequential cons definition scan follows scan fi delta delta map fi scan fi called sectioning exploited fix argument fi obtain unary function fi mapped 
representation match lh format scan allowed 
scan different possibilities express scan fst scan scan scan delta 
obtain possible terms fi terms defines associative operation 
try rightwards snoc definition scan fi delta scan fi delta scan fi fi alas run similar problem cons lists obvious substitutions fst scan scan lead non associative operation able express scan function homomorphism 
proceed general considerations get back example 
definition term th defines associative operation th fi 
term fu 
cg denotes result substituting variable terms built th substitutions tl th fx 
tr th fy 
obviously lh rh format see definition correspondingly 
terms tl tr semantically equivalent cons snoc representations function correspondingly 
example unsuccessfully tried pick cons term tc snoc term ts transform desired format various equalities theory lists 
omega means terms semantically equivalent equational theory relations terms introduced far illustrated diagram solid lines tl fi oe tc gamma gamma gamma gamma gamma fx 
lw th fi assoc oe tg oe generalization fy 
rw tr fi oe ts ultimate goal find term th tc ts scan function tc ts right hand sides correspondingly 
called generalization anti unification terms 
definition 
generalization equational theory terms substitutions oe oe term tg gene ft oe oe satisfies tg foe omega tg foe omega theorem 
lw term tc rw term ts function generalized term gene fx 
ts fy 
gg defines associative operation fi homomorphism fi combine operation 
call generalization theorem cs generalization cs cons snoc theory lists envisaged cs method finding combine operation understood diagram moving dotted arrows 
terms provided user tc cons ts snoc representation function checked lw rw format correspondingly 
cs generalized term tg associativity operation defined tg checked 
function scan representation obviously lw rw 
cs generalization yields term tg scan fi map scan fi fi scan fi operation fi defined tg associative fi map fi scan homomorphism scan fi hom fi fi 
designing cs generalization procedure investigating properties topic research scope 
section shows cs approach useful case non homomorphic functions 
homomorphisms practical non homomorphic functions called homomorphism convertible composition homomorphism adjusting function 
cole reports case studies constructing homomorphism tuple functions original function components 
main difficulty guess auxiliary functions included tuple find corresponding combine operation 
usually requires lot ingenuity program developer 
show cons snoc approach allows construct tuple homomorphisms systematically 
example 
consider maximum segment sum mss problem programming pearl studied authors :10.1.1.100.9674
list integers function mss finds contiguous segment list members largest sum segments returns sum notation mss gamma gamma gamma result contributed segment gamma 
empty segment defined sum result non negative 
express function mss cons lists 
element list may case mss delta mss mss returns larger integer arguments 
overlook possibility true segment interest includes initial segment introduce auxiliary function mis yields sum maximum initial segment 
add definition mis obtain closed definition tuple function mss mis cons lists mss delta mss mss mis mis delta mis mis approach requires define mss snoc lists 
leads auxiliary function mcs yielding sum maximum concluding segment mss delta mss mcs mss mcs delta mcs mcs tuples requires natural extension cs method notion homomorphism straightforwardly extended tuples generalization works representations union tuple mss example mss mis mss mcs mss mis mcs 
trying find cons definition mcs snoc definition mis see concluding segment delta may list need know sum combination functions yield 
introduce auxiliary function ts total sum 
function homomorphic tupling identity function trivial case clearly interest parallelization 
constructed quadruple mss mis mcs ts cons snoc representations obviously lw rw correspondingly mss delta mss mis mss mis delta mis mis mcs delta mcs ts ts delta ts ts fi fi fi fi fi fi fi fi mss delta mss mcs mss mis delta mis ts mcs delta mcs mcs ts ts delta ts ts applying cs generalization procedure pair wise see details obtain combine operation mss mis mcs ts fi mss mis mcs ts mss mcs mis mss mis ts mis mcs mcs ts ts ts fi associative tuple homomorphism mss mis mcs ts hom fi determines result tuple singleton list 
mss mis mcs ts target function mss computable follows mss fst ffi red fi ffi map function operation fi require constant time total time complexity homomorphic algorithm log 
processor number reduced log simulating lower levels tree sequentially brent theorem 
algorithm time cost optimal 
apply cons snoc generalization method parsing problem called input driven languages 
concatenating distributable homomorphisms section address second problem finding efficient parallel implementation homomorphism 
known difficulty arises output list homomorphism list 
case combine term top function com op call homomorphisms concatenating 
reduce stage starts singleton lists map stage arrives long result list root tree 
communication lists growing length induces linear execution time independently number processors 
follows scan concatenating homomorphism 
exist parallel logarithmic algorithms scan performance parallel machines producing monolithic output list distribute processors 
goal derive algorithms systematically 
restrict length balanced concatenation reduction red fi defined iff length length definition 
distributable combine operation phii omega lists equal length phii omega zip phi zip omega phi omega arbitrary binary associative operations elements 
definition 
distributable homomorphism dh denoted phi omega associative operations phi omega unique homomorphism phi omega hom phii omega phii omega defined 
illustrates dh computed concatenation lists dashed arrows denote replication partial results 

zip hx hy zip hx hy fig 

distributable homomorphism illustration simple example consider function list numbers yields sum sum sum sum delta delta delta yields sum list elements 
easy express component wise format zip zip 
generally function called distributed reduction defined fi red fi red fi red fi fi function implemented primitive mpi standard 
efficient parallel implementation ultimate goal find provably correct efficient parallel implementation dh functions 
section design implementation schema map hypercube topology 
introduce auxiliary functions 
functions simple rearrangements att nat ff 
nat ff att glue ff 
nat ff 
nat ff ff glue function permute interchanges pair wise elements distance positions list distance argument permute 
function attaches element flag equal element changed position left permute nat ff nat ff permute permute permute length permute map att map att length function triples composes list result permutation triples nat ff nat ff ff triples zip glue permute function apply performs binary operations phi omega elements list triples depending value flag apply ff ff ff ff ff ff 
nat ff ff ff apply phi omega phi omega illustrates function permute introduced function step element list 
permute step permute step fig 

functions permute step illustration step nat 
ff ff ff ff ff ff ff ff step phi omega map apply phi omega ffi triples function iter sequence step applications iter nat nat 
ff ff ff ff ff ff ff ff iter phi omega id iter phi omega iter phi omega ffi step phi omega definition iter tail recursive obvious iterative implementation usual cascading recursion homomorphism 
theorem establishes equivalence forms 
theorem 
arbitrary associative phi omega lists length phi omega iter phi omega proof induction theorem provides common iterative computation schema dh functions 
step map architecture independent solution particular processor topology 
example consider hypercube 
lists length stored dimensional hypercube nodes 
standard encoding position list stored node index bit binary representation access function hypercube hyp ff nat ff yields list index th element processor hypercube communicate directly neighbours indices differ bit position position determines dimension communication takes place 
dimension pairs processors communicate simultaneously dilation congestion 
processor partner dimension computed xor gamma xor bit wise exclusive 
definition 
function swap expresses pattern hypercube behaviour swap nat 
ff ff ff ff ff ff ff ff hyp swap phi omega hyp phi hyp hyp omega hyp length xor gamma definition follows compute result swap processor processor access element position communicate neighbour dimension swap consists pair wise directional communication dimension followed computation 
proposition establishes correspondence step iterative solution application swap 
theorem 
lists length holds step gamma phi omega swap phi omega introducing notation swap phi omega swap phi omega ffi delta delta delta ffi swap phi omega ffi swap phi omega obtain theorem theorem corollary common hypercube implementation 
dh computed node hypercube sequence swaps dimensions counting phi omega swap phi omega schema expresses standard way programming hypercubes implementation target spmd program explicit message passing generated easily 
implementation scan section derive parallel program computes scan function 
check scan function dh 
combine operator scan fi fi map fi scan fi scan fi task express right hand side component wise format sides zip form 
part left zip yields element pair 
obvious way express part right component wise replicate element 
scan fi red fi replication yields fi 
allows reformulate fi component wise fi zip zip fi introduced function fi homomorphisms tuple functions scan fi fi 
fit dh format massage tuple new function yields list pairs pair lists fi zip pi ffi scan fi fi 
pi elements matches dh format combine operator psi zip fi zip fi additional auxiliary functions necessary 
function expressed follows fi phi omega ffi map pair function pair transforms element pair operations phi omega pairs elements directly read pair phi fi omega fi fi follows expression scan adjusted dh format scan fi map ffi phi omega ffi map pair pair phi omega defined 
adjusted scan function dh format 
tuple structure initialization function pair computations expressed phi omega results systematic adjustment process 
directly rewrite implementation schema obtain hypercube program scan scan fi map ffi swap phi omega ffi map pair pair phi omega 
known folklore implementation 
illustrated dimensional hypercube computing scan 
map pair swap swap map pi fig 

computing scan hypercube implementation consists stages pairing repeating swaps projecting 
list length need processors 
pairing projection stage require constant time 
central stage sequential loop swaps swap pairs elements communicated computations performed pairs swap requires constant time 
time log implementation time optimal 
cost time processor product log cost sequential computation implementation cost optimal 
improve fewer processors processor working segment input list 
formal derivation time cost optimal algorithm practical situation exploits bmf transformations involve data distributions subject 
related approach parallelism extraction compared consider examples 
simple examples length 
scan involved calculations intuition required obtain fi advantages systematic cs approach evident 
homomorphisms method suitable 
existence leftwards rightwards algorithms evidence homomorphic algorithm exists approach authors provide method derive 
solution maximum segment sum problem similar provided earlier smith cole 
contribution systematic cs method provides uniform way introducing necessary auxiliary functions second exploits rigorous generalization procedure deriving resultant combine operation tuples 
parallelization scan function rich history starting seminal ladner fisher 
parallel algorithms scan part folklore usually ad hoc manner 
exceptions compare approach 
mou specifies scan algorithm algebraic model divide conquer suggests optimization similar tuple structure arises non formal argument result proved formally 
tree algorithm verified formally donnell derived formally gibbons 
arrives formally algorithm ladner fisher recursive notation 
approach differs target implementation result systematic provably correct adjustment specialization process obtained iterative form stages computations communication seen explicitly 
construction function iter special case compound list operations kumar skillicorn different purpose 
restriction lists length common misra 
get rid explicit recursion target program introducing iterative constructs 
approach restrictive consider list interleaving constructor misra 
approach similar deriving architecture independent solution mapping particular topologies taken schulte 
consider special class dh allows exploit additional transformations 
approach extended arbitrary number processors simd model 
general implementation schema dh functions hypercube resembles common structure ascending algorithms studied seminal preparata vuillemin 
view analogy promising sign research building taxonomy functions respect efficient parallel implementations 
propose approach exploiting divide conquer parallelism functions lists consists steps parallelism extraction finding homomorphic representation function second parallelism implementation adjusting function dh format common parallel implementation schema 
claim approach systematic methods previously reasons parallelism extraction step user provides sequential definitions function closed leftwards rightward form 
theorem difficulty finding lw rw form indicates function non homomorphic 
requirement closeness see mss example guides necessary auxiliary functions 
rest job done generalization procedure 
parallelism implementation step function cast dh format serves guide user 
implementation schema customized correspondingly 
methodologically important feature parallelism extraction step sequential thinking developer required provide sequential functional programs transformed generalization procedure 
considerations involving data control dependences usual parallelization techniques completely avoided 
contribution implementation methodology definition dh class functions lists formal derivation common efficient parallel implementation schema functions class 
derivation semantically sound transformation rules bmf guarantees correctness 
performance common target implementations easily predictable conforms known estimates 
includes designing standard generalization procedure cs method extending class functions efficient parallel implementation schemata various architectures built systematically 
acknowledgments am grateful murray cole jeremy gibbons christian lengauer lambert meertens christoph discussing different parts manuscript 
anonymous referees helped lot better 
author partially supported daad cooperation programs arc project 

schulte 
architecture independent massive parallelization divide conquer algorithms 
moeller editor mathematics program construction lecture notes computer science pages 

barnard schmeiser skillicorn 
deriving associative operators language recognition 
bulletin eatcs 

bentley 
programming pearls 
communications acm 

bird 
lectures constructive functional programming 
broy editor constructive methods computing science nato aso series computer systems sciences 
vol 
pages 
springer verlag 

blelloch 
scans primitive parallel operations 
ieee trans 
computers november 

mou 
compile time transformations optimizations parallel divide conquer algorithms 
acm sigplan notices 

cole 
parallel programming list homomorphisms 
parallel processing letters 

gibbons rytter 
efficient parallel algorithms 
cambridge univ press 

gibbons 
third homomorphism theorem 
fun 
programming 
appear 

gibbons 
upwards downwards accumulations trees 
bird morgan woodcock editors mathematics program construction lecture notes computer science pages 

gibbons 
third homomorphism theorem 
technical report univ auckland 


constructing list homomorphisms 
technical report mip universit passau 


stages transformations parallel programming 
kara editors machine models parallel distributed computing pages 
ios press 


systematic optimal parallelization scan list homomorphisms 
proceedings euro par 
lncs appear 

duff harrison 
parallelism homomorphisms 
parallel processing letters 
appear 

heinz 
lemma discovery anti unification regular sorts 
technical report tu berlin may 


mapping functional notation parallel programs hypercubes 
information processing letters 

plasmeijer 
distributed implementation dataparallel functional language 
parle lncs pages 

kumar skillicorn 
data parallel geometric operations lists 
parallel computing 

ladner fischer 
parallel prefix computation 
acm 

misra 
structure parallel recursion 
acm toplas 

mou 
parallel language scientific computing divide conquer 
proc 
rd symposium frontiers massively parallel computation pages october 

donnell 
correctness proof parallel scan 
parallel processing letters 

preparata vuillemin 
cube connected cycles versatile network parallel computation 
communications acm 

quinn 
parallel computing 
mcgraw hill 

skillicorn 
foundations parallel programming 
cambridge univ press 

skillicorn cai 
cost calculus parallel functional programming 
journal parallel distributed computing 

smith 
applications strategy designing divide conquer algorithms 
science computer programming 

swierstra de moor 
virtual data structures 
moeller editors formal program development lecture notes computer science pages 

walker 
design standard message passing interface distributed memory concurrent computers 
parallel computing 
article processed macro package llncs style 
