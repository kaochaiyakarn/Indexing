implementing distributed linda standard ml ellen siegel eric cooper october cmu cs school computer science carnegie mellon university pittsburgh pa implemented linda model shared distributed tuple space functional programming language standard ml 
ml flexible type system pattern matching facilities provide ml programmers basic linda operations tuples 
preprocessor compiler changes required 
separate ml modules implement linda interface operations tuple space communication tuples network replication tuple spaces 
approach allows different compositions modules configure system local remote access tuple space centralized distributed implementation tuple space 
resulting implementation linda standard ml offers attractive way separate functional imperative portions distributed system 
individual processes written ml pure functional style linda shared tuple space interconnect processes maintain state system 
research sponsored defense advanced research projects agency monitored air force systems command contract 
views document authors interpreted representing official policies expressed implied defense advanced research projects agency government 
keywords programming languages parallel distributed systems linda standard ml constructed flexible expressive environment implementing distributed systems combining standard ml support functional programming flexible type system linda model parallel programming 
implemented linda shared distributed tuple space ml preprocessor making compiler modifications 
separate ml modules implement linda interface operations tuple space communication tuples network replication tuple spaces 
approach allows different compositions modules configure system local remote access tuple space centralized distributed implementation tuple space 
linda shared distributed tuple space complements functional style ml providing natural mechanism maintaining shared global state location transparency necessary synchronization provided transparently linda system 
section provides background various systems implementation ml linda 
section discusses relevant design issues 
section examines major interfaces implementation choices major protocols sketched section 
status system directions discussed section 
background linda set high level operations added base language yield parallel dialect language 
linda programming model consists associative memory called tuple space set operators eval rd unit communication tuple list typed fields actual formal 
operation adds tuple tuple space 
operation removes tuple space tuple matches specified template blocking necessary match binding formal parameters template corresponding actuals matching tuple 
rd operation similar remove matching tuple tuple space 
predicates inp rdp nonblocking versions rd eval adds active tuple tuple space tuple fields computed independent process resolves conventional passive tuple 
linda program selects tuple specifying general tuple template matched contents tuple space 
tuple space contains matching tuple nondeterministic selection 
matching algorithm described detail section 
standard ml strongly typed functional supports polymorphic types exception handling garbage collection powerful module system 
expressivity type safety combined incremental approach constructing large programs attractive candidate building complex distributed parallel programs 
modular unit ml structure ml uses signatures describe functions types exported structures 
ml structures combined hierarchically parameterized modules called functors 
ml threads package provides facilities creating synchronizing multiple threads control single ml address space 
linda runtime system tuple space single local tuple space linda runtime system distribution tuple space tuple space tuple space multiple local tuple spaces design issues high level design goal build implementation linda standard ml transparently operated modes locally figures remotely single tuple space node remotely multiple nodes functioning distributed tuple space 
result distributed linda system client server processes may reside separate nodes communicate remote procedure call 
design avoids compiler modifications minimizes changes linda syntax semantics 
design takes layered approach achieving transparency advantage ml strong typing modular structure 
visible layers linda runtime layer tuple space storage layer 
communication layer insulates system network provides support remote procedure call distribution layer manages state associated multiple nodes distributed tuple space 
transparency flexibility achieved having communication distribution structures export ml signature tuple space structure 
transparent linda runtime system tuple space communication communication single remote tuple space tuple space communication tuple space communication tuple space communication linda runtime system communication distribution multiple remote tuple spaces layered approach allows ml linda system configured link time local remote access centralized distributed tuple space simply deciding modules include functor application build system 
specification distributed tuple space nodes configuration require performed run time 
system trivially expanded multiple tuple space environments instantiating desired number linda runtime modules 
basic linda system tuple 
tuples represented prototype list elements discriminated union int string bool pair int formal string formal bool formal wildcard collectively called ltype 
constructors int string bool take appropriate arguments recursive pair constructor takes pair representing linda formals take 
ml list type allows arbitrary number tuple fields 
generic wildcard formal extension linda typed formals 
runtime type information provided explicit ltype constructors increases expressive power ml linda operators power purely statically typed scheme albeit cost ease 
set primitive types provided initial implementation somewhat limited pair constructor provides equivalent cons cell build arbitrary data structures 
fact tuples represented directly nested applications pair constructor chose list representation provides simpler syntax application programmer 
arbitrarily complex distributed live data structures constructed tuple space 
distributed data structures advantage distributed components tuples components automatically available concurrent access linda runtime system provides necessary synchronization 
linda implementation compiler modifications requires access runtime type information match procedure 
standard ml statically typechecked require availability runtime type information 
implementation gets runtime type information requiring slightly modified syntax linda calls involves explicitly specifying field types tuple template arguments ltype constructors 
interfaces implementations interface specifications system linda runtime system interface tuple space server interface 
linda runtime linda runtime structure provides application level interface ml linda system 
signature describes types exceptions operations applications 
tuple space operators supported eval 
main function eval introduce concurrent processes ability fork concurrent threads ml environment provides essentially functionality 
linda runtime signature addition basic tuple space operators exports exception forthcoming version standard ml new jersey support dynamic runtime types may allow simplify linda interface 
signature linda sig structure tuplespace tuplespace exception val init string list unit val tuplespace ltype list unit val rd tuplespace ltype list tuplespace ltype list val tuplespace ltype list tuplespace ltype list val rdp tuplespace ltype list tuplespace ltype list val inp tuplespace ltype list tuplespace ltype list linda runtime signature indirectly exports discriminated union type ltype tuplespace substructure referenced tuplespace ltype 
capitalized operation names reserved word ml 
syntax seen programmer differs slightly linda dialects 
linda tuple represented ml list 
invocation linda operations ml requires fly construction ltype list desired tuple parameters deconstruction result tuple result returned ltype list direct binding formal parameters values linda 
illustrate differences compares syntax ml linda linda 
program fragments invokes linda operations rd linda uses preprocessor extract type information arguments call need specify types long previously declared program 
contrast call ml linda explicitly represented list denoted square bracket delimiters list element tuple field tagged appropriate constructor 
linda runtime structure exports application level interface maintains state generating hash strings unique ids translates runtime operations appropriate calls tuple space 
example small application program linda shown 
program exports functions repeatedly writes tuple string ping reads string pong reads tuple string ping writes string pong 
ml threads package functions forked concurrently executing threads portion code shown 
ml linda solution classic dining philosophers problem shown 
code create philosopher threads shown 
tuple space tuple space interface exported tuple space server additional layers linda runtime system 
additional layers virtualize tuple space interface 
operations correspond roughly runtime interface high level linda operations broken parts tuple space interface 
inp operations broken phases purge restore phases blocking rd operation likewise second phase rd done 
second phases operations required clean state undo side effects initial operations 
phase linda int char int struct pair char str int flag linda uses operator label formals rd 

ml linda val val string int int val int string int formal val template pair string formal int formal val pair string str int flag rd template str flag syntax ml linda linda local open linda tuplespace fun ping string ping print ping string pong ping fun pong string ping print pong string pong pong simple example local open linda tuplespace val num val room ticket string room ticket fun left chopstick string chopstick int fun right chopstick string chopstick int mod num fun philosopher think room ticket left chopstick right chopstick eat left chopstick right chopstick room ticket philosopher dining philosophers ml linda approach necessary tuple space implementation distinguish distributed cases order keep distribution transparent linda runtime system 
tuple space represented data structure maps hash strings tuples 
data structure implemented array linked bucket structures 
tuple space module multiple clients may multithreaded implementation provide appropriate synchronization locking shared data structures 
array slot corresponding lock 
array slots locked add operations lookup 
serializes operations modification involves updating value array slot bucket structures immutable 
node distributed tuple space maintains version tuple space data structure 
tuple field types restricted expressed constructors ltype discriminated union exported tuple space structure 
table tuple matching types values order tuple fields 
initial implementation takes naive approach hashes string constructed substrings representing type field order appearance tuple tend result unbalanced table tuples type grouped 
implement slightly modified version linda matching algorithm tuples formal fields allowed template parameters reside tuple space 
details matching protocol described section 
distributed tuple space distributed tuple space single logical associative memory implemented set distinct tuple space servers distributed collection physically separate nodes 
tuple storage matching systems replicated node distributed tuple space stored contents replicated 
node distributed tuple space manages resources exports linda functionality 
logic involved combining individual nodes single logical tuple space located distribution module layered transparently linda runtime communication layer 
signature tuplespace sig datatype ltype int int string string bool bool int formal string formal bool formal pair ltype ltype wildcard exception notfound val init string list unit add val add string ltype list unit lookup phase rd rdp val lookup string string ltype list bool ltype list rd done phase rd rdp val rd done string unit phase inp val string string ltype list bool unit purge restore phase inp val purge string bool ltype list val restore string unit tuple space signature tuplespace tuplespace tuplespace linda client distribution linda client distribution multiple clients distributed tuple space important goal distributed linda implementation transparency 
client application depend interface tuple space aspects having communication distribution physical location 
means distribution tuples distributed tuple space independent implementation choices hashing algorithm 
tuples may reside valid node distributed tuple space see client application sees single unified view tuple space 
ideally tuples distributed available nodes way optimize necessary network traffic balance loads relevant nodes 
initial implementation takes simple approach selects destination nodes cycling tuple space nodes 
general approach managing consistency availability data distributed system involves replication appropriate read write quorums 
ensure valid data available accesses read quorums updates write quorums 
sum read write quorums greater total number nodes system ensuring quorums overlap node 
replication scheme normally legal combination read write quorums linda implementation safely read write read quorums compromising location transparency system 
peculiarity due ambiguity rd operation 
reading single logical object rd operation returns member arbitrarily large set possible matching tuples 
set replies guaranteed include copies object arbitrary read quorum necessarily provide required overlap corresponding write quorum 
ml linda distribution layer uses read write approach communicate distributed tuple space 
means sends tuple single tuple space node rd request matches nodes 
simulate multicast communication multiple threads remote procedure calls parallel 
chose write semantics read write order minimize amount data transmitted tuple needs transmitted operation 
rd sent tuple space nodes match chosen furthermore version tuple space modified requests target specific tuple 
read write scheme inp operation expensive lookup operation performed single node remaining nodes involved order delete tuple tuple space 
distributed tuple space read write semantics application receive different tuples response inp rd operation 
phase operation tentatively remove matched tuple tuple space unavailable subsequent match requests 
inp destructive operation match accepted tentative removals associated responses undone 
addition restoring unwanted matches necessary terminate remote threads blocked operation 
details theta processor grid discussed allows valid intermediate quorum assignment depends physical configuration system 
configuration write quorum node consists nodes row read quorum consists nodes column 
rd return matching tuple optimization generally expect single match rd require second phase nodes returning notfound 
discussed detail section 
managing distributed tuple space discussed greater detail section 
communication implementation distributed linda requires typesafe transparent communication complex objects node 
rd operation binds fields appropriate matching tuple set local variables modified referenced 
order transmit opaque type necessary provide communication system information implementation available signature effectively type explicit requires new mechanism preprocessor extract relevant type information available communication system 
complex types implementations included signature explicit readily transmitted 
constraints ml type system impractical opaque types tuple fields 
order linda shared tuple space concrete representations visible 
ml linda implementation follows client server model individual tuple space nodes acting remote servers local linda client application 
communication support provides client server stub structures hide communication details application code 
stub structures provide routines marshaling unmarshaling relevant argument result types control structures making remote procedure calls 
server communication layer provides listener loop waits incoming requests network forks threads service 
communication structures appear transparent application server code export interface tuple space structure 
distributed version tuple space additional stub layer added hide distribution see 
client application see tuple space abstraction regardless tuple space structure local remote distributed 
ideally distribution module able multicast operations support multicast available 
current implementation simulates multicast multiple threads performing calls parallel 
protocols section describes linda tuple matching algorithm presents protocols implement distributed tuple space read write scheme described section 
tuple matching communication synchronization linda model accomplished tuples moving tuple space 
linda tuple matching algorithm defined follows 
call tuple defined fields rd operation template 
template matches tuple tuple space conditions hold ffl number fields 
ffl corresponding fields types 
ffl pair corresponding fields match follows actuals match respective values equal equality defined base language objects type 
formal actual match value may eventually assigned variable 
assignment takes place fields match 
actual formal match unconditionally 
value discarded 
formals match 
state information protocol inp discussed detail runtime system tuple space points view 
protocols sketched rd rdp operations runtime system point view 
operations construction hash string template tuple argument linda runtime system level see 
string hello int bool true string int bool string hello pair int formal bool formal wildcard string pair int formal bool formal wildcard hash string construction distribution structure maintains set data structures record state match tuple space node participating phase inp rd data structure includes ffl indicator empty string uniquely identifies operation structure 
ffl pointer connection supplying chosen match 
ffl tuple space status variable tuple space node 
tuple space status indicated discriminated union null match notfound state reset null operation time null indicates thread hasn returned failure model equivalent blocked thread 
synchronization achieved locking indicators 
process acquire lock order modify field field set null value 
process sets field unique id value corresponding data structure reserved resets field 
tuple space implements data structure maintains state required phase operations inp rd data structure maps unique id supplied linda runtime system match record consisting unique id hash string tuple kill record consisting unique id data structure currently implemented array linked structures lock array slot ensure access threads unique id serialized 
linda runtime module responsible generating hash strings tuple space operations unique id inp rd operations 
operation hash strings constructed simply concatenating strings representing type tuple template field 
unique id concatenation string representations sequence number incremented host name process id hash string 
inp operations operation phase operation implemented sequential remote calls see 
phase operation involves tuple space nodes 
second phase purge restore operation invoked node participating phase 
connect phases operation linda runtime assigns unique id sent argument remote call 
emulate multicast operation calls phase concurrently forking thread tuple space node 
find match delete tuple choose match purge restore linda runtime distribution tuplespace server multicast templates matching tuple th match nil acknowledgment protocol operation application side distribution layer reserves status structure writing unique id field 
emulates multicast operation concurrently sending unique id request template hash string linda runtime module tuple space nodes 
thread returns records appropriate status status structure thread match may modify match connection variable 
match call may terminated 
done making purge request tuple space node specified match connection variable making restore requests remaining tuple space nodes undo tuple space modifications kill blocked threads remaining request 
purge restore requests unique id access tuple hash string information stored state array 
purge operation returns matched tuple returned application process 
phase blocking operation may leave blocked threads tuple space nodes application chosen tuple 
threads located terminated part cleanup operation 
remote threads running concurrently possible remote match particular tuple space node time restore request running 
conditions create need communication synchronization filled tuple space state structure 
application provides phases unique id unique operation application 
hash table holds match record lookup phase kill record restore phase indicates lookup thread terminate 
thread acquires appropriate lock executing ensure blocked thread return match kill command issued 
remote server thread executes operation loop 
top loop immediately acquires lock part state structure corresponding unique id checks kill command restore operation exists thread clears command state array releases lock exits 
record restore operation thread searches tuple space match 
match matching tuple hash string recorded state array operation unique id thread releases lock returns 
match lock released thread blocks 
blocked threads awakened time tuple added restored tuple space 
blocked thread awakened continues execution top loop 
second phase operation consists single purge invocation node provided chosen match invocations restore remaining tuple space nodes 
remote thread executing restore acquires lock part state array corresponding unique id checks state array see thread phase matching tuple 
restore thread clears entry state array uses recorded information restore appropriate tuple tuple space releases lock returns 
matching tuple remote thread records kill command blocked thread find awakens releases lock returns 
purge operation similar restore operation simpler 
remote thread acquires lock appropriate part state structure clears existing entry state array releases lock returns 
purge request issued node returned match thread phase left record status array exited 
differences blocking operations relatively minor 
tuple space threads executing inp fail find match return notfound exceptions distribution module blocking matching tuple appears 
threads return notfound inp call relay exception application 
second phase nonblocking version need issue restore requests remote nodes raised notfound exception left state remote tuple space 
protocol 
rd operations rd operation similar phase operation side effects tuple space 
linda runtime system multicasts template argument hash string nodes distributed tuple space 
blocking rd call includes unique id status record may written match 
status record unnecessary nonblocking rdp call remote threads exit need clean remote state 
blocking rd threads involved call local remote remain blocked match 
response tuple received outstanding requests nodes canceled rd done operation tuple returned application 
rdp nonblocking tuple space node searches database returns tuple match raises notfound exception 
linda runtime simply returns matching tuple notfound exception node finds match 
write operation runtime system forwards tuple argument constructed hash string node distributed tuple space 
assuming reasonable distribution processes optimal write tuple local node tuple space node 
current implementation simply rotates list tuple space nodes provide wider distribution tuples 
addition new tuple tuple space causes blocked threads awakened try match new tuple 
discussion distributed linda implemented replication hashing 
designs include notion dynamic migration set tuples consumed particular node efficient stored directly node 
hash approach implements tuple space distributed hash table buckets map node 
tuples categorized disjoint sets hash function provided ensures tuples common characteristics hash bucket node 
tuple stores match requests directed node specified hash function localizing search area 
replicated approach easier add new types tuples system migrate existing tuples node 
depending relative frequency different operations replicated approach may require network traffic assuming multicast broadcast available 
performance approaches depend significantly pattern communication active processes 
fault tolerance unrealistic assumption production system ml linda prototype guarantee consistency correctness presence failures 
correctness linda communication model threatened failures crashes partitions 
conventional systems communication linda process process node node linda model constrains locations processes lifetime data tuple space external way tell data absent producer process died relevant nodes crashed partitioned data produced 
furthermore operations require participation nodes distributed tuple space making system highly vulnerable node communication failure 
replicated multi phase operations particularly difficult implement correctly presence failures 
fault tolerant implementation require support persistent storage transaction system ensure correctness leaves open possibility indefinitely long blocking multiple stages protocol 
status prototype ml linda system implemented standard ml new jersey compiler running mach operating system 
consists roughly lines ml implementing functors linda runtime distribution tuple space 
communication subsystem generated tuple space signature rpc stub generator included tally 
system runs vax mips sun machines 
earlier version implemented blocking rd operations repeatedly polling tuple space linda runtime layer current version uses blocking threads described sections ml thread scheduler integrated mach communication facilities 
performance current system require tuning enhancements production system 
straightforward require understanding typical application behavior order identify bottlenecks stresses system 
important direction implement different types linda applications monitor distribution frequency linda operations patterns average lifetimes tuples 
useful compare performance different heuristics choosing tuple space nodes operation possibly dynamic migration 
dynamic migration useful systems rd operations 
types heuristics integrated dynamic tuple space resizing part attempt keep distribution tuples properly balanced 
designing better hashing algorithm help keep tuples evenly distributed tuple space single node 
prototype implementation ml linda demonstrates feasibility combining ml functional approach linda model parallel programming distributed tuple space 
ease decomposing linda system ml modules reinforces suitability ml constructing complex distributed programs 
addition linda shared tuple space complements ml functional style provides flexible environment benefits programming models development distributed systems 
michael accetta robert baron william bolosky david golub richard rashid tevanian jr michael young 
mach new kernel foundation unix development 
proceedings summer usenix conference pages july 
ahuja nicholas carriero david gelernter venkatesh krishnaswamy 
matching language hardware parallel computation linda machine 
ieee transactions computers august 
andrew appel david macqueen 
standard ml compiler 
functional programming languages computer architecture pages 
springer verlag 
volume lecture notes computer science 
robert 
experience linda ipsc 
research report department computer science yale university march 
robert nicholas carriero david gelernter 
linda portable parallel 
research report department computer science yale university february 
nicholas carriero david gelernter 
net linda kernel 
acm transactions computer systems may 
nicholas carriero david gelernter 
write parallel programs guide 
acm computing surveys september 
nicholas carriero david gelernter 
linda context 
communications acm april 
eric cooper gregory morrisett 
adding threads standard ml 
technical report cmu cs school computer science carnegie mellon university december 
david gelernter 
generative communication linda 
acm transactions programming languages systems january 
david gelernter 
multiple tuple spaces linda 
parle volume lecture notes computer science pages 
springer verlag june 
david gifford 
weighted voting replicated data 
proceedings th symposium operating systems principles pages december 
published operating systems review 
robin milner mads tofte robert harper 
definition standard ml 
mit press 
robert 
linda supercomputing local area network 
proceedings supercomputing pages november 
