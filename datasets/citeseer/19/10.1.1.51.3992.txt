nonparametric multivariate density estimation comparative study hwang rong lay alan lippman information processing laboratory department electrical engineering ft university washington seattle wa algorithmically empirically studies major types nonparametric multivariate density estimation techniques assumption data drawn known parametric families distribution 
type popular kernel method variants uses locally tuned radial basis gaussian functions interpolate multi dimensional density second type exploratory projection pursuit technique interprets multi dimensional density construction dimensional densities highly interesting projections multidimensional data 
performance evaluations training data mixture gaussian mixture cauchy densities 
results show curse dimensionality sensitivity control parameters adverse impact kernel density estimators projection pursuit density estimators 
research partially supported national science foundation 
ecs nasa contract 

alan lippman supported postdoctoral fellowship office naval research 

signal processing applications algorithms properly probability densities multivariate signals noises known 
unfortunately reality densities usually available parametric non parametric estimation densities critically needed 
parametric density estimation assumptions parametric form distribution generates data nonparametric density estimation rigid assumptions distribution data 
probability density function pdf dimensional data continuous smooth function satisfies positivity integrate constraints dy set dimensional observed data ng task multivariate density estimation find estimated function best approximates true probability density function hand probability mass function pmf discrete function satisfies positivity sum constraints successful classification regression applications 
success pmf results developed clustering algorithms cluster multi dimensional data fy ng centroids fm kg pmf obtained estimating proportion data population cluster 
dealing continuous pdf successfully applied applications classifier design image restoration compression traditionally statistically pdf constructed locating gaussian kernel observed datum fixed width kernel density estimator adaptive kernel density estimator akde 
constructs density placing fixed width kernels observed data widely nonparametric density estimation method normally suffers practical drawbacks 
example inability deal satisfactorily tails distributions main part density 
curse dimensionality exponentially increasing sample size required effectively estimate multivariate density number dimensions increases 
akde introduced improve performance 
similar akde constructs density placing kernels observed data 
uses kernels fixed width akde allows widths kernels vary point 
akde slightly improves estimation capability reduce high cost incurred computation memory storage commonly required 
overcome problem high cost computation memory storage clustered radial basis function rbf kernel density estimator named rbf network 
rbf network uses reduced number radial basis kernels kernel representative cluster training data approximate unknown density function 
method referred mixture gaussian modeling 
rbf networks widely regression classification applications 
similar construction pmf construction rbf network requires determination cluster centroids fm furthermore estimates data correlation proportion clusters translated bandwidths orientations heights interpolating gaussian kernels deployed cluster centroids smooth continous pdf constructed 
determination centroids associated kernel parameters accomplished stage batch process done iterative manner 
stage batch process starts acquiring satisfactory set cluster centroids determine kernel bandwidths orientations heights batch statistical analysis sense maximum likelihood 
iterative kernel deploying approaches construction rbf density estimators iterative expectation maximization em algorithm maximum likelihood optimization procedure treating cluster label indicates kernel datum belong missing data maximizes likelihood respect kernel parameters centroids bandwidths orientations heights 
drawbacks approach slow convergence sensitivity initial label parameter guesses 
cases likelihood unbounded certain parameter space procedure diverge initial guess close space 
optimization approaches em algorithm suffers local optimum issues 
focus discussion stage batch process rbf network construction 
stage batch construction rbf network sequential batch clustering algorithms commonly determining cluster centroids 
clustering algorithms perform poorly presence probabilistic outlying data data large variations dynamic range dimensions imposing high sensitivity selection distance measures clustering 
overcome difficulties statistical data sphering technique combined centroid splitting generalized lloyd clustering technique known lbg algorithm robust rbf density estimator construction 
robust construction method successfully applied classification tasks 
robust rbf construction technique overcome difficulties encountered conventional rbf networks density estimation overcome drawback estimators performance sensitive settings control parameters number kernels locations kernels orientation kernels kernel smoothing parameters excluding threshold radius data sphering size training data motivated study statistical projection pursuit density estimation technique 
contrast locally tuned kernel methods data analyzed directly high dimensional space vicinity kernel centers projection pursuit method globally projects data dimensional subspaces analyzes projected data low dimensional subspaces construct multivariate density 
specifically projection pursuit defines index interest projected configuration variance adopted principal component analysis uses numerical optimization technique find projections interest 
projection index adopted density estimation degree departure projection data normality 
technique applied exploratory multivariate data analysis statistical tools 
organized follows section presents various versions kernel density estimators fixed width kernel method adaptive kernel method robust rbf method 
section discusses algorithms implementing projection pursuit density estimator 
extensive comparative simulations discussions results performed section followed concluding remarks section 
data point example fixed width kernel density estimation 
kernel density estimation set dimensional training data fy ng multivariate fixed width kernel density estimator kernel function oe fixed global kernel width parameter gives estimated density multivariate data nh oe kernel function oe chosen satisfy oe oe dy popular choice oe gaussian kernel oe exp symmetric kernel value smoothly decaying away kernel center 
illustration small training data set size 
normally observed data equally spread directions 
highly desired pre scale data avoid extreme differences spread various coordinate directions 
attractive approach sphere whiten data linear transformation yielding data zero mean unit covariance matrix apply eq 
sphered data 
specifically set dimensional observed data fyg define sphered data ey expectation evaluated sample mean data covariance matrix ey ey ud note orthonormal matrix diagonal matrix 
robust statistics methods derivation data covariance matrix easily shown sphering zz identity matrix 
resulting sphered data performs sophisticated density estimation nh oe det nh oe optimal kernel width determined minimization mean integrated squared error mise 
example gaussian kernels proposed estimating normally distributed data unit covariance 
complicated methods determining kernel width square crossvalidation method available increasing complication computation 
probabilistic neural network introduced specht multivariate kernel density estimator fixed kernel width 
kernel width commonly obtained trial error procedure 
small value causes estimated density function distinct modes corresponding locations observed data 
larger value produces greater degree interpolation data points 
widely nonparametric density estimation normally suffer practical drawbacks inability deal satisfactorily tails distributions main part density curse dimensionality calls requirement exponentially increasing sample size estimate multivariate density number dimensions increases 
drawback reflects potential computational burden density estimator construction due fact observed training datum kernel deployed extra term added eq 

adaptive kernel density estimator improved alternative adaptive kernel density estimator akde 
similar akde constructs density placing kernel observed datum allows kernel width vary point 
intent different widths kernels regions different smoothness 
method adopts step algorithm computing data adaptive kernel width 
algorithm summarized follows step sphere observed data fy fz zz step find pilot estimate satisfies 
step set local width factor fl geometric mean log log fl user defined sensitivity parameter satisfying fl 
step construct adaptive kernel estimate oef global width parameter eq 

natural pilot estimate kernel estimate fixed optimal kernel width see eq 

larger fl sensitive performance selection pilot density 
quite common set fl 
estimate akde small data set size illustrated 
radial basis function density estimator due requirement kernel placed observed datum implementations require kernels number training data huge 
density estimator radial basis function rbf network uses reduced number radial basis kernels kernel representative cluster training data fig 
fig 
data point example adaptive kernel density estimation 
data point cluster center example radial basis function density estimation 
highly desired 
shown training data grouped clusters density estimated constructing kernels different heights widths cluster center 
rbf networks introduced classification data regression applications 
example moody darken proposed hybrid learning method self organizing adaptive mean clustering algorithm locate positions kernel functions nearest neighbor heuristic determine kernel widths 
heuristic varies widths order achieve certain amount response overlap unit neighbors 
mean squares lms supervised training rule updating heights deployed kernels 
data sphering outlier removing density estimation task unsupervised learning task modifications learning procedures rbf classification regression networks needed 
rbf network possesses local tuning property positions kernels searched clustering algorithm cover areas representative data region cluster centers 
unfortunately clustering methods vulnerable data outliers generated long tailed portion density 
classification applications outlying training data useful carefully regularized increase generalization capability classifiers 
outlying training data density estimation application usually carry little information density represent meaningful isolated class classification application 
rbf network construction akde symmetric kernel placed observed training data outlying data play significant role approximating true density amount outlying data usually quite small 
hand clustering techniques adopted reduce number kernels deployed rbf construction outlying data play significant role 
specifically clustering algorithms types squares estimators sensitive outliers 
motivated remove outliers data sphering data clustering processes 
additional benefit applying data sphering data clustering simplify correlation structures data distance measures clustering algorithm simplified different dimensions non sphered data different scales 
rbf density estimation starts data sphering observed training data get rid probabilistic outliers time desired normalize spread data directions facilitate data clustering 
sphered data larger norm kzk fi fi prespecified threshold excluded clustering 
data sphering outlier removing process continues iterations outlying data removed 
verify assumption adverse impact outlying data density estimation simple density estimation experiment conducted 
shows true density long tailed single mode cauchy density function observed data randomly sampled distribution corresponding cluster centers centroids clustering algorithm discussed outlier removal wide spread shown 
rbf approximated kernel density built centroids shown 
note estimated density near true density 
hand outlier removal applied data clustering centroids shown lbg algorithm representative true data distribution 
estimated density better approximation true density see 
data clustering centroid splitting data sphering outlier removing clustering method applied search representative centroids reduced number kernels rbf network deployed 
generalized lloyd algorithm centroid splitting known lbg algorithm originally developed codebook generation vector quantization applications 
compared sequential batch mean algorithm performance lbg algorithm centroid splitting consistent affected initial guess means algorithm specifically lbg algorithm performs distortion descent search find set cluster centers comprise local minimum sense mean squared errors 
basic lbg algorithm summarized follows step set training data initial codebook 
step cluster training data old codebook prespecified distance measures euclidean distance 
average distortion small quit 
step replace old codebook centroids clusters obtained step 
go step 
centroid splitting approach applied reduce sensitive dependence locations size initial codebook performance clustering 
finds optimum codebook size centroid entire training data set 
single codeword split form initial codebook size lbg algorithm run reach local minimum 
procedure repetitively applied enlarge codebook size 
construction rbf density due employment data sphering covariance matrix data cluster sphered data expected close diagonal matrix data variance dimension independently computed 

oo cauchy data vq centroids outliers removed data points vq centroids 
cauchy data vq centroids outliers removed density rbf outliers removed density rbf outliers removed density true density single mode cauchy centroids lbg algorithm outlier removal 
estimated density centroids 
centroids lbg algorithm outlier removal 
estimated density centroids 
true density long tailed cauchy density function 
rbf density estimator kernels simplified response function oe oe ij ij ij ip denotes centroid vector th gaussian kernel obtained lbg clustering 
kernel height vector 
ip width vector th kernel 
implementation rbf density estimator heights fc kernels determined percentages training data clustered various centroids kernel widths fv ij designed proportional factor empirically simulations standard sample deviation dimension cluster 
case data points clustered centroid average standard deviation dimensions regularize estimation steep kernel avoided 
deploy asymmetric kernels clustered region number data points large compute full covariance matrix 
projection pursuit density estimation spirit projection pursuit density estimation ppde looking interesting low dimensional data projections reveal distribution structures 
notion interestingness may difficult quantify huber gave heuristic suggestion gaussian normal distribution ought considered interesting 
building suggestion friedman proposed algorithmic procedure called exploratory projection pursuit nonparametric multivariate density estimation 
ppde procedure steps involved 
data sphering simplify location scale correlation structures remove outliers discussed rbf density estimators see section 

projection index indicate degree interestingness different projection directions 

optimization strategy search efficiently direction maximal projection index 

structure removing perform density estimation projection data transform data remove structure 

density formation combine densities searched interesting directions form multivariate density function 
projection index projection direction interesting 
known projections multivariate gaussian density gaussian evidence data non gaussian projection evidence data multivariate joint gaussian 
intuitive definition projection index ff indicates close probability ff projection data ff direction ff gaussian sphered version ff ff dx projection direction ff maximizes ff yields projected distribution exhibit clustering multimodality kinds nonlinear structure 
transform data equation ff standard normal cumulative distribution function cdf 
dt fundamental theorem random variable transform ff ff rewrite eq 
terms ff dr dr friedman adopted slightly different form projection index ff ff dr dr note gaussian distributed projection index ff zero 
departure distribution normality larger value index ff 
expanded terms orthogonal legendre polynomials jg ff dr dr orthogonal legendre polynomials recursive relation follows orthogonal property weighting coefficients fb computed sample average dr dr approximated sample average 
eq 
rewritten ff dr optimization strategy search best projection analytical form projection index defined gradient respect projection direction ff derived constraint ff ff ff ffx derivative legendre polynomial easily calculated recursive formula hybrid optimization strategy search interesting projection direction 
coarse stepping optimizer applied perform search main axes principal component directions combination directions initial estimate maximum quickly reached 
gradient directed optimizer steepest ascent adopted fine tune projection direction ascend local maximum projection index 
structure removal data projection construct ppde interesting projections usually required 
interesting projection ff remove gaussian structure ff avoid search direction words data ff affecting density directions 
denote projection data respectively 
projection data accomplished ff inverse standard normal cdf eq 
ff estimate cdf friedman suggested empirical cdf ff rank rank rank observed data points 
empirical distribution formulation quite inaccurate usually results estimated densities 
estimate ff linear interpolation ff 
modification compute high dimensional structure removed data orthonormal matrix ff fi fi fi ffi gram schmidt algorithm 
uz ff fi fi fi uz fi fi fi uz projection index maximization procedure reapplied data searching interesting projection structures multivariate data close gaussian distribution direction 
noted solution projection perturbs normality previously solution projections longer exactly zero interest 
empirical experience indicates induced perturbation small 
desired backfitting procedure reapplied previous projections 
density formation projections density density original sphered data estimated combining projected density estimations 
density relation high dimensional data structure removed data th projection ff ff ff jj ff ff jj jacobian jm uz uz ff ff ff ff starting original multivariate data procedure applied interesting projection optimization procedure 
point say projections multivariate data exhibits deviation normality ff exp standard multivariate gaussian distribution 
density estimated ff ff ff jm jm ff ff ff probability ff ff estimated eq 
ff specifically ff ff ff em due polynomial form projection index recursive relations polynomials derivatives ppde rapidly computed 
figures gives step step illustration ppde construction projections training data sampled gaussian mixture 
randomly sampled gaussian mixture data 
true density gaussian mixture ppde st projection solution ppde nd projection solution ppde rd projection solution true density gaussian mixture 
ppde estimate ff st projection 
ppde estimate ff nd projection 
ppde estimate ff rd projection 
comparative simulations discussed nonparametric kernel projection pursuit density estimators structural computational viewpoints 
carry section detailed comparison performance methods simulation study 
simulated data types multidimensional data gaussian cauchy mixture distributions generated 
cauchy distribution long tail gaussian distribution 
data generated elements data vector independent 
data distribution forms gaussian mixture cauchy mixture constraint kj kj kj kj kj kj single mode distribution type data single mode distribution parameters chosen follows note cases take elements parameter set shown gaussian distribution cauchy distribution lightly overlapped mode distribution second type data lightly overlapped mode distribution parameters chosen follows gaussian mixture cauchy mixture heavily overlapped mode distribution third type data heavily overlapped mode distribution parameters chosen follows gaussian mixture cauchy mixture type data mixture gaussian mixture cauchy dimension randomly sampled data sets different sizes created training additional randomly sampled data set size created testing 
performance evaluation objectively compare performance monte carlo approximation percentage variance explained pve measures pv err ar err denotes mean squared error estimated density true density testing data ar denotes sample variance testing data denotes sample average true density 
experimental setup experiments comparative simulations done estimators akde rbf ppde discussed 
gaussian distribution long tail distribution outlier removing procedure necessary applied training data 
cauchy distribution exists probabilistic outliers bias covariance estimation mislead search kernel locations sphering radii fi fi observation data probability gaussian distribution zero radius tried outlier removing 
akde addition choices sphering radii values tried fl 
reported akde performance chosen best median terms pv measure parameter combinations 
simulations rbf density estimators combinations control parameters tried 
example different numbers clustered kernels 
clustering data cluster region assumed independent dimension variance clustered data dimension independently calculated 
kernel smoothing parameter chosen 
pv values corresponding different parameter combinations median pv values best pv values rbf estimation reported 
ppde simulations legendre polynomial orders tried 
number interesting projections required constructing density fixed advance determined dynamically new projection index smaller 
pv values corresponding different parameter combinations median pv values best pv values ppde estimation reported 
simulation results shows median best pv performance plots single mode gaussian cauchy data various dimensions versus various training data sizes 
perspective plots true estimated densities data corresponding median pv single mode distribution data shown 
shows median best pv performance plots mode gaussian cauchy lightly overlapped data various dimensions versus various training data sizes 
perspective plots true estimated densities data corresponding median pv mode gaussian cauchy lightly overlapped distribution data shown 
shows median best pv performance plots mode gaussian cauchy heavily overlapped data various dimensions versus various training data sizes 
perspective plots true estimated densities data corresponding median pv mode gaussian cauchy heavily overlapped data data shown 
observed ppde outperforms akde rbf approximation accuracy pv measures simulations 
pv plots clearly see performances ppde median curves degrade corresponding ppde best curves 
hand performances rbf median curves degrade lot corresponding rbf best curves 
fact indicates ppde robust sensitive setting control parameters values number projections kernels locations kernels orientation kernels kernel smoothing parameters excluding threshold radius data sphering size training data observe impact dimensionality method ppde expected suffers curse dimensionality compared akde rbf methods 
specifically rbf suffers curse dimensionality estimating cauchy mixtures 
note ppde require minimum number training data reasonably perform procedure akde rbf survive small number training data say due prespecified implicit kernel structures 
methods exhibit somewhat degraded performance estimation long tailed cauchy distribution 
performance akde rbf degrades ppde 
worthwhile mention comparative computational complexities density estimation methods 
construction projection pursuit density estimator recursive legendre polynomials iterative optimization procedure conclusive quantitative comparison computational complexity density estimator methods difficult 
general intensive simulations methods took quite comparable amount cpu time projection pursuit slightly faster construction estimators 
testing stage estimators constructed robust rbf methods fastest responding density values slowest 
extensively examined algorithmic aspects nonparametric multivariate density estimators carried thorough comparative study simulations 
simulation study ppde outperformed kernel methods approximation accuracy pve measures data sets 
particular expect rbf kernel method natural fit estimating density gaussian mixtures ppde performs better set data 
emphasizes success 
spite superior performance ppde suffers potential drawbacks require research 
specifically ppde satisfactorily deal structures hidden data density doughnut shape 
problem solved transforming original data coordinates polar coordinate application ppde appropriate coordinate transforms identification hidden structures densities remains challenging 
severe problem numerical instability caused denominator jacobian term long density tail solved sophisticated data analysis techniques 
acknowledgments authors wish anonymous reviewers valuable constructive suggestions revision benefited significantly 
abramson 
bandwidth variation kernel estimates square root law 
annals statistics 
gray 
vector quantization image processing 
proceedings ieee sep 
donoho johnstone 
regression approximation projection isotropic kernels 
contemporary mathematics vol 
pp 

duda hart 
pattern classification scene analysis 
wiley new york ny 
friedman stuetzle schroeder 
projection pursuit density estimation 
journal american statistical association vol 
pp 

friedman tukey 
projection pursuit algorithm exploratory data analysis 
ieee transactions computers pp 

friedman 
exploratory projection pursuit 
journal american statistic association vol 
pp 

fukunaga 
statistical pattern recognition 
new york academic press 
gray 
vector quantization 
ieee assp mag vol pp 
apr 
hall 
polynomial projection indices exploratory projection pursuit 
annals statistics vol 
pp 

huber 
robust statistics 
wiley new york 
huber 
projection pursuit 
annals statistics vol 

hurley buja 
analyzing high dimensional data motion graphics 
siam journal scientific statistical computing 
hwang lay lippman 
unsupervised learning multivariate probability density estimation radial basis projection pursuit 
ieee int conference neural networks pp 
san francisco ca march 
lay hwang 
robust construction radial basis function neural networks classification 
ieee int conf 
neural networks pp 
san francisco 
linde gray 
algorithm vector quantizer design 
ieee trans 
communication vol pp 
jan 
mclachlan basford 
mixture models inference applications clustering new york marcel dekker 
moody darken 
fast learning networks locally tuned processing units 
neural computation 
gray 
combining image classification image compression vector quantization 
ieee data compression conference proceedings pp 

popat picard 
novel cluster probability model texture synthesis classification compression 
proc 
spie visual communications image processing boston nov 
popat picard 
cluster probability model applied image restoration compression 
appear proc 
icassp adelaide australia april 
poggio girosi 
networks approximation learning 
proceedings ieee september 
rabiner 
tutorial hidden markov models selected applications speech recognition 
proceedings ieee feb 
scott 
multivariate density estimation theory practice visualization 
wiley series probability mathematical statistics new york 
silverman 
density estimation statistics data analysis new york chapman hall 
specht 
probabilistic neural networks 
neural networks vol 
pp 

smith makov 
statistical analysis finite mixture distributions new york john wiley 
xie laszlo ward 
vector quantization technique nonparametric classifier design 
ieee trans 
pattern analysis machine intelligence dec 
pve dash akde best solid akde median dash ppde best solid ppde median dash rbf best solid rbf median 
single mode gaussian 




pve 
single mode gaussian 




pve 
single mode gaussian 




pve 
single mode gaussian 




pve 
single mode cauchy 




pve 
single mode cauchy 




pve 
single mode cauchy 




pve 
single mode cauchy 




estimation accuracy pve measures single mode data gaussian cauchy 
true density single mode gaussian ppde density akde density rbf density true density single mode cauchy ppde density akde density rbf perspective plots single mode distributions gaussian true density 
ppde estimation 
akde estimation 
rbf estimation 
cauchy true density 
ppde estimation 
akde estimation 
rbf estimation 
pve dash akde best solid akde median dash ppde best solid ppde median dash rbf best solid rbf median 

lightly overlapped gaussian mixture 



pve 

lightly overlapped gaussian mixture 



pve 

lightly overlapped gaussian mixture 



pve 

lightly overlapped gaussian mixture 



pve 

lightly overlapped cauchy mixture 



pve 

lightly overlapped cauchy mixture 



pve 

lightly overlapped cauchy mixture 



pve 

lightly overlapped cauchy mixture 



estimation accuracy pve measures mode lightly overlapped data gaussian cauchy 
true density lightly overlapped gaussian mixture density ppde density akde density rbf density true density lightly overlapped cauchy mixture density ppde density akde density rbf perspective plots mode lightly overlapped distributions gaussian true density 
ppde estimation 
akde estimation 
rbf estimation 
cauchy true density 
ppde estimation 
akde estimation 
rbf estimation 
pve dash akde best solid akde median dash ppde best solid ppde median dash rbf best solid rbf median 

highly overlapped gaussian mixture 



pve 

highly overlapped gaussian mixture 



pve 

highly overlapped gaussian mixture 



pve 

highly overlapped gaussian mixture 



pve 

highly overlapped cauchy mixture 



pve 

highly overlapped cauchy mixture 



pve 

highly overlapped cauchy mixture 



pve 

highly overlapped cauchy mixture 



estimation accuracy pve measures mode highly overlapped data gaussian cauchy 
true density highly overlapped gaussian mixture density ppde density akde rbf density true density highly overlapped cauchy mixture density ppde density akde density rbf perspective plots mode highly overlapped distributions gaussian true density 
ppde estimation 
akde estimation 
rbf estimation 
cauchy true density 
ppde estimation 
akde estimation 
rbf estimation 
