performance analysis mips performance counters marco zagha larson steve turner marty silicon graphics shoreline blvd mountain view ca swt sgi com tuning supercomputer application performance requires analyzing interaction application underlying architecture 
describe support mips non monitoring variety processor events support particularly useful characterizing dynamic behavior multi level memory hierarchies hardware cache coherence speculative execution 
explain performance data collected integrated set hardware mechanisms operating system abstractions performance tools 
describe examples drawn scientific applications illustrate counters profiling tools provide information helps developers analyze tune applications 
keywords performance analysis profiling tools hardware performance counters mips sgi power challenge 
fundamental question asked hpc application developers time spent 
follow question challenging question time spent 
question partially addressed software analysis tools 
approaches simulation generate accurate counts processor memory system events cause slowdown orders magnitude accurate multiprocessor simulations 
approximate analysis static predictions generated instrumented programs expensive perturbs behavior executable may fail capture dynamic behavior computation 
increasing dynamic superscalar instruction scheduling mips hp pa static estimates computation inherently accurate increasing importance memory system behavior lack memory system statistics particularly limiting especially supercomputing applications 
design addresses problems providing hardware support counting various types events cache misses memory coherence operations branch mispredictions categories issued graduated instructions 
counters useful application developers gaining insight application performance pinpointing performance bottlenecks 
addition application tuning counters uses including predicting application performance scalability processors memory systems analyzing architectural tradeoffs generating address traces address statistics analyzing bus communication traffic evaluating compiler transformations profiling kernel testing hardware characterizing workloads 
similar types hardware counters appeared processors 
counters extensively cray vector processors appear form microprocessors intel pentium ibm power dec alpha hp pa 
microprocessor vendors provide documentation counters counter performance tools primarily hardware developers selected performance analysts 
different philosophy purpose counters closely aligned approach traditionally taken cray research 
believe counter data important application developers counters documented supported high level tools 
design constraints differed cray key areas 
addition having tighter area budget constraints felt necessary support procedure level event profiling arbitrary binaries requiring explicit recompiling relinking perturbing memory addresses 
able satisfy constraints integrated design hardware operation system functionality performance tools 
components described illustrated representative applications 
remainder organized follows 
section architecture summarized focusing parts relevance performance counters 
section covers software support operating system level 
section describes user mode software tools counter facility available 
pedagogical examples drawn scientific engineering applications discussed section 
summarized brief discussion directions section 
system bottom lower level details relegated appendices 
readers interested application level tuning skim sections 
hardware operating system support hardware support mips way superscalar microprocessor currently operates clock frequency mhz 
able fetch instructions kilobyte chip instruction cache processor cycle 
uses speculative execution continue decoding instructions conditional branches unresolved branches 
issuing instructions integer floating point functional units order register renaming reduce data dependencies capable continuing forward progress program execution instructions wait data dependencies cache misses satisfied 
kilobyte way set associative chip data cache capable issuing requests external data cache mb mb initial systems system interface continuing service accesses 
capabilities combine allow flexible dealing problems normally stall execution pipeline conventional microprocessor 
flexibility comes price terms user visible state 
code scheduling data placement decisions difficult processor seeks adapt ideal circumstances 
performance counter facility helps compensate additional complications providing system designers compiler writers application developers detailed information behavior chip 
order counters feasible implement negligible impact processor performance small set events chosen 
events selected form simple orthogonal set events software analysis produce sophisticated easily interpreted description system behavior 
events chosen particular attention illuminate dynamic behavior chip static analysis effectively implemented ways 
wanted bring aspects program behavior difficult impossible see 
state performance counters visible applications register read written kernel level processes 
hardware implements bit counters configured monitor distinct event types 
total different event types monitored event types cycles graduated instructions may monitored counters 
full set counters described appendix addition accumulating values read performance counter registers counters provide kernel level interrupt triggered counters overflows 
facility proved valuable allows counters generate interrupts periodic specified event allows period controlled software setting initial counter value overflow 
performance counter facility designed non intrusive 
monitoring done hardware software possible extract detailed information state processor affecting behavior program monitored 
facility designed introduced critical timing paths chip circuitry performance hardware degraded inclusion 
logical circuitry required implement counter facility specified lines rtl implemented fewer transistors total number non cache transistors included 
logic created primarily synthesis full custom circuitry timing issues critical 
difficult aspect circuit implementation routing wires required carry signals monitored back central counting circuitry 
signals interest scattered logical blocks long wires required 
illustrates wiring required implement counters 
wiring scheme performance counters 
expensive aspect implementing performance counters die area transistor count wires routed 
expense dominated design time required select appropriate set performance events determine derive corresponding set chip signals verify correctness counters 
architectural specification logic design verification process resulted design low cost terms chip resources 
design eminently suitable inclusion product replicated hundreds thousands times 
operating system library support operating system os virtualizes shared counter hardware presents abstraction flexible sharable user mode 
os layer sits hardware exclusive direct access counter hardware accessed supervisor coprocessor instructions 
os sole access provide interface simple efficient introducing minimum necessary overhead 
focus interface correspondingly modest terms ease presentation results preferring leave higher layers software exchange efficiency 
abstraction includes modes counting user mode system mode 
focus user mode 
details os interface system profiling described appendix kernel maintains different bit virtual counters user program developer programming interface 
number chosen allow events specified simultaneously underlying hardware counters count pairs events time constrained event types available particular counter see appendix 
user program specify events hardware counter 
kernel switches multiplexes events scheduler interrupt clock tick boundaries needed count specified events resident physical counter 
interpretation multiplexed counts statistical resident events physical counter counted time quanta 
introduces noise exchange coverage 
successful screening event categories responsible significant fractions program time relative uncertainties sampled counts empirically small 
os interface allows developer specify frequency event kernel synchronously delivers user signal process 
capability enabled various experiments memory address tracing design appropriate handlers cache overflow interrupts 
easy interface built top os interface provided library 
library manages common case bookkeeping allowing occasional users access counters learning somewhat unfamiliar ioctl system calls 

developer tools currently provide tools counter data command line interface new generation sgi performance tools 
provides program level event information simple command line interface cray utility 
user may monitor compatible event counters os multiplexing features sample counters 
example listed appendix 
multithreaded applications reports data thread addition aggregate counts 
identify processor events causing performance problems performance tools identify parts program source encountering 
performance tools provide wide variety traditional types performance data common usage model data format 
extended provide statistical profiling overflows hardware counters 
data recorded histogram hits vs program counter pc hit corresponds overflow particular counter 
data recorded analogous recorded traditional pc sampling run 
show source program overflows triggered function approximate source line level 
pc sampling clock interrupts runs risk undesirable correlation behavior application program 
operating system uses clock profiler schedule tasks including application applications awakened scheduler ticks pc sampling systematically count routines get triggered scheduling depending os schedules profiles vice versa 
hardware counter profiling bypass correlation 
cycle counter overflows obtain essentially data clock tick profiling os cycle counter overflow won exhibit correlation 
overflows counter cycles obtain information previously completely unavailable 
example profiling cache misses producing histogram indicating parts program thrashing cache 
profiling cache misses show instructions triggering misses may suggest restructuring array accesses experiments risk correlation th cache profiled program loop incurs misses iteration counts go th site uniformly distributed sites 
provide sets preset overflow values counters value prime number profiles similar overflow values statistically valid 
user run additional experiments different overflow numbers ensure data statistically valid 
examples appendix 
additional extensions exploiting counter overflow functionality investigation 
current profiling done entirely os profiling light weight 
mentioned section os allows overflow profiling signal delivered application 
functionality user unwound interrupt allowing profile inclusive cache misses 
experiment data space profiling functionality alluded section 
combining memory address indexed information program symbol management show elements array causing cache misses 

examples section step process tuning application programs examples operations research computation fluid dynamics image processing weather modeling 
order simplify presentation examples analyze smaller kernels similar behavior original applications 
case highlight relevant hardware features software tools program restructuring techniques 
experiments performed sgi power challenge 
graphs produced performance data generated library 
cache profiling example demonstrates typical straightforward counter performance tools 
application optimizes personnel requirements improved resource scheduling 
estimate influence various hardware resources running multiplexing mode sample counters multiplying projected event counts typical event costs 
indicated time dominated secondary data cache misses estimates event costs original program 
secondary data cache misses account majority cycles 
refine profiling generate line level estimates secondary data cache misses 
shows concentrated areas source code account majority secondary cache misses fact single source line accounts misses 
poor performance source line caused search loop accesses byte integer field element array structures structure larger single byte secondary cache line 
storing integer items separate shadow array secondary cache rate entire application reduced 
approximate percentage total number secondary data cache misses occur source code line 
bar represents single line line source program 
multi level memory hierarchy profiling consider simple example mimics memory behavior alternating direction implicit adi method solving set dimensional partial differential equations 
class applications typically memory bandwidth intensive sample kernel highlights memory performance simplified computational kernel retaining representative memory access patterns 
iteration algorithm performs sweep dimension grid 
data dependences neighboring elements sweep dimension dependences dimensions orthogonal sweep direction 
initial timings grid observe running time anticipated floating point operation counts addition observe processing rate varies considerably small changes grid size 
profile cycle count discover sweeps consume cycles respectively 
running multiplexing mode find time dominated memory operations approximately time translation lookaside buffer tlb misses second level data cache misses level data cache misses 
additional experiments memory events get closer pinpointing problems 
shows performance sweeps function grid size 
time sweeps adi function grid size 
total time represented top curve broken components primary secondary cache misses tlb misses computation including integer branch operations floating operations 
component times estimated multiplying event counts typical event cost assuming overlap events 
performance problems apparent graphs 
remedied optimizations array padding spikes caused cache thrashing 
assuming fortran array allocation conventions array element grid declared dimensions nx ny nz maps linear array index nx nx ny worst case nx ny large power data element axis maps cache line 
cache thrashing eliminated padding leading array dimensions 
loop interchange notice tlb misses dominate time sweep 
original implementation performs sweep independent passes nx ny lines axis 
pass accesses memory large stride approximately nx ny grid elements stride exceeds kbyte page size 
thrashing results capacity entry tlb exceeded 
tlb performance improved interchanging inner loop axis outer loops orthogonal dimensions 
passes lines axis interleaved contiguous grid points coordinate accessed accessing page 
causes slight increase number primary cache misses due increased working set greatly reduces number tlb misses 
loop fusion original program sweeps organized loop dimension outermost 
straightforward optimization fuse outer loops sweeps process slice grid time performing sweeps slice sweeps 
greatly reduces cost sweeps data needed loaded cache sweep 
result optimizations shown 
time optimized sweeps function grid size 
improvements lead performance consistent approximately factor faster original implementation large problem sizes 
multiprocessor sharing challenge power challenge systems maintain cache coherency cache snooping protocol 
memory coherence transactions monitored types events interventions invalidations 
transactions provide mechanism components multiprocessor system modify state data cached microprocessor 
types request communicated processor system bus 
example analyze multiprocessor performance weather modeling program 
program uses spectral methods kernel analyze physics loop 
program acceptable performance processor scales poorly processors 
multiplexing mode clear running time dominated secondary cache misses 
order understand behavior examine counters related secondary cache 
observe number secondary data cache misses increases number processors increased 
furthermore total number interventions invalidations closely tracks number secondary cache misses indicating high degree sharing 
parallel algorithm application little sharing expected 
processor works independent region memory accumulates sum results 
find cache misses occur accumulation step indicating false sharing probably cause performance problem 
analysis source code see sums processor allocated contiguously multiple sums located cache line 
problem fixed small change array declaration appropriate compiler directives 
eliminating false sharing see dramatic performance improvement number coherency events shown parallel speedup shown 
cache event counts vs number processors untuned version false sharing tuned version 
speedup untuned version false sharing tuned version 
branch prediction example analyze performance general purpose dimensional convolution subroutine 
example demonstrates performance counter tools quickly identify performance problems gain insight performance interaction application compiler hardware 
particular application filter blurring image 
running see initial version exhibits performance problems cycles floating point operation loads floating point operation interestingly mispredicted branches 
see 
estimates event costs original convolution subroutine 
examining counters mispredicted branches issued branches compute branches mispredicted 
statistic leads quick diagnosis 
mispredictions caused short innermost loops convolution mask 
compiler unable remove branches restructuring code subroutine written arbitrary mask size compiled separately 
understanding importance branch prediction requires background processor architecture 
path taken conditional branch predicted bit branch history memory updated branch decision resolved 
nested loops hardware typically predict branches innermost loops taken repeatedly incorrect prediction iteration inner loop 
short inner loops program misprediction rate expected near third 
case simple solution 
convolution routine recompiled loop nest optimization enabled compiler interchanges loops trip count inner loop derived image dimensions mask dimensions jams outer loop enable common subexpression elimination memory 
addition enabling inter procedural analysis ipa allows compiler propagate constant bounds mask size reduce number instructions issued 
performance improvements loop nest optimization inter procedural analysis 
indicated branch mispredictions virtually eliminated addition number issued instructions greatly reduced 
set improvements introduced changing compiler flags improves cycle count factor 
discussion main emerge experience design implementation hardware performance counters counter profiling tools 
counters worth silicon design time include 
provided valuable insight dynamic program behavior developers applications compilers operating systems hardware 
counters provide wealth data resource program execution data just organized effectively 
benefits deriving users enhanced ability quantify report performance bugs may hidden 
second simplest way counter facility justify cost terms customer application developer 
performance tools critical raw events constitute best assembly language performance experiments 
performance primitives need combined compiled performance experiments answer application level questions allow resulting data visually correlated application program components name spaces 
development hardware counters respond experiences application developers trends microprocessor design 
designs include additional accumulators event types chip design chip area costs justified 
new events particular interest memory stall cycles outstanding counts prefetch hits misses 
capability mechanism measuring correlations events count event occurrence helpful 
utility enhancements lies able address questions cache misses stall processor 
effective prefetching 
branch mispredictions cost 
distribution memory latencies 
making tool sofware flexible extensible goal 
api allow special purpose modules management source symbols data file format eventually graphical interface 
looking forward receiving customer feedback novice expert users 
feedback guide development hardware software tools 
viewed possible self informing architectural features counters represent exciting capability wealth unexplored potential 
appendix performance counters table lists events measured event counters 
note event definitions correspond versions processor older revision 
details exact meaning events definitions revisions see microprocessor user manual 
event counter counter cycles cycles instructions issued instructions graduated load prefetch sync issued load prefetch sync graduated stores issued stores graduated store conditionals issued store conditionals graduated failed store conditionals floating point instructions graduated branches decoded written back primary data cache written back secondary cache tlb refill exceptions correctable ecc errors secondary cache data branches mispredicted instruction cache misses data cache misses secondary cache misses instruction secondary cache misses data secondary cache bank mispredictions instructions secondary cache bank mispredictions data external intervention requests external intervention request hits external invalidate requests external invalidate request hits virtual coherency conditions stores prefetch clean exclusive secondary cache blocks instructions graduated stores prefetch shared secondary cache blocks appendix os interface system profiling os provides interface acquiring releasing counters reading counts modifying counting mode event 
interface takes process id parameter allows process manipulate counters process long manipulating process member process group root 
os counter abstraction user primarily proc interface ioctl calls 
process counters user mode control block counters kept user area 
process forks child starts life counter state parent 
counter values child zeroed fork 
child exits kernel sees parent waiting child add child bit counts waiting parent 
possible cause counts returned non waiting parent modify parent state 
normal case parent completing contain aggregate counts descendants 
system mode profiling quite different incompatible user mode 
system mode useful profiling kernel monitoring behavior job mix 
system monitoring tools performance pilot configured show graphical representation various counters cpu basis 
system mode defined state process root privileges kernel mode bit counter control register set 
mode context switch boundaries programs unable counters system mode 
system mode higher priority user mode processes root privileges forcibly acquire counters special system call 
user programs lose counters way counters subsequently restored usability mechanism detect fact 
support counters system mode cpu control block counters pointed private area 
global counter control block maintains counter state entire system 
counters system mode read stored context switch boundaries 
explicitly read program counters read kernel overflow interrupt 
occurs cpu interrupt occurred updates private virtual counters changes global counter control block 
counters read system mode ioctl call cpu counters aggregated global counters reflect total counted events entire system 
aggregation cpu counters happens counters released 
appendix sample output prof example output molecular dynamics simulation silicon 
example uses multiplexing feature os interface 
notice example counts graduated instructions disagree approximately due multiplexing projection noise 
md program output 
cycles 
issued instructions 
issued loads 
issued stores 
issued store conditionals 
failed store conditionals 
decoded branches 
written back 
correctable data array ecc errors 
primary instruction cache misses 
secondary instruction cache misses 
instruction misprediction way prediction table 
external interventions 
external invalidations 
virtual coherency conditions 
graduated instructions 
cycles 
graduated instructions 
graduated loads 
graduated stores 
graduated store conditionals 
graduated floating point instructions 
written back primary data cache 
tlb misses 
mispredicted branches 
primary data cache misses 
secondary data cache misses 
data misprediction way prediction table 
external intervention hits 
external invalidation hits 
store prefetch exclusive clean block 
store prefetch exclusive shared block 
example shows output program experiment graduated floating point gfp instructions sampling trigger 
produce output commands executed exp gfp md produces file md gfp 
prof md gfp produces profile listing generated wed may prof md gfp counter graduated fp instructions counter overflow value total numer cpu fpu clock mhz number cpus counter overflow 
sorted descending order number overflows procedure 
procedures excluded 
overflows cum overflows procedure dso file compute forces ik md 
pow usr lib 
exp usr lib 
min image distance md 
build neighbor lists md 
integrate positions md 
integrate velocities md 
min image distance md 
min image distance md 
clean positions md 
cos usr lib 
mixed usr lib libc 
total profile program equally spaced secondary cache data misses trigger 
cache intensive procedures particularly correlated floating point instruction count execution time reflection fact code cache misses majority routines accounting minor fraction total execution time 
counter overflow 
sorted descending order number overflows procedure 
procedures excluded 
overflows cum overflows procedure dso file integrate velocities md 
compute forces ik md 
pow usr lib 
integrate positions md 
min image distance md 
build neighbor lists md 
exp usr lib 
compute sum md 
total momentum check md 
times usr lib libc 
clean positions md 
min image distance md 
dump state md 
min image distance md 
acknowledgments people contributed design implementation counter hardware support tools notably robert ken john jun yu stephen jeff 
kevin kuhn extracted signal trace layout include 
jeff suggested adi convolution examples gilles garcia provided weather kernel 
ed rothberg jonathan provided valuable feedback early drafts 
brewer dellarocas weihl 
proteus high performance parallel architecture simulator 
mit lcs tr mit 
file ftp lcs mit edu pub papers tr proteus ps cray research performance utilities manual 
cray research publication sr 
january 
digital equipment 
pfm performance counter pseudo device 
dec osf manual pages 

eggers 
eliminating false sharing 
international conference parallel processing 
august 
netlib att com netlib att cs home papers icpp html eustace srivastava 
atom flexible interface building high performance program analysis tools 
dec wrl technical note tn 
july 
www research digital com wrl publications abstracts tn html galles williams 
performance optimizations implementation verification sgi challenge multiprocessor 
proceedings th annual hawaii international conference system sciences 
www sgi com technology challenge html gao larson 
workload characterization cray hardware performance monitor 
journal supercomputing 
gee hill smith 
cache performance spec benchmark suite 
ieee micro 
august 
goldberg hennessy 
performance debugging shared memory multiprocessor programs 
supercomputing 
nov 
horowitz martonosi mowry smith 
informing memory operations providing memory performance feedback modern processors 
proceedings rd international symposium computer architecture 
may 
ftp www flash stanford edu pub flash ps doug hunt 
advanced performance features bit pa 
compcon march 
www convex com tech cache technical html larus schnarr 
eel machine independent executable editing 
sigplan conference programming language design implementation pldi june 
www cs wisc edu larus eel html lebeck wood 
cache profiling spec benchmarks case study 
computer october 
www cs wisc edu papers cprof ps jussi ki 
power hardware performance monitor tools 
nov 
www csc fi rs margaret martonosi douglas clark 
shrimp performance monitor design applications 
acm sigmetrics symposium parallel distributed tools may 
mathisen 
pentium secrets 
byte magazine july 
green kaist ac kr art htm alan mink robert carpenter george john roberts 
multiprocessor performance measurement instrumentation 
ieee computer sept 
cmr ncsl nist gov articles ps mips technologies microprocessor technical brief 
october 
www mips com mips technologies superscalar microprocessor 

presentation available www mips com mips technologies microprocessor user manual version section coprocessor performance counter registers 
april 
www mips com silicon graphics power challenge technical report 
www sgi com products software pdf pwr silicon graphics performance pilot user administrator guide 
document number 
www sgi com technology singhal goldberg 
architectural support performance tuning case study 
proceedings st annual international symposium computer architecture april 
torrellas gupta hennessy 
characterizing caching synchronization performance multiprocessor operating system 
fifth international conference architectural support programming languages operating systems asplos boston october sigplan notices september 
jack veenstra robert fowler 
mint front efficient simulation shared memory multiprocessors 
proceedings second international workshop modeling analysis simulation computer telecommunication systems mascots 
jan 
related documentation available reality sgi com veenstra chan hicks 
power performance monitor 
powerpc power technical aspects new ibm risc system ibm sa pp 

www austin ibm com tech monitor html williams myers 
characterization scientific workloads cray mp performance monitor 
supercomputing 
nov 
witchel mendel rosenblum 
embra fast flexible machine simulation 
proceedings acm sigmetrics conference measurement modeling computer systems may 
www flash stanford edu simos papers html author biographies marco zagha sgi com performance analyst advanced systems division silicon graphics 
previously carnegie mellon pursuing ph computer science 
fact better defend thesis sc advisor pursuing 
larson sgi com joined advanced systems division sgi performance analyst 
previously senior scientist thinking machines holds ph theoretical condensed matter physics harvard university 
research contributions focused computational electronic structure atomic dynamics 
steve turner swt sgi com member design team mips technology division silicon graphics 
received ph computer science university illinois 
marty sgi com technical leader case performance tools group mips technology division silicon graphics 
ph chemistry physics caltech 
