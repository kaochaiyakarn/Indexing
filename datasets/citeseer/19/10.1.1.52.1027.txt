principles metareasoning stuart russell eric wefald computer science division university california berkeley ca dedicated memory eric wefald outline general approach study metareasoning sense explicating semantics explicitly specified meta level control policies sense providing basis selecting justifying computational actions 
research contributes developing attack problem resource bounded rationality providing means analysing generating optimal computational strategies 
reasoning computation doing necessarily involves uncertainty outcome probability decision theory main tools 
develop general formula utility computations utility derived directly ability computations affect agent external actions 
address philosophical difficulties arise specifying formula assumption limited rationality 
describe methodology applying theory particular problem solving systems provide brief sketch resulting algorithms performance 
research supported equipment foundation funding lockheed ai center california micro program national science foundation 
iri 
eric wefald supported ge foundation fellowship shell foundation doctoral fellowship 
gratefully acknowledge assistance 
addition steve bradley jack breese murray campbell jon doyle michael michael genesereth eric horvitz maurice richard karp david mcallester subramanian michael wellman reviewers valuable comments suggestions 
vain check impulse quench keep reason control 
marcus study resource bounded intelligent systems promises major area research ai near potential drastic revision understanding learning inference representation 
reason practical people believe classical normative models scale 
second fundamental reason existing formal models neglecting fact limited resources computation fail provide adequate theoretical basis build science artificial intelligence 
logicist approach ai exemplified mccarthy advice taker proposal emphasizes ability reach correct correct premises 
rational agent approach derived philosophical economic notions rational behaviour emphasizes maximal achievement goals decisions act 
resource bounds come play direct implementation approach results suboptimal performance 
want optimal design limited rational agent 
view artificial intelligence constrained optimization problem may profitable 
solutions constrained design problem may look different provided deductive decision theoretic models unconstrained problem 
long term project design robust software architectures goal driven resource limited intelligent systems known 
approach address design problem resources starting point trying lop corners deductive model 
major tool research normative meta level theory value computations allows agent allocate scarce computational resources optimally alternatively allows ai researcher show optimality non optimizing algorithm decision making design algorithms constructively 
progress developing applying theory forms main subject matter 
absence satisfactory axiomatic system computationally limited agents results heuristic basis strictly speaking 
general methodology structure theory remain place axiomatic approach development way practical implementations shown fundamental limitations realization theory metareasoning 
section defining notion real time problem solving discuss various approaches taken problem boundedness context 
view developed greater depth 
inhabit ralph rational agents limited performance hardware project berkeley 
see metareasoning vital role play meta level learning compilation 
section introduces idea rational metareasoning computations treated actions selected basis expected utilities 
turn utilities derived expected effects computations chief consumption time space possible revision agent intended actions real world 
define levels analysis specifying performance system increasing levels detail 
section sets equations general level section covers case bounded agents utility estimates decide actions 
way examine certain ways assumption limits agent rationality forces depart standard axiomatic framework decision theory 
section outlines methodology applying theory specific classes decision making systems mentions results obtained search applications 
framework developed allows analysis construction variety bounded rational systems deal rational selection types computation example learning induction compilation covered explicitly 
section discusses directions research 
approaches bounded rationality conditions conspire create called finitary real agents finite computational power second don time world 
characterization real time problem situation utility performing action varies significantly time necessary complete solution decision problem 
typically utility action decreasing function time 
time action carried depends amount deliberation required choose action performed tradeoff intrinsic utility action chosen time cost deliberation see section 
ai problems scaled reality virtually situations real time 
result system designs sufficiently flexible manage tradeoffs 
aim develop methodology constructing real time algorithms building blocks complex systems 
composition problem real time systems discussed section 
standard algorithms computer science maximize intrinsic utility little regard time cost minimize time cost achieving fixed level intrinsic utility 
real time ai traditionally followed variant approach focusing delivering ai capabilities applications demanding high performance negligible response times 
result designers typically choose fixed level output quality perform necessary precompilation optimization achieve level fixed time limit 
survey large number application programs realtime ai note somewhat currently ad hoc techniques making system produce response specified time interval 
solution optimality criterion success recognized theoretical computer science 
exact methods shown intractable wide range problems theorists looked algorithms properties 
guarantee solution returned ffl relative absolute optimal solution 
called approximation 

probability gamma ffi algorithm return correct optimal solution 
called probably correct algorithms 
researchers notably valiant field inductive learning studied probably approximately correct algorithms combining properties obvious way 
horvitz hansson mayer pointed needed theory algorithms maximize comprehensive value computation 
words utility computation resulting action function quality resulting solution time taken choose methods designing algorithms maximize combined utility 
suitable generalization complexity theory developed 
somewhat longer tradition considering effects decisionmaking exists economics decision sciences human characteristics considered 
emphasized conceptual distinction classical type rationality called type ii rationality maximization expected utility account deliberation costs 
researchers decision analysis especially howard studied problem value information 
theory developed independently strong parallel howard approach 
field economics simon clear distinction systems compute rational thing procedural rationality systems simply rational thing substantive rationality 
pointed procedurally rational systems execution architectures explicit declarative knowledge reach decisions act suffer deal overhead terms time extra cognitive machinery 
notion popularized brooks agre chapman deliberation waste time don just build agents right thing 
substantive rationality come free 
means agent perfectly rational despite limited computational resources arise prior design adaptation 
non trivial environments particularly significant variation case exact solutions decision problem intractable designer unreachable simple adaptation 
situation dependent allocation resources agent hand may possible approximate rationality degree 
believe flexible autonomous systems complex environments require ability reason appropriate resources allocate computation point computations effective 
premise shared researchers ai source number projects developed independently 
doyle rational psychology project idea computations internal state changes actions chosen actions 
applied idea clarify notions belief intention learning 
horvitz early ai contributor study rational choice computation recognizing potential provide new foundation design intelligent systems 
control probabilistic inference medical decision making parallels control search 
heckerman medical decision making example domain showing vary depth analysis therapy problem expected benefits 
third independent project started hansson mayer proposed information value means controlling heuristic search turn implemented probabilistic inference information heuristic function evidence 
dean real time planning assumes known variation intrinsic utility results computation method amount resources allocated method allocates resources optimally various resource bounded scenarios 
survey provides summary technical decision theoretic control inference 
breese applied decision theoretic approach control information gathering actions mobile robot domain 
agogino investigated decision theoretic modelling computation control mechanical systems 
bratman israel pollack sketch system design combining decision theory ai planning techniques plans limit set actions considered 
lesser group studied real time problem solving context distributed vehicle tracking application modulating approximate problem solving achieve robust performance 
framework metareasoning metareasoning mean deliberation concerning possible changes computational state agent 
analysis aimed primarily episodic decisions base level concerned changes internal state service selecting action real world 
computational actions inductive learning compilation covered general theory metareasoning cf 
doyle analysis 
principle utility defined terms effect complete sequence actions replacing single actions sequences analysis evaluate utility attempt derive practical consequences analysis appears premature stage 
context formal treatment computations change agent utility function lies outside framework 
classical decision theory assume agent actual utility function fixed estimates value may change computation 
rational changes utility functions understood 
ultimately autonomous agent general know utility function exactly induced specific experiences pain pleasure death interpretation utility data points definitional 
revisions utility function seen primarily attempts bring predictions happiness line reality 
episodic decision making vital complementary roles metareasoning allows designers reason computational strategies implement discuss rationality bounded context second implemented explicitly agent allows agent allocate flexibly limited computational resources depending decision situation design compile substantively rational decision procedures 
role justifications employing explicit metareasoning effect declarative base level systems additional argument knowledge required knowledge agent computational structure available little difficulty 
meta level systems share common methodology implementation base level problem solver operates explicit formulation solution meta level problems 
example base level problem solver genesereth essentially theorem prover takes user goal simply running resolution algorithm sets goal finding way prove user goal 
new goal theorem proving task right solved meta level knowledge 
uniform meta level architecture meta level problems formulated language base level problems solved mechanism meta meta level problem set decide solve meta level goal 
uniformity language enables meta level rules apply meta meta level goals 
produces flexible systems introduces possibility infinite regress 
regress particularly problematic try define constructive notion optimal design limited rational agent metareasoning done control problem solving optimally costs needs controlled 
words computation executed computation executed decide 
regress mentioned researchers concerned bounded rationality far lipman claimed progress problem 
clearly back insisting optimal control reasoning just back insisting optimal decisions act 
actions computational external taken immediate results deliberation 
decisions various points hierarchy hardwired default approximate decision methods 
action including computational action taken agent optimal limited rational agent agent extremely fortunate selections action result prior deliberation adaptation constructed policy intensionally defined class situations 
reasons important topics ralph project inductive learning meta level policies compilation reasoning 
meta level learning discussed briefly section greater length 
compilation decision making see 
turn topic agent select computations optimally knowing outcome topic rational metareasoning 
rational metareasoning construction system capable rational metareasoning rests basic principles 
computations treated actions selected basis expected utilities 

utility computation derived expected effects consisting passage time associated changes external environment 
possible revision agent intended actions real world 
ability computation cause agent take different course action revealed computation superior agent original intention fundamental source positive utility computations 
important emphasize obvious fact choice computation continue computing absence exact immediately available knowledge outcome computation computation pointless 
possible best perform optimally average computing expected value computation 
computations treated stochastic experiments outcomes completely deterministic 
note goes classical bayesian assumption agent probabilities expectations conditioned sum total knowledge assumed deductively closed 
philosophical discussion point supports view see hacking 
formal standpoint results sections heuristic justification borne practical results 
expect structure theory retained put footing 
assume outcome base level action known 
equations set forth extended cover case uncertainty action outcomes cost terms complexity exposition 
hand consider utility outcome uncertain cases 
utilities certain small set possible states game positions goal states may fully known utilities states defined expectation distribution known states 
classical theory holds utility game position example logically determined utility game positions minimax criterion accessible agent knowledge case approach treating exact utility positions inherently random mentioned value computations change agent utility function problematic 
problematic question computation valuable increases agent confidence right course action offering possibility revising course action 
clearly undone computation increase agent confidence course action decrease optimality action guaranteed 
utility computations sole possible outcome increase confidence 
variable familiar ai researchers 
just standard axioms probability utility theory revised allow limited rationality real agents making vulnerable charge incoherence important open philosophical problem shall attempt tackle 
suggest goals re axiomatization accomplish 
models deliberation types computations may refining decision act 
section introduce progressively specific models deliberation 

external model general level analyze system external observer ascribing utilities probabilities system actions internal states 
formal discussion section applies computation deciding action long time default action current best action denote ff agent take ceased computing time 
important emphasize action appears best agent deliberations far necessarily action truly best agent 
goal computation prior action refine choice default action 
note algorithm deciding act assimilated model assuming initial default action consists uniform random choice available options taken algorithm interrupted produced useful output 

estimated utility model way agent select current best action making explicit numerical estimates utilities action outcomes 
agent best action ff time action current utility estimate maximum assume ties broken randomly 
ai literature utility estimation functions called evaluation functions 
deliberation proceeds revising refining utility estimates 
model discussed section 
principal theoretical problem introduced model dependence utility estimates computations done 
results potential ambiguity defining rational course computation 

concrete model concrete level decision algorithm specified far way results computation step revise agent intended action 
class estimated utility systems means updating action utility estimates 
applications concentrated metareasoning forward search programs programs revise utility estimates outcome states generating evaluating successors 
analysis concrete level discussed briefly section 
notation notation ffl set possible external actions available agent current state 
streamline notation context dependent current state implicit 
ffl set possible computational actions available agent 
ffl world state 
includes external aspects internal state agent 
ffl world state results action current state action internal computational action external 
simplicity consider case action deterministic outcome 
ffl result action world state ffl agent utility state typically depend external portion world state 
ffl sequence computational actions typically sequence carried previous external action current state 
refer potential sequence computational actions particularly ended external action 
ffl sequence actions consisting sequence followed action ffl agent estimate quantity estimate results computation ffl ff agent current default intention typically external action considered far highest utility 
ffl ff external action recommended computation ffl fi fi external actions currently ranked second best third best metalevel decision problem order concept resource allocation sense system question choice computations available return decision affect ultimate decision 
computations may vary dimensions amount time quality solution returned certainty adequate solution returned usefulness partial computation process interrupted 
purposes amount time quality solution returned metalevel decision situation significant aspects 
illustrates choice situation agent finds 
time agent decide continue computing performing computing take current best external action ff 
agent takes computation step sequence steps may taken including empty sequence followed external action ff complete sequence computation steps undertaken acting 
example president faced difficult potentially unpopular economic policy choice request coarse grained simulation model run results detailed model run eventually bullet taxes raised 
decision theory optimal action maximizes agent expected utility probability agent currently state value computation step defined terms resulting state 
computations directly affect system internal state indirectly external world consuming time utility function usually refers aspects total situation external agent budget deficits 
define terms changes take place world computation occurs possible change agent action result computation 
section precise 
important recall stage considering meta level choice viewpoint external observer suggesting agent explicitly set solve decision problem computation 
particular assume agent access exact utility function value computation define net value computational action resulting increase utility compared utility default external action ff taken gamma ff major distinction needs specifying partial complete computations 
partial computation result commitment external action complete computation 
complete computation utility just utility action ff chosen result computation action carried completed 
ff 
ff gamma ff example aforementioned economic simulation takes week value difference doing ff cutting spending raising taxes week 
general partial case computational action bring changes internal state agent affect value possible computational actions 
case want assess utility internal state terms effect agent ultimate choice action 
utility internal state expected utility base level action agent ultimately take internal state 
expectation defined summing possible ways completing deliberation internal state 
letting range possible complete computation sequences ff represent action chosen computation sequence ff probability agent perform computation sequence agent perfectly rational metalevel computation sequence selected maximizing ff sequence probability equation 
words agent carry computation step valuable computation sequence 
leads standard minimax max approach decision analysis see pearl ch 

agent limited rationality reason assume succeed action highest expected utility 
assumption warranted modeling agent outside 
approaches avoid requirement perfection discussed section 
completion sequences maximal utility probability occurring result summation 
ideal approximate control decision theory ideal solution meta level decision problem simply perform whichever action set fff maximum expected utility 
equivalently terms net value computation defined ideal control algorithm follows 
keep performing available computation highest expected net value positive expected net value 

commit action ff preferred internal state resulting step 
algorithm intuitive notion value computation defined precisely proposed 
obviously calculation expected values various possible computations instantaneous fact describe arbitrarily hard 
possible approximate ideal algorithm making simplifying assumptions 
particular show possible agent utility estimation function estimate expected net value computations 
value utility estimate revisions section spell transformations equations previous section render useful omniscient designer limited rational agent explicitly reasoning problem solving 
correspond second level analysis defined section 
job replace function function assuming agent able calculate terms 
require care function depends stage computation 
reasons discuss choose replace equation utility estimates actions state computation question done 
estimated net value computation equation gamma ff assume agent take action appears best time decides act equation max note assumption differs dubious assumption classical decision theory agent choose action true utility highest 
course computation performed random variable 
agent know ahead time exact value sufficient statistical knowledge distribution similar actions past situations agent estimate expectation gamma ff subsections deal problem estimating equation complete computations 
subsection discusses problem estimating expected value partial computations fully satisfactory solution 
section concludes generic description rational behaviour respect decisions computation action 
analysis complete computations suppose know assume agent act computation step question act immediately suppose choosing complete computations 
utility equal utility action ff believed agent optimal carried action carried completed 
ff net value ff gamma ff expectation current state ff gamma ff equation clear knowledge necessary assign values computations resides probability distribution utility estimates top level actions 
computation step general affect utility estimates actions hu joint distribution probability actions get new utility estimates respectively 
ffj projection distribution current best action ff probability distribution random variable ff 
max equation max du gamma gamma ffj du probability distributions obtained gathering statistics past computations case computations yielding exact values simply agent current probability distribution variable question 
case computation characterized belonging class computations economic forecast provided certain model additional ply search iterative deepening algorithm 
computation characterized pre determined set features describing situation carried 
characterize distribution random variable computing post hoc net increase ff gamma ff large sample computations similar situations drawn class 
sampling done line results stored parameterized form cost applying formula estimate expected net value computation orders magnitude cheaper carrying 
case expected value calculation worth doing allows select computations prune pointless branches terminate deliberation way maximize utility agent 
crude approach fail value computation depends aspects current state data needed provide accurate statistical estimates aspects ignored resulting large errors 
better need know process computation revises utility estimates external actions 
section describes improvements 
discussion deep issues arise fact agents dealing limited rationality 
manifest particularly questions theoretical status utility estimates 
majority limited rationality done context probability estimates utility estimates viewed estimating probability obtaining exact rewards issues 
put simply problem probability estimates particular computation sequence obey axioms probability 
example axiom probability states probability tautology 
say winning opening move chess implication relationship rules chess fact 
probability estimate arrive win 
reason adopted superscript notation computation arrive utility estimate 
breese simply write computation additional conditioning conditional probabilities decisions 
natural misleading longer dealing probabilities 
lack coherent theoretical basis probability utility estimates results tricky problems formulating approach controlling computation 
note equations estimate sj evaluate ff ff new old best moves 
reason obvious consider case provides performance profiles available computations dean deliberation scheduling algorithm follows equation consisting running available decision procedures small increment time 
ff ff ff ff simply revises upward estimated utility ff alter choice move 
net value depend passage time spent deliberation real intrinsic utility course constant 
case utility estimate new best move current utility estimate current best move 
examining howard information value theory find formula context amount defining expected net value ff gamma ff equivalent formula equation provided current state ff ff 
coherence condition hold true perfectly rational agent expected increase decrease expected utility estimate due deliberation reflected current estimate 
agent limited rationality instance agent relies fixed easily computed evaluation function may safe assume utility estimate rational sense 
fact may case coherence condition holds optimal limited rational agent evaluation function satisfied coherence condition complicated expensive compute 
underlying principle respected real utility carrying action time changed just thinking 
principle important inductive meta level learning agent evaluates computational actions post hoc order learn statistical distributions predictive function value computation see section 
want formula ff gamma ff expectation taken lead erroneous evaluations 
particular case ff ff ought case external effect computation delay action 
equation agreement condition equation need 
gives second reason employ bayesian conditional subjective expectation notation js concept denotes expected utility knowledge logically deducible agent state trivially obeys identity js js js fact expectation symbol ffl equation interpreted caution 
recall wish view computations stochastic experiments outcomes drawn unknown probability distribution 
assumption equation refers expectation objective frequency sense 
course desired effect obtained current estimates moves 
computation non positive utility definition ff higher current utility estimate moves 
time cost far captured real time nature environment explicitly including situation action taken argument utility function 
comprehensive function total state affairs captures constraints trade offs particular form time constraint expressed way 
inclusion dependence state significantly complicates analysis 
certain assumptions possible capture dependence utility time separate notion cost time consideration quality action separated considerations time pressure 
estimated utility functions define related function estimated intrinsic utility denoted cost function expresses difference total intrinsic utility gamma 
course exist function satisfy equation trivially 
order qualify intrinsic utility satisfy constraint 
state new current state agent optimal action time highest intrinsic utility independently cost sufficient condition cost computation independent action evaluated gamma cases considering change actual utility action occurs computation depend js length elapsed time course events outside world time 
definition computations alter internal state affect course events depend length computation computation 
cost function case call tc time cost gives loss utility agent due temporal delay performing action gamma tc js ai applications intrinsic utility function static evaluation function defined yield accurate estimate true utility action various time pressures 
fact independently definable empirical observations outcomes 
define intrinsic utility current situation convenience fact utility defined arbitrary positive linear transformation 
approximately true ai domains game playing path planning fixed slowly changing environment 
true domains hunting war different possible actions gain lose value different rates time 
chess condition fail time complex positions valuable 
function tc exists separate cost benefit computation 
rewrite equation follows ff gamma ff ff gamma ff gamma tc js delta gamma tc js delta ff gamma ff denotes estimated benefit computation 
delta estimated increase intrinsic utility new best action old best action 
simplifying assumptions ideally point computation able assess expected value immediate continuations computation making assumptions afterward 
computations general arbitrarily long complete analysis infeasible 
difficult estimate value computations provide making computations possible valuable 
necessary employ simplifying assumptions approximations 
simplifications 
closely related pearl called myopic policy 
validated consideration domain application 
experiments show resulting selection computations far better random fact better algorithm designed hand certain conditions 
meta greedy algorithms explicit consideration possible complete sequences computation steps intractable obvious simplification consider single primitive steps estimate ultimate effect choose step appearing highest immediate benefit 
call algorithms meta greedy algorithms 
get different variants depending estimate ultimate effect computation see 
meta greedy algorithm effectively fixed meta meta level policy depth limit meta level decision problem 
analysis approach said employ meta greedy assumption assumption employing restricted horizon meta level decision problem provide adequate framework meta level control 
compared corresponding assumption game playing research limited depth search adequate method choosing moves 
weaker form approach consider purposes meta level analysis finite sequences computation steps 
instance context single agent heuristic search consider expansion leaf nodes finite depth fixed depth horizon 
analysis incomplete consider possibility expanding different nodes different depths involve exponentially possibilities number leaf nodes lead tractable policy 
considering simple subset possible computation sequences finite size provide tractable approximation complete policy 
single step assumption discuss detail section restrict attention limited set possible computations difficult assess ways computation increase utility 
particular difficult take account impact computation making computations possible valuable 
hand difficult write simple closed form expressions expected value complete computations seen 
obvious simplification equations evaluate partial computations 
assume computation value complete computation useful approximation true value possibly partial computation 
assumption tantamount acting time complete computation step call single step assumption 
assumption cause underestimation value computations case game playing trees grown certain size node expansions valuable partial computations value complete computations 
effectively limits depth meta greedy algorithm employing single step assumption search game tree 
case single agent search phenomenon occur restriction search depth 
worth emphasizing meta greedy single step assumptions completely relaxed completely true 
possible consider possible sequences computations completely relaxing meta greedy assumption restriction consider sequences complete computations assuming process deliberation eventually terminate single step assumption exactly correct 
hand accurately compute full expected value single computation steps considered possibly partial computations followed computations need consider possible computation sequences 
simplification lies employing assumptions jointly restriction 
partial computations assume agent necessarily take action ff performing computational action methods sections suffice 
general case long agent arrive complete certainty utility function assume agents attain state agent choice action ff continuing deliberate 
assume simplicity course computational action open agent juncture 
value computation value having choice 
section discuss possible ways attempting relax single step assumption evaluate accurately partial computation discussion preliminary general problem remains unsolved 
ways model utility state having choice actions discuss 
see practical effect ignoring partial computation values consider computation increases utility estimate current second best action fi point roughly midway current value fi ff 
change choice current best move positive benefit complete computation 
suppose followed computation decreases utility estimate ff fi case complete sequence net benefit delta ff gamma ff ff fi evaluate computations separately single step assumption decide delta delta ff gamma ff 
intuitively clear benefit ascribed possible effect 
just ordinary decision making best consider plans action sequences easily identifiable benefit 
adaptive approach assume agent able faced choice choose best option utility having choice actions just maximum utilities actions 
standard approach taken decision analysis see instance pearl 
action continuing compute state 
model utility computational action current state ff difficulty formula defines value computation terms value possible computation 
usually unreasonable agent assume limited agent perfect knowledge utility function necessarily choose action maximum utility state 
hand replace equation obtain maxf ff argued equation principle rationality sense imposes constraint extension base level actions computational actions 
true definition agent pick action maximum sense equation says agent value action values computation recommended action 
far possible function obey equation 
argued agent knows estimated utility function error prone needn think right hand side equation gives true expected utility computational equation define unique extension computational actions ungrounded specify recursion bottoms 
possible way overcoming non uniqueness involves specifying conservative extension base level computational actions 
fact need method arriving reasonable post hoc evaluation computational action order gain knowledge distribution values statistical sampling 
note time collecting sample data available complete outcome decision making event 
willing assume solely purpose evaluating sample computations current agent decisions action computation correct arrive justifiable numerical values evaluating completed computations equation backing values obtained determine values partial computations 
values data points induce intensional characterization utility computations 
detailed description procedure 
data derived way course error prone point doing analysis think agent incorrect judgments concerning continue computing 
done sampling equipped agent decision theoretic search control knowledge longer agent different hope better choices sorts situations 
initial set distributions obtained simple matter agent revise distributions incrementally gains decisionmaking experience 
way agent adaptively converge state possess accurate knowledge value computational procedures 
knowledge applied negligible overhead system achieved state bounded optimality 
probabilistic self modelling wish assume agent able choose best action state may assume agent certain probability action 
probability may directly related utility action extreme case assume probability action highest utility actions arrive model equation 
better agent utility estimator approximation closer probabilities come extreme case long remains error prone probabilities lie open interval 
ff js js respectively probabilities state agent immediately take new best action ff continue deliberation computational action model expected utility computational action difficult settle sorts philosophical questions raised considerations attempt 
hope dilemma raised convince reader questions raised deep 
action ff js ff js equation formula gives value current computational action terms value 
expand action recursively similar way expansion develop decision tree usual sequential decisions fact peripheral branches represent external actions see 
right hand side equation expectation sum terms form ff js ff ff js js ff ff js js js ff expression averages possible complete computations see equation 
combine terms corresponding situations action chosen get expression form delta delta delta represents probability action eventually chosen completing computation 
transforming equation way drop expectation sign right hand side obtain constraint ja chosen conditional notation denote informally fact action chosen influences estimate utility action utility depend time taken computation ends recommended 
believe possible practice estimate various probabilities conditional expected utilities involved equation attempted implementation 
qualitative behaviour looking specific implementations describe qualitative behaviour algorithm approach 
clearly agent tend forego consideration action current estimated value best candidate far apart case computation provide useful information probability changing action preference reasonable amount extra computation negligible 
deliberation may pointless current estimated utilities actions close variance difference values small case may computation reveal significant difference 
extreme case actions may symmetric nearly amount computation differentiate significantly 
case received scant attention literature algorithm designers terminate terminate continue basic situations erroneously assume goal deliberation identify best action maximize net expected utility 
lastly considerable uncertainty values available actions considerable overlap computation recommended 
illustrate major situations graphically 
applications concrete level point working general level making assumptions nature base level decision making mechanism 
naturally attributes certain mechanisms amenable meta level control 
computation modular sense divided steps chosen steps capable carried varying orders 
systems estimated action utilities decision making amenable analysis discussed section 
section give brief description methodology results analysing implementing limited rational systems concrete level described section 
mentioned section decision theoretic control reasoning carried statistical knowledge probability distributions utility estimates external actions estimates changed computation question 
crude approach data giving distributions directly refined knowledge base level decision making methods agent 
essentially principle 
typically computation consideration known affect certain components agent internal structure example running query proposition belief network affect probability agent assigns 
changes components affect agent choice action known ways example base level decision theoretic change probability assigned action outcome affect expected utility action choice action manner prescribed equation 
empirical component evaluating computations arises stages specific structure base level easier focus defined homogeneous population computation episodes accurate value estimates 
basic technique achieve localization stochastic effect computation write value top level action function immediate output computation 
example search algorithm immediate outcome node expanded new backed value node 
recall probability density function vector new values top level actions computation composed probability density function ij top level action immediate outcome computation change value node tree model effect computation density function jj new value define propagation function transmits new value node produce new value top level action case random variable defined function 
standard theorem rewrite density function ij terms density function jj ij jj gamma fi fi fi fi fi dx gamma fi fi fi fi fi transformation applied base level decision making algorithm 
algorithm characteristic propagation function depend characteristic ways current state computation 
main effort involved applying theory consists identifying function decision algorithm proving simplifying theorems value computation formula 
extended example process see 
subtree independence base level decision making algorithms satisfy general condition computation affects utility estimate action 
case subtree independence enables obtain simplification equation 
domains standard game playing programs minimax back method independence assumption straightforwardly true consider individual node expansions single computational steps 
formally subtree independence holds actions search space treated graph tree chess go programs analysis slightly complicated 
certain problem solving systems full analysis 
example computation involves refining probability estimate influence diagram new value may affect utility top level actions 
worst case metalevel may resort simulating computation question 
revision action preference subtree independence action utility estimate affected case examining equation see essentially distinct cases computation positive benefit changing agent intention 
computation currently non preferred move fi causes utility estimate raised ff computation ff causes utility estimate lowered fi current second best move 
call computations respectively see 
suppose considering computation affects estimated utility action fi search action change preferred move fi ff equivalently equation fi ff shaded region right ff 
happens expect better amount fi gamma ff 
gain move preference remains unchanged 
case ff ij gamma ff dx gamma tc similarly perform computation affects utility estimate current best action ff action preference changed ff new expected value current preferred move fi 
case fi new best action 
new estimated utility new preferred action current estimated utility current preferred action agent better computation revealed ff blunder 
fi gamma ffk fi gamma dx gamma tc ffk probability density function ff 
quantities equations defined directly available agent estimated statistically 
simplification greater accuracy obtained applying transformation equation 
results search applications search program computation typically proceeds expanding frontier nodes partially grown search tree 
value estimates actions calculated backing values new leaf nodes parents 
propagation function depends type backing typically involve examining values critical nodes adjacent path leaf node root 
density functions jj immediate effect computation depend nature node expanded nature expansion computation 
statistical information probability distribution acquired induction large sample similar states type expansion computation 
sketch nature applications performance 
details appear various papers cited 
single agent search admissible heuristic shown nodes subtree current best move expanded derived computable formula expected benefit expanding set nodes shown best search fact best policy heuristic function derived optimal stopping criterion real time search 
common applications type search familiar puzzle path planning environment containing randomly shaped polygonal obstacles 
model cost computation assuming fixed cost ratio cost generating edge search graph cost corresponding motion external world arrive total cost solution problem weighted sum cost solution path taken cost search employed find 
constructed algorithm called dta decision theoretic attempts minimize expected total solution cost ideas discussed 
tested dta cost ratio parameter finds shortest paths regardless search cost rta uses limited search horizon 
algorithm total solution cost various values rate exchange computation cost solution path length 
typical results puzzle dimensional path planning problems random polygons shown 
regardless rate exchange dta outperforms algorithms cost computation tends zero behaviour tends expect 
game playing derived formula value expanding leaf node computed little overhead simplifying assumptions outlined 
implemented search algorithm formula played game tournaments alpha beta algorithm depth limits algorithms evaluation function 
results terms games won nodes searched cpu time table 
decision theoretic search control shown thirteen times effective alpha beta pruning 
results noted depth limit rta additional parameter chosen user problem instances best performance obtained limit set hillclimbing 
puzzle results path planning results algorithm wins nodes game sec game ff fi ff fi ff fi ff fi ff fi table summary results othello refined search control method preliminary show factor improvement 
expect performance trend persist alpha beta programs 
search tree grows larger highly reach situation single node expansion alter best move choice point meta greedy single step assumptions algorithm conclude search worthwhile 
call phenomenon meta greedy barrier 
promising approach short term stage search consisting say depth alpha beta search extended search yielding effective search depth 
actively pursuing line collaboration hans berliner 
theory applied probabilistic games backgammon deep searches feasible backgammon due enormous branching factor 
expect significant performance improvements result 
research topics divided classes concerning construction completely general framework metareasoning concerning improvement generalization methods arise framework current state 
said satisfactory formal theory metareasoning scope theory extended govern kind computational action 
computations learning compilation result long term internal state changes contributing immediate decisions 
include framework need consider utility lifetimes instantaneous states 
resulting need consider complete action sequences pose theoretical difficulty framework builder remains seen useful simplifications yield practical insights 
place metareasoning general theory bounded optimality ascertained 
instantaneous metareasoning yields bounded optimality available costs picture 
problem infinite regress mentioned section illustrates complexities 
route clarity may lie construction feedback constraints learning procedure shown converge bounded optimality architecture arbitrary levels metareasoning 
framework established plan extend analysis evaluation search forms decision making computations construct general problemsolving architecture employs normative control activities 
concept universal subgoaling intended capture notion complete decision model making aspect agent deliberation recursively open metareasoning 
obtaining satisfactory definition computational action distinct action general nontrivial 
doyle simply posits division total world state internal external portions 
addition time framework reasonably straightforward 
actions experiments problematic rules governing rationality isomorphic computations ordinary external actions 
soar system basic deliberation mode goal directed search 
intend construct problem solving architecture decision theoretic deliberation various possible compilations basic modes computation metareasoning carried principled fashion outlined hand generated condition action rules 
consider possibility applying ideas control search theorem provers 
order needs amounting current best move 
currently implemented theorem provers partial information success branch consideration see application conspiracy numbers theorem proving search 
notions guaranteed solution proof replaced tentative partial solution justification 
algorithms defaults abstraction hierarchies island driving strategies amenable meta level control robust face complexity 
addition trying relax meta greedy single step assumptions obtain better search control algorithmic extensions yield better performance 
improve efficiency real time interleaving computation action preserving extending partial search tree developed previous deliberations 
current implementations successfully alternate deliberation action retain information deliberations 
keeping extending part part search tree involves action chosen system approach standard optimizing algorithms limit unbounded computation 
highly time bounded situations system behaviour essentially reactive system adapting dynamically constructed plan violations expectations look ahead horizon 
improve space efficiency selective search algorithms extension recursively defined decision making system 
selective search paradigm come criticism need keep significant portion search tree memory 
recursive problem reduction algorithm implemented employs metareasoning methods described keeps small number nodes memory 
approach iterative expansion generalization iterative deepening 
algorithm current state resource limit say nodes search calls state successors resource allocations depending results initial search algorithm increase resource allocation successor constant factor ff 
way algorithm uses linear space limit wastes negligible amount time repeated subtree expansions 
furthermore information returned subtree select direction search gives scheme clear advantage ida 
decision theoretic metalevel seen means construct near optimal anytime algorithm dean sense atomic computation steps 
anytime algorithms performance profiles mappings time allocation output quality may wish construct complex real time system applying simple composition operators having explicitly specify time allocations subsystems 
natural generalization task compiler language procedural abstraction subroutines 
contract specification caller callee additional freedom 
consider example definition treatment system defun treat repair diagnose performance profiles subsystems mathematically straightforward construct optimal resources total allocation construct optimal anytime algorithm problem 
currently investigating extent programming constructs simple functional composition generalized way 
summary see computational resource limitations major influence design optimal agents 
influence neglected classical theories normative behaviour result practical ai systems non trivial domains constructed ad hoc fashion 
theory value computation play central role design optimal limited rational agents 
basic insight normative control reasoning computations actions 
choosing actions involves reasoning outcomes utilities 
utility computational action derived effect agent ultimate choice action real world 
computational action effects changes internal state amount learning compilation relevant effect long term sequence actions 
problem assess effect performing computation 
method viewed extension revision information value theory cover computations resource bounded agents 
base level problem solver operates value estimates real world actions effects computations assessed prior statistical knowledge distribution new value computation question 
required distributions induced direct observation actual computations 
estimates value computations optimize system behaviour real time situations 
derive general qualitative insights principles resource allocation pruning termination 
formalized notion real time problem solving framework identified time cost useful abstraction enabling significant simplifications theory 
applied theory analyze single agent problem solving competitive game playing case knowledge decision making algorithm derive efficiently computable formula value computation 
resulting algorithms exhibit significantly better performance standard methods negligible metalevel overhead 
indicated areas research vein 
underlying idea decision theoretic control distinct approach dealing complexity ai systems 
view prevalent inference community described kautz intractable problem classes avoided progress concentrating finding polynomial time subclasses general possible 
propose systems simply select computations yield highest return shortest time knowledge domain possible carry selection 
theory identifies utilizes source appropriate knowledge 
domains identifiable regularities formal intractability results apply 
decision theoretic meta level architecture particularly endowed varied set forms compiled knowledge generates rich space possible agent configurations 
ideally system converge state bounded optimality 
full development theory metareasoning provide set principles define guide convergence process replacing standard axioms perfect rationality 
agre chapman 
implementation theory activity 
proc 
th national conference artificial intelligence seattle wa morgan kaufmann 
agogino 
real time reasoning time constraints model precision complex distributed mechanical systems 
proceedings aaai spring symposium ai limited rationality stanford ca aaai 
batali 
computational theory rational action draft 
cambridge mit ai lab 
bratman israel pollack 
press plans resource bounded practical reasoning 
computational intelligence appear 
brooks 
robust layered control system mobile robot 
ieee journal robotics automation 

minimal rationality 
cambridge mit press 
dean 
intractability time dependent planning 
georgeff lansky eds workshop reasoning actions plans 
los altos morgan kaufmann 
dean boddy 
analysis time dependent planning 
proc 
th national conference artificial intelligence minneapolis mn morgan kaufmann 
dean 
press decision theoretic control inference time critical applications 
international journal intelligent systems appear 
doyle 
rational psychology 
modern mental philosophy 
ai magazine 
doyle 
artificial intelligence rational self government 
technical report 
cmu cs computer science department carnegie mellon university pittsburgh pa elkan 
conspiracy numbers caching searching trees 
proceedings eleventh international joint conference artificial intelligence detroit mi morgan kaufmann 
breese 
computational model decision theoretic control problem solving uncertainty 
proceedings fourth workshop uncertainty artificial intelligence minneapolis mn aaai 
genesereth smith 
meta level architecture 
stanford heuristic programming project memo hpp stanford university stanford ca 

year plan automatic chess 
machine intelligence 

principles rationality 

eds 
foundations statistical inference 
toronto holt rinehart winston 
hacking 
slightly realistic personal probability 
philosophy science 
hansson holt mayer 
comparison optimization search algorithm performance 
unpublished manuscript columbia university computer science department 
hansson mayer 
optimality satisficing solutions 
proceedings fourth workshop uncertainty artificial intelligence minneapolis mn 
hansson mayer 
press probabilistic heuristic estimates 
annals mathematics artificial intelligence appear 
hansson mayer 
heuristic search evidential reasoning 
proceedings fifth workshop uncertainty artificial intelligence windsor ontario august 
haussler 
quantifying inductive bias ai learning algorithms valiant learning framework 
artificial intelligence 
heckerman 
perspective confidence focusing attention knowledge acquisition 
proc 
third workshop uncertainty ai seattle wa aaai 
horvitz 
problem solving design reasoning computational value tradeoffs resources 
proc 
second annual nasa research forum moffett field ca nasa ames 
horvitz 
reasoning beliefs actions computational resource constraints 
uncertainty artificial intelligence vol 
levitt lemmer kanal eds amsterdam north holland 
horvitz 
reasoning varying uncertain resource constraints 
proceedings seventh national conference artificial intelligence minneapolis mn morgan kaufmann 
horvitz russell 
forthcoming done 
preparation 
howard 
information value theory 
ieee transactions systems science cybernetics ssc 
kautz 
computers thought lecture eleventh international joint congress artificial intelligence detroit mi 
korf 
real time heuristic search results 
proc 
th national conference artificial intelligence seattle wa morgan kaufmann 
korf 
depth iterative deepening optimal admissible tree search 
artificial intelligence 
cox schmidt kao read 
real time knowledge systems 
ai magazine 
laird 
universal subgoaling 
doctoral dissertation computer science department carnegie mellon university pittsburgh pa laird newell rosenbloom 
soar architecture general intelligence 
artificial intelligence 
lesser durfee 
approximate processing real time problemsolving 
ai magazine 
lipman 
decide decide limited rationality decisions games 
proc 
aaai symposium ai limited rationality stanford ca aaai 
mcallester 
conspiracy numbers min max search 
artificial intelligence 
mccarthy 
programs common sense 
readings knowledge representation brachman levesque eds los altos morgan kaufmann 
pearl 
probabilistic reasoning intelligent systems networks plausible inference san mateo ca morgan kaufmann 
russell 
guide technical report 
stan cs computer science department stanford university stanford ca 
russell 
execution architectures compilation 
proceedings eleventh international joint conference artificial intelligence detroit mi morgan kaufmann 
russell 
fine grained decision theoretic search control 
appear proceedings sixth workshop uncertainty artificial intelligence cambridge ma morgan kaufmann 
russell wefald 
multi level decision theoretic search 
proceedings aaai spring symposium series computer game playing stanford ca march 
russell wefald 
decision theoretic control search general theory application game playing 
technical report ucb csd computer science division university california berkeley ca 
russell wefald 
optimal game tree search rational metareasoning 
proceedings eleventh international joint conference artificial intelligence detroit mi morgan kaufmann 
simon 
models bounded rationality volume 
cambridge mit press 
valiant 
theory learnable 
comm 

von neumann morgenstern 
theory games economic behavior 
princeton princeton university press 
wefald russell 
estimating computation case realtime search 
proceedings aaai spring symposium ai limited rationality stanford ca march 
wefald russell 
adaptive learning decision theoretic search control knowledge 
proceedings sixth international workshop machine learning ithaca ny morgan kaufmann 
wefald russell 
decision theoretic control heuristic search 
berkeley technical report forthcoming 
