learning strategies adaptive information retrieval system neural networks fabio crestani department computing science university glasgow uk presents results experimental investigation neural networks associative adaptive information retrieval 
learning generalisation capabilities backpropagation learning procedure build employ application domain knowledge form sub symbolic knowledge representation 
knowledge acquired examples queries relevant documents collection 
tests reported different learning strategies introduced analysed 
results terms learning generalisation application domain knowledge studied ir point view 
retrieval performance studied compared obtained traditional retrieval approach 
subsymbolic learning domain knowledge query adaptation research information retrieval ir suggests significant improvements retrieval performance requires techniques sense understand content documents queries 
ir researcher tried application domain knowledge determine relevant relationships documents queries 
aim research show possibility learning domain knowledge ir application means learning generalisation capabilities neural networks nn 
objective obtain sub symbolic representation ir application domain knowledge ir system adapt original user formulated query interpreting user information need light particular characteristics application domain 
principle base query adaptation similar queries similar sets relevant documents information acquired documents relevant leave dipartimento di elettronica ed informatica universita di padova italy queries find documents relevant new query 
order perform experimental analysis tools necessary document collection relevance judgements neural network neural network simulator 
document collection chosen investigation aslib cranfield test collection 
collection built considerable effort testbed aslib cranfield research project aimed studying factors determining performance indexing systems 
produced test collections documents aeronautics comprehensive documents requests relative relevance judgements 
full description collections see 
investigation reported operative limits document collection requests relevance judgements 
course understood limits generality results obtained 
main purpose investigation demonstrate feasibility proposed approach 
open issues application nn ir problem scaling results major ones 
noticed dimension data set experiments larger application nn techniques ir author knowledge 
investigations reported nn simulator planet running fast conventional computer 
ii 
simulation system simple simulation system henceforth simply called ss developed 
composed components query processor transforms query expressed index terms binary vector indicates presence term query absence 
dimension vector enable representation possible queries user formulate 
neural network simulator layers feedforward nn back propagation bp learning rule simulated planet 
matcher evaluates similarity binary vectors dice coefficient see produces value indicating similarity 
document processor transforms documents usually represented index terms binary vector representation 
experiment reported composed phases training phase retrieval phase 
retrieval purposes ss trained 
structure system training phase depicted fig 
left 
training phase matcher 
side query processor gets query form set index terms 
query processor transforms binary vector dimension input layer nn model 
input output layer nn model nn simulator set represent query relevant document bp algorithms learning 
monitored nn simulator control structure predetermined conditions met learning phase halted 
link matrices produced representing application domain knowledge acquired 
stored retrieval phase 
ss fed various teaching strategies explained section iv 
retrieval phase components ss interact way see fig 
right 
query processor transformed query binary representation nn activated 
activation spreads input layer output layer weight matrices produced training phase 
vector representing query modified better adapted application domain knowledge new query representation vector produced nn simulator output layer 
side entire collection documents transformed large representation matrix document processor 
big matrix fed result query adaptation matcher 
matcher produces ranked list document identification numbers 
ranking reflects evaluated relevance documents query 
interface ss display documents user evaluated relevance query 
iii 
evaluation criteria main features considered evaluation 
document processor neural network simulator planet query processor query simulation system relevant documents matcher knowledge representation matrices matcher document processor neural network simulator planet query processor query documents ranked list relevant documents knowledge representation matrices simulation system schematic view simulation system training retrieval phases learning performance evaluated ability system acquire domain knowledge 
evaluated approach classical nn field 
consists evaluation mean error training target results obtained results 
generalisation performance ability system generalise domain knowledge retrieval phase evaluated 
recall precision performance ss determined 
known effectiveness measures ir 
respectively proportion documents collections relevant query retrieved proportion retrieved set documents relevant query 
evaluated different stages learning different sets training examples 
learning domain knowledge taken place representation structure generalise improvement performance obtained retrieval new queries expected 
retrieval performance evaluated 
done comparing retrieval performance ss classical ir systems 
comparison enables evaluation query adaptation strategy versus original query 
results comparison recall precision graphs 
iv 
experimental results typical form experiments consists training system subset examples provided relevance assessment 
knowledge acquired means training phase adapt original user query take account experience acquired solving similar queries training phase 
training performed effectiveness evaluated ss tested see able generalise associations learned respond correctly remaining part examples 
solutions provided ss compared solutions provided domain experts 
done effectiveness ss tested effectiveness classical system evaluation similarity original user query documents 
order assure solutions provided ss better provided methods application domain knowledge 
sections report description evaluation different forms learning resulting different ways training ss 
second kinds learning called total learning tl horizontal learning hl 
application domain knowledge learned training ss examples spanning entire application domain time 
third kind learning called vertical learning vl tends build knowledge going straight specialisation dimension bothering build large base 
total learning purpose set experiments investigate ability system learn application domain knowledge set training examples form single training example query document known relevance assessment relevant query 
set training examples documents relevant set queries 
learning results observed results queries small set relevant documents gradually got worse size set relevant documents increased 
complete accordance nn theory 
larger set associations patterns learned bigger error 
mean error measure difference training set retrieved set 
context seen difference sets documents 
set composed documents experts application domain associate query considered target learning 
second set ss response query submitted 
higher error bigger difference sets difference desired real response ss 
recall training training training training recall conventional irs training training performance total learning target determined relevance assessments evaluation considered objective evaluates ss versus best results possibly give 
interpretation applies experiments related learning performance ss 
comparison figures obtained various experiments suggested setting ffl number input output units equal number terms respectively query documents input units output units ffl hidden layer explained theorem need having layers theoretically able separate classes arbitrarily complex shape ffl number hidden units set bringing number connection weight evaluated pass ffl number learning cycles performed learning phase set improvement gained performing learning cycles worth time computational resources obtaining 
generalisation results set experiments aimed investigating capabilities ss perform generalisation induction trained associations query index terms document index terms 
generalisation enable ss deal new query associating appropriate set document index terms 
equivalent modification adaptation user query application domain 
course larger training set easier ss find query similar new training set 
seen previous set experiments larger set training examples training phase lower performance learning 
interesting see generalisation varies different numbers queries training phase 
results obtained various dimensions training set reported left fig 

refer precision recall values obtained entire set queries ss trained portion 
noticed graph precision recall values higher ss receives larger training 
demonstrates generalisation capabilities nn perform better ground base generalisation 
precision recall figures obtained case absence training just possible obtain terms chosen randomly 
retrieval results ability ss perform kind generalisation required dealing new queries tested performance ss compared achieved conventional operational irs 
performance ss evaluated different stages training 
results depicted fig 
right 
recall precision graphs reported 
obtained conventional irs dice coefficient similarity original query documents entire collection 
second third obtained evaluating similarity measure documents adapted query 
different stages training displayed 
graph shows reasonable levels training approximatively ss performs poorly compared operational irs 
retrieval performance acceptable level 
approach needed modified 
probable explanation results structure training examples 
training examples represent patterns learned 
patterns input different outputs 
case nn learn associate different outputs input 
ideal situation 
association different outputs input generates noise encoding 
quite difficult nn detect similarities patterns difficult perform generalisation 
horizontal learning new set experiments performed training examples form single training example query cluster representative set documents known relevant query 
motivation performing experimentation came analysis noise generalisation results obtained tl see section 
possible way avoiding problem kind synthesis characteristics set documents relevant query 
equivalent single document representation query training phase having single different output input 
unique document representation characterise relevant documents query 
common way obtaining representation clustering set documents order produce cluster representative summarises represents objects cluster 
centroid cluster representative determined query intuition terms occurring cluster taken consideration representative cluster 
learning results learning performance increased compared obtained tl 
results gradually getting worse size set queries training increased 
case situation better tl 
adding new query set training examples adds pattern tl adds patterns documents relevant query 
hl increase error linear increase number queries training tl increases linearly 
generalisation results ss second hand information 
directly terms representation relevant documents terms representative entire set relevant documents 
implies loss information number training examples decreases enormously easing computational problems nn learning 
results obtained evaluating entire set queries various dimensions training set reported left fig 

generalisation performance appears considerably improved 
ss shows higher values recall precision different levels training 
demonstrates simpler patterns train nn easier nn encode detect similarities 
actual number different patterns reduced fact recall training training training training recall conventional irs training training performance horizontal learning patterns simpler clearer facilitate encoding feature detection generalisation 
retrieval results graph right fig 
shows improvement retrieval performance ss due new type training 
performance ss lower achieved classical irs original query 
vertical learning vl set training examples form training example query representation relevant document representation 
set subset documents documents documents known relevant particular query 
different dimensions learning set 
experiments identified ratio cardinality learning set entire set documents known relevant query 
illustrative values ratio 
various differences vl tl 
main vl concerns single query uses information documents known relevant finding relevant documents query 
heuristic rule ss uses documents relevant query documents relevant 
way similar classical ir relevance feedback 
tl ss generalise information queries relative relevant documents acquired training phase find proper query adaptation user formulated query 
case ss uses heuristic rule sets documents relevant queries set document relevant query 
tasks mutually exclusive thought different stages query session 
ss point user set documents knowledge application domain appears relevant 
relevance feedback user ss point relevant documents appear previous set 
case general application domain knowledge locate preliminary set document considered relevant specific knowledge acquired interaction user identify precisely relevant documents 
learning results results gradually getting worse size set relevant documents 
learning ratio increased 
bigger increase noted learning performance compared obtained tl hl 
due partially relatively small set patterns involved learning specific application domain context training performed 
generalisation results fig 
left reports results obtained various dimensions learning ratio 
noticed generalisation get better ss possesses larger amounts information base 
important note necessary provide ss large amount relevance information 
possible provide information gradually interactive process 
user point small set relevant documents ss reorder relevance evaluation entire collection information means training session 
user look documents identify relevant documents provided training session 
way generalisation performance ss improve ss identify new relevant documents precisely 
retrieval results retrieval results depicted right fig 

interesting note results obtained vl better term precision obtained traditional irs 
precision obtained thirds training better obtained half training low values recall situation opposite high levels recall 
possible explanation specific training obtained larger number relevant documents enables retrieve fewer documents recall training third training half training thirds training recall conventional irs thirds training half training performance vertical learning relevant ones 
behaviour ss optimal relevance information small favours larger recall relevance information gets specific ss favours precision 
query adaptation produced tl give results 
nn able learn generalise characteristics application domain knowledge 
amount information submitted system system shows form confusion 
necessary filter information learned 
query adaptation produced hl gives performance similar provided original query 
interesting thing adapted query time quite different original formulation 
accordingly sets documents resulting original query adapted quite different 
adapted query able retrieve relevant documents original query able retrieve 
adaptation process determines useful terms specified original query useful determination set document relevant information need 
level performance 
happens ss gives importance domain knowledge acquired training phase modifying query accordingly doing looses information contained original query terms specified original formulation query adapted version 
investigated performance improve constraining ss user specified terms 
result query expansion query adaptation 
results produced vl show easier learn narrow topic knowledge interfere learning 
advantage result possible distinguish different kind query generic query user expresses defined information need specific query user able point document knows relevant 
case query adaptation resulting hl combination traditional adaptive retrieval 
result provided retrieval enable user point relevant documents retrieved 
second case user process relevance feedback formulation query giving example relevant documents known ir query example provide specific formulation information need 
system information retrieve relevant documents account knowledge entire application domain focussing particular topic 
situations typical interactive query session combined relevance feedback devices 
major point result query session 
query specification set relevant documents stored training sessions 
process keep improving performance system response kind query 
proved experimental investigations going devoted analysis improvement domain knowledge acquisition 
vi 
acknowledgment partially funded italian national research council cnr project sistemi linea di ricerca 
croft 
approaches intelligent information retrieval 
information processing management 
mills keen 
aslib cranfield research project factors determining performance indexing systems 
aslib 

user guide planet version tool constructing running looking pdp network 
computer science department university colorado boulder usa december 
van rijsbergen 
information retrieval 
second edition butterworths london 
hertz krogh palmer 
theory neural computation 
addison wesley new york 
