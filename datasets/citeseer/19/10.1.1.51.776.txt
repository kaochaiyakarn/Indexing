structural matching computer vision probabilistic reasoning christmas submitted degree doctor philosophy university surrey vision speech signal processing group department electronic electrical engineering university surrey guildford surrey gu xh september fl christmas summary thesis describes method probabilistic reasoning matching geometric features extracted image features similar type model 
feature measurements represented form invariant nearly unknown transformation scene model spaces 
may measurements directly represented form relations pairs features order achieve invariant property 
scene model features measurements may viewed pair attributed relational graphs matching problem viewed graph matching 
model nodes set candidate labels scene nodes objects 
problem posed calculation labelling probabilities object measurement information posterior probabilities labelling yields highest probability selected correct 
order problem tractable making certain independence assumptions conditional probabilities expressed terms measurement error distributions prior probabilities 
resulting formula may iterated manner akin traditional probabilistic relaxation process 
form measurement error distributions dependent type geometric feature measurement noise model nature unknown scene model transformation examples 
number variations basic labelling algorithm described implications real time applications 
algorithm readily different types parallel processing computers 
key words matching labelling probabilistic relaxation object recognition 
email christmas ee surrey ac uk www www surrey ac uk supervisors josef kittler maria petrou guidance stimulating discussions course providing ideas motivation led place 
colleagues group interest discussions 
particular due george matas paul providing tools libraries implementing ideas feasible andrew enthusiasm delving theory 
lastly importantly wife support encouragement difficult times notion discovering world academic research remained pipe dream 
supported projects ied serc joint project 
ied epsrc project 
gr esprit project 
aerial images kindly provided defence research agency uk 
due british gas provided support application described section 
contents object labelling graph matching feature sets object labelling feature measurements relationship scene model higher order measurements examples theoretical framework object labelling labelling problem map labelling rule reformulation terms known quantities iterating update rule drawback object centred approach iterating update rule help relaxation rule drawbacks iteration evaluation terms formulae assignment prior match probabilities evaluation attribute attribute non null labellings attribute null labellings evaluation attribute domain size ii contents evaluation relation relation label null label relation label null compatibility coefficients comment evaluation points line segments features points features line segments features measurements line segments attributes relation types unknown euclidean transformation types unknown transformation errors directed undirected line segments estimating measurement errors real time issues identifying problem identifying degenerate relations eliminating impossible pairs nodes restricting range relations included pruning label sets example hierarchical matching parallel processing variations matching algorithm asynchronous updating improving contextual information undirected segments alternative factorisation excluding attributes iterations contents iii evaluating algorithm evaluation match accuracy road matching convergence rate sensitivity parameter values sensitivity scaling errors stereo image matching matching implementing matching algorithm comparison techniques review labelling methods comparison relaxation methods comparison neural net approach discussion review method philosophers corner iv contents chapter dimensional feature matching matching task appears component problems computer vision 
typically arises wish find sort correspondence image model aspect image images 
needed object recognition depth recovery binocular motion stereo image fusion registration problems 
restrict range applications required establish correspondence image model 
order describe matching problem start considering sources information scene model 
scene case form image example contain objects interest image taken vehicle surroundings view ground taken satellite aeroplane 
model usually sort idealised representation characteristic features scene particular consider cases scene model include spatial locations features 
take example scene fig 
single band infrared image ground taken aeroplane stored grey scale image 
features interest case roads corresponding model road map shown fig 

example model covers larger area scene includes rotated scene region 
stretch definition model little include second image scene model example images stereo pair model image regarded image 
task find correspondence scene model 
task consists parts extracting set features scene extracting model second set features comparable type matching extracted features scene model 
task matching features subject assumed means exists finding relevant scene model features 
consider features simple geometrical type points line segments corners 
non trivial application unknown transformation scene model spaces 
concentrated applications unknown trans chapter 
scene model example scene corresponding model formation euclidean transformation words unknown translation rotation 
show method extended incorporate transformations provided reasonably close euclidean 
example method handle scaling error provided error large 
example fig 
process aerial image extract roads form pixel strings approximate strings set straight line segments discarding shorter threshold 
line segments constitute scene feature set 
create second set line segments approximation roads map form model feature set 
sets shown fig 
look corresponding pairs features sets 
example set corresponding pairs desired locate aerial image map 
approach taken find correspondences probabilistic reasoning 
model features set potential labels scene features 
compute probabilities various possible labellings account measurement information available 
take view best labelling highest probability maximum posteriori probability 
order calculate probabilities bayesian approach reformulate probabilities terms measurement distributions distributions provide direct means incorporating measurements calculation 
reliance placed relations pairs features order capture contextual information scene model 
methodology handles labellings frequently required computer vision context 
approach leads evidence combining formula prescribes unified consistent manner measurements relating individual features pairs features available prior world knowledge jointly brought bear labelling problem 
scene model scene corresponding model extracted line segment features resulting update rule iterated ensure consistent solution 
iterated rule seen parallels traditional probabilistic relaxation approaches feature matching method appears converge quickly 
derivation rule simple probabilistic statement removed heuristic elements traditional relaxation methods particular provide rationale calculation compatibility coefficients 
offers clear methodology designing processes 
compatibility coefficients characterise probabilistic relaxation algorithms defined case terms relation measurement error distributions 
measurements incorporated iterations relaxation process compatibility coefficients represents significant point departure earlier 
support function derived formulation ad hoc form product rule show form approximated summation rule rosenfeld cases contextual information low 
theoretical framework shows prior information initialise probabilistic relaxation process 
contrasts approach adopted li commenced iterative process random assignment label probabilities 
feature matching method owes early inspiration probabilistic relaxation scheme kittler hancock relations features method applicable wider range matching applications 
relations follows particular 
algorithm evolved form 
non iterative version described complete description preparation 
enhancements algorithm appeared application described 
rela chapter 
method neural network approaches appeared 
follows setting framework matching theory chapter 
develop theory labelling scheme chapter discuss effects relaxing scheme chapter 
evaluation terms labelling scheme covered general way chapter described detail specific feature types chapter 
chapters deal various modifications algorithm chapter concerned real time issues 
chapter algorithm tested selection different applications sensitivity parameter values examined 
implementation issues briefly covered chapter 
deferred discussion matching algorithms relationship described chapter grounds easier comparisons method fully described 
observations method chapter discuss ways continued 
chapter object labelling graph matching chapter express matching problem object labelling considering type measurement information available show problem matching attributed relational graphs 
discuss feature sets define mean labelling context 
discuss general sense measurements features scene model transformation scene model measurement spaces 
uncertainties transformation lead idea relations pairs measurements giving rise idea scene model measurement information represented pair attributed relational graphs 
give examples showing different types attributes relations appropriate different levels knowledge transformation scene model measurement domains 
feature sets object labelling consider scene means extracted set features 
refer scene feature object call set scene features object set members fo similarly set model features labels objects 
ideally label objects single operation order ensure labellings consistent known message centred approach 
practice unable find algorithm achieve reliably reasonable time 
turn attention method labels object individually object centred approach 
chapter look method ensuring consistency individual labellings 
define distinct label set object labels sets may need consist members 
way need distinguish different sets term object frequently denote complex structure corresponds complete physical entity refers single feature 
chapter 
object labelling graph matching derivation labelling rule chapter need able distinguish labels different objects 
hand distinction label sets important suffix dropped 
symbols denote specific labels set object suffices labels frequently omitted avoid clutter 
symbol denotes labelling object label symbols denote general label label variable set typically perform operation label set label set features obtained directly model remaining member null label label objects label appropriate 
shall see null label unique correspond physical feature extracted model 
functions ffl represent model features missing result errors model ffl represent model features outside model applications scene covers larger area model ffl act label spurious scene features generated result noisy scene images imperfections feature extraction 
consequence including null label possible find label objects making simpler express labelling process relatively homogeneous manner 
matching process labelling 
consider object ultimately correct label hand separate label set object label appear label set label assigned object 
feature measurements scene feature characterised set km values referred scene feature measurements km variable denote complete set measurement sets fx measurements usually include position feature image depending application may include orientation size colour feature 
scene image usually contain noise feature extraction process subject errors measurements contain errors 
relationship scene model viewed instances corresponding random variables 
note random variables necessarily independent may necessary specify joint distribution 
customary frequently symbol denote measurement random variable instance 
corresponding set km measurements model feature km similarly abbreviate set label measurement sets fx xm keeping usual notion model sort adopt convention model measurements contain errors corresponding random variables 
applications case model errors assumed incorporated scene measurements 
discussion measurements postponed considered know relationship scene model measurement spaces 
relationship scene model measurements order perform labelling compare scene model measurements 
measurements expressed domain example transforming scene measurements model domain vice versa 
transformation usually components known uncertain 
example chapter may know relative scale scene model relative displacement may known approximately image lies map relative orientation 
assume available certain information transformation applied image scaled match map 
left uncertain component transformation forms crux labelling problem 
denote uncertain transformation operator maps measurements scene space model space 
set measurements associated object measurements expressed model domain set fx words represents knowledge enables relate measurements scene model 
general know define completely may example include parameters values unknown parameters may represented random variables 
extremes defined precisely known 
completely unknown solve matching problem means comparing measurements spaces 
hand chapter 
object labelling graph matching know precisely problem trivial scene measurements mapped model domain precisely labelling process reduces looking nearest label object 
time knowledge uncertain significant usually explicitly represent uncertainty form finite set kf uncertain constant parameters fc parameters example represent relative position orientation sets features 
distinguish categories parameters 
wemay know parameter alternatively parameter know value 
case measurements directly resort combination 
case may know example lies finite range incorporate information modelling random variable maximum entropy principles estimate possible distribution 
consider example simple application features points measurement types components position vector features 
case operator reduces addition constant vector scene measurements map model space 
location scene respect model uncertain vector uncertain uncertain transformation parameters 
known parameter values direct labelling process known provide information labelling process 
hand may differential information derive measurements objects invariant uncertain transformation usefully compared corresponding quantities derived model 
differential information way incorporate labelling process represents main advance previous map labelling methods 
higher order measurements attributed relational graphs discussion concluded general necessarily measurement types directly solve matching problem uncertainty transformation means general map measurements scene domain model domain loss information 
combine measurements ensembles objects generate quantities known relations invariant transformation relation objects called ary relation 
principle order relation may purposes rapidly increasing computational cost increases consider applications solved binary relations 
examples binary relations relative position object respect relative size orientation 
topological symbolic relations object top object general considered 
consider methods improving performance matching algorithm chapter effect consider relations type object range object 
evident symbolic relations easily incorporated desired 
note considering 
higher order measurements binary relations possible find sufficient relations invariant transformation cases loss information severe 
may regard set objects set nodes graph scene graph define sets attributes relations 
consider object measurement types km directly sufficient information object measurements usefully compared model measurements directly 
set measurements associated object defined attributes graph node fa words attribute types associated particular matching problem 
denote entire set scene attributes fa applications may convenient select attributes function relevant measurements measurements attributes directly 
similarly binary relations derived pairs object measurements may regarded mapping model space relations arcs joining nodes 
relations different types pair nodes fr provided measurement information duplicated relations expect km measurement information expressed attributes relations expect total number attribute relation types number measurement types km set relations node nodes denoted fr gamma entire set object relations possible pairs nodes denoted scene graph attributed relational graph 
corresponding model graph constructed model labels measurements model node attributes fa relations ab nodes ab fr ab ab see labelling problem seen graph matching 
relations computed possible pairs nodes graph fully connected 
chapter 
object labelling graph matching seen attributes relations derived noisy measurements mapped model space additional uncertainty due uncertain transformation attribute set viewed instances underlying random variables distribution components due entirely different causes ffl measurement noise generally uncorrelated objects ffl transformation scene model uncertainty generally highly correlated objects similarly relations 
hand assumption earlier model measurements precise model attributes relations calculated precisely model measurements 
expect object label set correct label label attributes correspond expected value 
argument relations 
relations possibly attributes created functions measurements form transformation operator different case denote transformation operators attributes relations respectively 
order avoid confusion note terms scene feature object scene node refer thing different terms merely provide difference emphasis 
terms model feature label model node likewise synonymous 
examples consider hypothetical application discussed section nodes represent point features object associated positional measurements km 
example transformation known precisely 
case stated earlier problem relatively trivial 
known precisely distribution delta function transformed position measurements attributes relations needed 
measurement noise correct labels correspond exactly find best labelling look labels minimise distance scene model attributes 
example translation unknown 

examples longer measurements attributes know map scene measurements model space 
relations form differences pairs measurements invariant unknown translation gamma gamma delta 
example translation uncertain 
know translation scene model spaces approximately example may know translation lies limits 
transformed position measurements attributes difference relations previous example represent measurement information accurate form 
example say attributes weak relations strong relations relatively narrow distribution compared attributes 
example translation orientation unknown 
case scene subjected unknown euclidean transformation respect model 
scalar difference position measurements relation fi fi gamma fi fi information pertaining relative orientation half total available measurement information longer higher order relations needed express lost information 
example translation orientation scale unknown 
words corresponds unknown similarity transformation 
second order relations invariant transformation measurement information solve problem recourse higherorder relations 
chapter 
object labelling graph matching chapter theoretical framework object labelling bayesian reasoning chapter formulating labelling problem framework bayesian probability theory derive formula enables calculate labelling measurements 
start expressing labelling problem terms maximum posteriori map labelling probability 
bayes rule making series assumptions able expand map probability express terms measurement information attributes relations available 
explicit relations evidence computing contextual map probability labelling represents crucial point departure previous probabilistic labelling relied attributes 
formulation labelling problem maximum posteriori labelling rule mentioned previous chapter section order labelling problem tractable adopting object centred approach labelling object calculated independently 
define best label object generates highest map probability object assigned label map provided probable labelling information system object label attributes relations 
state map rule follows appropriate label object map map arg max pr gamma delta approach model attributes relations regarded known constants random variables appear conditional quantities 
conciseness generally omitted expressions follow assumed implicitly included 
words map rule written map arg max pr gamma delta chapter 
theoretical framework object labelling expression note measurement information may sense duplicated example relations derived objects 
reformulation map rule terms known quantities know evaluate conditional probability right hand side directly seek express terms known quantities 
going adopt approach bayes theorem expect incorporate measurement information deriving expression specific conditional labelling pr ja probability density functions attributes relations conditional appropriate labellings view prior labelling probabilities 
expect find expression terms ffl jl attribute vector labelling evaluated point shape determined uncertain processes involved generating feature extraction mapping model domain 
offset attribute vector label match ffl jl relation vector labellings evaluated point form determined similar reasoning 
ffl pr priori probability labelling probability reasoning incorporate knowledge attributes relations 
consider reduce number attributes relations labelling dependent shrinking set relations 
relation set includes relations object objects measurements objects generating simplistic viewpoint argue case adding relations provide information 
may strictly true hand practice usually iterate map expression discuss chapter information remaining relations incorporated successive iterations 
reduce number relations considered labelling object set restricting number relations way consistent decision pursue object centred approach restricting information concerns object labelled 
shrinking set attributes 
consider classes attributes corresponding measurements generate relations denoted remaining ones denoted attributes class computed function relevant attributes object corresponding relations gamma delta reasonable exclude attributes fa ig 
class relevant relations information contained attributes 
reformulation terms known quantities object may labelling object attributes retained 
assumption assumption 
labelling object significantly affected values attributes relations involving object attributes objects corresponding relations 
comment applications example section fact calculate discarded attributes relations remaining ones case assumption clearly valid 
applications assumption may strictly true argue loss information small assumption reasonable 
note result assumption measurement information duplicated 
conditional items probability term map rule reduced number pr gamma delta pr gamma delta defined set attributes phi psi definition conditional probability write pr gamma delta gamma delta gamma delta said hope ultimately generate expression includes terms relations 
jl relations objects includes labelling terms include labelling theorem total probability expand numerator denominator label set possible object labellings turn ensure labellings appear objects including labelling pr gamma delta gamma gamma gamma gamma gamma delta gamma delta step term appears numerator denominator equation 
done different ways may need different set chapter 
theoretical framework object labelling assumptions 
approach favour factorised follows gamma delta gamma delta theta gamma delta theta pr gamma delta evaluate terms turn 
considering term assumption assumption 
relations set conditionally independent 
provides information ik comment relations derived feature measurements relations derived measurements include object error measurements common relations making relations independent 
hand common measurement information represents half information derive relations half comes remaining nodes errors independent 
assumption term factorised gamma delta gamma delta seek reduce amount conditional information 
mind assumptions assumption 
relations depend attributes knowledge 
comment errors attributes practice dominated systematic errors transforming model domain 
relations hand generally selected invariant errors dominated noise due feature extraction 
assumption reasonable 
assumption 
relations depend attributes comment reasonable attributes ones derivation relations 
assumptions simplified gamma delta address second factor right hand side see section alternative derivation 

reformulation terms known quantities assumption 
attributes conditionally independent 
comment remarked previously systematic errors attributes invalidate assumption 
consequence ignore systematic nature errors 
second factor right hand side simplified gamma delta gamma delta gamma delta consider factor assumption 
prior unconditional labelling probabilities independent 
comment argue measurement information knowing label object tells 
assumption plausible decision allow label object section consequence object centred approach 
think object particular label objects label 
hand encounter situations practice important object label assumption reflects situations 
third factor pr gamma delta pr substituting get gamma delta pr gamma delta gamma delta pr obtain expression conditional labelling probability pr gamma delta pr gamma delta gamma delta pr gamma delta gamma delta gamma delta theta gamma gamma pr chapter 
theoretical framework object labelling factor product expression depends label object apart object consideration 
rearrange simplify express conditional labelling probability formulae gamma delta pr pr gamma delta pr gamma delta gamma delta pr gamma delta gamma delta quantity known support function match encapsulates information available provides support updating prior probability pr 
tell express match probabilities conditional attributes relations function quantities referred earlier ffl information attributes ffl information relations ffl prior match probabilities label gives largest updated posteriori probability chosen correct label 
view update rule updates prior match probabilities combining measurement information form attributes relations pr gamma delta gamma 
pr gamma delta note measurement information may considerably diluted various independence assumptions 
completes derivation object centred map update rule 
chapter discuss iterating rule ensure consistent labelling 
chapters chapters discuss terms labelling rule evaluated 
chapter iterating update rule chapter explain object centred approach object labelling described previous chapter generate solutions globally consistent 
describe heuristic method rectify problem method uses update rule previous chapter relaxation iterative scheme encourage convergence consistent global labelling 
drawback object centred approach setting map rule form previous section assuming labelling object independent labelling objects object centred approach attempt maximise posterior probability pr ja labelling object individually 
contrast message centred approach attempt maximise joint posterior probability pr ja 
effect approach evident final formula prior probabilities practice generally contain little information combined attributes relations build evidence particular labelling 
evidence particular labelling strong relations particular labellings remaining objects consequence object centred approach account taken labellings provide evidence labellings 
words relations objects match relations ab labels provide support labelling irrespective plausibility labelling simple illustration effect features line segments scene model chapter 
iterating update rule scene subjected unknown translation rotation respect model noise added form small arbitrary rotations line segments 
map updating rule object labelled label object labelled label labellings clearly inconsistent 
hand labelling object completely reasonable 
see conflict arises objects labelled independently fact labelling map labelling deciding label incidentally note example labelled label fairly obvious example support labelling greater label iterating update rule help summarise update rule follows set prior labelling probabilities values determined means unrelated measurements considering 
rule expresses improve probabilities incorporating new information form attributes relations 
ideally order generate consistent solution improve prior probabilities combine attributes relations 
obvious heuristic step apply update rule second time time results iteration prior probabilities indicated prior probabilities obtained naturally want best ones available 
reasonable prior probabilities obtained way useful iteration 
repeat process times needed meet convergence consistency criterion progressively propagating information node node graph manner relaxation algorithm final best labelling selected combining strong relations plausible neighbouring labellings 
take trust iterative procedure converge stable consistent unambiguous solution 
extensive testing algorithm wide range applications authors encourages believe asymptotic solutions consistent unambiguous sense defined hummel zucker 
objection scheme expressed follows formula generates value pr ja label probability measurement information implication term pr denotes probability include information 
putting way calculating probabilities dependent set measurements combining measurements set probabilities incorporates information updated probabilities different previous set 
reject view reasons ffl view update rule indicates update set label probabilities give indication prior probabilities obtained implying best possible information times 

relaxation rule ffl assumption 
previous chapter update rule uses restricted sets attributes relations iteration posterior probability calculated pr ja 
subsequent iteration remaining information incorporated convergence posterior probability calculated pr ja 
words maintain different posterior probability calculated time 
relaxation rule discussion suggests possible improve solution problem labelling defined combining relaxation scheme 
implement scheme th iteration prior probabilities pr posterior probabilities calculated nth iteration gamma jl delta jl jl pr pr gamma delta pr gamma delta gamma delta pr gamma delta gamma delta relaxation scheme initialised original update rule setting pr prior probability pr 
algorithm terminates equation determine map labelling 
remaining issue decide iterations needed 
simple heuristic terminate certain labelling reached object assigned label probability probabilities labels particular object zero 
form updating rule derived approach state unambiguous labelling asymptotically practice adopt heuristic rule 
possibilities listed ffl algorithm iterated form relaxation algorithm noting discussion section iterate times ensure measurement information propagated nodes ii iterate ensure relational information combined plausible labellings 
rule suggest applications scene model graphs fully connected possible relations included iterations 
results indicate chapter find little improvement gained iterating twice cases 
ffl terminate scene node match probabilities exceeds gamma 
chapter 
iterating update rule ffl terminate current iteration probabilities changed 
ffl terminate current iteration conditions met probability labelling selected map rule increased ii probability labellings decreased 
ffl real time applications algorithm terminate fixed number iterations 
ffl terminate labellings changed current iteration 
iterative rule applied example section termination criterion map labelling probability algorithm terminated iterations 
possible consistent labellings final labelling fl reached second iteration 
worth noting relation term jl expression support function plays similar role compatibility coefficients relaxation methods quantifies compatibility matches relationship explored chapter 
drawbacks iteration important practical implications result inclusion iteration algorithm ffl relation iteration stored recalculated iteration 
stored creates far largest demand data storage implementation algorithm coefficients worst case placed severe restriction size matching problem handled 
recalculated time extra computation considerably increases total computational load 
hand large problems number relations number labels calculated usually substantially reduced see chapter 
ffl computation required iterations needed 
iterations needed relation stored computation extra computation required iterations small fraction total 
ffl amount computation required known advance problem real time implementation 
practice usually possible put modest upper limit number iterations needed 
chapter evaluation terms labelling formulae relaxation process equations requires evaluation types terms prior probabilities describe attributes relations 
detail evaluation specific particular type feature chapter discuss general aspects leaving specific discussion chapter 
assignment prior match probabilities prior unconditional match probability pr represents probability labelling absence measurement information 
estimation probabilities usually rough ready affair inevitably prior probabilities nature quantities lacking information 
hand method unduly sensitive values chosen 
knowledge unconditional match probability involving null node may different typically larger denote value constant evidence available contrary principle indifference prior probabilities remaining labellings object assumed equal pr gamma delta gammaz example number scene nodes larger total number model nodes reasonable suppose gamma scene nodes labelled null model node 
case put gamma adjust prior probabilities 
alternatively may know due say poor image quality estimate proportion scene features spurious 
set proportion 
chapter 
evaluation terms formulae information concerning incidence null labellings extend principle indifference set equal prior match probabilities pr gamma delta illustrate argument fig 
scene taken greetings card model outline bird 
features example line segments scene model greetings card scene corresponding bird model extracted line segment features corresponding edges 
case scene larger model task locate instance model scene 
scene generated features model features 
null match prior probability assigned value 

evaluation attribute evaluation attribute evaluate attribute jl attribute values set arguments problem remains determine form 
forms null jl label question null label non null jl label question corresponds physical model feature 
discuss case turn 
attribute non null labellings discussed section scene attributes derived mapping scene measurements model measurement space 
assume practice scene measurements transformed way true noiseless unknown attribute values close corresponding attributes correct label attribute values 
example original image model different known scales assume image model rescaled appropriately 
assume object attributes correct label differ types error introduced respectively noise scene scene model transformation uncertainties 
order able evaluate expression non null label need express types error explicitly total probability formula incorporate uncertain element transformation gamma delta gamma delta gamma delta df absence measurement information independent match gamma delta simplifies gamma delta gamma delta df term describes effect attributes transformation models uncertainty scene attributes due measurement errors result feature extraction process 
second term models uncertainty transformation scene model domains 
consider terms turn 
influence attributes relationship frames set attributes object label correct label able precisely map scene model transformation operator label attributes correct values object attributes chapter 
evaluation terms formulae mean distribution 
correct label attribute function form gamma delta gamma typically unimodal function maximum 
example measurement error distribution gaussian attributes linear combination measurements gamma delta ka jsj exp ae gamma gamma gamma oe denotes multivariate gaussian distribution random variable mean covariance matrix consider label say correct label correct value mean distribution 
unimodal maximum mean value evaluating correct label highly give larger result incorrect 
similar argument applies evaluation relation observation gives confidence update rule combination decision map labelling decision rule give required labelling 
relationship scene model frames constant ideally regarded parameter value estimated part labelling process 
labelling method preceding arguments indicate regard random variable decide distribution order perform integration 
knowledge application general comments 
applications know relationship coordinate systems order map attributes precisely 
example wish match line segments application relative orientation scene model known 
case just attribute type segment orientation 
case attribute transformation collapses delta function non null matches gamma delta gamma delta alternatively may able estimate mean variance case maximum entropy considerations take form gaussian distribution 
know lies region volume maximum entropy considerations indicate uniform distribution region appropriate ae 
evaluation attribute attribute null labellings previous methods null nodes attributes simply discarded null node label 
method requires measurements labellings distribution estimated attributes labelled null label 
reasons null labelling generated 
model may incomplete case model nodes missing null node provides alternative label 
alternatively image noisy may find feature extraction process generates spurious nodes labelled null model node 
consider situations turn 
incomplete model applications model imperfect may missing nodes 
example stereo matching application described chapter designate image scene model may edge scene occluded model may lie just outside border model 
case take view missing node exist attributes relations nodes unknown node character wild card match nodes scene genuine match missing 
null model node presents problem theory explicitly permits model node label object nodes 
wish explicitly reflect existence null nodes prior probability null match adjusted accordingly section 
viewpoint consider measurements null node unknown values interpret set random variables 
order determine appropriate form theorem total probability expand making measurements explicit da term integral ja conditional location missing null model node 
form jl non null case may remember chapter model measurement included implicitly 
second term jl knowledge labelling provides information object measurements say model measurements general lie model domain 
know set measurements correct labels lie scene domain 
term adopt maximum entropy approach uniformly distributed smaller scene model attribute domains denote symbol volume chapter 
evaluation terms formulae applications extent model domain defined case scene domain 
practice second term larger variance ja dominate result put size spurious image nodes scene data usually noisy affect measurements genuine features extracted scene creates possibility spurious scene nodes may generated correspond actual physical features 
cope situation permitting spurious nodes labelled null model node 
case null node physical existence attributes relations model node 
conditional part expression attribute 
match expression jl tells attributes involving spurious scene nodes provides information evaluating take maximum entropy view assume absence information uniformly distributed scene attribute domain size result necessarily previous case missing model nodes depending relative extents scene model domains 
particular application view taken cause null labellings 
fortunately algorithm proves fairly insensitive value null match 
see section 
size actual domain denoted attribute null match evaluation attribute domain size order evaluate null estimate domain size attribute volume occupied possible values multivariate attribute random variable take 
method employ find volume fairly crude take product approximate ranges individual attribute types 
evaluation relation reasoning procedure evaluating relation jl broadly attribute form depends null label involved 

evaluation relation relation label null label types error object measurements represented separately total probability formula jl df deciding relation types aim choose set invariant transformation case delta function express relation jl analogy attributes mean model relations 
example relations mutually independent gaussian distribution non null form gamma ab delta relation label null case label null remaining label provides little useful information form case treated way labels null 
cases refer null similar reasoning attributes assumed uniform scene relation domain value relation domain size estimated similar fashion attributes 
example consider application points matched unknown translation 
relation set consists angle distance measurement angle range ffi distance measurement typically range commensurate image size geometric mean width height say 
estimate 
compatibility coefficients remarked earlier section relation performs role analogous compatibility coefficients relaxation methods 
differences clearly dimensionless values units reciprocal random variable concerned compatibility coefficients hummel zucker example 
find convenient talk terms compatibility coefficients 
normalise values affecting outcome update rule dividing neutral value 
null match density appear appropriate value null labelling express support labelling chapter 
evaluation terms formulae contextual information 
coefficient values greater unity represent evidence matches degree compatible values range indicates incompatibility 
note logarithm values generate coefficients form hummel zucker 
comment evaluation discussed chapter object labelled independently assumption attributes relations independent 
assumption unfortunate consequence come evaluate attribute relation formulae 
formulae remember application total probability theorem uses uncertain transformation 
transformation applies scene practice strong correlation transformations applied individual object 
independence assumptions fact completely ignored transformation applied object taken independent possibly entailing serious loss information 
minimise effect problem look sets attributes relations minimise dependence compact possible 
exactly reason relations attributes ability replace set attributes equivalent set relations gives chance finding superior distribution set relations attributes invariant transformation equivalent set relations attributes transformation compact 
chapter points line segments features chapter continue discussion previous chapter evaluation attribute relation particular depend null labelling 
decide types attributes relations 
turn depend ffl actual geometric feature nodes graphs represent measurements associated features 
ffl knowledge relationship scene model spaces 
having selected sets attributes relations show results chapter equations respectively evaluate examples chapter uncertainty scene model transformation measurement errors assumed additive application uncertain operator subtraction random variable written convolutions gamma delta gamma delta discuss preceding theory may applied problems features points space 
extend discussion features straight line segments 
addition segments may undirected ffi ambiguity orientation directed ambiguity 
points features points represent simplest type feature features may generated example corner junction detection process 
just associated measurements identify position space 
assume errors feature chapter 
points line segments features independent features order satisfy independence assumptions chapter 
mentioned discussed section selection attribute relation types determined knowledge relationship scene model spaces 
consider example unknown translation scene model relative position scene model planes unknown relative scale orientation known 
attributes relate position isolated scene feature isolated model feature way say presumably label scene feature lies model 
second term integral uniform model attribute space say gamma delta constant term cancel update rule 
hand relation types specifying position node relative 
example cartesian representation object represented measurement pair 
relations gamma gamma second term integral delta function evaluate relation need know distribution image noise estimated knowledge feature detection process 
example know measurement errors feature uncorrelated normally case point features gaussian distribution variances follows gammax ae gamma oe consider variations example 
scene orientation unknown scene orientation unknown transformation longer delta function 
cartesian representation relations retained difficult determine 
polar representation centred relations represented distance relative orientation corresponding relations model ij ij 
points features measurement noise variance small independent components radial direction remains delta function angular direction uniform angular range 
angular measurements longer convey useful information retain distance nodes relation result gaussian example gamma ab delta small unknown error scale case polar representation angular component delta function 
scaling error expressed unknown scale factor uniformly distributed range jdj relations dr distance component quantity dr ignoring errors uniform distribution range proportional distance question er er observations practical note order 
firstly distributions jl convolved order evaluate relations 
example gaussian uniform distributions respectively convolution integral tedious evaluate 
usually case form distribution calculated estimated heuristically may convenient distribution integral easier 
example jl gaussian distribution simplify matters distribution gaussian standard deviation er 
secondly width distribution varies distance features distant pairs features distribution relatively broad information provided relation correspondingly useful 
occurrence pairs separation increases separation useful computational savings may omitting calculations involving distant feature pairs 
discussed detail section 
positional information attributes applications stereo matching case positional information relating image model available 
example feature height image similar height horizontal correlation 
information included pairs positional attributes 
distribution attributes broader relations particularly horizontal direction 
relations included information included twice 
chapter 
points line segments features measurement information available stronger form relations hand attributes information prune improbable labellings calculation outset see section 
application distributions estimated knowledge camera separation distance features cameras 
line segments features feature type consider chapter line segment 
line segments typically created edge detection process 
edge detectors usually consist stages image filtered enhance edges enhanced image differentiated orthogonal directions maxima resulting images detected 
pixels corresponding maxima linked strings polygons fitted strings 
edges polygons straight line segments features matching process 
applications road matching intensity ridges may detected approximated set line segments way 
line segment complicated type feature point derivation relations distributions correspondingly straightforward 
defining measurements section 
case unknown euclidean transformation choose appropriate set attributes relations section corresponding variances covariances 
done point features discuss attributes relations need types unknown transformation section 
section distinguish directed undirected line segments 
measurements line segments line segment defined measurements usually positions space endpoints cartesian representation local segment aligned define errors measurement db db follows simplifying assumptions 
line segments features 
error position segment endpoint characterised independent distributions collinear perpendicular segment respective variances denoted xx yy 
errors endpoints segment independent 

errors segment independent segments point features 
assumption valid example neighbouring segments common endpoint 
cases exception rule 
simplify notation assume section distributions endpoint errors constant problem 
minor additional complication deal cases true 
deriving relations convenient represent measurements position segment centre point length global orientation errors dc dc aligned segment assuming measurement errors small compared segment length dc db da dc db da dq db gamma da dl db gamma da corresponding measurement error variances xx yy qq yy ll xx ql way segments generated segment length turns useful measurements mainly practice lines broken chapter 
points line segments features arbitrary manner 
result tend avoid segment length generate attributes relations needed estimating relation variances 
discussed section 
attributes relation types unknown euclidean transformation initially consider unknown euclidean transformation scene model unknown relative position orientation known relative scale 
case useful measurement types attributes define relations invariant transformation 
chose simple express angle segments position centre segment respect expressed local polar representation ij ij ij choices possible example local cartesian representation relative centre position place polar 
relations invariant transformation delta function errors relations expressed terms measurement errors dr gamma cosq dc gamma sin dc gamma cosq ji dc gamma ji dc dq gamma sin dc gamma cosq dc sin ji dc gamma cosq ji dc delta gamma dq dy dq gamma dq specified distributions measurement errors exploit independence assumptions section calculate variances covariances relation errors gamma cos cos ji delta xx gamma sin sin ji delta yy theta gamma sin sin ji delta xx gamma cos cos ji delta yy yy yy 
line segments features gamma sin sin ji delta yy gamma xx yy earlier assumed errors relations variances constant set objects 
apparent expressions covariance matrix terms functions relations assumption oversimplification 
assumed covariance matrix diagonal clearly case particular set relations chosen 
types unknown transformation different types unknown transformation handled similar way euclidean example 
give examples information available 
unknown translation case relative orientation scene model known segment orientation attribute 
relation angle segments redundant longer 
unknown euclidean transformation small scaling error unknown transformation nominally euclidean practice small scaling errors distortions encountered 
order generate set relations invariant scaling errors options discard distance relation entirely entails loss substantial proportion structural information ii ternary relations option rejected outset 
practice case point features small amounts scale distortion may accommodated adding extra error term distance relations proportional distance 
variance term affected analogy point features gamma cos cos ji delta xx gamma sin sin ji delta yy er variance scale error 
effect adjustment scaling error give emphasis relations nearby nodes contrast distant nodes 
remember previous chapter section solution suffers drawback scaling error modelled separate random variable chapter 
points line segments features relation 
clearly true means ignoring fact scaling error single constant 
hand scale factor error modelled single random variable method model arbitrary unknown deformation provided amount deformation increases distance 
systematic errors may wish model similar way 
consider example image structure model wish match corresponding features image model 
position camera known approximately model projected image plane error 
knowledge projection process extra terms added variances similar manner scaling error 
stereo matching epipolar constraint similarly 
errors application stereo image matching described section unknown transformation images roughly modelled translation 
poor representation transformation amount translation feature pair depend depth scene point 
type application worth noise model relations derived section simpler model variances relation types independent constant 
difficulty approach values variances estimated 
finding correspondence image projection model section assumption unknown transformation euclidean 
better uncertainty model assuming pose model subject errors explicitly propagating errors projection process 
directed undirected line segments comment order concerning angle measurements relation line segments 
segment defined pair endpoints 
applications endpoints ordered know way round segment case segments derived edge detection example direction segments defined looks direction intensity gradient image positive say right hand side 
segments directed segments segment orientation range gamma ffi ffi arithmetic involving orientation performed modulo ffi hand consider example segments extracted detection intensity ridges segments extracted outline drawings know way round segment endpoints ordered segment orientation ambiguity ffi segment orientation range gamma ffi ffi arithmetic measurement performed modulo ffi segment undirected segment 
information available result ambiguity may retrieved modification matching algorithm section 

estimating measurement errors cases directed undirected segments exist 
example scene may generate directed segments edge detection process 
case direction segment depends relative image intensity side edge 
hand model may information undirected segments generated 
case angle arithmetic performed modulo ffi estimating measurement errors practice sections shown distributions attributes relations expressed terms measurement distributions turn determined variance terms providing form measurement error distributions known estimated 
section discuss possible origins measurement errors turn gives indication assign values variances 
practice variance values may approximate method unduly sensitive actual values 
discuss errors terms variances xx yy errors segment endpoint defined section point features single error variance section deduced means yy matching algorithm evaluated number different applications features variously directed undirected line segments points 
distinct sources positional errors feature measurements identified 
feature types noise image creates errors usually quite small 

line segments errors caused uncertainties collinear location segment points mainly due line breakage 
line breakage occurs different reasons different applications feature genuinely straight line image noise feature occlusion caused feature detection process break segment smaller ones 
occlusions caused image boundary 
underlying feature curve approximated set straight line segments scene model position segment endpoints curve arbitrary general correspond scene model 

causes line breakage line features may deliberately broken smaller pieces order give better defined physical location 
actual noise parameters errors type analysis processes generate segments original image analysis example provides means estimating xx yy directly 
errors type essentially affect xx practice effect line breakage location segment endpoints direction collinear segment poorly defined chapter 
points line segments features resulting large value xx effect errors type 
errors assumed uniformly distributed range xx set value 
note approach taken value xx clearly different different segments especially errors type covariance expressions section modified accordingly 
errors type correspondence segment lengths scene model poor dl large segment length provides little useful information 
errors type segment lengths fairly defined tend similar contain little information 
way practical considerations avoid segment length generate attributes relations 
seen needed estimating relation variances 
chapter real time issues practical machine vision problems time taken algorithm computed important 
storage requirements algorithm impact real time performance general larger data stores slower access times 
strict upper limit time available computation applications described hard real time 
mind long program takes provided criterion met 
hand hard fast limit may rough time limit performance regarded unacceptable soft real time application 
software requirement type usually limit patience patient computer user 
basic iterative rule described previous chapters expensive terms computation time storage requirements need examine extent requirements look ways computational load reduced practice 
discussed chapter term compatibility coefficient denote normalised relation distinction important terms interchangeably 
identifying problem iterated map update rule derived chapters summarised chapter 
real time issues iterate objects ng labels gamma jl delta jl jl pr pr gamma delta pr gamma delta gamma delta pr see frequently executed part algorithm multiply accumulate operation constitutes inner loop calculation support functions 
parts computation dominate processing time multiply accumulate calculation relation parts require processing power directly related number compatibility coefficients 
takes significantly longer compute compatibility coefficient perform multiply accumulate coefficients reused iteration relaxation process highly desirable store assuming iteration required 
constitutes main storage requirement algorithm storage requirement directly related number compatibility coefficients 
see key reducing computational requirements reduce number compatibility coefficients 
said coefficients iteration remaining loops problem fourth order 
precisely number non trivial coefficients calculated approximately square total number labellings number possible non null labels object coefficients considered dimensional array convenient portray form array sub arrays fig 

sub arrays corresponds different ordered pair scene nodes sub array elements 
rows columns entire array 
see ordering coefficients lends efficient indexing arrangement performing multiply accumulate operations expression support function 
identified approaches may able reduce number coefficient calculations 
ffl identify relations containing little information dealt en masse effect pruning scene model graphs 
identifying degenerate relations arrangement coefficients array ffl reduce total number possible labellings ffl reduce number features matched initially 
consider approach turn 
point stressed relation hard real time applications 
basic algorithm described amount computation precisely determined advance sizes scene model feature sets number iterations known 
practice number iterations needed fixed advance time needed compute matches predetermined 
property essential requirement hard real time application 
apart multiprocessing option methods described suffer defect computation time longer determined advance execution time unmodified algorithm serves upper bound 
identifying degenerate relations eliminating impossible pairs nodes consider application scene covers larger area model example attempting locate object cluttered scene example section discussed 
pairs nodes scene possibly corresponding pair model labels null label 
scene pairs corresponds complete sub array chapter 
real time issues fig 

values subarray terms zero exception right hand column bottom row ones involve null label value unity value 
consequences threefold ffl compatibility coefficients individually calculated 
ffl storage individual sub array allocated separately storage need allocated sub arrays 
ffl apart bottom row subarray inner multiply accumulate loop support function expression consists single non zero term obviating need perform multiply accumulate row 
bottom row computational savings possible 
adopt similar strategy case applications model covers larger area scene example described chapter 
case model contain pairs nodes possible matches scene 
case wish coefficient storage necessary change round storage strategy sub array corresponds particular ordered pair model nodes 
inner loop longer processes consecutive zero valued coefficients computational savings significant 
restricting range relations included consider possible pairs nodes scene model follows provided sufficiently rich set relation types may large amount redundancy set compatibility coefficients 
relations nodes sufficient define node completely respect similarly nodes follows node defined completely respect practice information perfect recognise having information implicitly having available explicitly 
restrict number nodes node relations example considering node pairs separated distance 
mechanics scheme operate similar way previous section difference node pairs excluded values corresponding compatibility coefficients set unity indicating view possible matches concerned provide support 
economies calculating storing coefficients section hand omitting corresponding multiply accumulate operations replace accumulate operations 
scheme particularly appropriate situation assume relative scale scene model known contains small error 
case discussed chapter variance distance relations small node pairs close increasingly large node pairs 
pruning label sets apart 
node pairs sufficiently far apart relation distribution dominated scaling error corresponding compatibility coefficients set unity 
pruning label sets analysing application usually label sets ng considered contain members object labelled model label total number coefficients calculated nm measurements attributes application attribute bounded may possible eliminate labellings outset 
labelling may case jl 
means labelling impossible remove label label set outset 
corresponds deletion row column array fig 

example know projection scene model euclidean relative orientation scene known limit sigma 
assume scene noise uncertainty due noise orientation individual scene node say sigman 
attribute lies entirely domain gamma gamma possible matches relative orientations differ nj ignored 
example tested strategies sections road matching application described 
example fig 
segments longer pixels segments scene pixels square map scaled match scene contained segments covered area times scene pixels square 
matched segments shown black lines unmatched segments map shown grey 
matched segments calculate position orientation image respect map represented fig 
correspondence cross pointer symbols scene map 
ran matching algorithm initially enhancement schemes non null compatibility coefficients computed algorithm converged iteration time sun sparc 
approximately execution time spent calculating coefficients performing single relaxation step 
examine effect algorithm applying strategies described 
tested separately combined 
criterion convergence labelling node probability 
chapter 
real time issues image map matching road segments eliminating impossible pairs nodes model larger scene searching pairs model nodes simultaneously label pair scene nodes 
largest separation pairs model segments estimated finding largest separation pairs scene segments adding corresponding standard deviation pixels total 
possible pairs model segments outside range eliminated calculation described 
case coefficients computed 
algorithm converged iteration complete labelling generated 
restricting range relations included strategy specified maximum distance segments model relations considered 
set distance pixels result coefficients computed 
iterations required reach convergence algorithm took run 
time nodes labelling different case reasonable candidate labels alternative picked 
restrict range distances segments scene tested iterations needed result execution time increased 

hierarchical matching pruning label sets case assumed orientation map respect scene known sigma ffi enabled restrict set possible labellings segment orientations match range 
number potential matches reduced coefficients generated execution time 
combining schemes combined schemes reducing computation number coefficients computed computation time 
labellings generated original example 
results table ease comparison 
scheme reducing 

execution 
coefficients coefficients iterations time sec eliminate impossible pairs reduce relation range pruning label sets schemes combined table performance figures schemes reducing number coefficients hierarchical matching applications quality measurement information objects may superior 
example line segments matched longer segments better defined orientation shorter ones spuriously generated 
hierarchical approach features shorter threshold length discarded leaving subset better longer scene features large reliably establish match model 
scene segments accidentally broken model may possible prune shorter model features similar fashion 
basis separate label set pruned threshold length length particular object preliminary match determined reduced object label sets results match determine accurate transformation scene model 
information possible generate additional attributes method section eliminate possible labellings matching algorithm rerun original complete node sets 
chapter 
real time issues image map image road network map showing respective node sets illustrate technique road matching example 
time segments included scene contained nodes model nodes 
generated theta compatibility coefficients number effectively reduced order magnitude method previous section 
problem large run machines available time machine available extrapolation results indicated execution time order minutes sun sparc relative position scene model unknown attributes available 
segment length means ordering node sets nodes certain length eliminated consideration pass 
threshold set heuristically generate sets reasonable size 
example shown fig 
threshold pixels yielding sets sizes nodes scene model respectively 
generated theta coefficients pass converged iterations executed sun sparc 
result pass shown fig 
crosses arrows image map indicate respective relative position orientation matched unmatched nodes shown respectively coarser finer line segments 
original roads segmentation indicated map finest lines 
fig 
indicates pass possible estimate position orientation scene respect model having done possible estimate accuracy match 
second pass possible labellings estimated positions error standard deviations discarded 
rigor 
parallel processing image map correspondences st pass showing computed relative position orientation ous pruning applied labellings orientation mismatches labellings estimated orientations error ffi discarded 
generous tolerance adopted extra line segments included second pass shorter ones larger orientation errors pass 
second pass theta coefficients generated iteration sufficient convergence execution time 
results shown fig 
relative orientation derived pass rotate map align image 
short road segment shown finer line correctly matched segments fig 
incorrectly matched null model node 
order demonstrate importance selecting node subsets saliency pass rerun time nodes selected random create sets image map size pass 
case match resulted appears roughly region map fact entirely incorrect fig 

apparent different direction dotted pointers figs 

parallel processing examine labelling rule chapter apparent computations performed independently 
working innermost loop outwards observations chapter 
real time issues image map correspondences nd pass results st pass rotate map image map incorrect result st pass random node selection 
parallel processing summation loop terms summation independent computed parallel summation partly need log serial operations size label set 
product loop factors product similarly independent product needs log serial operations object set size 
loop label set labellings loop computed independently 
loop object set provided modification algorithm described section labellings loop independent performed parallel 
modification labelling probabilities calculated object needed labelling object parallel computation level longer possible 
relaxation loop clearly iteration outermost loop dependent results previous iteration parallelisation possible 
case parallelisation possible compatibility coefficient single processor coefficient calculations performed processor 
cases parallelising label object set loops amount interprocessor communication required small speedup linear number processors reasonably expected 
parallelising algorithm finest level innermost loop appropriate single instruction multiple architectures range architectures earlier cray machines 
parallelising coarser levels appropriate loosely coupled machines meiko computing surface set networked machines 
chapter 
real time issues chapter variations matching algorithm details matching algorithm unfolded chapters inevitably heuristic decisions 
usual decisions things necessarily done quite way done 
chapter discuss changing rules lead slight modifications algorithm 
asynchronous updating chapter observed update rule usefully iterated leading iterative rule repeated gamma jl delta jl jl pr pr gamma delta pr gamma delta gamma delta pr gamma delta gamma delta discussion update rule iterated section point best possible available information concerning labellings prior probabilities pr 
iteration best information available posterior probabilities calculated previous iteration posterior probabilities iteration prior probabilities iteration 
extend argument latest available probabilities time probabilities new object updated 
example iteration new label probabilities object calculated objects updated 
case newly calculated values pr place pr calculating support object 
probabilities process calculated course take care new label probabilities requirement label probabilities sum unity violated 
chapter 
variations matching algorithm get benefit technique objects scene features possible ordered descending order saliency quality 
way best features better defined measurements processed 
example features line segments variances relation distributions longer segments smaller shorter ones section spurious features generated noise section 
ordered length longest shortest 
ordered object sets particularly useful update rule iterated information available processing objects measurement information weaker 
improving contextual information undirected line segments selection attribute relation types appropriate line segments discussed section selection essentially basic principles common sense 
distinction directed undirected segments particular pointed undirected segments opposed directed segments significant amount information lost due ffi ambiguity orientation segments 
ambiguity lead incorrect match may see considering simple labelling problem shown scene model anomalous match due orientation uncertainty object labelled label gets support assuming orientation labelling object label gets support assuming opposite orientation labelling object label calculating support label accumulate evidence relations object neighbouring nodes individually label gets strong support 
obvious case context label wrong need exploit contextual information 
way incorporating information follows 
labelling assume scene model segments matched specific orientation 
effect possible labellings consider pair segments 
improving contextual information undirected segments segments pointing direction pointing opposite directions 
calculate support function twice possible labellings performing calculations angle measurements modulo ffi modulo ffi larger value support function assumed correct 
pairing scene model segments labellings amount computation increase fourfold separate support function labelling computed twice relations consider 
extra computational burden reduced factor 
consider set relations pairs line segments discussed chapter ij ij ij relation types process clearly affects angle relation types furthermore really interested relative orientations particular scene model features support function currently calculated fo ag fig 
features calculation fo bg fo gg 
case relative direction relations ab orientation label respect object affects relation values orientation respect case relative orientation measurements ab relative orientations relevant 
continue measure modulo ffi measure modulo ffi relative orientations affect computation relative orientations words calculating support labelling ambiguities orientations features involved labellings longer relevant 
need calculate support twice possible relative orientations labelling objects included computation 
variant particularly appropriate update rule iterated 
iterated case extra contextual information provided scheme effectively provided subsequent iterations 
chapter 
variations matching algorithm alternative factorisation total probability expression derivation update rule chapter total probability term factored different ways 
factorisation leads preferred update rule shown 
describe alternative derivation rule different factorisation early version method 
assumption 
attributes relations derived different measurements attributes type section attributes relations independent 
comment theory excludes weak attributes corresponding relations strong example section example 
practice attributes type errors dominated uncertainty scene model transformation usually handled 
version distinction categories attributes version algorithm total probability term factored follows gamma gamma gamma delta gamma gamma gamma delta theta pr gamma gamma gamma delta term simplified assumptions assumption 
attributes conditionally independent see assumption 
gamma gamma gamma delta gamma delta second term factorised follows pr gamma gamma gamma delta pr gamma gamma gamma delta theta pr gamma gamma gamma delta theta theta pr gamma delta theta pr gamma delta theta pair assumptions regard self evident 
alternative factorisation assumption 
probability labelling dependent labelling relation conversely relation affects labelling labelling 
written pr gamma gamma gamma delta pr gamma delta pr gamma gamma gamma delta pr gamma delta gamma delta pr pr gamma delta pr pr gamma delta pr expression gives gamma delta pr pr pr pr gamma delta pr gamma delta gamma delta pr gamma delta gamma delta compatibility coefficient pr jl pr expanded simplified assumption 
order express terms known quantities pr pr gamma delta pr form compatibility coefficient depends labels null 
assume non null relation unimodal 
example gaussian chapter 
variations matching algorithm coefficient values function scene relation notation section form gamma ab delta gammaz gamma aw delta gammaz gamma aw delta fig 
illustrates simple example compatibility coefficient vary function showing different forms null label 
example relation type non null model nodes 
model node null node relation value non null model nodes 
noise distribution gaussian variance 
remaining parameters 
observations compatibility coefficient varies function near point ab term denominator labelling tends dominate coefficient tend maximum value pr gamma 
moves away region model relation value value drop away sharply neighbouring starts dominate denominator 
fig 
shows nearest neighbour close push peak value opposite direction maximum value asymptote 
coefficient approaches minimum value approaches aw 
unity 

excluding attributes iterations compatibility coefficients formed way interesting differences derived chapter ffl definition asymmetrical labellings represent ratio probability labelling relations labelling 
words viewed kind elemental support function indicating support labelling labelling ffl intrinsically normalised dimensionless 
ffl supporting label null provides support labelling regardless label view value unity 
ffl converse true labelling considered null labelling supporting supporting labelling provide information 
scene relation consistent null label vicinity non null labels coefficient low value vice versa 
support null label higher labels nearby 
excluding attributes iterations relaxation rule derived chapter incorporates attributes relations stage iterated rule 
differs earlier version incorporated relations iteration 
see particular merit earlier version include completeness 
rule derived follows 
previous section assume attributes type section 
bayes rule applied update rule order replace prior probabilities probabilities conditional attributes pr pr gamma delta pr gamma delta gamma delta pr gamma delta gamma delta rule describes add relational information set probabilities contain information attributes iterative rule form jl pr pr gamma delta pr gamma delta gamma delta pr gamma delta gamma delta chapter 
variations matching algorithm probabilities initialised applying bayes rule pr gamma delta pr gamma delta gamma delta pr gamma delta chapter evaluating performance matching algorithm fist consider ways performance matching algorithm assessed 
discuss examples different applications algorithm 
road matching example earlier chapters 
application demonstrate convergence rate algorithm test sensitivity parameter values scaling errors 
second stereo matching example third application establish correspondence image projection model 
evaluation match accuracy algorithm component larger machine vision application important able estimate quality result way 
useful heuristic indicators distance corresponding features scene model transformation determined amount support map labellings number null matches 
distance corresponding segments map labellings determined scene model transformation determined performing mean square fit corresponding features 
calculation possible find measure average distance matched pairs features 
heuristic approach taken just centre gravity features 
chapter 
evaluating algorithm labelling support look support function labelling defined section gamma jl delta jl jl pr convergence object label map label probability pr map equal unity remaining labelling probabilities value zero 
just non zero term summation expression rewritten map jl map jl map map jl map assume non null distributions involved unimodal maximum corresponding exact match 
maximum possible value map support function readily calculated 
ratio actual value maximum averaged scene nodes gives measure goodness fit result 
number null matches labellings algorithm usually assigns null label 
abnormally large number null labels usually indicates problem match 
drawback indicator experience required particular application order able judge null matches acceptable 
road matching tested algorithm series aerial images fig 
extracted larger image consisted road network 
relaxation algorithm detected intensity ridges locate roads line segments fitted mean square fit algorithm 
line segments clearly undirected sense section 
images corresponded locations map reproduced fig 

image size chosen order give feel typical navigation problem image significantly smaller map task find position orientation image respect map 
orientation images assumed image model scales closely matched unknown transformation assumed euclidean attributes relation types section 
image map segments shorter pixels discarded 
noise model covariance matrix method section 
correct position orientation image respect map known tests match accuracy mean position orientation matched segments 
algorithm generated consistent matches images correct image 
unfortunately case incorrect highly plausible match correct fig 

incorrect labels shown dark segments correct position image indicated 

road matching test images line segments superimposed chapter 
evaluating algorithm map image correct position image map showing incorrectly labelled segments map showing incorrect labelling image 
road matching convergence rate number iterations needed shown table 
match defined fig 
iterations result iterations final result fig 
iterations result iterations final result table number iterations required convergence labels basically correct incorrectly matched null node 
algorithm terminated map labelling probability value 
final labelling reached typically null labels replaced correct ones non null labelling may change cases choice labels 
result image deserves comment 
spurious scene nodes missing model nodes scene nodes poorly orientated respect correct label segments 
segments labelled null nd iteration 
sensitivity parameter values application parameter values needed null match value prior probability null label variances associated position segment endpoint 
rationale calculation default values discussed obvious values generated precise 
accordingly examine sensitivity labelling result turn 
case default values remaining parameters 
image tests image default values parameters generated genuinely null label corresponding missing model feature 
null value attributes instance concerned value relation null size relation space section 
angle relations distance relation section 
modification section range ffi range ffi image square side pixels range pixels 
theta theta reciprocal gives default value 
default value generate results table 
expect null value primarily affect number null labellings 
order test sensitivity algorithm value multiplied default value chapter 
evaluating algorithm multiplier null value 
null matches 
iterations final result table variation labelling range factors results shown table 
results suggest default value borderline range values lower value safer 
value default scene parameters model parameters give lower value algorithm insensitive parameter 
null label prior probability default value parameter section number non null labels example 
image image test default value generated null label 
expect value primarily affect number null labellings 
results surprising values gave identical results default value null labels 
setting zero forced labels non null inevitably update rule labelling probability zero value remain zero 
nearby incorrect segment selected 
similarly setting forced null labels 
variances segment endpoint position xx yy calculating default value xx errors segment endpoints segment da db assumed uniformly distributed range sigma see section 
range values side default value tested table 
cases non null matches ones case null multiplier xx 
null matches iterations final result table variation labelling xx matches multiplier scene node labelled null node labelled plausible non null model node 
appears table default value roughly middle usable range values actual value chosen critical 
subjective examination image suggested reasonable value yy region pixel values side tried results shown table 
algorithm tolerant reasonably wide range values 

stereo image matching yy 
null matches iterations final result table variation labelling yy general comments order concerning variance values illustrated results 
variances small value restricts severely permitted degree misalignment scene model causes null labels chosen expected 
large values chosen non null broader lower peak value 
consequences ffl widened lose discriminatory power may cause slow convergence ffl peak values lower value null null labels necessarily chosen 
sensitivity scaling errors examine sensitivity method scaling errors test effectiveness modelling scaling error noise described section 
experiment map range factors 
segments shorter pixels scaled map discarded 
default values parameters 
results shown table indicating performance algorithm scale extra term null match 
extra term null null null iterations extra term final result extra term table variation labelling scaling error extra term relation distance variance 
note map scale factor value gamma sj factor extra variance term 
results indicate incorporating extra term unknown scale error distance error variance range unknown scale factors algorithm tolerate significantly increased 
increased results indicate iterations needed 
expected effect degrade distant relations means iterations needed spread contextual information scene termination condition list section 
stereo image matching application stereo pair images office scene image measuring pixels 
edges images detected fitted directed chapter 
evaluating algorithm straight line segments 
assumed images orientation segment orientation attribute standard deviation ffi relation types section unknown translation 
able exploit epipolar constraint method stands assumed features image pixels horizontally pixel vertically features image information prune labelling sets section 
line segments pixels long discarded 
left hand image contained segments model right hand segments scene 
increased prior probability null labelling reflect greater likelihood null matches 
fig 
shows typical result matching stereo image pair 
note algorithm permits scene node right hand image case matched model left hand image node 
corresponding line segments images indicated white lines black lines correspond remained unmatched 
matching edge segments stereo pair images ground truth problem able identify segments 
particular worth noting segments constitute extra window panes right hand image matched correct 
extra picture appears wall left hand image part incorrectly matched middle pictures right hand image 
matching example simulation typical underwater inspection task offshore petroleum industry 
structure inspected scale model part typical offshore oil rig 
matching jacket fig 
cad model provided 
scale model jacket real life camera mounted underwater remotely operated vehicle rov 
rov moving power influence unknown currents pose position orientation rov respect jacket normally difficult ascertain accurately 
task initial rough estimate rov position establish correspondence image model generate accurate estimate rov position 
procedure follows 
initial guess camera pose project cylinder edges cad model image plane set directed line segments 

extract cylinder edges image form set directed line segments 

establish match sets segments 

gradient descent method cost function mismatch segment pairs iteratively refine camera pose 
matching algorithm implement step 
relatively easy establish camera upright able segment orientation attribute relations previous example section 
corresponding segments disparate length useful break shorter segments length roughly corresponding cylinder diameter 
chapter 
evaluating algorithm example shown fig 

fig 
image shown projection model superimposed projection initial estimate camera pose 
fig 
model projected image time updated camera pose generated system 
initial projection final projection projections model image chapter implementing matching algorithm time writing algorithm exists form pair programs gf arg generates attributed relational graph set geometric features 
optionally generate corresponding sets covariance matrices 
matcher scene model graph generates list objects corresponding labels 
utilities available assist visualisation results including find uses mean square algorithm label correspondences fit scene features model 
finds position orientation scene model 
utilities create display geometric features optionally overlaid background image 
create figures thesis 
complete labelling algorithm summarised steps 
knowledge available measurement types scene model transformation select attribute relation types appropriate problem chapter 

model features calculate model attributes relations 

scene features calculate scene attributes relations 

method section scene noise model knowledge scene model transformation generate attribute relation distributions estimate 
chapter 
implementing matching algorithm 
evaluate attribute relation terms jl jl methods chapters 
assumed gaussian distribution non null 
set iteration counter 
initialise probabilities pr prior probabilities values determined method described section pr pr 
label object compute support function gamma jl delta jl jl pr 
label object find updated probability match pr gamma delta pr gamma delta gamma delta pr gamma delta gamma delta 
termination criteria section object termination criteria satisfied go step increment iteration counter go step 

object choose labelling highest probability 
flow data algorithm shown fig 

relation distributions attribute support functions map probabilities feature match scene noise model scene measurements scene graph model graph model measurements prior knowledge attribute relation values scene model transformation uncertainty data flow chart chapter 
implementing matching algorithm chapter comparison method graph matching techniques graph matching problem important computer vision workers described multitude different methods years 
briefly discuss methods discuss relationship method methods closely related 
review labelling methods matching problem approached different ways computer vision literature 
early attempts widely popular graph search methods 
techniques generally rely heuristic measures reduce complexity inherently np complete search problem manageable level 
efforts energy minimisation simulated annealing mean field theory deterministic annealing neural networks relaxation labelling 
relaxation labelling approach particular advantage replaces basic np complete search method polynomial complexity 
probabilistic relaxation shown offer effective method attributed relational graph matching foundations consequently relaxation process design methodology heuristic 
kittler hancock directed theoretical underpinning probabilistic relaxation bayesian framework proved successful 
led development evidence combining formula fuses observational prior contextual information theoretically sound manner 
polynomial combinatorial complexity reduced concept label configuration dictionary 
unfortunately methodology applicable low level matching problems edge line postprocessing 
main reason limitation initialisation stage observations compute initial probabilities object labellings process measurements 
chapter 
comparison techniques workers attempted remedy problem heuristic means 
yamamoto information theoretic approach derive compatibility measure relational measurements measure generated heuristic means compatibility coefficients fit relaxation method rosenfeld 
li incorporated relational measurements compatibility coefficients probability updating formula 
way overcame major criticism probabilistic relaxation approach measurements stages iterative process encourage consistent labelling 
solution retained heuristic framework probabilistic relaxation introduced hummel zucker 
particular compatibility support functions specified heuristically 
similarity structure probabilistic relaxation algorithms neural network algorithms 
authors explicitly draw parallel perceptron neural networks method described parallel summarised section 
approach map rule developed method assigning probabilities labellings heuristic decision iterate rule achieve consistent result 
offer proof consistent solution obtained find practice attempts place relaxation aspect labelling problem theoretical footing 
instance method hummel zucker shown lead consistent solution albeit different definition consistency 
form update rule support function different practice converges slowly see 
show methods similar cast optimisation problems 
comparison method relaxation methods section compare method workers particular methods kittler hancock rosenfeld hummel zucker hummel zucker li kittler petrou 
derivation method similar principle kittler hancock important difference include binary unary information 
cases map probability sought cases support function initially derived form multiple summation product exponential complexity equation case 
problem resolved ways model sufficiently small dictionary method may assumed neighbouring nodes interact directly node independent enables factorisation support function 
method inclusion binary information leads form support function factorised need assumptions means apply large problems node interacts nodes 
factorised form support function similar form derived 
type product sum support function derived different approaches authors 
compare updating rule proposed rosenfeld see form support function related support function 
comparison relaxation methods form support function different 
show method limiting case method assume contextual information conveyed binary measurements small attributes 
discussion compatibility coefficients section may normalise affecting result may put pr value match expressing support match value uniform results null labelling section appropriate value positive quantity view expressing compatibility matches particular match supports match greater vice versa 
influence match match small assumed example put assuming quantities small numbers jp substituting obtain pr expanding product ignoring second higher order terms pr pr jn gamma ps form support function equivalent weighted correlation coefficients rosenfeld see methods equivalent 
practice variances small compared range corresponding measurements correspondingly large peak values rapidly diminishing tails section assumption jp alternatively attributes incorporated initialising probabilities described section 
chapter 
comparison techniques valid 
attempts method scaling ps satisfactory matches frequently incorrect obtained support function equation number iterations required convergence typically greater order magnitude 
important difference rosenfeld especially hummel zucker compatibility coefficients authors symmetric respect arguments derived general see chapter 
method match necessarily give match support gives 
hummel zucker showed updating scheme symmetrical coefficients equivalent optimisation global cost function 
asymmetry compatibility coefficients implies equivalence apply case 
method li uses similar form support function compatibility coefficients similar derived heuristically 
updating rule modified form projected gradient algorithm hummel zucker 
analysis earlier clear approach li corresponds case low contextual information 
assumption clearly hold variances distributions small 
scheme needed iterations converge typically scheme reaches stable solution typically couple iterations 
comparison method neural network approach neural networks labelling problems 
point view significant drawbacks usually require long training period particularly problems features design terms number nodes needed form activation functions largely heuristic 
shown map labelling algorithm represented terms traditional neural network components 
particular form algorithm comparison variation method described section probabilities initialised values conditional attributes 
neural network representation algorithm takes form perceptron network explicitly indicates number nodes needed form activation functions 
architecture shown fig 

evaluation support function labelling algorithm represented perceptron layers network 
inputs iteration probabilities conditional attributes 
compatibility coefficients contain scene model relational information form weights layer 
similar traditional perceptron design model information contained weights difference weights longer learnt theory 
form activation functions longer heuristic logarithmic exponential second layers respectively 
final auxiliary layer provides normalisation function ensure labelling probabilities sum unity 
probabilities fed back input layer iterative version algorithm 

comparison neural net approach log log log exp exp exp log nm units connections units nm units units nm units nm im nm weights weights feedback artificial neural network nm ia inputs attributes weights simply learnt relations multilayer perceptron representation map labelling scheme chapter 
comparison techniques alternative neural net representation briefly explored version shown fig 

simplicity attribute information included 
layers perceptron nodes calculate support functions 
time labelling probabilities represented weights layer scene model measurements form compatibility coefficients constitute input 
weights initialised prior probabilities standard map rule section probabilities conditional attributes scheme section 
weights longer contain model information respect representation common hopfield model 
auxiliary layer exponential activation function representation fig 
implicit mechanism uses support functions output update weights perceptron layer 
outputs convergence case binary give indication relative supports set labellings 
practice iterating labelling support usually significantly dominate 
fig 
network single object shown 
standard version algorithm probabilities objects updated simultaneously network replicated object 
hand asynchronous updating scheme preferred single copy network sufficient process iterated object 
representation fig 
extended include explicit generation compatibility coefficients means layer radial basis functions 

comparison neural net approach labelling label neighbour scene node inputs support labelling node label labelling label scene node inputs neighbours ji ji ji ni ni ni ji ni ni ni log log log log log intermediate nodes distinct weights nodes contribution support node nodes alternative neural net representation map labelling scheme chapter 
comparison techniques chapter discussion review method developed algorithm matching dimensional structures composed geometrical features 
method reliable rugged computationally efficient readily applications arbitrary parameters adjust 
algorithm requires inputs user scene model feature measurements total possible range scene measurements null values distributions scene measurement errors uncertainty scene transformation 
provision feature measurements suitable form usually straightforward 
scene measurement range deduced image size type feature extracted 
distributions principle problem 
measurement error distribution depends turn knowledge feature extraction process may awkward analyse noise model original imaging process may difficult obtain 
transformation error distribution may awkward calculate 
processing distributions obtain required attribute relation distributions usually complicated 
applications tried far assumed attribute relation distributions gaussian estimate measurement variances provided order compute variances covariances 
attributes cutoff value attribute distribution provided reduce number potential labellings 
power method ultimately stems basic decisions 
maximum posteriori probability rule map rule determine correct object labelling 
map rule required direct expression measurement information turn led second decision express information terms relations measurements pairs features enabled disentangle errors due measurement noise uncertainty relationship scene model measurements 
chapter 
discussion map rule map rule required evaluation posterior match probabilities 
values probabilities known directly bayes rule manipulate form consisted quantities computed 
way relaxation rule created terms direct physical interpretation consequence methodology evaluate apparent 
result algorithm requires arbitrary parameters supplied parameters required methodology provided calculate process generated features scene properties original scene 
binary relations types unknown quantity matching problem measurement noise uncertainty transformation scene model 
measurement noise substantially independent various scene features transformation uncertainty highly correlated 
applications represented parameters types unknowns need 
transformation uncertainty concisely represented possible find measurement quantities invariant approach taken 
elementary unary measurements usually required invariance measurements combinations features relations required invariance 
number features involved relation low possible computation time worst case increases exponentially number 
applications set binary relations pairs features essentially invariant transformation adequately representing structure scene model features 
restricted binary relations 
conclude summarising principal benefits method ffl derivation update rule maximum posteriori probabilities indicates terms rule evaluated ffl algorithm tolerant measurement errors presence spurious scene features absence model features ffl noise model measurements explicitly included ffl algorithm converges significantly faster relaxation methods needing iterations usually generates consistent result single iteration 
philosophers corner clearly thesis submitted degree doctor philosophy complete philosophical discussion 
case discussion topic briefly 
philosophers corner various interpretations term probability justification way assign values probabilities 
number held differing views probability basic axioms probability accepted 
identifies broad classes interpretation widely held classical view view cope situations atomic set events finite number mutually exclusive assumed equiprobable 
probability outcome reciprocal number possible outcomes 
probability calculus enables assign values various combinations outcomes 
particularly importantly point view embraces principle indifference principle insufficient reason events considered equiprobable means deciding probable 
tossing coin assume coin fair probability outcome 
know coin fair know imperfections assume equiprobable outcome 
relative frequency view commonly taught view 
view experiments probability particular outcome happening defined ratio number actual outcomes total number experiments number experiments tends infinity 
course conduct infinite number experiments practice number sufficiently large satisfy criterion 
coin tossing experiment accurate probability values regardless fairness coin provided course coin wear process 
priori view view development classical approach attempts enlarge rigorous manner range situations handled covered classical approach 
defines probability measure logical support proposition evidence 
associated theory attempts generate useful probability values small number experiments performed 
appear harsh judgements fairness coin small number tosses produce outcome 
subjective view view probability value particular individual believes 
clearly related way people place bets 
know person tossing coin mind outcome particularly money involved 
labelling algorithm viewed combining set probabilities prior probabilities set measurements instances random variables create set probabilities posterior probabilities 
implement algorithm addition providing measurements assign values prior probabilities establish distributions random variables 
deciding distribution effect assigning relative values probabilities possible values corresponding random variable 
discuss probability assignments turn 
chapter 
discussion prior probabilities assign values prior probabilities section general assumptions 
take view proportion null matches guess order assign value prior probability null match 
correspond subjective view probability 
principle indifference assign equal values remaining probabilities clearly corresponds classical view 
probability distributions distributions established scene attributes relations possibly scene model transformation 
attributes relations types distributions chapter involve null match distributions involving null labelling argued uniform distribution appropriate largely basis principle indifference 
case dealing random variable continuous type looking limiting case classical view handle arguments properly belong subjective approach 
distributions involving null labelling argued precise distribution estimated knowledge feature extraction process pushing problem back processing path point outside range discussion 
practice assume gaussian distribution felt fit observed subjective examination typical images 
practice clearly subjective camp 
see justification assignment probability values largely combination classical subjective views 
clearly performing exhaustive randomised experiments determine values relative frequency view particular relevant 
argue views place depending particular problem intrinsic proponents claim 
take modest successes far labelling method add weight view 
inevitably ways described extended suggestions means form complete list 

theoretical analysis theoretical underpinning needed particularly assessing effect independence assumptions establishing convergence iteration scheme 
aspect undertaken 
relation scheme optimisation methods better understood rigorous approach taken decision iterating 
heuristic schemes section 
attribute relation types types attributes relations particularly chosen fairly arbitrary basis reasonable 
methodology needed establish relative merits different choices 
alternatively computational efficiency desirable set relations diagonal covariance matrix 
higher order relations modelling uncertainties scene model transformation attempt select relations invariant transformation 
consider binary relations method limited transformations binary relations invariant approximately invariant 
example case line segment matching principle limited unknown euclidean transformation 
higher order relations particularly ternary incorporated undue extra computational cost range applications considerably extended 
extension problems higher order relations infeasible may able represent transformation uncertainties noise 
simple example incorporation small scaling errors section 
applications chapter dimensional aspect method currently ignores aspect treats problem straightforward matching 
stereo matching example section effect epipolar constraint possible feature misalignment ignored 
similarly example section image features matched model projection parameters known approximately account taken manner parameters propagate projection process 
cases parameters known approximately possible model uncertainty part scene feature measurement errors 
improved feature extraction typical machine vision application matching algorithm form just components system 
algorithm measurement chapter 
discussion information goes applications method benefit effort spent developing improved methods feature extraction 
say purpose feature extraction reduce amount data original image manageable proportions 
time important minimum possible amount useful information lost process 
look road matching examples fig 
representation line segments crude say 
particular curvature information largely lost roads broken arbitrary places 
stereo example fig 
edges time time broken wrong places 
sort effects represent degradation features puts corresponding burden matcher 
sha ullman deserves investigation respect 
wider range feature types examined including particular corners junctions 
feature quality feature extraction process useful possible assess quality features 
information improve assessment prior probabilities particularly null labelling improve measurement noise modelling 
improved evaluation labelling accuracy regarding algorithm system component important algorithm attempt indicate feature correspondences correct ones 
done examining fit matched features heuristic mean square approach reporting mismatch 
number null matches obtained mean support practice give useful information quality result 
rigorous approach preferable 
comparison performance methods discussed chapter different methods feature matching 
instructive compare performance method established methods particularly respect robustness computational complexity ability deal wide range applications 
bibliography ackley hinton sejnowski 
learning algorithm boltzmann machines 
cognitive science 
baird 
model image matching location 
mit press 
beveridge riseman 
hybrid weak perspective full perspective matching 
conference computer vision pattern recognition pages 
bhanu 
representation shape matching objects 
ieee trans 
pattern analysis machine intelligence 
bhanu faugeras 
shape matching dimensional objects 
ieee trans 
pattern analysis machine intelligence 
bienenstock 
neural graph matching techniques image processing 
anderson editor neural information processing systems pages 
addisonwesley 
blake 
disturbance principle weak constraints 
pattern recognition letters 
blake zisserman 
visual reconstruction 
mit press cambridge ma 
bolles 
robust feature matching maximal cliques 
proc 
soc 
photo opt 

april 
boyer kak 
structural stereopsis vision 
ieee trans 
pattern analysis machine intelligence 
cass 
polynomial time object recognition presence clutter occlusion uncertainty 
second european conference computer vision santa margherita ligure italy may pages 
springer verlag 
christmas kittler petrou 
matching computer vision contextual correspondence 
course preparation 
christmas kittler petrou 
matching computer vision probabilistic relaxation 
appear ieee trans 
pattern analysis machine intelligence 
bibliography christmas kittler petrou 
analytical approaches neural net architecture design 
pattern recognition practice iv netherlands 
christmas kittler petrou 
location objects cluttered scene probabilistic relaxation 
nd international workshop visual form capri italy 
christmas kittler petrou 
matching road segments probabilistic relaxation reducing computational requirements 
welch editors sensing imaging vision control guidance aerospace vehicles volume spie pages orlando florida usa 
christmas kittler petrou 
matching road segments probabilistic relaxation hierarchical approach 

chen editor neural stochastic methods image signal processing iii volume spie pages san diego california usa 
christmas kittler petrou 
non iterative contextual correspondence matching 

eklundh editor computer vision eccv volume ii pages stockholm sweden 
springer verlag 
christmas kittler petrou 
modelling compatibility coefficient distributions probabilistic feature labelling schemes 
accepted bmvc sixth british machine vision conference 
davis 
shape matching relaxation techniques 
ieee trans 
pattern analysis machine intelligence january 
deriche faugeras 
noisy edge points reconstruction scene robust approach uncertainty analysis 
johansen olsen editors theory applications image analysis volume series machine perception artificial intelligence pages aalborg denmark 
world scientific publ 
pte singapore 
faugeras 
improving consistency reducing ambiguity stochastic labeling optimization approach 
ieee trans 
pattern analysis machine intelligence april 
faugeras hebert 
representation recognition locating objects 
international journal robotics research 
fischler elschlager 
representation matching pictorial structures 
ieee transactions computers 
geiger girosi 
parallel deterministic algorithms mrf surface reconstruction 
ieee trans 
pattern analysis machine intelligence may 
geman geman 
stochastic relaxation gibbs distributions bayesian restoration images 
ieee trans 
pattern analysis machine intelligence 
bibliography wong au 
graph optimal monomorphism algorithms 
ieee trans 
systems man cybernetics april 
grimson lozano perez 
localizing overlapping parts searching interpretation tree 
ieee trans 
pattern analysis machine intelligence 
hancock kittler 
edge labelling dictionary relaxation 
ieee trans 
pattern analysis machine intelligence 
hancock kittler 
improved error criterion neural networks 
johansen olsen editors theory applications image analysis aalborg denmark 
series machine perception artificial intelligence vol 
hopfield 
neurons graded response collective computational properties state neurons 
proceedings national academic science volume pages usa 
hopfield tank 
neural computation decisions optimisation problems 
biol 
cybern 
hummel zucker 
foundations relaxation labeling processes 
ieee trans 
pattern analysis machine intelligence may 
kirby 
product rule relaxation method 

kirkpatrick vecchi 
optimisation simulated annealing 
science 
kittler 
relaxation methods neural net implementation 
wechsler editors statistics neural networks berlin 
springerverlag 
kittler christmas petrou 
probabilistic relaxation matching symbolic structures 
workshop structural syntactic pattern recognition pages bern switzerland 
kittler christmas petrou 
probabilistic relaxation matching problems computer vision 
proceedings fourth international conference computer vision pages berlin germany 
kittler 
compatibility support functions probabilistic relaxation 
cvgip pages 
kittler hancock 
combining evidence probabilistic relaxation 
international journal pattern recognition artificial intelligence 
koch yuille 
analog neuronal networks early vision 
proceedings national academic science volume pages usa 
li 
matching invariant translations rotations scale changes 
pattern recognition 
bibliography li kittler petrou 
automatic registration aerial photographs digitised maps 
optical engineering june 
peleg 
new probabilistic relaxation scheme 
ieee trans 
pattern analysis machine intelligence 
pelillo 
relaxation labeling processes travelling salesman problem 
proceedings international joint conference neural networks volume pages 
pelillo 
optimization algorithm determining compatibility coefficients relaxation labeling processes 
icpr volume pages 
pelillo 
learning compatibility coefficients relaxation labelling processes 
ieee trans 
pattern analysis machine intelligence 
petrou palmer christmas kittler 
robust skeletonization object recognition grey images 
nd international workshop visual form capri italy 

image sequence analysis relational structures 
pattern recognition 
rosenfeld hummel zucker 
scene labeling relaxation operations 
ieee trans 
systems man cybernetics june 
sha ullman 
structural saliency detection globally salient structures locally connected network 
international conference computer vision pages 
shapiro haralick 
structural description inexact matching 
ieee trans 
pattern analysis machine intelligence september 
fogelman soulie 
multi modular neural network architectures pattern recognition applications optical character recognition human face recognition 

stein medioni 
structural indexing efficient object recognition 
ieee trans 
pattern analysis machine intelligence 
petrou kittler 
foundations probabilistic relaxation product support 
course preparation 
petrou kittler 
probabilistic relaxation optimizer 
accepted bmvc sixth british machine vision conference 
ullman 
relaxation constraint optimization local process 
comp 
graph 
image proc 
vaidya boyer 
stereopsis image registration extended range features absence camera pose information 
conference computer vision pattern recognition 
bibliography 
philosophical foundations probability theory 
routledge kegan paul 
wells 
map model matching 
conference computer vision pattern recognition pages 
witkin terzopoulos kass 
signal matching scale space 
international journal computer vision 
yamamoto 
method deriving compatibility coefficients relaxation operators 
comp 
graph 
image proc 
yang snyder 
matching images models association graphs 
image vision computing 
zucker mohammed 
analysis probabilistic labeling process 
ieee conf 
chicago usa pages 
