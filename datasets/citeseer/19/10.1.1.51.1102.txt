causal discovery mml chris wallace kevin korb dai department computer science monash university clayton victoria australia korb bruce cs monash edu au february automating learning causal models sample data key step incorporating machine learning automation decision making reasoning uncertainty 
presents bayesian approach discovery causal models minimum message length mml method 
developed encoding search methods discovering linear causal models 
initial experimental results show mml induction approach recover causal models generated data quite accurate reflections original models results compare favorably tetrad ii program spirtes algorithm supplied prior temporal information mml 
keywords causal discovery minimum message length mml induction bayesian learning causal modeling inductive inference machine learning 
bayesian network technology despite decade old applied wide variety tasks involving reasoning uncertainty 
interest developed bayesian networks transferred learning bayesian networks natural known difficulties limitations knowledge acquisition techniques especially difficulties eliciting probability estimates domain experts :10.1.1.156.9918
networks plausibly understood cases describing causal structure physical phenomenon automation learning potentially tantamount automation scientific inductive practice promises substantial advance solving ai problem general frame problem particular 
social sciences developed course century battery statistical methods studying causal models social phenomena including factor analysis path analysis structural equation modeling 
causal models studied limited bayesian networks effect variables strictly additive linear functions exogenous variables 
significant limitation partially ameliorated various techniques converting non linear linear relations adoption allows comparatively easy environment develop test ai methods learning causal structure 
generality required ai methods learning arbitrary bayesian networks strongly suggests examining somewhat simpler general problems learning linear causal models 
despite centrality issues artificial intelligence substantial research program aimed automated learning linear causal models clark glymour spirtes carnegie mellon university underway past decade see 
approach shown successes leading commercially available program tetrad ii 
methods incorporating number principles judea pearl specifically call principles ii rely orthodox statistical techniques significance tests ignore prior probabilities candidate causal models 
report initial results investigation wallace minimum message length principle mml search evaluate linear causal models sample data including experimental comparisons tetrad ii 
linear causal model population ordered pair set random variables set direct causal relations pairs variables parameters specifying strength causal relation 
iff direct cause relative causal structures generally form directed acyclic graph dag cyclic graphs non recursive models studied 
limit dags 
current research explore induction linear causal models directly sample data incorporating background knowledge causal temporal relations random variables considered 
kind primitive unaided form induction hand necessary prerequisite sophisticated forms induction see hand easier set examine 
drawback experimenting primitive induction generally harder get useful results similar methods take commonly available human background knowledge account 
report significant initial successes example temporal ordering causal variables mml temporal information performing par tetrad ii temporal information 
start just unrefined set sample data recording joint measurements random variables times sample sample sample xn xn task find causal model highest posterior probability data set model mml produces model message reporting model sample data encoded model minimum length 
proceed presenting mml method causal induction 
describe techniques encoding causal models calculating message length causal models 
describes search strategies search space causal models 
describe various criteria evaluating algorithms recovering causal models including likelihood residual variance measures intuitive measure discovered causal structures report experiments run comparing mml performance tetrad ii criteria 
sketch natural extension report 
mml learning causal models key features mml discovery causal models measuring mml cost models requires invention efficient encoding method causal models sample data search space possible causal models 
features correspond directly distinction commonly studies scientific method context justification context discovery 
minimizing mml cost set causal models equivalent locating probable model posteriori set key step evaluating justifying causal theory bayesian methodology 
number models possible variables just number dags procedure estimating parameters sample data describe number grows exponentially number variables see 
variety biased discovery essential front evaluation step 
implemented greedy search favors local small changes current causal model minimizes mml cost local change mml cost partial model guide greedy search total space causal models 
encoding dag search best causal model mml need find efficient encoding method encoding dag provides unique code dag assigns shannon definition information plausible probability values 
information theory total length message reporting causal model gammalog gamma log djh djh gammalog cost number bits encoding causal model djh gammalog djh cost encoding sample data model 
sequel logs base natural logs written ln 
composed parts cost encoding causal structure dag cost encoding model parameters total cost encoding causal model djh djh developed successful ways encoding directed acyclic graph measuring formula assumes dag encoded specifying total ordering requiring logk 
bits specifying pairs nodes connected requires gamma bits assumption probability link corresponds maximal ignorance degree connectedness graph avoid explicit prior information causal models looking 
specify presence absence arcs orientations implied ordering provided 
ordering may consistent dag specifying particular ordering introduces coding inefficiencies multiple distinct messages reporting dag reduce hypothetical message length number bits needed select total orderings consistent dag total orderings known linear extensions dag 
log 
gamma gamma log unfortunately counting number linear extensions dag known nphard problem 
efficient means producing upper bound investigating provide estimate value calculate brute force understanding technique applicable modestly sized causal models 
dags length length message length simple dags second method calculating message length dag begins describing undirected graph costs gamma bits specifies particular direction arc assume results acyclic graph 
count number possible acyclic orientations ae yielding gamma log ae cost counting ae unfortunately exponential 
methods result mml costs close wide variety simple graph structures bit graphs expect choice encoding method little difference experimental results 
practice far implementation faster results reported employed method 
encoding parameters data message length encoding parameters data causal model complex determine 
examine case models dependent variable order illustrate message length calculated general case example variances subscripted ambiguity variables 
encoding method parameters yields encodings dag data mml cost fully specified model order estimate parameter values particular dag data find values minimize total mml cost 
section concerned find minimum values encoding estimating model 
assume model trying find nk variable means assumed zero oe oe fa kk unknown 
wallace freeman message length encoding parameters constant parameters lnf gamma ln parameters oe gamma jaj fisher information data matrix delta thetak assuming parameters normally distributed prior oe proportional oe parameters prior oe fa prior oe prior fa oe gammaa ff oe ff hyper parameter reflecting priori expected strength causal effects relative unexplained variation 
ln lnn gamma gamma ln gammaa ff oe gamma gamma ln gammaa ff oe ln gammak ln ff oe ln ln ff oe ln data random sample normal distribution likelihood function yj theta fa oe gamma oe yn gamma nk simplifying ignoring volume term see 
message length encoding data model djh fa oe gamma gamma ik oe ln oe combined message length encoding parameters data model djh ln oe ff ln minimize value examine partial derivatives respect oe djh oe oe gamma oe ff obtain estimate oe oe oe ff djh oe gammax ij ff oe gamma ij ff ff gamma ij letting ff ak delta delta delta xk yn 
theta square matrix ij thetak delta thetak theta unit matrix 
gamma solution parameter estimates gamma oe ff ff gamma ik adding conversion logs base produces total mml cost model relative input data 
search strategies results section available means calculate path coefficients causal model observational data means evaluate causal models data 
described effective means generating set models worth evaluating discovery step effective scientific induction 
know sample data set variables exponentially possible candidate models may fit data 
search space exhaustively tested variety biased heuristic search methods produced adequate results reasonable time moderately sized problems 
search methods employed seed model attempt improve model making local changes adopting new model represents improvement mml cost 
seed model may structure measured variables empty fully connected may may reflect prior user knowledge problem domain describe way automatically generating useful seed model employing prior knowledge 
search strategies tested greedy search best search random search 
third slightly outperform second search technique 
experimental results report technique adopted 
greedy search runs pair nodes arbitrary order attempting add arc direction delete reverse 
change effected mml cost goes relative current model 
loop continues node pairs 
looking pairs pass long change adopted pass 
search ends quiescence change improve mml cost model means program local global minimum model space 
results reported obtained lookahead improved addition 
best search iterates node pair single best change complete iteration mml relative improvements way 
frequently applications technique intuitively plausible tendency follow misleading paths resulted slightly inferior models 
random search takes node pairs random tests possible change causal relation improvement total mml cost 
continues number node pairs examined effect passes threshold 
technique performs comparably results report 
seed models algorithm assumes initial seed model available search starts 
seed model encode user best guesses causal connections variables giving algorithm initial bias search may greatly simplify finding optimal model method adopted heckerman bayesian network learning algorithm example 
stronger measures may taken stipulating certain causal connections occur acceptable model entail changes mml encoding methods search procedure 
search initial biases typically harder avoided far biases ground ability perform primitive induction remain necessary prior knowledge available reliable 
algorithm sensitive seed model empty seed models fully connected seed models obvious candidates avoiding informed prior bias performs fairly poorly 
adopted simple heuristic introducing useful initial causal connections seed model perform significance tests highest marginal sample correlations variables add arcs direction long result dag significance tests fail significance level 
evaluation test procedure tested mml tetrad ii identical conditions order get idea compare primary task causal structure underlying set observations 
located causal models social science literature claimed explain social phenomenon 
directly interested claims true simply models generate hypothetical sample data stochastically 
sample data generated postulated models true causal models task set mml tetrad ii simply induce models close possible true underlying causal models input sample data half runs tetrad ii sample data plus information temporal ordering variables 
statistical equivalence complicating factor search causal models explain sample data assessment algorithms performing search existence models diverse structures statistically equivalent causal models random variables skeletons undirected graphical structures differ orientations arcs precisely matching predictions joint measurement variables 
theorems utility understanding statistically equivalent structures theorem verma pearl causal structures statistically equivalent identical skeletons structures 
structures refer triples nodes subgraph nodes common effect parents adjacent 
chickering extended verma pearl criterion statistical equivalence converting topological criterion simpler apply theorem chickering causal structures statistically equivalent exists sequence covered arc reversals transforms 
covered arc nodes share parents excepting nodes question 
causal structures separated chain reversals arcs distinguished basis sample data apparent effectiveness algorithm finding way structures similar true model shows number times studies discounted result prior knowledge strengths orientations direct causal relations arcs apply tetrad ii cases explicitly indicate path models meaning variables standardized 
henceforth shall term causal structure refer model parameters specified causal model refer fully specified model 
prior knowledge result bias mml bias favor models linear extensions chance outcome taken favor algorithm 
way noticing effect statistical equivalence examine expected likelihoods models relative test data reported table 
chickering proves measures likelihood measures statistically equivalent models identical 
likelihoods calculated table course calculated fully specified models estimated parameters 
cases causal structures statistically equivalent estimated models expected vary slightly case blau duncan model 
evaluation criteria recovered models may assessed variety different measures adequacy 
intuitively induced causal model better arcs directions original model competitor fewer arcs occur original 
large ll leave intuitive assessments reader constructed simple measures appear capture intuitions error accuracy rates 
case believe clear mml performed quite particularly comparison tetrad ii provided prior temporal information 
evaluation measures report 
message length message length approximates minus log probability model data bayesian measure evaluating model 
mml search aims minimize value training data value relative data hardly fair basis comparison report mml cost relative test sample cases 
djh 
squared residual residual variance variable amount variance remaining effect predictor variables taken account 
function predictor variables perfectly predicts variable values remain variance predictions 
plausible way measuring predictive adequacy residual variance test cases 
residual measured fl ij number samples number variables ij pp 
gamma ax gamma bx path coefficient matrix discovered causal model unit matrix vector sample test data elements fu ij jk residual vector 

expected negative log likelihood likelihood model djh traditional measure goodness fit data entrenched primary means evaluating statistical models statistical practice maximum likelihood methods 
methods typically deal noise overfitting performance likelihood new test data model discovered distinct training data normally reveal overfitting 
tests running originating causal models hand better computing expected likelihood model comparing original model eliminating issue sampling error 
general best linear predictor variable new samples prior sample data linear regression variables overfitting maximally connected model best predictor principle originating model 
expected negative log likelihood measures effectively similar data sets generated original model recovered model djh ln tr gamma number variables true covariance matrix covariance matrix recovered model tr trace matrix sum diagonal elements 

squares measurement summing squared differences sample correlations correlations predicted causal model standard way calculating goodness fit models data 
minimizing value standard way estimating parameters models 
squares measurement evaluated ls ij gamma ij ij sample correlation value ij estimated correlation value derived model see 

error rate error rate intended capture intuition important part task causal discovery find dag close possible underlying model dag furthermore task discovery arcs generally significant discovery orientations particularly coefficients large magnitudes 
arc orientations statistically important alternative dags cases statistically equivalent true structures structure crucial spirtes principle ii 
error rate normalized function types error recovered model failure identify existing arc identifying non existent arc original model 
error rate recovered model defined ffi ffi ffi ffi number possible arcs original model number original model number links derived model original model number links absent derived model original model number misidentified structures 
ffi ffi ffi path coefficients links corresponding variety error ffi coefficient derived model cases original model 

algorithm accuracy rate accuracy rate recovered model simply gamma ffi 
report accuracy associated algorithm weighted accuracy models reported algorithm weight reflects posterior probability ranking model 
tetrad ii weight models mean accuracy weight taken inverse number models returned 
experimental results report experimental comparisons mml causal discovery tetrad ii causal path models reported causal modeling literature 
technique take model reported generate random sample data data input tetrad ii mml induction program 
intuitively causal induction program working perfectly reproduce exactly model generate data 
practice sampling errors result deviations original model sample sizes joint measurements study programs reproduce dag structure similar original secondarily coefficient values similar original considered performing better 
study compare discovered models terms criteria described 
tetrad ii estimate parameters done authors advise standard statistical techniques maximizing squares goodness fit criterion purpose 
tetrad ii run case default values 
originating causal model mml discovered model tetrad ii model discovered prior temporal information ordering variables partial order grouping variables tiers indicated case study tetrad ii model returned prior temporal information available 
blau duncan model blau duncan model stratification process model occupation 
variables interpreted introduced authors father education father occupation respondent occupation respondent education respondent current job true mml model returned 
intend return set probability weighted models 
parenthetical numbers refer temporal tier number supplied tetrad ii chronological information 
case tetrad ii run informed occur caused variable related temporally may cause case produced tetrad ii temporal constraints provided figures produced temporal constraints 
tables report scoring models evaluation criteria 
tetrad mml topology similar scores squares measurement reflects method tetrad ii parameters optimized course mml done temporal information 
temporal information tetrad ii gives models 
means tetrad ii unable select best model leaving user choose remaining models 
recovered causal structures statistically equivalent examination chickering criterion reveal 
original model mml induction tetrad ii tetrad ii tetrad ii tetrad ii tetrad ii tetrad ii tetrad ii blau duncan model evans model illustrates peter evans income inequality model ii models induced mml tetrad ii 
variables investment dependence capita gdp change service sector employment gini index income inequality introduced variable reflects tetrad ii temporal information figures produced temporal information provided tetrad ii unable decide models recovered structures statistically equivalent 
mml outperforming tetrad ii models likelihood 
measures tetrad ii outperforming mml slightly temporal information mml measure mml clearly outperforming tetrad ii denied temporal information 
original mml induction tetrad ii tetrad ii tetrad ii evans model model illustrates choe model fertility women models discovered mml tetrad ii generated sample data 
variables original model follows residence education age marriage fertility case produced tetrad ii temporal constraints provided temporal constraints tetrad ii produced structures statistically equivalent 
model developed mml temporal information 
case tetrad ii appears slightly outperforming mml search particular picking weak link variables 
interest coincidental fact model contains version simpson paradox 
original model combined effect causal links variables exactly direct effect variable leaving marginal correlation gamma 
follows original submodel consisting variables distinguished observational data submodel discovered models submodel fewer link remaining links directed inward variable nearly statistically equivalent original submodel 
notice tetrad likelihood original model general feature simpson paradox 
noted restricted form statistical equivalence treated chickering criterion depends exact parameter values concerns statistically equivalent causal structures statistical equivalence fully specified causal models 
mml cases prefer simpler submodel case tetrad ii likewise 
original mml tetrad ii tetrad ii fertility model goldberg model illustrates goldberg mediation model voter preferences 
variables father social characteristics respondent social characteristics father party identification respondent party identification respondent attitudes respondent vote reflects tetrad ii temporal information 
temporal information tetrad ii produced possible dags derived skeleton figures produced illustrative arc directions close original model possible far possible original model bracket performance additional tetrad models 
original model mml discovered model fig 
structurally identical 
clear mml model tetrad ii models 
original model mml induction tetrad ii tetrad ii tetrad ii goldberg model miller stokes model miller stokes model voting behavior congressional representatives shown 
variables original model follows district attitudes representative perception district attitudes representative attitudes representative behavior reflects tetrad ii performance temporal information temporal information tetrad ii discovered models 
recovered causal structures including mml statistically equivalent reflected identical expected log likelihoods 
original mml tetrad ii tetrad ii miller stokes model rodgers model rodgers model publishing productivity academic psychologists shown 
variables interpreted ability graduate school program quality quality job post phd publications pre phd publications citations sex mml tetrad ii prior temporal information rediscovered original causal structure temporal information tetrad ii produced substantially inferior structures statistically equivalent 
verbal mechanical abilities model illustrates model verbal mechanical ability described pp 

variables hypothetical having introduced factor analysis 
variables hypothetical factor hypothetical factor hypothetical factor verbal test verbal test mechanical test mechanical test mml rediscovered original dag 
tetrad ii temporal information recovered close original introducing spurious arc 
temporal information forced orientation arcs surprising result 
tetrad ii temporal information produced possible trees original skeleton figures 
tetrad ii relies primarily principle ii find arc orientations applies original model mml induction tetrad ii tetrad ii tetrad ii tetrad ii tetrad ii rodgers model original model mml induction tetrad ii tetrad ii tetrad ii tetrad ii tetrad ii tetrad ii tetrad ii tetrad ii verbal mechanical ability structure occur case tetrad unable resolve orientations 
reason mml resolved reproduced original structure simply original structure linear extensions alternatives lower mml cost see 
special merit trees statistically equivalent structures 
evaluation criteria report measures described models cases 
table shows accuracy rates mml tetrad ii temporal information tetrad prior table tetrad ii temporal information 
accuracy rates averaged cases mml tetrad prior information tetrad prior information 
blau evans goldberg miller rodgers verbal original mml tetrad tetrad tetrad tetrad tetrad tetrad tetrad tetrad table message length test data blau evans goldberg miller rodgers verbal original mml tetrad tetrad tetrad tetrad tetrad tetrad tetrad tetrad table expected negative log likelihood blau evans goldberg miller rodgers verbal original mml tetrad tetrad tetrad tetrad tetrad tetrad tetrad tetrad table squared residual measurement test data blau evans goldberg miller rodgers verbal original mml tetrad tetrad tetrad tetrad tetrad tetrad tetrad tetrad table squares measurement test data blau evans goldberg miller rodgers verbal mml tetrad tetrad tetrad tetrad tetrad tetrad tetrad tetrad table error rates derived models blau evans goldberg miller rodgers verbal mml tetrad prior tetrad prior table algorithm accuracy rates cases examined mml background information produced models structurally similar generating model 
furthermore evaluative criteria examined mml induced model generally tetrad ii model discovered prior temporal information generally better models discovered prior information 
particular statistical recovered causal structures somewhat obscures issue expected likelihoods mml preferred models clearly superior tetrad ii models produced prior information cases evans goldberg rodgers 
noted selected test cases favorable mml simply causal models tested selected reasons prominence literature small size variability structure 
take results significant confirmation path producing automated means learning causal models phenomena mml 
promises assistance scientists wishing causal modeling techniques understand data assess theories important particularly social sciences promises shed light nature enterprise artificial intelligence model scientific discovery 
clearly accomplished far encouraging preliminary 
bayesian mml methods provide means directly incorporating background knowledge temporal ordering variables prior probability distributions causal models employed information 
intend address issues extending methods deal various kinds non linear models search latent variable models 
shall examine different search strategies example incorporate experimental reasoning factor analysis analogical reasoning discovery process 
investigating gibbs sampling techniques provide faster approximative solutions 
research supported part arc appendix 
fisher information theta oe fa gamma logp xj theta gamma xj theta logp xj theta theta foe xj theta log oe oe oe gamma oe gamma nk oe gamma oe oe gamma nk oe gammax ni gamma oe ni oe ni nj oe gamma oe oe oe er oe oe gamma oe oe oe oe oe ni nj oe oe fi fi fi fi fi fi fi fi fi fi fi fi oe oe delta oe delta oe delta xk oe delta oe delta oe delta xk oe xk delta oe xk delta oe xk delta xk fi fi fi fi fi fi fi fi fi fi fi fi xn oe oe jaj oe gamma jaj jaj jx delta thetak appendix 
mml details miller models miller total total original mml induction tetrad tetrad length parameters 
length data model 
length dag 
table message length breakdown miller cases asher 
causal modeling 
sage publications beverly hills 
blau duncan 
american occupational structure 
wiley new york 
graham peter winkler 
counting linear extensions complete 
proc 
rd annual acm symposium theory computing new orleans la 
david chickering 
transformational characterization equivalent bayesian network structures 
proc 
th conference uncertainty artificial intelligence pages 
cooper herskovits 
bayesian method constructing bayesian belief networks databases 
proc 
th conference uncertainty ai 
morgan kaufmann 
daniel kahneman paul amos tversky 
judgment uncertainty heuristics biases 
cambridge 
duncan 
structural equation models 
academic press new york ny 
peter evans michael 
dependence inequality growth tertiary comparative analysis developed countries 
american sociological review august 
clark glymour richard scheines peter spirtes kevin kelly 
discovering causal structure artificial intelligence philosophy science statistical modeling 
academic press san diego 
harman 
modern factor analysis 
university chicago chicago third edition 
david heckerman dan geiger david chickering 
learning bayesian networks combination knowledge statistical data 
machine learning 
khachiyan 
conductance order markov chains 
technical report dcs tr computer science rutgers university 
kevin korb 
inductive learning defeasible inference 
journal experimental theoretical ai 
wai lam fahiem bacchus 
learning bayesian belief networks approach mdl principle 
computational intelligence 
john 
latent variable models factor path structural analysis 
lawrence erlbaum associates hillsdale new jersey second edition 
jack mcdonald 
algebraic properties action model moment structures 
british journal mathematical statistical psychology 
richard neapolitan 
probabilistic reasoning expert systems 
wiley new york 
oliver baxter 
mml bayesianism similarities differences 
technical report tr computer science monash university 
judea pearl 
probabilistic reasoning intelligent systems 
morgan kaufmann san mateo california 
hans reichenbach 
theory probability 
university california berkeley second edition 
rodgers 
causal models publishing productivity psychology 
journal applied psychology 
simpson 
interpretation interaction contingency tables 
journal royal statistical society series 
peter spirtes clark glymour richard scheines 
causality probability 
tiles mckee dean editors evolving knowledge natural science artificial intelligence london 
pitman 
peter spirtes clark glymour richard scheines 
causation prediction search 
springer verlag new york berlin 
peter spirtes clark glymour richard scheines meek 
tetrad ii tools causal modeling 
lawrence erlbaum hillsdale new jersey 
verma pearl 
equivalence synthesis causal models 
proceedings th conference uncertainty artificial intelligence pages boston ma 
morgan kaufmann 
chris wallace david boulton 
information measure classification 
computer journal 
chris wallace freeman 
estimation inference compact coding 
journal royal statistical society 
chris wallace michael georgeff 
general selection criterion inductive inference 
ecai advances artificial intelligence pages 
wright 
method path coefficients 
annals mathematical statistics 
