wait free algorithms heaps greg barnes dept computer science engineering fr university washington seattle wa february examines algorithms implement heaps shared memory multiprocessors 
natural model machines asynchronous parallel machine processors subject arbitrary delays 
machines desirable algorithms wait free meaning thread progress independent threads executing machine 
algorithm implement heaps 
algorithms similar general approach optimizations allow threads heap simultaneously guaranteeing strong serializability property 
interested designing efficient data structures algorithms shared memory multiprocessors 
processors machines may execute instructions varying rate due cache behavior example subject long delays swapped scheduler page fault 
programs executed collection threads processors 
may threads processors user view program running arbitrarily large collection mail address greg cs washington edu 
research supported nsf ccr 
processors subject arbitrary delays 
natural model capture behavior asynchronous parallel machine processors suffers delays length time 
model desirable algorithms wait free 
presents wait free algorithm manipulate heaps 
algorithm uses approach significantly different previous wait free algorithms concurrent objects 
previously known wait free algorithm manipulate heaps arises herlihy methodology implementing concurrent objects 
herlihy basic methodology requires thread check pointer object change copy object check object back 
thread changed pointer variable checked check fails thread start 
copying algorithm heaps efficient variant procedure copies log nodes operation entire heap 
algorithm achieves theoretical performance similar copying algorithm 
upper lower bounds asymptotically give similar serializability guarantees output 
approach different 
contrast copying algorithm algorithm maintains copy heap data structure 
threads complete heap operations making series small changes structure 
algorithm correctly necessary threads able detect complete incomplete series changes structure 
bershad describes similar idea implementing synchronization primitives machines support primitives 
approach offers advantages 
expect algorithm achieve better speedup copying algorithm 
copying algorithm complete entire heap operation algorithm allows new operation operation completed constant number steps 
second algorithm maintains random access nature heap storing array 
copying algorithm copies log nodes heap stored tree pointers 
third expect algorithm repeat spreads threads entire structure concentrating pointer 
certain pathological cases algorithm repeat copying algorithm threads section tree 
cases expect threads spread evenly descend tree 
contention unnecessary farther thread progresses away root 
approach offers hope efficient wait free implementations certain data structures 
known algorithm structures copying algorithm derived herlihy methodology difficult see copying algorithm linear array objects avoid copying entire structure 
algorithm similar desirable change portions object affected operation 
background previous typically concurrent access shared objects implemented critical sections guarded locks 
locks unattractive solution asynchronous models thread holding lock delayed indefinitely forcing threads wait lock released 
desirable algorithms non blocking guarantee thread complete operation finite number steps 
wait free algorithm special case non blocking algorithm guarantees threads complete finite number steps 
early wait free objects focused proving power various synchronization primitives 
herlihy unifies showing existence universal primitives compare swap implement wait free object 
load linked store conditional universal pair primitives similar compare swap herlihy describes methodology converting synchronous implementations data structure algorithms non blocking wait free implementations 
felten techniques improving performance herlihy protocol practice 
anderson woll compare swap design efficient asynchronous algorithms problem 
heaps implement priority queues 
researchers examined problem concurrent access priority queue structures skew trees trees trees 
existing algorithms locks control concurrent access structure 
herlihy provides previously known wait free implementation heaps 
basic methodology explained section copy object change try check new copy synchronization primitives test variable changed interim 
copying entire object time consuming herlihy suggests large objects programmer supply copying algorithm copies little structure possible 
heap stored tree pointers heap nodes copying algorithm need new copies log nodes operation nodes changed operation plus ancestors 
usually heaps stored array allowing random access elements see way copying algorithm maintain constant time access making new copy array operation 
algorithm uses load linked store conditional synchronization primitives 
load linked acts load instruction 
store conditional similar store instruction succeeds thread written variable load linked instruction 
store conditional returns boolean value indicating write succeeded failed 
load linked store conditional efficiently implemented cache coherent architecture supported mips ii architecture 
remainder organized follows 
discussion basic approach algorithm section 
section presents high level sketch algorithm section provides sketch proof correctness algorithm 
section discusses performance algorithm section conclude notes suggestions 
detailed presentation code proof correctness omitted 
approach heap balanced binary tree 
node tree associated key 
loss generality assume keys unique 
keys obey heap property parent key keys children 
insert operation adds key heap delete min operation removes minimum key heap 
herlihy explicitly algorithm describe algorithms heaps skew heaps algorithm easily derived 
algorithm stores heap array pointers nodes 
node record consisting key flags auxiliary variables 
load linked store conditional pointer record algorithm atomically check entire record 
similar strategy anderson woll union find algorithms 
standard heap algorithms delete min insert operations composed series suboperations new leaf added heap root key removed replaced key leaves series swaps performed restore heap property structure 
copying algorithm suboperations transparent threads performing operation individual threads execute suboperations local copies heap shared copy 
algorithm suboperations performed shared heap 
allowing multiple simultaneous changes data structure introduces interference problems 
consider depicting types problems arise multiple operations allowed heap 
shows incomplete operation 
threads begun delete min operations sifting keys tree delayed 
naively choose implement standard heap algorithms examine keys children notice key decide 
clearly wrong key belongs keys 
note similar situation arise threads try sift keys tree 
shows incomplete 
trying complete delete min operations time delayed middle swapping keys 
detect way knowing key swapped recover situation 
difficulties eliminated suboperations executed atomically incomplete suboperations occur incomplete operations trivial problem difficult handle 
example solve problem sufficient store flag node indicating key obeys heap property 
reads notice key may obey heap property realize sifting key 
simply wait move key farther delayed indefinite amount time 
algorithm executes swap 
ae oe ae oe ae oe ae oe ae oe ae oe ae oe ae oe ae oe ae oe ae oe ae oe potential problems multiple threads 
completed continue task 
unfortunately know suboperations atomic 
algorithm suboperations effectively atomic 
definition set variables changed say officially begun variable changed thread trying execute effectively atomic begun changes variable begins completed 
guaranteeing effective atomicity easier reason correctness algorithm begun completed 
guarantee effective atomicity algorithm uses strategy similar solve problem thread detects suboperations completed threads completes 
example solve problem stores new key node old key 
detect incomplete swap reading old key complete swap 
thread indicates incomplete marking variables changes 
marking variables helps delayed threads recover restarted 
arguing strategy sufficient necessary details algorithm 
algorithm section give high level sketch algorithms operations followed brief description main data structures important functions 
high level sketch simplify discussion assume atomicity suboperations 
algorithm supports operations heap delete min insert 
delete min takes argument pointer location minimum key heap stored 
insert takes key argument 
operation divided preliminary phase key added deleted structure sifting phase key longer obeys heap property preliminary phase sifted proper location 
preliminary phase executed time heap operation thread successfully change special record holds global variables associated heap including operation currently performing preliminary phase 
thread completes preliminary phase changes special variable operation begins sifting phase 
assuming encounters incomplete operations delete min operation proceeds standard heap algorithm 
preliminary phase consists steps highest active leaf tree marked inactive key leaf moved root old root key written desired location 
sifting phase new root key sifted tree repeatedly swapping lower valued key children reaches node key children keys 
insert operation key root leaf standard heap algorithm 
key stored leaf implicitly moved tree path root leaf 
assuming encounters incomplete operations preliminary phase new key stored lowest inactive leaf position pointer root 
pointer indicates current location key sifting phase 
root modified hold corresponding pointer leaf 
sifting phase leaf points ancestors 
time key leaf key ancestor pointing keys swapped 
appropriate pointers changed indicate key moved level sifting phase 
developed version algorithm mimics standard algorithm sifting inserted keys leaf sifting root allows clean serialization algorithm see section simplifies proof correctness somewhat keys sifted direction 
data structures functions algorithm uses main data structures heap status record stores global information heap heap entry record contains information node 
records contain usual heap variables extra variables flags indicate partially completed operations suboperations 
heap status record special variable mentioned section contains size heap information operation preliminary phase currently performed including value inserted insert operation memory location minimum key written delete min counter indicating number preliminary phases performed 
counter provides unique identifier operation 
mentioned heap stored array 
entry array pointer heap entry record contains key status field auxiliary variables 
status field enumerated type denote nodes sifted result delete min insert operations nodes swapped nodes associated uncompleted inactive leaves types auxiliary variables heap entry record variables hold old keys example recover swap problem variables point nodes sifting phase insert operation id variables store operation associated node 
id variables help delayed processes detect condition wake 
preliminary phase begun thread successfully change heap heap status record hold information operation 
thread loads record op field indicates preliminary phase progress thread completes phase changes record indicate heap free 
thread tries change status store conditional instruction hold information operation store conditional fails start 
note fair algorithm thread continually prevented operation timing particularly bad 
assuming finite number operations performed heap algorithm 
unbounded number operations algorithm written merely non blocking auxiliary scheduling scheme described herlihy solve problem 
difficult show process guarantees preliminary phase executed time 
important function algorithm fix 
thread calls fix attempting change node 
fix returns clean copy node examines node status finishes uncompleted associated 
correctness paragraphs sketch main ideas proof algorithm correctness 
key proving correctness algorithm prove guarantees effective atomicity suboperations 
key proving atomicity show incomplete detected changes variables begun detected difficult see thread finish begun thread data structures described section 
section argue effectively atomic suboperations algorithm performs sequential algorithm particular delete min operation gives minimum key heap 
assuming previous suboperations effectively atomic thread begins new trouble threads executing older suboperations 
old changes variables completed thread executing discover completed soon reads tries store conditional variable 
possible interference comes threads try suboperations begun 
mark variables changes guard interference threads operations suboperations follow basic patterns 
operations follow similar procedure root leaf changed key sifted tree 
suboperations preliminary phases operations swap sifting phase delete min implicit move sifting phase insert algorithm combines possible swap move 
suboperations operate similar set nodes ancestor node child ancestor descendants 
need guard possibilities thread comes thread changes leaf 
ancestor node guards ancestor marked sifting operations node status indicates incomplete operation preliminary phases ancestor root 
guard threads change leaves begins changing lowest descendant set variables changes 
descendant successfully changed thread tries new changes variables read ancestor descendant node begins able detect incomplete 
serializability operations standard notion correctness asynchronous parallel algorithms assume atomic instructions threads interleaved linear order algorithm correct behaves properly interleavings 
context proper behavior defined results delete min operations results delete min operations correspond serialization operations algorithm correct 
stronger assertion 
theorem op op operations performed algorithm heap order operations successfully execute preliminary phases 
results delete min operations asynchronous sequence results returned uniprocessor heap algorithm sequence operations theorem proved lemmas 
lemma clean node lower valued key clean descendants 
proof proceeds induction fact suboperations executed atomically property false true 
lemma delete min operation return minimum key tree 
proof sketch delete min calls fix get clean copy root 
fix returns possible currently uncompleted sifting phases completed root key deleted 
resulting tree key root hold keys nodes clean 
valid interleaving instructions lemma key root keys tree 
note lemma true inserted keys sifted leaves 
performance years researchers proposed different versions asynchronous pram including differing notions run time 
measure performance algorithm measure series papers fault tolerant prams 
done algorithm total number steps taken threads 
absence threads operation takes log maximum number nodes tree 
total amount perform operations log plus amount expended unnecessarily multiple threads threads trying perform operation time unsuccessful store conditional 
lemma gives upper bound performance algorithm including unnecessary 
lemma algorithm uses kp log perform heap operations maximum number nodes tree number threads 
proof sketch amortize charging done thread trying complete 
thread performs constant operation consists log suboperations total kp log 
unfortunately bound best implies speedup sequential case 
worse strong adversary impose ordering atomic operations threads bound tight 
lemma algorithm omega gamma kp log time perform heap operations 
scenario adversary force tree path root leaf nodes obey heap property 
omega gamma threads try fix root operate essentially lock step doing omega gamma log complete omega suboperations 
adversary recreate situation repeatedly yielding omega gamma kp log total 
bounds copying algorithm 
intuitively lower bound algorithms arises threads position tree time 
practice expect threads algorithm concentrate area tree spread evenly travel tree 
particular key sifted result delete min operation swap keys right child left child 
said insert sifting follows predefined path leaf successive insertions take place neighboring leaves 
true amount lost due interfering delete min operations decrease factor level node root half keys node sifted child keys sifted 
informally algorithms suffer contention root means algorithm spend factor log time copying algorithm lost due delete min operations 
expect algorithm greater speedup copying algorithm 
copying algorithm provides sequential access heap 
thread tries complete operation simultaneously succeed rest heap pointer changed 
algorithm multiple operations performed heap simultaneously 
preliminary phase operation completed new thread operation old thread performs sifting phase operation 
certain pathological cases may take omega gamma time operation 
practice expect algorithm behave near best case behavior constant time preliminary phase 
note constant time preliminary phase yield speedup constant optimal speedup log algorithm shows possible multiple asynchronous threads simultaneously perform wait free operations copy heap data structure 
important property algorithm suboperations effectively atomic 
obvious step code algorithm run real machine see performs practice particularly comparison copying algorithm 
tests run determine algorithm repeats due contention provides better speedup copying algorithm hypothesized section 
algorithm poses interesting theoretical practical questions 
lower bound section satisfactory 
nice show better bounds special cases 
anderson woll show union find data structure algorithms perform better threads choose request randomly large pool outstanding requests 
approach sufficient heap interference caused location tree thread works data request strategy change key positioned 
better strategy choose random leaf location performing insert operation move key random leaf root delete min operation 
strategy successive inserts longer necessarily operate part tree may possible arguments lost due multiple insert operations similar delete min operations section 
strategy devised want code see performs practice 
general approach algorithm useful devising wait free algorithms data structures 
similar algorithms devised objects support small number simple operations 
objects particularly linear nature approach yield efficient implementations obvious copying algorithm objects requires frequent copying entire structure algorithm similar change portions object affected operation 
objects copying algorithm efficient may prefer algorithm uses approach suffers contention provides better speedup 
richard anderson originally posed problem helpful listening ideas answering questions 
juan ed felten discussed pointed similar 
larry ruzzo simon kahan gave useful suggestions comments 
felten 
performance issues non blocking synchronization shared memory multiprocessors 
proceedings eleventh annual acm symposium principles distributed computing pages vancouver canada aug 
anderson woll 
wait free parallel algorithms problem 
technical report university washington 
see 
anderson woll 
wait free parallel algorithms problem 
proceedings third annual acm symposium theory computing pages new orleans la may 
barnes 
method implementing lock free shared data structures 
proceedings acm symposium parallel algorithms architectures pages germany june 
bayer 
concurrency operations trees 
acta informatica 
bershad 
mutual exclusion multiprocessors 
technical report cmu cs carnegie mellon university 
bershad 
practical considerations lock free concurrent objects 
technical report cmu cs carnegie mellon university 
biswas browne 
simultaneous update priority structures 
international conference parallel processing pages 
cole 
incorporating asynchrony pram model 
proceedings acm symposium parallel algorithms architectures pages santa fe nm june 
cole 
expected advantage asynchrony 
proceedings acm symposium parallel algorithms architectures pages crete greece june 
ford 
concurrency control mechanisms serializability concurrent tree algorithms 
proceedings third annual acm symposium principles database systems pages 
gibbons 
practical pram model 
proceedings acm symposium parallel algorithms architectures pages santa fe nm june 
guibas sedgewick 
dichromatic framework balanced trees 
th annual symposium foundations computer science pages ann arbor mi oct 
ieee 
herlihy 
methodology implementing highly concurrent data objects 
proceedings second annual acm sigplan symposium principles practices parallel programming pages mar 
herlihy 
methodology implementing highly concurrent data objects 
technical report crl dec cambridge research lab oct 
see 
herlihy 
wait free synchronization 
acm transactions programming languages systems 
herlihy wing 
axioms concurrent objects 
conference record fourteenth annual acm symposium principles programming languages pages munich west germany jan 
jones 
concurrent operations priority queues 
communications acm jan 
kanellakis shvartsman 
efficient parallel algorithms robust 
proceedings eighth annual acm symposium principles distributed computing pages edmonton alberta canada aug 
kedem spirakis 
efficient robust parallel computations 
proceedings second annual acm symposium theory computing pages baltimore md may 
lamport 
multiprocessor computer correctly executes multiprocessor programs 
ieee transactions computers 
lehman yao 
efficient locking concurrent operations trees 
acm transactions database systems dec 
martel park 
asynchronous prams synchronous prams 
proceedings st annual symposium foundations computer science pages st louis mo oct 
ieee 
mips computer 
mips risc architecture 
nishimura 
asynchronous shared memory parallel computation 
proceedings acm symposium parallel algorithms architectures pages crete greece july 
sagiv 
concurrent operations trees overtaking 
proceedings fourth annual acm symposium principles database systems pages jan 
