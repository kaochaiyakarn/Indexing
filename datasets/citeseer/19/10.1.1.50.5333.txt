class similarity viewpoint invariance recognition objects shimon edelman dept applied mathematics computer science weizmann institute science rehovot israel internet edelman wisdom weizmann ac il human vision processes representations involved identifying specific individuals frequently assumed different basic level classification classification largely viewpoint invariant identification 
assumption tested psychophysical experiments objective similarity stimuli consequently level distinction varied controlled fashion 
subjects trained discriminate classes computer generated objects resembling monkeys dogs 
classes defined set parameters encoded sizes shapes placement limbs ears interpolation parameter vectors class prototypes yielded shapes changed smoothly monkey dog 
class variation induced trial randomly perturbing parameters 
subjects reached correct performance fixed canonical view object discrimination performance tested novel views differed ffi training view 
experiment distribution parameters class unimodal experiment bimodal classes stimuli differed parametrically consisted geons parts recognized virtually independently viewpoint low similarity condition 
experiment prototypes differed complement geons subjects performance depended significantly viewpoint high similarity condition 
experiments higher inter stimulus similarity associated increase mean error rate ffi increase degree viewpoint dependence 
results suggest geon level difference stimuli strictly necessary sufficient viewpoint invariant performance 
standard characterization basic subordinate level processes visual recognition may need revision 
features recognition issue representation central importance recognition areas vision 
consequently development successful recognition schemes may aided progress finding objects object classes represented human vision 
theories recognition proposed different approaches representation problem 
prominent example structural description terms geons generalized cylinders representing object parts rbc recognition components scheme biederman 
alternative approach ullman basri poggio edelman calls representing objects small collections images 
shown recognition performed representations process interpolation stored images 
human vision representations identifying specific instances object classes called subordinate level frequently postulated different basic level classification 
hand demonstrated viewpoint dependency subordinate level recognition rock tarr pinker edelman bulthoff bulthoff edelman consistent theories hold visual system represents dimensional objects storing dimensional views 
developments computational vision especially new approaches model recognition ullman basri poggio edelman edelman poggio support possibility 
hand psychophysical findings basic level recognition point representation object prototypes symbolic manner example collections volumetric primitives components biederman 
visual system rely distinct sets representations processes subordinate basic levels recognition 
proposal edelman outlined possible unified approach recognition levels notion features recognition 
central tenet proposed account recognition normally requires reconstruction stimulus maintenance library models objects 
information sufficient recognition image locations object features 
choice features complexity may vary objects 
example recognized characteristic pattern scales 
main feature case textural distributed object surface 
comparison relevant features peanut texture characteristic outline 
consider complex example aircraft classified presence wings may considered complex features 
time image aircraft recognized fighter passenger jet basic features contour elements corners appropriately situated image vicinity locations corresponding features image prototypical aircraft 
highlights approach proposed edelman follows 
versatility recognition starts extraction large variety image features 

plasticity recognition procedure object category level synthesized need optimized practice 

hierarchy ways optimizing recognition performance involves formation compound features simpler ones subsequent reliance features 

invariance diagnosticity tradeoff features localized image frame 
exclusive reliance features certain circumstances recognition viewpoint dependent 
comparison features defined extended regions support viewpoint independent performance expense ability system discriminate members basic category differ local details 
predicted tradeoff viewpoint invariance feature diagnosticity degree discrimination object instances affords deserves clarification 
consider instance domain objects composed generalized cylinders polyhedra 
recognize objects visual system local features image plane positions object corners edges extended features patterns shading object surfaces 
types features general lead different performance 
pose object relative viewer changes projected locations corners shift 
shift compensated pose recovery model alignment ullman recognition unfamiliar views object poor 
comparison shape shaded patch principle extracted regardless pose object belongs long patch visible 
time pose fixed projected corners edges localized features offer better discrimination similar shapes shading cf 
bulthoff mallot 
human subjects difficulty recognizing novel views central characteristic performance tasks require discrimination members basic category bulthoff edelman edelman bulthoff 
objects classified basic level recognition performance depends viewpoint lesser extent biederman biederman 
observations suggest patterns performance emerge response different levels detail addressed subordinate basic level recognition 
true expect extent viewpoint invariance subjects performance affected manipulation relevant level detail determined inter object similarity 
reports experimental demonstration effect human subjects computational modeling analysis 
psychophysics experimental methods experiments designed demonstrate tradeoff viewpoint invariance discriminative power features subjects trained tell apart parameterized dimensional monkey dog objects see 
subjects shown succession isolated static images objects belonging classes discriminated pressing buttons computer mouse 
trial initiated displaying fixation aid center screen msec 
immediately stimulus image displayed msec followed mask image collection tapered cylinders size orientation location taper factor randomized anew trial 
subsequent trial followed msec subject response 
display interval short prevent subjects employing conscious discrimination strategy essentially non spatial features distinctive color viewpoint invariant perception little viewing geometry considered 
keep performance ceiling manipulation independent variables experiments opportunity discernible effect 
training objects appeared limited range attitudes sigma ffi fixed orientation corresponding roughly quarters frontal view defined palmer 

auditory feedback incorrect responses subject reached correct performance trailing trials 
point subject notified auditory signal testing stage 
testing feedback objects appeared attitudes differed training attitude rotation depth horizontal vertical axis 
subjects performance measured combined percentage correct positive responses objects 
measure performance non parametric affected subject bias possible responses green swets 
experiment experiment parameter distribution corresponding object classes unimodal parameter independent gaussian distribution standard deviation times mean value parameter 
main independent variable experiment distance centers distributions see top 
distributions closer second session subjects vice versa subjects 
mean response time sigma msec mean percentage correct responses cr sigma 
lack speed accuracy tradeoff signified negative correlation response time percent correct gamma 
multiple range duncan test cr means subject divided subjects non overlapping groups cr larger group subjects cr smaller group subjects 
data subjects poor performance group omitted subsequent consideration see section discussion 
mean cr deletion 
data subjected homogeneity slopes analysis variance anova sas glm procedure subject specified random class effect similarity fixed class effect stimulus relative training attitude continuous effect 
analysis revealed significant effects similarity interaction similarity theta 
main effect subject 

separate analyses levels similarity near far prototypes parameter space showed marginal effect far condition significant effect near condition 
linear regression analysis sas procedure reg revealed similar pattern different slopes similarity conditions 
regression far condition 
slope significantly different 
slope linear regression near condition effect subject near condition far condition 
interaction subject separated similarity levels estimated design 
gamma sigma regression significant 
figures support notion invariance discrimination tradeoff predicted features recognition theory 
experiment second experiment classes objects consisted subpopulations modes see bottom 
modes class gaussian standard deviation previous experiment 
distance means modes times distance points parameter space corresponded prototypical monkey dog 
modes situated appropriate point ones line parameter space connecting prototypes outside 
arrangement stimuli reported subjects difficult learn difficulty reflected longer training sessions possibly due bimodal distribution parameter values object class 
subjects participated experiment 
mean response time sigma msec mean percentage correct responses sigma 
lack speed accuracy tradeoff signified negative correlation response time percent correct gamma 
previous experiment data subjects mean cr grouped lowest performance interval duncan test discarded subjects 
performance remaining subjects function stimulus respect training attitude plotted 
plot cr vs inner mode near condition revealed knee ffi comparison leastsquares adjusted means produced glm procedure confirmed impression means ffi ffi ffi different means ffi ffi significantly different 
subsequent analysis carried ffi ffi decision discussed section 
analysis carried homogeneity slopes anova subject theta mode theta illustration levels mode see left panel glm procedure 
strong main effect significant subject theta mode interaction 
hint theta mode interaction prompted separate mode linear regression analysis 
regression results highly significant modes slopes respectively gamma sigma gamma sigma gamma sigma gamma sigma 
result shows dependence cr higher high similarity inner mode near condition conditions 
research holyoak showed subjects sensitive mean tendencies distributions stimulus parameters variability fried holyoak 
bimodal distributions initially treated unimodal leading impaired performance exemplars deemed outliers 
may take hundreds trials tacit assumption dropped 
experiment results experiments indicate necessary objects differ part geon structure obtain performance varies little viewpoint 
specifically performance obtained monkey dog stimuli provided sufficiently widely separated parameter space object classes exactly geons relationships respect 
experiment attempt show geon difference addition strictly necessary sufficient obtaining viewpoint invariant performance 
stimuli experiment versions monkey dog shapes modified separate contrasting features 
features obtained turning parts previously cylindrical ellipsoidal objects different geons 
example tapered cylinder monkey concave generalized cylinder dog convex 
entire set newly introduced contrasts objects distinguished merely presence absence image geon type 
degree contrast varied blending parameter ff instance convexity concavity generalized cylinders prominent 
closest separation times distance modes near modes distinct contrasts remained noticeable conditions 
subjects participated experiment 
mean response time sigma msec mean percentage correct responses sigma 
lack speed accuracy tradeoff signified lack positive correlation response time percent correct 
subjects rejected mean cr criterion employed analysis previous experiments 
shows plot cr vs remaining subjects 
curve near condition far condition revealed upward concavity subsequent analysis carried ffi ffi facilitate comparison linear trends conditions see discussion section 
homogeneity slopes glm analysis variance theta similarity theta subject showed significant main effect significant similarity theta subject interaction 
data pooled levels mode effects mode 
experiment indication possible theta similarity interaction separate similarity linear regression analysis carried 
slopes far near conditions respectively gamma sigma regression gamma sigma regression significant 
experiment dependence cr higher high similarity near condition 
discussion qualifications may drawn data section subject qualifications 
rejection data poorly performing subjects 
experimental session started training phase subject pass testing phase performance training images better 
rejection criterion data testing phase set mean correct rate allowed lower performance generalization novel views discarding data subjects sense failed learn task 
second qualification concerned range linear trends reported hold 
experiment range ffi ffi trends clearly discernible 
experiments interval ffi ffi separate consideration low high effects 
specifically linear trends experiments apparent ffi effects cr ffi may attributed onset different viewpoint dependence viewpoint invariance mechanism smaller values phenomenon warrants investigation preclude obtaining meaningful characterization human performance ffi summary psychophysical findings subject qualifications results experiments summarized follows ffl geon level difference stimuli necessary nearly viewpoint invariant performance stimuli experiments differed parametrically complement geons recognized relatively independently viewpoint far condition experiment 
ffl geon level difference stimuli sufficient achieving viewpoint invariance indicated significantly viewpoint dependent performance subjects near condition experiment 
ffl experiments increasing inter stimulus similarity affected characteristics recognition performance mean percentage correct responses cr deteriorated degree viewpoint dependence reflected slope regression cr stimulus orientation relative training increased slope negative 
altogether performance total subjects performance passed acceptance criterion described suggests standard characterization basic subordinate level processes visual recognition may need revision 
section describes computational simulations hint possible direction revision take 
simulations psychophysical data described dependence human recognition performance viewpoint varies inter stimulus similarity manner compatible predictions features recognition approach outlined section 
way gain computational understanding psychophysical results simulation experiments 
section presents simulation 
model replicate psychophysical experiments interpolating classifier represents objects collections views 
classifier radial basis functions interpolate stored views objects poggio edelman 
previous experience approach modeling subordinate level recognition objects positive see bulthoff edelman 
far problem representation individual views objects circumvented supplying classifier representations assumed computed separate mechanism 
step clarifying nature representation individual views preceding classification stage rbf model simple feature extraction stage investigating extent human performance recognition replicated resulting scheme 
transduction stage feature extraction method simulations chosen satisfy criteria 
method generic elaborate specific employing sophisticated available approaches feature extraction developed computer vision amounted forcing answer question features recognition 
second method computationally viable 
feature extraction convolution input image bank localized receptive fields rfs meets requirements commit entire simulation framework particular choice high level features record success modeling low level visual functions hyperacuity poggio higher level functions face recognition edelman 
related methods feature extraction proposed repeatedly past amari nishihara poggio koenderink edelman 
simulations described assumed individual rfs possess gaussian profile aspect ratio distributed uniformly 
density coverage input image rfs decreased center outward normal distribution 
separate simulations run values number rfs determines dimensionality representation passed subsequent classification stage 
typical arrangement rfs respect input image illustrated 
classification stage classification input represented vector activities transducer receptive fields performed radial basis function rbf classifier moody darken 
classifier trained images stimuli objects images taken range viewpoints training human subjects 
training images taken basis function centers classifier trained output images monkey gamma images dog 
classifier performance tested exactly images seen human subjects experiment 
outcome trial considered correct output classifier correct sign attempt model noise decision stage 
simulated experiment repeated different values parameter determined width oe basis functions 
values oe factor combined values number receptive fields transduction stage yielded fold replication simulated experiment 
results simulations means standard errors percentage correct responses classifier runs 
note simulation run consisted fact testing blocks preceded training stage just real experiments sessions separate training testing stage 
simulation results results simulations summarized 
comparison corresponding summary human data appears reveals similarities major discrepancies 
apparent similarities order performance levels different modes best outer mode far condition worst inner mode near condition slower deterioration performance outer mode far condition including ffi relative modes 
noticeable discrepancy absolute level performance floor human performance remained chance tested values model performance dropped chance ffi discussion simulated experiment described attempted replicate human performance real experiments simple stage model recognition transduction followed interpolating classification 
despite stronger sensitivity model viewpoint surprisingly stored images stimuli represented collections locally averaged intensity values objective specification stimuli intuitive description involved volumetric primitives 
may taken indication recognition human visual system relies extent view interpolation cf 
poggio edelman bulthoff edelman 
biederman may conjectured features combinations receptive fields signal presence collinear parallel contour segments lead better performance large exhibited simple model 
guidelines enhancing feature extraction ability model psychophysical data interactions spatial filters human vision sagi neurobiological evidence long range lateral connections primary visual area mammals gilbert katz callaway 
remains seen endowing stage model feature detectors enable perform chance large resorting elaborate multistage approach hummel implementation recognition components theory hummel biederman 
value oe computed follows 
mean separation vectors entire ensemble inputs computed value oe recommended saha keeler 
second oe set times studied interaction class similarity viewpoint dependence recognition 
intuitively expects increased sensitivity viewpoint discrimination highly similar objects distinguished paying attention small details change appearance occluded objects rotate space 
intuition major motivation development features recognition framework supported psychophysical results 
results clearly warrant 
open issues important stage contribution primary visual areas recognition full functional simulation stream primary visual areas mammalian cortex including spatial filters multiple scales wilson bergen log polar mapping contour completion von der heydt lateral interactions filters sagi edelman employed transduction stage model 
success resulting model signify certain tasks recognition may require little machinery available model second stage interpolating classifier implemented weighted sum receptive fields primary visual cortex 
structure psychological representation space modeling approach adopted assumed views objects represented points multidimensional metric space activities collection receptive fields 
psychophysical methods multidimensional scaling kruskal wish employed explore structure space 
psychology decision making recognition assumption identity input view decided comparison internally represented views variant nearest neighbor criterion 
relevant open questions concerned details decision criteria adopted human subjects influence learning stimulus parameters criteria 
specifically interesting determine feature vector new input compared explicitly represented decision surface constructed feature space representations previously encountered exemplars corresponding familiar views set prototypes stands class familiar objects nosofsky edelman maddox ashby 
computational analysis computational analysis possible sources observed orientation effects recognition appears appendix results stated indicate dependence performance stimulus orientation explained computational mechanisms single basis rbf preprocessor bayesian decision module conjunction nearest neighbor approach representation space 
address computational issues left open appendix explore ways distinguish possible explanations 
generalization results object classes lack software tools automatic generation object classes jointly parameterized isomorphic sets variables hampers extension results reported additional objects 
way technical difficulty may stimuli collections geon parts random configurations cf 
biederman 
random objects evolved controlled perturbation real objects approach help clarify role prior everyday exposure recognition process possibly demonstration object superiority effect harris real objects 
summary psychophysical results reported suggest viewpoint invariance characteristic basic level classification viewpoint dependence trait subordinate level recognition may closely related previously thought 
possibility varying degree viewpoint dependence subjects performance manipulating objective similarity stimuli indicates unified account recognition suggested section may feasible 
extent unified account may feature extraction coupled exemplar classification appears depend developments feature extraction methods simple approach taken simulations described 
acknowledgments irving biederman heinrich bulthoff nathan intrator yael moses tomaso poggio shimon ullman useful discussions goldberg programming assistance preparing appendix subjects psychophysical experiments time patience 
described supported basic research foundation administered israel academy arts sciences 
amari 

feature spaces admit detect invariant signal transformations 
proc 
th intl 
conf 
pattern recognition pages tokyo 
biederman 

recognition components theory human image understanding 
psychol 
review 
biederman 

recognizing depth rotated objects evidence conditions viewpoint invariance 
journal experimental psychology human perception performance 
press 
bulthoff edelman 

psychophysical support view interpolation theory object recognition 
proceedings national academy science 
bulthoff mallot 

interaction depth modules stereo shading 
journal optical society america 


local log polar frequency analysis striate cortex basis size orientation invariance 
rose dobson editors models visual cortex pages 
wiley new york ny 
edelman 

features recognition 
cs tr weizmann institute science 
edelman 

representing objects sets activities receptive fields 
cs tr weizmann institute science 
biol 
cybern 
press 
edelman 

representation similarity chorus prototypes 
cs tr weizmann institute science 
edelman bulthoff 

orientation dependence recognition familiar novel views objects 
vision research 
edelman poggio 

bringing grandmother back picture memorybased view object recognition 
int 
pattern recog 
artif 
intell 
edelman reisfeld yeshurun 

learning recognize faces examples 
sandini editor proc 
nd european conf 
computer vision lecture notes computer science volume pages 
springer verlag 
fried holyoak 

distributional expectations induction category structure 
journal experimental psychology learning memory cognition 
fried holyoak 

induction category distributions framework classification learning 
journal experimental psychology learning memory cognition 
gilbert 

neuronal synaptic organization cortex 
singer editors neurobiology neocortex pages 
wiley new york ny 
green swets 

signal detection theory psychophysics 
wiley new york 
hofstadter 


viking england 
hummel biederman 

dynamic binding neural network shape recognition 
psychological review 


identification disoriented objects dual systems theory 
mind language 
katz callaway 

development local circuits mammalian visual cortex 
ann 
rev neurosci 
knill kersten 

ideal perceptual observers computation psychophysics neural networks 
watt editor vision visual dysfunction volume chapter pages 
macmillan london 
kruskal wish 

multidimensional scaling 
sage beverly hills ca 
maddox ashby 

comparing decision bound exemplar models categorization 
perception psychophysics 
moody darken 

fast learning networks locally tuned processing units 
neural computation 
moses ullman 

limitations non model recognition schemes 
sandini editor proc 
nd european conf 
computer vision lecture notes computer science volume pages 
springer verlag 
nishihara poggio 

stereo vision robotics 
brady paul editors robotics research international symposium pages 
mit press cambridge ma 
nosofsky 

exemplar accounts relations classification recognition typicality 
journal experimental psychology learning memory cognition 
palmer rosch chase 

canonical perspective perception objects 
long baddeley editors attention performance ix pages 
erlbaum hillsdale nj 
poggio edelman 

network learns recognize dimensional objects 
nature 
poggio fahle edelman 

fast perceptual learning visual hyperacuity 
science 
sagi 

lateral interactions spatial channels suppression facilitation revealed lateral masking experiments 
vision research 
rock 

case viewer centered object perception 
cognitive psychology 
saha keeler 

algorithms better representation faster learning radial basis function networks 
touretzky editor neural information processing systems volume pages 
morgan kaufmann san mateo ca 
koenderink 

discrimination thresholds channel coded systems 
biological cybernetics 
snodgrass 

standardized set pictures norms name agreement image agreement familiarity visual complexity 
journal experimental psychology human learning memory 
tarr pinker 

mental rotation orientation dependence shape recognition 
cognitive psychology 
ullman 

aligning pictorial descriptions approach object recognition 
cognition 
ullman basri 

recognition linear combinations models 
ieee transactions pattern analysis machine intelligence 
von der heydt baumgartner 

illusory contours cortical neurons responses 
science 
weiss edelman 

representation receptive fields recognition 
cs tr weizmann institute science 
harris 

visual detection line segments object superiority effect 
science 
wilson bergen 

mechanism model threshold spatial vision 
vision research 
computational formulation invariance diagnosticity tradeoff tradeoff relative invariance respect viewing position supported choice features degree discrimination objects features allow predicted edelman possible manifestation unity mechanisms underlying basic subordinate level recognition 
section explore possible general approaches analysis tradeoff 
simplify analysis assumed individual views represented points decision mechanism variant nearest neighbor scheme 
distinct views object arbitrary view object denote action feature extraction stage vector valued function feature extraction process lead gain viewpoint invariance required jj metric nearest neighbor scheme 
time feature extraction lead increase object discriminability required jj generally feature space different dimensionality input space 
care taken distances feature extraction compared feature extraction may fall different ranges merely different dimensionalities 
section problem avoided normalizing distances comparison 
assuming views represented orthographic projections spatially localized features notion reachability projections objects defined moses ullman show requirements simultaneously satisfied views objects 
result weak practical significance useful find example conflicting requirements satisfied simultaneously average majority viewpoints 
tradeoff product rbf classification assume nearest neighbor classification stage preceded rbf preprocessor single gaussian basis function corresponding single stored view see 
case recognition rate views object improved merely increasing width oe basis function 
manipulation cause increase false alarm rate tendency classifier edelman poggio 
quantify effect respectively view stored rbf center test view object output basis unit number features object 
compare effect relative view distances computed rbf stage 
raw distance raw kv gamma kpx gamma pt ff feature vector view projection orthographic projection matrix ff transformation matrix corresponding rotation ff respect orientation 
distance rbf stage rbf gamma oe gamma oe gamma gamma gammap ff vr oe delta oe width gaussian basis function rbf stage 
note starts jffj asymptotes oe jffj 
asymptotic value rate change influenced oe 
assess influence numerically vertex objects consisting clouds unlabeled feature points created choosing coordinates feature independently randomly uniform probability density gamma interval 
objects plausible value oe set requiring jffj rbf jffj numerical solution equation yields oe 
estimate average effects object orientation ff distances raw computing appropriate partial derivatives integrating relevant range orientations say radians 
rbf ff oe ff dff oe ff dff raw draw ff oe ff dff raw oe ff dff numerical evaluation expressions chosen value oe yields raw average dependence training smaller dependence raw numerical results averages test objects 
changes oe affect viewpoint dependence system uses single center rbf preprocessor 
shows plot partial derivative rbf ff oe ff vs oe jffj 
observe chosen value oe viewpoint dependence system components ff euler angles encoding object orientation 
object relative arbitrary viewpoint measured single rotation axis orientation space defined importance object possesses intrinsic natural orientation due presence major axis symmetry 
single rotation denoted follows jffj 
method choosing oe average inter object distance mentioned section appropriate object assumed recognized separate module poggio edelman 
performance increases decrease oe 
recall value oe affects false alarm rate system assume system adapt changing conditions adjusting value 
false alarm rate grows due increased similarity objects transition far near conditions psychophysical experiments reduced decreasing value oe 
cause increase viewpoint dependence system performance similar psychophysical experiments 
tradeoff product decision making step invariance diagnosticity tradeoff may arise product decision making process 
deciding views produced feature vectors belong object significance difference feature vectors assessed 
factors supply significance judged intrinsic variability exemplars object classes differences classes 
note factors experiments reported kept constant 
second factor varied variation associated change percentage correct responses concomitant change degree viewpoint invariance 
preceding discussion may expected reducing distance object classes changes feature vector caused shift viewpoint relatively prominent psychophysical experiments 
situation analyzed ideal observer approach see knill kersten 
test view observer classify belonging object view object view assume observer decision say favor object likelihood ratio jv jv delta prior delta psychophysical experiments prior probabilities appearance objects need consider ratio probability obtaining view object divided probability obtaining view object 
assuming test view attributed observer object prototypical view closest compute oe dv oe dv evidence effect subjects assign exemplar category basis likelihood having generated category fried holyoak 
general treatment likelihood ratios contexts perceptual decisions see green swets 
oe standard deviation normally distributed noise parameter space represents effect object rotation region integration fv jv gamma jv gamma jg see 
note equation substituted monte carlo integration estimate dependence variance object appearance influenced dissimilarity object classes 
follows distinction factors influence object appearance parameter variation orientation 
reason factors modeled noise normally distributed std dev oe qualitative influence quantitative details irrelevant level analysis 
dissimilarity manipulated blending object prototypes psychophysical experiments see section 
ff blending parameter controls distance object prototypes gamma ff ff ff gamma ff definition ff prototypes original separation determined ff equal left shows plot likelihood ratio vs ff oe likelihood ratio large appears clipped plot small ff small oe decreases values parameters increase 
contour plot polynomial fit ff oe shows rate fall increasing oe higher high values ff 
influence factors contribute image appearance variability noise rotation grows prototype objects similar 
parameterization stimuli objects graphics tools study object representation features recognition framework see section predicted tradeoff discriminative power degree viewpoint invariance basic features object representation 
crucial component experimental demonstration tradeoff control similarity different stimuli 
control easily achieved wire stimuli edelman bulthoff 
wire objects belong basic category serve stimuli experiment address issue basic level classification 
smooth control shape possible complex objects appropriately parameterized cf 
hofstadter 
parameterization objects described points dimensional parameter space object blend defined ffx gamma ff ff blending constant 
linear combination convex ff blended object sense original ones 
allowing parameters vary randomly central values normal distribution moderate variance leads objects random variations central prototypical themes 
shows family images objects obtained procedure outlined psychophysical experiments 
classes objects resembling monkeys dogs snodgrass monkey dog belong separate basic level categories 
classes defined set parameters encoded sizes shapes placement limbs ears applying prototypical central members classes blending formula ff changing small steps caused resulting object change shape smoothly monkey dog 
list parameters creating object shapes illustrate parametric relationship object classes experiments monkey dog section lists names values parameters defined object prototypes 
parameter name monkey dog define size define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define define legends family images classes parameterized objects obtained blending procedure described appendix objects created rendered gl language silicon graphics gt workstation 
illustration shows class prototypes blended objects effects random perturbation parameters top object rotation bottom left 
relationships classes stimuli objects dimensional parameter space illustrated schematically dimensional 
top experiment controlled parameter distance near far distributions corresponding classes 
bottom experiments distributions bimodal modes fixed parameter space 
experiment 
left schematic illustration experimental conditions 
right percentage correct responses cr low high inter class similarity conditions far near modes upper lower curves respectively plotted vs angular distance training orientation means standard errors subjects 
experiment 
left schematic illustration experimental conditions 
right percentage correct responses cr experimental conditions top bottom curves outer inner modes low inter class similarity far conditions outer inner modes high inter class similarity near conditions 
abscissa represents angular distance training orientation 
data means standard errors subjects 
experiment left schematic illustration experimental conditions 
right percentage correct responses cr similarity conditions far upper curve near lower curve plotted vs angular distance training orientation 
see section details 
snapshot typical distribution receptive fields transduction step simulated experiment example receptive fields see section overlayed image stimuli monkey shown overlay image subjected edge detection presentation clarity 
simulation percentage correct responses inner outer subclasses experimental conditions low inter class similarity far curves marked high inter class similarity near curves marked 
abscissa represents angular distance training orientation 
data means standard errors runs see text 
compare 
nearest neighbor classifier preceded invariance module implemented rbf network 
section analyzes output simplified rbf module consisting single basis unit indicated illustration arrow 
generally output vector valued module linear combination vector activities basis units poggio edelman 
plot dependence performance viewpoint reflected value rbf ff ff oe 
dependence viewpoint seen increase decreasing oe chosen value oe relevant values jffj 
diagram decision situation experiment involves discrimination objects 
illustration purposes space images possible objects shown dimensional 
points corresponding images object prototypes denoted task experiment decide objects gave rise test image left likelihood ratio decision input view belongs object falls closer see plotted vs blending parameter ff measure variability object appearance oe data means pairs objects random objects simulations appendix 
point plot obtained sample monte carlo integration equations 
right contour plot rd degree bivariate polynomial fit ff oe 
oe density contours direction increasing oe grows ff 
image stimuli objects monkey 
cr deg cr deg cr deg alpha sigma da alpha sigma da alpha sigma alpha sigma alpha sigma 
