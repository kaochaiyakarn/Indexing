ijcai conference montreal august hybrid learning genetic algorithms decision trees pattern classification bala huang vafaie school information technology engineering george mason university fairfax va dejong wechsler department computer science george mason university fairfax va introduces hybrid learning methodology integrates genetic algorithms gas decision tree learning id order evolve optimal subsets discriminatory features robust pattern classification 
ga search space possible subsets large set candidate discrimination features 
feature subset id invoked produce decision tree 
classification performance decision tree unseen data measure fitness feature set turn ga evolve better feature sets 
ga id process iterates feature subset satisfactory classification performance 
experimental results illustrate feasibility approach difficult problems involving recognizing visual concepts satellite facial image data 
results show improved classification performance reduced description complexity compared standard methods feature selection 
pattern classification difficult fundamental task ai depends heavily particular choice features classifier 
usually starts set features attempts derive optimal subset features leading high classification performance 
standard approach involves ranking features candidate feature set criteria involving nd order statistics anova information theory measures infomax deleting lower ranked features 
ranking usually criteria measure effectiveness features selected actual classification task capture possible nonlinear interactions features 
provides specific answers problems raised describes hybrid learning approach optimal feature selection derivation robust pattern classifiers 
novel approach includes genetic algorithm ga tree induction system id minimizes number features classification simultaneously achieving improved classifications rates 
ga search space possible subsets large set candidate discrimination features 
feature subset id invoked produce decision tree 
classification performance decision tree unseen data measure fitness feature set turn ga evolve better feature sets 
ga id process iterates feature subset satisfactory classification performance 
experimental results illustrate feasibility approach difficult problems involving recognizing visual concepts satellite facial image data 
results show improved classification performance reduced description complexity compared standard methods feature selection 
background object pattern recognized classified possess number discriminatory properties features 
step recognition process performed machine human choose candidate discriminatory features evaluate usefulness 
feature selection pattern recognition involves derivation salient features raw input data order reduce amount data classification simultaneously provide enhanced discriminatory power 
number features needed successfully perform classification task depends discriminatory qualities selected features 
selection appropriate set features difficult tasks design pattern classification system 
lowest level raw feature data nice clean symbolic data green noisy sensor data spectral properties characteristics complex irregular 
addition considerable interaction low level features identified exploited 
typical number possible features large prohibit systematic exploration possible interaction types pairwise interactions 
large feature sets noisy numerical data provide considerable difficulty traditional symbolic inductive learning systems 
running time learning system accuracy complexity output rapidly fall acceptable level 
rationale approach belief michalski advances pattern analysis classification require integration various learning processes modular fashion 
learning systems employ strategies potentially offer significant advantages single strategy systems 
type input acquired knowledge flexible hybrid systems applied wider range problems 
examples integration include combinations genetic algorithms neural networks gruau whitley genetic algorithms rule systems bala vafaie de jong 
integration genetic algorithms inductive decision tree learning optimal feature selection pattern classification novel application approach topic 
selected id induction algorithms entropy information measure tree derivation 
entropy underlies infomax principle maximum information preservation successive processing layers 
self organization perceptual networks development receptive fields shown driven principle 
specifically linsker reported perceptual system develops recognize relevant features environment infomax principle 
integration genetic algorithms decision tree learning advocated part broader issue actively explored evolution learning synergistically hinton nowlan 
ability learn shown ease burden evolution 
evolution genotype learning get close goal phenotype learning fine tune behavior muhlenbein 
darwinian theory allow inheritance acquired characteristics lamarckian evolution learning acquired behaviors influence course evolution 
baldwin effect local search employed change fitness strings acquired improvements change genetic encoding individual active study whitley 
gain perspective lamarckian hypothesis moving individual chromosome agent ecosystems species addressing cultural evolution wechsler 
ga id hybrid learning basic idea hybrid system gas efficiently explore space possible subsets feature set order find feature subsets low order high discriminatory power 
order achieve goal felt fitness evaluation involve direct measures size classification performance measures ranking methods discussed previous section 
speed id suggested feasibility approach shown 
initial set features provided training set measured feature vectors extracted raw data corresponding examples concepts decision tree induced 
genetic algorithm ga explore space subsets feature set preference features sets achieve better classification performance smaller dimensionality feature sets 
selected feature subsets evaluated fitness measured testing decision tree produced id quinlan 
process iterated evolutionary lines best feature subset recommended actual design pattern classification system 
order ga efficiently search large spaces give careful thought representation chosen evaluation function 
case natural representation space possible subsets feature set fixed length binary string representation value ith gene indicates ith feature feature set included specified feature subset 
individual ga population consists fixed length binary string representing subset feature set 
advantage representation standard understood ga modification 
member current ga population represents competing feature subset evaluated provide fitness feedback evolutionary process 
achieved invoking id specified feature subset set feature subsets evaluation id genetic evolution population feature subsets feature extraction full feature set data evaluation measure feature subsets data raw data optimal feature subset data stopping criterion hybrid learning system genetic algorithms decision trees training data reduced include feature values specified features 
decision tree produced id tested classification accuracy set unseen evaluation data 
accuracy size feature subset ga fitness measure 
belief hybrid learning system identify significantly better feature subsets produced existing methods reasons 
exploiting power gas efficiently explore non linear interactions set features 
second id evaluation loop efficient mechanism directly measuring classification accuracy 
order test ideas implemented prototype version system 
ga component modification genesis grefenstette standard ga implementation 
similarly modification standard implementation id quinlan build decision trees evaluation procedure 
components standard default parameter settings literature 
ga module resulted constant population size crossover rate mutation rate pruning confidence level set default 
random generation datasets selection best dataset average performance runs selection best run set evaluation data training data data set learning data data set evaluation data training data runs ga id different seeds random generator final tree unseen testing data results runs ga id different seeds random generator setup ga id experiments experimental results initial set experiments performed assess performance hybrid ga id learning system 
subsets optimal features recognizing visual concepts satellite facial image data learned compared standard methods feature selection 
error rates unseen image data tree description complexity measured number nodes basis comparison 
order apply cross validation learning process learning data randomly shuffled generate sets 
set examples inducing decision trees evaluation learned description 
experiments performed set order find best average performance 
set produced best result lowest error rate selected training set 
tree generated best run set runs applied unseen test data 
results obtained ga id system compared sets results 
obtained features satellite date facial data 
generate second result set features reduced number produced ga id experiment 
reduction achieved independent ranking feature information theory entropy measure infomax estimate features discriminatory 
features lead greatest reduction estimated measure training examples chosen 
exact criterion choose feature vector values xv xv xv minimizes expression log log classes number examples class values xv number negative examples examples belonging class value xv experiments satellite data satellite image database consists multi spectral values pixels neighborhoods classification associated central pixel neighborhood 
aim predict classification multi spectral values 
sample database experiments class pixel coded number 
frame landsat mss imagery consists digital images scene different spectral bands 
visible region corresponding approximately green red regions visible spectrum near infra red 
pixel bit binary word corresponding black white 
spatial resolution pixel 
image contains pixels 
original data database experiments generated data purchased nasa australian center remote sensing 
frame imagery consists digital images scene different spectral bands 
visible region corresponding approximately green red regions visible spectrum near infra red 
pixel bit binary word corresponding black white 
example data corresponds square neighborhood pixels completely contained sub area contains pixel values spectral bands converted ascii pixels neighborhood number indicating classification label central pixel 
tables characterize data 
shows average performances evaluation sets runs ga id system 
table shows results ga id experiment corresponding performances set features ii set features reduced number obtained ga id experiment ranked entropy infomax measure 
characteristic description number examples learning set examples test set examples number features spectral bands pixels neighborhood features feature values feature value numerical range number classes decision classes table characteristics satellite data class name learning set testing set red soil cotton crop gray soil damp gray soil soil vegetation damp gray soil table number examples learning test sets satellite data full set features reduced feature set ga id system features reduced feature set feature ranking best features chosen error rate tree complexity error rate tree complexity error rate tree complexity nodes nodes nodes table experiment results satellite data st 
data set nd 
data set error trials average error rate runs satellite data sets experiments face data ability detect salient facial features important component face recognition system 
facial features available appears eyes play important role face recognition social interaction 
detecting eyes serves important role face normalization facilitates localization facial landmarks 
eye detection allows focus attention salient facial configurations filter structural noise achieve eventual face recognition 
purposes applied hybrid learning system accomplish feature selection eye detection problem 
eye nose facial region examples available learning eyes nose facial region examples test data experiments 
original eye image nose image image regions resolution column row pixels cut human face images pixels 
features produced example 
configuration features follows rules listed table table gives characteristics face data 
shows average performance evaluation sets runs ga id system 
table shows results ga id experiment corresponding performance set features ii set features reduced number obtained ga id experiment ranked entropy infomax measure 
represents graphically comparison various results obtained experiments 
satellite face data improvement recognition rate lower error rate observed sets features reduced ga id system 
method reduced tree complexity satellite data 
reduction complexity face data observed 
generated trees facial data fairly simple nodes 
number features reduced facial data satellite data 
features description obtained averaging window pixels overlap shift 
represent standard deviation window 
represent entropy window 
table configuration features characteristic description number examples learning set examples test set examples 
number features features 
feature values feature value numerical range 
number classes decision classes 
table characteristics facial data full feature set features reduced feature set ga id system features reduced feature set feature ranking best features chosen error rate tree complexity error rate tree complexity error rate tree complexity nodes nodes nodes table experimental results face data st 
data set nd 
data set error trials fi ure average error rate runs face data sets face data satellite data face data satellite data face data satellite data recognition error rates percentages description complexities expressed number nodes number features sets full feature set reduced independent ranking reduced ga id system comparison results introduced hybrid learning methodology integrates genetic algorithms gas decision tree learning id evolving optimal subsets discriminatory features robust pattern classification 
experimental results illustrate feasibility approach difficult problems involving recognizing visual concepts satellite facial image data 
results shown significant improvements classification performance reduced description complexity compared standard methods feature selection 
clearly needs done 
data sets quite complex comparison symbolic machine learning data sets modest image processing point view 
currently involved refining system described test larger complex problems 
interesting extension explored possibility additional feedback id concerning evaluation feature set 
currently classification accuracy returned 
potentially exploitable information respect features build decision tree relative positions tree 
acknowledgments army research laboratory arl partially supported huang wechsler daal face recognition 
eric bloedorn ali useful comments experiments bob explanations satellite data 
bala bala de jong multistrategy learning engineering data integrating inductive generalization genetic algorithms machine learning multistrategy approach vol 
iv michalski tecuci eds morgan kaufmann san mateo ca pp 

gruau whitley gruau whitley adding learning cellular development neural networks evolution baldwin effect evolutionary computation vol pp 

grefenstette grefenstette david genesis genetic algorithms system tsp ma 
hinton nowlan hinton nolan learning guide evolution complex systems vol pp 

linsker linsker self organization perceptual network computer vol 
pp 

michalski michalski inferential theory learning developing foundations multistrategy learning machine learning multistrategy approach vol 
iv michalski tecuci eds morgan kaufmann san mateo ca pp 

muhlenbein muhlenbein dynamics evolution learning 
genetic neural networks pfeifer fogelman soulie steels connectionism perspective elsevier science pp 

quinlan quinlan effect noise concept learning machine learning artificial intelligence approach michalski carbonell mitchell eds morgan kaufmann publishers san mateo ca pp 

vafaie de jong vafaie de jong improving rule induction system genetic algorithms machine learning multistrategy approach vol 
iv michalski tecuci eds morgan kaufmann san mateo ca pp 

wechsler wechsler perspective evolution lamarckian hypothesis artificial worlds genetic algorithms revue internationale de vol 
pp 

whitley whitley gordon mathias lamarckian evolution baldwin effect function optimization davidor schwefel manner eds parallel problem solving nature ppsn iii springer verlag pp 

