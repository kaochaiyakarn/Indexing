appear machine learning proceedings twelfth international conference ml fast effective rule induction william cohen bell laboratories mountain avenue murray hill nj research att com existing rule learning systems computationally expensive large noisy datasets 
evaluate proposed rule learning algorithm irep large diverse collection benchmark problems 
show irep extremely efficient frequently gives error rates higher rules 
propose number modifications resulting algorithm competitive rules respect error rates efficient large samples 
obtains error rates lower equivalent rules benchmark problems scales nearly linearly number training examples efficiently process noisy datasets containing hundreds thousands examples 
systems learn sets rules number desirable properties 
rule sets relatively easy people understand catlett rule learning systems outperform decision tree learners problems pagallo haussler quinlan weiss indurkhya rule sets natural familiar order version prolog predicates techniques learning propositional rule sets extended order case quinlan quinlan cameron jones certain types prior knowledge easily communicated rule learning systems cohen pazzani kibler weakness rule learning systems scale relatively poorly sample size particularly noisy data cohen prevalence large noisy datasets real world applications problem critical importance 
goal develop propositional rule learning algorithms perform efficiently large noisy datasets extend naturally order representations competitive generalization performance mature symbolic learning methods decision trees 
product effort algorithm competitive rules respect error rates scales nearly linearly number training examples efficiently process noisy datasets containing hundreds thousands examples 
previous complexity rule pruning techniques modern rule learners adapted decision tree learning 
widely decision tree learning systems overfit simplify learning strategy handle noisy data hypothesis formed growing complex tree overfits data simplifying pruning complex tree quinlan mingers usually pruning strategies improve error rates unseen data training data noisy quinlan mingers schaffer variety methods proposed prune trees effective technique reduced error pruning rep 
rep easily adapted rule learning systems pagallo haussler brunk pazzani rep rules training data split growing set pruning set initial rule set formed overfits growing set heuristic method 
rule set repeatedly simplified applying set pruning operators typical pruning operators delete single condition single rule 
stage simplification pruning operator chosen yields greatest reduction error pruning set 
simplification ends applying pruning operator increase error pruning set 
rep rules usually improve generalization performance noisy data pagallo haussler brunk pazzani weiss indurkhya cohen furnkranz widmer computationally expensive large datasets 
previous cohen showed rep requires time sufficiently noisy data fact initial phase overfitting training data requires time 
proposed alternative overfit simplify method called grow competitive rep respect error rates order magnitude faster set benchmark problems 
showed grow asymptotically faster rep random data assumes grow hypothesis approximately size target concept 
cameron jones showed grow systematically overfits target concept noisy data 
adverse effect grow time complexity result grow requires time asymptotically 
response inefficiency rep furnkranz widmer proposed novel learning algorithm called incremental reduced error pruning irep 
irep shown experimentally competitive rep grow respect error rates faster fact benchmark problems irep faster initial step overfitting data 
take point departure promising results obtained furnkranz widmer irep algorithm 
initial goal simply replicate results evaluate irep broader set benchmarks compare irep mature tree rule induction methods 
course doing discovered irep generalization performance considerably improved greatly affecting computational efficiency 
remainder describe implementation original irep algorithm give evidence affords room improvement 
outline modifications new metric guiding pruning phase new stopping condition technique optimizing rules learned irep 
taken modifications give generalization performance comparable rules quinlan large set diverse benchmarks 
modified learning algorithm scales number training examples 
current implementation efficiently handle training sets examples 
incremental reduced error pruning irep rule learning algorithm described detail furnkranz widmer summarize 
irep tightly integrates reduced error pruning separate conquer rule learning irep pos neg ruleset pos grow prune new rule split pos neg rule rule rule error rate rule exceeds return ruleset add rule ruleset remove examples covered rule pos neg endif endwhile return ruleset irep algorithm gorithm 
presents class version algorithm 
class boolean case rule simply conjunction features rule set dnf formula 
standard separate conquer algorithm irep builds rule set greedy fashion rule time 
rule examples covered rule positive negative deleted 
process repeated positive examples rule irep unacceptably large error rate 
order build rule irep uses strategy 
uncovered examples randomly partitioned subsets growing set pruning set implementation growing set contains examples 
rule grown 
implementation propositional version foil quinlan quinlan cameron jones begins empty conjunction conditions considers adding condition form nominal attribute legal value continuous variable value occurs training data 
repeatedly adds condition maximizes foil information gain criterion rule covers negative examples growing dataset 
growing rule rule immediately pruned 
prune rule implementation considers deleting final sequence conditions rule chooses deletion maximizes function rule gamma respectively total number examples number examples covered rule 
process repeated deletion improves value irep algorithm described class learning problems 
implementation handles multiple classes follows 
classes ordered 
experiments described ordering increasing order prevalence ordering prevalent class prevalent 
irep find rule set separates remaining classes done single call irep contains examples labeled contains examples labeled instances covered learned rule set removed dataset irep separate classes process repeated single class remains class default class 
extended rule learning algorithm handle missing attributes follows tests involving attribute defined fail instances value missing 
encourages learner separate positive examples tests known succeed 
differences widmer irep implementation differs furnkranz widmer details 
pruning rules implementation allows deletions final sequence conditions furnkranz widmer implementation allows deletions single final condition 
implementation stops adding rules rule set rule learned error rate greater furnkranz widmer implementation stops accuracy rule accuracy empty rule 
importantly implementation supports missing attributes numerical variables multiple furnkranz widmer described pruning algorithms 
called irep prunes equation stops 
second called irep prunes metric rule stops 
experiments confirmed furnkranz widmer irep generally outperforms irep discovered irep performance improved adopting irep stopping condition 
classes 
applicable wider range benchmark problems 
experiments irep experiments irep showed fast 
results representative artificial problem summarized graph cpu time needed rules shown 
results shown log log scale recall polynomials appear lines plot slope line indicating degree 
rules scales roughly cube number examples irep scales linearly 
extrapolating curves suggests require cpu years rules process example dataset irep handles cpu minutes 
artificial concept extremely large number training examples demonstrate issues similar performance issues arise natural datasets smaller graphs demonstrate 
graph shows curves kx kx log furnkranz widmer formal analysis irep predicts running time log number examples dataset contains fixed percentage classification noise 
results consistent prediction 
analysis similar furnkranz widmer predicts cubic behavior shown rules 
irep efficient experiments real world datasets showed generalization performance irep offered substantial room improvement 
compared irep rules diverse set benchmark problems summarized table 
test set associated benchmark indicated ran rules ran irep times averaged 
test set indicated ran different fold cross validations algorithms averaged results 
due space considerations focus comparisons rules learns rule sets performance rules datasets similar 
release quinlan version rules quinlan concept ab bcd irrelevant binary attributes classification noise uniformly distributed examples 
cpu time measured mips irix configured mhz processors gb memory 
irep randomized algorithm random partitioning examples curve irep average trials 
time rules ignores time needed run 
generally faster rules problem requires cpu seconds handle example dataset 
run time generally comparable irep 
sec min hr day month number examples ab bcd noise kx rules ripper irep number examples weather irep ripper rules number examples fire irep ripper rules cpu times rules irep ripper left hand graph contains point benchmark problem positioned irep error rate axis position rules error rate axis position 
points line irep performance inferior rules points line irep performance better 
graph readily see irep worse rules better specifically irep error rate higher times lower times times 
course may irep fact outperform rules converse problems test suite won lost tie ratio due random variation error estimates 
nonparametric sign test page determine probability observing ratio sided just irep chance rules problems test suite 
conclude confidence rules outperforms irep test suite 
evident graph irep seldom better rules infrequently worse 
obvious best aggregate measurements learning problems method consider average value ratio error rate irep error rate rules set problems average ratio precisely conclude rules outperforms irep sense problem drawn random test suite error rate measured described probability greater measured error rate rules lower irep 
table benchmark problems experiments size training testing sets number classes number nominal continuous attributes brief description 
starred problems uc irvine repository 
name train test classes attributes description ap gamma text categorization problems audiology gamma medical diagnosis bridges gamma mech 
engineering problems iris gamma flower classification labor gamma labor negotiations promoters gamma dna promoter sequences sonar gamma sonar signal classification ticket gamma text categorization problems ui gamma text speech subproblem coding dna coding sequences fire risk forest fires market market analysis mushroom random split mushroom data predict equipment failure predict equipment failure ocr image classification segment image analysis splice split dna splice junction data thyroid medical diagnosis decide game moves random voting congressional voting records weather weather prediction discounts single extreme outlier average irep error rates higher rules 
average includes mushroom dataset benchmark rules obtains error irep 
additional point ran propositional foil pruning mechanism 
ratio error rate hypothesis obtained overfitting data propositional foil error rate rules excluding mushroom dataset 
ran irep described furnkranz widmer irep furnkranz widmer stopping condition 
average ratio irep mushroom dataset 
irep restrictive furnkranz widmer stopping condition average ratio mushroom 
best tied record systems relative rules achieved propositional foil pruning 
summarize average irep variants performed substantially worse rules irep variants performed substantially better simply overfitting data 
evidence irep fails converge natural datasets 
example wellknown krk illegal problem muggleton quinlan encoded propositional version problem implemented data generator 
noise irep reliably learns approximate theory error rate examples irep improve error rate examples 
contrast rules reliably produces perfect theory examples 
artificial examples constructed show non convergence greater extent example irep obtains error examples concept 
behavior algorithm main strength efficiently handles large numbers examples 
improvements irep experiments irep implemented modifications algorithm alternative metric assessing value rules pruning phase irep new heuristic determining adding rules rule set postpass optimizes rule set attempt closely approximate conventional non incremental reduced error pruning 
propositional encoding constructed linus zeroski lavrac uniform distribution generate krk positions 
irep error irep rules ripper error ripper rules comparison generalization performances rules vs irep ripper 
rule value metric occasional failure irep converge number examples increases readily traced metric guide pruning equation 
preferences encoded metric highly unintuitive instance assuming fixed metric prefers rule covers positive examples negative examples rule covers examples negative example note highly predictive 
replaced irep metric rule gamma intuitively satisfying behavior 
stopping condition implementation irep stops greedily adding rules rule set rule constructed error exceeding pruning data 
heuristic stops soon moderate sized samples especially true learning concept containing low coverage rules 
assessment problem low coverage rules estimate error afforded pruning data high variance learning series small rules chance rules series error rate incorrectly assessed causing irep prematurely 
put way irep unduly sensitive small disjunct problem holte solution problem 
rule added total description length rule set examples computed 
new version irep stops adding rules description length bits larger smallest description length obtained far positive examples 
experiments 
rule set simplified examining rule turn starting rule added deleting rules reduce total description length 
revised rule value metric stopping heuristic substantially improve irep generalization performance 
original irep modified version irep henceforth irep converges artificial concept 
irep won lost tied record irep high confidence state irep outperforms irep problems test suite 
error ratio rules reduced including mushroom including mushroom 
irep won lost tied record rules 
briefly summarize mdl encoding scheme method encoding set examples theory latest version rules quinlan 
part encoding scheme allows identify subset elements known set elements log gamma log gamma bits known recipient message 
allow bits send rule conditions number possible conditions appear rule number bits needed send integer rules quinlan page estimated number bits required send theory multiplied adjust possible redundancy attributes 
rule optimization repeated grow simplify approach irep produce results quite different conventional non incremental reduced error pruning 
way possibly improve irep incremental approach postprocess rules produced irep closely approximate effect conventional reduced error pruning 
instance re prune rule minimize error complete rule set 
experimentation developed method optimizing rule set rule considered turn order learned 
rule alternative rules constructed 
replacement formed growing pruning rule pruning guided minimize error entire rule set pruning data 
revision formed analogously revision grown greedily adding conditions empty rule 
decision final theory include revised rule replacement rule original rule 
decision mdl heuristic 
optimization integrated irep follows 
irep obtain initial rule set 
rule set optimized described 
rules added cover remaining positive examples irep 
call algorithm ripper repeated incremental pruning produce error reduction 
optimization iterated optimizing rule set output ripper adding additional rules irep call algorithm ripper general algorithm repeatedly optimizes times 
generalization performance ripper improves generalization performance irep 
won lost tied record irep significant improvement 
error ratio rules reduced excluding mushroom error ratio irep ripper including mushroom error ratio irep ripper 
ripper won lost tied record rules 
additional stage optimization gives benefit 
ripper reduces error ratio rules excluding mushroom precisely variant evaluated inserting rule set deleting rules increase total description length rules examples 
total description length examples simplified rule set compare variants table summary generalization results won loss tied error ratio vs rules rules irep irep irep irep ripper ripper format datasets datasets mushroom mushroom weighting similar datasets 
furnkranz widmer stopping criterion 
described section 
including mushroom ripper won lost tied rules improved 
ripper statistically significantly better rules ripper certainly quite competitive problems test suite 
concrete probability ripper measured error rate equal rules problem taken random test suite 
won lost tied record means confident confident confident 
right hand graph gives detailed comparison error rates ripper rules table summarizes generalization results section 
problem averaging error ratios actual error rates small ratios tend extreme values 
reason reported averages mushroom dataset dataset actual error rates range ratios range remarks may help readers stability comparison ffl groups similar datasets weighted average ratio ripper rules 
mushroom excluded weighted average ratio 
ffl largest smallest ratios excluded average ratio ripper rules 
ratio mushroom extreme values 
ffl average difference ripper error rate rules error rate 
weighting similar datasets means ratios ap datasets bridges datasets ticket datasets network datasets averaged averaged ratios remaining datasets 
ffl won loss tied record ripper decision tree learner pruning 
average ratio ripper pruning mushroom 
efficiency importantly modifications described major effect computational efficiency 
shows ripper scales number examples concepts artificial concept larger noisier natural datasets test suite 
fact lines ripper irep parallel shows modifications introduced affect constant factors asymptotic complexity algorithm 
constant factors ripper reasonably low ripper requires cpu minutes process examples artificial concept 
quite space efficient requires data structures larger dataset 
previous cohen sought formal explanations efficiency inefficiencies rep rule pruning algorithms 
space permit analysis intuitions faster large noisy datasets 
basic strategy find ruleset models data irep find initial model iteratively improve model optimization procedure described 
process efficient building initial model efficient initial model tend large relative target concept optimization steps require time linear number examples size initial model 
rules constructs initial model iteratively improves 
rules initial model subset rules extracted unpruned decision tree improvement process greedily deletes adds single rules effort reduce description length 
rules repeats process different sized subsets total pool extracted rules uses best ruleset hypothesis subsets uses empty ruleset complete ruleset randomly chosen subsets rules 
unfortunately noisy datasets number rules extracted unpruned decision tree grows number examples 
means initial model save empty model size proportional sufficiently large initial models larger target hypothesis 
means build theory size target concept requires order changes initial model step optimization order changes possible 
improvement process expensive greedy search potentially quite finding best ruleset 
summary rules start initial model iteratively improve heuristic techniques 
large noisy datasets generally start initial model right size rules starts large initial model 
means search efficient 
conjecture search effective large noisy datasets 
ripper generally better compared rules larger datasets particular datasets examples average ratio ripper rules datasets examples average ratio ripper rules 
incremental reduced error pruning irep rule learning algorithm efficiently handle large noisy datasets 
experiments large collection benchmark problems extended implementation irep allows continuous variables multiple classes 
showed irep perform mature expensive rule learning algorithm rules 
proposed series improvements irep extremely competitive rules seriously affecting efficiency 
irep incorporates new metric guide rule pruning mdl heuristic determining rules learned 
adds iterations optimization step closely mimics effect non incremental reduced error pruning 
irep shown statistically clear improvements irep problems test suite 
ripper extremely competitive rules fact problems test suite ripper achieves error rates lower equivalent rules 
noisy datasets efficient rules 
scales nearly linearly number examples dataset contrast rules scales cube number examples 
asymptotic improvement translates speedups situation contrasted decision tree pruning large tree pruned efficiently certain senses optimally instance pruned tree lowest error pruning set linear time 
orders magnitude problems modest size examples ability effectively process datasets containing hundreds thousands noisy examples 
research conducted visit university sydney funded ross quinlan australian research council 
research benefitted substantially numerous helpful discussions ross quinlan nitin indurkhya members university sydney machine learning community 
author grateful valuable suggestions jason catlett comments jason catlett haym hirsh draft suggestions anonymous reviewers 
brunk pazzani clifford brunk michael pazzani 
noise tolerant relational concept learning algorithms 
proceedings eighth international workshop machine learning ithaca new york 
morgan kaufmann 
cameron jones michael cameron jones 
complexity cohen grow method 
unpublished manuscript 
catlett jason catlett 
test flight 
proceedings eighth international workshop machine learning ithaca new york 
morgan kaufmann 
cohen william cohen 
efficient pruning methods separate conquer rule learning systems 
proceedings th international joint conference artificial intelligence chambery france 
cohen william cohen 
grammatically biased learning learning logic programs explicit antecedent description language 
artificial intelligence 
dzeroski lavrac saso dzeroski nada lavrac 
learning relations noisy examples 
proceedings eighth international workshop machine learning ithaca new york 
morgan kaufmann 
furnkranz widmer johannes furnkranz gerhard widmer 
incremental reduced error pruning 
machine learning proceedings eleventh annual conference new brunswick new jersey 
morgan kaufmann 
holte robert holte acker bruce porter 
concept learning problem small disjuncts 
proceedings eleventh international joint conference artificial intelligence detroit michigan 
morgan kaufmann 
william richard dennis editors 
mathematical statistics applications 
duxbury press second edition 
mingers john mingers 
empirical comparison pruning methods decision tree induction 
machine learning 
muggleton stephen muggleton bain jean hayes michie donald michie 
experimental comparison human machine learning formalisms 
proceedings sixth international workshop machine learning ithaca new york 
morgan kaufmann 
pagallo haussler pagallo david haussler 
boolean feature discovery empirical learning 
machine learning 
pazzani kibler michael pazzani dennis kibler 
utility knowledge inductive learning 
machine learning 
quinlan cameron jones quinlan cameron jones 
foil midterm report 
pavel brazdil editor machine learning ecml vienna austria 
springer verlag 
lecture notes computer science 
quinlan ross quinlan 
simplifying decision trees 
international journal man machine studies 
quinlan ross quinlan 
learning logical definitions relations 
machine learning 
quinlan ross quinlan 
programs machine learning 
morgan kaufmann 
quinlan ross quinlan 
mdl categorical theories continued 
machine learning proceedings twelfth international conference lake california 
morgan kaufmann 
schaffer cullen schaffer 
sparse data effect overfitting avoidance decision tree induction 
proceedings tenth national conference artificial intelligence san jose california 
mit press 
weiss indurkhya weiss nitin indurkhya 
reduced complexity rule induction 
proceedings th international joint conference artificial intelligence sydney australia 
morgan kaufmann 
