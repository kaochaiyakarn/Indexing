mutation scheduling unified approach compiling fine grain parallelism steven alexandru nicolau department information computer science university california irvine ca 
trade offs code selection register allocation instruction scheduling inherently interdependent especially compiling fine grain parallel architectures 
conventional approach compiling machines arbitrarily separates phases decisions phase place unnecessary constraints remaining phases 
mutation scheduling attempts solve problem combining code selection register allocation instruction scheduling unified framework trade offs functional register memory bandwidth resources target architecture fly response changing resource constraints availability 
mutation scheduling ms unified compiler approach exploiting functional register memory bandwidth characteristics arbitrary single threaded fine grain parallel architectures vliw super scalar super pipelined 
ms value oriented approach instruction scheduling allows computation value change dynamically scheduling conform varying resource constraints availability 
generating code single threaded fine grain parallel architectures consists phases code selection register allocation instruction scheduling 
code selection refers deciding sequence machine operations compute value needed program 
register allocation determines values reside registers transferred memory register file 
instruction scheduling refers mapping selected operations appropriate functional units architecture order execution minimizes execution time preserving semantics original program 
conventional compilers perform phases separately decisions code selection register allocation unnecessarily constrain ability scheduling phase utilize available machine resources 
problem exists conventional pipelined architectures critical fine grain parallel machines 
example consider super scalar architecture consisting functional units adder shifter multiplier 
want generate value possible single operation code selections immediately obvious add mul 
code selection phase generally associate cost sum operation latencies possible code sequence choose smallest cost 
single operation sequences generally selected quickest reduction strength optimization pass forcing instruction scheduling phase assign operation shifter unit 
scheduling case shift appears languages compilers parallel computing springer verlag lncs series 
supported part nsf ccr onr 
unit committed computing operations point schedule units remains simultaneously idle 
context shift operation lowest code selection cost operations may appropriate 
similarly registers allocated prior scheduling spurious dependencies write write write read created prevent operations scheduled parallel 
mutation scheduling integrates code selection register allocation instruction scheduling phase attempt adapt program best fit physical characteristics target architecture 
ms works associating value val defined program set called mutations val functionally equivalent expressions computes val different resources target architecture 
time parallelization exactly expressions mutations val program graph compute val 
scheduling expression expr currently generates val resources expr unavailable expression mutation val better fits resources may substituted mutations val 
happens say val mutated 
mutations sets integrating register allocation scheduling process allowing mutations sets change dynamically scheduling contain new expressions may available value 
value val computed resides register register expressions mutations val 
val spilled home location memory expression load val home val added mutations val 
point scheduling val needed expression evaluation function applied choose mutations val best way accessing necessary re computing val 
register val mutations val register simply 
val regenerated scheduling expression mutations val 
allow register spilling insist operation expression store home val val load val home val member mutations val 
addition val spilled memory mutations val contain single operation expression load val home val 
mutations val may contain expressions capable re computing val data stored register file 
note expressions may simple semantically equivalent operations derived simple understanding target architecture complex esoteric operation sequences generated 
actual expression chosen mutations val regenerate val depends relative merits accessing memory versus re computing value turn depends functional register memory bandwidth availability time scheduling process 
related years number techniques developed extent redefine boundaries conventional separation code selection register allocation instruction scheduling concerns 
example instruction scheduling register allocation integrated 
techniques start initial register allocation scheduling compilers partially mitigate effect early register allocation removing spurious dependencies dynamic register renaming 
perform potentially expensive post scheduling register re allocation 
expression selected new mutation val instantiated entirety store load scheduled separately final locations store load generally adjacent instructions 
allocate unused registers dynamic renaming remove false dependencies 
techniques release allocated registers computations introducing spill code techniques full register allocation instruction scheduling fly including register spilling appropriate 
re materialization technique register allocation technique methods partially integrates code selection pertaining re generating needed values 
technique conventional register allocation phase performed live value needs removed register file operation originally computed value may re compute place spill code long doing worthwhile heuristics measure semantics preserving 
traditional compiler optimizations strength reduction common subexpression elimination cse exhibit similar trade offs code selection register allocation traditional compilers eliminate trade performing transformation prior register allocation 
incremental tree height reduction partially integrates code selection instruction scheduling 
thr known technique changing structure expressions exploiting associative distributive properties arithmetic logical operators 
incremental thr change fly dependencies encountered instruction level scheduling doing increase degree parallelism 
abovementioned techniques successfully performed techniques rely conventional separation concerns compiling fine grain parallel architectures collectively successes provide motivation mutation scheduling ms 
ms differs notably previous techniques unifies aspects code selection register allocation instruction scheduling single framework trade offs ms share similarities technique techniques ms attempts full register allocation conjunction instruction scheduling techniques ms follows paradigm starting initial register allocation modifying scheduling response changing resource availability 
re materialization ms allows code spill reload sequence regenerate value previously removed register file ms allows functionally equivalent computation choice including spill code depends relative merits respect current resource availability current point scheduling 
incremental thr technique ms allows code compute expressions change scheduling response changing resource dependencies greater generality functionally equivalent expression may substituted just derivable thr 
course previous techniques ms necessity depend heuristic guidance problems deals np hard 
ms advantage allowing single uniform heuristic provide trade offs code selection register allocation instruction scheduling unified framework 
framework heuristic aspects encapsulated away actual code trans techniques try eliminate spill code unnecessary result scheduling 
including derivable cse re materialization strength reduction complex sequences may derived programmer expert knowledge target architecture super optimizer 
formations problems easily tuned adjusting heuristics modifying code transformation algorithms 
value oriented tips ms schedules operations system parallelizing program transformations called percolation scheduling tips 
tips hierarchical extension percolation scheduling ps preserves completeness ps enabling non incremental transformations type hierarchical control flow graph called hierarchical task graph 
facilitate value oriented view ms augment structure slightly modified version static single assignment ssa form :10.1.1.100.6361
pure ssa form program reached exactly definition 
definitions multiple control paths needed special oe function inserted confluence control paths merges multiple values single definition 
ssa form variable name corresponds value defined 
time execution value defined oe function just oe function reached current control path 
unique name definition ssa form natural view variable value produced consumed dataflow sense definition uses 
reason ssa variables usually referred values 
simplicity exposition assume load store elements arrays structures represented access update operations defined terms dataflow treat element load store scalar read write entire array structure 
actual method compiler similar allows conservative handling ambiguous incremental updates ssa form 
issues involved handling ambiguous somewhat interesting context ssa form especially relevant ms discussed 
parallelizing transformations provided ssa enhanced tips essentially normal tips 
significant difference maintaining ssa form scheduling progresses 
order expose parallelism scheduling allow operations join point conditional move conditional duplicating true false branches 
operation op depends oe function join point conditional op control dependent conditional may define different values depending branch taken conditional 
op copied op branch say conditional op depends oe function replaced oe function reached similarly op defines variable copy op branch define new variable say respectively oe function oe replace op join point 
note op depend oe function join point op control dependent conditional identical copies op duplicated control path requiring new oe function slight structural relaxation true ssa form requires unique destination name textual occurrence operation fundamentally consistent intended meaning ssa form value unique name 
note relaxation allows multiple textual occurrences value occur re generating values released register file 
mutation scheduling section describes mutation scheduling 
mutations sets defined section 
techniques finding constructing multiple functionally equivalent mutations values discussed section 
section describes mutate transformation provides mechanism mutations sets integrating code selection register allocation scheduling process detailed section 
mutation sets conceptually view mutations set set arbitrarily long expressions computes value 
intermediate values defined expression may multiple expressions mutations represent expressions follows 
expressions computes val tree form consists leaf nodes interior nodes 
leaf corresponds constant value produced expression 
interior node corresponds operation uses values defined children tree defines value parent tree 
edges tree join operand operation interior node definition leaf destination operand operation 
root tree corresponds operation defines val 
tree form expression val represented system mutations sets storing operation op associated root tree mutations val creating new mutations sets sub expression rooted non leaf child associated op 
assume expression ssa form respect program expression may program new mutations sets created new values 
note set theoretic sense mutations val contains operations remainder say expression mutations val re constructed mutations sets reversing process starting operation mutations val root tree representation expressions similar value numbering representing multiple identical subexpressions single subexpression referenced multiple times directed acyclic graph represent multiple identical equivalence classes expressions mutations sets single equivalence class referenced multiple times value name 
finding expressions technique may generating initial set expressions stored mutations sets long abovementioned guidelines followed 
simple useful technique initialize mutations set value val defined operation op mutations val take transitive closure mutations set respect constructive functional equivalence relation defined follows 
expressions tree form true 
leaves set variables inputs 

operations associated roots define variable outputs 

valid assignments leaf variables values produced identical equivalence determined compiler constructive relation 
note definition says internal structure expression may arbitrarily complex simple 
instance thr yield large number functionally equivalent expressions may different numbers kinds operations addition different structure 
due finite precision computer arithmetic actual values produced run time may differ somewhat thr equivalent expressions 
differences significant application dependent 
rules step determine functional equivalence necessity incomplete due undecidability program equivalence problem target architecture simple important classes functional equivalence usually determined 
instance types functional equivalence generally lend constructive characterization architectures application domains synonyms restricted specific functions operations synonymous meanings 
instance performed architectures number ways assign add mul may require different resources may may different latencies depending particular architecture 
composition decomposition architectures offer specialized compound operations perform function multiple sequences operations 
possible change resource requirements latency computation composing sequence operations equivalent compound operation decomposing compound operation sequence operations 
instance processors designed digital signal processing applications offer single multiply accumulate mac operation performs computation decomposed operation sequence 
executing mac operation takes time decomposed pair operations mac operation typically requires multiply add functional units back back may possible particular point program operation scheduled units 
case multiply add units separately available decomposed sequence operations produce result sooner 
addition architectures intel provide general mechanism allows fairly arbitrary compositions operations executed functional units allowing operand address specify output functional unit fed directly input unit bypassing register access stages execution pipe 
type explicit bypassing feature complicated fact result functional unit usually available bypassing specific hot spot cycle recipient access value 
fortunately mutation scheduling provides trivial mechanism performing hot spot scheduling possible keep hot spot register register mutations expression value mutations set value 
point scheduling mutation value best utilizes available resources selected 
tree height reduction constant folding tree height reduction thr known technique changing structure expression tree form exploiting associative distributive properties arithmetic logical operations 
flattening tall thin expression trees shorter wider ones thr increases degree parallelism expression changes resource requirements 
similarly expression contains constant terms possible group constant terms operation thr 
allows operations involving constant terms performed statically compile time replaced new resulting constant 
process typically referred constant folding 
course thr constant folding performed result numerical instability application 
types functional equivalence combine mutations scheduling may cumulative effect performing conventional optimizations 
instance constant folding composition decomposition synonym mutations combine yield incremental form strength reduction 
types functional equivalence employed including esoteric tricks provided experienced assembly language programmer super optimizer 
simple types functional equivalences sufficient yield large number functionally equivalent expressions 
instance expression simple common address computation array exhibits forms functional equivalence 
row size element size address addr synonym composition decomposition thr closure represented mutations sets mutations addr mul addr addr log add addr mutations add mad mutations mul mutations mul mutations mul log assumes power typical arrays containing scalar values 
note mad operation mad meaning ignoring resource constraints expression mad addr log generally selected initial code selection best expression addr point scheduling computation produce addr sooner may mutations resources required operations unavailable 
example happen section 
mutate transformation core transformation ms mutate routine shown 
mutate responsible selecting scheduling best computation val scheduled path instructions described path template list tuples form node ops tuple contains instruction node set operations ops need added node order compute val list resource constraints resource constraints satisfied operations ops added node 
node functional resource constraints specify new operations may scheduled functional unit register constraints generally specify new register values may live register value value defined operation writes register opposed memory value defined operation store writes memory 
say value val allocated register val live register value target architecture hot spots treat hot spot register resource latch register exists cycle defined opposed normal register resources exist 
prevents mutate scheduling definition hot spot cycle prior hot spot value 
scheduling definition earlier cause register holding hot spot value cease exist causing number live hot spot values exceed number available hot spot registers hot spot allowed mutate transformation 
tuple path template list corresponds node actual definition val intended take place 
subsequent tuples represent function mutate val try shorter mutations 
jp realizable mutation val 
realize mutation val 
return true return false function procedure realize mutation val jp 
node isolate node insert ops node remove redundancies node update live info node procedure function realizable mutation val val live node return true op choose op mutations val ops satisfies resource constraints reads op live node jp reads op realizable mutation 
jp ops ops op return true val realizable forget subexpressions 
jp ops return false function fig 

mutate transformation path leading intermediate values needed computing val may realized 
say value val realizable respect path template val live node operation op mutations val scheduled node resource constraints resource constraints satisfied values read op realizable respect rest path template 

jp 
realizable mutation routine shown constructive version condition 
called mutate ops sets tuple path template empty 
realizable mutation searches realizable mutation ops sets filled operations needed compute realize val 
realizable mutation succeeds realize mutation inserts operations contained ops set tuple corresponding node removes redundancies created updates live information nodes affected 
affected nodes control path duplicated isolate effect new expression path specified notice mutate prefers shorter expressions longer ones maximum length expressions resources consume order mutations tried represent heuristics completely separate mutate transformation making mutate general transformation approaches instruction scheduling 
specific scheduling approach conjunction desired application domain cost vs performance trade offs dictate actual choices mutate heuristics 
target architecture supports conditional write back possible operations instruction produce value write back operation predicated condition write back negation condition 
case operations replaced single operation write back predicated condition negation 
mul mul add addr mul load load cc cc live 
live 
mutation mutation mutate addr 
add unit registers available add mul shift unit available fig 

mutate example shows application mutate transformation realize mutation value addr mutations set defined earlier 
recall best mutation addr absence resource constraints mad addr log 
realizable mutation return mutation shift unit assigned operation expression rooted mul addr considered expression realizable multiply unit busy 
leaves final operation mutations addr add addr 
operation satisfy ready execute uses live case path template includes tuple realizable mutation recursively try realize value realizable functional unit available mul register available hold entry candidate mutations mul log 
multiply unit virtually assigned computation operation realizable shift operation realizable shift unit available available register remains hold right side shows mutation addr realized mutate 
scheduling section details mutate transformation integrated existing global resource constrained percolation grip scheduler yield mutation scheduling system 
grip scheduling requires satisfiable resource constraints invariant code motion transformations 
grip operations progressively scheduled earlier ps tips transformations ranked order blocked resource constraints resource dependencies true data dependencies false data dependencies free registers available performing dynamic renaming 
mutation scheduling dependencies encountered opposed techniques ignore resource constraints scheduling satisfy resource estimates 
scheduling mutate attempt remove dependence 
operation defines val prevented scheduled earlier true data dependence functional resource dependence try find new mutation val scheduled earlier 
code motion blocked lack available registers mutate may free registers re generating values stored registers time 
procedure move val val op val live node writes reads op resources op get cont path mutate val return insert op op isolate delete op op update live info live regs live decrease reg pressure procedure procedure decrease reg pressure val choose reg val live get path val reads mutate val return procedure fig 

move val transformation move val routine shown incremental transformation responsible trying schedule definition value val currently defined operation op instruction instruction earlier 
relaxed ssa form allows multiple definitions variable long value defined possible definition val reaches val live 
happen definition val scheduled separately control path val previously defined control path leading kicked register file generating code including definition val re generate val 
case presence val live definition val exists indicates conditions originally required re definition val currently scheduled changed op simply deleted causing definition val reaches reach uses reached op 
facility extending live range previous definitions value provides trivial useful mechanism performing ps unify transformation undoing bad register allocation decisions eliminating regeneration code unnecessary due changing register pressure scheduling 
val live move val begins testing functional resource data dependence 
dependence exists current definition val simply scheduled 
dependence exist mutate tries realize mutation val 
get cont path function returns sake notational convenience describe ms context modifying incremental ps transformation move op non incremental counter part tips ms specific issues identical 
note val register value memory value hot spot values scheduled solely byproduct mutate transformation 
unify merges multiple definitions reached point scheduled separately different control paths 
path template path nodes computation val may take place 
resource constraints specified path template exceed maximum resources available specified path instructions may depending relative importance value mutated resources freed current mutation value new mutation scheduled earlier 
mutate fails realize val val currently movable suspended condition blocked movement changes 
definition val successfully scheduled possibly mutate effect movement isolated current path val scheduled 
multiple predecessors isolate inserts copy paths delete op called anyway deletes op copy predecessors 
delete op recursively delete definitions op 
op operation longer exists done 
live information updated reflect fact val values possibly ceased live 
turns number live register values exceeds actual number registers happen instance val register value register values ceased live decrease reg pressure called restore satisfiability register constraints 
decrease reg pressure applies selection criteria furthest choose register values live increasing order importance 
register value say unused realizable scheduled kill release register allocated longer live entry 
long selection criteria ensures register values candidates selection decrease reg pressure succeed restoring correct register utilization val realizable may selected register value release 
case delete previous definition killed new definition just scheduled 
repeated calls decrease reg pressure register file saturated cumulative effect deferring definitions values latest point useful 
results mutation scheduling adapts code resources target architecture making trade offs fly functional register memory bandwidth resources response changing constraints availability scheduling 
section results experiments different target architectures highlight important aspects trade offs 
focus register versus functional resource memory bandwidth trade offs second focus parallelism versus register functional resource trade offs third focus trade offs heterogeneous specialized functional units 
experiment compares speedup obtained mutating grip compiler outlined section set benchmarks obtained non mutating grip compiler 
presence absence mutation scheduling transformations difference compilers uses list scheduling heuristics rank order operation importance pipeline loops resource directed loop pipelining technique described recall length path represents maximum length expression actual mutation just operation 
note maximum path length sufficient exploit synonym composition decomposition thr mutations 
ratio sequential parallel cycles observed simulation 
rf speed bench size ms ms ll ll ll ll ll ll ll ll ll ll ll ll ll ll avg table 
trading functional units memory bandwidth registers speed bench ms ms ll ll ll ll ll ll ll ll ll ll ll ll ll ll avg table 
trading resources parallelism speed bench ms ms ll ll ll ll ll ll ll ll ll ll ll ll ll ll avg table 
trade offs heterogeneous specialized functional units 
works unrolling shifting loops scheduling expose operations parallelize resources fully utilized cost vs performance constraints satisfied 
experiments exact mutating non mutating compilers set benchmarks experiments differ characteristics target architectures specified 
experiments sections assume idealized vliw architectures homogeneous functional units 
simple architectures provide useful framework illustrating ability mutation scheduling general trade offs resources parallelism explicitly factor ability exploit unusual specialized features exist realistic architectures discussed separately section 
third experiment realistic hypothetical vliw architecture combines functional unit characteristics motorola superscalar explicit pipeline datapath control characteristics similar architectures intel 
model highlight ability mutation scheduling exploit trade offs heterogeneous functional units specialized architectural features 
experiments run livermore suite 
addition factoring distorting albeit interesting characteristics cache performance benchmarks small known results easily understood interpreted 
experiment detail 
registers vs functional units memory bandwidth experiment focus ability mutation scheduling decrease register pressure necessary exploiting unused functional resources memory bandwidth recompute spill reload values removed register file 
highlight ability compiled benchmark vliw homogeneous functional units minimal number registers 
benchmark define minimal number live registers allowed parallelization assumed register file size target architecture equal maximum number virtual registers live point initial sequential schedule produced gnu front register allocation disabled 
minimum number loop shifting refers unwinding loop head true successor predecessors exposing new operations subsequent iterations loop scheduling parallel existing operations 
registers target architecture need execute sequential schedule spilling registers 
allowing sequential schedule registers needs enable frontend produce best schedule respect conventional optimizations strength reduction common sub expression elimination factor sequential register allocation constraints resulting parallel code 
turn helps ensure speedups represent ability compiler parallelize initial schedules merely remove deficiencies poor ones 
table shows speed ups obtained compiling benchmark mutating version grip compiler versus non mutating version 
notice mutation worse cases strictly better non mutating version 
fact benchmarks mutation scheduling version provides fold improvement non mutating version 
compilers renaming remove false dependencies register register operations accomplished ssa form version capable performing sort register re allocation allowing code motion number live register values completed transformation exceed register file size 
improvements provided mutation scheduling come part ability release registers critical operations exploiting available functional memory bandwidth resources recompute spill reload values needed comes part ability select code decreases register requirements exploiting opportunities express computations terms values register file lieu introducing new intermediate values 
parallelism vs register functional resources showed ms improve performance register file heavily utilized trading registers available functional memory bandwidth resources 
experiment show architecture robust ms improve performance increasing parallelism expense increased resource consumption 
experiment assume vliw target architecture homogeneous functional units registers 
table shows speed ups obtained compiling mutating version grip obtained non mutating version 
compilers produce speed ups 
case non mutating version performs mutating version remaining cases mutating version produces significantly superior results improving speed 
functional units homogeneous register file large trade offs different functional units discussed section registers functional units section affect performance levels mutating compiler 
speed differences mutating version compiler non mutating version caused trade offs parallelism resources provided constant folding thr mutations defined section 
ll mutations performed thr increase resource consumption parallelism 
expressions involved mutations part critical dependence chain non mutating grip compiler able achieve greater increases parallelism just loop pipelining increases resource consumption 
sophisticated mutation heuristic choose thr mutations net increase resource consumption greatly decrease possibility ms degrade performance significantly inhibiting ability ms increase parallelism 
trade offs heterogeneous specialized functional units experiment focus ability mutation scheduling increase parallelism making trade offs heterogeneous functional units specialized architectural features 
target architecture hypothetical vliw machine combining functional unit characteristics motorola superscalar explicit instruction issue datapath control characteristics real world architectures 
model assume types functional unit alu units take cycle perform integer addition subtraction logical operations shift units take cycle perform shift operations units take cycles perform floating point addition subtraction operations mul units take cycles perform integer floating point multiply operations div units take cycles perform integer floating point divide operations mem units take cycles read cache cycle write cache cache misses stall processor branch units take cycles perform conditional branches 
exception branch unit arbitrarily defined take cycles functional unit kinds latencies roughly motorola superscalar 
experiment assume alu shift mul mem units div branch units just little functionality wide homogeneous vliw 
assume single register file registers 
terms control logic adopt approach similar respects 
vliw instruction specifies exactly possibly nop operation functional unit 
operation issued functional unit optional side effect pushing execution pipeline functional unit 
furthermore assume data paths set allow explicit register file bypassing allowing operand instruction address register output functional unit 
assume register fetch write back stages part pipeline functional unit explicitly bypassed mentioned take cycle bypassing latency fetch writeback operation greater execution latency functional unit executes operation 
table shows results obtained architecture 
mutating grip compilers perform mutating version consistently outperforms non mutating version 
note machine model essentially functional resources wide homogeneous vliw mutating grip compiler lesser extent non mutating grip compiler produce order magnitude speed ups sequential case 
indicative ability compiler especially mutating version effectively exploit spatial temporal pipeline parallelism target architecture 
main reasons large improvements mutation scheduling non mutating compiler target architecture ability mutation scheduling better utilization explicit register file bypassing 
interesting thing note times explicit register file bypassing degrade performance code locally decreases latency computation 
see consider bypassing register file floating point multiply add sequence 
decreases latency sequence total cycles improving utilization temporal parallelism 
loop pipelining scheduled operations different iterations parallel spatially case latency sequence sense cycles total fetch writeback latency operation 
mutation scheduling heuristics attempt handle trade operations explicit pipeline control proven difficult inconvenient compilers mutation scheduling provides fairly clean mechanism scheduling environment allows exploit benefits explicitly controlling pipeline 
context treat immediate fields instruction registers 
doing improve performance ll benchmark mutating version strictly better non mutating version example mutation heuristics exploited bypassing feature constrained performance loop 
emphasized currently simple mutation heuristics easily improved unfortunate reality dealing np hard problems resource constrained scheduling matter heuristics get cases perform sub optimally 

aho sethi ullman 
compilers principles techniques tools 
addison wesley reading ma 

berson gupta soffa 
resource framework integrating register allocation local global schedulers 
working conf 
par 
arch 
compilation techniques august 

eggers henry 
integrating register allocation instruction scheduling 
asplos april 

briggs cooper torczon 

pldi 

cytron ferrante 
name 
icpp pages august 

cytron ferrante rosen wegman zadeck 
efficiently computing static single assignment form control dependence graph 
toplas october 

ebcioglu 
design ideas vliw architecture sequential software 
ifip proceedings 

polychronopoulos 
automatic extraction functional parallelism ordinary programs 
march 

goodman hsu 
code scheduling register allocation large basic blocks 
ics july 

gupta soffa 
region scheduling approach detecting redistributing parallelism 
april 

kuck muraoka chen 
number operations simultaneously executable fortran programs resulting speedup 
toc december 

massalin 
look smallest program 
asplos 

moon ebcioglu 
efficient resource constrained global scheduling technique superscalar vliw processors 
micro portland december 

nakatani ebcioglu 
lookahead window compaction parallelizing compiler 
micro 

nicolau 
uniform parallelism exploitation ordinary programs 
icpp 

nicolau 
incremental tree height reduction high level synthesis 
dac san francisco ca june 

nicolau wang 
register allocation renaming impact parallelism 
lang 
compilers par 
comp 
springer verlag 

nicolau 
efficient global resource constrained technique exploiting instruction level parallelism 
icpp st charles il august 

nicolau 
hierarchical approach percolation scheduling 
technical report tr univ calif irvine 
appears proceedings international conference parallel processing st charles il august 

nicolau 
resource directed loop pipelining 
technical report univ calif irvine dept information computer science 


percolation compiling evaluation parallelism hardware design trade offs 
phd thesis univ calif irvine 

rau 
efficient code generation horizontal architectures compiler techniques architectural support 
symp 
comp 
arch 
april 
article processed macro package llncs style 
