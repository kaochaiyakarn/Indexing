robust cluster analysis mixtures multivariate distributions geoffrey mclachlan david peel department mathematics university queensland st lucia queensland australia 
normal mixture models increasingly way clustering sets continuous multivariate data 
provide probabilistic soft clustering data terms fitted posterior probabilities membership mixture components corresponding clusters 
outright hard clustering subsequently obtained assigning observation component highest fitted posterior probability belonging 
outliers data affect estimates parameters normal component densities implied clustering 
robust approach fit mixtures multivariate distributions longer tails normal components 
expectation maximization em algorithm fit mixtures distributions maximum likelihood 
application model provide robust approach clustering illustrated real data set 
demonstrated components provides extreme estimates posterior probabilities cluster membership 
finite mixtures distributions provided mathematical approach statistical modeling wide variety random phenomena mclachlan basford mclachlan 
usefulness extremely flexible method modelling finite mixture models continued receive increasing attention years practical theoretical point view 
multivariate data continuous nature attention focussed multivariate normal components computational convenience 
easily fitted iteratively maximum likelihood ml expectation maximization em algorithm dempster laird rubin mclachlan krishnan iterates step closed form 
applied problems tails normal distribution shorter required 
estimates component means covariance matrices affected observations atypical components normal mixture model fitted 
consider fitting mixtures multivariate distributions 
provides robust approach fitting normal mixture models observations atypical component reduced weight calculation parameters 
distribution provides longer tailed alternative normal distribution tends give extreme estimates posterior probabilities component membership 
useful application normal mixture models important field cluster analysis 
having sound mathematical basis approach confined production spherical clusters means type algorithms euclidean distance mahalanobis distance metric allows cluster correlations variables feature vector clustering methods defined solely term mahalanobis distance normal mixture clustering takes account normalizing term sigma gamma estimate multivariate normal density adopted component distribution corresponding ith cluster 
term important contribution case disparate group covariance matrices mclachlan chapter 
crude estimate cluster covariance matrix sigma suffices clustering purposes severely affected outliers 
highly desirable methods cluster analysis robust 
robustness meant method affected significantly small departures assumed model presence outliers 
problem providing protection outliers multivariate data difficult problem increases difficulty dimension data woodruff 
related problem making clustering algorithms robust received attention example mclachlan basford chapter de campbell dav krishnapuram krishnapuram rousseeuw kaufman zhuang 

past attempts modifying existing methods cluster analysis provide robust clustering procedures 
ad hoc nature 
mixture model provides sound mathematical basis robust method clustering 
shall illustrate usefulness context cluster analysis real data set 
normal mixture model xn denote observed dimensional random sample size normal mixture model approach drawing inferences data data point assumed realization random dimensional vector component normal mixture probability density function psi oe sigma mixing proportions nonnegative sum oe sigma denotes multivariate normal mean vector covariance matrix sigma psi gamma contains elements distinct elements sigma 
multivariate distribution consider multivariate normal oe sigma 
way broaden parametric family potential outliers adopt component normal mixture 
gamma ffl oe sigma sigma large ffl small representing small proportion observations relatively large variance 
huber subsequently considered general forms contamination normal distribution development robust estimators location parameter discussed section 
normal scale mixture model written oe sigma dh probability distribution places mass gamma ffl point mass ffl point suppose take distribution function chi squared random variable degrees freedom take random variable distributed gamma gamma ff fi density function ff fi ff fi ffi ff ff gamma gamma ff exp ff fi indicator function zero 
obtain distribution location parameter positive definite inner product matrix sigma degrees freedom sigma gamma sigmaj gamma gamma ffi sigma ffi sigma gamma sigma gamma gamma denotes mahalanobis squared distance sigma covariance matrix 
tends infinity converges probability marginally multivariate normal mean covariance matrix sigma family distributions provides heavy tailed alternative normal family mean covariance matrix equal scalar multiple sigma 
sequel generic symbol ml estimation mixtures distributions consider ml estimation component mixture distributions psi sigma psi gamma application em algorithm ml estimation case single component distribution described mclachlan krishnan sections 
results extended cover case component mixture multivariate distributions 
em framework observed data xn augmented component label vector defining component origin ij zero belongs belong ith component 
light characterization distribution convenient view observed data augmented incomplete introduce complete data vector additional missing data un defined ij ij sigma independently ij gamma un independently distributed 
follows th iteration step sigma updated ij ij ij ij sigma ij ij gamma gamma ij ij ffi sigma ij sigma psi current estimate posterior probability belongs ith component mixture 
seen sigma effectively chosen weighted squares estimation 
step updates weights ij step effectively chooses sigma weighted squares estimation 
updates parameters available closed form degrees freedom specified advance 
updated computed iteratively 
process speeded multicycle ecm algorithms liu rubin mclachlan krishnan section 
algorithm mclachlan 
fitting normal mixture models option fitting mixtures components 
clustering applications mixture models ml estimation component means robust sense observations large mahalanobis distances 
clearly seen form equation mle estimate specified decreases degree outlier increases 
finite jj jj 
effect ith component location parameter estimate goes zero effect ith component scale estimate remains bounded vanish 
course option manually excluding observations considered grossly atypical bulk data minimum covariance determinant criterion see example hawkins mclachlan 
seen mixtures distributions provides sound statistical basis formalizing implementing somewhat ad hoc approaches proposed past 
provides framework assessing degree robustness incorporated fitting mixture model specification estimation degrees freedom component 
example illustrate mixture model approach clustering consider crab data set campbell genus analysed ripley 
attention focussed sample blue crabs males females corresponding groups respectively 
specimen measurements width frontal lip fl rear width rw length midline cl maximum width cw body depth bd mm 
fig 
give scatter plot second third variates group origin noted 
hawkins simultaneous test multivariate normality equal covariance matrices suggests reasonable assume group conditional distributions normal common covariance matrix 
consistent sample linear discriminant function formed known classification data observations 
cluster data ignoring known classification data 
fit mixture normal components equal covariance matrices 
implied clusters consist cluster containing observations containing observations plus remaining observations clustering observations observations fitted mixture components common inner product matrix degrees freedom 
estimated parameters data 
inferred value 
mixture model solution produces slightly improved outright clustering fewer observation smaller sized cluster containing observations larger containing observations mixture model slightly improved outright clustering produce extreme probabilistic clustering observations 
demonstrate point listed estimates posterior probabilities membership group normal mixture models observations misclassified normal mixture model table 
seen mixture model results observation having estimated posterior probability belonging component mixture corresponding group greater 
observation longer misclassified outright clustering data 
remaining observations misclassified increased estimated posterior probabilities belonging particular estimated probabilities observations closer threshold value 
previous estimation components common way robust fitting normal mixture models undertaken estimates update component estimates step em algorithm mclachlan basford campbell 
case updated component means weights ij defined ij ij ij ij gamma sigma gamma gamma gamma gammas huber function defined sign appropriate choice tuning constant ith component covariance matrix sigma updated ij replaced ij ij alternative huber function function example hampel piecewise linear function 
problems forming posterior probabilities component membership 
question parametric family component mclachlan basford section 
possibility form corresponding function adopted 
case function finite rejection points corresponding campbell normal related univariate de density degrees freedom location scale component parameters estimated weighted median mean absolute deviation respectively 
seen mixtures distributions provides sound statistical basis formalizing implementing somewhat ad hoc approaches proposed past 
provides framework assessing degree robustness incorporated fitting mixture model specification estimation degrees freedom component 
campbell 

mixture models atypical values 
mathematical geology 
campbell 

multivariate study variation species rock crab genus 
australian journal zoology 
dav krishnapuram 

robust clustering methods unified view 
ieee transactions fuzzy systems 
dempster laird rubin 

maximum likelihood incomplete data em algorithm discussion 
journal royal statistical society 
de 

robust estimation normal mixture 
statistics probability letters 
krishnapuram 

robust algorithm automatic extraction unknown number clusters noisy data 
pattern recognition letters 
hawkins 

new test multivariate normality 
technometrics 
hampel 

robust estimation condensed partial survey 
verw 
gebiete 
hawkins mclachlan 

high breakdown linear discriminant analysis 
journal american statistical association 
huber 

robust estimation location parameter 
annals mathematical statistics 


robustness statistical pattern recognition 
dordrecht kluwer 
liu rubin 

ml estimation distribution em extensions ecm 
statistica sinica 
mclachlan 

discriminant analysis statistical pattern recognition 
new york wiley 
mclachlan 

finite mixture models 
new york wiley 
mclachlan basford 

mixture models inference applications clustering 
new york marcel dekker 
mclachlan krishnan 

em algorithm extensions 
new york wiley 
mclachlan peel basford adams 

algorithm automatic fitting testing normal mixture models 
unpublished manuscript 
ripley 

pattern recognition neural networks 
cambridge cambridge university press 
woodruff 

robust estimation multivariate location shape 
journal statistical planning inference 
rousseeuw kaufman 

fuzzy clustering scatter matrices 
computational statistics data analysis 
zhuang huang zhao 

gaussian density mixture modeling decomposition applications 
ieee transactions image processing 
article processed macro package llncs style table 
estimated posterior probability membership normal mixture normal mixture 
mixture 
mixture fig 

plot third versus second variate male female blue crabs ffi denotes male theta female 
