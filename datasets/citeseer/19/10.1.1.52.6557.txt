binocular visual tracking integration perception control alexandre jos santos victor instituto de sistemas rob instituto superior lisboa portugal isr ist utl pt presents active binocular tracking system including perceptual control points view 
perceptual part significant aspect space variant sensor geometry implementing focus attention center visual field favours tracking process 
simple fast low level vision algorithms employed allowing real time hz reliable performance 
control part developed visual servoing framework including kinematics dynamics system 
show certain assumptions kinematic relations system simple decoupled system dynamics expressed image feature space 
facts allow design simple dynamic controllers degree freedom directly image feature space properties 
system implemented medusa stereo head specific processing hardware 
results tracking experiments illustrate performance system different control strategies objects different shapes motions 
visual tracking problem decomposed major problems perception control 
perceptual problem deals estimation motion target objects environment vision sensors 
control problem addresses control tracking device estimated target motion 
visual servoing approach established formal way designing motor control scheme presence defined visual features target :10.1.1.47.8960
control strategies consider kinematic aspects robotic system neglect dynamics 
kinematic relations motion objects motion robot usually exhibit complicated highly coupled expressions 
system show tracking purposes possible obtain simple decoupled relations 
control system design consider system dynamics show expressed image feature space 
structured conditions objects constrained shapes motions move simple backgrounds visual servoing systems successfully employed 
complex dynamic environments restrictions kind objects motions systems lack robustness reactivity flexibility 
main cause comes perceptual problems instance extraction reliable partially funded project tpr 
image features apply visual servoing algorithms 
usual feature matching algorithms slow dependent environmental conditions illumination clutter size objects 
systems amount noise coming perceptual processes control scheme slow conservative filter noise sensors 
consider purposive design perceptual algorithms 
non standard computer vision techniques employed encouraging results 
common cartesian images exploit geometric properties log polar representation inspired non uniform resolution human retina 
computational performance improvements arise log polar images take advantage higher resolution image center 
furthermore feature matching algorithms rely lower level processes faster compute precise purposes 
cues supported large areas images improves robustness measurements 
correlation entire images centroid average flow computation simple techniques employed 
main ocular movements human visual system considered 
saccadic smooth pursuit vergence movements cooperate execution visual tasks 
saccadic smooth pursuit movements retinal position velocity errors respectively order compensate lateral motion target 
vergence movements mainly disparity cues compensate motion depth 
perceptual processes system designed estimate disparity retinal position velocity 
decomposition separate complementary movements leads simplification sensorimotor processes independently derived medusa stereo head 
section dedicated kinematics perspective visual servo systems 
tracking problem medusa stereo head 
fixation assumption stated allow decouple inputs stimuli outputs movements system 
section develop dynamic controller tracking system 
aspects robot dynamics considered show possible develop independent controllers joint system dynamics expressed image plane coordinates 
estimators target motion developed 
sections perception related aspects discussed 
emphasis space variant sensor geometry 
algorithms developed disparity motion detection described 
section show results tracking experiments real setup 
simulated targets step design visual loop controllers 
results show performance system real targets 
section draw envisage improvements 
kinematic visual servoing section start introducing visual servoing framework remaining terms notation basic assumptions 
emphasis eye hand visual servoing problem related particular application 
general results setup 
eye hand visual servoing problem usually stated minimization task function depends pose objects environment position attitude points lines surfaces pose cameras visual robotic system necessarily pose information represented cartesian coordinates position orientation usually means translation vector orientation matrix relative world coordinate frame sake generality assume pose parameterized generalized coordinate vectors target camera configuration spaces 
denote target pose camera pose gamma delta gamma delta respectively 
instance composed spherical coordinates represent position roll pitch yaw angles represent orientation 
vector composed parameters directly represent degrees freedom system joint angles displacements uniquely define cartesian pose cameras 
task function error function defined cartesian space configuration space feature space image coordinates 
choice sensitive system calibration errors provides simpler solutions 
case visual servoing problem stated minimization error function fl fl gamma fl fl image feature parameter vector represent position points orientation lines 
desired vector 
feature parameter vector gamma gamma delta delta gamma delta relative pose objects cameras projection mapping due imaging system 
feature sensitivity expected feature parameters change due changes robot configuration ffi actuate due changes object configuration ffi actuated 
linearizing operating point ffi gamma delta delta ffi gamma delta delta ffi image jacobian feature sensitivity matrices relating rate change features rate change robot configuration target configuration parameters gamma delta gamma gamma delta delta delta gamma delta gamma delta gamma gamma delta delta delta gamma delta target configuration parameters variations known reliably estimated suitable kinematic control solution ffi gammaj gamma delta ffi gamma delta ffi non square jacobians squares solutions obtained replacing inverse jacobian appropriate generalized inverses 
despite simplicity solutions solely kinematic considerations adequate high performance applications 
case robot target dynamics taken consideration 
target location determination computation jacobians requires current configuration parameters practical situations obtained robot internal encoder information estimated image feature information assume possible compute target configuration image features robot configuration call process forward visual kinematics gamma delta camera system general case possible obtain dimensional information position points space depth undetermined 
obtain dimensional information objects camera priori knowledge object structure 
forward visual kinematics usually requires precise calibration robot camera system sensitive modeling errors 
see visual tracking process computation avoided 
fixation assumption discussion assume desired feature vector chosen error function arbitrarily small values condition enforces kinematic constraint virtual linkage camera target poses 
equations constraint expressed configuration space gamma delta define fixation space set parameters gamma delta perfect tracking attained phi gamma gamma delta delta psi points belonging manifold called fixation points 
tracking situations expect near fixation manifold reason equation replace general jacobians jacobians fixation points result approximation ffi gamma theta gamma delta ffi theta gamma delta ffi gamma delta gamma delta particular application considered approximation brings substantial reduction computation complexity see 
medusa stereo head medusa stereo head binocular system degrees freedom designed replicate main motions performed human visual system 
revolution joints cameras neck pan tilt 
angular position joint denoted angles left camera right camera pan tilt represents mechanical structure stereo head shows configuration parameters world coordinate frame 
assume frontal vergence configurations gamma define configuration vector camera system gamma medusa stereo head 
robot configuration parameters world frame 
application concerned tracking point space keeping projected features center image planes 
target configuration parameters spherical coordinates see ae cos fl sin oe ae sin fl ae cos fl cos oe ae oe fl point pw gamma delta represented world coordinate frame 
define feature parameter vector target configuration parameters 
gamma projections target image planes 
relative pose relative position target camera coordinate transformation gamma delta gamma delta delta gamma delta gamma delta rotation matrix translation vector 
order compact notation define extended vectors coordinate transformation 
delta medusa stereo head introducing constraint frontal vergence gamma delta gammas gammas gammac gammac gamma delta gammac gamma delta gamma gammas gammas gamma gammas gammac gammas gamma delta abbreviations cos sin respectively represents distance left right cameras 
result equation gamma delta oe gamma oe gamma gamma oe gamma oe gamma oe gamma oe gamma gamma oe gamma gamma oe gamma oe gamma oe gamma pose jacobians assume complex form 
image formation perspective projection system gammax gammax feature parameter vector comes gamma gamma gamma projection jacobian gamma gamma gamma gamma gamma gamma observing equations see general situation feature sensitivity matrices complex structure 
practical reasons represented 
restrict analysis fixation subspace defined reasonable choice dealing tracking problems significantly simplifies form sensitivity matrices 
kinematics fixation tracking purposes intend keep target projection center images 
desired feature vector assumed initialization tracking process target projection center images 
target head configurations condition true fixation points 
tracking task consists keeping fixation condition despite target motion 
medusa stereo head fixation condition guides gamma delta delta cot approximation reduces target location determination problem simple stable computation 
fixation assumption pw gamma delta cot cot cot gamma delta derivatives equation gamma delta cot gammad cot dc gammad cot gammad cot gamma delta dc cot cot gammas dc cot cot dc gamma delta gamma gamma gamma equation sensitivity matrices fixation subspace gamma gammac gammas gammac observe jacobian matrices diagonal decoupling different stimuli motion parameters 
invertible conditioned practical situations cameras tilt angles bellow degrees see 
allows separate controllers kinematic visual servoing joint major advantage terms mathematic simplification computation time 
dynamic control section considered kinematics visual tracking problem 
kinematic controllers limited performance lack knowledge dynamics actuators mechanical structure robot 
section take consideration dynamical aspects include effect target motion system dynamic model 
see fixation assumption simplifies analysis system dynamics 
particular able represent system dynamics terms dynamics image features 
absence friction disturbances manipulator dynamic model written gamma delta gamma delta inertia matrix comprises gravitational terms 
mechanical design gravitational terms influential head dynamics inertia terms decoupled joint 
furthermore high geared joints velocity control motors effective linearizing axis dynamics eliminating load variation 
circumstances joint dynamics approximately second order model gamma delta delta time constant velocity command joint respectively 
considering joints gamma gamma delta gamma delta image visual servoing model little 
dynamic model expressed directly terms image feature vector 
achieve start considering case dim gamma delta dim gamma delta includes particular problem 
equation time derivatives multiplying gamma provided invertible get gamma gammaj gamma time differentiating ffi ffi represents high order terms considered external disturbances 
substitute equation equation obtain gammaj gamma gamma ffi substituting equation expression get gammaj gamma gamma gamma gamma gamma ffi dynamic model general time variant image jacobians depend particular head configuration change time 
fixation subspace matrix diagonal commute gamma get gamma gamma gamma gamma ffi define new control input represented image plane coordinates 
target motion redefined represents motion projection target image planes 
system dynamics gamma gamma gamma gamma ffi assuming fixation condition get second order linear approximation dynamics expressed image plane features 
way develop dynamic visual controllers directly image feature properties 
notice dynamics decoupled matrices diagonal 
separate controllers joint 
independent joint control motion estimation previous analysis linear second order dynamic representation system 
model control design state estimation follow known techniques optimal control estimation methods 
sequence consider smooth trajectories target assume local constant velocity model small accelerations 
equation term containing disregarded 
additionally dynamics decoupled define separate controllers joint 
gamma joint define state vector state space linear representation written delta delta delta delta observations observation noise vector 
gamma digital computer implementation interested designing discrete time controller 
discretization system dynamics leads phi delta gamma delta gamma delta delta phi gamma gamma exp gamma gamma delta delta exp gamma gamma delta gamma gamma gamma gamma exp gamma gamma delta delta gamma exp gamma gamma delta state space model compute regulator gains standard regulator design techniques control law gammak delta tracking problem target trajectories fed system 
target motion estimation provided systematic tracking errors occur simple trajectories 
problem define model target trajectory inadequate types target motion 
assume trajectories smooth small time interval considered linear 
providing sampling fast order acquire amount data strategy provide tracking performance types motion 
appropriate model image target motion discrete equivalent dynamics target motion estimation augment system model motion model phi gamma gamma delta model able estimate reconstruct state consisting state space structure phi delta gamma delta delta gamma delta lw delta gamma delta computation required estimator gains lw standard techniques state estimation state space representation described equations system model augmented target motion model 
note model regulator design 
obtained phi gamma system 
plan estimated value feedforward control scheme reduce errors 
presents block diagram full control system 
space variant sensor biological systems main reason ocular movements consists existence space variant resolution retina 
human visual system receptors retina distributed space increasing density center visual field fovea 
eye movements human oculomotor system point central high resolution fovea direction scene areas observe carefully 
apart exceptions active vision systems cartesian image representations 
system described log polar space variant image sampling 
advantages block diagram dynamic control system 
kind sampling important data reduction obtained cost reducing resolution periphery images high resolution fovea improve substantially performance tracking process shall see 
log polar transformation conformal mapping points cartesian plane points log polar plane 
mapping described log ae ae denote commonly polar coordinates 
log polar mapping exhibits singularity origin coordinate plane ae tends zero 
means mapping defined neighborhood origin log ae min log ae max ae max depends cartesian plane dimension 
shows discretized cartesian log polar planes 
min max log log max space variant mapping cartesian plane log polar plane 
tracking purposes important characteristic log polar sensor area objects center visual field highly increased relatively area periphery 
properties objects center dominant distracting elements background area algorithms 
works implicit focus attention area visual field target expected time center 
sensing algorithms section describe algorithms developed estimate disparity position motion target relative cameras 
disparity estimation traditional algorithms calculate disparity measures include cepstral filtering phase correlation 
techniques time consuming adequate real time applications 
furthermore cartesian images object interest smaller background background disparities lead erroneous estimates 
way overcome problem space variant geometry image representation areas belonging target dominant 
exploit correlation log polar images extract disparity cues 
correlation fast compute show technique easy adjust precision disparity estimation function available computation time 
correlation log polar domain correlation measures usually applied compute similarity measure images 
traditionally simplicity sum squared differences ssd ssd gamma digital images 
ssd value minimal similarity images maximal 
consider continuous form ssd ki gamma zz gamma dx dy function interpreted giving distance space continuous images usual norm 
theorem continuous form correlation measure allow derive important relation correlation computed cartesian images non uniform resolution images 
theorem correlation non uniform resolution images 
consider non uniform resolution images obtained cartesian images differentiable mapping 
jjj jacobian correlation operator defined equation 
correlation non uniform resolution images related correlation cartesian images jjj jjj demonstration zz gamma dw dz applying coordinate change comes zz gamma jj dx dy zz jj gamma jj dx dy jjj jjj theorem shows correlation value non uniform resolution images corresponds correlation cartesian images weighted square root jacobian coordinate change 
corollary result theorem log polar mapping 
corollary correlation log polar images 
consider images obtained cartesian images log polar mapping 
correlation operator defined 
result applies ae ae ae demonstration excluding center image log polar mapping differentiable jacobian jj fi fi fi fi fi fi fi fi fi fi fi fi fi fi fi fi fi fi fi fi square root jj theorem corollary statement true 
result see correlation log polar images correlation weighted cartesian images weighting window inverse distance center image 
spatial window represented graphically 
observe high weight areas close center image implements direct focus attention areas 
algorithm define discrete correlation function corr ssd gamma weighting window corresponding correlation log polar images 
center truncated due mapping singularity 
formula valid cartesian images shows correlation process consists translating horizontally images computing ssd translated images 
log polar images horizontal translation replaced equivalent complicated warping 
dominant horizontal disparity images expect correlation function minimum algorithm search maximum similarity search horizontal disparity correlation function minimal 
search possible disparities probably take computation time 
define set disparities fd dn search restricted 
cardinality set increased available computation time obviously improve precision algorithm 
shows block diagram process composed set channels associated particular disparities set channel computes correlation image pair associated disparity 
estimated disparity channel output minimal 
channel disparity channel disparity argmin disparity estimation 
assuming smooth trajectories target motion disparity remains small time set cover small disparities dense manner 
cope faster displacements large disparities considered coarse manner required computational power kept limits situations large displacements convergence achieved phases initially vergence angle roughly attracted correct angle fine adjustment performed 
compare results applying approach cartesian log polar images acquired sequence stereo images central object various disparities 
object disparity known compare ground truth value output different disparity channels 
shows correlation surface obtained computing ssd various disparity channels various target disparities 
observe general selected channel close true disparity cartesian channel disparity pixels real disparity pixels correlation channel disparity pixels real disparity pixels computation ssd disparity channels cartesian left log polar right images log polar images 
log polar images correlation surface sharper neighborhood true disparity flat cartesian images 
selection optimal channel easier log polar images compared cartesian images erroneous disparity estimates occur 
small objects existing background mismatches images lead low values similarity correct vergence situations 
non uniform resolution representation elegant solution problem 
having higher resolution center images target expected areas belonging target dominant computation correlation index reducing negative influence background elements 
position velocity estimation position velocity estimates required control gaze direction pan tilt angles 
measure target position velocity image planes ground segmentation problem addressed 
able discriminate target points points belonging background objects visual field 
assume target vergence means location stereo images approximately segmentation problem addressed zero disparity filtering 
algorithms extraction zero disparity points images developed vertical gradient sigma sigma sigma sigma sigma sigma sigma sigma pixels case 
matching care taken cope log polar representation images 
shows output segmentation process pair real images 
ground segmentation zero disparity filtering log polar images 
left right left camera image right camera image filter output 
points belonging target extracted estimate motion 
position velocity estimates taken segmented areas obtained log polar images cartesian coordinates representation 
position error position error defined difference position object coordinates center image 
definition ambiguous objects occupying point image 
centroid points belonging object determine position rr dx dy rr dx dy position error coordinates 
velocity error velocity estimation simply done differentiating position data 
position estimates considerable amount noise amplified strategy 
known technique velocity estimation optical flow provides velocity estimates point image 
integration normal flow vectors point belonging target provides stable velocity measure noise rejection 
strategy relies computation normal flow vectors segmented area followed computation average rr dx dy rr dx dy results section experimental results relative subjects addressed 
system implemented medusa stereo head shown computation done pentium mhz computer 
set experiments illustrate proposed controllers kinematics normal flow projection optical flow vector direction image gradient 
observable component optical flow due aperture problem 
medusa stereo head experimental tests 
dynamics aspects compare performance common types controllers 
experiments run hz 
perform comparison control strategies simulate target trajectory order stimuli different runs real electro mechanical components system 
useful comparison purposes method address particular characteristics visual signals mainly terms noise contents 
aspect addressed second set experiments real images 
show target trajectory easily reconstructed odometry stereo head tracking achieved objects different shapes motions 
real images system runs hz special processing hardware 
comparison controller types experiment set illustrates effect kinematics compensation inverse jacobian visual control loop versus simple proportional error controller ffi gammak theta gamma delta ffi vs ffi gammak delta ffi constant gain matrix 
addressing dynamical aspects system matrix manually adjusted obtain transient response 
recall jacobian strong effect loop gain coordinate images pan angle tilt vergence angles large small vergence tilt angles loop gain approximately unitary ffi cos delta cos delta ffi results corresponding experiment shown 
situation placed target coordinates moved object step manner coordinates gamma 
motion affects coordinate images control loop pan angle 
transition vergence tilt angles small values 
observe plots corresponding situation far target controllers behave similar manner 
targets close observer effect kinematics compensation evident 
second situation target moved point point gamma corresponds high values tilt vergence angles 
observe differences responses controller 
controller kinematics compensation produces slower response 
time sec 
step motion far target time sec 
step motion far target time sec 
step motion near target time sec 
step motion near target kinematics compensation 
response pan angle image feature step input different situations 
top row vergence tilt angles small bottom row high 
solid line corresponds proportional controller kinematics compensation dashed line corresponds proportional controller kinematics compensation 
second experiment set compares model controller target motion estimation proposed section 
proportional controller including kinematics compensation 
time constant sec model joint sampling period sec 
regulator estimator gains model controllers obtained lqr design 
situation piecewise constant velocity trajectory target 
target moves linearly points gamma gamma 
starting target takes sec reach constant velocity 
stops sec repeats trajectory motions pan tilt angles image coordinates shown 
observe error image features smaller time sec 
piecewise constant velocity motion time sec 
piecewise constant velocity motion time sec 
piecewise constant velocity motion time sec 
piecewise constant velocity motion response pan tilt angles image features piecewise constant velocity input 
solid line corresponds model controller motion estimation dashed line corresponds proportional controller 
average model controller 
target velocity discontinuities error exhibits short spike constant velocity periods smaller error proportional controller 
second situation target describes elliptical trajectory rad sec 
angular velocity 
shows error image feature controller estimation motion feature 
situation due discontinuities target motion error model controller smaller proportional controller 
target trajectories strong changes velocity position discontinuities correspond limit infinite velocity performance model time sec 
elliptical motion rad response elliptical motion target 
solid line corresponds feature error model controller motion estimation dashed line corresponds feature error proportional controller dash dot line corresponds estimation feature motion 
controller motion estimation looses advantages 
observed elliptical motion target rad sec angular velocity step motion 
slow changing velocity model adopted target motion longer valid situations 
fast target motions adopt control strategies 
instance visual systems animals fast redirections gaze performed saccades motions executed open loop manner visual information acquired control purposes 
experiments real images set experiments developed perceptual algorithms extract real images feature vector required control system 
process generate trajectories targets precise quantitative ground truth information compare results 
qualitative evaluation results realize performance system see 
experiment generated approximately linear trajectories target system track 
position joints collected time steps allowing reconstruct target trajectory qualitative way equation 
figures show time evolution joint angles trajectory reconstruction 
corresponds motion depth 
expected vergence angle significant variations 
target moves horizontally direction perpendicular initial gaze direction 
tracking motion achieved pan joint 
shows diagonal trajectory tracking requires contribution joints 
cases reconstructed trajectory close expected qualitative sense 
second set experiments unknown motion target 
case results sequence images obtained tracking process 
performance observed target kept close center images 
sequences 
sequence notice system calibration target motion coarse fashion 
time sec 
elliptical motion rad time sec 
step motion response fast changing motions 
solid line corresponds feature error model controller motion estimation dashed line corresponds feature error proportional controller 
sampling periods vergence tilt pan depth tracking 
time evolution joint angles left trajectory reconstruction right 
sampling periods vergence tilt pan fronto parallel tracking 
time evolution joint angles left trajectory reconstruction right 
sampling periods vergence tilt pan diagonal tracking 
time evolution joint angles left trajectory reconstruction right 
observe tracking human hand 
fixation stable door back room images 
hand gets close gaze direction system starts tracking target 
notice hand kept close center images despite background motion target rotation scaling 
second sequence shows reliable tracking human face scaling pose changes 
tracking objects environment important subject robotics research 
realtime tracking system copes objects different shapes motions 
tracking problem divided main issues control motion robot motion objects environment control problem estimation motion objects visual information sensor problem 
control problem addressed kinematics dynamics aspects 
kinematics analyzed general configurations robot objects environment 
tracking tasks target objects kept particular positions relative cameras 
constraint show system kinematics relation motion cameras motion target decoupled assume simple form 
dynamics analyzed considering simple reliable model joint stereo head 
show possible express system dynamics target motion image feature coordinates 
obtain linear state space dynamic model includes target motion model design motion controller 
experiments illustrate performance system 
perception strategies log polar geometry represent images 
geometry focus attention center visual field target usually located abstracting elements background influential system performance 
furthermore log polar mapping reduces size images allowing faster algorithms real time functionality 
sensing algorithms image correlation disparity filtering optical flow fast simple compute assume previous knowledge target shape 
address aspects control sensor problems 
particular application possible obtain simple dynamic model visual servoing system 
possible due fixation assumption careful choice coordinate systems visual features 
result extended complex systems generalized 
fixation bring advantages visual hand tracking left face tracking right 
servoing systems 
answers question lead important results visual servoing theory 
relative sensor problem try reduce amount noise visual estimates 
noise power requires appropriate filtering slows control system 
important improvement arise run time estimations reliability sensor signals directly control system parameters 
important reliability visual measurements depend aspects illumination clutter texture specularities suffer strong fast variations real environments 
andersson 
dynamic sensing ping pong playing robot 
ieee robotics automation december 

binocular de em log polar 
master thesis instituto superior lisbon portugal december 
santos victor 
correlation vergence control log polar images 
proc 
th int 
symposium intelligent robotic systems lisbon portugal july 
santos victor 
vergence control robotic heads log polar images 
proc 
ieee international conference intelligent robots systems pages osaka japan november 
ieee computer society press 
sandini 
dynamic vergence log polar images 
international journal computer vision august 
carpenter 
movements eyes 
london 
chaumette rives 
positioning robot respect object tracking estimating velocity visual servoing 
proceedings ieee international conference robotics automation pages 
coombs brown 
real time binocular smooth pursuit 
int 
journal computer vision october 
corke 
visual control robots high performance visual servoing 
research studies press 
corke 
dynamic effects visual closed loop systems 
ieee trans 
robotics automation october 
craig 
robotics mechanics control 
addison wesley 
chaumette rives 
new approach visual servoing robotics 
ieee trans 
robotics automation june 
faugeras fua hotz ma robert zhang 
quantitative qualitative comparison area feature stereo algorithms 
st editors robust computer vision 

fleet jepson jenkin 
image matching windowed fourier phase 
cvgip image understanding march 
franklin powell 
digital control dynamic systems 
addison wesley 

visual tracking known dimensional objects 
international journal computer vision april 
hager chang morse 
robot hand eye coordination stereo vision 
ieee control systems magazine 
horn 
determining optical flow 
artificial intelligence 
hutchinson hager corke 
tutorial visual servo control 
ieee trans 
robotics automation october 
sandini 
space variant vision active camera mount 
proc 
spie aerosense florida usa april 
papanikolopoulos kanade 
visual tracking moving target camera mounted robot combination control vision 
ieee trans 
robotics automation february 
papanikolopoulos nelson 
degree freedom hand eye visual tracking uncertain parameters 
ieee trans 
robotics automation october 
santos victor van 
medusa stereo head active vision 
proc 
int 
symposium intelligent robotic systems grenoble france july 
schwartz 
spatial mapping primate sensory projection analytic structure relevance perception 
biological cybernetics 
wallace ong bederson schwartz 
space variant image processing 
int 
journal computer vision september 

log polar vision mobile robot navigation 
proc 
electronic imaging conference pages boston usa november 
yeshurun schwartz 
cepstral filtering columnar image architecture fast algorithm binocular stereo segmentation 
ieee trans 
pami july 
