nonsystematic backtracking search dissertation submitted department computer science committee graduate studies stanford university partial fulfillment requirements degree doctor philosophy william harvey march fl copyright william harvey rights reserved ii certify read dissertation opinion fully adequate scope quality dissertation degree doctor philosophy 
matthew ginsberg principal adviser certify read dissertation opinion fully adequate scope quality dissertation degree doctor philosophy 
michael genesereth certify read dissertation opinion fully adequate scope quality dissertation degree doctor philosophy 
jean claude latombe approved university committee graduate studies dean graduate studies iii practical problems artificial intelligence search trees large search exhaustively amount time allowed 
systematic techniques chronological backtracking applied problems order examine nodes find solution explored fraction space 
nonsystematic techniques proposed alleviate problem searching nodes random order 
technique known iterative sampling follows random paths root tree fringe stopping path ends goal node 
nonsystematic techniques suffer problem exploring nodes bad order reconsider nodes ruled problem serious density solutions tree low 
unfortunately practical problems order nodes matters density solutions low 
consequently chronological backtracking iterative sampling average case performance 
new search algorithm called bounded backtrack search combines merits backtracking iterative sampling 
algorithm backtracks chronologically reaching backtrack bound immediately backtracks root restarts new random path 
show new algorithm suffer problems alternatives derive theoretical conditions guarantee better average case performance 
experimental results job shop scheduling show theoretical conditions expected performance hold real problems 
analysis search space properties real problems shows chronological backtracking successor ordering heuristics effectively 
accuracy iv heuristics early decisions critical algorithm efficiency accuracy relatively unimportant deep tree alternatives considered quickly 
unfortunately heuristics typically reliable early decisions important 
second new algorithm called limited discrepancy search examines nodes increasing order discrepancies points disagreement problem heuristics 
show algorithm exceptional average case performance heuristics accurate reasonable performance heuristics bad 
conjecture challenge solving large problems met quickly advances heuristics evolution brute force methods argue techniques limited discrepancy search rely heuristics explore alternatives heuristics fail practical 
thinking people helped directly indirectly am reminded fortunate 
mother dr diane harvey taught challenges impossible apply determination confidence 
hard grow beliefs love support family 
mom dad ben giving chance 
don think intends graduate school long time usually works way 
goodness friends going 
think john frank castro marco know get running doctors 
need business partners hugh holbrook chris responsibilities oregon 
research individual effort 
help andrew baker ari jonsson jimi crawford don scott roy dave smith lost obscure problem solve 
think enjoyed learned productive discussions research groups stanford cirl 
entered graduate school engineering solutions practical problems distilling scientific content solutions 
advisor matt ginsberg patience convince difference show scientist 
hope thesis evidence succeeded 
vi contents iv vi systematicity backtracking contributions bounded backtrack search limited discrepancy search experimental results overview bounded backtrack search mistakes mistakes costly depth search mistakes costly iterative sampling mistake probability goals randomly distributed goals distributed scheduling problems effect heuristics ignoring small mistakes heuristics affect small mistakes 
vii bigger mistakes 
bounded backtrack search algorithm general conditions algorithm example relationship depth search relationship iterative sampling relationship depth search restarts average case cost analysis general case analysis full binary trees full binary trees crossover point choosing lookahead pruning limited discrepancy search existing strategies iterative sampling backtracking nonsystematic methods discrepancies upper bounds likelihood finding solution wrong turns estimating heuristic probability analysis early iterations success probability chronological backtracking success probability iterative sampling viii comparison existing techniques variations extensions variable reordering different heuristics combining lds bounded backtrack search local optimization lds experimental results scheduling csp measuring performance comparison ai techniques comparison techniques performance strategies stochastic iterative broadening backtracking restarts iterative sampling bounded backtrack search limited discrepancy search scheduling sat variations weakening value order heuristics weakening variable order heuristics incremental systematicity related algorithms chronological backtracking iterative sampling ix iterative broadening profile job shop scheduling search space heuristics search space heuristics earlier graphs profile scheduling problems sat profile random sat characterizing search tree getting part difficult part graphs problems collecting profile data node classes traversing search tree incorporating heuristics implementation considerations weighted random selection values walk start restarting different variables application csp heuristics scheduling bibliography list figures nodes mistakes 
mistakes costly large subtrees 
small mistakes costly iterative sampling 
look goals distributed randomly 
real problems fairly constant heuristics unpredictable effects effective mistake probability node lookahead 
node lookahead heuristics 
ratio lookahead 
depth search algorithm 
bounded backtrack search algorithm 
bbs probe fails discover goal node calculating average case cost lookahead 
theoretical crossover point full binary trees height 
optimal lookahead full binary trees height 
theoretical crossover point full binary trees height 
optimal lookahead full binary trees height 
performance bbs various fixed lookahead amounts 
limited discrepancy search 
execution trace lds 
possibilities node children 
probes iteration 
discrepancy component xi problem height 
problem height 
limited discrepancy search bounded backtrack 
iterative sampling chronological backtracking competitive 
front runners 
results survey benchmark 
iterative broadening cutoff backtracking restarts timeout variations iterative sampling 
adding bounded backtrack isamp major improvement 
small lookahead value works slightly better 
bounded backtrack improves lds 
wsat 
weighted random selection worse alternatives 
weighted random selection better alternatives 
randomize variable order 
incremental systematicity improves bbs 
incremental systematicity iterative sampling 
depth search time limit 
iterative sampling 
iterative broadening 
numbering scheme sadeh problems 
distribution nodes depth range sadeh rand 
sadeh rand 
ratio sadeh rand 
sadeh rand magnified right 
sadeh rand 
cost bad subtrees height sadeh rand 
cost height bad subtrees depth sadeh rand 
xii sadeh rand 
sadeh rand 
sadeh rand 
sadeh rand 
sadeh rand 
distribution nodes depth range sadeh heur 

sadeh heur 

cost bad subtrees height sadeh heur 

sadeh heur 
magnified right 
ratio sadeh heur 

sadeh heur 

sadeh heur 

sadeh heur 

sadeh heur 

sadeh heur 

sadeh heur 

cost bad subtrees height heuristics 
cost bad subtrees height heuristics 
distribution nodes depth range random sat 
random sat 
random sat magnified right 
cost bad subtrees height random sat 
ratio random sat 
random sat 
cost height bad subtrees depth random sat 
distribution nodes depth range random sat 
random sat 
cost bad subtrees height random sat 
cost height bad subtrees depth random sat 
xiii interior node classes 

function randomize value order 
function restarting different variables 
ways area possible configurations 
xiv chapter chapter 
systematicity backtracking simple intuitive algorithm systematically exploring set alternatives search solutions problem 
algorithm said systematic considers alternatives set considers 
searching finite set alternatives systematically advantage guaranteed terminate solution proof solution exists 
unfortunately problems practical interest set alternatives large search exhaustively amount time situation allows 
circumstances importance systematicity comes question 
alternative equal chance solution problem optimal search protocol finding solution bounded amount time considered ruled alternatives fastest 
real world problems alternatives equal chance solutions success failure independent 
usually possible similar alternatives fail reason case failure affects conditional probability succeeds 
light observation optimal search protocol necessarily fastest consider new alternatives 
alternatives better 
nonsystematic backtracking search strategies variations backtracking algorithm sacrifice guarantees completeness order explore better alternatives quickly 
new algorithms bounded backtrack search limited discrepancy search 
realistic model search space properties notion better alternative derived 
bounded backtrack search examines alternatives little common alternatives known failures 
limited discrepancy search examines alternatives fewest discrepancies points disagreement problem heuristics 
chapter 
backtracking constraint satisfaction problems provide useful framework research backtracking techniques 
problem find complete assignment set variables satisfies set constraints limiting specific combinations variable assignments 
backtracking explores set alternatives complete variable assignments picking variable branching sequentially possible values 
value explores possible assignments remaining variables extending partial assignment level recursion 
research backtracking constraint satisfaction aims avoid unnecessary search proving remembering certain partial assignments inconsistent constraints problem 
partial assignment known inconsistent backtracking algorithm ignore extensions assignment danger missing solution 
research topic divided overlap categories consistency preprocessing constraint propagation intelligent backtracking dependency directed backtracking 
ffl reasoning problem constraints consistency processing techniques eliminate values domains variables search 
effectiveness approach demonstrated scene recognition problems dramatically reducing number possible interpretations line drawing blocks shadows 
sufficient degree consistency processing problem solved search altogether 
unfortunately consistency techniques expensive search depending domain structure constraints 
ffl consistency reasoning applied dynamically variable instantiation backtracking search algorithm 
known constraint propagation procedures eliminate values inconsistent constraints current partial assignment 
efficiency concerns consistency processing critical procedures applied dynamically invoked times 
called hybrid systems chapter 
combining small degree constraint checking intelligent backtracking appear effective 
ffl detecting partial assignment inconsistent constraints problem chronological backtracking returns variable assignment tries alternative value value way responsible failure 
intelligent backtracking seeks avoid thrashing behavior identifying backtrack points responsible failure returning directly 
simple intelligent backtracking scheme called backjumping widely improvement chronological backtracking :10.1.1.27.4126
ffl perfectly chosen backtrack points backtracking consider partial assignments containing specific combinations variable assignments previously inconsistent 
redundancy eliminated remembering causes failure detected 
subsequently partial assignment containing known cause failure pruned 
dependency directed backtracking truth maintenance systems attempt store causes discovered 
storage indexing principal concerns approach 
practical techniques restrict set stored causes cost expanding nodes full dependency directed backtracking expand 
considerable research gone keeping backtrack search exploring provably bad alternatives relatively little gone guiding explore plausibly alternatives 
related research focuses choosing order variable instantiation manner minimizes size search tree 
simplest form search rearrangement instantiates variable fewest possible remaining values 
basic principles search rearrangement shown dramatically increase search efficiency 
complicated methods depend models apply real world problems 
chapter 
search rearrangement methods achieve efficiency reducing size search tree exploring promising areas tree early 
objective find solution bounded amount time order examining alternatives important size search tree amount redundancy 
earlier iterative broadening introduced notion bad node developed probabilistic model likelihood node considered search succeed 
langley adopted model compare expected performance chronological backtracking nonsystematic technique called iterative sampling 
plausible conditions iterative sampling shown better average case performance traditional backtracking 
conditions hold real world problems 
series scheduling experiments appeared demonstrate 
nonsystematic techniques legitimate alternatives backtracking large search spaces 
research thesis comes observation backtracking techniques nonsystematic techniques compatible 
combining merits able develop new algorithms significantly better average case performance chronological backtracking iterative sampling 
chronological backtracking iterative sampling iterative broadening closely related new algorithms refer frequently 
included algorithms appendix contributions bounded backtrack search bounded backtrack search new algorithm combines elements backtracking iterative sampling 
ways backtracking iterative sampling alike 
backtracking search iterative sampling extends partial assignment reaching consistent total assignment detecting inconsistency constraints problem 
detecting inconsistency iterative sampling immediately backtracks way assignment 
contrast chapter 
chronological backtracking algorithms backtrack assignment 
bounded backtrack search nonsystematic derivative chronological backtracking incorporates bound length sequence backtracks 
algorithm backtracks chronologically reaching backtrack bound point forced backtrack assignment restart 
show theoretically tree height optimal backtrack bound lies properly iterative sampling bound zero chronological backtracking bound bounded backtrack search simple modification backtracking algorithm dramatically decreases expected time find solution 
limited discrepancy search large problems practical interest carefully tuned value ordering heuristics guide search regions space contain solutions 
problems heuristics lead directly solution 
limited discrepancy search addresses problem heuristics fail 
show theoretically experimentally chronological backtracking effective accurate value ordering heuristics 
heuristic may mistakes rarely mistake high search tree traditional backtracking strategies recover consider alternative time allowed 
intuition heuristic fails probably succeeded small number wrong turns way 
tree height ways heuristic single wrong turn ways 
number wrong turns small discovered systematically searching paths differ heuristic path small number decision points discrepancies 
limited discrepancy search backtracking algorithm searches nodes tree increasing order discrepancies 
derive upper bound exhaustively searching space limited number discrepancies show formally limited discrepancy search greater chance finding solution limited amount time alternative approaches 
chapter 
experimental results job shop scheduling problem significant practical importance representative large class problems important frontier tractability 
studied operations research artificial intelligence communities job shop scheduling ideal domain evaluating performance algorithms introducing 
comprehensive evaluation algorithms established benchmark large scheduling problems 
compare results ai search techniques dedicated scheduling programs 
results confirm theoretical expectations performance traditional backtracking techniques show iterative sampling performs easy scheduling problems performance larger problems competitive 
test variety nonsystematic backtracking techniques find categorically outperform chronological backtracking iterative sampling significant margins 
better algorithms combination bounded backtrack limited discrepancy algorithm choice 
argue theoretical grounds algorithm remain superior technology science meet challenge scaling research problems problems real world 
overview body thesis contained chapters recommend reading sequence 
chapter introduce search space properties form basis theoretical analysis 
go describe shortcomings various existing search techniques show bounded backtrack search avoids problems 
conclude formal analysis expected time find solution bounded backtrack search comparing theoretical performance iterative sampling chronological backtracking 
chapter extend analysis tree search heuristics 
limited discrepancy search algorithm analyze expected performance 
conclude discussion variations extensions useful practice 
chapter chapter 
experimental results 
compare search techniques experimentally evaluate individually testing variations adjustments parameters 
number individual experiments unexpected results implications search algorithms 
explore results part chapter suggest various topics investigation 
appendix contains descriptions related search techniques 
appendices attempt profile search spaces job shop scheduling problems show theoretical properties search spaces argued exist real world problems 
comparison profile search space random sat problems appendix appendix describe method profiling 
appendix give algorithm implements variety nonsystematic backtracking strategies 
chapter bounded backtrack search chapter 
bounded backtrack search problems ai formulated tree search problems 
search space consists nodes tree subset recognized goal nodes representing solutions 
formulation defines nodes search algorithm examine provide precise information nodes search algorithm expected examine finding solution 
reason course performance different search procedures depends wide variety factors size search space density solutions 
factors significant standard average case cost analyses search procedures apply 
mistakes factor important backtracking search algorithms notion mistake 
define bad node node goals subtree 
node node bad 
mistake bad node parent node 
example shown nodes drawn solid dot bad nodes drawn 
goal node node ae ae ae ae omega omega omega omega omega omega ffl ffl theta theta ffl theta theta nodes mistakes 
bad nodes introduced ginsberg harvey context iterative broadening 
argued tree constant branching factor chapter 
bounded backtrack search reasonable assume absence information number children node remains constant depths 
conditions iterative broadening shown outperform depth search significant margins 
committing constant number children node define mistake probability likelihood randomly selected child node depth mistake node 
example node tree branching factor children chance selecting mistake child random children node depth gammas see mistake probability search space property significantly affects average case performance backtracking search procedures 
remainder section attempt demonstrate mistakes relate backtracking 
section investigate mistake probability property search space 
section bounded backtrack search algorithm potential exploit property achieve better performance alternative backtracking strategies 
section formal analysis search algorithm carry chapter 
experimental results comparing bounded backtrack search procedures chapter 
mistakes costly depth search reason effectiveness iterative broadening reduces cost making mistake early search tree 
mistake leads large subtree solutions serious threat depth search 
depth search investigating mistake node sibling algorithm commits exploring entire subtree mistake exploring portions search tree 
practical problems interest size subtree may sufficiently large algorithm recover amount time allowed run 
consider problem shown 
tree height just easily imagine large tree structure 
depth search chapter 
bounded backtrack search explores nodes left right commitment fatal mistake 
ae ae ae ae omega omega omega omega omega omega ffl theta ffl theta theta ffl ffl theta theta theta theta theta theta theta theta theta theta theta theta theta ffl ffl theta theta theta ffl ffl mistakes costly large subtrees 
things particularly alarming example 
standards problem extremely easy half fringe nodes goal nodes possible mistake entire search space 
fact simple problem unsolvable depth search reasonable amount time indication algorithm may suited task 
second alarming fact problems structure obscure pathological cases perfectly natural 
example months ago needed travel wedding texas busy holiday weekend 
decision fly driving 
phone calls travel agents gave decided fly san antonio drive 
told travel agent flexibility booking flight easy 
turned airline flew weekend airline completely booked 
attempts fly various connecting flights failed reason connect american eagle booked 
point enabled solve problem got gave flying long exhausting ways possible 
committed trying possible connecting flights considering driving phone 
time commitment flying natural step coming plan 
ai problems early commitments search chapter 
bounded backtrack search considerably arbitrary threat early mistakes serious 
mistakes costly iterative sampling proposed approach dealing problem early mistakes abandon systematicity 
iterative sampling employs strategy boldly traversing random path root tree directly fringe node 
fringe node goal returned solution 
algorithm restarts random path root tree repeating finds solution 
algorithm advantage balanced search tree doesn matter goal nodes distributed 
example iterative sampling probably find solution tries 
unfortunately iterative sampling weaknesses 
consider tree shown 
example tree small imagine larger tree structure 
search tree depth search find solution short amount time mistake possible opportunity 
size tree nodes systematic procedure guaranteed find solution nodes 
iterative sampling provide guarantee 
consider lucky iterative sampling find solution probe 
mistake times row 
chance finding solution iterative sampling search average nodes finding solution 
problems difficult depth search problems share structure easy imagine occur frequently practice 
mistake probability examples previous section suggest mistakes important factor performance various search algorithms 
establish chapter 
bounded backtrack search omega omega omega omega omega omega omega omega omega omega omega omega theta theta theta theta ffl ffl ffl ffl ffl small mistakes costly iterative sampling 
mistake probability meaningful property search space 
clarity continue binary trees examples arguments apply branching factor 
analysis iterative broadening assumption mistake probability depths 
consider example assumption true 
examine representatives real world problems test assumption reasonable practice 
goals randomly distributed say gave problem represented full binary tree height person tells fourth nodes fringe goal nodes 
assumption search space mistake probability approximately depths denote constant mistake probability calculate knowledge quarter fringe nodes goals follows nodes fringe theta goal nodes 
branching factor constant chance selecting bad node children randomly selected parent depth equal chance selecting bad node collection nodes parents depth letting tree root node children zero half 
exactly tree 
chapter 
bounded backtrack search number bad nodes parents parent exactly children combining equations confirms number nodes grows depth gamma 
assuming gamma gamma gamma observations evaluating expression 
mistake probability depends nodes depth definition node successor 
binary tree node children 
consequently value greater binary tree 
fact depths tree single goal node depth zero single node depth exactly half times times number nodes depth tree height calculate 
having calculated proceed analyze expected performance various search algorithms space length chapter 
unfortunately analysis original assumption mistake probability depths 
say person generated problem secretly decided nodes fringe goal nodes flipping coins 
real mistake probability vary quite dramatically depth 
general greater gamma tree branching factor chapter 
bounded backtrack search graph real shown 
calculated mistake probability bad representative actual mistake probability just depth 
ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl look goals distributed randomly 
goal nodes randomly distributed assumption mistake probability depths clearly wrong 
practical search problems compelling reason believe goals randomly distributed 
real idea goal nodes distributed 
absence information assume goals randomly distributed assume mistake probability constant 
intuitive basis assumption usually stronger see experimental mistake probability calculated follows node depth classified children bad 
node left right child bad case bad case case bad bad case 
height child subtree gamma gamma 
number fringe nodes child subtree gammak gamma probability fringe node goal probability child subtree goals implying child bad gamma gammak gamma probability child gamma mistake probability ratio bad nodes parents depth nodes bad parents bad node parent depth case case node nodes bad parents depth case case case node 
zero bad nodes parents depth case node 
ratio half times probability case case divided probability case case case gammax gammax chapter 
bounded backtrack search evidence support 
sections results drawn practical scheduling problems 
goals distributed scheduling problems job shop scheduling example practical problem intuitions supporting constant mistake probability fairly strong 
job shop scheduling problem finding schedule ordering set operations number machines satisfies set time ordering constraints 
problem formulated search tree binary decisions decision ordering decision operations contend single resource prevent resource conflict operation complete operation begins vice versa 
expect point search wrong ordering decision committing partial schedule feasible extensions 
mistakes go undetected deeper search yielding tree discovered early pruning mechanism yielding tree 
mistakes detected important consideration return 
moment concerned plausibility making mistake depth search tree 
shows mistake probability range depths taken prototypical job shop scheduling problem 
appendix explains data collected gives number additional examples 
interesting note mistake probability constant isn curve randomly distributed nodes 
assumptions constant mistake probability better explanation data 
effect heuristics search problems formulated csps heuristics generally select variable instantiate value assign 
csps job shop scheduling discussed length chapter 
chapter 
bounded backtrack search ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl real problems fairly constant formulated tree search problems value selection heuristics successor orderings variable selection heuristics determine arrangement decisions search tree 
successor ordering critical understanding analyzing search space properties hope capitalize chapter discuss value selection heuristics passing 
variable selection heuristics affect assumptions search space order decisions search tree relevant mistake probability depths 
intuitively obvious heuristics affect mistake probability general certainly depend individual heuristics problems 
job shop scheduling problems powerful variable value selection heuristics thought illustrative 
scheduling problem searched random variable selection searched heuristic variable selection 
effect certainly difficult predict 
bizarre effect appears idiosyncratic 
tested variety scheduling problems heuristics see appendix curves idiosyncratic 
appears intuitive experimental way predict effect heuristics mistake probability 
assumption mistake probability constant true particular problem remains reasonable chapter 
bounded backtrack search ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl heuristics unpredictable effects priori assumption search space 
ignoring small mistakes looking back wonder mistake probability affected significantly looking ahead node 
define effective mistake probability lookahead probability selecting bad child children parent considering children subtrees height lookahead effective mistake probability calculation simply ignores dead nodes subtrees height zero 
definition effective mistake probability problem zero depths 
term lookahead may little misleading talking properties search space parameters search procedure 
definition effective mistake probability depends strictly search space 
get search procedures section established search space properties hoping exploit 
node lookahead effective mistake probability drops shown 
drop significant confirming intuition practical problems pruning mechanisms may detect mistakes relatively early 
chapter 
bounded backtrack search ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl effective mistake probability node lookahead 
heuristics affect small mistakes 
shows effective mistake probability heuristics 
saw section heuristics large unpredictable effect mistake probability different depths 
effects understandable ignore small mistakes 
shows problem previous figures time searched heuristics lookahead 
ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl node lookahead heuristics 
chapter 
bounded backtrack search graph remarkable 
effective mistake probability wiped heuristics 
just problem scheduling problems tested similar results see appendix 
discuss appendix data graphs reflects bottom depths search tree 
depths recorded range shown marking horizontal axis 
problems trivial solve depth search heuristics case effective mistake probability zero depths 
high search tree possibility making serious mistake 
sense 
early search scheduling heuristics informed 
decisions arbitrary 
expect mistake probability high gradually decrease deeper search tree 
expectation contrast sharply steep increase mistake probability randomly distributed goals 
bigger mistakes 
effect node lookahead dramatic job shop scheduling problems foolish consider trying deeper lookahead 
graph ratio effective mistake probability lookahead mistake probability lookahead range lookahead amounts scheduling problem shown earlier figures 
problem solved heuristics 
seen heuristics reduce mistake probability zero lookahead just additional lookahead advantage heuristics 
value average lookahead depths examined portion search space see appendix 
mistake probability remains roughly constant depth average value reasonable representative 
graph dramatic reduction effective mistake probability lookahead zero ratio steps graphs sadeh problems look pretty alike 
see appendix graphs problems 
geometric mean appropriate calculations involving mistake probability just want show mistake probability varies lookahead 
chapter 
bounded backtrack search ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ratio lookahead 
chapter 
bounded backtrack search lookahead zero lookahead 
additional reduction lookahead increases 
clear deeper lookahead affects mistake probability 
determine effects significant turn discussion search procedures 
bounded backtrack search algorithm preceding sections discussed lookahead strictly property search space 
existing procedures may suggested benefit cost search procedure performing lookahead tried postpone topic section 
discussion take advantage search space properties improve performance backtracking search algorithm 
step define general backtracking procedure serve framework comparison 
depth search iterative sampling interesting special cases procedure ends spectrum possibilities 
central question hope answer chapter backtracking procedures depth search iterative sampling better performance conditions 
general conditions search algorithm binary search trees 
easily extended arbitrary branch factors presenting version binary trees analysis clearer lessons direct 
node exactly zero successors returned ordered list successors function 
node zero successors fringe node 
subset fringe nodes identified goals 
rest dead ends 
task search algorithm search tree goal node return goal node 
requiring lookahead reaches height search tree ratio zero 
data taken subtree levels high see appendix fact curve approaches zero expected 
chapter 
bounded backtrack search search algorithm find goal nodes return failure goal nodes search tree 
stipulating search algorithm revisit nodes examined 
short requiring search algorithm systematic 
interested average cost search algorithm find goal node certain properties search space concerning likelihood cost mistakes 
average cost search algorithm measured number nodes examined 
algorithm bounded backtrack search algorithm nonsystematic derivative simple depth search procedure 
clear differences give pseudocode description depth search dfs followed bounded backtrack search bbs 
dfs node timeout return timeout result goal node return node child successors node result dfs child result nil return result return nil depth search algorithm 
algorithms thing discover goal node return back tree unwrapping recursive calls 
difference comes run dead node 
bbs probe keeps track backtracks far backtracked height subtree rooted node chapter 
bounded backtrack search bbs probe node lookahead goal node return child random permutation successors node hresult bbs probe child lookahead max height result nil return hresult height lookahead return hnil return hnil bbs node lookahead loop timeout hresult bbs probe node lookahead result nil return result return timeout result bounded backtrack search algorithm 
chapter 
bounded backtrack search backtracking 
bbs probe backtracked subtree height lookahead continues backtracking way root tree ignoring unexplored siblings goes 
bbs probe leaves nodes unexplored may goal node exists original search tree 
bbs probe fails bbs tries 
different random permutations lists successors line new probe chance finding solution 
example suppose applied bbs algorithm lookahead search tree shown 
assume random permutation function returned successors left right order particular iteration bbs probe 
probe bbs probe expand node account fact backtracked subtree height rooted note bbs probe backtracks continues explore siblings backtrack subtree height lookahead 
omega omega omega omega omega omega omega omega delta delta delta delta delta delta ffl ffl ffl theta theta theta theta bbs probe fails discover goal node chapter 
bounded backtrack search relationship depth search lookahead amount greater equal height entire search tree single iteration bbs probe equivalent dfs exception successors explored random order 
exception significant successors function takes account heuristic information order nodes manner finding solution 
section discuss ways incorporating heuristics random permutation function stochastically perturbing original order remains consideration need bbs randomness competes efficacy successor ordering heuristics 
analysis chapter assume sacrifice randomizing successor order 
relationship iterative sampling extreme lookahead amount zero bbs algorithm equivalent langley iterative sampling algorithm 
implementation factor counting nodes consider 
iterative sampling backtracks root node save state traverses path 
practice implementations successors function typically copy modify previous state generate successors record changes manner unwound 
cases overhead required support backtracking may significant expense iterative sampling pay 
analyzing search algorithms number nodes expanded expense factor analysis 
chapter report experimental results showing algorithmic improvements generally outweigh constant factors nontrivial problems 
note observation section 
bounded backtrack search needs keep states lookahead backtracks backtracks way 
especially large easy problems linear factor storage may significant 
implementation sat solver tableau bound storage limitations problems alleviated recorded levels state 
chapter 
bounded backtrack search relationship depth search restarts depth search restarts rdfs modification depth search overcomes problem early mistakes sacrificing systematicity 
rdfs iteratively retries depth search randomized value selection timeout number nodes 
rdfs similar bounded backtrack search circumstances algorithms identical suitably chosen timeout values 
consider probe bounded backtrack search lucky unlucky way dead node maximum depth tree backtracking 
failing depth probe backtrack depth gamma try alternative depth node solution probe backtrack depth gamma continuing manner explore entire subtree height gamma th node original path 
backtracks parent gamma gamma backtrack bound forces return way 
subtree height full rdfs timeout value gamma gamma rdfs probe explore identical nodes successor orderings 
significant difference search algorithms comes probe recoverable mistakes height way 
nodes explored subtrees recoverable mistakes count rdfs eventual timeout affect bounded backtrack probe 
rdfs timeout value gamma gamma nodes accommodate recoverable mistakes height way side effect small excursions extra time spent exploring subtrees height exceeding average case cost analysis average case cost bounded backtrack search expected number nodes searched find solution 
successive probes iterations bbs probe selected random replacement cost simply expected cost probe divided likelihood probe succeeds 
expected chapter 
bounded backtrack search cost probe average possible iterations bbs probe weighted frequency occur 
likelihood computed variety ways depending chosen assumptions search space 
analysis assumptions likelihood making mistake level search tree height subtree mistake 
omega omega omega omega omega omega omega omega ffl ffl ffl theta theta theta theta expected probe cost nodes 
probability probe success 
average case cost find solution nodes 
calculating average case cost lookahead 
general case section introduced probability making mistake depth search tree expanding bad child depth sibling 
certain special cases height search tree needed predict performance algorithm see section 
general performance bounded backtrack search depend height size subtrees mistakes 
section derive formulas bounded backtrack expected time find solution terms functions characterizing height size subtrees mistake nodes 
probability subtree bad node depth search tree height assume probability independent particular path root tree bad node 
know things chapter 
bounded backtrack search function priori 
bad node deepest level tree subtree bad node height zero bad node deepest level 
reasoning know particular depth value zero outside range gamma data section show scheduling problems subtrees mistake nodes height zero 
expect general depth function begins spike rapidly falls zero gamma 
quickly function falls important factor calculating cost search 
probability probe success calculate probability success probe bounded backtrack search 
assume solutions lie deepest level tree tree necessarily full bad branches may detected early pruned 
assumption holds search trees wide variety problem formulations constraint satisfaction problems searches iterative deepening 
order find solution probe needs avoid making fatal mistakes times row 
fatal mistake mistake recover backtracking height subtree allowed lookahead 
tree binary probability making fatal mistake depth minus times probability height subtree bad node depth lookahead 
letting function probability success probe bounded backtrack search lookahead gamma gamma expected number probes gamma gamma chapter 
bounded backtrack search cost searching bad node computing average cost probe requires knowing size subtrees bad nodes addition heights subtrees necessarily full 
assume size subtree depends depth original tree height 
denote cost subtree height depth 
consider cost making fatal mistake depth examining bad node counts node 
chance bad node successors case total cost mistake 
chance gamma search continues successors bad node 
possibilities subtree child height lookahead amount search fully expand subtree go explore second child returns subtree child height greater equal lookahead amount search explore restricted part subtree ignore sibling returns 
letting costs respective possibilities cost searching subtree bad node depth bounded backtrack search lookahead bad gamma gamma cost case sum cost searching successors 
cost searching bad node independent path leading know successors fact subtree height lookahead 
cost searching second just bad 
subtree child fully explored height lookahead amount 
cost exploring subtree weighted average costs subtrees allowable heights 
expanding bad node depth parent depth gamma bad 
coefficient cancels zero denominator 
chapter 
bounded backtrack search bad case second child ignored 
child bad node subtree height letting cost exploring bad node subtree height function similar bad takes account fact subtree known height zero functions bad defined follows examining bad node counts node 
chance bad node successors 
possibilities depending height subtree child subtree child height gamma search fully expand subtree go explore sibling known subtree height gamma parent subtree height subtree height gamma search fully expand subtree explore sibling known height sibling subtree subtree child height greater equal lookahead amount search explore restricted part subtree ignore sibling returns 
letting costs respective possibilities gamma gamma gamma chapter 
bounded backtrack search cost case cost exhaustively searching child height gamma plus cost searching sibling height gamma 
gamma gamma gamma gamma known height sibling second case cost searching bad bad gamma gamma cost case case bad cost searching bad node deepest level tree nodes beneath 
bad combining equations recurrences give cost searching bad node depth lookahead terms cost searching node consider cost searching node depth node counts 
possibilities depending child mistake node 
probability gamma child node probability mistake 
letting respective costs gamma coefficient cancels zero denominator 
similar conditions hold 
chapter 
bounded backtrack search gamma easy see child node second child explored 
cost searching node cost searching bad node depends mistake fatal mistake 
mistake fatal probability gamma recoverable probability 
cost fatal mistake cost searching bad node subtree height 
cost recoverable mistake cost exploring bad child short subtree plus cost searching sibling 
gamma cost searching node deepest level obviously equations define cost searching node depth tree 
recurrences yield expected cost probe iteration bbs probe 
combination results section yields average case cost bounded backtrack search lookahead terms properties search space chapter 
bounded backtrack search analysis full binary trees section apply general analysis full binary trees known 
full binary trees full binary tree height subtree node extends maximum depth tree 
function probability subtree bad node depth height simply delta function gamma cost subtree height just gamma 
keeping section assume sake analysis probability making mistake depth constant depths 
practice expect exactly constant deviations affect predicted performance significantly 
denote probability characterize search space full binary tree follows gamma gamma remainder section apply recurrences general analysis search space characteristics working closed form solutions expected number nodes examined bounded backtrack search iterative sampling depth search 
subtrees height gamma value cost function gamma irrelevant 
derivations section validated evaluating general recurrence equation functions equations set example trees comparing results results expressions step derivation 
chapter 
bounded backtrack search bounded backtrack search working bad recurrences 
substituting functions equations yields bad gamma gamma gamma gamma bad gammak gamma bad gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma gammak gamma bad gamma gamma gamma gammak gamma bad solve recurrence pieces 
equation gamma gamma gamma gamma gammak gamma increased recursive call condition gamma gamma gamma holds new value decreased 
coefficients equation remain zero 
combining equations gamma gammak recurrence holds reaches equation 
solution recurrence just sum gamma increasing powers reaches zero reaches bad bad gammak equations 
recurrence identical recurrence equation stopping chapter 
bounded backtrack search gammak gamma 
equation gammak gamma 
similar argument extends gammak gamma equation gamma gamma coefficients zero 
recurrence form gamma point gammak gamma equation 
solution recurrence just gamma gamma plus value stopping case 
coefficient gamma gamma gamma combining equations gamma gamma gammak gamma gamma gamma gamma gamma gamma turn cost searching node full binary tree 
substituting equation equations gamma gamma gamma gamma gamma gamma gamma gammak gamma gamma gamma expected cost subtrees depth shorter full binary tree subtrees depth height exactly gamma gamma equation defined gamma gamma range coefficient non zero 
solve recurrence equation pieces 
gamma gamma gamma gammak gamma gammak gamma gamma gammak chapter 
bounded backtrack search 
recurrence adds gamma times quantities gamma times decreasing power 
simplification gamma gamma gammaj gammak gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma value recurrence reaches gamma comes equation substituting gamma gamma gamma stopping value recurrence gamma simplify form recurrence gamma gamma 
solving equation gamma gamma gamma gamma gamma gamma mk solving recurrence tedious technically difficult 
recurrence stops gamma value gamma multiplied gamma gamma gamma iterations 
mk terms summed multiplied gamma successive iteration yielding gamma gammal gammak gammal gammak gamma gamma gamma gamma gammal gammak gamma gamma gamma gammal gammak gamma gammam gammal gammak gamma chapter 
bounded backtrack search closed form solution sum ja gamma gamma gamma gammal gammak gamma gamma gamma gammal gammak gamma gammam gamma gamma gamma gamma gammal gammak gamma gamma gamma gamma gammal gammak gamma gamma gammal gammak gamma gamma gamma gammal gammak gamma gamma gamma gamma gamma gammal gammak gamma gamma gamma gammal gammak gamma gamma gamma gamma gamma gammal gammak gamma gamma gamma gamma gamma gammal gammak gamma gamma gamma gammal gammak gamma gamma gammal gammak gamma gamma gamma components equation equation simple understand terms search 
consider node depth gamma probe node follow straight path backtracking depth gamma point gamma gammal gammak chance having mistake 
probe gets depth making mistake explore full subtree finding solution 
expected number nodes search subtree equation 
component equation 
chance having mistake path chapter 
bounded backtrack search depth gamma gamma gamma gammal gammak mistake search explore full subtree known solutions bad node 
cost exploring full subtree gamma 
second component equation 
third component gamma gamma just number nodes expanded path depth gamma equation gives final closed form expression expected number nodes expanded probe bounded backtrack search lookahead bbs gamma gamma gamma gammal gamma gamma gammal gamma gamma likelihood individual probe succeeds gamma gammal expected number probes bbs gamma gammal product expected number nodes bounded backtrack search expand finding solution searching full binary tree mistake probability depth search analysis depth search follows directly analysis observing depth search extreme case bounded backtrack search height tree lookahead amount 
substituting equation dfs gamma gamma single probe depth search examines tree finding solution probe suffices 
equation shows average case performance depth search proportional mistake probability 
practical consequence chapter 
bounded backtrack search fact successor ordering heuristics decrease chance making mistake generally marginal effect average case performance 
successor ordering heuristics battle search space depth search search method choice 
return implications section 
iterative sampling iterative sampling extreme case bounded backtrack search 
substituting equation realizing obvious isamp isamp gamma contrast depth search performance iterative sampling varies th power suggesting successor ordering heuristics effective search procedure 
unfortunately iterative sampling depends randomness value selection competes successor ordering heuristic see section 
crossover point clear analysis particular depth iterative sampling superior depth search full binary trees small mistake probabilities 
unique solution depth search superior avoids searching nodes redundantly 
single solution probability making mistake node successors goal subtree 
average cost depth iterative sampling searches dfs chapter 
bounded backtrack search isamp large depth limit depth search explore times nodes iterative sampling order find unique solution 
small mistake probability mistake probability depth search iterative sampling equivalent performance 
graphs show crossover point varying heights 
range goes search space having solutions depending depth search space unique solution 
expected depth search affected linearly making crossover point fairly dramatic 
log nodes expanded ffi isamp ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi pi dfs pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi ffl bbs ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl theoretical crossover point full binary trees height 
figures solid line performance bounded backtrack search optimal lookahead chosen value legitimate lookahead values line guaranteed go lines 
interesting goes lines 
circumstance bounded backtrack search superior iterative sampling chapter 
bounded backtrack search best lookahead fflffl optimal lookahead full binary trees height 
log nodes expanded ffi isamp ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi pi dfs pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi ffl bbs ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl theoretical crossover point full binary trees height 
chapter 
bounded backtrack search best lookahead ffl optimal lookahead full binary trees height 
depth search 
figures show 
furthermore depth search increases comparing depth depth range superiority covers problems multiple solutions 
analytically crossover point iterative sampling depth search particular values gamma gamma gamma observing range letting gamma see gamma gamma gamma gamma gamma chapter 
bounded backtrack search log log log log log gamma log gamma log large depth limit iterative sampling superior depth search full binary tree 
choosing lookahead figures show optimal lookahead values bounded backtrack search corresponding graphs 
oddly optimal lookahead values fairly small range jump sharply point near 
experiments scheduling problems performance bounded backtrack search sensitive particular lookahead value chosen 
helpful property applying algorithm real world problems analytically optimal lookahead determined 
practice just try lookahead values training set problems pick best value 
shows theoretical performance bounded backtrack search variety lookahead amounts ranging equivalent iterative sampling equivalent depth search 
find full binary trees choice difference scheduling experiments 
remains case reasonably optimal lookahead trying alternatives training set problems 
condition stronger condition multiple solutions implies number solutions grows exponentially increasing depth 
experiments non full binary trees 
try increasing powers 
lookahead value general 
chapter 
bounded backtrack search log nodes expanded ffi isamp ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi pi dfs pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta performance bbs various fixed lookahead amounts 
chapter 
bounded backtrack search pruning figures show full binary trees bounded backtrack search better performance iterative sampling depth search triangular region curves 
seen search trees scheduling problems full 
fact subtrees mistake nodes pruned right mistake nodes 
better predict performance bounded backtrack search problems characteristics profiled scheduling search spaces find distribution mistake subtree heights 
expected curve drop quickly peak trailing zero gamma 
surprise initial peak subtrees fairly evenly distributed possible heights 
despite early pruning number nodes mistake subtree height grew exponentially meant vast majority mistakes small subtrees large subtrees 
ironically pathological cases iterative sampling depth search discussed earlier section section 
expect problems characteristics triangular regions graphs figures larger 
investigation job shop scheduling shown real world problems characteristics seriously hurt average case performance iterative sampling depth search 
iterative sampling eager backtrack depth search reluctant 
sense bounded backtrack search compromise extremes 
shown theoretically bounded backtrack significant improvement existing techniques 
profiles scheduling search spaces indicate improvements greater real problems 
experimental results test optimistic outlook chapter 
details experiment appendix chapter limited discrepancy search chapter 
limited discrepancy search practice search problems spaces large search exhaustively method 
find solutions small fraction search space relying carefully tuned heuristics guide search regions space contain solutions 
problems heuristics lead directly solution time 
chapter consider heuristics fail 
focus attention procedures solving tree search problems 
allow state objective succinctly tree search problems heuristically ordered successors search procedure find solution time limit chronological backtracking iterative sampling 
address question follows section comment existing algorithms 
introduce limited discrepancy search derive upper bounds algorithm 
section endeavor quantify properties successor ordering heuristic leads detailed analysis algorithm 
section compare performance limited discrepancy search techniques theoretical properties search space 
section discuss variations lds believe useful solving real world problems 
experimental results chapter 
existing strategies consider tree search problem successor ordering heuristic leads directly solution 
problems common practice areas ai research planning scheduling 
heuristic satisfied algorithm follows heuristic just gives heuristic fails lead solution algorithm call 
performance satisfactory confronted question search algorithm leads chapter 
limited discrepancy search dead 
iterative sampling backtracking candidates 
iterative sampling iterative sampling isamp simple idea random paths probes root eventually discovering path leads solution 
node path successors selected random expanded 
successors selected random reaching goal node dead 
path ends dead isamp starts new probe root 
algorithm samples replacement chance probe ends goal node affected failure earlier probes 
assuming fixed number solutions reduce chance finding solution arbitrarily small positive amount samples 
iterative sampling shown effective problems solution density high performance fallback procedure questionable ignores successor ordering heuristic 
heuristic key solving problem despite low solution density expect iterative sampling effective 
experimented biasing random selection successors heuristic results discouraging see section 
backtracking alternative fallback procedure simply backtrack chronologically fails 
experiments section scheduling show falling heuristic chronological backtracking provide improvement analysis mistakes chapter provides explanation 
reasonable chance early path mistake selecting successor goal nodes entire subtree 
early mistake committed successor subtree subsequent decisions difference 
chapter 
limited discrepancy search subtree mistake large chronological backtracking spend allowed run time exploring empty subtree making back decision mattered 
counting heuristics find goal node small fraction search space chronological backtracking puts tremendous burden heuristics early search relatively light burden heuristics deep search 
unfortunately problems heuristics reliable early search making decisions reduce problem size heuristics reliable 
uneven reliance heuristics chronological backtracking making best heuristic information 
nonsystematic methods nonsystematic backtracking strategies address problem early mistakes time heuristic information 
experimental results depth search restarts rdfs variations iterative broadening sib bbs chapter 
methods balance dependence heuristics need search alternatives making random moves time heuristic recommendation 
standpoint relying heuristics methods fundamentally isamp go detail describing algorithms 
discrepancies return tree search problems successor ordering heuristic leads directly solution 
concern cases heuristic lead solution 
intuition fails heuristic probably lead solution wrong turns got track 
ought possible systematically try heuristic decision point 
fails try heuristic decision points 
chapter 
limited discrepancy search number wrong turns small find solution restricted searches space 
call decision points follow heuristic discrepancies 
limited discrepancy search embodies idea iteratively searching space limit number discrepancies allowed path 
iteration limit zero discrepancies just 
iteration searches possibilities discrepancy 
algorithm shown 
assume search tree binary 
successors function returns list zero successors heuristic preference 
tree required full binary tree examples full trees 
discrepancy limit 
iteratively call lds probe increasing time 
lds probe depth search traversal tree limiting number discrepancies eventually reaches maximum depth tree lds probe searches entire tree exhaustively 
search guaranteed find goal node exists guaranteed terminate goal nodes 
iteration lds probe limits number discrepancies restricting search nodes exactly discrepancies iteration nodes iterations gamma examined see 
see section redundancy significant factor complexity search 
shows trace lds exhaustively searching full binary tree height 
heuristic orders nodes left right 
pictures show paths depth order 
dotted lines open circles represent nodes backtracked previous picture follow trace looking pictures sequence 
counting black circles gives total number nodes expanded search 
nodes lot fifteen number nodes depth search require search tree exhaustively 
take closer look amount redundancy 
chapter 
limited discrepancy search lds probe node goal node return node successors node null return nil return lds probe result lds probe second gamma result nil return result return lds probe lds node maximum depth result lds probe node result nil return result return nil limited discrepancy search 
upper bounds introduced limited discrepancy search argued failed heuristic probably wrong turns 
consider full binary search tree height 
possibility depth zero discrepancies 
possibilities discrepancy 
iteration lds probe discrepancy limit expands nodes average fringe node 
searching space restricted discrepancy requires examining nodes 
iteration zero discrepancy limit examines nodes 
regarding iteration redundant nodes small fraction examined iteration 
chapter 
limited discrepancy search ffl omega omega ffi delta delta delta delta delta delta ffi delta delta delta delta delta delta ffi ffl ffl omega omega ffi delta delta delta delta delta delta ffi ffl omega omega ffi delta delta delta delta delta delta ffi delta delta delta delta delta delta ffi ffl ffl ffl omega omega ffi ffl omega omega ffi delta delta delta delta delta delta ffi delta delta delta delta delta delta ffi ffl ffl omega omega ffi delta delta delta delta delta delta ffi ffl omega omega ffi delta delta delta delta delta delta ffi delta delta delta delta delta delta ffi ffl ffl ffl ffi iteration ffl omega omega ffi delta delta delta delta delta delta ffi delta delta delta delta delta delta ffi ffl ffl omega omega ffi delta delta delta delta delta delta ffi ffl omega omega ffi delta delta delta delta delta delta ffi delta delta delta delta delta delta ffi ffl ffl ffl omega omega ffi ffl omega omega ffi delta delta delta delta delta delta ffi delta delta delta delta delta delta ffi ffl ffl omega omega ffi delta delta delta delta delta delta ffi ffl omega omega ffl ffl ffi iteration ffl omega omega ffi delta delta delta delta delta delta ffi delta delta delta delta delta delta ffi ffl ffl omega omega ffi delta delta delta delta delta delta ffi ffl omega omega ffl ffl omega omega ffi ffl omega omega ffl omega omega ffl ffi iteration ffl omega omega ffl omega omega ffl omega omega ffl iteration execution trace lds 
chapter 
limited discrepancy search easy see number possibilities discrepancies depth tree 
ignoring internal nodes cost iteration grows factor 
suggests upper bound total number possibilities examined iterations algorithm exhaustively searching space restricted fewer discrepancies gamma gamma factor comes fact iteration explores possibilities discrepancies exactly discrepancies 
iteration examines possibilities 
iteration examines 
iteration examines 
rewrite equation gamma dropping second sum replacing sum get upper bound 
bound total cost iterations grows increases suggesting cost earlier iterations insignificant compared 
small tighter upper bound derived approximating gamma gamma kd gamma gamma gamma gamma xd gamma second sum equation form ja closed form solution gamma gamma chapter 
limited discrepancy search gamma gamma gamma gamma xd gamma gamma gamma gamma large gamma approximately upper bound number possibilities searched lds discrepancy limit approximately large search spaces clear small values practical interest 
experiments job shop scheduling small meant 
likelihood finding solution recognizing search problems time search space exhaustively know likelihood finding solution various methods amount time willing wait 
precise formalize mean heuristic wrong turn 
wrong turns simplicity consider case full binary tree 
children choice point assumed order heuristic preference 
assume choice point goal node subtree probability heuristic probability child goal node subtree 
gamma chance child goal child goal choice point children 
case heuristic wrong turn putting children wrong order 
notion wrong turn closely related mistake probability 
chapter defined bad node node goal nodes subtree 
defined mistake bad node parent bad 
mistake probability probability randomly selected child node bad 
heuristic orders successors randomly heuristic probability dual chapter 
limited discrepancy search mistake probability gamma heuristic better random selection gamma conceivably heuristic worse random selection case better just 
worst possible heuristic anti heuristic gamma making wrong turn possible opportunity 
shows possibilities node children 
indicates bad node solid dot node 
probability node class classes left children class class parent bad 
mistake probability half probability node classes mistake child conditional probabilities combinations follow shown 
omega omega omega omega omega omega omega omega omega omega omega omega omega omega omega omega theta ffl ffl ffl theta theta theta theta ffl ffl ffl ffl pr gamma pr gamma pr gamma pr pr gamma gamma pr possibilities node children 
chapter argued mistake probability constant depths tree 
experimentally assumption reasonable lead analytical estimates expected run time various algorithms 
particular chance finding solution random path depth isamp simply gamma heuristics probability finding solution path 
see 
cases exhaustive pr pr zj 
gamma 
chapter 
limited discrepancy search estimating heuristic probability derive estimate running large training set problems domain interest 
success rate training set 
probability small training set may impractically large get reliable estimate 
problems small 
heuristics developed job shop scheduling shown yield probability nearly small research problems 
earlier experimental problems standard csp heuristics yield success rate percent 
larger scheduling problems success rate sophisticated heuristics operations research keep competitive search techniques :10.1.1.36.7506
appears large tree search problems heuristics key finding solution small fraction search space 
conditions lds offer substantial improvement 
analysis early iterations preliminaries early iterations limited discrepancy search important practically large problems cost successive iterations grows rate quickly exceeds reasonable amount time willing wait 
focus attention second iteration probes 
simplify analysis assume start iteration skipping probe normal lds run 
searching discrepancy limit includes path zero discrepancies get probe iteration 
heuristic path fact probe iteration shown 
shows probes discrepancy iteration search tree height 
assume problem solution root node node drawn solid dot 
know priori goodness internal nodes drawn open circles 
sake analysis chapter 
limited discrepancy search theta omega omega ffi omega omega ffi omega omega ffi omega omega ffl theta ffi omega omega ffi omega omega ffi omega omega ffl theta omega omega ffi ffi omega omega ffi omega omega ffl theta omega omega ffi omega omega ffi ffi omega omega ffl theta omega omega ffi omega omega ffi omega omega ffi ffl probes iteration 
assume analyzing particular probe earlier probes failed helpful draw terminal nodes bad nodes 
nodes numbered probe starting root node zero 
useful define propositions search tree height ffl node probe node 
ffl succeed ffl redundant succeed define probabilities ffl pr redundant ffl pr succeed redundant ffl pr redundant conditional probability probe succeeds objective calculate likelihood finding solution probes terms tree height denote probability probability finding solution probe example just probability finding solution probes minus probability failing find solution second probes 
failures independent chapter 
limited discrepancy search events second probes node see 
decision probe going right possible explanation probe failure 
decision mistake decision second probe going left 
failure probe increases likelihood second probe succeed 
failure second probe increases likelihood third succeed second decisions third nodes alternatives 
failure second probe decreases likelihood third succeed decisions second nodes 
conditional probability probe succeeds earlier probes failed 
probe succeed decisions path mistakes 
probability node path succeeds parent just product knew calculate original objective 
conditional probability node probability node unaffected failure earlier probes contain node parent 
derive expressions cases case easiest failure earlier probes obviously unrelated 
node left child node pr example conditional probability node probe affected redundant fact probes failed 
case affected failure earlier probes 
node probe probability node just probability node pr gamma gamma assume path node ends goal independent success failure probes nodes common 
chapter 
limited discrepancy search case affected redundant condition 
ground reasoning example specific lift example case gamma generalize result case consider likelihood node probe parent 
parent node failure probe increases likelihood decision go right node probe reason probe failure node 
probability node probe parent probe failed treating node classes predicates subscripting coordinates parent node see pr redundant pr applying bayes rule pr pr entailed events ratio probabilities events conditioned ratio unconditional probabilities 
pr pr pr pr pr shows pr pr pr 
pr pr pr 
pr pr pr pr 
chapter 
limited discrepancy search pr pr pr pr pr pr pr pr substituting values gamma gamma gamma gamma gamma gamma gamma mp mp gamma case gamma general form equation pr redundant condition redundant means earlier probes failed 
assumed failures probes containing node affect replace redundant symbol meaning earlier probes containing node failed 
dropping subscripts pr pr xf zf applying bayes rule equation pr xf pr xf zf equation add condition entailed events 
pr xf pr xf zf chapter 
limited discrepancy search pr pr fj pr pr fj pr pr jx pr xj pr jy pr pr jx pr xj pr jy pr pr jz pr zj letting stand pr pr pr pr pr pr zj gamma earlier probe probe gamma contains node chance fails node gamma pr gammaj gamma 
node probe definitely fails 
gamma pr gamma pr gammaj gamma pr pr gamma pr gammaj gamma substituting values gamma gamma gamma gammaj gamma gamma gamma gamma gammaj gamma gamma gamma gamma gammaj gamma case general form equation different values failure earlier probes irrelevant earlier probes contains node gamma probe gamma relevant contains node gamma 
gamma probes gamma gamma contain node gamma 
general gamma previous probes relevant 
earliest chapter 
limited discrepancy search probes relevant node gamma case gamma gamma decisions earliest probe mistake 
probability gamma pr gammaj gamma scaling term equation 
remaining gamma previous probes relevant node gamma regard previous gamma probes starting depth independent smaller problem height gamma gamma setting recurrence see 
theta omega omega ffi omega omega ffi omega omega ffi omega omega ffl theta ffi omega omega ffi omega omega ffi omega omega ffl theta omega omega ffi ffi omega omega ffi omega omega ffl theta omega omega ffi omega omega ffi ffi omega omega ffl theta omega omega ffi omega omega ffi omega omega ffi ffl discrepancy component example failure boxed nodes probability gamma component expression probability gamma previous probes fail node gamma gammaj gamma gammaj gamma compute form equation follows pr gamma gammaj gamma gammaj gamma gamma pr gammaj gamma gamma gamma gammaj gamma gammaj gamma gamma gammaj gamma pr gamma gammaj gamma gammaj gamma gamma gamma gammaj gamma gammaj gamma pr gamma pr gammaj gamma gamma gamma gammaj gamma node gamma gamma probes succeed bad depth gamma 
chapter 
limited discrepancy search probability success probes define observing probability finding solution zero probes zero 
equations combination equations define terms definitions follow directly 
probability non redundant probe succeeds product probabilities node path gamma chance finding solution probes fewer chance finding solution gamma probes fewer gamma gamma times chance finding solution probe earlier probes failed gamma gamma 
probability finding solution probes fewer gamma gamma gamma gamma gamma graphs shown section 
comparison curves drawn analogous curves chronological backtracking iterative sampling 
success probability chronological backtracking remarked section successor ordering heuristics marginal effect performance chronological backtracking 
expected cost search dfs gamma gamma mistake probability constant factor equation 
replacing gamma equation reduces cost gamma times original exponential number nodes heuristic successor ordering effect replacement 
compare probability success time limited discrepancy search 
calculated backtracking chapter 
limited discrepancy search recurrence ps gamma gamma gamma gamma gamma probability finding solution tree height nodes times probability finding solution left subtree fewer nodes plus gamma times probability right subtree minus number nodes left subtree parent 
take 
calculation measured number nodes examined lds calculations measured number probes probe potentially nodes counting root 
compensate difference give backtracking nodes probe plus 
success probability iterative sampling iterative sampling samples replacement probability probes fail product probabilities individual probes fail 
probe fails likelihood gamma gamma success probability iterative sampling samples isamp gamma gamma gamma comparison existing techniques figures show theoretical success probability curves iterative sampling isamp chronological backtracking dfs limited discrepancy search lds various heuristic probabilities graphs show probability probability gamma left child mistake case search wastes gamma nodes examining left subtree plus parent 
number somewhat smaller average lds restart root node probe 
relative advantage chronological backtracking draws extra nodes negligible fact obvious graph 
chapter 
limited discrepancy search finding solution number probes dfs curve nodes probe plus 
highest heuristic probabilities shown 
number probes probability success pi lds pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi lds lds ffi lds ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffl isamp ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl dfs problem height 
problem height mistake probability 
problem fringe nodes goals 
solution density expect iterative sampling sample fringe nodes finding solution exact 
accounts problem solution density fairly easy problem 
takes nodes average find solution iterative sampling 
expected number probes slightly number probes required find solution percent probability 
number goals gamma expected number probes gamma example expected number coin flips getting heads takes single coin flip percent probability getting heads 
number probes required achieve success probability log gammas gamma gammam log gamma gammam chapter 
limited discrepancy search practice may interested number nodes required find solution higher probability success 
number nodes required iterative sampling percent success probability problem 
compare performance limited discrepancy search 
lds percent probability just eleven probes nodes 
savings nearly factor depends heuristic order successors correctly times successors mistake 
gamma heuristic orders successors correctly half time better random selection 
curve shows performance lds slightly worse iterative sampling conditions 
heuristic orders nodes correctly times 
curves show expected performance lds increases dramatically better dfs curve rises marginally probability fringe node goal 
futility dfs clear deeper search shown 
problem height quite nodes 
density solutions theta gamma iterative sampling needs probes nodes percent chance success 
earlier problem heuristic orders nodes correctly times lds percent chance just probes nodes order magnitude savings iterative sampling 
savings factor success probability percent 
percent orders magnitude savings doubtful doubtful graph suggest 
discrepancy iteration ends probes 
probes discrepancy iteration path common see likelihood probes succeeds failed small 
probes discrepancy iteration begins explore fresh paths 
consequently expect lds curve rise steadily graph leaves 
probability fringe node examined dfs goal simply chapter 
limited discrepancy search number probes probability success pi lds pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi lds lds ffi lds ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffl isamp ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl dfs problem height 
variations extensions reason focused analyzing early iterations limited discrepancy search believe practice iterations matter 
earlier argued mathematical grounds important iterations 
take position practice iterations don matter 
reason objective maximize probability finding solution number nodes promising things nodes iterations limited discrepancy search 
section discusses promising things 
involve combinations techniques depend search space properties difficult quantify discussion formal earlier sections 
view limited discrepancy search tool combination techniques craft effective search procedure real world problem 
chapter 
limited discrepancy search variable reordering constraint satisfaction problems sat problems formulated tree search fixing order variables instantiated determining order dynamically search progresses 
case node search tree choice point possible instantiations particular variable 
effective heuristic solve problem limit discrepancy chosen variable order may solve problem discrepancy different variable order 
wrong turn instantiations heuristic variable order may follow unit propagation second 
suggests simple technique repeating discrepancy iteration lds different variable orders 
variable order determined dynamically may suffice just search different variable iteration 
related experimental results section 
different heuristics alternative heuristics try repeating discrepancy limit iterations lds different heuristics 
heuristic unlucky wrong turns problem heuristic may 
general hard heuristic may hard 
lds effective way give heuristic reasonable chance switching secondary heuristic 
combining lds bounded backtrack search lds easily combined bounded backtrack search produce algorithm count discrepancies fail quickly discrepancy limit 
combined algorithm alternative lds 
experimentally lds bbs algorithm outperforms lds bbs job shop scheduling problems see section 
scheduling lds bbs appears algorithm choice nonsystematic backtracking strategies 
compelling theoretical argument performs chapter 
limited discrepancy search lds bbs probe node lookahead goal node return successors node reverse child break gamma hresult lds bbs probe child lookahead max height result nil return hresult height lookahead return hnil lds bbs node lookahead maximum depth hresult lds bbs probe node lookahead result nil return result return nil limited discrepancy search bounded backtrack 
chapter 
limited discrepancy search better lds 
chapter mistakes resulted quick immediate failures 
heuristic wrong turns fewer wrong turns exceed backtrack bound 
adding bounded backtrack enables limited discrepancy search discover solutions discrepancy limit number wrong turns exceed backtrack bound potentially reducing number required iterations 
cost lds iteration grows factor savings substantial 
added cost backtrack bound relatively insignificant 
adding backtrack bound node cost factor 
backtrack bound costs factor upper bound conservative heuristic assumption mistakes 
local optimization lds problems scheduling lds search neighborhood existing solution 
discrepancy iteration lds modified path previous best solution heuristic 
depth discrepancy algorithm diverges previous solution follows heuristic remaining decisions 
path ends solution better previous best adopted immediately stored contender basis iteration 
variation lds requires measure goodness solution 
scheduling problems schedule length appropriate measure 
searching schedule takes time successful produces schedule takes time set standard lds iterations repeated lower time bound optimization variant lds applied consider variations previous schedule differ discrepancy 
cost factor node 
paths longer 
alternatively time bound adjusted binary division 
single iteration lds decision procedure failure find schedule time bound proof schedule exists 
chapter 
limited discrepancy search limited discrepancy search effective way heuristic information tree search problems 
experiments see section experiments researchers shown chronological backtracking 
analysis attempted offer explanation 
chapter presents experimental findings corroborate theoretical expectations 
experimentation general csp heuristics applied job shop scheduling problems 
weak heuristics variations limited discrepancy search best algorithms tested 
lds sensitive techniques accuracy heuristics expect improving heuristics greater effect lds alternatives 
consequently optimistic applicability lds solving real world problems heuristics tuned high degree accuracy 
chapter experimental results chapter 
experimental results body experimental job shop scheduling problems 
chose domain number reasons 
scheduling problem obvious practical significance problem studied research communities artificial intelligence operations research 
known np complete job shop scheduling representative large class problems important frontier tractability 
hope algorithms thesis apply useful domains 
certainly intuitions theoretical arguments broadly applicable 
analyzed search space properties algorithms efficient formulas computing expected performance algorithms properties 
chapter put theoretical arguments test 
prior conducting experiments profiled search spaces small job shop scheduling problems ascertain theoretical properties exist 
results profiles job shop scheduling comparison random sat appendices scheduling domain appear necessary properties 
evaluate performance algorithms chose established benchmark job shop scheduling problems 
ran variations algorithm hopes measuring algorithms best efforts determining sensitive particular choices parameters 
report findings evaluation performance nonsystematic backtracking strategies 
compare results existing ai search techniques scheduling programs 
section investigate algorithms individually detail 
report topics relating heuristics affect algorithms 
chapter 
experimental results scheduling csp job shop scheduling known np complete problem finding schedule set nm operations various durations machines subject set sequence constraints bound length schedule 
operations organized sequences jobs operations 
operations job assigned different machines 
machines unordered set operations performed operation job 
desired schedule set start times operations satisfying conditions operations machine overlap operations job performed sequence overlap operations complete time allowed bound schedule length 
problem formulated constraint satisfaction problem finding total order operations machine satisfying sequence constraints jobs 
total order operations derived gamma binary decisions pairs operations 
pair distinct operations ha machine precede precede machines mn gamma decisions 
csp formulation ordering decisions variables 
domain constraint satisfaction problem solved tree search branching possible values variables predetermined dynamic order 
csp implementations job shop scheduling amount constraint reasoning propagate effects ordering decisions 
typically ordering decisions forced effects resulting far fewer mn gamma real choice points 
tree search formulation variable instantiations follow constraint reasoning constitute nodes 
path root tree terminal node consists sequence mn gamma binary decisions node children 
paths consist different numbers problem statement np completeness proof garey johnson allows jobs fewer operations stipulates adjacent operations job machine 
ease representation job shop benchmarks operations job machine 
chapter 
experimental results choice points tree necessarily uniform depth 
order variables instantiated values assigned dramatic effect size search trees efficacy search algorithms 
experiments applied standard csp heuristics domain 
heuristics weak scheduling standards provide clear benchmark measuring relative performance search algorithms 
measuring performance number ways evaluate performance search algorithms scheduling problems 
described job shop scheduling satisficing problem find schedule meets certain set criteria 
evaluation method satisficing problems compare long takes algorithm find solutions problems benchmark 
algorithm solve problems amount time willing wait 
algorithm lose 
losing strong penalty penalize algorithm relative solve problems 
evaluation method compare number problems solved time limit problem 
scheduling problems typically fairly easy search algorithm solve extremely hard 
consequently relative performance search algorithms particularly sensitive time limit chosen problem reasonable time limit usually easily nearly 
benchmark consisting large set problems scores search algorithms indications performance 
scheduling domain third evaluation method arguably representative algorithm utility solving real world problems 
real world scheduling optimization problem find schedule minimum length 
performance search algorithms scheduling problems measured lengths schedules able find amount time 
reported early results graphing time required solve percent problems 
curve transpose cumulative distribution function demonstrated scores method quite reasonable scheduling problems 
chapter 
experimental results vaessens aarts lenstra compute schedule percent optimal length optimizing search algorithm produces shorter schedules run time :10.1.1.36.7506:10.1.1.36.7506
function search algorithm taken percent optimal length best schedule find fewer nodes 
benchmark problem average problems benchmark 
keeping vaessens call mean relative error mre 
evaluation criteria considered mre curves appear clearest measurement performance 
formulated csp scheduling optimization problem 
transform satisficing problem optimization problem run search algorithms iteratively decreasing bound schedule length time slightly length schedule 
point time algorithm best schedule basis computing job shop scheduling benchmark consisted thirteen problems taken operations research literature 
problems varied size theta theta theta jobs machines 
depths search trees varied range choice points 
comparison ai techniques shows performance basic nonsystematic backtracking strategies discussed thesis bounded backtrack bbs limited discrepancy lds depth search restarts rdfs iterative broadening sib combination lds bbs lds bbs 
compare performance performance iterative sampling chronological backtracking dfs 
clearly demonstrates effectiveness nonsystematic strategies 
nodes iterative sampling achieves mre percent chronological backtracking percent 
nonsystematic backtracking strategies percent range 
exception iterative broadening nonsystematic algorithms optimal length taken length best reported schedule problem november 
problems available electronically sending message ic ac uk 
chapter 
experimental results appear fairly predictable 
node limit problem thousands avg 
percent optimal ffl dfs ffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl ffl ffi rdfs ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi sib lds bbs isamp bbs pi lds pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi iterative sampling chronological backtracking competitive 
interesting note chronological backtracking progress short amount time 
corroborates theoretical predictions performance chronological backtracking 
researchers observed phenomenon responded writing backtrack free tree search algorithms terminology 
shown chronological backtracking may effective run time nonsystematic backtracking strategies 
compares performance various nonsystematic backtracking strategies 
difference percent may small quite large context just better algorithms 
discuss basic nonsystematic strategies individually sections chapter 
strategies number variations parameters chapter 
experimental results node limit problem thousands avg 
percent optimal ffi rdfs ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi sib lds bbs bbs pi lds pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi pi front runners 
affect search 
graph chosen representatives strategies 
point basic algorithms performance dramatically affected different choices parameters long reasonable 
imagine algorithm perform set problems parameters tuned magic values dramatically better values 
appears case algorithms 
comparison techniques thirteen problems benchmark picked random 
survey operations research results job shop scheduling uses exact set thirteen chapter 
experimental results problems :10.1.1.36.7506
benchmark compare results results large community researchers 
authors programs mre ratings survey reproduced 
author program mre dell ts ts shuffle sa rcs shuffle bottle sb ga sa sa sb ga sb bottle gls bottle sb gls ga ta ga sbi results survey benchmark 
scheduling thesis objective write scheduler compete programs reported survey 
important problems test search algorithms representative problems people care 
goal achieve respectable performance established benchmark solely advances search technology 
best results percent mre range 
performance chapter 
experimental results best scheduling results respectable standards dedicated scheduling programs 
scheduling programs survey fit broad categories local search techniques genetic algorithms constraint satisfaction neural networks 
best reported results come local search technique known taboo search authors survey point benefits come expense non trivial amount testing tuning 
best representative survey constraint satisfaction program rcs program randomized constraint satisfaction 
incorporating bottleneck reasoning derived sadeh better heuristics restarts rcs extremely strong performance backtrack free tree search algorithm 
rcs type program potentially benefit search results thesis 
performance strategies stochastic iterative broadening thesis referred earlier introduced iterative broadening algorithm 
search space property possible mistakes lead subtrees goal nodes see chapter analysis iterative broadening showed iteratively searching tree uniform branch factor artificial smaller branch factor cutoff increased iteration produce orders magnitude savings expected time find solution 
eventually reach iteration algorithm guaranteed search entire space eventually return solution existed 
adapted iterative broadening algorithm binary search trees fractional branch factor 
number children expanded particular node determined probabilistically 
branch factor cutoff second child expanded probability 
likewise second child expanded probability 
technique branch factor cutoff increased rate successive iterations 
call technique chapter 
experimental results stochastic iterative broadening sib 
experimented various rates increase branch factor cutoff various non increasing fixed values 
intuition may fixed value optimal particular domain 
increasing value iterative broadening quickly pass optimal value causing allowed run time spent iterations large branch factor 
results shown 
node limit problem thousands avg 
percent optimal ffl ffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi iterative broadening cutoff surprised learn increasing successive iterations standard iterative broadening manner outperformed fixed values considered 
furthermore sib competitive sophisticated backtracking strategies 
chapter 
experimental results appears experiments serious drawback iterative broadening performance time unpredictable 
example experiment run nodes drawn vastly different optimal branch factor cutoff 
performance nonsystematic methods vary different domains iterative broadening remains viable alternative 
job shop scheduling bounded backtrack limited discrepancy techniques appear better suited domain 
backtracking restarts chapter introduced rdfs simple modification chronological backtracking periodically restarts root 
algorithm orders children node randomly explore portion search tree time restarts 
performance rdfs shown 
simple algorithm performance extraordinarily 
chosen timeout parameter yields mre points sophisticated algorithms 
choice timeout parameter appears important 
rdfs achieves approximately mre nodes nodes 
explanation extra nodes iteration node timeout significantly improve likelihood probe finding solution 
performance rdfs fairly sensitive variable value ordering variations 
see section section complete discussion variations 
commented chapter rdfs closely related bounded backtrack search 
expected performance similar bbs experiments corroborate expectation 
discuss see section bbs practical situations rdfs 
strong performance rdfs emphasizes easily early mistakes problem chronological backtracking overcome 
chapter 
experimental results node limit problem thousands avg 
percent optimal ffl ffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi backtracking restarts timeout iterative sampling constraint satisfaction problems term iterative sampling loosely applied algorithms differ important ways 
choices randomize variable order randomize value order 
possible combinations performance graphed 
tree search definition iterative sampling randomizes values variables 
csp definition isamp randomizes values variables 
backtrack free heuristic algorithm calling randomizes values variables 
combination previously unnamed call randomizes variables values 
striking result experiment algorithm didn name best performance variations chapter 
experimental results node limit problem thousands avg 
percent optimal ffl random variable random value order isamp ffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi heuristic variable random value order iterative sampling ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi random variable heuristic value order heuristic variable heuristic value order variations iterative sampling 
significant margin 
probably escaped prior attention legitimate algorithm properties difficult characterize understanding formal sense variable value ordering heuristics 
quite possible example amount run time reduce probability finding solution solvable problem positive ffl 
dominant performance deserves notice just importance variable ordering see section related experiments 
interesting heuristic variable order appears better random values chosen randomly margin somewhat convincing 
see nodes common variations algorithm catches technique single heuristic path 
fairly weak heuristics experiments effect amplified practice carefully tuned heuristics 
chapter 
experimental results bounded backtrack search chapter gave bounded backtrack algorithm binary search trees 
straight forward generalization bbs trees arbitrary necessarily uniform branch factor 
generalized bbs algorithm called reprinted 
implementation names bbs interchangeably 
bounded backtrack basically capacities simple way improve existing algorithms isamp stand search algorithm competitive merits 
shows results bounded backtrack capacity 
node limit problem thousands avg 
percent optimal ffl isamp node lookahead ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi isamp lookahead ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi adding bounded backtrack isamp major improvement 
result adding just node bounded backtrack isamp fairly dramatic reducing mre 
value competitive chapter 
experimental results nonsystematic methods algorithms hardly surprising 
isamp simple algorithm uses heuristics 
competitive question progress research field 
point graph just show bounded backtrack effective speed technique 
second capacity tuned making decisions randomize variable value order lookahead value backtrack bound 
randomizing variable value order decision affects nonsystematic algorithms consider issues separately section section 
compares performance different lookahead values 
node limit problem thousands avg 
percent optimal ffl ffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi small lookahead value works slightly better 
find experiments confirm theoretical projections particular choice lookahead parameter tremendously significant chapter 
experimental results range reasonable values 
practical impact easy tune 
trying increasing powers example generally sufficient experimentation get nearly optimal performance 
search trees nonuniform depth easier pick efficient reliable backtrack bound pick restart timeout rdfs backtrack bound independent length solution paths restart timeout 
limited discrepancy search isamp limited discrepancy search improved adding bounded backtrack 
shown bounded backtrack performance extremely 
lookahead nodes best performance algorithms tested 
strong reasons believe variations lds promise application real world problems 
commented earlier value ordering heuristics real world problems tuned higher degree accuracy 
lds gain improvement 
remarkable success shows importance variable ordering particular effectiveness trying different variable orders 
expect running discrepancy iteration lds iteratively different variable orders increasing discrepancy limit tremendous potential 
limited discrepancy search viewed way get lot mileage accurate value ordering heuristic 
basic idea customized incorporated types search strategies appropriate domain 
scheduling sat csp formulation scheduling problem translated satisfiability problem ordering decisions propositions theory extremes chronological backtracking iterative sampling performance claiming significantly different 
chapter 
experimental results node limit problem thousands avg 
percent optimal ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi bounded backtrack improves lds 
enforces temporal coherence constraints scheduling problem 
details translation crawford baker report experimental results applicability satisfiability algorithms scheduling 
compare nonsystematic backtracking strategies wsat wrote davis putnam style satisfiability engine modeled crawford tableau program 
search algorithm sat engine able compare bounded backtrack search wsat common problem representation 
results shown 
translation sat yields efficient problem representation severely limiting size problems able test 
sadeh benchmark expansion factor problems tested 
chapter 
experimental results timeout problem units nodes tree search flips wsat problems solved ffl dfs ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi bbs ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi bbs isamp wsat wsat 
job shop scheduling problems 
problems megabyte sat form near limit workstations capacity converted internal representations search programs 
evaluated performance programs graphing number problems solved time crawford baker comment size sat problem representation scheduling problems order nd number operations number time points number constraints 
sadeh problems approximately time points operations 
problems main benchmark time points operations 
assuming nd term dominates calculation sat form main benchmark problems exceed megabytes problem 
internal representation additional super linear expansion factor 
chapter 
experimental results limit problem 
shows performance chronological backtracking isamp bounded backtrack variations comparison wsat 
expanding node tree search required approximately amount cpu time wsat required flips curves scaled appropriately 
shows isamp performs better wsat aid bounded backtrack 
isamp curve corroborates results crawford baker 
wsat curve crawford baker 
adding small bounded backtrack isamp appears small gain large bounded backtrack appears net loss 
node lookahead version bbs solves problems half time isamp 
chronological backtracking representing limiting case large backtrack bound yields disastrous results echo earlier experiments theoretical predictions 
help understand adding bounded backtrack isamp increase level performance significantly profiled search space sat scheduling problems manner originally understand search space properties bounded backtrack exploits 
results reported appendix complete profiles appendix due size search spaces 
appears mistake nodes small subtrees 
mistakes bounded backtrack help isamp avoid potential benefit bounded backtrack appears limited problem representation 
variations weakening value order heuristics avoid search path probe nonsystematic backtracking strategies select child expand random 
unfortunately selection purely random basis effect heuristically sorting children 
data represent performance wsat unit propagating quiescence original sat theory performing preprocessing steps 
performance wsat original theories direct translation csp form significantly worse 
chapter 
experimental results seen sorting children important solving hard problems 
middle ground weighted random selection satisfied demand non redundancy search completely disregarding advice heuristic 
scheduling problems binary search trees issue involves deciding children expand 
followed heuristic expand left child percent time 
selected randomly expand left child percent time 
probability yields better performance extremes 
compares performance iterative sampling selecting heuristic value percent percent percent time 
node limit problem thousands avg 
percent optimal ffl percent ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi percent ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi percent weighted random selection worse alternatives 
result experiment surprising 
curve weighted random chapter 
experimental results selection dramatically worse extremes 
repeated experiment implementation node bounded backtrack heuristic variable order iterative sampling uses random variable order 
curves selecting heuristic value percent percent percent percent time shown 
node limit problem thousands avg 
percent optimal ffl percent ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl fflffl ffl ffl ffl ffl ffi percent ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi percent percent weighted random selection better alternatives 
percent mre intermediate weights perform better extremes implementation 
weighting appears predictable tuning issue expected 
respect efficacy intermediate weighting values opposites 
explain difference need theoretical model encompassed effects variable ordering real problems 
suggest topic investigation 
see section discussion implementation weighted random value selection non binary branching factors 
chapter 
experimental results weakening variable order heuristics observed earlier experiments variable ordering heuristics scheduling occasionally produce bad variable orders 
restarting random variable orders eliminates problem time exploit heuristic 
nonsystematic techniques ought able take partial advantage heuristic committing particular order 
reasoning applied value ordering refuted experiments section conducted similar experiment variable ordering 
domains entire path variable instantiations largely determined selection variable 
starting probes nonsystematic algorithms random variables avoids problem pathological variable orders sacrificing heuristic net loss 
shows result walk start variable selection describe detail section 
search algorithm iterative sampling random value order 
shows performance walk start variable selection heuristic variable order search algorithm random order worse alternative 
efficacy depend formulation problem experiment indication type strategy 
value ordering experiments experiments predicted results 
incremental systematicity spirit iterative broadening considered algorithm increased backtrack bound level probe 
probes bound reach full height tree tree searched exhaustively 
modified algorithm report solutions terminated finding 
iterative algorithm seriously flawed successive probes took exponentially longer complete 
combining best elements systematic nonsystematic techniques combine worst ignored value ordering heuristic exhausted run time exploring paths failed chapter 
experimental results node limit problem thousands avg 
percent optimal ffl random variable order ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi heuristic variable order ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi ffi walk start variable order randomize variable order 
reason 
better modification suggested jonsson 
early decisions spread systematically starting successive probes fringe nodes depth limited search tree depth tried probe node depth tree increase start probe node tree depth 
example probe starts root tree 
increase 
full binary tree nodes depth second third probes start 
increase start probes nodes depth 
eventually reaches height tree tree searched systematically 
personal communication ari jonsson november 
chapter 
experimental results incremental systematicity modification bounded backtrack search gradually enforces probe different 
approach waste time exploring large subtrees additional appeal enforces systematicity top ignoring heuristic accurate 
details algorithm section shows performance cost incremental systematicity modification 
node limit problem thousands avg 
percent optimal ffl nonsystematic bbs ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi systematic bbs ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi incremental systematicity improves bbs 
expected modification guarantee completeness small cost 
surprised find cost whatsoever 
fact modification improved average case performance slightly 
repeated experiment iterative sampling 
results shown 
chapter 
experimental results node limit problem thousands avg 
percent optimal ffl nonsystematic isamp ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi systematic isamp ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi incremental systematicity iterative sampling 
evaluation algorithms shows clearly chronological backtracking effective computational resources problems job shop scheduling tree search possibility making early mistakes 
success search dependent heuristics attractive iterative sampling alternative 
discouraging progress depth search looks performance better iterative sampling problems tested 
find problem early mistakes surprisingly easy overcome nonsystematic methods retain benefits heuristics 
striking example restarting depth search periodically random value orders yields dramatic improvement rate progress performance small change original algorithm 
chapter 
experimental results best levels performance appear require sophisticated algorithms 
variations bounded backtrack limited discrepancy search scored percent optimal benchmark step nonsystematic methods large step iterative sampling chronological backtracking 
combination limited discrepancy bounded backtrack best performance algorithms tested 
problems benchmark large contemporary research standards considered large relative types sizes scheduling problems useful solve real world 
complexity scheduling challenge scaling research problems real world problems met quickly advances heuristics evolution brute force methods 
expect fullness time techniques depend heuristics recover gracefully search heuristics fail win techniques ability search depends ignoring heuristic advice 
chapter chapter 
motivated challenges solving real problems 
dating back developed iterative broadening improve performance search algorithms crossword puzzle generation 
ironically crossword puzzle generation discovered bounded backtrack search years 
iterative sampling belief heuristic importance systematicity freeing investigate nonsystematic backtracking strategies time 
early investigating systematic algorithms 
minor algorithmic improvements backjumping attempting gather experimental data show significance 
experiments 
large search spaces appeared hard improve search efficiency ruling provably bad parts space 
results draw scientific shape course research 
soon began exploring nonsystematic algorithms started measurable progress real problems 
noticed modifying iterative sampling spend time fringe tree improved efficiency 
related experiments periodically restarting depth search different variable orders virtually eliminated problem early mistakes 
incrementally experiments led discovery bounded backtrack search 
performance results 
small dictionary lisp implementation bounded backtrack search generate theta blank 
large dictionary containing dubious words generated theta largest computer generated blank crossword reported 
success crossword experiments turned attention understanding algorithm performed 
building iterative broadening research developed model strong intuitive basis 
explain bounded backtrack performance suspicion assumptions way linked crossword puzzle search 
validate generate new york times theta puzzles quite easily turned blank challenging benchmarks 
chapter 
results experimentally needed benchmark domain 
chose established benchmark scheduling problems operations research 
enabled compare results artificial intelligence search techniques dedicated scheduling programs 
scheduling experiments show conclusively bounded backtrack search improvement alternatives 
revealed weakness technique 
scheduling domain strong value ordering heuristics 
bounded backtrack search depends ignoring heuristic search new parts space 
experiments merits algorithm compensated loss heuristic larger problems heuristics important 
fundamentally thought ought way better value ordering heuristics 
thoughts motivated development limited discrepancy search 
relatively weak heuristics scheduling standards limited discrepancy search competitive best search algorithms tested 
technique value ordering heuristics expected performance improve relative techniques larger problems 
experimented combining limited discrepancy bounded backtrack search 
combination resulted best algorithms tested leading explore combinations variations algorithms 
experiments unexpected results 
course discovered clever way bounded backtrack search guarantee completeness small cost heuristic early stages search 
modification algorithm terminate proving problem solutions 
surprised discover addition guaranteeing completeness modification improved algorithm average case performance 
experiments unexpected positive results 
variation iterative sampling heuristic value ordering example turned remarkably performance 
productive lines research tend start gradually lead lines research 
experiments exception 
shown nonsystematic backtracking strategies eminently practical chapter 
experiments revealed facets searching large problems theoretical model tools analysis blunt explain 
search spaces real problems random 
solve large problems need acknowledge random need seek understand characteristics 
appendix related algorithms chronological backtracking iterative sampling iterative broadening closely related bounded backtrack search limited discrepancy search 
give pseudocode description algorithms 
notation node branch point possible values unassigned variable csp 
possible values values domain variable known inconsistent constraints problem 
appendix related algorithms chronological backtracking chronological backtracking depth search dfs systematically searches nodes tree run completion 
algorithm limited amount time run may return timeout signal lieu solution 
dfs node timeout return timeout result goal node return node child successors node result dfs child result nil return result return nil depth search time limit 
line loop sequentially assigns child elements successors list successors node 
node representing consistent total assignment recognized function goal node 
appendix related algorithms iterative sampling iterative sampling follows random path root tree node fringe 
algorithm terminates finds solution reaches time limit 
comparison algorithms give recursive implementation algorithm 
probe node timeout return timeout result goal node return node null successors node return nil return probe select randomly successors node iterative sampling node loop result probe node result nil return result iterative sampling 
probe line selects element random successors list 
successors list empty line returns nil 
iterative sampling returns solution timeout signal 
section modification algorithm guarantees exhaustive search tree run completion 
appendix related algorithms iterative broadening iterative broadening repeats restricted depth search considers successors node 
branch factor cutoff begins increases successive iterations 
tree constant branching factor th iteration searches tree exhaustively 
ib probe node timeout return timeout result goal node return node child successors node result ib probe child result nil return result gamma return nil return nil iterative broadening node result ib probe node result nil return result return nil iterative broadening 
dfs iterative broadening returns solution certificate solutions timeout signal 
iterative broadening suited tree search problems large branching factors 
section adapted algorithm binary search trees 
appendix profile job shop scheduling number ai studies scheduling benchmark set job shop scheduling problems developed sadeh doctoral thesis 
problems small easy contemporary standards embraced community large representative real world scheduling problems reasons ideal candidates profile attempt illuminate various important characteristics scheduling search spaces 
problems consist sets samples constructed randomly generating ready times deadlines certain distribution parameters sets 
details problem sets differ particularly important search space characteristics studying shared samples 
names problems 
problems consisted machines jobs job sequence operations performed machines non overlapping schedule operations jobs 
csp formulation problem see section search tree consists series ordering decisions jobs machine 
sadeh problems implies maximum search depth decisions 
orderings follow constraint propagation effective appendix profile job shop scheduling 
filename 
filename ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr ddr numbering scheme sadeh problems 
appendix profile job shop scheduling height search tree maximum path length legitimate decisions generally 
height varies substantially depending variable order heuristics determine ordering decisions consider see section 
profiled problems 
profiles generally random sat experiments discussed section sample set gives fair representation set problems large 
conserve space give full profile problems selectively cull mistake probability graphs profiles problems point relevant differences similarities 
chapter discussed differences search spaces scheduling problems searched variable order heuristics search spaces problems searched heuristics 
difference great profiles search heuristics search 
discussions presentation data follow sections 
search space heuristics shows distribution nodes nodes goals profiled portion search space problem 
profile search timeout nodes general large search entire space exhaustively 
graphs reflect data collected subtrees search spaces assume representative full search spaces respect relevant statistics see section 
shows contrast random sat problems proportion nodes nodes appears percent difficult region space 
important actual proportion mistake probability shown 
mistake probability low reasonably constant recorded range 
effective mistake probability lookahead extremely small range suggesting lookahead bounded backtrack algorithm may offer significant advantage iterative sampling 
appendix profile job shop scheduling individual problem number possible values mistake probability depth limited number nodes example depth zero node 
mistake probability defined children 
variable child mistake probability possible values 
profile search collect meaningful samples outside depth range graph mistake probability outside range statistically reliable 
figures chapter restricted range depths samples cutting noise ends 
appendix showing data leaving editing reader 
dramatic difference mistake probability lookahead zero brings question utility larger lookahead amounts bounded backtrack algorithms 
shows dramatic step zero effective mistake probability appears decrease linearly lookahead amount 
effective mistake probability decreased linearly random sat problems value substantially lower value 
gives information heights trees mistake nodes 
probability subtree mistake node height mistake node deep impossible 
graph shows vast majority subtrees height zero subtree heights appear fairly evenly distributed 
investigate zero height subtrees 
graph shows probability depth subtree mistake node height zero 
amazingly nearly entire space 
strongly suggests bounded backtrack algorithm lookahead offer significant improvement iterative sampling 
contrast graph relatively nodes high tree tall subtrees straight forward probability distribution mistake subtree heights heavily biased nodes deep tree 
defined way gives depths equal representation probability subtree mistake node height selecting mistake node random set nodes particular depth selected random set depths exceeding gamma appendix profile job shop scheduling random sat problems random sat zero space 
small mistake subtrees relevant performance iterative sampling dramatically affect performance systematic methods exhaustively searching subtree takes time nodes examine 
large mistake subtrees hand threat systematic methods reason 
fact mistake subtrees small encouraging depth search takes large mistake subtree destroy depth search average performance 
large subtrees exist 
shows subtrees height exceeding 
shows size subtrees nodes 
general appears size subtrees growing height larger mistake subtrees high tree profile search discover 
confirms average cost mistake subtree generally quite small maximum cost prohibitively large 
remaining figures section show mistake probabilities problems 
mistake probability appears roughly constant depth range 
near edges number samples get reliable estimate explains data 
appear mistake probability higher left side graphs suggesting may higher earlier search tree 
affect consistent intuitions scheduling problems unable confirm experimentally 
appendix profile job shop scheduling number nodes depth goal nodes ffl nodes fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi nodes ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi distribution nodes depth range sadeh rand 
ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl fflfflffl fflfflffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffiffi ffi ffi ffi ffiffiffi sadeh rand 
appendix profile job shop scheduling mk ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ratio sadeh rand 
ffl ffl fflffl ffl ffl ffl fflffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl fflfflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl sadeh rand magnified right 
appendix profile job shop scheduling ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl fflffl ffl fflffl ffl fflffl fflffl fflffl fflfflffl fflfflffl fflfflffl fflfflffl ffl ffl ffi gamma ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffiffi ffi ffiffi ffi ffiffi ffiffi ffiffi ffiffiffi ffiffiffi ffiffiffi ffiffiffi ffi sadeh rand 
log nodes subtree ffl mistake nodes ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi bad nodes ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi cost bad subtrees height sadeh rand 
appendix profile job shop scheduling cost number nodes subtree ffl mean cost ffl ffl fflffl ffl ffl ffl fflffl fflfflffl ffi max cost ffi ffi ffi ffi ffiffi ffi ffiffi ffi ffiffi ffi ffiffi ffi ffiffi ffiffi ffi ffiffi ffi ffiffi ffiffiffi ffiffiffi height subtree ffl mean height ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl fflffl fflfflffl ffl ffl ffi max height ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffiffi cost height bad subtrees depth sadeh rand 
ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl fflfflffl ffl fflffl fflfflffl fflffl fflffl fflffl fflffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffiffiffi ffiffi ffiffiffi ffiffiffi ffi sadeh rand 
appendix profile job shop scheduling ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl fflffl fflffl ffl ffl ffl fflffl fflffl ffl fflffl ffl fflffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffi ffiffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi sadeh rand 
ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl fflffl ffl ffl fflfflffl ffl ffl ffl ffl ffl ffl ffl ffl fflfflffl fflfflffl fflffl ffl fflffl fflfflffl ffl ffl ffl ffl fflffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffi ffiffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffiffi ffiffi ffi ffi ffi ffi ffi sadeh rand 
appendix profile job shop scheduling ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl fflffl fflffl ffl ffl ffl ffl fflffl fflffl ffl fflfflffl fflfflffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffiffi ffiffi ffi sadeh rand 
ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl fflffl fflffl ffl ffl fflffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffiffiffi ffi ffi ffi ffiffi ffi ffi ffi ffiffi ffi ffi ffi sadeh rand 
appendix profile job shop scheduling search space heuristics variable order heuristics csp formulation job shop scheduling attempt put critically constrained decisions see section 
effect preference reduce height search space 
heuristics solutions problem depths half deep search space problem heuristics 
proportion goal nodes nodes surprisingly high lower heuristics 
heuristics help 
mistake probability helps explain 
graph mistake probability constant graph effective mistake probability lookahead zero entire profiled range 
mistakes profiled range subtrees height zero 
graphs problems show similar effects 
problems solved depth search backtracking subtree height greater serious mistake nodes higher tree recorded range 
unfortunately tracking mistakes high tree exceed current computational resources 
shows cost bad subtrees appears growing take estimate rate growth full search space expect search space nodes range current resources profiling procedure 
interesting note search space variable ordering heuristics twice high cost bad subtrees growing half exponent 
leads speculate efficacy heuristics may derive reduction size search space conventional wisdom 
magic scheduling heuristics may subtle currently understand 
remaining figures section don show know graphs 
include figures comparison search space scheduling heuristics search spaces random sat problems 
easy interesting regions appendix profile job shop scheduling graphs 
showing distribution subtree heights non zero point 
shows ratio effective mistake probability lookahead mistake probability lookahead zero 
effect confirmed 
missing point depth graph reveals mistake nodes depth 
appendix profile job shop scheduling number nodes depth goal nodes ffl nodes ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflfflffl ffi nodes ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffiffi distribution nodes depth range sadeh heur 

ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi sadeh heur 

appendix profile job shop scheduling log nodes subtree ffl mistake nodes ffl ffi bad nodes ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi cost bad subtrees height sadeh heur 

ffl ffl sadeh heur 
magnified right 
appendix profile job shop scheduling mk ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ratio sadeh heur 

ffl fflfflffl fflffl ffi gamma ffiffiffi ffiffi sadeh heur 

appendix profile job shop scheduling ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflfflffl ffl ffl ffl fflffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi sadeh heur 

ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi sadeh heur 

appendix profile job shop scheduling ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi sadeh heur 

ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffi ffiffiffi ffiffi ffiffi ffiffi ffiffiffi ffiffi ffiffi ffiffi ffiffiffi ffiffi ffiffi ffiffi ffiffiffi ffiffi ffiffi ffiffi ffiffiffi ffiffi ffiffi ffiffi sadeh heur 

appendix profile job shop scheduling ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffi sadeh heur 

appendix profile job shop scheduling search spaces job shop scheduling problems appear low mistake probabilities depths variable order heuristics 
vast majority mistake subtrees height zero 
appears possible mistake high tree leads large subtree solutions 
combination search space properties suggests bounded backtrack search algorithm effective iterative sampling depth search 
heuristics peculiar effects mistake probability 
lookahead mistake probability varies dramatically depth range 
lookahead effective mistake probability zero entire depth range 
effects argue strongly bounded backtrack algorithm lead question understanding scheduling heuristics 
speculate efficacy heuristics may come subtle factors just reduction size search space 
earlier graphs figures showing job shop scheduling problems thesis identify problems problem number brevity 
mapping problem number filename problems sadeh thesis 
differences graphs chapter graphs section 
difference graphs chapter heuristics random value selection graphs section heuristic value selection see section explanation 
difference affects depth range properties graphs illustrate 
second difference earlier graphs minimum samples cutoff samples data point 
section cutoff sample graphed data points 
parsed versions files lisp readable format available web url cirl uoregon edu harvey 
appendix profile scheduling problems sat sat encoding sadeh job shop scheduling problems yields relatively large representations problems 
csp representation typical problem bytes sat representation typically larger megabyte 
sat formulations sadeh problems uses propositions clauses 
variables get assigned unit propagation actual number choice points decisions deepest path tree far fewer 
profiled sadeh problems represented sat encoding 
timeout nodes problems solved 
solutions solved problems depth approximately variable assignments followed unit propagation 
striking difference profiles profiles problems csp formulation number mistake nodes search space deep tree 
search space csp formulation fraught mistake nodes levels 
search space sat formulation apparently mistakes deep search tree 
deep tree sat formulation appears node bad sibling node sibling 
clearly tree goal node terminal node goal mistake node 
sat formulations mistakes appendix profile scheduling problems sat log nodes subtree ffl mistake nodes ffi bad nodes ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffiffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffiffi ffi cost bad subtrees height heuristics 
nodes examined 
profiled data sat formulation scheduling problems mistake probability approximately zero deep tree 
evidence small lookahead reduce effective mistake probability 
mistake node exist large tall subtree 
may mistake nodes smaller subtrees mistake nodes exist part search tree profiling methods able illuminate 
size tree record required data computer orders magnitude faster current resources 
due limitations graphs mistake probability omitted section 
recorded data sufficient show cost bad subtrees function height appears grow rate approximately contrast growth rate bad subtree cost csp formulations heuristics 
results shown graphs section 
appendix profile scheduling problems sat log nodes subtree ffl mistake nodes ffi bad nodes ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi cost bad subtrees height heuristics 
appendix profile random sat randomly generated sat problems propositional theories consisting propositions variables clauses 
clause disjunction literals literal variable negation 
empirically researchers difficult random sat problems generated fixing proportion clauses variables 
ratio believed crossover point point half random sat theories generated satisfiable half :10.1.1.21.2207
generated set random sat problems variables clauses near crossover point 
problems generated satisfiable 
profiled satisfiable problems davis putnam style satisfiability engine modeled crawford tableau program 
timeout nodes searched space problems exhaustively rest partially collecting statistics way discussed section statistics reveal number peculiar characteristics random sat search spaces strikingly different search spaces scheduling problems 
profiles problems fell evenly categories problem problem representatives 
problems category similar profiles problem problems second appendix profile random sat category similar profiles problem discuss differences section 
complete profiles problems figures section 
characterizing search tree decision point search contributes nodes search space assigning variable true assigning false 
variable assignments follow unit propagation count additional nodes 
search continues variables assigned variables assigned unit propagation actual height tree far height variable assignments unit propagation counted nodes 
solutions problems clustered depth tree shown 
problem number solutions depth appears idiosyncratic 
naively measure difficulty problem height tree average depth fringe nodes 
characterization search space misleading 
notice nodes depth greater nodes 
path depth ends goal node 
real difficulty problem getting nodes depth 
graph mistake probability shows decision depth choice bad variable assignment 
number nodes depth exactly 
nodes depth chance arriving nodes random path relatively small 
drop mistake probability consistent observation nodes deeper depth bad 
reason deep nodes fails appears depth clauses theory experimentally observed bad performance iterative sampling problems result appears consistent profile search space 
appendix profile random sat satisfied partial variable assignment partial variable assignment inconsistent theory 
clauses satisfied partial assignment possible assignment remaining variables consistent theory 
remaining variables full binary tree height path representing partial assignment 
difficult part search space upper tree height 
hanging paths difficult part full binary trees height consisting entirely nodes 
running experiments expected trees height consisting entirely bad nodes hanging difficult part 
large bad subtrees bear traps depth search 
account traps expected alternative search techniques bounded backtrack search branch factor cutoff search perform better surprise traps 
shows depth search bad subtree high negligible number nodes 
upper tree height difficult part problem 
getting part searching space tree way get large trees hanging difficult part paths difficult part representing partial assignments consistent theory 
tree search problem hard solving difficult part notwithstanding trees 
total assignment techniques presence trees may irrelevant nodes reached places search space necessarily having follow paths 
course search space arbitrary total assignments larger size tree searched davis putnam style algorithms unit propagation tradeoff trees nodes large cases number goal nodes represents quarter total number nodes entire search space ironic statistic problems proven extremely difficult solve 
appendix profile random sat obviously 
trying achieve pruning benefits unit propagation total assignment paradigm topic current research 
prospect efficiently searching fringe tree remains open question 
difficult part tree search techniques require finding successful paths difficult part search space upper tree height 
studying profile tree may able find characteristics search space exploited search algorithm improve average case performance 
mistake probability shown promising 
shows paths 
decision matters 
know earlier theoretical results see section tree full depth search outperform iterative sampling factor height tree 
tree full 
shows number nodes bad subtree height size bad subtrees appears growing significantly growth rate full binary trees 
hope reduce effective mistake probability lookahead 
shows heights mistake subtrees fairly evenly distributed distribution scheduling problems 
see exactly effect lookahead effective mistake probability 
data promising 
ratio goes drop suggest particular lookahead 
scheduling problems probability height mistake subtree zero extremely high nearly search 
random sat experiments shown empirically tradeoff random sat 
gsat variants outperform tree search algorithms orders magnitude problems 
growth rate holds true random sat problems crossover point independent size problem growth rate useful estimating search space size estimate lookahead equal depth tree impossible mistake 
effective mistake probability zero 
appendix profile random sat problems probability zero search see 
lookahead dramatically affect mistake probability scheduling problems effect whatsoever search tree random sat 
graphs problems profile problem shown 
difference mistake probability artifact data collection reflection difference search space 
timeout nodes able search problem exhaustively problem 
profiling problem search timed backtracking past depth 
shows second half search space missing difficult part 
part show consistent graph reason believe fundamental difference search spaces problems 
tableau style search engine uses variable ordering heuristics reduce size search space 
attempted profile space problems random variable ordering timeout increased fold nodes solutions 
profile data searches reach goal nodes properties relating mistakes obvious reasons don record mistakes 
search spaces scheduling problems number properties nonsystematic algorithms able exploit improve performance 
appendix attempted show profiling search spaces scheduling problems properties really exist 
method profiling search space large search exhaustively relies assumptions discuss appendix assumptions reasonable reason doubt appendix profile random sat hold wanted absolutely sure evidence collected artifact collection technique bug program 
needed control experiment compare results 
profile random sat problems served control 
appendix profile random sat number nodes depth goal nodes ffl nodes ffl ffl ffl ffl ffl ffl ffl ffl fflffl ffl fflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi nodes ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi distribution nodes depth range random sat 
ffl ffl fflfflffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi random sat 
appendix profile random sat ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl fflffl ffl fflffl ffl ffl fflfflffl ffl ffl ffl ffl ffl ffl ffl fflfflffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fflffl fflffl ffl fflffl ffl ffl fflfflffl ffl ffl ffl ffl ffl ffl ffl fflfflffl ffl random sat magnified right 
log nodes subtree ffl mistake nodes ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi bad nodes ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi cost bad subtrees height random sat 
appendix profile random sat mk ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ratio random sat 
ffl ffl fflffl ffl ffl fflfflffl ffl ffl ffl ffl fflffl ffl fflffl ffi gamma ffi ffiffi ffi ffi ffiffiffi ffi ffi ffi ffi ffiffi ffi ffiffi random sat 
appendix profile random sat cost number nodes subtree ffl mean cost ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi max cost ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi height subtree ffl mean height ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi max height ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi cost height bad subtrees depth random sat 
number nodes depth goal nodes ffl nodes ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi nodes ffi ffi ffi ffi ffi ffi ffi ffi ffiffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi distribution nodes depth range random sat 
appendix profile random sat ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi random sat 
log nodes subtree ffl mistake nodes ffi bad nodes ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi cost bad subtrees height random sat 
appendix profile random sat cost number nodes subtree ffl mean cost ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi max cost ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi height subtree ffl mean height ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffi max height ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi cost height bad subtrees depth random sat 
appendix collecting profile data thesis number graphs showing properties various search spaces 
graphs generated exhaustively searching subtree search tree collecting statistical data way 
section presents details data collected graphs drawn 
node classes search trees profiled binary trees 
node zero successors 
ignoring order successors node dead belongs classes shown 
ae ae omega omega omega omega ffl theta ffl theta theta theta theta ae ae omega omega omega omega ffl ffl ffl theta theta ii theta theta ae ae omega omega omega omega theta theta theta theta theta iii theta theta interior node classes 
node successor 
bad node appendix collecting profile data successors 
nodes affect mistake probability nodes class ii 
enormous subtree consists class iii nodes result early mistake search tree effect mistake probability tree 
profile search tree record depth number nodes class heights subtrees 
traversing search tree exhaustively search entire search tree problem determine exactly mistake probability search tree recording nodes bad levels tree 
unfortunately problems approach 
search trees interesting problems grow exponentially elaborate pruning mechanisms exhaustively searching trees exceeds computational resources 
second problem search trees exhaustively exact mistake probability individual problem really property interest 
really mistake probability set possible realistic problems profiled problem representative 
know example mistake early search tree 
individual binary tree half zero root node children 
set possible problems intermediate value 
light difficulties approach profiling problem follow path node depth exhaustively search subtree node choosing computational resources exceeded 
assume subtree chosen node contains goals representative entire search space 
subtree contain goal nodes contain mistake nodes insufficient determine uncommon circumstance report properties search tree unknown 
graph various data graph depth samples statistically significant 
example searched appendix collecting profile data full binary tree exhaustively sample requiring samples graphing 
incorporating heuristics scheduling heuristics experiments variable value ordering heuristics csp formulation job shop scheduling 
tree search formulation csp value ordering heuristics translate successor ordering heuristics 
exhaustively searched portion search tree successor ordering heuristics affect recorded statistics successors node searched regardless order 
csp variable ordering heuristics affect tree search formulation fundamentally instantiating variables different orders yields different search trees 
experiments show search trees generated scheduling csps random variable ordering different properties search trees generated heuristic variable ordering 
statistical data recorded subtree assume representative entire search space 
path root subtree depth sequence decisions successors 
decisions randomly successor ordering heuristic 
successor ordering heuristic risks selecting subtree representative space large 
successor ordering heuristic risks making really bad choice decisions leads subtree goal nodes 
subtrees solutions affect way contain nodes 
experimentally subtree goals typically representative space large regardless path subtree 
best computational resources chosen successor ordering heuristics determine path subtree depth argued differences help explain variable ordering heuristics effective reducing cost solving csp 
analysis variable ordering heuristics mistake probability properties scope interesting topic research 
appendix collecting profile data efficiency reasons translation scheduling problems constraint satisfaction tree search treat forced variable assignments variable assignments unit propagation separate nodes 
height search tree length longest sequence real choice points may number variables depth solutions 
solution depth varies dramatically scheduling problems difficult predict probability probe success spaces graphs 
appendix implementation considerations name implementation bounded backtrack search 
sketch algorithm 
implementation incorporates completeness modification discussed section 
value increases maximum depth tree top part tree root searched systematically 
reaches maximum depth entire tree searched systematically 
decision procedure producing solution proof search space solutions 
functions weighted random weight select value list index 
randomize value order manner works large small branch factors 
parameter line standard bounded backtrack search 
branch limit increased iteration result iterative broadening bounded backtrack 
branch limit simulate fractional branch factor cutoff replacing constant line function returns bcc dce probabilistically see section 
combined limited discrepancy search 
simplified version implementation 
appendix implementation considerations mp node depth lookahead randomness goal node return successors node weighted random length randomness length child select value depth break hresult mp child depth lookahead randomness max height result nil return hresult height lookahead return nil node lookahead randomness maximum depth hresult mp node lookahead randomness result nil return result return nil 
appendix implementation considerations weighted random selection values implementation allows arbitrary non uniform branching factors 
experimenting crossword puzzle generation simple implementation weighted random selection values worked small large branching factors 
generate random number skewed probability distribution minimum random numbers zero number successors values 
assuming successors list sorted order heuristic preference promote th successor front list leaving order successors unchanged 
promoting bad value front particularly harmful bad values tend fail quickly get caught bounded backtrack 
large branching factors simple promotion scheme appeared satisfy need random selection significantly compromising heuristic 
functions algorithm shown 
weighted random weight random weight gamma min random return select value list index index return nth list index return nth index gamma list return nth index list function randomize value order 
weighted probability distribution value successor probability gamma gamma selection 
value probability scheduling appendix implementation considerations problems 
randomness parameter see 
randomness value scheduling domain 
walk start restarting different variables nonsystematic methods explore space probes relative iterative sampling may benefit restarting different variable probe 
iterative broadening depth search restarts bounded backtrack large lookahead examples methods 
domains variable ordering heuristic selects variables affected instantiations minimize thrashing backtrack search entire path variable instantiations largely determined selection variable 
possible variable ordering heuristic generally occasionally commit pathological sequence instantiations value ordering heuristic little chance guiding search solution 
function select variable successive probes heuristically ordered list 
function called number variables probe number result index ordered list variables variable probe start 
weighted cycle mod infinity return gamma function restarting different variables 
appendix implementation considerations function cycles variables weighted cycle selects early variables variables variable ordering heuristic 
pattern 
application csp heuristics scheduling csp search procedures instantiate variables fixed order 
dynamically evaluate variable instantiate decision point 
known heuristic choose constrained variable evaluate 
variable constrained estimated counting number values domain variable consistent constraints previous assignments 
constrained variable taken fewest remaining values 
variables scheduling csp values representing possible orders operations machine 
counting values doesn provide estimate variable constrained 
estimate constrained variable considering number configurations value represents 
think total order operations machine representing possible sets start times operations operations don overlap start times consistent total order solutions 
likewise think value scheduling csp order operations representing assuming zero valued variables picked constraint propagation 
appendix implementation considerations possible sets start times configurations operations consistent chosen order constraints assignments 
course solving problem impossible know configurations consistent constraints crude estimate consider counting number configurations consistent chosen order established earliest latest possible start finish times 
number configurations space call measured continuous discrete time formulations 
consider example operations shown 
measure space order follows 
starting positions start range 
starting positions start time 
starts start time unrestricted 
starts start time restricted hours 
starts start time restricted long started 
ways continuous time number configurations represented area graph shown 
discrete time calculation slightly complicated endpoints 
space calculations continuous time discrete time follows appendix implementation considerations min lft est max gamma eft lst gamma est max eft est min lft lst max gamma lst gamma gamma gamma eft eft appendix implementation considerations delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta delta eft lft est lst start time finish time area possible configurations 
calculations estimate number configurations consistent order constraints problem 
sum estimate number remaining possible configurations operations borrowing intuition csp variable ordering may take constrained ordering decision fewest remaining possible configurations 
bibliography aarts van laarhoven lenstra 
computational study local search algorithms job shop scheduling 
orsa comput appear 
adams balas 
shifting bottleneck procedure job shop scheduling 
management sci 
applegate cook 
computational study job shop scheduling problem 
orsa comput 
balas 
machine sequencing disjunctive graphs implicit enumeration algorithm 
oper 
res 
barnes chambers 
solving job shop scheduling problem tabu search 
ieee trans appear 
reingold 
backtrack programming techniques 
communications acm 
bruynooghe 
solving combinatorial search problems intelligent backtracking 
information processing letters 
cheng smith 
generating feasible schedules complex metric constraints 
proc 
national conference artificial intelligence 
cohen 
non deterministic algorithms 
computing surveys 
bibliography crawford auton 
experimental results crossover point satisfiability problems 
proc 
th aaai 
crawford baker 
experimental results application satisfiability algorithms scheduling problems 
proc 
th aaai 
croce 
genetic algorithm job shop problem 
comput 
oper 
res appear 
davis putnam 
computing procedure quantification theory 
journal acm 
de kleer 
assumption truth maintenance system 
artificial intelligence 
dechter 
enhancement schemes constraint processing backjumping learning cutset decomposition 
artificial intelligence 
dechter meiri 
experimental evaluation preprocessing techniques constraint satisfaction problems 
proceedings eleventh international joint conference artificial intelligence 
dell trubian 
applying tabu search job shop scheduling problem 
ann 
oper 
res 
dorndorf pesch 
evolution learning job shop scheduling environment 
comput 
oper 
res appear 
freuder 
sufficient condition backtrack free search 
acm 
garey johnson 
computers intractability 
freeman 
gaschnig 
performance measurement analysis certain search algorithms 
phd thesis carnegie mellon university 
bibliography ginsberg 
dynamic backtracking 
journal artificial intelligence research 
ginsberg frank halpin torrance 
search lessons learned crossword puzzles 
proc 
th aaai 
ginsberg harvey 
iterative broadening 
artificial intelligence 
haralick elliot 
increasing tree search efficiency constraint satisfaction problems 
artificial intelligence 
harvey 
search job shop scheduling 
technical report cirl tr cirl university oregon 

probability statistical inference 
springer verlag 
knuth 
estimating efficiency backtrack programs 
math comp 
korf 
depth iterative deepening optimal admissible tree search 
artificial intelligence 
kumar 
algorithms constraint satisfaction problems survey 
ai magazine 
laarhoven aarts lenstra 
job shop scheduling simulated annealing 
oper 
res 
langley 
systematic nonsystematic search strategies 
artificial intelligence planning systems proceedings international conference 
lawrence 
resource constrained project scheduling experimental investigation heuristic scheduling 
technical report working university 
bibliography mackworth freuder 
complexity polynomial network consistency algorithms constraint satisfaction problems 
artificial intelligence 
matsuo suh sullivan 
controlled search simulated annealing method general jobshop scheduling problem 
technical report working graduate school business university texas austin 
mitchell selman levesque 
hard easy distributions sat problems 
proc 
th aaai 
nadel 
constraint satisfaction algorithms 
computational intelligence 
nowicki smutnicki 
fast taboo search algorithm job shop problem 
technical report institute engineering cybernetics technical university 
nuijten aarts van erp kip van hee 
job shop scheduling constraint satisfaction 
technical report computer science note department mathematics computer science eindhoven university technology eindhoven 
pearl 
heuristics intelligent search strategies computer problem solving 
addison wesley 
prosser 
hybrid algorithms constraint satisfaction problem 
computational intelligence 
purdom 
search rearrangement backtracking polynomial average time 
artificial intelligence 
sadeh 
look ahead techniques micro opportunistic job shop scheduling 
technical report cmu cs school computer science carnegie mellon univ 
bibliography selman kautz 
local search strategies satisfiability testing 
proc 
dimacs workshop maximum clique graph coloring satisfiability 
smith cheng 
slack heuristics constraint satisfaction scheduling 
proc 
eleventh national conference artificial intelligence 
stallman sussman 
forward reasoning dependency directed backtracking system computer aided circuit analysis 
artificial intelligence 
taillard 
benchmarks basic scheduling problems 
journal operational research 
taillard 
parallel taboo search technique jobshop scheduling problem 
orsa comput appear 
vaessens aarts lenstra :10.1.1.36.7506
job shop scheduling local search 
technical report eindhoven university technology 
walker 
enumerative technique class combinatorial problems 
combinatorial analysis proceedings symposium applied mathematics vol 

waltz 
understanding line drawings scenes shadows 
winston editor psychology computer vision 
mcgraw hill new york 
wilkins 
practical planning extending classical ai planning paradigm 
morgan kaufman san mateo california 
zabih mcallester 
rearrangement search strategy determining propositional satisfiability 
proc 
th aaai 
