organization hierarchical perceptual sounds music scene analysis autonomous processing modules quantitative information integration mechanism kashino kinoshita tanaka tanaka lab 
bldg department electrical engineering faculty engineering university tokyo ku tokyo japan 
kashino mtl tokyo ac jp propose process model hierarchical perceptual sound organization recognizes perceptual sounds included incoming sound signals 
consider perceptual sound organization scene analysis problem auditory domain 
model consists multiple processing modules hypothesis network quantitative integration multiple sources information 
input information processing module available module rises process asynchronously writes output information hypothesis network 
hypothesis network individual information integrated optimal internal model perceptual sounds automatically constructed 
model music scene analysis system developed acoustic signals ensemble music recognizes rhythm chords source separated musical notes 
experimental results show method permitted autonomous stable effective information integration construct internal model hierarchical perceptual sounds 
past years number approaches taken machine vision theoretical experimental efforts feature extraction shape restoration stereo vision knowledge vision techniques accumulated 
hand research machine audition computer systems understand acoustic information far focused mainly spoken language understanding 
requirements intelligent system possess ability recognition various events environment 
specifically understanding visual information speech various acoustic information play essential role intelligent system works real world 
recognition understanding non speech acoustic signals pioneering works currently ntt basic research laboratories 
literature 
example environmental sound recognition systems auditory stream segregation systems developed oppenheim lesser nakatani music transcription systems music sound source separation systems roads kashino tanaka brown cooke consider aspects flexibility processing hierarchy perceptual sounds 
note flexibility existing systems limited compared human auditory abilities 
example automatic music transcription systems deal ensemble music played multiple music instruments realized studies conducted mont chafe regarding flexibility auditory functions humans progress physiological psychological acoustics offered significant information 
especially property information integration human auditory system highlighted demonstrated auditory restoration phenomena handel achieve flexibility machine audition systems property sound source separation sub problem sound understanding inverse problem general formalization properly solved information memories sound models external world sensory data 
blackboard architecture information integration sound understanding realized oppenheim lesser cooke necessary consider quantitative theoretical background information integration 
second consider basic problem sound understanding single sound noting distinction perceptual sound physical sound 
perceptual sound terminology cluster acoustic energy humans hear sound physical sound means actual vibration media 
example listens ensemble music instruments loudspeaker single physical sound source hear multiple perceptual sounds 
discussed sections essential property perceptual sound hierarchical structure 
points background provide novel process model hierarchical perceptual sound organization quantitative information integration mechanism 
model probability theory characterized autonomous behavior theoretically proved stability 
problem description perceptual sound organization essential problem perceptual sound organization clustering acoustic energy create clusters humans hear sound entity 
important note humans recognize various sounds hierarchical structure order properly grasp understand external world 
perceptual sound structured spatial temporal hierarchy 
example waits person meet standing busy street waiting person hears traffic noise entity hears noise specific car entity 
directs attention specific car sound engine noise car frictional sound road surface tires car heard separately entity 
shows example snapshot perceptual sounds music 
note spatial structure shown temporal clusters perceptual sounds typically melodies chord progression temporal structure perceptual sounds depicted simplicity 
notes piano piano frequency components flute chord chords layers entities stands individual perceptual sound 
example snapshot perceptual sounds problem perceptual sound organization decomposed sub problems 
extraction frequency components acoustic energy representation 

clustering frequency components perceptual sounds 

recognition relations clustered perceptual sounds building hierarchical symbolic representation acoustic entities 
note consider problem extraction symbolic representation flat energy data approaches auditory scene analysis far considered problem restoration target sound signals nakatani brown cooke computer vision field scene analysis problem considered symbolic representation bitmap images clearly distinguished image restoration problem addresses recovery target images noise intrusions 
music scene analysis chosen music example applicable domain perceptual sound organization 
term music scene analysis sense perceptual sound organization music 
specifically music scene analysis refers recognition frequency components notes chords rhythm performed music 
sections introduce general configuration music scene analysis system 
focus discussion hierarchical integration multiple sources information essential problem perceptual sound organization 
behavior system results performance evaluation provided followed discussions 
system description illustrates process model optima organized processing intelligent music scene analysis 
input model assumed monaural music signals 
model creates hypotheses frequency components musical notes chords rhythm 
consequence probability propagation hypotheses optimal term optimal sense maximum likelihood set hypotheses obtained score display midi musical instrument digital interface data re synthesized sound signals 
optima consists blocks preprocessing block main processing block knowledge sources 
preprocessing block frequency analysis performed sound spectrogram obtained 
example sound spectrograms shown 
acoustic energy representation frequency components extracted 
process corresponds sub problem discussed previous section 
case complicated spectrum patterns difficult recognize onset time offset time solely bottom information 
system creates terminal point candidates extracted component displayed white circles 
rosenthal rhythm recognition method rosenthal desain quantization method desain honing rhythm information extracted precise extraction frequency components recognition onset offset time 
integration beat probabilities termination probabilities terminal point candidates candidates fixed status continuous terminated consequently processing scopes formed 
processing scope group frequency components onset times freq 
components time freq 
analysis monaural music signals processing modules musical notes clustering clustering source identification freq component extraction bottom sound formation note prediction prediction processing modules top freq component perceptual rules tone memories hypothesis network output data generation midi data display resynthesized sound chord note relations timbre models temporal processing modules chord group creation chord transition prediction chords chord analysis analysis rhythm beat processing scope creator main processes preprocesses knowledge sources chord transitions rules chord naming configuration process model ordinate frequency abscissa time 
source part chamber ensemble auld lang performed piano flute example spectrograms close 
processing scope utilized basic time clock succeeding main processes optima discussed 
examples formed processing scopes shown bottom panel 
processing scope created preprocessing block passed main processing block shown 
main block hypothesis network layers corresponding levels abstraction frequency components musical notes chords 
layer encodes multiple hypotheses 
optima holds internal model external acoustic entities probability distribution hierarchical hypothesis space 
multiple processing modules arranged hypothesis network 
modules categorized blocks bottom processing modules transfer information lower level higher level top processing modules transfer information higher level lower level temporal processing modules transfer information time axis 
processing modules consult knowledge sources top extracted frequency components displayed lines terminal point candidates white circles 
radius circle corresponds estimated probability termination 
ordinate frequency abscissa time 
middle terminal point candidates component top panel plane display showing difficulty finding component terminates starts bottom information 
ordinate power abscissa time 
bottom processing scopes label component id formed rhythm information 
vertical dotted lines show rhythm information extracted system 
example scope highlighted 
ordinate frequency abscissa time 
source part chamber ensemble auld lang performed piano flute examples frequency components processing scopes necessary 
sections discuss information integration hypothesis network behavior processing module 
information integration hypothesis network information integration hypothesis network require method propagate impacts new information network 
employ pearl bayesian network method pearl fuse propagate new information represented probabilities network separate links link link network singly connected tree structured graph 
shows application hypothesis network 
shown previous section network layers component level note level chord level 
link level node level node single link corresponds processing scope 
link level level multiple link consequence temporal integration multiple notes time axis may form single chord 
level nodes connected time temporal link encodes chord progression 
level level level time link link link set hypotheses set hypotheses set hypotheses set hypotheses set hypotheses set hypotheses set hypotheses set hypotheses set hypotheses set hypotheses set hypotheses set hypotheses set hypotheses processing scope scope scope scope scope scope node node node node node node node node node node node node node correlations correlations correlations correlations correlations correlations correlations correlations correlations correlations correlations correlations correlations chords notes components topology hypothesis network discuss information integration scheme assume wish find belief bel induced node example 
letting stand data contained tree rooted data contained rest network bel ajd probability vector am 
bayes theorem assuming independence hypotheses ja ja ja ajd ffp ja ajd ff normalization constant 
substituting ja ajd equation written bel ff conditional probabilities adjacent nodes derived children parent pearl derivation considered propagation diagnostic causal support minimum set processing modules required node network shown 
holder holds belief bel passes new information messages adjacent holders 
optima model holders embedded hypothesis network explicitly drawn 
creates hypotheses initial probabilities 
correlator evaluating conditional probabilities node node parent node required information propagation process 
holder correlator parent node creator child nodes hypotheses hypotheses hypotheses parent node hypotheses child node child node parent node parent node processing modules node hypothesis network note local computations required updating scheme efficient order computational requirement linear number nodes square number hypotheses node 
addition instabilities indefinite relaxations avoided parameter system order provision information affect status network probability values propagation process 
properties hypothesis network support integration multiple sources information derived autonomous processing modules 
section shows processing modules create instances hypothesis network 
system behavior optima process model music scene analysis system implemented 
total amount codes approximately lines mbyte graphical user interface codes 
processing module communicates modules tcp ip socket interface enables install modules remote computers 
implementation frequency analysis module frequency component prediction module installed parallel computer fujitsu ap achieve high processing speed part system developed workstations 
section discusses configuration knowledge sources behavior processing modules main processing block 
knowledge sources types knowledge sources utilized optima 
chord transition dictionary holds statistical information chord progression gram assumption typically currently assume length markov chain chords simplicity 
level node ngram hypotheses note independence condition stated equation satisfied nodes 
constructed dictionary statistical analysis traditional songs western tonal music popular japan countries 
chord note relation database probabilities notes played chord stored 
information obtained statistical analysis chords 
part stored data shown table 
chord naming rules music theory recognize chord hypotheses played notes 
table examples chord note relation knowledge conditional probabilities obtained statistical analysis printed music 
chord examples note am confidence interval tone memory repository frequency components data single note played various musical instruments 
currently maintains notes played instruments clarinet flute piano trumpet violin different expressions forte medium piano frequency range durations 
recorded sound samples professional music studio 
timbre models formed feature space timbre 
selected parameters musical timbre onset gradient frequency components deviations frequency modulations reduced number parameters eleven principal component analysis 
eleven dimension feature space timbres mentioned instruments completely separated timbre model information 
perceptual rules describes human auditory characteristics sound separation bregman currently harmonicity rules onset timing rules employed kashino tanaka bottom processing modules bottom processing modules optima nhc note hypothesis creator chc chord hypothesis creator 
nhc creator note layer performs clustering sound formation clustering source identification create note hypotheses 
uses perceptual rules clustering sound formation timbre models discrimination analysis timbres identify sound source note 
chc creator chord layer creates chord hypotheses note hypotheses 
refers chord naming rules knowledge sources 
top processing modules fcp frequency component predictor np note predictor top processing modules 
fcp correlator note layer frequency component layer evaluates conditional probabilities hypotheses layers consulting tone memories 
np correlator chord layer note layer provide matrix conditional probabilities layers 
np uses stored knowledge chord note relations 
temporal processing modules temporal processing modules ctp chord transition predictor chord group creator 
ctp correlator adjacent chord layers estimates transition probability grams transition probability chords chord transition knowledge source 
decides link chord layers note layers 
processing scope receives chord hypotheses note hypotheses 
rhythm information extracted preprocessing stage tries find successive scopes correspond node chord layer create instances 
link structure formed dynamically processing progresses 
evaluation performed series evaluation tests system frequency component level tests note level tests chord level tests tests sample song performances 
section part results 
note level benchmark tests example experimental results level evaluation displayed shows effect information integration note recognition rates 
tests performed ways perceptual sound organization information integration information integration level 
case best note hypothesis produced bottom processing nhc just viewed answer system case tone memory information fcp integrated 
cases kinds random note patterns simultaneous note pattern simultaneous note pattern 
patterns composed computer performed midi sampler digitized acoustic signals bit khz natural musical instruments clarinet flute piano trumpet violin 
recognition rate defined right wrong total right number correctly identified correctly source separated notes wrong number spuriously recognized surplus notes incorrectly identified notes total number notes input 
difficult distinguish surplus notes incorrectly identified notes included wrong 
scale factor normalizing number output notes number input notes notes incorrectly identified notes correctly identified normalization 
results indicate integration tone memory information significantly improved note recognition rates system 
cp tp vp cvp fcp ctp confidence interval fp center right left integration note level integration note chord level integration results benchmark tests note recognition chord level benchmark tests example experimental results shows efficacy level information integration chord recognition rates 
test chose sample song chord transition chords 
chord transition pattern test note groups composed 
test note groups noise random addition removal note added ways exp noise note chord chords exp noise notes chord chords exp noise note chords exp noise notes chords 
displays significant improvement chord recognition rates information integration scheme 
exp exp exp exp recognition rate integration integration error bar confidence interval results benchmark tests chord recognition evaluation sample music addition benchmark tests artificial test data evaluated system music sound signals 
shows note chord recognition rates sample song part chamber ensemble auld lang performed sampler acoustic signals flute clarinet piano 
clearly shows information integration effective test data music performance 
related physiological psychological findings ones bregman summarized bregman brown cooke developed computational auditory scene analysis system brown cooke basically bottom system effective integration information considered 
viewpoint information integration lesser proposed ipus acoustic signal understanding system blackboard architecture lesser cooke considered blackboard auditory scene analysis system cooke blackboard architecture systems requires global control knowledge tends note recognition rates chord recognition rates integration integration integration source part chamber ensemble auld lang performed sampler flute clarinet piano sound signal note chord recognition rates sample music result system complex control rules 
contrast model needs local computations consequently supports simple control strategy theoretically proved stability 
nakatani reported studies multi agent scheme nakatani model viewed quantitative version multi agent approach uses probability theory 
proposed method hierarchical organization perceptual sound described configuration behavior process model 
model music scene analysis system developed 
specifically employment hypothesis network permitted autonomous stable efficient integration multiple sources information 
experimental results show integration chord information tone memory information significantly improves recognition accuracy perceptual sounds comparison conventional bottom processing 
focused mechanism information integration left detailed discussions optimality output processing module 
planning clarify theoretical limits accuracy processing module conduct experiments evaluate systematically advantages disadvantages information integration mechanism proposed model 
bregman bregman auditory scene analysis 
mit press 
brown cooke brown cooke computational model auditory scene analysis 
proceedings international conference spoken language processing pages 
brown cooke brown cooke perceptual grouping musical sounds computational model 
journal new music research 
chafe chafe smith techniques note identification polyphonic music 
proceedings international computer music conference pages 
cooke cooke brown crawford green computational auditory scene analysis listening things 
endeavour 
desain honing desain honing quantization musical time connectionist approach 
computer music journal 
handel handel listening 
mit press 
kashino tanaka kashino tanaka sound source separation system ability automatic tone modeling 
proceedings international computer music conference pages 
lesser lesser ipus architecture integrated signal processing signal interpretation complex environments 
proceedings th national conference artificial intelligence pages 
event formation separation musical sound 
ph thesis department music stanford university 
mont mont problemsolving strategies music transcription system 
proceedings international joint conference artificial intelligence pages 
nakatani nakatani okuno auditory stream segregation auditory scene analysis multi agent system 
proceedings th national conference artificial intelligence pages 
oppenheim oppenheim 
eds 
symbolic knowledge signal processing 
prentice hall 
pearl pearl fusion propagation structuring belief networks 
artificial intelligence 
roads roads research music artificial intelligence 
acm computing surveys 
rosenthal rosenthal machine rhythm computer emulation human rhythm perception 
phd 
thesis department computer science institute technology 
