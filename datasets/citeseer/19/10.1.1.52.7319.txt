lsi meets trec status report susan dumais bellcore south st morristown nj std bellcore com 
overview latent semantic indexing latent semantic indexing lsi extension vector retrieval method salton mcgill dependencies terms documents addition associations terms documents explicitly taken account 
done simultaneously modeling association terms documents 
assume underlying latent structure pattern word usage documents statistical techniques estimate latent structure 
description terms documents user queries underlying latent semantic structure surface level word choice representing retrieving information 
latent semantic indexing lsi uses singular value decomposition svd technique closely related eigenvector decomposition factor analysis cullum 
large term document matrix decomposed set typically orthogonal factors original matrix approximated linear combination 
representing documents queries directly sets independent words lsi represents continuous values orthogonal indexing dimensions 
number factors dimensions smaller number unique terms words independent 
example terms similar contexts documents similar vectors reduced dimension lsi representation 
svd technique capture structure better simple term term document document correlations clusters 
lsi partially overcomes deficiencies assuming independence words provides way dealing synonymy automatically need manually constructed thesaurus 
lsi completely automatic method 
appendix provides brief overview mathematics underlying lsi svd method 
deerwester furnas additional mathematical details examples 
interpret analysis performed svd geometrically 
result svd vector representing location term document dimensional lsi representation 
location term vectors reflects correlations usage documents 
space cosine dot product vectors corresponds estimated similarity 
term document vectors represented space similarities combination terms documents easily obtained 
retrieval proceeds terms query identify point space documents ranked similarity query 
lsi method applied standard ir collections favorable results 
tokenization term weightings lsi method equaled outperformed standard vector methods variants case better cases deerwester 
standard vector method differential term weighting relevance feedback improve lsi performance substantially dumais 
lsi applied experiments relevance feedback dumais schmitt filtering applications foltz dumais 
trec conference opportunity scale tools explore lsi dimension reduction ideas rich corpus word usage 
large collection standard documents relevance judgements valuable ir resource important step systematic development effective retrieval systems 

application lsi trec collection overview existing lsi svd software analyzing training test collections query processing retrieval 
pragmatic reasons divided trec collection subcollections ap doe fr wsj ziff ap fr wsj ziff 
queries passed appropriate subcollections returns recombined arrive single ranked output 
main stages involved processing documents constructing relevant data structures 
steps completely automatic involved human intervention 
resulting reduced dimension representations matching retrieval 

pre processing indexing extracting terms calculating term weights 
computing svd number dimensions ranged 
adding new documents terms pre processing indexing minimal pre processing raw text trec documents 
markups text delimiters removed hand indexed entries removed wsj ziff collections 
upper case characters translated lower case punctuation removed white spaces delimit terms 
minimum term length 
terms occurring document list words generate term document matrix 
stemming phrases syntactic semantic parsing word sense disambiguation heuristic association spelling checking correction proper noun identification complex controlled vocabulary thesaurus manual indexing 
entries term document matrix transformed log tf td entropy weighting 
weight assigned term entropy noise entropy log td log td number documents collection index terms index documents td gf tf td tf td frequency term document gf global frequency occurrence term collection 
simplicity refer log entropy term weight 
transformed term document matrix input svd 
results svd analysis dimensional real vector term document singular values stored database 
terms log entropy weights stored database 
subcollections processed separately 
software constraints initial indexing svd analysis done random subset documents 
remaining documents added resulting data structure described 
completed svd analysis complete document term doe collection experiments reported 
table summarizes number terms documents samples scaling total number terms documents databases 
svd scaling sampled added total total database collection docs terms docs docs terms ndim meg doe wsj ap ziff fr wsj ap ziff fr totals table 
summary subcollections notes 
union subcollections word tokens word types 

general database size ndim 
total combined database size meg docs terms 
single combined database total database size smaller terms represented database 
unique terms combined database meg 
fact number terms grow linearly number documents help large svd calculations possible 
svd svd program takes log entropy transformed term document matrix input calculates best reduced dimension approximation matrix 
result svd analysis reduced dimension vector term document vector singular values 
trec computed separate svd subcollection 
number dimensions ranged 
adding new documents terms noted initial indexing svd typically performed random sample documents subcollection 
documents included sample folded database 
documents located weighted vector sum constituent terms 
vector new document computed term vectors terms document 
term vectors combined appropriate term weights singular values differentially weight dimension 
details deerwester 
documents term document matrix derived vector corresponds exactly document vector svd 
new terms added analogous fashion 
vector new terms computed document vectors documents term appears 
trec experiments new documents terms added 
sizes complete databases including documents added summarized table 
adding documents terms manner assume derived semantic space fixed new items fit 
general space obtain new svd calculated original new documents 
previous experiments sampling scaling documents folding remaining documents resulted performance indistinguishable observed documents scaled 
timing data trec experiments pre processing retrieval done sparc meg ram 
svd analyses run dec approximately meg ram 
table provides summary times minutes process documents create necessary data structures 
important note costs incurred 
subsequent query processing require new svd calculations database updates 
pre processing indexing includes time sampling documents necessary processing raw ascii text creating raw term document matrix calculating log entropy term weights requires passes transforming matrix entries log entropy weights 
combination code awk shell scripts 
time required depends amount raw text number terms number documents 
svd svd program computes best dimensional approximation transformed matrix 
sparse iterative single vector lanczos svd code berry 
code written ansi fortran double precision arithmetic available netlib 
number singular values dimensions calculated trec subcollections ranged 
turned dimensions retrieval fewer dimensions computed 
reported svd times higher necessary particular svd times ap ziff fr approximately lower dimensions computed 
adding new documents time required add new documents includes time pre process index text new documents time compute new document vectors 
translation existing tools patched trec experiments additional translation involved 
removed soon 
adding collection index svd new docs total mins doe wsj ap ziff fr wsj ap ziff fr table 
summary lsi svd times minutes retrieval query processing queries automatically processed way documents 
queries derived topic statement began full text topic topic fields stripped sgml field identifiers 
feedback queries full text relevant documents 
stemming phrases syntactic semantic parsing word sense disambiguation heuristic association spelling checking correction proper noun identification complex controlled vocabulary thesaurus manual indexing 
note boolean connectors proximity operators query formulation 
implicit connectives ordinary vector methods fall ors ands additional kind fuzziness introduced dimension reduced association matrix representation terms documents 
adhoc queries topic statements automatically processed described generate list query terms frequencies 
histogram query terms form query vector 
query vector weighted vector sum constituent term vectors 
separate query vector created matching databases doe wsj ap fr ziff wsj ap fr ziff 
subcollection query terms occurring database term weights 
example doe query vector created term weights term vectors doe database compared documents doe 
procedure repeated remaining collections resulting total similarities adhoc queries documents full trec collection 
note started query terms 
terms usually somewhat different weights different collections terms subcollections 
dimensions cosine similarity measure collections 
submitted results sets adhoc queries 
sets adhoc results differed information subcollections combined arrive single ranking 
case combined information databases simply raw cosines different collections ranking largest smallest 
call adhoc topic cosine results 
case normalized cosines subcollection combining 
subcollection transformed cosines scores mean standard deviation 
combined collections normalized scores raw cosines ranking largest smallest 
call adhoc topic normalized cosine results 
method normalizing scores offers somewhat flexibility combining information subcollections 
means example different numbers dimensions similarity measures different subcollections combined basis comparable score 
trec experiments comparisons number dimensions normalization equate real differences data statistical artifacts analysis 
routing queries routing queries created filter profile training topics 
submitted results sets routing queries 
case filter just topic statements treated routing queries adhoc queries 
filter located vector sum terms topic 
call routing topic cosine results 
case feedback relevant documents training set 
filter case derived vector sum relevant documents 
call routing cosine results 
atypical variant relevance feedback replaced combined original topic relevant documents 
extremes provide baselines compare methods combining information original query feedback relevant documents 
cases filter single vector 
new documents matched filter vector ranked decreasing order similarity 
previously conducted experiments suggest performance improved filter represented separate vectors 
method trec results submitted subsequent experiments 
see kane foltz dumais discussion multi point interest profiles lsi 
topic separate filter vector created training databases wsj ap fr ziff 
filters represented different databases 
new documents wsj ap fr ziff automatically pre processed indexed described 
new documents folded comparable training database compared filter vector database 
example new document wsj added wsj database compared filters database 
important note term vectors term weights training subcollections indexing comparing new documents routing filters 
dimensions cosine similarity measure routing comparisons 
results different training subcollections combined raw cosine values 
matching retrieval times queries filters documents represented reduced dimension vectors 
cosine query document computed documents ranked decreasing order similarity query 
cosines computer dimensions adhoc queries dimensions routing queries 
fewer dimensions standard vector retrieval entries non zero inverted indices useful 
means query compared document 
dimensional vectors cosines computed minute sparc 
time includes comparison time ranking time assumes document vectors pre loaded memory 
adhoc queries time compare query documents minutes comparisons sequential 
straightforward split matching machines parallel hardware 
preliminary experiments pe maspar showed cosines computed sorted second 
routing queries time compare new document filters filters databases sec sparc term filter vectors read disk 

improving performance time lsi svd system built research prototype investigate different information retrieval interface issues 
retrieval efficiency central concern wanted assess method worked worrying efficiency initial applications lsi involved smaller databases documents 
effort went re designing tools efficiently large trec databases 
obvious ways decrease indexing svd retrieval time discuss 
pre processing svd database creation time spent unnecessary translation transposing large matrices eliminated soon 
time spent svd 
svd algorithms get faster time 
sparse iterative algorithm times faster method initially 
usual speed memory tradeoffs svd algorithms time probably decreased different algorithm memory 
parallel algorithms help little probably factor 
calculations done double precision time memory decreased single precision 
preliminary experiments smaller ir test collections suggest decrease precision lead numerical problems svd algorithm 
important note pre processing svd analyses time costs relatively stable domains 
new items added existing svd database redoing svd scaling seriously diminishing retrieval effectiveness 
query construction retrieval calculations scalings various sorts done fly easily precomputed 
addition calculations done floating point speeded integer arithmetic 
dropping low vector values sparse vectors constructed take advantage efficient methods currently vector methods 
query vectors compared document 
document clustering reduce number comparisons 
query matching improved tremendously simply machine parallel hardware 
parallel query matching produces larger gains modifications discussed 
pe maspar attempt optimize data storage sorting decreased time required match dimensional query vector document vectors sort factor 
accuracy section accuracy divided main parts examining results adhoc routing runs submitted looking detail failures lsi system 
compared systems lsi performance average adhoc topics somewhat average routing topics tho see section misses discussion sizable improvements 
differences systems tokenization query construction representation matching amount human effort difficult isolate performance differences specific theoretically interesting components 
reason focus experimental results failure analyses step understanding improving performance 
lsi experiments adhoc normalization experiment 
submitted results sets adhoc queries 
sets adhoc query results differed similarities cosines subcollections combined arrive single ranking 
case adhoc topic cosine simply raw cosines different collections 
case adhoc topic normalized cosine normalized cosines subcollection combining 
differences accuracy methods large 
raw cosine method combining better normalized cosine method vs relevant articles vs pt precision 
general form normalization needed correct measurement artifacts lower mean cosine higher dimensions combining scores different subcollections 
number dimensions comparisons subcollection correction unnecessary experiments 
normalization appeared undesirable consequences topics 
normalization subtracts mean cosine divides variance raw cosine higher normalized score comes subcollection low mean cosine low variance precisely subcollections probably want avoid 
routing feedback experiment 
routing queries created filters queries training topics 
case routing topic cosine routing query just terms topic statements adhoc query 
case routing cosine feedback relevant documents training set located filter vector sum relevant documents 
intent runs baselines alternative methods combining original query relevant documents compared 
somewhat surprisingly query just topic terms accurate feedback query vs relevant articles vs pt precision 
suspect part problem attributable small number inaccuracy relevance judgements initial training set 
substantial impact performance topics feedback queries relevant articles ignored original topic description 
topic example relevant articles appear relevant topic topic potential military interest virtual reality called relevant article denmark crisis nuclear power threatening membership nato 
surprisingly article query relevant articles virtual reality returned 
larger number hopefully accurate relevance judgements repeat basic comparison 
baseline runs explore combining relevant documents original topic selecting relevant documents discriminating terms representing query vector points interest single average 
failure analyses order better understand retrieval performance examined kinds retrieval failures false alarms misses 
false alarms documents lsi ranks highly judged irrelevant 
misses relevant documents top returned lsi 
observations preliminary analyses topics lsi performed poorly 
suggest methods improving performance tested systematically entire trec collection plan 
false alarms 
common reason false alarms accounting approximately examined lack specificity 
highly ranked irrelevant articles generally topic interest meet restrictions described topic 
topics required kind detailed processing lsi system designed address 
precision lsi matching increased standard techniques proper noun identification syntactic statistically derived phrases pass approach involving standard initial global matching followed detailed analysis top documents 
salton buckley smart global local matching evans clarit evoke discriminate strategy nelson conquest global match followed locality information krupka rau ge pre filter followed variety stringent tests pass approaches advantage trec tests 
intend try methods trec focus general purpose completely automatic methods modified new domain query restriction 
common cause false alarms appears result inappropriate query preprocessing 
negation best example problem 
trec topics contained explicit negations 
lsi included negated words query words 
topic computer aided crime stated articles simply mentioned spread computer virus worm relevant 
documents lsi returned computer viruses 
example inappropriate query processing involved logical connectives 
lsi handle boolean combinations words returned articles covering subset anded topics 
clear false alarms returned lsi 
lsi uses statistically derived semantic space surface level word overlap matching queries documents difficult understand particular document returned 
advantage lsi method documents match queries words common produce spurious hits 
topic natural language processing technology returned articles chip processing technologies high technology products general 
reason false alarms inappropriate word sense disambiguation 
lsi queries located weighted vector sum words words disambiguated extent query words 
similarly initial svd analysis context words articles determine location word lsi space 
word location appears middle 
related possibility concerns long articles 
lengthy articles talk distinct subtopics averaged single document vector produce spurious matches 
breaking larger documents smaller subsections matching help 
misses 
analysis examined random subset relevant articles top returned lsi 
relevant articles fairly highly ranked lsi notable failures seen persistent readers 
far systematically distinguished misses list 
misses examined represent articles primarily different topic query contained small section relevant query 
documents located average terms lsi space generally near dominant theme desirable feature lsi representation 
kind local matching help identifying central themes documents 
misses appear result inappropriate selection subcollections 
recall analyzed subcollections separately combined similarities arrive single ranked list 
different subcollections different densities documents topics 
evident considering computer related topics 
general collections ap wsj relatively articles computers suspect dimensions lsi semantic space devoted distinguishing documents 
similarities documents queries computers relatively high undifferentiated 
ziff collections hand lsi dimensions represent differences computer concepts 
similarities top articles computer queries lower average finer distinctions subtopics possible 
consequence combining collections articles ziff subcollections included queries computer related topics 
different term weights different subcollections contributed problem 
inappropriate subcollection selection accounts lsi failures computer related topics 
consider example topic ibm saa standards 
lsi performs poorly compared systems topic returning fewest relevant articles having lowest pt precision 
summing systems topic total number returned articles relevant articles ziff 
lsi top articles ziff articles relevant 
comparable proportion lsi documents selected ziff number relevant increased pt precision increased 
performance places lsi slightly median topic 
performed analysis topics total returned articles ziff 
topics adhoc topics routing topics 
topics mean percent ziff articles chosen systems compared lsi 
comparable proportions ziff articles selected lsi average number relevant documents increased pt precision increased 
total new relevant documents adhoc topics new relevant documents routing topics 
performance improvements observed topics improvements products poor pre processing omitted lsi query see 
results encouraging problem select appropriate subcollections solved 
routing topics training data set apriori mixture articles various subcollections 
strategy generally applicable adhoc queries 
examine appropriate way combining subcollections take distributional effects account 
alternatively randomly selected documents topically organized ones create subcollections 
single large combined scaling need combine subcollections 
misses attributable poor text query pre processing tokenization 
keep single letters database location names important acronyms disappeared completely articles queries 
surprisingly resulted missed documents 
noticed top performing automatic systems smart pre processing hope trec 
allow better understand usefulness lsi se additional confounds introduced different indexing 
open experimental issues results failure analyses suggest directions pursue trec including improving pre processing tokenization exploring precision enhancing methods developing methods effectively combining subcollections 
hope explore additional 
separate vs combined scaling separate trec experiments 
decision subcollections largely pragmatic initially 
create single large scaling compare results obtained subcollections 
centroid query vs separate points interest single vector represent query 
cases vector average terms topic statement cases vector average previously identified relevant documents 
single query vector inappropriate interests facets near lsi space 
case routing queries example match new documents previously identified relevant documents separately average 
developed techniques allow match controllable compromise averaged separate vectors kane 
method trec trec 
interactive interfaces lsi evaluations conducted non interactive system essentially batch mode 
known underlying retrieval matching engine achieve different retrieval success different interfaces 
examine performance real users interactive interfaces 
number interface features help users faster accurate relevance judgements help explicitly reformulate queries 
see dumais schmitt preliminary results query reformulation relevance feedback 
interesting possibility involves returning richer rank ordered list documents users 
example clustering graphical display top documents quite useful 
done preliminary experiments clustered return sets extend trec collection 
general idea provide people useful interactive tools knowledge skills attempting build database representation matching components 

onward trec quite pleased able existing lsi svd tools trec collection 
important finding regard large sparse svd problems computed numerical convergence problems 
computations fast day cpu existing workstations subcollection certainly feasible especially calculations done create database 
computed larger svds take advantage trec 
terms accuracy lsi performance reasonable 
obvious ways improve initial pre processing indexing 
indexing methods similar possible automatic vector methods examine contribution lsi se 
basic tools place able conduct experiments comparing various indexing query matching ideas underlying lsi engine 
lsi designed method increase recall especially short queries users typical generate 
trec application explore precision enhancing tools 
probably consist refined matching algorithms hope move direction interactive interfaces 
see effective way combining human machine intelligence 

berry large scale singular value computations 
international journal supercomputer applications 
cullum lanczos algorithms large symmetric eigenvalue computations vol theory chapter real rectangular matrices 
boston 
deerwester dumais landauer furnas harshman indexing latent semantic analysis 
journal society information science 
dumais improving retrieval information external sources 
behavior research methods instruments computers 
dumais schmitt iterative searching online database 
proceedings human factors society th annual meeting 
foltz dumais personalized information delivery analysis information filtering methods 
communications acm dec 
furnas deerwester dumais landauer harshman streeter lochbaum information retrieval singular value decomposition model latent semantic structure 
proceedings sigir 
kane streeter dumais casella relevance density method multi topic queries information retrieval 
proceedings rd symposium interface ed 
salton mcgill modern information retrieval 
mcgrawhill 
appendix latent semantic indexing lsi uses singular value decomposition svd technique closely related eigenvector decomposition factor analysis cullum 
take large term document matrix decompose set typically orthogonal factors original matrix approximated linear combination 
formally rectangular matrix example matrix terms documents decomposed product matrices orthonormal columns diagonal rank socalled singular value decomposition largest singular values kept corresponding columns matrices rest deleted yielding matrices resulting matrix unique matrix rank closest squares sense idea matrix containing independent linear components captures major associational structure matrix throws noise 
reduced model usually approximate term document association data number dimensions reduced model smaller number unique terms minor differences terminology ignored 
reduced model closeness documents determined pattern term usage documents near regardless precise words describe description depends kind consensus term meanings dampening effects polysemy 
particular means documents share words user query may near consistent major patterns word usage 
term semantic indexing describe method reduced svd representation captures major associative relationships terms documents 
interpret analysis performed svd geometrically 
result svd dimensional vector representing location term document dimensional representation 
location term vectors reflects correlations usage documents 
space cosine dot product vectors corresponds estimated similarity 
term document vectors represented space similarities combination terms documents easily obtained 
retrieval proceeds terms query identify point space documents ranked similarity query 
attempt interpret underlying dimensions factors rotate intuitively meaningful orientation 
analysis require able describe factors verbally merely able represent terms documents queries way escapes unreliability ambiguity redundancy individual terms descriptors 
choosing appropriate number dimensions lsi representation open research question 
ideally want value large fit real structure data small fit sampling error unimportant details 
dimensions method begins approximate standard vector methods loses power represent similarity words 
dimensions discrimination similar words documents 
typically find performance improves increases decreases dumais 
lsi typically works relatively small compared number unique terms number dimensions shows dimensions fact capturing major portion meaningful structure 
