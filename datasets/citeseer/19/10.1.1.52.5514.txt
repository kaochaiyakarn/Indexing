niklasson boden ziemke editors proceedings icann th international conference artificial neural networks volume pages 
springer london 
self organization large document collections state art teuvo kohonen helsinki university technology neural networks research centre box fin hut finland email teuvo kohonen hut fi self organizing map som forms nonlinear projection high dimensional data manifold low dimensional grid 
representative model subset data associated grid point 
som algorithm computes optimal collection models approximates data sense error criterion takes account similarity relations models 
models ordered grid similarity 
som exploration statistical data data vectors approximated models dimensionality 
mapping documents represent statistically word frequency histograms reduced representations histograms regarded data vectors 
soms collections documents 
document mapped grid point link point document database 
documents ordered grid contents neighboring documents browsed readily 
keywords key texts search relevant documents 
new effective coding computing schemes mapping described 
visual overviews large data sets produced various clustering projection methods 
self organizing map som forms projection high dimensional data distribution dimensional regular grid cluster structure data preserved 
representative model subset observations associated grid point 
som algorithm computes optimal collection models approximates arbitrary distribution input observations sense error criterion 
criterion involves spatial ordering models similar models shall adjacent grid points dissimilar ones shall located farther away grid 
sense som similarity graph data 
grid may act groundwork various kinds illustrative displays 
instance shades gray groundwork indicate clustering tendency vectorial distances neighboring model vectors values component model vectors displayed separately study contribution cluster structure 
vast majority som applications input data constitute highdimensional real feature vectors model vectors approximations somewhat similar sense codebook vectors classical vector quantization 
models need necessarily replica input vectors may parametric representations operators generate sequences data 
hand exist means approximate data sets symbol strings approximated average strings 
soms form similarity graphs documents models taken real vectors describe collections words documents 
models simply weighted histograms words usually dimensionality reduction histograms carried shall see 
statistical models documents primitive vector space model basic vector space model stored documents represented real vectors component corresponds frequency occurrence particular word document model document vector viewed weighted word histogram 
weighting word importance shannon entropy document classes inverse number documents word occurs inverse document frequency 
main problem vector space model large vocabulary sizable collection free text documents means vast dimensionality model vectors 
latent semantic indexing lsi attempt reduce dimensionality document vectors forms matrix column corresponds word histogram document column document 
factors space spanned column vectors computed method called singular value decomposition svd factors influence matrix omitted 
document vector formed histogram remaining factors smaller dimensionality 
method called latent semantic indexing lsi 
randomly projected histograms shown experimentally dimensionality document vectors reduced radically random projection method essentially losing power discrimination documents 
consider original document vector weighted histogram rectangular random matrix elements column assumed normally distributed 
form document vectors projections rn experiments order similarity relations arbitrary pairs projection vectors approximations corresponding relations original document vectors computing load projections reasonable hand radically decreased dimensionality document vectors time needed classify document radically decreased 
experiments selected compare results earlier experiments dimensionality 
histograms word category map self organizing semantic map method words free natural text clustered neighboring grid points special som 
synonyms closely related words opposite meanings forming closed set attribute values mapped grid point 
sense clustering scheme effective thesaurus method sets synonyms manually 
input self organizing semantic map usually consists adjacent words text taken moving window 
word vocabulary indexed represented unique random vector scan occurrences word text positions construct word average context vector fr gamma fr means average random vector representing word position text scaling balancing parameter 
notice expression computed different word identical 
making semantic som word category map documents input iteratively sufficient number times 
grid point labeled words mapped point 
way grid points usually get multiple labels 
forming word category histogram document words document scanned counted grid points som labeled word 
counting words weighted shannon entropy inverse number documents text corpus word occurred inverse document frequency 
word category histograms computed reasonably fast faster lsi 
randomly projected word category histograms great number experiments performed histograms word category maps models ability method discriminate documents reduced grid points word category map contain say words average specific information contained words lost 
interested large document collections may contain say hundreds thousands unique words discarding rare words remaining vocabulary consisted tens thousands words 
order keep number words point word category map tolerable level word category map reasonably large example grid points latest experiments 
histograms dimensionality projected randomly form dimensional statistical document vectors 
combination word categorization random projection guarantees certain degree invariance respect choice synonyms high degree discrimination documents maintained similar reasons random projection method 
construction random projections pointers report new idea speedup computation document vectors 
programmed large demonstration 
preliminary tests advisable read sec 
returning point 
detailed description total system experimental results motivate idea discussed section 
table compares projection methods model vectors case dimensional 
material experiment english documents discussions usenet newsgroups internet 
text preprocessed explained sec 
remaining vocabulary consisted words word forms 
documents represented different kinds document vectors classified way 
document map discussed closely sec 
formed document mapped grid points 
points classified majority newsgroup names 
documents represented minority group grid point counted classification errors 
take account newsgroups identical topics names different 
misclassifications due reason simply counted errors 
discussions diffuse identify group 
accuracies reported pessimistic really regard figures relative ones meant comparison different methods 
classification accuracy cent reported row table refers classification carried vector space model full dimensional histograms document vectors 
practice kind classification orders magnitude slow 
random projection matrix original document vectors dimensional space normally distributed matrix elements normalized columns yielded statistical accuracy computation figures basic vector space method 
reported second row 
figures averages statistically independent tests rest cases 
rows meaning third row matrix elements thresholded gamma fourth row exactly randomly distributed ones generated column elements zeroes fifth row number ones sixth row number ones respectively 
concluded sparse binary projection matrix practice normally distributed vector space model 
apply fast computing method 
table classification accuracies documents cent different projection matrices figures averages test runs different random elements accuracy standard deviation due different randomization vector space model gamma normally distributed thresholding gamma ones column ones column ones column fast computation projected histograms matrix product rn eq 
drop document index sparse matrix computed fast 
consider trivial looking piece pseudocode 
step scheme supposed give idea reserve memory array xm acts accumulator array nn permanent address pointers locations locations matrix element ij equal accumulate values fast pointers 
sparse scheme works fast 
may easier understand version method 
project ready histograms pointers word text construction low dimensional document vectors 
assume precomputed word vocabulary weight entropy inverse document frequency 
vocabulary weights reside table entries hash coding textbook account cf 
hash addresses formed basis ascii codes words 
hash address spare location corresponding word entry store small number say random pointers elements array 
scanning text hash address word formed word resides hash table elements array say address pointers incremented weight value word 
weighted randomly projected word histogram obtained way may normalized optionally 
computing time needed form histograms case cent matrix product method 
reasons assume speedup holds larger maps 
construction document map original document organization system named websom websom hut fi websom word category histograms statistical models documents 
certain reasons accuracy classification led prefer straightforward random projection shortcut computation pointers forming statistical models documents 
carried numerous experiments maps different sizes comparable figures table document collection earlier 
experiments word category map grid points dimension projected model 
taken account word category map method deal extra self organizing process forming random projection straightforward computation 
websom method method collection programs combined different ways 
brief overview computing phases 
table classification accuracies similar material table matrix product pointer method pointers column random projection randomly projected word category histogram preprocessing raw text nonrelevant information punctuation marks articles stopwords message headers urls email addresses signatures images numbers removed 
common words words occuring rarely times corpus discarded 
remaining word represented unique random vector dimensionality 
language finnish plenty inflections stemmer 
experiments far regarded various english word forms different words vocabulary stemmer english 
formation statistical models reduce dimensionality models randomly projected word category histograms randomly projected word histograms weighted shannon entropy inverse document frequency 
formation document map document maps formed automatically som algorithm statistical models documents input 
size som determined average articles mapped grid point mainly determined convenience browsing 
speed computation especially large soms increased methods instance winner search accelerated starting search neighborhood corresponding winners cycle iteration sec 
increasing size number grid nodes stepwise learning estimation procedure sec 

user interface document map series html pages enable exploration grid points clicking mouse links document data base enable reading contents articles 
depending size grid subsets viewed zooming 
usually zooming levels bigger maps reading documents 
automatic method assigning descriptive map regions deeper zooming signs appear 
words appear articles map region rarely 
content addressable search html page provided form field user type query form short document 
query preprocessed document vector histogram formed way stored documents 
histogram compared models grid points specified number best matching points marked round symbol diameter larger better match symbols provide starting points browsing 
problem may encountered user wants single keyword keywords key document 
queries bad histograms 
case advisable different modes websom user specify document type keyword type query 
case operation described case index word vocabulary pointers documents words occur conventional indexed search find matches 
example biggest document map writing consists grid points 
model dimensional projecting word category map grid points randomly dimensional space 
text material taken different usenet newsgroups consisted documents average length words 
size accepted vocabulary words 
words weighted shannon entropy computed distribution words classes newsgroups 
took month process soms newest speedup methods searching occurs nearly real time 
accuracy classifying document groups cent 
fig 
exemplifies case content addressable search 
document map depicted background shades gray correspond document clusters 
grid points models matched best short query visible small black heap left hand side document map 
browser documents mapped grid points document map read html page 
title pages shown 
article fig 
deals nn chess 
computer chess documents similar returned 
fourth documents obviously deal chess 
query chess playing neural nets nn chess player vs human player content addressable search document websom experiments encoding documents statistical identification performed effectively believed years ago 
particular various random projection methods accurate practice ideal theoretical vector space method faster compute eigenvalue methods lsi extensively solve problem large dimensionality 
content addressable search obviously implemented differently complete new documents key information vs keywords 
identify users needs background information article wanted method kind keyword directed search engine 
ought emphasized order ensues websom may represent taxonomy articles serve basis automatic indexing documents similarity relationships better serve finding searching relevant information 
jain ak dubes rc 
algorithms clustering data 
prentice hall englewood cliffs nj kruskal jb wish multidimensional scaling 
sage university series quantitative applications social sciences 
sage publications park ca kohonen self organizing maps 
series information sciences vol springer verlag heidelberg second ed japanese ed springerverlag tokyo ultsch self organizing networks visualization classification 
opitz lausen eds information classification 
springer verlag berlin pp rueckert schumacher vlsi technologies artificial neural networks 
ieee micro lampinen oja self organizing maps spatial temporal ar models 
eds proc scand conf image analysis 
ry helsinki pp kohonen self organizing maps symbol strings 
report 
helsinki university technology laboratory computer information science espoo finland salton mcgill mj 
modern information retrieval 
mcgrawhill new york deerwester dumais furnas landauer indexing latent semantic analysis 
am soc inform sci kaski data exploration self organizing maps 
acta mathematics computing management engineering series 
dr tech thesis helsinki university technology finland kaski dimensionality reduction random mapping 
proc ijcnn int joint conf neural networks 
ieee press piscataway nj pp ritter kohonen self organizing semantic maps 
biol cyb kohonen content addressable memories 
springer verlag heidelberg second ed 
