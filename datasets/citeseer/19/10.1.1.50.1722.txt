opponent modeling multi agent system david carmel shaul markovitch computer science department technion haifa israel email cs technion ac il agents operate multi agent system need efficient strategy handle encounters agents involved system 
searching optimal interactive strategy hard problem depends behavior 
interaction agents represented repeated player game agents objective look strategy maximizes expected sum rewards game 
assume agents strategies modeled finite automata 
model reasoning approach possible method learning efficient interactive strategy 
describe agent find optimal strategy model 
second heuristic algorithm infers model opponent automata input output behavior 
set experiments show potential merit algorithm reported 
keywords opponent modeling model reasoning finite automata game theory 
central issues research multi agent systems mas deals development efficient interactive mechanisms selfish rational autonomous agents 
agents operate mas consider existence agents involved system need efficient interactive strategy handle encounters 
example software agent searches information internet may benefit cooperating software agents share similar goals 
agent agree retrieve information agents exchange information retrieved 
looking efficient strategy interaction agent consider main outcomes behavior 
direct reward action current encounter 
second effect behavior expected behavior agents 
going back example cooperation may increase cost current search due overhead helping may increase cooperation 
looking optimal strategy interaction hard problem depends strategies agents involved 
agents autonomous strategies private 
way deal problem endow agents ability learn strategies interaction experience 
studies littman sen shoham tennenholtz sandholm crites describe various methods incorporating learning mas 
suggest model approach learning efficient interactive strategy 
framework interaction agents represented repeated player game objective agent look interaction strategy maximizes expected sum rewards game 
assume agent indifferent rewards opponents 
model learning approach stage interaction learning agent holds model opponent strategy 
assume opponent strategy modeled finite automaton rubinstein model rubinstein agent exploits current opponent model order predict behavior chooses action model prediction 
model prediction wrong agent updates opponent model order consistent new counterexample 
previous carmel markovitch similar approach model learning zero sum player games 
call agents opponents 
section describe basic framework 
section describe agent find optimal strategy model 
section heuristic algorithm infers model opponent automaton input output behavior report experimental results 
interaction repeated game assume interaction agents described sequence encounters 
encounter agents described game 
finite set moves player theta 
utility function player common knowledge private 
sequence meetings agents described repeated game repetition indefinite number times 
stage game players choose moves theta simultaneously 
history finite sequence joint moves chosen agents current stage game 
theta gamma gamma set histories length strategy ff sequence functions sets histories repeated game set player moves 
set possible strategies player distinguish stationary player selects strategy game change adaptive player change strategy stage repeated game 
history game common knowledge player predicts course game differently 
agent chooses moves agent order maximize expected sum rewards game 
agent uses strategy opponent model predict infinite sequence joint moves theta define expected sum rewards fl gammat ij fl ij discount factor describes agent estimates probability re meeting agent easy show converged fl ij 
assume player objective maximize expected sum rewards repeated game called dominant strategy player respect strategy 
generally searching optimal strategy space strategies complicated agent limited computational resources 
adopt common convention strategies represented deterministic finite automata rubinstein dfa moore machine defined tuple sigma ffi sigma non empty finite set states 
sigma machine input alphabet 
initial state sigma output alphabet 
ffi theta sigma transition function 
ffi extended range theta sigma usual way ffi ffi soe ffi ffi oe null string 
sigma output function 
ffi output string sigma strategy player opponent represented dfa sigma sigma history theta gamma gamma move selected gamma 
optimal strategy opponent model assume agent strategies represented dfa agent model opponent dfa 
play optimally 
theorem shows opponent model dominant strategy agent shows computed 
theorem dfa exists dfa jm dominant respect proof assume ffi 
define fl ij max ffi characterizes expected sum rewards player state player performs action continues act optimally new accepted state computation markovian problem stable solution computed dynamic programming bertsekas best response player state opponent model opt arg max dominant player dfa ffi constructed follows ffl ffl ffl opt ffl ffi ffi 
parallel state reacts optimally 

theorem shows opponent model 
section discusses methods acquiring model 
opponent modeling assumption opponent strategy modeled dfa learning agent infer dfa sample opponent behavior past 
finding smallest finite automata consistent sample shown np hard gold angluin shown minimal consistent automata approximated polynomial time algorithm pitt passive modeling automaton arbitrary sample infeasible 
angluin angluin describes algorithm efficiently infers automata model minimal adequate teacher oracle answers membership equivalence queries 
membership query algorithm asks machine output string input actions 
equivalence query algorithm conjectures model machine equivalent 
teacher replies right conjecture provides counterexample model machine disagree 
algorithm named efficient inference procedure constructs minimal dfa consistent learned machine 
computational time polynomial number states machine longest counterexample supplied teacher 
alternative studied rivest schapire rivest schapire procedure simulates iterated interactions robot unknown environment adequate teacher answers queries learner permitted experiment environment machine 
learner requested simulate membership query specific input operates machine observes result 
model prediction different actual behavior machine learner treats counterexample 
methods described suitable problem 
learning agent uncooperative environment treat opponents teacher contrast rivest schapire procedure experiments opponent expensive destructive learner 
propose deal problem considering heuristic approaches 
occam razor principle search minimal dfa consistent opponent behavior 
inference procedure incremental 
stage interaction learner exploits opponent current model predict opponent behavior 
model prediction wrong agent updates opponent model consistent new counterexample 
heuristics try control growth model construction making limiting assumptions data show reasonable solution may 
method analogous famous classification problem constructing decision tree set pre classified examples 
finding smallest decision tree consistent data known np hard quinlan rivest heuristic methods described quinlan quinlan reasonable consistent decision tree constructed 
method shown efficient practical applications 
identifying dfa sample example dfa behavior pair sigma sigma annotates output machine input sequence sample finite set examples machine behavior 
example mark 
say model consistent sample iff example 
gold gold studied problem identifying dfa sample representing machine observation table 
sigma prefix closed set strings 
sigma suffix closed set strings called tests 
dimensional table row element sigma sigma oe sigma column element table entries sigma table closed iff sigma string row row 
table consistent iff strings row row oe sigma row oe row oe 
say dfa consistent observation table iff entry se 
dfa consistent closed consistent table constructed follows angluin ffl sg ffl row ffl ffi row oe row soe ffl row theorem angluin closed consistent observation table dfa consistent table dfa consistent equivalent states 
say table covers sample entry se 
say table entry supported sample example se oe oe 
closed consistent table covers construct consistent problem finding consistent dfa reduced problem finding closed consistent observation table covers sample easy find se 
table identification forces learner fill table entries 
table entries supported filled se 
main question remaining fill entries supported entry table called permanent entry supported 
called hole entry supported table entries called tied assignment vector sigma assigns output value hole table 
assignment legal iff tied holes receive value 
finding legal assignment table easy 
example assignment inserts output value holes legal 
call trivial assignment 
problem harder look legal assignment yields closed consistent table 
call optimal assignment 
theorem gold problem finding optimal assignment observation table covers sample np hard 
angluin angluin describes algorithm inferring structure dfa help minimal adequate teacher directs learner fill hole values optimally answering membership queries 
algorithm maintains observation table representing learned dfa 
initially fg table entries filled membership queries 
main loop tests current table closeness consistency 
case failure extends table closed consistent new table entries filled membership queries 
table closed consistent constructs asks equivalence 
counterexample provided teacher table extended include new example 
algorithm continues replied teacher conjectured model 
theorem angluin eventually terminates outputs minimal dfa equivalent teacher dfa 
number states teacher dfa upper bound length longest counterexample provided teacher total running time bounded polynomial heuristic algorithm learning dfa algorithm suitable opponent modeling due unavailability teacher 
need alternative method filling holes 
construction naive model covers data possible useful 
assigning values holes usually table inconsistent 
correct need extend table 
extension may yield model size data 
propose deal problem considering heuristic approaches search assignment induces minimal extension current observation table 
stage learning process learner holds closed consistent observation table covers past examples 
table represents current model 
new example arrives supporting example counterexample 
case table entries changed current model changed 
counterexample cases considered 
new example contradicts values table algorithm changes values order agree example 
counterexample covered table algorithm extends table cover way 
algorithm arranges updated table closed consistent constructs new model consistent new table 
new entries extended table filled follows entry supported past example permanent entry filled example output value 
table entry supported past example hole entry filled output value predicted current model 
spite consistency accepted model sample size grows limitation predicting power 
guiding principle algorithm limit growth model possible 
algorithm extends table cover new counterexample attempts change holes assignment table way new example covered minimal necessary extensions 
algorithm tries change holes assignment prevent necessity adding new states current model 
full description algorithm proof correctness carmel markovitch theorem closed consistent observation table covers new example 
eventually terminates outputs closed consistent table covers ftg 
suggested heuristic implemented easily possible 
research intend develop additional heuristics fill table holes study situations succeed controlling growth size learned model 
example run algorithm assume sigma fa bg sigma 
shows target dfa describes example learning session algorithm 
dfa example supporting example changes entry permanent 
second example counterexample 
table entries changed new model states 
third example ab counterexample 
algorithm adds aba abb sigma observation table inconsistent row row ab row aa row aba row ab row abb 
contradiction original changing holes aba equal aa abb equal ab table consistent extension 
result third model equivalent learned machine 
size model affected set examples order arrive 
correctness proof carmel markovitch shows arbitrary sample observation table increase size exponential size sample 
hypothesize algorithm best suited prefix closed samples 
case opponent modeling history includes prefixes example aa ab example ab aa aba ab abb example learning session dfa 
holes marked squares 
examples learned model equivalent machine 
examples 
conducted experiment random dfas various sizes created modeled various sizes random prefix closed samples behavior 
random machine dfa number states constructed choosing random transition function choosing random output function 
experiments conducted pair sample size machine size 
important clarify randomly built dfa necessarily minimal 
shows average size learned models function sample size function dfa size 
quite clear average size learned models similar size machines affected sample size 
results suggest strong ability explore common pattern sample 
summary finding optimal strategy interaction mas hard problem depends strategies agents involved system 
adaptation learning abilities essential intelligent agent interacts selfish agents 
treat process interaction repeated game agents adapt strategy history game 
suggest model approach agent learns model opponent strategy past behavior uses model predict behavior 
learning feasible restrict attention opponent strategies represented dfa 
learning dfa teacher infeasible 
heuristic algorithm model size vs sample size machine size machine size machine size machine size machine size model size sample size average model size accepted random prefix closed samples various size function size learned machine angluin algorithm 
algorithm maintains model consistent past examples 
new counterexample arrives tries extend model minimal fashion 
conducted set experiments random automata represent different strategies generated algorithm tried learn prefix closed samples behavior 
algorithm managed learn compact models agree samples 
size sample small effect size model 
experimental results suggest random prefix closed samples algorithm behaves 
angluin result difficulty learning uniform complete samples angluin obvious algorithm solve complexity issue inferring dfa general prefix closed sample 
currently looking classes prefix closed samples behaves 
step area opponent modeling 
algorithm enables adaptive player model agent strategy order find proper response 
tasks modeling adaptive players modeling players hide interactive strategies avoiding agent attempts model strategy extremely difficult deserve research 
angluin angluin 
complexity minimum inference regular sets 
information control 
angluin angluin 
learning regular sets queries counterexamples 
information computation 
bertsekas bertsekas 
dynamic programming deterministic stochastic models 
prentice hall 
carmel markovitch carmel markovitch 
algorithm incorporating opponent models adversary search 
technical report cis report technion march 
carmel markovitch carmel markovitch 
unsupervised learning finite automata practical approach 
technical report cis report technion march 
gold gold 
complexity automaton identification data 
information control 
littman michael littman 
markov games framework multi agent reinforcement learning 
proceedings eleventh international conference machine learning pages july 
pitt pitt 
inductive inference dfas computational complexity 
jantke editor analogical inductive inference lecture notes ai pages 
springer verlag 
quinlan rivest quinlan rivest 
inferring decision tree minimum description length principle 
information computation 
quinlan quinlan 
induction decision trees 
machine learning 
rivest schapire rivest schapire 
inference finite automata homing sequences 
proceedings th acm symposium theory computing pages 
rubinstein rubinstein 
finite automata play repeated prisoner dilemma 
journal economic theory 
sandholm crites sandholm crites 
multiagent reinforcement learning iterated prisoner dilemma 
biosystems journal submitted 
sen sen hale 
learning coordinate sharing information 
proceeding twelfth national conference artifical intelligence aaai pages 
shoham tennenholtz shoham tennenholtz 
learning evolution social activity 
technical report stan cstr stanford department computer science 
