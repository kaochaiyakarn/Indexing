workload characterization survey maria giuseppe dipartimento di informatica sistemistica dipartimento di elettronica informazione universit di pavia politecnico di milano pavia italy milano italy mail mcc mail polimi performance system determined characteristics composition load processed 
quantitative description fundamental part performance evaluation studies 
methodologies construction workload models functions objective study architecture system analyzed techniques adopted 
survey applications methodologies various types systems batch interactive database network parallel supercomputer 
performance system influenced characteristics hardware software components load process 
analysis workload plays key role studies performance indices system determined 
indices directly related workload expressed quantities independent 
behavior real workload complex difficult reproduce model required 
model capture static dynamic behavior real load compact repeatable accurate 
goal give survey workload characterization pointing applications various steps required construction workload model sets parameters considered various types studies 
organized follows 
state art techniques methodologies construction workload models section 
application domains methodologies discussed 
section devoted centralized systems batch interactive database systems 
workload characterization network environments described section 
section analyzes multiprocessor systems parallel supercomputer systems 
drawn section 
supported part italian research council progetto sistemi pf pf italian projects 
workload modelling techniques execution workload typically deterministic phenomenon modeled nondeterministic application statistical techniques 
big amount data measured large numbers variables interacting phenomena considered 
main steps construction workload models see chapter summarized follows formulation 
characterization level workload basic component smallest level detail job step interactive command update inquiry transactions database parameters description selected 
criterion evaluation model representativeness determined 
collection parameters workload modeled executed 
statistical analyses measured data 
sub steps identified preliminary analysis 
collected data may include distinct workload populations batch time sharing transaction 
discovery natural partitions promotes insights focusing attention smaller manageable portions original data set 
analysis parameter distributions 
type analysis may lead application various types transformation logarithmic original values parameters identification removal outliers 
example density function parameter highly positively skewed logarithmic transformation required 
furthermore outliers components parameter values different typical ones may distort classification process 
original data set trimmed removing elements having parameters values greater predetermined percentile 
sampling 
order process measured data reasonable amount processing time storage number components considered small 
sample drawn measured data steps 
static analysis 
robust classification obtained values parameters scaled lie common interval 
classification partitioning workload components usually attained clustering algorithms 
cluster analysis statistical technique useful discovering homogeneous groups data set 
various clustering algorithms commonly applied workload characterization non hierarchical means method 
statistical techniques grid techniques principal components analysis adopted partition data set classes homogeneous components 
representative elements selected classes extraction criteria construction workload models 
dynamic analysis 
time varying characteristics workload dynamic characteristics processing requests evolution time mixes components execution reproduced properties time series considered 
application various techniques numerical fitting statistical analysis nonstationary series events stochastic processes provides concise representation analyzed data sequences arrival departure patterns components system 
probabilistic graphs represent approach description dynamic behavior workload 
user behavior graphs adopted modelling interactive users able capture dynamic characteristics load reproducing sequences commands submitted users 
nodes graph user correspond different command types 
arcs associated probabilities represent issuance command completion current 
duration user stay node probabilistically equals times user spends typing command type waiting system response thinking command input 
representativeness 
criteria adopted assess representativeness workload model 
performance oriented criterion characterization terms vector components performance indices selected objective study widely applied 
examples indices response time throughput resource utilizations 
accuracy workload model measured function difference obtained executing real workload model respectively 
workload analyzer tool wat tool allows construction workload model implementing steps previously described 
workload characterization centralized systems workload characterization centralized systems stabilized topic extensively studied applied early seventies 
systems represent application domain workload characterization papers topic appeared literature 
subsections survey studies various approaches techniques described section applied 
batch interactive systems popular method adopted workload characterization batch interactive systems clustering 
earliest applications technique construction workload model dual processors system scientific environment 
significative clusters obtained ranging eleven characterized set parameters cpu time number accesses device type number job steps number files 
resource functional oriented procedure workload modelling proposed application data measured batch system described 
program steps characterized parameters dealing resource consumptions analyzed different techniques clustering methods principal components analysis pca 
nonhierarchical means hierarchical minimal spanning tree algorithms produce representative clusters programs distributed values parameters 
composition cluster investigated functional view point 
precisely programs characterized terms additional features related programming language fortran cobol type activity performed compilation execution 
distribution programs various clusters reflects resource oriented subdivision 
example compilations cobol programs belong single cluster contains intensive executions 
third type analysis pca allows identification factors able explain correlations variance existing resource oriented parameters 
correlations features respect factor factor displayed 
relative positions parameters show loadings factor 
example derive factor cpu factor high loadings disk cpu times parameters highly correlated 
considerations apply parameters number lines printed number 
furthermore factors account total variance data set 
information previous results help simplifying workload model reducing number features considered 
distinct characteristics program types compilations executions pointed means pca 
displays projections programs steps compilations subspace identified factor factor 
particular programs grouped different memory requirements factor placed various compilers 
variations group due different cpu times factor required turn function size source codes 
model static characteristics workload provide perfectly loading factor parameter factor factor loading factor parameter lines printed memory tapes loadings resource oriented parameters factor factor 
factor memory factor disks cpu fortran cobol assembler 
kw kw kw projections compilations factor factor subspace 
accurate representation load lacks capturing variation time components reproduce dynamic behavior 
stochastic processes numerical fitting graph techniques commonly models obtaining concise representations workload dynamic characteristics 
hierarchical structure interactive workloads analyzed terms stochastic model top view basic components 
view user session sequence runs jobs consist sequences tasks editing compilation 
task seen sequence commands statements 
lower level physical resources consumed statement 
workload set runs initially grouped means clustering techniques 
parameters characterizing job functions software resources filing fortran compiler link load execution 
task level markov chain states correspond software resources run employed description behavior users 
transitions states denote probable sequence runs belonging various clusters 
shows example task sequence measured single run 
seen different states identified corresponding software resources employed fictitious states represent termination run 
note run reaches state steps 
tests run order investigate properties sequences 
state fortran compiler editing link load file output execution compilers step number task sequence state state measured single run 
analysis order markov chain expresses step dependencies sequences equal clusters 
low order models clusters small numbers runs preferred states 
type characterization particularly suitable construction synthetic scripts setup benchmark experiments interactive systems 
alternative approach characterization interactive workloads user behavior graphs employed different respects 
adopted means obtaining synthetic representation workload terms command types resource demands sequence 
functional approach initially applied data measured users interactive computer running unix operating system 
commands grouped types corresponding user behavior graph constructed 
note users assumed statistically identical obey 
number different command types submitted system quite large initial grouping frequency occurrence performed 
consisting nodes heaviest commands plus catch command combining remaining ones obtained 
subdivision commands mean coefficient variation resource demands required dealing manageable model 
resource oriented consisting nodes constructed 
goal study analyze causes nodes graph perfectly accurate model nodes 
sensitivity accuracy clustering workload characterization dispersion resource demands clustered commands evaluated 
results obtained shown clustering method workload model design reasonably accurate sensitivity quite low 
numerical fitting techniques analysis fluctuations arrival patterns workload components construction parametric model able provide concise representation analyzed phenomena 
arrival times jobs system collected month operation 
measurements discarded occurrence anomalous events crash holidays maintenance occurring days 
day periods considered 
typical behavior variations arrival rate day period am pm plotted 
seen peaks value morning reached am followed decrease till pm corresponding lunch break 
values afternoon rate constant lower morning ones 
dotted solid curves fig 
refer estimated rate function corresponding polynomial function provided fitting techniques respectively 
am pm arrival rate 
estimated dotted curve polynomial solid curve arrival rate functions 
application methods various days shown degree polynomial function suitable representation analyzed arrival processes 
representative patterns similar behaviors identified data means clustering applied coefficients various polynomial functions 
model obtained easily forecast system load near driving simulations different dynamic control policies investigated 
database systems database system seen subset part centralized system users access interactively database terminals entering messages called transactions 
workload description commonly adopted studies dealing types system analysis traces measured real environments strings generated stochastic processes 
traces collections accesses database items blocks produced transactions processed observation interval 
various techniques applied characterization clustering statistical analyses non stationary series events 
identification locality subsets blocks database sequentiality sequences increasing database block addresses transaction types provides preliminary information performance behavior database possible techniques adopted studies dealing buffer replacement concurrency control policies see 
particular transactions classified functions store query finite state machine models applied 
table lists examples parameters collected real database environment 
values parameters provided belong traces measured system different configurations typical load conditions 
mean transaction length refers number different pages accessed transaction 
transactions page accessed considered 
parameters trace trace trace observation interval number transactions mean transaction length pages accessed pages written transaction types table summary parameters derived traces collected database system different configurations 
characterizing workloads different page behavior hierarchical functional approach adopted 
approach starting user viewpoint database workload description modified level order obtain appropriate physical characterization 
methodology independent database application abstraction levels proposed ffl application level user viewpoint database data application functions relationships defined ffl transaction level transaction types associated functions previously identified defined ffl physical resource level list read write page accesses cpu demands defined 
various statistical approaches analysis large quantity data collected computer running ims database management system 
exploratory study access path lengths sequence segments accessed searching database measured day period performed 
graphical displays simple numerical summaries reveal patterns data 
appropriate stochastic process input simulation models ims installations proposed 
data times transaction taken days analyzed represented means nonhomogeneous poisson process seen superposition inputs various users 
shows day plots mean number transactions initiated function time day dashed curve 
note values computed average adjacent unit time intervals 
time rate function mean number transactions initiated unit time intervals dashed curve global estimate exponential polynomial degree solid curve 
exponential polynomial function estimation oscillatory nature poisson process see fig 

workload classification aimed determining capacity ibm mvs system 
study considers workload types batch timesharing transaction processing 
examples parameters developing cluster description transaction workload total database calls number input output message segments total lock requests 
note parameters reflect instantaneous conditions system database organization mix interaction availability common pool space heavily influence behavior transactions 
table reports values centroids clusters obtained analysis sample consisting transactions 
clusters account sample 
workload characterization network systems starting overview methodologies workload characterization network environments want clarify term denote basic computer networks considered isolation interconnected heterogeneous wide area metropolitan area local area networks different protocols distributed systems see 
parameters cluster number database calls lock requests input messages output messages table centroids clusters obtained transaction processing workload 
commonly performance measures environments throughput channel utilization various forms delay transfer time queueing delay expressed function nature traffic characteristics protocols network 
sensitivity studies potential performance systems obtained varying load network topology connectivity required capacity planning design configuration purposes 
important identify set parameters able capture reproduce nature traffic flowing networks 
type analysis fundamental multimedia networks supporting digital audio digital video components characterized wide variety traffic types 
furthermore complexity special routers bridges gateways adapter cards constituting network systems architectures interconnections requires parameters able take account influence mutual interactions components 
consequence techniques parameters introduced previous sections centralized systems longer sufficient environments 
workload characteristics network environment specified terms basic parameters packet generation rate node workstation terminal server size routing packets 
analysis source destination nodes allows distinguish intranet source destination network internet source destination different networks traffic 
note information concerning routing measured derived user profiles specify source destination applications 
addition protocol dependent parameters number packets generated message distribution 
case store forward networks cpu time spent packet setup teardown time spent protocol conversion gateways considered 
defined set parameters characterizing workload network appropriate measurement tools 
studies literature different approaches adopted special purpose devices adhoc test monitoring tools constructed 
follows give survey studies appeared literature describe measure analyze parameters introduced input definition analytical simulation models different types networks 
authors focus experimental measurements ethernet local area networks 
see studies quite similar results obtained different architectural differences environments 
experimental study aimed characterizing traffic performance mbps ethernet local network 
network connecting machines different kinds applications ranging file transfer access shared database systems specialized programs 
load network analyzed hours period described terms traffic inter packet arrival times 
noticed behavior load strictly related time light night heavy daytime hours dip 
length packets exhibits high correlation traffic type file transfer terminal traffic shows bimodal distribution mean value bytes 
note mbps network maximum packet length equal bytes 
source destination traffic matrix provides information frequent patterns identifying unbalanced situations possible bottlenecks network 
analyzed environment traffic concentrated specialized servers 
large network mainly consisting diskless workstations virtual memory operating systems studied 
measurements collected instrumenting kernel dedicated unix machine 
packets flowing mbps ethernet local area network read protocol headers timestamps packets stored 
seen fig 
packet length mean size equal bytes mainly distributed protocols applications nfs nd tcp 
case initial characterization packets functional subdivision appropriate 
packets belonging group specific traffic carry 
example groups identified nfs packets consisting short ones transporting requests responses remote procedure calls long ones produced data fragmentation performed ip file read write operations respectively 
important result deals distribution packet interarrival times tcp nd nd tcp tcp nfs nd nfs length packet data field distribution packet length function protocols 
times subsequent transmissions 
sort correlation dependence protocols packet size traffic intensity 
poisson process typically employed simulation analytical models suitable case 
shows network utilization minute intervals caused traffic generated client workstation communicating file server nfs protocol 
behavior network activity exactly reflects user behavior usually characterized certain number pauses 
pm pm time day second intervals network utilization function time day nfs protocol 
measurements aimed determining time copy mbyte file nodes local area network varying load normal heavy light contention free loads 
experiments intended validation means results obtained campus network model developed solved design tool 
workstation type rate generates traffic average size packets measured means specialized monitor 
sending workstation transmits average average size bytes 
receiving workstation generates bytes acknowledgments average rate study shown background traffic transmission time larger overhead due software 
typical campus area network analyzed 
traffic hierarchically characterized various layers application transport medium access layers 
behavior intra lan inter lan lan wan traffic investigated 
synthetic externally driven model able generate load actual distributed system file server unix nfs environment 
model analysis measurements performed week period capture requests responses file server 
key factors frequency distribution requests interarrival time distribution file referencing behavior distribution sizes read write requests identified 
preliminary analysis parameters helps discovering typical behavior requests simplifying model description 
example initial simplification obtained looking various request types 
small number types corresponding dominating ones considered negligible ignored 
analysis arrival process shown exponential characterization process appropriate average interarrival time variance equal seconds respectively 
model constructed set parameters identified workload characterization stage 
survey performance issues token ring local area networks various protocols 
main workload parameters analysis delay throughput characteristics basic ieee fddi protocols information field lengths exponentially distributed frame generation rate poisson process 
case simulations flow control mechanism token rings interconnected bridges backbone ring parameters chosen mean message length kbyte coefficient variation mean frame length bytes exponentially distributed intervals generation messages time bridge process frame equal size buffer pools bridge kbytes 
note mean message length chosen frame length distribution segmentation insertion control information resembles bimodal distribution measured real systems 
shows example results study total throughput versus total offered data rate various window sizes completely symmetrical traffic pattern 
seen throughput initially increases linearly may decrease heavy load network queues frames bridges 
offered data rate mbps throughput mbps throughput function offered data rate various window sizes 
performance effects different distributions node locations linear bus ethernet examined 
parameters simulations mainly related protocol network carrier collision detection time interframe gap length jam signal number buffers node 
signal propagation delays set resembling network 
traffic characterized packet length fixed study bytes 
interpacket arrival times exponentially distributed chosen yield moderately heavy loads 
study real time services packet switched store forward wide area network 
communication fixed route connections channels virtual circuits performance guarantees 
multimedia traffic diversity captured considering types channels network resources differently 
parameters characterizing channels maximum service time node channel packets minimum packet interarrival time channel min minimum value ave average packet interarrival time interval duration table shows values parameters channel types 
see channel imposes heavy load channel light 
channel type min ave table characterizing parameters expressed time units channels 
section global approach workload characterization network environments see described 
methodology layered structure corresponds logical subdivision hardware components groups user terminals processing nodes communication subsystem 
scheme load submitted users requires services local processing nodes eventually goes network 
layers user processing network different basic workload components involve different physical resources identified 
shows layered structure systems 
seen load processing node layer comes users layer network layer 
dashed lines display examples possible paths followed local remote requests respectively 
modelling load layer probabilistic graphs chosen ability capture static dynamic properties load 
user behavior graphs adopted layer lower layer system graph sequence requests ordered arrival time generated users coming network 
requests need processing remote nodes cause various types traffic communication subsystem 
load layer characterized communication subsystem system graphs users behavior graphs 
user terminals processing nodes 
layer network layer processing layer user 
network graphs traffic flow matrix layered structure workload characterization network environments 
network graph derived flow messages communication subsystem traffic flow matrix representing routing 
main steps modelling load various layers account mutual interactions summarized follows ffl measurements arrival sequence command types submitted user construction corresponding behavior graphs layer ffl measurements hardware software resource consumptions arrival times requests processed node construction system graph layer ffl measurements arrival time length type source destination addresses messages flowing network construction corresponding graph traffic flow matrix layer 
parameters measured derived layers corresponding modelling techniques listed table 
layer characterization parameters techniques level measured derived user arrival time arrival rate command type interarrival time user behavior graph processing arrival time arrival rate node request type system graph hw sw resource consumptions communication arrival time generation rate subsystem message type interarrival time message length network graph source destination nodes traffic flow matrix table parameters techniques adopted network environments 
multiprocessor systems technological advances increasing demands computing power led development fast computers parallel systems supercomputers 
parallelism computations key factor performance parallel systems 
performance improvements achieved supercomputers mainly due new architectural aspects 
issues related workload characterization types systems addressed subsections 
parallel systems sequential environments performance system adequately described terms service demands amount computation time required processor instruction rate 
performance parallel systems characterized large number cooperating processors influenced multiplicity factors mainly related structure applications ability exploit parallel features system 
graphs modelling parallel algorithms widespread practice 
node represents sequence computations tasks arcs represent data dependencies 
directed graphs task graphs representing data driven computations undirected graphs communication graphs preferred modelling control driven computations 
sequel limit characterization algorithms represented means task graphs 
note type approach easily extended communication graphs 
general classification metrics parallel environments done terms dependence independence system architectures 
analysis graphs see fig 
set system independent performance metrics related static properties algorithms deduced 
static indices describe complexity structure algorithm capture inherent parallel characteristics suitability particular system 
dynamic indices system dependent describe behavior algorithm executed system reflect efficiently parallelism exploited 
metrics appropriate evaluation match algorithms architectures 
summary static indices table 
measure task granularity static metrics description total number nodes degree avg 
number direct predecessors nodes degree avg 
number direct successors nodes depth longest path input output nodes maximum cut max number arcs taken possible cuts problem size size data considered table system independent metrics derived task graph algorithm 
values degree degree related synchronization complexity 
larger number predecessors node higher probability corresponding task wait synchronization 
value depth longest path terms number nodes starts initial node ends final node directly related execution time algorithm 
maximum cut maximum number arcs taken possible cuts initial node final node deals maximum theoretical parallelism achieved execution 
problem size measure number elements data space considered 
illustrate workload characterization process discuss parallel metrics respect algorithms 
consider typical parallel algorithms block decomposition matrix multiplication lu decomposition task graphs reported 
values static indices derived analysis matrix size theta theta processors summarized table 
block multiplication algorithm consists sequence intermixed computation communication phases 
presence phases emphasized dynamic indices see fig 

task graph lu decomposition asymmetric high probability maximum number processors maximum cut small fraction global execution time 
tasks strongly interconnected reflected degree value 
static indices lack representing parallelism exploited algorithm system behavior execution progresses dynamic metrics expressed single value curve see table 
start task graphs block matrix multiplication lu decomposition algorithms 
algorithm problem size nodes degree degree depth max cut block lu table static indices task graphs block multiplication lu decomposition algorithms 
single value indices determined executing algorithm number processors average characteristics tasks comp comm messages exchanged messages messages global number operations op particularly useful load algorithm reproduced simulation studies evaluation mapping routing strategies 
complete characterization behavior parallel algorithms consists plotting metrics function number available processors signatures execution progresses profiles 
global execution time algorithm execution signature subdivided components comp computation signature comp represents fraction execution time processors computing communication signature time spent communicating including synchronization delays 
usually comp monotonically decreasing function increasing function 
dynamic metrics description single value comp avg 
computation time tasks comm avg 
communication time tasks messages avg 
number messages sent received tasks messages avg 
length messages op number operations signatures comp global computation time vs number processors global communication time vs number processors global execution time vs number processors speedup vs number processors efficiency vs number processors efficacy vs number processors profiles busy proc number busy processors vs execution time proc number communicating processors vs execution time comp proc number computing processors vs execution time table system dependent metrics derived execution algorithm processors 
shows signatures block decomposition algorithm obtained transputer system mesh topology equal 
seen particular problem size characterization algorithm changes computation bound communication bound processors 
processors granularity tasks small computation time task smaller time required transmit results processors 
speedup describes gain time parallel algorithm executed processors respect serial 
serial time may denote time taken best possible serial algorithm time required execute parallel algorithm single processor 
definition absolute evaluation algorithm required describes algorithm parallelized 
difficult impossible derive optimal serial time simple algorithms second definition commonly adopted 
speedup curves various problem sizes block decomposition algorithm reported fig 

advantage increasing evident problem size large speedup linear 
speedup curves lu decomposition algorithm obtained intel ipsc different problem sizes reported 
matrix size decreases reduction speedup occurs due relative increase communication time compared computation time 
comp comm signatures block decomposition algorithm mesh topology 
processors allocated potential reduction computation time increase communication time 
behavior speedup curves particular type workload characterization derived 
curves fig 
typical representative behaviors considered semi linear matrix size concave matrix size ranging flat matrix size 
efficiency measure fraction time processors busy 
efficacy describes processors 
increases maximum decreases 
number processors attains maximum processor working set pws number processors ratio benefit increase speedup cost decrease efficiency maximum 
pws coincides number processors corresponding knee execution time efficiency profile 
usually maximum obtained different values shows odd transposition sort elements obtained transputer machine linear array topology 
maximum speedup obtained processors maximum efficacy corresponds processors 
means marginal benefit allocating processors considered problem size cost associated additional processors 
pws maximizes performance index power ratio throughput response time 
characterization algorithms pws useful design studies processor allocation strategies investigated system tuning studies identification optimal system operating point 
parallelism profile gives number busy processors function time derived theoretically assuming idealized machine having unbounded number processors 
number processors system determines algorithm behavior fixing maximum number available processors measuring value real system appropriate behavior algorithm system described 
speedup curves block decomposition algorithm mesh topology 
parallelism profile decomposed computation profile plots number processors computing instant time communication profile corresponds number processors simultaneously communicating 
parallelism computation profiles block decomposition algorithm executed processors shown 
characteristics algorithm synchronism computations communications processors emphasized profiles 
computation phase interval time processors busy alternates communication phase processors exchanging data 
extreme phases initial loading processors submatrices loading results evident profiles 
concept matrix size speedup curves lu decomposition algorithm hypercube topology 
speedup efficacy odd transposition sort elements 
comp 
parall 
parallelism computation profiles block decomposition algorithm processors problem size 
phases parallel algorithm discussed 
information profile succinctly captured form representation referred shape 
representation cumulative plot fraction execution time certain number processors busy 
example shapes derived parallelism computation profiles obtained shown 
profiles shapes possible derive single value dynamic metrics average numbers busy computing communicating processors 
variability profiles small average values effectively characterize program behavior 
variability high distribution values required 
shape parallelism profile fraction time maximum minimum numbers processor utilized obtained 
fraction inherently sequential portion algorithm corresponds fraction time comp av 
comp 
parall 
av 
parall 
example shapes derived parallelism computation profiles 
processor active 
example shape fig 
processors busy execution time 
time processors computing 
detailed information activities processor timings respect global execution time provided horizontal bar diagrams see 
overlap processor activities instant execution time shown 
solid line segment indicates corresponding processor computing 
example horizontal bar diagram 
period time 
empty line segment indicates communication activity period 
supercomputers supercomputers high performance multiprocessors machines vector facilities designed large scientific engineering applications 
range possible performance improvements quite wide programs equal benefits see 
hardware software implementations systems strongly affect performance experienced users 
accurate characterization workload systems required 
depending objectives study workload model defined terms traditional parameters related physical resource consumptions global processor execution times number disk accesses application domains image processing structural analysis 
furthermore workload processed supercomputers described means parameters able capture behavior programs respect architectural aspects systems 
analysis source code applications information provided tools profilers pre compilers allows identification program characteristics directly related architectures 
examples parameters number floating point operations average vector length percentages scalar vectorized parallel code vector stride communication patterns number noncontiguous memory accesses see 
starting detailed characterization statistical analyses applied identifying classes representative components performance studies 
example case benchmarking popular technique employed assessing supercomputer performance careful accurate definition programs experiments carried 
workload characterization included preliminary step effective benchmarking see 
static dynamic workload characterization study cray mp 
job trace records analyzed functional resource levels 
jobs described terms cpu time time memory space time product subdivided clusters 
changes workload intensities average weekday analyzed characteristic periods identified transient periods increasing decreasing intensities stable periods fairly constant intensities respectively 
concluding section want mention additional metrics related properties programs way structured measured supercomputers see 
variation performance vector length captured parameters denote asymptotic performance measured mflops vector length necessary achieve half asymptotic performance respectively 
actual vector lengths programs compared order establish performance achieved 
shows function vector length values obtained cpu cray mp different operations dyadic triadic operations 
represented inverse slope negative intercept axis best fit line respectively 
particular equal mflops dyadic vector triadic operations 

dyadic operation vector triadic operation triadic operation 
workload characterization viewed settled discipline remarkably progressed 
methodologies techniques applied constructing workload models strictly related objectives studies type system tested centralized distributed parallel systems 
pointed problems encountered characterization workload centralized systems known approached solved quite long time 
similar drawn types architectures multiprocessor systems client server architectures distributed database systems 
increasing number hardware software components interacting performance systems heavily dependent characteristics load 
necessary identify set parameters able capture reproduce behavior evolution time workload components processed systems 
furthermore workload characterization process take account continuous evolution system architectures 
example case widely multi window workload described terms logical physical existing commands simultaneously active system 
heavily influence behavior user patterns requests submitted system 
appropriate techniques developed modelling type workload 
general identify steps seen common basis workload characterization study steps summarized follows ffl choice set parameters able describe behavior workload ffl choice suitable instrumentation existing performance monitoring tools construction ad hoc ones ffl experimental measurement collection ffl analysis workload data ffl construction static dynamic workload models 
sort customization phase steps required matching objective study type system test 
conclude workload characterization remains promising research field updated continuously new techniques making suitable requirements raised new architectures 
acknowledgment authors wish lo conti drawing ability 
ferrari 
measurement tuning computer systems 
prentice hall 
spat 
clustering algorithms data reduction classification objects 
ellis horwood publ uk 
hartigan 
clustering algorithms 
wiley 
ferrari 
foundations artificial workload design 
proc 
acm sigmetrics conference pages 

design workload analyser tool 
esprit document university pavia august 
ferrari 
workload characterization selection computer performance measurement 
computer 

construction representative synthetic workload 
comm 
acm 
bard 
characterization vm workloads 
editor modelling performance evaluation computer systems pages 
north holland 
ferrari 
performance oriented procedure modeling interactive workloads 
ferrari editors experimental computer performance evaluation pages 
north holland 

state dependent workload characterization software resources 
proc 
acm sigmetrics conference pages 

workload model representative static dynamic characteristics 
acta informatica 
editor 
workload characterization computer systems computer networks 
north holland 
king 
workload characterization 
cmg transactions pages 
marie trivedi 
system performance user behavior graphs 
performance evaluation 

construction multiclass workload models 
performance evaluation 
appear 
agrawala mohr bryant 
approach workload characterization problem 
computer pages 

functional resource oriented procedure workload modeling 
editor performance pages 
north holland 

stochastic models interactive workloads 
agrawala tripathi editors performance pages 
north holland 
ferrari 
sensitivity study clustering approach workload modeling 
performance evaluation 

characterization variation time workload arrival patterns 
ieee trans 
computers 
kearns 
diversity database behavior 
proc 
acm sigmetrics performance pages 

modeling data base behavior 
balbo editors computer performance evaluation modelling techniques tools pages 
northholland 
gaver price jr exploratory analysis access path length data data base management system 
ibm journal research development 
lewis 
statistical analysis non stationary series events data base system 
ibm journal research development 
artis 
capacity planning mvs computer systems 
ferrari editor performance evaluation computer installations pages 
north holland 
tanenbaum 
computer networks nd edition 
prentice hall 

measured performance ethernet local network 
comm 
acm 

measurement study diskless workstation traffic ethernet 
ieee trans 
communications 
segal srinivasan 
design tool large scale heterogeneous computer networks 
ieee journal selected area communications 
acharya newman wolfe chow 
realtime hierarchical traffic characterization campus area network 
editors computer performance evaluation modelling techniques tools pages edinburgh scotland 
bunt 
synthetic workload model distributed system file server 
proc 
acm sigmetrics conference pages 

token ring local area networks performance 
proc 
ieee 
tobagi 
performance effects station locations access protocol parameters ethernet networks 
ieee trans 
communications 
ferrari verma 
scheme real time channel establishment wide area networks 
ieee journal selected area communications 

workload modeling computer networks 
kastens editors und von pages 
springer verlag 
tsitsiklis 
parallel distributed computation numerical methods 
prentice hall 

multiprocessor performance 
wiley series parallel computing 
stone 
multiprocessor scheduling aid network flow algorithms 
ieee trans 
software engineering se 
fox johnson otto salmon walker 
solving problems concurrent processors volume prentice hall 
lord kumar 
solving linear algebraic equations mimd computer 
acm 
park wagner 
parallel workload characterizations comparisons mappings 
technical report dept computer science vanderbilt university 

modeling partitioned multiprocessor systems 
int 
journal high speed computing 
appear 

characterization numerical algorithms distributed memory multiprocessors 
technical report 
progetto sistemi italian cnr rome 
smirni carlson 
robust partitioning policies multiprocessor systems 
performance evaluation 
appear 
tripathi 
processor working set scheduling multiprocessor systems 
ieee trans 
software engineering 
eager zahorjan lazowska 
speedup versus efficiency parallel systems 
ieee trans 
computers 

experimental evaluation internal sorting algorithms transputers 
becker editor int 
conf 
transputers advanced research industrial applications pages 
ios press 
kleinrock 
power deterministic rules thumb probabilistic problems computer communications 
international conference communications pages 
kumar 
measuring parallelism computation intensive scientific engineering applications 
ieee trans 
computers 
carlson wagner 
speedup properties phases execution profile distributed parallel programs 
editors computer performance evaluation modelling techniques tools pages edinburgh scotland 
sevcik 
characterizations parallelism applications scheduling 
proc 
acm sigmetrics performance pages 
martin 
supercomputer performance evaluation comparative analysis highspeed architectures applications 
martin editor performance evaluation supercomputers pages 
north holland 
martin 
methodology characterizing scientific workload 
pages 
simmons 
close look vector performance register vector computers new model 
proc 
acm sigmetrics conference pages 

workload characterization supercomputers 
martin editor performance evaluation supercomputers pages 
north holland 
jordan 
performance comparison large scale scientific computers scalar mainframes mainframes integrated vector facilities supercomputers 
ieee computer 
pasquale 
static dynamic workload characterization study san diego supercomputer center cray mp 
proc 
acm sigmetrics conference pages 

measurements cpu cray mp 
parallel computing 

problem related performance parameters supercomputers 
martin editor performance evaluation supercomputers pages 
north holland 
