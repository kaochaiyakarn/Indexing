heterogeneous uncertainty sampling supervised learning david lewis jason catlett bell laboratories murray hill nj lewis research att com catlett research att com appeared william cohen haym hirsh eds machine learning proceedings eleventh international conference morgan kaufmann publishers san francisco ca pp 

uncertainty sampling methods iteratively request class labels training instances classes uncertain despite previous labeled instances 
methods greatly reduce number instances expert need label 
problem approach classifier best suited application may expensive train selection instances 
test classifier highly efficient probabilistic select examples training rule induction program 
despite chosen heterogeneous approach uncertainty samples yielded classifiers lower error rates random samples times larger 
machine learning algorithms build classification rules data sets consisting hundreds thousands instances 
applications unlabeled training instances abundant cost labeling instance class high 
information retrieval application described class labels assigned human assigned computer simulation combination 
terms oracle teacher source labels usually call expert 
constraints induction process limit number instances oracle choice instances important 
random sampling may ineffective class rare training instances may majority class 
effective expert time methods collectively call uncertainty sampling label data sets incrementally alternating phases presenting expert instances label selecting finite infinite source instances labels uncertain despite indications contained previously labeled data 
type classifier uncertainty sampling cheap build 
iteration new classifier built fortunately small sample applied unfortunately large sample 
uncertainty sampling method requires estimate certainty classifications class probability value induction systems provide 
examines heterogeneous approach classifier type selects instances training classifier type 
motivated applications requiring type classifier computationally expensive select instances 
section reviews research uncertainty sampling 
section points class frequencies uncertainty samples severely distorted training algorithm accept parameter correct 
experiments described section large text categorization data set showed method correction effective robust respect particular parameter value 
uncertainty samples chosen probabilistic classifier significantly better random samples times larger modification quinlan algorithm 
section lists 
background theoretical analysis practical experience shown classifier built fewer instances learning algorithm allowed create artificial instances membership queries expert label 
unfortunately queries may create nonsensical examples pregnant non smoking male high risk heart disease 
applications instances images natural language texts arbitrary membership queries implausible 
algorithms proposed base querying filtering stream unlabeled instances creating artificial instances 
expert asked label instances class membership sufficiently uncertain 
definitions uncertainty sufficiency esti 
obtain initial classifier 
expert willing label instances apply current classifier unlabeled instance find instances classifier certain class membership expert label subsample instances train new classifier labeled instances algorithm uncertainty sampling finite training set single classifier 
mating classifier consistent previously labeled data produce correct class label unlabeled instance 
approaches viewed combination stratified sequential approaches sampling refer uncertainty sampling 
simple form uncertainty sampling possible classifiers operate testing numeric score threshold 
single classifier trained instances scores closest classifier threshold candidates expert 
set instances finite single instance score closest threshold stream instances effectively infinite choose instances scores distance threshold 
cycle described finite case 
single classifier approaches uncertainty sampling criticized grounds classifier representative set classifiers consistent labeled data version space 
degree problem practice established 
single classifier approaches successfully generating arbitrary queries sampling labeled data 
uncertainty sampling single classifier viewed variation heuristic training misclassified instances 
familiar example windowing appeared quinlan id questioned re examined chapter book 
uncertainty sampling windowing builds sequence classifiers selecting instances add training set iteration 
key difference assumption class labels training instances known examines order choose misclassified examples add 
large scale test uncertainty sampling single classifier approach showed uncertainty sampling reduce factor amount data labeled achieve level accuracy 
heterogeneous uncertainty sampling uncertainty sampling requires construction large numbers thousands classifiers applied large numbers examples 
suggests kind classifier loop sampling cheap build run 
unfortunately uncertainty sample strong connections classifier form select despite containing disproportionately large number instances low frequency classes yields accurate classifier 
characteristics sample cause happen form classifier effect instances different attribute values suggest different classes 
effect perfect classifiers form selection 
new classifier trained uncertainty sample unduly biased predicting low frequency classes 
mechanism counterbalance effect needed 
feature cart software decision trees specifying priors classes application required decision rules 
version modified catlett accept parameter specifying relative cost types error false positives false negatives chapter 
call number loss ratio lr 
loss ratio indicates errors equal costs original assumption 
loss ratio greater indicates false positive errors classifier built training set enriched positive instances costly false negative errors positive instance classified negative setting loss ratio counterbalance positive instances exactly 
question motivates sensitivity analysis effect parameter accuracy classifiers produced 
modifications left selection criterion unchanged contrast cart treatment 
building trees original checks split decreases error rate replaces split leaf build line disabled preempts construction rules classes examples 
class values leaves determined majority vote comparison probability threshold lr lr reciprocal appropriate 
pruning minimizes expected loss estimated errors simply lr usual correction 
similar change minimum error rate required drop rule 
choice default class expected loss estimates number examples left uncovered rule appeared low arbitrary factor introduced counterbalance 
problematic question adapt sifting rules class guided mdl principle 
current implementation simply multiplies coding cost false positives false negatives lr lr appropriate increase coding cost rulesets expensive error 
step lacks theoretical justification performance appeared satisfactory 
task data set applications motivating research fall heading text categorization classification instances composed partly fully natural language text pre specified categories 
business applications categorizing text aid routing analysis 
texts reside large databases supporting boolean queries pages restricted version propositional logic 
decision rules converted form probabilistic models requiring arithmetic choice final classifier 
important advantage comprehensible humans decision trees 
databases contain hundreds thousands unlabeled instances uncertainty sampling natural approach 
discussed section current decision rule induction software uncertainty sampling large text databases 
decided test heterogeneous approach uncertainty sampling 
key aim research reduce time spent human experts categorizing texts hardly ask label instances sake experiments 
data set similar properties applications titles stories categorized news agency 
collected electronic form titles articles appeared ap newswire early 
divided randomly training set titles test set titles 
titles converted lower case punctuation removed 
distinct word treated binary attribute resulting attributes 
data matrix extremely sparse instance having average nonzero attribute values 
ap data labeled types subject categories 
defined binary categories ap titles keyword line article page 
frequency information categories table 
categories chosen resemble applications interest approximately instances positive classes somewhat noisy perfectly determined text 
stories randomly allocated test set probability 
goal test set positive instances category 
training test category number percent number percent bonds ireland budget hostages table categories experiments number percentage positive occurrences training test sets 
training text data modification quinlan software produce decision rules training data select examples impractical large text databases requires training test instances tuples specifying values attributes 
training instances attributes required gigabytes 
expanding data stressed 
algorithm implemented manner suited sparse data machine learning software feature 
eliminating attributes take value true times training data left attributes cost eliminating useful attributes 
feature selection methods requiring class labels solution labels unknown 
uncertainty sampling probabilistic classifier methods efficient training probabilistic classifiers large sparse data sets widely information retrieval 
type classifier select instances uncertainty sampling 
model described detail brief gives estimate probability instance belongs class cjw exp log jc exp log jc indicates class membership ith attribute values vector instance 
instance assigned class cjw exceeds 
intuition model jc plausible approximation exact certain independence assumptions class priors hold likelihood ratio wjc wj predictor class membership 
scaled provide explicit estimate cjw 
approach scaling logistic regression 
training proceeds follows 
values jc estimated word estimation uses sparse representation data requires seconds training instances 
large values theta log jc selected features strategy useful text classification problems 
value jc computed training instance training data set logistic regression 
classifier sort trained iteration uncertainty sampling applied unlabeled training instances 
instances estimated cjw closest selected instances cjw closest 
subsample size compromise efficiency 
selecting examples simple way halve potential number duplicate examples may benefits training 
initial classifier initial classifier sampling algorithm commence long period nearly random sampling finding examples low frequency class 
obtaining plausible initial classifier usually easy surprising expert able classify instances suggest positive negative instances attribute values correlated class 
experiments generated initial classifiers positive instances category selected randomly avoid experimenter bias 
feature selection cost specifying values attributes small training set large feature selection needed presenting data 
union sets words attributes alternatively view node neural net input weights set probabilistic model error propagation 

words occurring instances 
words occurring positive instances 
words occuring initial positive instances 
experiment design experiment tested heterogeneous uncertainty sampling produce decision rules significantly lower error rates trained random samples larger size 
wanted determine sensitivity rules accuracy loss ratio 
sources variability included categories quality starting classifiers vagaries random sampling 
repeated uncertainty sampling process times trials binary categories different random set initial positive instances 
run initial instances build initial classifier uncertainty sampling subsample size run iterations 
yielded groups uncertainty samples various sizes 
trained rules uncertainty samples run instances final instances 
values loss ratio ratio loss incurred false positives loss incurred false negatives tested 
comparison applied samples size produced adding random instances sets starting positive instances initialize uncertainty sampling 
starting positive instances retained comparison fair random sampling 
samples size produced adding additional random examples samples size 
refer samples random completely random 
analyses samples size 
interested difference accuracy compared instance selection loop 
practicable test directly train probabilistic classifiers uncertainty random samples provide comparison 
results shows average error rates rules trained uncertainty samples size various loss ratios categories 
tenth category resulted degenerate classifiers instances classified category nonmembers conditions 
cases error rates uncertainty samples size close better random sample instances provided loss ratio 
loss ratio error rate cent bonds loss ratio error rate cent number errors loss ratio number errors loss ratio error rate cent loss ratio error rate cent number errors ireland loss ratio number errors loss ratio error rate cent budget loss ratio error rate cent number errors hostages loss ratio number errors average error rate rules trained uncertainty samples size black dots white dots various loss ratio values 
average error rates rules trained random samples size large dashes small dashes shown dashed lines 
percentage positive instances training set follows category name triangles indicate percentage test set 
uncertainty random reject lr prob 
lr lr prob 
lr category average sd average sd average sd average sd bonds ireland budget hostages table average standard deviation percentage error various classifiers 
reject classifier deems instances non members category 
types training set uncertainty sample size random sample size 
types classifier built training set decision rule classifier trained probabilistic classifier described text 
uncertainty sample loss ratio random sample loss ratio original 
figures averages runs classifiers built random samples probabilistic method runs combinations 
uncertainty random reject lr prob 
lr lr prob 
lr category fp fn fp fn fp fn fp fn fp fn bonds ireland budget hostages table average number false positives fp false negatives fn categories conditions 
experiment conditions table 
table lists error rates classifier uncertainty sampling 
figures loss ratio uncertainty samples unmodified random samples 
probabilistic classifier uses loss ratio cases 
table shows errors divide false positives false negatives 
discussion shows uncertainty sample instances situations training rules random sample instances 
loss ratio significantly better random sample instances 
cases uncertainty sample instances reliable 
expected necessary loss ratio greater training rules 
fortunately leeway choosing loss ratio error rates produced values highest value tried data 
results show heterogeneous uncertainty sampling effective 
table presents data larger uncertainty samples random samples tabular form 
point extremely low category frequencies table indicate error rate strategy classifies instances nonmembers 
strategy low error rate useful 
cases classifiers manage beat error rate evaluation measure penalized false negatives show greater advantage trained classifiers 
table shows error rates probabilistic classifier samples selected random samples size 
significantly better probabilistic classifier random sample better uncertainty sample 
suggests suitable text categorization task probabilistic classifier penalty accuracy heterogeneity uncertainty sampling 
table similar table shows false positives false negatives separately 
shows total numbers errors produced classifiers substantially smaller total number strategy rejects instances errors balanced false positives false negatives 
section discuss unexplored directions believe rich area study 
significance score 
null hypothesis differences average error rate runs category normally distributed mean zero category specific variance 
believe uncertainty sampling sequential active exploratory approaches learning enable learning research learning applications large complex real world data sets fixed training sets impracticable 
natural language processing great interest inducing knowledge support tagging parsing semantic interpretation forms analysis particularly fruitful application area 
heterogeneous approaches common response resource limitations desire train new algorithms previously generated uncertainty samples 
better understanding minimize problems caused heterogeneous approach desirable 
note treated large finite set instances infinite 
adapting results sequential sampling may possible improve uncertainty sampling tell additional iterations longer providing benefit juice squeezed data set 
contrast assumptions theoretical querying categories stochastic deterministic 
classifier may indicate probability category membership classifier incompletely trained expert may really classify instances category members time 
seen evidence instances selected iterations uncertainty sampling run 
instances best ones training 
suggests goal producing classifier estimates cjw accurately simply classifying accurately 
variance estimate important may appropriate treat problem regression interpolation classification 
summary partially formed classifiers select training data incrementally reduce number instances expert label achieve error rate 
experiments show reduction possible uncertainty sampling heterogeneous classifiers select instances different type built final sample 
decision rules produced uncertainty samples roughly instances chosen probabilistic classifier significantly accurate random samples times larger 
ability cheap classifiers select data training expensive classifiers uncertainty sampling attractive variety applications large amounts unlabeled data available 
william cohen fitzpatrick yoav freund william gale trevor hastie doug mcilroy robert schapire sebastian seung advice useful comments ken church help text processing tools 
dana angluin 
queries concept learning 
machine learning 
bratko lavrac 
study deep qualitative knowledge expert systems 
mit press cambridge massachusetts 
leo breiman jerome friedman richard olshen charles stone 
classification regression trees 
wadsworth belmont ca 
catlett 
test flight 
machine learning proceedings eigth international workshop pages san mateo ca 
morgan kaufmann 
william cochran 
sampling techniques 
john wiley sons new york rd edition 
david cohn les atlas richard ladner 
improving generalization self directed learning 
appear machine learning 
stuart crawford robert fung lee richard tong 
classification trees information retrieval 
eighth international workshop machine learning pages 
daniel davis hwang 
attentional focus training boundary region data selection 
international joint conference neural networks pages baltimore md june 
james egan 
signal detection theory roc analysis 
academic press new york 
freund seung shamir tishby 
information prediction query committee 
advances neural information processing systems san mateo ca 
morgan kaufmann 
william gale kenneth church david yarowsky 
method disambiguating word senses large corpus 
computers humanities 
ghosh 
brief history sequential analysis 
ghosh sen editors handbook sequential analysis chapter pages 
marcel dekker new york 
norm goldstein editor 
associated press manual 
addison wesley reading ma 
donna harman 
ranking algorithms 
william frakes ricardo baeza yates editors information retrieval data structures algorithms pages 
prentice hall englewood cliffs nj 
peter hart 
condensed nearest neighbor rule 
ieee transactions information theory may 
reprinted agrawala machine recognition patterns ieee press new york 
hwang jai choi oh robert marks ii 
query learning applied partially trained multilayer perceptrons 
ieee transactions neural networks january 
igor ivan bratko 
experiments automatic learning medical diagnostic rules 
technical report jozef stefan institute ljubljana slovenia 
david lewis william gale 
training text classifiers uncertainty sampling 
seventeenth annual international acm sigir conference research development information retrieval 
appear 
david lewis philip hayes 
editorial 
acm transactions information systems 
special issue text categorization 
appear 
david mackay 
evidence framework applied classification networks 
neural computation 
david mackay 
information objective functions active data selection 
neural computation 
michel 
knowledge intensive induction 
machine learning proceedings sixth international workshop pages 
mccullagh nelder 
generalized linear models 
chapman hall london nd edition 
tom mitchell 
generalization search 
artificial intelligence 
mark white 
selecting concise training sets clean data 
ieee transactions neural networks march 
quinlan 
discovering rules induction large collections examples 
expert systems micro electronic age edinburgh uk 
edinburgh university press 
ross quinlan 
programs machine learning 
morgan kaufmann san mateo ca 
quinlan 
decision trees probabilistic classifiers 
proceedings fourth international workshop machine learning pages irvine california 
gerard salton 
processing transformation analysis retrieval information computer 
addison wesley reading ma 
claude sammut scott hurst dana donald michie 
learning fly 
ninth international workshop machine learning pages 
seung opper sompolinsky 
query committee 
proceedings fifth annual acm workshop computational learning theory pages 
kumar sinha 
sequential methods finite populations 
ghosh sen editors handbook sequential analysis chapter pages 
marcel dekker new york 
paul utgoff 
improved training incremental learning 
sixth machine learning pages 
weiss robert galen prasad tadepalli 
maximizing predictive value production rules 
artificial intelligence september 
winston 
learning structural descriptions examples 
winston editor psychology computer vision pages 
mcgraw hill new york 
wirth catlett 
costs benefits windowing id 
proceedings fifth international conference machine learning ann arbor michigan 
morgan kaufmann 
