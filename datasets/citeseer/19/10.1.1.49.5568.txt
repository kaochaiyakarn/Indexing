cooperation observation framework basic task patterns kuniyoshi makoto ishii kita intelligent systems division electrotechnical laboratory tsukuba city ibaraki japan institut informatique jean france tokyo university cho ku tokyo japan novel framework multiple robot cooperation called cooperation observation 
introduces interesting issues viewpoint constraint role interchange novel concepts attentional structure 
framework potential realize high level task coordination decentralized autonomous robots allowing minimum explicit communication 
source power lies advanced capability robot recognizing agent actions primarily visual observation 
provides rich information current task situation robot facilitates highly structured task coordination 
basic visuo motor routines described 
concrete examples experiments real mobile robots 
order execute complex tasks multiple mobile robots achieve superlinear increase task performance number robots need variety flexible highly structured coordination robot behaviors 
method coordination strong restrictions imposed distributed asynchronous nature entire system minimum explicit communication decentralized control real time response 
attempts achieve appropriate balance goal restrictions 
approaches especially look implementations real mobile robots consistent tendency higher level coordination restriction violated 
novel framework multiple robot cooperation called cooperation observation potential realize high level task coordination decentralized autonomous robots allowing minimum explicit communication 
source power lies advanced capability robot recognizing agent actions primarily visual observation 
provides rich information current task situation robot facilitates highly structured task coordination 
aspect extraction interpretation variety concrete information current task situation effects task execution largely unexplored 
section look related extend discussion 
section presents framework discuss implications 
basic visuo motor routines constitutes fundamental behaviors briefly section 
concrete examples experiments real mobile robots section 
final section summaries results proposes directions framework 
related previous literature level task coordination roughly parallels amount explicit communication robots 
communication extremes steels brooks arkin rely indirect interactions robot behaviors physical states environment 
variety tasks realized approaches limited collecting scattered rock samples 
contrast highest levels cooperative tasks demonstrated real mobile robots noreils distributed planning methods rely intensive inter robot communication 
closer analyses balance local vs global control effect communication task 
mataric analyzed demonstrated effect local inter agent sensing ability implicit communication performance navigation flocking behavior group robots 
arkin analyzed effect broadcasting robot coordinates goal achieving states performance cooperative navigation 
parker explored proper balance local vs global information formation keeping cooperative navigation team locally controlled agents 
transferred shared information included global navigation goal intermediate goals complete global path 
suggested behavior observation anticipation 
lines mataric arkin especially parker assume implicit communication agent sensing ability shared knowledge global goals 
introducing capability visually recognizing agents actions anticipating forthcoming events attempt achieve high levels task coordination amount explicit communication 
specifically demonstrate types cooperative behaviors posing unblocking passing absolutely explicit communication robots 
cooperation observation kinds social animals including humans show highly coordinated group behaviors explicit communication 
example carry group hunting successfully silence 
everyday life routinely perform cooperative tasks speaking thinking 
typical example carrying large baggage hands approaches closed door person near open door 
action understanding ability tacit cooperation action understanding 
defined process observe agent action choose appropriate actions regarding observed action current task situation 
observation portion process refined classify qualitative movement agent body look target action causality anticipate detect effect movement target 
machine understanding limited class human actions developed 
possibility coordinated manipulation force observation explicit communication shown 
details theory implementation action understanding scope see 
important note action understanding provides significantly richer information ongoing task situation previous implicit communication methods exchanging agent position goal achievement state 
acquired information includes movements relative positions relative velocity agents regarding objects states objects temporal evolution 
agents objects define relations automatically selected attention control meaningful relative current task observer 
attention switching qualitative events temporal segmentation observed task situation automatically done synchronizing ordering behaviors different robots 
examples functions section 
assumptions assumptions characterize framework cooperation observation 
local control central processor central database 
robot controls behavior 
communication explicit inter robot communication minimized 
shared knowledge members robot team share static portion global knowledge high level task goals common strategies 
complex dynamic environment objects robots scattered task space 
current task specific robot objects robots relevant independent 
task complexity order achieve global goal highly structured coordination multiple robot actions required 
structures defined terms temporal ordering synchronization combination actions relative positions movements 
benchmark task dozens robots carry various sizes shapes weight scattered warehouse outside narrow door soon possible 
homogeneous robots robots equivalent structures physical ability cognitive competence 
observation ability robot equipped appropriate sensors ex 
stereo vision proximity force touch recognition routines observing robot actions 
issues interesting problems arise assumptions 
selective attention action recognition requires extracting causally related pair movement effect 
observation complex environment mandatory dynamically select observe relevant entities surroundings 
viewpoint constraint central database explicit communication strictly limited 
bird eye view global model task situation obtained 
observations viewpoint robot 
interchange roles merit homogeneous robots role robot dynamically changed task situation 
example robot auxiliary helper situation independent task performer situation 
improves performance robot group 
important issue dynamically select appropriate role local observations 
sensing robot sensory functions appropriate action recognition complex environment 
combination controlled vergence stereo vision optical flow analysis quite powerful 
candidate methods including sensor modalities force touch sensing audio behaviors real time responses behavior architecture extensions incorporate attention control qualitative representations cooperative task patterns 
strong candidate proposed chapman 
modified meet viewpoint constraint deal gaze shifts maintaining limited temporal persistence spatial cognition 
representation situations order select appropriate actions regarding current role task state robot internal qualitative representations cooperative behavior patterns 
representation describe partial aspects target situation characterize type cooperation 
infinite instances actual positions movements robots objects qualitative situation 
number permutations roles situation increase exponentially number robots contained need efficient way handle role interchange 
grounded communication communicated information grounded local situation robot uses 
basically information qualitative relative receiver current action state 
generate useful information robots received information challenging problem 
attentional structure chance jolly classified social structures monkeys apes categories 
society formed superior male 
members society mainly pay attention behavior male control behaviors 
attacked superior male go front defense retreat followed 
society behaves opposite way scatters attack 
idea attentional structure quite important explains various social structures grounded action observation 
conversely attention control action observation process candidate driving force emergence various social structures 
examples attentional structures illustrated fig 

ground instances animal societies 
original notion attentional structure describes purely social interactions 
group robots engage cooperative task consider physical interactions objects 
partnership orders loop leadership team swarm agent attention fig 
attentional structures 
adopt generalized version notion attentional structure attentional structure set attentional relations members cooperative group related objects 
attentional relation describes watches actions watches object order control self behavior 
classification cooperative behaviors framework cooperation observation introduces wide variety cooperative task patterns 
preliminary study choose example tasks shown fig 
analyze structures regard features number robots nr objects involved attentional structure physical interactions involved robots objects temporal relations robot actions rt ordered ord simultaneous sim robot cases 
assume robot manipulate object nr direct physical contact robots 
possible attentional structures uni directional bi directional 
patterns pushing tumbling rt sim fr gg 
basically robots need observe vision force sensing physical state coordinating behaviors 
tumbling requires tighter coordination pushing 
patterns involve physical interactions objects robots task visual observation mandatory coordination 
pattern giving way simplest case rt sim fr gg 
just stopping waiting keeps constant distance orientation preparatory behavior helping call posing behavior 
mutual avoidance formation keeping fall category bi directional attention 
pattern passing requires sequencing actions frt ord 
attentional structure uni directional fr case robots grasp object pass free space bidirectional attention necessary 
pattern unblocking rt complex situation transporter robot carrying object path blocked obstacle 
limited maneuvering ability costs time avoid 
helper recognizes situation helps approaching pushing away 
similar simpler version demonstrated noreils explicit communication 
pattern achieved uni directional attention fa fr gg flexibility increases bi directional type applied 
example case fails approach wait recover accomplish unblocking 
final pattern cargo loading rt sim fr gg requires tight coordination visual observation 
fig 
cooperative task patterns pushing 
tumbling 
giving way 
passing 
unblocking 
cart loading 
basic visuo motor functions implemented set visuo motor functions serves basis cooperative behaviors 
algorithms selected meet conditions section especially complex environment robots objects viewpoint constraint 
currently assume mobile robot vergence fig 
situation recognition unblocking task left recognition release action right 
stereo cameras arm 
contains major functions required example tasks section 
details vision algorithms scope describe briefly 
find redirects observer attention new target moving robot obstacles 
optical flow field continuously computed incremental version horn schunck algorithm 
current implementation executes iterations frame acquisition msec 
noise removal local averaging applied 
flow field compared theoretical background flow cancel self motion detect interesting targets 
order deal significant noise flow field currently assume pure translation pure rotation self motion comparison coarsely quantized intensity orientation flow vectors 
background flow rotation trivial 
translation compute theoretical flow produced virtual vertical wall front robot preset distance time collision self velocity 
virtual wall field threshold ignore distant targets extract close obstacles quickly approaching robots 
result field segmented clustering residual vectors 
method detect moving static objects moving robot 
track strong spatial selectivity required tracking complex environment 
adopt vergence controlled stereo zero disparity filtering strong depth selectivity 
extracts zero disparity image features extracting vertical edges left right edge images simply results 
result contains features lying horopter circle defined camera centers current fixation point 
combination classical region interest method system actively select region extract visual information 
output edges tracked controlling vergence angle stereo cameras 
order follow target motion depth axis extended original incorporating limited search near zero disparities find best match feedback result vergence control 
anticipate situation fig 
left helper need anticipate possible collision 
target motion tracked constant distance line fit recorded trajectory mean square method 
system quickly scans gaze point line vergence control 
scan output continuously monitored detect object 
experimental result shown fig 
right 
near zero disparity search turned phase time top specification target depth 
event detection passing type task receiving robot synchronize action recognizing release action robot 
done monitoring temporal change segmented fig 
tracking mobile robot left 
trajectory estimation obstacle detection right 
figures raw stereo images shown top extracted edges middle outputs bottom right results computation shown bottom left 
processing done near frame rate hz 
optical flow field shown fig 
right 
event signalled area segmented flow suddenly decreases average velocity area reversed sandini similar method recognizing push action 
order simplify computation cope noise assume observer moving detecting release action approximate segmented region surrounding rectangle current implementation 
navigation guides robot target position unblocking situation fig 
left released object passing situation fig 
right 
constraints robot take straight line path visible target unblocking situation robot uses visual guidance 
steering angle selected deg sign displacement angle current fixation point cameras current forward direction mobile base 
course crude control converge sufficient preliminary experiments cycle time short msec compared speed mobile base 
cases robot directly approach target follow precomputed trajectory 
example passing situation receiver robot push target object direction robot 
cases robot compute approach path order cope nonholonomic nature preserve approach distance visual guidance routine correct significant odometric error self orientation imposed turning desired pushing direction 
example tasks order verify effectiveness visuo motor routines concrete examples cooperation observation realized task patterns posing passing unblocking 
prototype system total spec length width height weight kg max speed gaze platform dof verge baseline range deg precision deg max speed deg fig 
mobile robot stereo gaze platform 
fig 
shows mobile robot equipped stereo gaze platform 
gaze platform dof vergence control 
robot onboard processors controlling mobile base gaze platform 
image processing currently done remote host processor consists pipeline image processors gaze platform cameras mhz host processor rs actuators mobile base mhz actuators mobile robot fig 
overview prototype system 
datacube system cpu board running real time operating system 
system configuration fig 

posing target distractor fig 
chasing target robot left attentional structure right 
situation posing experiment illustrated fig 

mission robot keep fixed relative position distance orientation regard target robot 
distractor robot moving comes target 
lock target 
simplest example attentional structure emerges local attention relations 
basic behavior supports cooperative behaviors complex dynamic environments 
case target form ordered pair distractor isolated spatially level cooperative behaviors 
result shown fig 

experiment computer controlled manually controlled 
purpose experiment test stereo tracking visual servo routines 
turned quite robust 
passing realized pass behavior pattern shown fig 

shows result motion segmentation release detection 
released detected receiver robot starts follow computed approach trajectory 
done open loop manner fig 
vision processing receiving action view receiver robot 
segmented optical flow region including robot 
release action detected 
released segmented 
followed approach path 
approach behavior visual servo optical flow 
white marker indicates target position 
ing temporally spatial memory 
making steep turn visible robot approaches visual guidance 
shows bird eye view entire situation 
evidently passing behavior pattern successfully demonstrated 
unblocking simplified experiment unblocking task discussed 
experiment transporter robot carry object different fig 

simplification justified purpose experiment verify behavior helper 
fig 
shows result 
helper robot successfully anticipated obstacle helped transporter robot pushing away obstacle just time transporter pass 
summary novel approach achieving highly structured task coordination resorting explicit communication 
supported mutual observation actions framework called cooperation observation 
main contribution framework focus fig 
posing behavior 
left follows target moving downward 
distractor moving upward comes target disturbed locks target 
extraction interpretation useful information task coordination cooperating autonomous agents 
framework introduces interesting issues viewpoint constraint role interchange novel concepts attentional structure classifying cooperative task patterns 
major contribution presents working examples high levels cooperative tasks implicit communication visual action recognition 
advanced examples implicit communication framework demonstrated real mobile robots 
basic visuo motor functions characterized spatial selectivity anticipatory functions dynamic nature 
routines basically general utility need refinement augmentation 
especially functions need realized quick robust methods finding identifying objects multiple attention parallel processing 
experiments autonomous robot acting helper fixed program manually controlled robots 
robot system completely independent problem duplicating prototype system 
done achieve versatile implementation cooperation observation including qualitative representation cooperative task patterns dynamic selection appropriate cooperative behavior large number potential patterns implementation role interchange treatment shared knowledge 
steels 
cooperation distributed agents selforganization 
proc 
ieee int 
conf 
intelligent robots systems 
brooks lunar base construction robots 
proc 
ieee int 
workshop intelligent robots systems pages 
arkin 
cooperation communication multiagent schema robot navigation 
robotic systems 
mataric 
minimizing complexity controlling mobile robot population 
proc 
ieee int 
conf 
robotics automation pages 
parker 
designing control laws cooperative agent teams 
proc 
ieee int 
conf 
robotics automation pages 
arkin 
communication behavioral state multi agent retrieval tasks 
proc 
ieee int 
conf 
robotics automation pages 
noreils 
architecture cooperative autonomous mobile robots 
proc 
ieee int 
conf 
robotics automation pages 
decentralized cooperative sensing system robot vision 
proc 
rd int 
symp 
industrial robots pages 

consideration cooperation multiple autonomous mobile robots 
proc 
ieee int 
workshop intelligent robots systems pages 
wilson 
sociobiology new synthesis 
harvard 
kuniyoshi inoue 
qualitative recognition ongoing human action sequences 
proc 
ijcai pages 
hirai sato 
motion understanding world model management 
proc 
pages 
ikeuchi 
assembly plan observation 
technical report cmu cs school computer science carnegie mellon univ pittsburgh pa usa 
inoue 
cooperative manipulation autonomous intelligent robots 
conf 
robotics mechatronics pages 
japanese 

colony architecture artificial creature 
technical report ai tr mit ai lab 
chapman 
vision instruction action 
mit press 
isbn 
chance jolly 
social groups monkeys apes men 

horn schunck 
determining optical flow 
artificial intelligence 
von brown coombs 
detecting regions zero disparity binocular images 
technical report university rochester 
kita kuniyoshi 
tracking moving object stereo camera head 
proc 
th annual conf 
robotics society japan 
appear 
sandini 
dynamic aspects active vision 
cvgip image understanding 
fig 
passing task 
robot pushing left right 
robot releases returns fetch helper robot recognizes situation 
helper robot determines pushing direction starts follow computed approach trajectory 
helper robot approaches visual servo 
pushing direction robot 
fig 
unblocking behavior binocular robot helper left watched monocular transporter robot moving right left estimated path possible obstacle path top quickly approached obstacle visual servo middle successfully pushed away help transporter bottom 
