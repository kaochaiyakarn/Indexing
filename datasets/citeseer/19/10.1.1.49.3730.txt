multiple time scales multi stream speech recognition system st ephane dupont herv bourlard fpms belgium idiap martigny switzerland email dupont fpms ac bourlard idiap ch propose investigate new approach multiple time scale information automatic speech recognition asr systems 
framework particular hmm formalism able process different input streams recombine temporal anchor points 
phonological level recombination defined priori optimal temporal anchor points obtained automatically recognition 
current approach parallel cooperative hmms focus different dynamic properties speech signal defined different time scales 
speech signal defined terms information streams stream resulting particular way analyzing speech signal 
specifically current models aimed capturing syllable level temporal structure parallel classical phoneme models 
tests different continuous speech databases show significant performance improvements motivating research efficiently large time span information order ms standard ms phone asr systems 

multi stream approach discussed principled way merging different sources temporal information possibly asynchronous different frame rate potential advantages 
approach assumed speech signal described terms multiple input streams stream representing different characteristic input signal 
streams supposed entirely synchronous may accommodated simply 
case frame rate 
multi stream approach discussed allows deal 
framework input streams processed independently certain anchor points synchronize recombine partial segment likelihoods 
phonological level recombination defined priori optimal temporal anchor points obtained automatically recognition 
supported fonds pour la formation la recherche dans dans agriculture belgium 
affiliated intl 
computer science institute berkeley ca 
case subband recognition particular case multi stream recognition shown databases approach yielding significantly better noise robustness 
general idea subband approach split frequency band represented terms critical bands subbands different recognizers independently applied recombined certain speech unit level yield global scores global recognition decision 
subband approach potential advantages including possibility better accommodate possible asynchrony different components speech spectrum 
feature investigated current possibility incorporate multiple time resolutions part structure multiple length units phone syllable 
framework possible define subword models composed cooperative hmm models focusing different dynamic properties speech signal 
results preliminary require development 
show quite clearly proposed multi stream approach provide promising way modeling syllable length information spanning ms information standard ms phone asr systems 

multi stream statistical model briefly address problem recombining information sources represented different input streams see detailed discussion mathematical formalism 
case observation sequence representing utterance recognized assumed composed input streams xk possibly different lengths different frame rates 
hypothesized model associated built concatenating sub unit models associated sub unit level want perform recombination input streams syllables allow processing input streams independently pre defined sub unit boundaries determined automatically decoding sub unit model composed parallel models possibly different topologies forced recombine respective segmental scores temporal anchor points 
resulting model il recombination sub unit level general form stream recognizer anchor points speech units force synchrony different streams 
note model topology necessarily different subsystems 
fig 

model note ffl parallel hmms associated input streams necessarily topology 
ffl recombination state regular hmm state responsible recombining possible rules discussed probabilities likelihoods accumulated temporal segment streams 
course done possible segmentation points 
problem appears similar continuous speech recognition problem concurrent word segmentations phone segmentations hypothesized 
recombination concerns sub unit paths time best state path sub stream models necessary keep track dynamic programming paths sub unit starting points 
approach asynchronous level dynamic programming synchronous formulation required 
alternatively particular form hmm decomposition referred hmm recombination 
discussed training recognition problems including automatic segmentation recombination coined different statistical formalisms likelihoods posterior probabilities linear nonlinear neural network recombination schemes 
recognition find best sentence model maximizing xjm likelihood formalism different solutions investigated including 
recombination sub unit level sub unit models composed parallel sub models input stream illustrated 

allow asynchrony different topologies different streams recombination hmm state level hmm states done 
recombination hmm state level done ways including untrained linear way trained linear nonlinear way recombining neural network 
pretty simple implement amounts performing standard viterbi decoding local log probabilities obtained linear nonlinear combination local stream probabilities 
course approach allow asynchrony shown promising multi band approach 
hand recombination input streams sub unit level requires significant adaptation recognizer 
presently algorithm referred hmm recombination adaptation hmm decomposition algorithm 
hmm decomposition algorithm time synchronous viterbi search allows decomposition single stream speech signal independent components typically speech noise 
spirit similar algorithm combine multiple input streams short term features long term features single hmm model 
constraint parallel sub models implemented forcing models points 
resulting decoding process implemented particular form dynamic programming guarantees optimal segmentation 
carried framework hybrid hmm ann artificial neural network systems 
top advantages known approach particularly attractive multi stream experiments reported allows estimate local global posterior probabilities directly reflecting confidence levels allows compute probabilities basis large acoustic contexts catch long term information 
multi stream approach shown particularly robust unpredictable seen training data band limited wideband noise conditions 
shown able better accommodate possible asynchrony different frequency bands 

syllable level dynamics potential advantage approach studied possibility combine long term dynamic properties long term features shortterm dynamic properties short term features asr systems 
current asr systems short term information typically phoneme level 
long term information representing temporal regions stretching typical phoneme duration difficult capture model standard asr systems typically looking ms frames assuming piecewise stationarity level hmm states 
state art systems phonemes carefully dictated clean speech performance severely compromised natural conversational speech noisy speech 
reason current feature extraction acoustic modeling schemes allow information time regions covering ms 
long time regions interesting distinguishing variable speech stationary noise 
observed modulation spectra spectra temporal envelope signal modulation energy speech signals generally maximum hz corresponding period ms ms maximum syllable duration distribution long term time regions allow better catch syllable level dynamics 
studies attempted acoustic context 
done conditioning posterior probabilities acoustic frames temporal derivative features 
typically optimum observed context covering ms speech corresponding approximately mean duration phonetic units 
approaches allow representing higher level temporal processes syllable dynamics instance underlying hmm model phoneme 
course amount training data building syllable models simply concatenating hmm states emitting ms frames help capture long term information 

generic syllable model framework multi stream approach long term information streams introduce long term dependencies current phone systems precisely hmms concatenation states emitting ms feature vectors 
case parallel standard ms acoustic stream consider acoustic stream looking larger temporal windows 
acoustic streams processed different sub unit hmm models better suited temporal properties supposed capture 
current experiments performed view modeling syllabic sub unit models means different streams forced recombine predefined syllable levels 
consequently lexicon words transcribed term syllables defined phoneme sequences containing vowel nucleus optional left right consonants 
simple rules obtain lexical syllable boundaries 
illustrated fig syllable models composed parallel models 
classical syllable model built context independent hmm ann phone states really modeling syllable structure probabilities obtained output phone ann typically looking frames ms illustrated fig 
minimum phoneme duration defined half mean duration phoneme 

particular hmm model aimed capturing syllable level temporal structure speech signal 
preliminary experiments simple state hmm supposed common syllable models 
model output probabilities output ann looking temporal segments spanning ms syllable se multi stream model 
continuous speech databases experiments ffl numbers consists numbers spoken naturally telephone lines public switched network 
utterances training utterances testing 
training procedure anns uses cross validation scheme prevent neural network training data 
training set sentences adjusting weights anns crossvalidation purposes 
grammar testing ffl darpa resource management official sentences training cross validation training anns 
february sentences testing 
standard grammar perplexity 
note databases quite different respect speaking style 
resource managment read speech numbers spontaneous speech 
single state hmm ann context independent phone models 
feed forward multilayer perceptrons mlps generate local probabilities different hmms 
log rasta plp parameters numbers experiments resource management experiments 
system frames ms contextual information gross syllable model frames ms 
decoding done hmm decomposition recombination algorithm 
recombined sub stream models log likelihoods linearly artificial neural network 
recombination weights optimized training set 
additional point tests performed constraining search phone hmms match true syllable segmentation obtained viterbi alignment 
results reported table compared stateof art phoneme hybrid hmm ann system clearly show significant performance improvement 
phone linear mlp cheat error rate table word error rates continuous numbers numbers database 
phone refers regular phone recognizer 
linear refers multi stream system linear recombination streams 
mlp refers recombination mlp 
cheat refers constraining dp search syllable boundaries 
noise additive gaussian white noise db snr 
phone linear mlp cheat error rate table word error rates continuous speech resource management database february test set 
achieved time dependent syllable transition penalties penalties high time slots syllable transition allowed 

modeling phenomena extension preliminary experiments hmm responsible capturing larger time scale properties extended model stressed syllables differently 
course number models increased cover wider range syllabic structures cv stressed cv cvc syllable hmms stressed syllables 
state models similar introduced previous section gross syllable modeling 
syllable qualified stressed vowel nucleus lexically stressed 
approach proposed rescoring syllable models best hypothesis phone recognizer 
hmm scores types models combined utterance weights optimized training set 
case merging phone decisions syllable decisions performed recombine individual scores force models temporal endpoints 
numbers database parameterization scheme previous section 
strong mismatch lexically defined syllables acoustic realization observe table proposed method yields performance improvement 
phone linear error rate table word error rates continuous numbers numbers database 
stressed syllable models 
compared table 
discussed speech recognition multiple time scales framework multi stream approach independent processing recombination feature streams 
approach attempt define particular hmm model able focus different dynamic properties speech signal model piecewise stationarity different feature levels 
preliminary results suggest generic approach provide new formalism combining different sources short term long term information 
gross syllable models efficiently catch syllable level dynamics somewhat constraining phoneme system align syllables allowing features syllabic stress 
method shown yield significant performance improvement 
alternative approach introducing syllabic constraints shown acoustically derived syllable onsets improve speech recognition performance 
motivates research efficient long time regions covering ms syllable level information 
preliminary extended directions 
experiments done determine features best suited capture relevant long term dynamic properties distinguish different kinds syllabic structures stressed syllables 
respect modulation spectrum features interesting candidate 
furthermore mentioned mismatch lexically defined syllables acoustic realizations particularly conversational free speech 
highlights need research finding appropriate lexical representations long term properties syllable level dynamics 
acknowledgments european community support long term research project 

bourlard dupont ris multi stream speech recognition tech 
rep idiap rr idiap martigny switzerland 
bourlard dupont new asr approach independent processing recombination partial frequency bands proc 
intl 
conf 
spoken language processing philadelphia pp 
oct 
bourlard morgan connectionist speech recognition hybrid approach 
kluwer academic publishers isbn 
cole lander telephone speech corpus proc 
intl 
spoken language processing yokohama japan september 
greenberg kingsbury modulation spectrogram pursuit invariant representation speech proc 
icassp munich pp 

jones woodland modelling syllable characteristics improve large vocabulary continuous speech recogniser proc 
intl 
conf 
spoken language processing 
hermansky sub band recognition noisy speech proc 
icassp munich pp 

tomlinson russell moore modelling asynchrony speech elementary single signal decomposition proc 
icassp munich pp 

varga moore hidden markov model decomposition speech noise proc 
ieee internat 
conf 
acoust 
speech signal process pp 

wu greenberg morgan integrating syllable boundary information speech recognition proc 
ieee internat 
conf 
acoust 
speech signal process munich pp 
apr 
