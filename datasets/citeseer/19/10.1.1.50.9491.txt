lips face real time tracker oliver alex pentland vision modeling group mit media laboratory cambridge ma usa media mit edu francois clips imag bp grenoble cedex france francois imag fr describes active camera real time system tracking shape description classification human face mouth sgi indy computer 
system blob features spatially compact clusters pixels similar terms low level image properties 
patterns behavior facial expressions head movements classified real time hidden markov model hmm methods 
system tested hundreds users demonstrated extremely reliable accurate performance 
typical classification accuracies near 

describes real time system accurate tracking shape description classification human face mouth blob features hidden markov models hmms 
experimental apparatus described real time frames second runs sgi indy workstations special purpose hardware 
notion blobs representation image features long history computer vision different mathematical definitions :10.1.1.47.9503
usage compact set pixels share visual property shared surrounding pixels 
property color texture brightness motion shading combination salient spatio temporal property derived signal image sequence 
usage blobs coarse locally adaptive encoding images spatial color texture motion properties 
prime motivation interest blob representations discovery reliably detected tracked complex dynamic scenes extracted real time need special purpose hardware 
properties particularly important applications require tracking people blob tracking real time body human interfaces real time recognition american sign language hand gestures 
years research done machine recognition human facial expressions 
feature points physical skin muscle activation models optical flow models feature models manually selected features local parametrized optical flow deformable contours combined optical flow deformable templates techniques facial expression analysis 
extends previous efforts real time analysis human face blob tracking methodology 
extension required development incremental expectation maximization method new mixture gaussians blob model continuous real time hmm classification method suitable classification shape data 
applications new system called lips face tracker include video conferencing real time computer graphics animation virtual windows visualization 
particular interest ability accurate real time classification user mouth shape constraining head position ability possible time real time speech reading expression recognition unconstrained office environments 
structured follows general mathematical framework face detection tracking mouth detection mouth tracking mouth expression recognition results applications 

mathematical framework notion grouping atomic parts scene form blob entities proximity visual appearance natural interest visual scientists gestalt psychologists studied grouping criteria early century 
modern computer vision processing seek group pixels images segment images visual coherence features obtained efforts usually taken boundaries contours regions regions 
complex scenes containing people natural objects contour features prove unreliable difficult find 
blob representation developed pentland way extracting extremely compact structurally meaningful description multi spectral satellite mss imagery 
method feature vectors pixel formed adding spatial coordinates spectral textural components imagery 
clustered image properties color spatial similarity combine form coherent connected regions blobs pixels similar image properties 
blob fact special case minimum description length mdl algorithms 
essentially technique real time tracking people color video 
application spatial coordinates combined color brightness channels form element feature vector point 
clustered blobs drive connected blob representation person 
expectation maximization em methods obtain gaussian mixture models spatio chrominance feature vector complex shapes color patterns adaptively estimated image stream 
system incremental version em allows adaptively continuously update spatio chromatic blob descriptions 
adapt different skin colors changes illumination 

blobs probabilistic representation represent shapes low order statistics 
clusters points spatial means covariance matrices shall denote blob spatial statistics described terms second order properties computational convenience interpret gaussian model 
gaussian interpretation terribly significant keep pixel pixel support map showing actual occupancy 
representations computer vision signal analysis including superquadrics modal analysis eigen representations blobs represent global aspects shape augmented higher order statistics attain detail data supports 
reduction degrees freedom individual pixels blob parameters form regularization allows ill conditioned problem solved principled stable way 
blobs useful physical interpretation blob parameters image space 
mean represents geometric center blob area volume 
covariance symmetric diagonalized eigenvalue decomposition flf orthonormal diagonal 
diagonal matrix represents size blob independent orthogonal object centered axes rotation matrix brings object centered basis alignment coordinate basis decomposition physical interpretation important estimation shape vary different rate rotation parameters separated treated appropriately 

maximum likelihood estimation blob features modeled mixture gaussian distributions color texture motion space 
algorithm generally employed learning parameters mixture model expectationmaximization em algorithm dempster 
system input data vector normalized content pixels image 
color distribution blobs modeled mixture gaussian probability distribution functions pdf iteratively estimated em 
perform maximum likelihood decision criterium clustering done human skin forms dense manifold color space 
different clustering techniques derived em employed line training process line adaptive learning process 
order determine mixture parameters blobs unsupervised em clustering algorithm computed line hundreds images different classes modeled case face lips interior mouth similar way done skin color modeling 
new frame available likelihood pixel computed learned mixture model compared likelihood threshold 
pixels likelihood threshold classified belonging model 

adaptive modeling em general models system relatively user independent adaptive model 
adaptive statistical modeling blob features narrow general model parameters closer specific users characteristics 
element adaptive modeling update model priors soon user face face features detected 
new distribution parameters computed follows snew gamma general gamma user gamma new snew gamma general general gamma user user equation corresponds model averaging general learned models prior probability model 
update priors occurs sequence assuming blob features going drastically change run time 
obtain fully adaptive system able handle second second severe changes illumination user characteristics 
line expectation maximization algorithm adaptively model image characteristics model background face mixture gaussian distributions mixing proportions components gamma gamma gamma gamma js unknown parameters model sufficient statistics gaussian distribution mixing proportions number components mixture sufficient statistics updated computing online version traditional em update rules 
data points computed parameters data point read estimated follows responsibility new data point computed responsibility interpreted probability data point generated component responsibility known sufficient statistics mixture components updated weighted responsibilities gamma gamma oe oe gamma gamma oe oe standard deviation component average responsibility component point superscript refer estimated parameters data points processed gammaw main idea update rules distribute effect new observation terms proportion respective likelihoods 
new component added current mixture model observation sufficiently explained model 
observed data point low likelihood respect components mixture outlier components new component added mean new data point weight covariance matrix specified user 
threshold likelihood fixed stochastically chosen algorithm randomly choose add component outlier 
maximum number components mixture 
foreground models initialized line unsupervised learned priori mixture distributions described 
way algorithm quickly converges mixture model directly related priori models classes 
background models initialized priori distribution learned line image 

map segmentation models map foreground background decision rule applied compute support maps classes pixel pixel maps showing class membership model 
statistical blob models potentially describe particular image data membership decision searching model maximum posteriori map probability 
class memberships determined statistics class updated em algorithm described 
approach easily seen special case mdl segmentation algorithms developed darrell pentland ayer sawhney 

kalman filtering ensure stability map segmentation process spatial parameters blob model filtered zero order kalman filter 
blob maintain independent zero order filters position blob centroid dimensions blob bounding box 
map segmentation loop 
blob predict filter state vector covariance matrix dt matrix measures precision tolerance estimation vector depends kinematics underlying process 

blob new observations new estimates blob centroid bounding box computed image data acquired mahalanobis distance observations predicted state computed 
distance threshold filters updated account new observations gamma gamma gamma gamma gamma gamma discontinuity assumed filters reinitialized generalized version technique employed fusing concurrent observations 

continuous real time hmms approach temporal interpretation facial expressions uses hidden markov models hmms recognize different patterns mouth movement 
hmms basic probabilistic tools time series modeling 
hmms fall bayesian framework addition time feature vector 
offer dynamic time warping efficient learning algorithm clear bayesian semantics 
developed real time hmm system computes maximum likelihood input sequence respect models testing recognition phase 
hmm system runs real time sgi indy low level vision processing occurring separate indy communications occurring socket interface 

automatic face detection tracking approach face finding problem uses coarse color size shape information 
approach advantages correlation eigenspace methods speed rotation invariance constant illumination conditions 
schiele shown normalized chromatic color information reliably finding flesh areas scene despite wide variations lighting 
training model thousands skin color samples line em clustering obtained model valid broad spectrum users indian asian south american 
described mathematical framework section system uses adaptive em algorithm 
foreground background classes learned incrementally data 
trade adaptation process speed new models updated significant drop posteriori match model data 
mixture components typical number required accurately describe face 
mouth models complex requiring components 
mouth model include lips interior mouth teeth 

blob growing initial application map decision criterion image isolated spurious pixels misclassified 
local pixel information needs merged connected regions correspond blobs 
transition local global information achieved applying algorithm grows blob 
algorithm speed optimized version traditional considers pixel values neighborhood certain radius varied run time order determine pixel belongs connected region 
blobs filtered obtain best candidate face mouth 
color information robust purpose 
background instance may contain skin colors grown erroneously considered faces 
additional information required 
current system geometric information size shape object detected faces combined color information locate face 
consequence skin blobs size shape ratio aspect bounding box closest canonical face size shape considered 
result shown 

face detection growing 
active camera control system maintains kalman filter estimate centroid bounding box blob relatively simple matter estimates control camera face user appears center image desired size 
system uses abstraction camera control parameters different camera motor systems currently canon vcc sony evi successfully totally transparent way 
order increase tracking performance camera pan tilt zoom control done independent light weight process thread started main program 
current estimation position size user face provides signal pd controller determines tilt pan zoom camera target face desired size desired location 
zoom control relatively simple just increased decreased face reaches desired size 
pan tilt speeds controlled ce cd de dt fz constants error distance face current position center image zoom factor final speed transmitted camera 
zoom factor plays fundamental role camera control speed camera needs adjusted depends displacement fixed point image undergoes rotation angle directly related current zoom factor 
relation zoom factor current camera zoom position follows non linear law needs approximated 
case second order polynomial provides approximation 

mouth extraction tracking face location shape parameters known center face width height image rotation angle anthropometric statistics define bounding box mouth located 
mouth modeled principles face second order mixture model describes chromatic color spatial distribution 
obtain performance produce finely detailed model face region surrounding mouth 
face model adequate detection tracking adequate accurate mouth shape extraction 
system acquires image patches located mouth builds gaussian mixture model 
current implementation skin samples different facial regions mouth extracted initialization phase statistics computed 
example system performs case facial hair 
robustness system increased 
head mouth tracking rotations facial hair computing time step linearly predicted position center mouth 
confidence level prediction computed depending prediction error 
prediction available confidence level drops threshold mouth position reinitialized 

mouth shape mouth shape characterized area spatial eigenvalues width height bounding box 
feature vector classify facial expressions suggested psychological experiments examined important discriminative features expression classification 
rotation invariance achieved computing face image plane rotation angle rotating region interest negative angle 
user turn head mouth appears nearly horizontal illustrates 

speed accuracy robustness running single sgi indy mhz processor average frame rate tracking typically hz 
mouth detection parameter extraction added face tracking average frame rate hz 
measure accuracy head motion rms error measured having users large cyclic motions axes respectively true position face determined manual triangulation 
experiment camera actively tracked face position image processing camera control loop running nearly constant hz 
image size full resolution pixels camera control law varied pan tilt zoom place face center image fixed pixel resolution 
rms error true location system output computed pixels shown table 
shown variation apparent head size system error stabilizing face image size 
seen system gave quite accurate estimates position 
important robustness rms rms translation range pixels pixels cm static face gamma translation gamma translation gamma translation width std height std size change pixels pixels pixels zooming max 
size min 
size table 
accuracy 
system 
tested hundreds users different events lighting environmental conditions 
examples digital bayou part siggraph second international face gesture workshop october sponsors open houses 

recognition mouth shape feature vector described trained different hmm mouth configurations illustrated neutral default mouth position extended smile mouth sad mouth extended open mouth 
neutral mouth acted separate various expressions 
smile open sad open smile silence model acts speech recognition 
final hmm swe derived non neutral mouth configurations consisted state forward hmm 
neutral mouth modeled state forward hmm 
recognition results different users making expressions summarized table 
users divided different groups training testing purposes 
recognition tasks shown table corresponds training testing users 
total number examples denoted having total instances mouth expressions training testing 
seen accurate classification achieved case 
recognition results training testing users single user table 
recognition results training testing data 
applications 
automatic camera man static nature current video communication systems induces extra articulatory tasks interfere real world activity 
example users keep head object interest field camera microphone order perceived distant parties 
result user ends attentive way interface conversation 
communication degraded enriched 
sense active camera face tracking acts automatic camera man continuously looking user moves gestures video conference session 
informal teleconferencing testing users confirmed capability significantly improves usability teleconferencing system 
system virtual window mode user moves front local camera distant camera moved way 
informal tests users said virtual window system gives sense distant space 

real time computer graphics animation continuously tracks face location image plane face rotation angle mouth shape simple matter information obtain real time animation computer graphics character 
character simpler version constantly mimic user virtual mirror complex system understand recognize user doing react 
virtual mirror version system character named shown exhibited digital bayou section siggraph new orleans naive users 

real time computer graphics animation 
preferential coding front preferential image coding system 
known people sensitive coding errors facial features 
sense accurate expensive coding algorithm facial features accurate cheaper algorithm remaining image data 
location features detected system coding scheme 

described real time system finding tracking human face mouth recognizing mouth expressions hmm 
system runs single sgi indy computer produces estimates head position surprisingly accurate 
system successfully base different applications including automatic camera man virtual window video communications system real time computer graphics animation system 
system tested hundreds naive users physical locations success rate 
huang 
model image coding advanced video coding techniques low bit rate applications 
february 
ayer sawhney 
layered representation motion video robust maximum likelihood estimation mixture models mdl encoding 
iccv pages 
azarbayejani starner horowitz pentland 
visually controlled graphics 
pami june 
black yacoob 
tracking recognizing rigid non rigid facial motions local parametric models image motion 
volume pages 
ieee 
bobick bolles 
representation space paradigm concurrent evolving object descriptions 
pami february 
bregler omohundro 
advances neural information processing systems chapter surface learning applications lipreading 
morgan kaufmann san francisco ca 
crowley 
multi modal tracking 
puerto rico june 
cvpr 
darrell pentland 
cooperative robust estimation layers support 
pami may 
darrell sclaroff pentland 
segmentation minimal description 
iccv pages 
dempster laird rubin 
maximum likelihood incomplete data de em algorithm 
journal royal statistical society 
eleftheriadis 
model assisted coding video teleconferencing sequences low bit rates 
iscas may june 
ellis 
source book gestalt psychology 
harcourt brace 
essa pentland 
facial expression recognition dynamic model motion energy 
iccv pages 
gaver smets 
virtual window media space 
chi 
venkatesh stork 
deformable templates infer visual speech dynamics 
technical report california research center june 

locating tracking human faces neural networks 
technical report cmu pittsburgh pa august 
jebara pentland 
parametrized structure motion adaptive feedback tracking faces 
technical report mit media lab cambridge ma 
appear proceedings ieee cvpr 
kass witkin 
snakes active contour models 
international journal computer vision january 
pentland thomas 
blob unsupervised clustering approach spatial preprocessing mss imagery 
th int symp 
remote sensing environment ann harbor mi 
andp 

analysis synthesis facial motions 
volume pages zurich 
international workshop automatic face gesture recognition 
lee kimura tsuji 
automatic recognition human facial expressions 
cvpr volume pages 
ieee 

emotion model 
pages zurich 
international workshop automatic face gesture recognition 
moses reynard blake 
determining facial expressions real time 
volume pages zurich 
international workshop automatic face gesture recognition 
saito kaneko 
interactive model facial image new motion detection algorithm 
ieice october 
pentland 
classification clustering 
ieee symp 
machine remotely sensed data purdue 
thornton stokes 
aspects face processing chapter quantification facial expressions mathematics model face pages 

adaptive mixtures 
journal american statistical association 
rabiner juang 
hidden markov models 
ieee assp magazine pages january 
redner walker 
mixture densities maximum likelihood em algorithm 
siam review 

candide parametrized face 
phd thesis link university ee depart oct 
schiele waibel 
gaze tracking face color 
international workshop automatic face gesture recognition pages 
starner pentland 
real time asl recognition video hmm 
technical report mit media laboratory mit media laboratory cambridge ma 
waters 
muscle model animating dimensional facial expression 
volume pages 
acm siggraph conf 
proceedings 
wren azarbayejani darrell pentland 
pfinder real time tracking human body 
photonics east spie volume bellingham wa 
yacoob davis 
recognizing human facial expressions long image sequences optical flow 
pami june 
yamada 
dimensions visual information categorizing facial expressions emotion 
japanese psychological research 
yuille hallinan cohen 
feature extraction faces deformable templates 
journal computer vision pages 
