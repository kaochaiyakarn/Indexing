aras asynchronous risc architecture simulator chia chien mark franklin pan prabhu computer communications research center washington university st louis missouri asynchronous pipeline instruction simulator aras 
simulator design selected instruction pipelines check performance 
performance measurements pipeline configuration obtained simulating execution benchmark programs machine architectures developed 
depending simulation results obtained aras pipeline configuration altered improve performance 
explore design space asynchronous pipeline architectures 
presents graphic simulation tool aras asynchronous risc architecture simulator developed ease modeling visualization performance evaluation asynchronous instruction pipelines 
objectives ffl essential elements aras modeling tool 
ffl show aras model instruction pipelines 
ffl demonstrate aras may obtain important performance data guide design asynchronous instruction pipelines 
early risc machines employed single stage pipeline 
advanced machines performance improved increasing pipeline depth employing multiple pipelines superscalar 
techniques divide instruction finer research funded part nsf ccr arpa contract dabt 
currently itri industrial technology research institute taiwan republic china 
segments reducing cycle time 
superscalar techniques hand issue instructions parallel pipelines increase average number instructions processed cycle 
instruction pipelines modeled aras simulation tool permits visualization pipeline operation collection pipeline performance data 
commercial machines currently clocked asynchronous design attracted attention years clock rates power levels increased 
asynchronous methodology currently requires chip area generally entails higher design complexity large base available design automation tools certain potential advantages 
having performance governed mean versus worst case function delays eliminating limitations associated clock skew introducing limitations having potentially lower power levels 
performance advantages associated asynchronous systems discussed detail 
asynchronous modules design processors goes back late washington university st louis wasn entire asynchronous microprocessor designed california institute technology 
asynchronous version arm processor amulet completed university manchester uk 
currently sun microsystems developing asynchronous microprocessor called pipeline processor appears institutions companies investigating design asynchronous machines 
shows typical stage instruction pipeline buffers stage 
analytic modeling system easily accomplished reasons buffer instruction fetch operand fetch buffer instruction decode write back store logic add sub division load multiplication buffer stage pipeline multiple buffers ffl service rates associated stage easily quantifiable reflect processing requirements instruction type 
ffl achieve realistic pipeline arrival distribution best model arrival process real workload instruction traces 
traces generally modeled analytically tractable manner 
ffl basic queueing system associated realistic instruction pipeline model host logical exception conditions associated eliminating hazards result forwarding easily captured analytic models 
section illustrates aras display helps visualization pipeline operation discusses data collection facilities 
section basic aras operation briefly considered 
section considers problems associated insuring aras pipeline user implemented indicates constraints associated pipeline construction 
section illustrates uses aras 
pipeline design experiment second third consider effects adder design handshaking delays pipeline performance 
suggestions research modifications aras section 
aras aras simulates instruction pipeline processor executing benchmark program evaluates processor performance 
example aras display 
construction display driving program considered 
rectangle display represents block micro operations associated stage processor instruction pipeline 
lines blocks represent paths instructions may take aras display tion 
illustrates stage instruction pipeline 
pipeline begins parallel instruction fetch blocks connect shared instruction decode block 
fetch blocks represent possible parallel fetching instructions 
third stage different parallel blocks handle branch operand fetch operations respectively 
certain situations permit instruction parallelism 
different parallel blocks 
permits alu register instructions proceed parallel memory access instruction load place 
visualization pipeline operation dynamics employs main techniques ffl execution movement instructions pipeline corresponds movement dots block 
presence dot particular block indicates instruction processed block block empty 
ffl time instruction moves block line blocks involved momentarily 
ffl color dot shown black white corresponds instruction type executed arithmetic logic branch 
ffl border block color coded reflect changes block status 
block may idle busy blocked 
changes border color reflect changes block status 
clock system movement dots blocks governed availability blocks input instructions 
indicated dot instruction may blocked particular block successor block required instruction busy processing instruction 
movement dots temporary thickening block interconnect lines color changes dot border allow designer visualize progress instructions asynchronous pipeline 
instructions flow left right finishing example completion fourth stage earlier branch encountered 
addition dynamic visual display asynchronous instruction processing designer gather global system local block performance results 
global system performance includes system throughput number processed instructions simulation time required execution processed instructions 
local performance block obtained 
include number instructions processed throughput percent idle working blocked time associated selected block 
global local results designer attempt improve pipeline performance modifying restructuring pipeline 
example pipeline performance generally improved stage takes roughly equal time 
designer examine effect moving various micro operations blocks done editing configuration data file rerunning aras comparing various results 
technical report provides procedures followed altering pipeline configuration data files 
basic aras operation discrete event simulation core aras standard trace driven discrete event simulator 
aras accessed configuration file particular pipeline block finish time block id finish time block id current block finish time finish time block id instruction fetch instruction decode execution back write memory access move instruction block stay block id id update system state perform current block operations increase system clock decrease finish time find block smallest id id id steps process event aras table created 
table schedule events completion instruction usage block generated pipeline operation 
indicated block possible states idle busy blocked 
block idle state available process instruction 
busy state denotes block currently processing portion instruction operation 
blocked state occurs instruction prevented moving block pipeline successor block busy exists data dependency unresolved 
event occurs aras principally block completes processing instruction changes state busy idle blocked busy instruction 
event processed blocks may change states triggering events 
event scheduling depicted configuration example pipeline shown 
block table lists blocks unique identification numbers indicates finish time associated block 
instruction enters block finish time block calculated instruction type operation performed block 
block table shows allocated finish times point simulation 
blocks finish times block idle 
aras proceeds simulation selecting busy block smallest finish time scanning right left 
finish time selected block current block added global simulation clock decrement finish time busy blocks table 
aras performs operations associated processing instruction current block updating registers tables changing block states 
checks see current block instruction moved block requires 
movement blocks checked see event permits movement blocked instructions 
procedures described continue new block selected current block 
simulation ends entire trace program processed 
driving aras instruction traces drive aras obtained collecting execution information programs running sparc computer 
program traced executed sparc single step mode control debugger instruction trace collected 
execution information collected sent interpreter puts form useful aras 
placed part aras memory corresponding source segment 
data stack segments created aras 
standard benchmark traces developed users interested experimenting various pipeline designs 
users interested developing traces details interpreter programs described technical report 
pipeline design constraints basic constraints blocks design instruction pipelines 
section discusses constraints associated set rules way aras handles 
aras instruction set derived sparc instruction set 
instruction divided number micro operations initially dlx micro operations may common group instructions 
prior defining pipeline blocks instruction state diagram indicates sequencing constructed 
simple example shown certain alu jump instructions illustrated 
ir pc pc pc temp rd temp temp pc immediate register alu add branch set data transfer alu jump sub decoding operation instructions jump typical finite state diagram general pipeline block may consist single micro operation group sequential defined state diagram 
entire set micro operations available user correspond actual micro operations associated sparc implementation basic micro operations needed execution sparc instruction 
currently due implementation limitations aras handle arbitrary assignments micro operations blocks 
set predefined pipeline blocks associated micro operations available user explore variety pipeline designs 
way extend capability develop flexible micro operation block assignment mechanism 
shows instructions add rd sub rd jr path take finite state diagram order executed correctly 
shows individual state represents micro operation micro operations grouped form blocks constitute stages pipeline 
simple example consider implementation instruction fetch operation 
approach define single block performs temp rd temp temp pc ir pc pc pc write back execution instruction decode instruction fetch execution write back macroblocks blocks add jr sub instruction fetch instruction decode decoding operation 
micro operations synthesis micro operations macroblocks instruction fetch micro operation program counter pc update micro operation micro operations 
approach separate sequential blocks performing instruction fetch second handling pc update 
block types available explore approaches 
designing working pipelined machine general rules apply ffl micro operations constituting instruction executed proper sequence true instruction possible instruction sequence 
ffl pipelined machine able handle control hazards occur due branching 
ffl pipelined machine able handle resource hazards may arise multiple instructions request execution resource adder 
ffl pipelined machine able handle data hazards ensure instructions executed proper operands 
rule implemented user defining blocks pipelines maintain operation sequence defined instruction state diagram 
example suppose write back rd placed prior execution micro operations performing addition subtraction temp temp 
clearly result incorrect instruction execution register written prior updated 
aras users provided table similar gives sequence followed 
table indicates micro operations performed parallel provided resource hazards 
second rule implemented requiring instructions order including block blocks include instruction decoding branch address calculation branch condition evaluation 
order execution permitted micro operations performed 
branch detected condition evaluation takes place instructions earlier pipeline need flushed 
ensures control hazards instructions entered pipeline branch changed register states flushed 
third rule enforced handshaking protocol inherent asynchronous design 
instruction requesting resources blocks busy automatically stalled current block received 
aras handles data hazards standard technique 
includes checking register reservation table start operand fetch micro operation ensure reserved prior instruction stalling block register reserved 
addition instruction write register reserve register operand fetch instruction fetch id instruction decode ex execution wb write back id ex id wb id id id id ex ex sp sp sp sp pf id br ex ex pipeline configurations analyzed aras block 
write back micro operation completed instruction cancel register reservation 
ensures register operations order 
performance evaluation design section illustrates uses aras 
architecture pipelined machine developed aras 
second effect alternative module case adder designs pipeline performance 
third influence particular design parameter handshaking delay performance considered 
design asynchronous pipeline aras consider initial pipeline basic stages instruction fetch stage instruction decode stage execute stage 
assume write back operations may performed execute stage 
execute stage includes memory access micro operations 
approach developing higher performance machines attempt lengthen instruction pipeline 
various design alternatives available issue find design yields highest instruction throughput 
preliminary executions indicated stage pipeline instruction fetch stage bottleneck 
divided stages stage pipeline examined 
concerned achieved actual hardware implementation 
results show significant improvement explored 
block status display set benchmark programs see table executed stage pipelined machine simulation results identify blocks pipeline performance bottlenecks 
block status information obtained visually aras display aras output simulation 
shows visualization block status aras display 
display option user get information dynamic final block status 
shows final block status stage pipeline machine benchmark programs 
micro operations stages identified performance bottlenecks redistributed greater number blocks 
resulted blocks increasing pipeline depth fewer number micro operations block reducing block delay enabled find configurations yielded table benchmark programs instruction counts program description instruction type counts name alu branch memory total qsort quick sort randomly generated numbers sieve calculation prime numbers discrete event simulation iterations percent table simulation results sp pipeline block state id ex idle busy blocked higher throughput 
large number ways blocks may divided simple heuristic approaches conjunction aras difficult analyze various configurations 
table gives details benchmark programs instruction counts total number alu branch memory access instructions program 
qsort program uses quick sort algorithm sort numbers 
sieve program uses sieve method obtain prime numbers 
discrete event simulator performs iterations 
table shows percentage idle busy blocked time stage pipeline sp shown 
benchmark programs discussed obtain data 
simulation results table show id stage busy time indicating performance bottleneck 
reinforced high percentage time stages blocked 
user aras see visualization pipeline noting id block busy 
note stage idle instructions available processed 
approach reducing bottleneck divide micro operations associated id block blocks id id 
addition blocks ex block increase performance may result dividing micro operations associated instruction fetch stage blocks 
simulation table simulation results mips model qsort sieve harmonic mean sp sp sp sp pf results table stage pipeline sp show performance improvement stage case 
stage pipeline sp constructed id micro operations divided blocks ex block divided ex separate wb write back block 
results simulation shown table 
performance case higher stage pipeline lower stage pipeline 
results combination factors 
number pipeline stages increases average cycle time stage decreases 
handshaking delays discussed larger percentage stage cycle time establish lower bound time 
addition longer pipelines role hazards increases probabilities hazard pipeline stall penalties associated hazard increase 
combination factors results lower throughput 
approach increasing performance addition dividing blocks alter pipeline configuration take advantage instruction level parallelism 
example shown sp pf case illustrates simple superscalar configuration 
case branch instructions flow br branch block instructions proceed operand fetch block 
multiple ex blocks instruction level parallelism potentially table simulation results sp pipeline block state id id id ex wb idle busy blocked table simulation results sp pf pipeline block state id br ex ex idle busy blocked improving performance 
note output br block shown entering ex blocks branch instructions zero execute time essentially exit system leaving br 
shown table configuration yields highest performance 
influence functional module adder current version aras functional modules simulated greater detail provide information operation time main pipeline simulation 
example cache memory simulator determine times associated memory access 
simulator separate set associated caches instructions data 
module simulated greater detail bit complement integer adder 
different adder designs available asynchronous ripple carry adder rca asynchronous adder sel conditional sum adder csa 
structures adders described 
users observe change performance resulting different adders particular configuration 
simulation results previous configurations different adders shown table 
csa tree structure takes constant amount time log complete addition considered fastest adders clocked design achieves highest throughput configurations 
complexity csa circuit higher adder circuits 
remaining adders sel results best throughput 
sel blocks performs addition bit numbers 
sel containing blocks performs addition bit numbers performance sel case 
due presence multiplexers alter output block depending carry previous block 
multiplexer delay significant number partitions increased 
throughput decreased 
configuration rca worst throughput adders long carry chain increases addition delay 
figures show distribution addition times adders rca sel 
obtained qsort benchmark program referred table 
aras display enables user view distribution addition times dynamically simulation 
addition times dependent operand distribution adder pipeline configuration 
distributions indicate long carry chains occur expected uniformly distributed operands 
appears due additions occur effective address calculations stack operations occur high memory addresses influence performance pipeline configurations choice adders 
sort simulation results conjunction vlsi implementation requirements users decide adder design design environment 
example csa larger sel increases pipeline performance sel de table simulation results different adders mips mean benchmarks adder rca sel sel sel sel csa sp sp sp sp pf addition time rca addition time sel sign desired choice 
similar studies performed focusing functional modules influence number sets cache memory size instruction data cache memories 
technology design parameters prior sections focused high level pipeline architecture considerations individual functional modules 
underlying asynchronous simulation set assumptions concerning technology parameters implementations 
aras allows explore effects table operation delays type operation delay handshaking ns cache access ns main memory access ns instruction decode ns simple alu operation ns add sub bit carry chain ns register access update ns parameters performance conjunction configuration considerations 
performance results associated table parameter values table 
optimum configuration may depend parameters 
example handshaking delays reduced may stages 
synchronization overheads important factors affect performance asynchronous pipelines especially case longer pipelines 
obtain idea sensitivity handshaking delays configuration consider results table 
results indicate performance gain achieved stage pipeline handshaking delays reduced ns 
techniques overlapping handshaking operations developed lead effective zero handshaking delay improvement achieved ns case 
results show lower handshaking delays stage pipeline yields higher performance stage pipeline 
aras reflects change optimal depth pipelines change handshaking delays 
keeping factors constant handshaking delays reduced deeper pipelines necessarily perform better shallower pipelines 
due data dependencies seen table simulation results mips mean benchmarks delay sp sp sp sp pf ns ns ns ns son stage pipelines handshaking delays ns 
aras uses program traces factors taken account 
aras indicates handshaking delays greater ns superscalar configuration outperforms single pipeline configurations configuration sensitive changes handshaking delays 
research asynchronous risc architecture simulator aras 
brief description simulator operation user interface 
general rules building working instruction pipeline explained examples aras explore performance alternative pipeline configurations functional module performance parameter values 
aras simulate pipelined machine visualize operation obtain performance data 
aras simulation times depend size benchmark programs 
set programs table aras took average seconds sun sparc workstation simulation presentation final results 
intermediate results required status registers instruction visualization longer times result 
reports version aras 
current includes making aras user friendly flexible block configurations areas 
enhancements include permitting aras simultaneously simulate clocked asynchronous versions pipeline configuration 
performance data program traces include system calls supervisor mode instructions 
done remove limitation integrate set programs aras 
chien prabhu 
aras asynchronous risc architecture simulator 
technical report washington univ st louis mo 
clark 
computer 
proc 
afips spring joint computer conference pages april 
franklin pan 
clocked asynchronous instruction pipelines 
proc 
th acm ieee symp 
microarchitecture pages austin tx december 
franklin pan 
performance comparison asynchronous adders 
proc 
symp 
advanced research asynchronous circuits systems salt lake city utah november 
day garside woods 
arm 
int conf 
large scale integration vlsi september 
hennessy patterson 
computer architecture quantitative approach 
morgan kaufmann publishers palo alto ca 
hwang 
computer arithmetic principles architecture design 
wiley 
ieee computer society 
proceedings int symposium advanced research asynchronous circuits systems salt lake city ut november 
jouppi wall 
available instruction level parallelism superscalar machines 
asplos iii proceedings pages april 
martin burns lee 
design asynchronous microprocessor 
proc 
caltech conf 
vlsi pages 
mit press march 
sproull sutherland molnar 
pipeline processor architecture 
ieee design test computers fall 
flynn 
arithmetic digital system designers 
cbs college pub new york 
