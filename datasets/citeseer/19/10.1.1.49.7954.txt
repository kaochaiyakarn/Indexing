parity declustering continuous operation redundant disk arrays describe evaluate strategy declustering parity encoding redundant disk array 
declustered parity organization balances cost data reliability performance failure recovery 
targeted highly available parity arrays systems 
improves standard parity organizations reducing additional load surviving disks reconstruction failed disk contents 
yields higher user throughput recovery shorter recovery time 
address generalized parity layout problem basing solution balanced incomplete complete block designs 
software implementation declustering evaluated disk array simulator highly concurrent workload comprised small user accesses 
show declustered parity penalizes user response time disk repaired recovery comparable non declustered raid organizations penalty user response time fault free state 
show previously proposed modifications simple single sweep reconstruction algorithm decrease user response times recovery contrary previous suggestions inclusion modifications may configurations slow reconstruction process 
result arises simple model disk access performance previous consider throughput variations due positioning delays 

applications notably database transaction processing require high throughput high data availability storage subsystems 
demanding applications require continuous operation terms storage subsystem requires ability satisfy user requests data presence disk failure ability reconstruct contents failed disk replacement disk restoring fault free state 
fulfill requirements arbitrarily degraded performance unusual organization requires continuously available data incur financial losses substantially larger organization total investment computing equipment service severely degraded prolonged period time 
time necessary reconstruct contents failed disk certainly minutes possibly hours focus performance continuous operation storage subsystem line failure recovery 
recommend line failure recovery environment tolerate line recovery restores high performance high data reliability quickly 
redundant disk arrays proposed increasing input output performance reducing cost high data reliability kim livny patterson salem offer opportunity achieve high data availability sacrificing throughput goals 
single failure correcting redundant disk array consists set disks mapping user data disks yields high throughput chen mapping parity encoding array data data lost disk fails recovered system line lee :10.1.1.52.634
single failure correcting disk arrays employ mirrored parity encoded redundancy 
mirroring bitton copeland hsiao duplicate copies data stored separate disks 
parity encoding kim patterson gibson popularized redundant arrays inexpensive disks raid subset physical blocks array store single error correction code usually parity computed subsets data 
mirrored systems potentially able deliver higher throughput parity systems workloads chen gray increase cost consuming disk capacity redundancy 
mark holland department electrical computer engineering carnegie mellon university pittsburgh pa holland ece cmu edu garth gibson school computer science carnegie mellon university pittsburgh pa garth cs cmu edu supported national science foundation number ecd defense advanced research projects agency monitored darpa contract mda ibm graduate fellowship 
proceedings th conference architectural support programming languages operating systems 
examine parity redundancy scheme called parity declustering provides better performance line failure recovery common raid schemes high capacity overhead mirroring muntz primary figures merit reconstruction time wallclock time taken reconstruct contents failed disk replacement user response time reconstruction 
reconstruction time important determines length time system operates degraded performance significant contributor length time system vulnerable data loss caused second failure 
fixed user throughput contrasting user fault free response time response time failure reconstruction gives measure system performance degradation failure recovery 
section describes terminology presents declustered parity organization 
section describes related studies notably declustering muntz lui muntz explains motivations investigation 
section presents parity mapping left open problem muntz lui 
section gives brief overview simulation environment sections brief analyses performance declustered array fault free failed disk replacement 
section covers reconstruction performance contrasting single thread parallel reconstruction evaluating alternative reconstruction algorithms 
section concludes look interesting topics 

declustered parity layout policy illustrates parity data layout left symmetric raid redundant disk array lee 
data stripe unit simply data unit defined minimum amount contiguous user data allocated disk data allocated disk 
parity stripe unit simply parity unit block parity information size data stripe unit 
term stripe unit data unit parity unit distinction data parity pertinent point 
size stripe unit called unit convenience integral number sectors minimum unit update system software 
parity stripe set data units parity unit computed plus parity unit 
di represents data units parity stripe number 
muntz lui term clustered term declustered 
may derived clustering independent raids single array parity overhead 
follows earlier copeland keller copeland redundancy information declustered minimal collection disks 
pi represents parity unit parity stripe parity units distributed disks array avoid write bottleneck occur single disk contained parity units 
disk array data layout provides abstraction linear logical block address space file system 
addition mapping data units parity stripes left symmetric raid organization specifies data layout data mapped stripe units di ascending ascending means user data logically choice set contiguous data units map different disks maximizing read parallelism 
file system may may allocate user blocks contiguously address space disk array data mapping insure maximal parallelism 
parity computed entire width array cumulative parity data units 
disk identified failed data unit reconstructed reading corresponding units parity stripe including parity unit computing cumulative exclusive data 
note disks array needed access requires reconstruction 
shall see declustered parity relaxes constraint 
muntz lui number units parity stripe including parity unit consider problem decoupling number disks array 
reduces problem finding parity mapping allow parity stripes size units distributed larger number disks purposes larger set disks array 
comparison purposes raid example 
property defines raid mappings context 
perspective concept parity declustering redundant disk arrays demonstrated logical raid array distributed disks containing fewer units 
way 
muntz lui muntz term group denote call parity stripe avoid usage conflicts patterson definition patterson set disks set disk blocks 
parity data layout raid organization 
disk disk disk disk disk offset mapping generated topic section 
advantage approach reduces reconstruction workload applied disk failure recovery 
see note stripe unit failed physical disk parity stripe belongs includes units subset total number disks array 
example disks participate reconstruction parity stripe marked 
disks called reconstruction disks 
contrast raid array disks participate reconstruction units failed disk 
presents declustered parity layout described section 
important point fifteen data units mapped parity stripes array disk units raid organization sixteen data units mapped parity stripes number disk units 
disk units consumed parity parity stripe represented disk smaller fraction surviving disk read reconstruction 
example disk zero fails parity stripe read reconstruction 
note successive stripe units parity stripe occur varying disk offsets section shows significant performance impact 
spread parity units evenly disks constructions section possess property 
muntz lui define ratio parameter call declustering ratio indicates logical array physical array possible declustering parity stripe size array disks 
disk disk disk disk disk offset example data layout declustered parity organization 
fraction surviving disk read reconstruction failed disk 
note raid organization indicating surviving disk participates reconstruction 
performance graphs sections parameterized parameters ratio determine reconstruction performance data reliability cost effectiveness array 
determines cost array specifies number disks 
determines array data reliability mappings require data surviving disks reconstruct failed disk 
failures disks constituting array cause data loss 
hand determines percentage total disk space consumed parity declustering ratio determines reconstruction performance system smaller value yield better reconstruction performance failed disk reconstruction workload spread larger number disks 
general system administrators need able specify installation time cost performance capacity data reliability needs 
provides analyses decisions 

related idea improving failure mode performance declustering redundancy information originated mirrored systems copeland hsiao 
copeland keller describe scheme called interleaved declustering treats primary secondary data copies differently 
traditionally mirrored systems allocate disk primary secondary 
copeland keller allocate half disk primary copies 
half disk contains portion secondary copy data primaries disks 
insures failure recovered primary secondary copies data different disks 
distributes workload associated reconstructing failed disk surviving disks array 
hsiao dewitt propose variant called chained declustering increases array data reliability 
muntz lui applied ideas similar copeland keller parity arrays 
proposed declustered parity organization described section modeled analytically making number simplifying assumptions 
attempt identify limits theoretical analysis provide performance predictions software implementation array simulation 
primary concerns muntz lui analysis 
study assumes set surviving disks replacement disk driven utilization 
unfortunately driving queueing system magnetic disk full utilization leads arbitrarily long response times 
response time important customers critical database line transaction processing oltp systems 
specifications oltp systems require minimal level responsiveness example benchmark requires transactions complete seconds 
system requires minutes hours recovery failed disk rule apply relatively rare recovery intervals 
analysis reports user response time recovery presents simple scheme trading reconstruction time user response time 
second concern muntz lui analysis modeling technique assumes disk accesses service time distribution 
real disk accesses subject positioning delays dependent current head position position target data 
example suppose track replacement disk reconstructed widely scattered stripe units track valid written result user reconstruction accesses reconstruction 
units may skipped reconstruction may simply reconstructed rest track written data hold 
whichever option selected previously reconstructed sectors rotate disk heads time needed reconstruct track decrease 
muntz lui model assumes track reconstruction time reduced factor equal size units needing reconstruction divided size track case 
idea disk drives preserving due head positioning spindle rotation delays effect difficult model analytically relatively straightforward address simulation study 
balanced incomplete complete block designs described section achieve better performance reconstruction 
reddy reddy block designs improve recovery mode performance array 
approach generates layout properties similar restricted case 
data layout strategy section describe layout goals technique achieve 
comment generality approach 

layout goals previous declustered parity left open problem allocating parity stripes array 
extending non declustered parity layout research lee identified criteria parity layout 
deal exclusively relationships stripe units parity stripe membership recommendations relationship user data allocation parity stripe organization 
file systems free allocate user data arbitrarily logical space storage subsystem presents parity layout procedures direct control criteria 

single failure correcting 
stripe units parity stripe may reside physical disk 
basic characteristic redundancy organization recovers data failed disks 
arrays groups disks common failure mode power data criteria extended prohibit allocation stripe units parity stripe disks sharing common failure mode schulze gibson 

distributed reconstruction 
disk fails user workload evenly distributed disks array 
replaced repaired reconstruction workload evenly distributed 

distributed parity 
parity information evenly distributed array 
data update causes parity update uneven parity distribution lead imbalanced utilization hot spots disks parity experience load 

efficient mapping 
functions mapping file system logical block address physical disk addresses corresponding data units parity stripes appropriate inverse mappings efficiently implementable consume excessive computation memory resources 

large write optimization 
allocation contiguous user data data units correspond allocation data units parity stripes 
insures user performs write size data portion parity stripe starts parity stripe boundary possible execute write pre reading prior contents disk data new parity unit depends new data 

maximal parallelism 
read contiguous user data size equal data unit times number disks array induce single data unit read disks array requiring alignment data unit boundary 
insures maximum parallelism obtained 
shown left symmetric mapping raid arrays meets criteria 

layout strategy declustered parity layouts specifically designed meet criterion distributed reconstruction lowering amount reconstruction done surviving disk 
distributed reconstruction criterion requires number units read surviving disk reconstruction failed disk 
achieved number times pair disks contain stripe units parity stripe constant pairs disks 
muntz lui recognized suggested layouts literature balanced incomplete block designs hall 
demonstrates done way 
block design arrangement distinct objects tuples containing elements object appears exactly tuples pair objects appears exactly tuples 
example non negative integers objects block design 
example demonstrates simple form block design called complete block design includes combinations exactly distinct elements selected set objects 
number combinations useful note free variables relations true bk vr 
relations counts objects block design ways second counts pairs ways 
layout associates disks objects parity stripes tuples 
clarity discussion illustrated construction layout block design 
build parity layout find block design minimum possible value explained section 
mapping identifies elements tuple block design disk numbers successive stripe unit parity stripe allocated 
tuple design lay parity stripe data blocks parity stripe disks parity block disk 
second tuple stripe disks parity disk 
general stripe unit parity stripe assigned lowest available offset disk identified th element tuple mod block design 
layout shown top quarter derived process block design 
apparent approach produces layout violates distributed parity criterion 
resolve violation derive layout duplicate times times assigning parity different element tuple 
tuples called blocks block design literature 
avoid name conflicts commonly held definition block contiguous chunk data 
sample complete block design 
tuple tuple tuple tuple tuple cation shown right side 
layout entire contents duplicated stripe units disk mapped parity stripes 
refer iteration layout blocks disk block design table complete cycle blocks full block design table 
show layout procedure meets layout criteria 
pair stripe units parity stripe assigned disk elements tuple distinct 
insures single failure correcting criterion 
second criterion reconstruction distributed evenly guaranteed pair objects appears exactly tuples 
means copy block design table disk occurs exactly parity stripes disk 
disk fails disk reads exactly stripe units reconstructing stripe units associated block design table 
note actual value significant 
necessary constant pairs disks guaranteed definition block design 
distributed parity criterion achieved full block design table composed block design tables assigning parity different element tuple 
results assignment parity disk cluster exactly times course full block design table 
see refer group vertical boxes right half see block design table parity assignment function touches element block design table exactly course full block design table 
object appears exactly tuples block design table disk assigned parity exactly tuples full block design table 
unfortunately guaranteed layout efficient mapping fourth criterion size block design table guaranteed small 
section demonstrates small block design tables available wide range parity stripe array sizes 
fifth sixth criteria depend data mapping function higher levels software 
unfortunately simple mapping data successive data units successive parity stripes simulations meeting large write optimization criterion meet maximal parallelism criterion sets adjacent data units mapping allocated different disks 
reading adjacent data units starting data unit zero causes disk twice disks 
hand employ data mapping similar lee left symmetric parity non declustered raid arrays may fail satisfy large write optimization criterion 
leave development declustered parity scheme satisfies criteria 

generation block designs complete block designs easily generated cases insufficient purposes 
number disks array large relative number stripe units parity stripe size block design table unacceptably large layout fails efficient mapping criterion 
example disk array parity overhead allocated complete block design tuples full block design table 
addition memory requirement table layout meet distributed parity distributed reconstruction criteria large disks rarely sectors 
reason turn theory balanced incomplete block designs hall 
goal find small block design objects tuple size difficult problem general hall presents number techniques theoretical interest practical value provide sufficiently general techniques direct construction necessary designs 
fortunately hall presents list containing large number known block designs states bounds list solution case known exist 
presents scatter plot subset hall list designs 
possible parity declustering implementation uses hall designs 
balanced incomplete block design required parameters may known 
cases find balanced incomplete block design attempt complete block design indicated parameters 
method produces unacceptably large design resort choosing closest feasible design point point yields value closest desired 
results indicate performance array highly sensitive small variations block designs simulations holland 

block designs available anonymous ftp niagara nectar cs cmu edu file usr anon pub declustering bd database tar known block designs 
declustering ratio full block design table parity declustering organization 
disk disk disk disk disk offset tuple parity stripe parity block design table full block design table data layout physical array layout derivation block designs 
simulation environment acquired event driven disk array simulator called chen lee analyses 
simulator developed raid project berkeley katz 
consists primary components illustrated 
component described 
top level abstraction synthetic generator capable producing user request streams drawn variety distributions 
table shows configuration workload generator simulations 
restricted attention random accesses size kb model oltp system effective buffer cache ramakrishnan 
request produced generator sent raid striping driver originally actual code sprite operating system ousterhout implement raid device set independent disks 
table shows configuration extended version striping driver 
upper levels run sprite machine 
low level disk operations generated striping driver sent disk simulation module accurately models significant aspects specific disk access seek time rotation time cylinder layout 
table shows characteristics mb inch diameter ibm model lightning disks simulations ibm 
lowest level abstraction event driven simulator invoked cause simulated time pass 
striping driver code originally taken directly sprite source code essentially zero modification accommodate simulation modifications conform sprite constraints 
assures streams generated driver identical observed actual disk array running synthetic workload generator 
forces implement layout strategy reconstruction optimizations extended code way re incorporated operating system time 
minimizes possibility un considered implementation details lead erroneous 
reconstruction algorithms discussed section fully implemented tested simulation version raid striping driver 
evident simulator models software implementation striped disk array expect hardware implementation deliver similar performance 
model time taken compute xor functions cpu simulator incur rotation slips due interrupt overhead com synthetic raid striping driver disk simulation module event driven simulator generator structure 
mand processing time cpu code path length mapping functions significantly longer declustered layouts raid case 

fault free performance figures show average response time experienced read write requests fault free disk array function declustering ratio simulated system disks fraction space consumed parity units 
read case show average response time curves corresponding user access rates random reads kb second average user reads kb second disk applied disks capable maximum random kb reads second 
write case show curves longer average response time corresponding 
performance plots data point average independently seeded runs simulator 
find confidence intervals small include graph 
maximum width confidence interval data points plots value data point 

simulated arrays disks accesses second correspond accesses second disk 
user accesses expand physical accesses due cycle writes fly reconstruction 
accesses second disk chosen low load chosen value close maximum workload writes reconstruction mode eighteen determined maximum user disk access write writes fault free mode 
geometry cylinders heads sectors track sector size bytes revolution time ms seek time model ms ms min ms avg ms max track skew sectors dist dist disk parameters access size fixed kb user access rate accesses second alignment fixed kb distribution uniform data write ratio sections section workload parameters stripe unit fixed kb number disks fixed spindle synchronized disks 
head scheduling geist parity stripe size stripe units parity overhead resp 
data layout raid left symmetric declustered parity stripe index parity layout raid left symmetric declustered block design power disks independently powered array parameters table simulation parameters 
random user writes kb second 
user writes slower user reads writes update parity units data units 
striping driver behavior execute separate disk accesses user write single disk access needed user read 
high cost user writes system able sustain user writes kb second kb accesses second disk 
separate disk accesses user write pessimistic patterson menon rosenblum gives results wider generality result simulating specifically optimized systems 
figures show writes fault free performance essentially independent parity declustering 
exception result optimization raid striping driver employs requests data unit applied parity stripes containing stripe units chen 
case driver choose write specified data unit read response time reads 
fault free degraded response time writes 
fault free degraded data unit parity stripe directly write corresponding parity unit disk accesses pre reading overwriting specified data unit corresponding parity unit disk accesses 
rest neglect case avoid repeating optimization discussion 
note parity declustering implementation may perform equivalently left symmetric raid mapping user requests larger data unit 
declustered parity advantage exploiting large write optimization smaller user writes smaller parity stripes 
hand implementation currently meet maximal parallelism criterion able exploit full parallelism array large user accesses 
performance workloads modeled simulations dictated balancing effects depend access size distribution 

degraded mode performance figures show average response time curves array degraded failed disk replaced 
case fly reconstruction takes place access requires data failed disk 
access read failed disk contents reconstructed reading computing exclusive surviving units requested data parity stripe 
amount entails depends size parity stripe average response time curves suffer degradation lower parity declustering ratio smaller array size fixed 
effect shown reads writes consideration 
user write specifies data surviving disk associated parity unit failed disk value trying update lost parity 
case user write induces disk accesses 
effect decreases workload array relative fault free case low declustering ratios may lead slightly better average response time degraded fault free mode 

reconstruction performance primary purpose employing parity declustering raid organizations desire support higher user performance recovery shorter recovery periods muntz 
section show effective show previously proposed optimizations improve reconstruction performance 
demonstrate remains important trade higher performance recovery shorter recovery periods 
reconstruction simplest form involves single sweep contents failed disk 
stripe unit replacement disk reconstruction process reads stripe units corresponding parity stripe computes exclusive units 
resulting unit written replacement disk 
time needed entirely repair failed disk equal time needed replace array plus time needed reconstruct entire contents store replacement 
time termed reconstruction time 
array maintains pool line spare disks replacement time kept sufficiently small repair time essentially reconstruction time 
highly available disk arrays require short repair times assure high data reliability mean time data loss inversely proportional mean repair time patterson gibson 
minimal reconstruction time occurs user access denied reconstruction 
take minutes takes read sectors disks usually takes longer continuous operation systems require data availability reconstruction 
muntz lui identify optimizations simple sweep reconstruction redirection reads piggybacking writes 
user accesses data reconstructed serviced redirected replacement disk invoking fly reconstruction data available 
reduces number disk accesses invoked typical request reconstruction 
second optimization user reads cause fly reconstruction cause reconstructed data written replacement disk 
targeted speeding reconstruction units need subsequently reconstructed 
muntz lui mention servicing user write data unit contents reconstructed device driver choice writing new data directly replacement disk updating parity unit reflect modification 
case data unit remains invalid reconstruction process reaches 
model assumes user write targeted disk reconstruction sent replacement reasons explained question idea 
investigate algorithms distinguished amount type non reconstruction workload sent replacement disk 
minimal update algorithm extra sent possible user writes folded parity unit reconstruction optimization enabled 
user writes algorithm corresponds muntz lui baseline case user writes explicitly targeted replacement disk sent directly replacement 
redirection algorithm adds redirection reads optimization user writes case 
redirect algorithm adds piggybacking writes opti 
follows distinguish user accesses generated applications part normal workload reconstruction accesses generated background reconstruction process regenerate lost data store replacement disk 
mization redirection algorithm 
single thread vs parallel reconstruction figures reconstruction time average user response time reconstruction algorithms user workload kb random reads kb random writes 
figures show substantial effectiveness parity declustering lowering reconstruction time average user response time relative raid organization 
example user accesses second array declustering ratio reconstructs failed disk twice fast raid array delivering average user response time lower 
figures strong case advantages declustering parity fastest recon single thread reconstruction time reads writes 
minimal update user writes redirect redirect piggyback minimal update user writes redirect redirect piggyback single thread average user response time reads writes 
minimal update user writes redirect redirect piggyback minimal update user writes redirect redirect piggyback struction shown minutes times longer physical minimum time disks take read write entire contents 
problem single reconstruction process uses blocking operations able highly utilize array disks particularly low declustering ratios 
reduce reconstruction time introduce parallel reconstruction processes 
speed reconstruction substantially degrade response time concurrent user accesses 
figures show reconstruction time average user response time processes concurrently reconstructing single replacement disk workloads user accesses second reconstruction time reduced factor relative 
gives reconstruction times minutes 
response times suffer increases 
worst average response times ms simple transaction tpc benchmark require disk accesses transaction chance meeting required transaction response time seconds 
comparing reconstruction algorithms response time curves figures show muntz lui redirection reads optimization little benefit lightly loaded arrays low declustering ratio benefit heavily loaded raid arrays reductions response time 
addition piggybacking writes redirection reads algorithm 
comparison raid products available today specify line reconstruction time range hours 

reconstruction process acquires identifier stripe reconstructed synchronized list reconstructs stripe repeats process 
way parallel reconstruction time reads writes 
minimal update user writes redirect redirect piggyback minimal update user writes redirect redirect piggyback intended reduce reconstruction time penalty average user response time 
user loads employ piggybacking writes yields performance differs little redirection reads 
pursue piggybacking writes section 
figures show optimized reconstruction algorithms consistently decrease reconstruction time relative simpler algorithms 
particular single threaded reconstruction user writes algorithm yields faster reconstruction times values 
similarly way parallel minimal update user writes algorithms yields faster reconstruction times values 
surprising results 
expected optimized algorithms experience improved reconstruction time due loading utilized surviving disks utilized replacement disk piggybacking case reduce number units need get reconstructed 
reason reversal loading replacement disk random penalizes reconstruction writes disk loading benefits surviving disks surviving disks highly utilized 
complete explanation follows 
clarity consider single threaded reconstruction 
reconstruction time time taken reconstruct parity stripes associated failed disk data time unexpected effect understood examining number time taken reconstructions single unit shown 
call single stripe unit reconstruction period reconstruction cycle 
composed read phase write phase 
length read phase time needed collect exclusive surviving stripe units approximately maximum reads disks supporting moderate load way parallel average user response time reads writes 
minimal update user writes redirect redirect piggyback minimal update user writes redirect redirect piggyback random user requests 
disks saturated loading small amount significantly reduce maximum access time 
small amount random load imposed replacement disk may greatly increase average access times reconstruction writes sequential require long seeks 
effect suggesting preference algorithms minimize non reconstruction activity replacement disk contrasted reduction number reconstruction cycles occurs user activity causes writes portion replacement disk data reconstructed 
presents sample durations intervals illustrated 
numbers averaged reconstruction stripe units replacement disk 
final reconstruction cycles piggybacking writes occur redirection reads greatest utility 
selected operating point give redirection reads algorithm maximum advantage 
shows way parallel case complex algorithms tend yield lower read phase times higher write phase times 
numbers suggest low declustering ratio minimal update algorithm advantage user writes algorithm faster algorithms 
single thread case figures entirely bear suggestion minimal update algorithm gets reconstruction done user requests case algorithms 
single threaded case reconstruction slow loss free reconstruction benefit dominates minimal update algorithm reconstructs slowly smallest declustering ratio 
way parallel case reconstruction fast free reconstruction compensate longer services times experienced replacement disk free reconstruction moves heads randomly 
comparison analytic model muntz lui proposed analytic expression reconstruction time array employing declustered simple algorithms write replacement optimizations write replacement time read surviving disks read surviving disks effect redirection piggybacking reconstruction cycle 
parity muntz 
shows best attempt reconcile model simulations 
model takes input fault free arrival rate read fraction accesses disk user requests apply conversions required user write induces disk reads disk writes 
letting fraction user accesses reads muntz lui rate arrival disk accesses times larger user request arrival rate fraction disk accesses reads 
model requires input maximum rate reconstruction cycle time ms user accesses second 
mu uw rp mu uw rp mu uw rp mu minimal update uw user writes redirect rp redirect piggyback read time ms write time ms single thread reconstruction way parallel reconstruction mu uw rp mu uw rp mu uw rp comparing reconstruction time model simulation user accesses second 
user writes redirect redirect piggyback minimal update user writes redirect redirect piggyback model simulation disk executes accesses 
parameter causes disagreement model simulations 
maximum rate disk services entirely random accesses accesses second model 
consistent way muntz lui designed model account fact real disks execute sequential accesses faster random accesses 
example disks random accesses minimum time required read write entire disk seconds times longer fastest simulated reconstruction time 
manifestation problem single disk service rate predictions benefits redirection reads piggybacking writes optimizations 
redirecting replacement disk model increase disk average access time predictions user writes algorithm pessimistic algorithms 

demonstrated parity declustering strategy allocating parity single failure correcting redundant disk array trades increased parity overhead reduced user performance degradation line failure recovery effectively implemented array controlling software 
exploited special characteristics balanced incomplete complete block designs provide array configuration flexibility meeting proposed criteria goodness parity allocation 
particular block designs map parity stripes disk array insures parity update load line reconstruction load balanced surviving disks array 
achieved performance penalty normal non recovering user workload dominated small kb disk accesses 
previous proposing declustered parity mappings redundant disk arrays suggested implementation block designs proposed optimizations simple sweep reconstruction algorithm analytically modeled resultant expected reconstruction time muntz 
addition extending proposal implementation evaluates optimizations reconstruction time models context software implementation running disk accurate simulator 
findings strongly agreement theirs utility parity declustering disagree projections expected reconstruction time value optimized reconstruction algorithms 
disagreements largely result accurate models magnetic disk accesses 
find estimates reconstruction time significantly pessimistic optimizations slow reconstruction cases 
find practice multiple parallel reconstruction processes necessary attain fast reconstruction additional load degrade user response time substantially 
surprising result array low declustering ratio parallel reconstruction processes simplest reconstruction algorithm produces fastest reconstruction time best avoids disk seeks 
feel parity declustering related performance reliability tradeoffs area rich research problems sample give 
reconstruction time improved making parity unit size larger data unit size 
amounts striping data finer grain parity allow reconstruction proceed larger units 
spent time data mapping declustered parity arrays think layouts may amenable large write optimization maximal parallelism criteria 
eye performance modeling see analytical model disk array single drive incorporates complexity disk accesses 
view analytical modeling useful generating performance predictions short periods time demonstrated care taken formulation 
broaden results intend explore disk arrays different stripe unit sizes user workload characteristics 
important concern muntz lui considers impact cpu overhead architectural bottlenecks reconstructing system chervenak 
greater control reconstruction process intend implement throttling reconstruction user workload flexible prioritization scheme reduces user response time degradation starving reconstruction 
hope install software implementation parity declustering experimental high performance redundant disk array measure performance directly 
acknowledgments re indebted ed lee berkeley raid project supplying simulator peter chen art dan siewiorek dan watson john wilkes insightful reviews early drafts 
bob barker karl brace derek anurag gupta john kuo jason lee kevin lucas tom lily howard read roland schaefer watson graciously supplied compute cycles workstations time short met deadlines 
bitton bitton gray disk shadowing proceedings th conference large data bases pp 

chen chen evaluation redundant arrays disks amdahl proceedings acm sigmetrics conference pp 

chen chen patterson maximizing performance striped disk array proceedings acm sigarch conference pp :10.1.1.52.634

chervenak chervenak katz performance raid prototype proceedings acm sigmetrics conference pp 

copeland copeland keller comparison high availability media recovery techniques proceedings acm sigmod conference pp 

parallel interleaved file system university rochester technical report 
geist geist daniel continuum disk scheduling algorithms acm transactions computer systems vol 
pp 

gibson gibson redundant disk arrays reliable parallel secondary storage ph dissertation university california ucb csd 
published mit press 
gibson gibson patterson designing disk arrays high data reliability journal parallel distributed computing appear january 
gray gray horst walker parity striping disc arrays low cost reliable storage acceptable throughput proceedings th conference large data bases pp 

hall hall combinatorial theory nd edition 
holland holland gibson parity declustering continuous operation redundant disk arrays carnegie mellon university school computer science technical report cmu cs 
hsiao 
hsiao dewitt chained declustering new availability strategy multiprocessor database machines proceedings th international data engineering conference pp 

ibm ibm ibm disk drive product description model edition low storage products 
katz katz project high performance subsystems acm computer architecture news vol 
pp 

kim kim synchronized disk interleaving ieee transactions computers vol 
pp 

lee lee software performance issues implementation raid prototype university california technical report ucb csd 
lee lee katz performance consequences parity placement disk arrays proceedings asplos iv pp 

livny livny khoshafian boral multi disk management algorithms proceedings acm sigmetrics conference pp 

disk array systems proceedings compcon pp 

menon menon methods improved update performance disk arrays proceedings hawaii international conference system sciences pp 

muntz muntz lui performance analysis disk arrays failure proceedings th conference large data bases pp 

ousterhout ousterhout sprite network operating system ieee computer february pp 

patterson patterson gibson katz case redundant arrays inexpensive disks raid proceedings acm sigmod conference pp 

ramakrishnan ramakrishnan biswas analysis file traces commercial computing environments proceedings acm sigmetrics conference pp 

reddy reddy gracefully disk arrays proceedings ftcs pp 

rosenblum rosenblum ousterhout design implementation log structured file system proceedings th acm symposium operating system principles pp 

private communication 
salem salem garcia molina disk striping proceedings nd ieee conference data engineering 
schulze schulze gibson katz patterson reliable raid proceedings compcon pp 

tpc benchmark standard specification transaction processing performance council 
