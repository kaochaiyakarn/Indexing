gestural interface visual computing environment molecular biologists vladimir pavlovic rajeev sharma thomas huang image formation processing artificial intelligence groups beckman institute advanced science technology university illinois urbana champaign mathews avenue urbana il years tremendous progress immersive display virtual reality vr technologies 
scientific visualization data applications benefited progress 
fully exploit potential applications new environment need natural interfaces allow manipulation displays burdensome attachments 
describes visual hand gesture analysis enhanced speech recognition developing bimodal gesture speech interface controlling display 
interface augments existing application vmd vr visual computing environment molecular biologists 
free hand gestures manipulating graphical display set speech commands 
concentrate visual gesture analysis techniques developing interface 
dual modality gesture speech greatly aid interaction capability 

exciting progress years immersive display virtual reality vr technologies corresponding human computer interaction hci technologies lagged 
example current interfaces involve heavy vr devices may deter distract user vr facility 
development natural means interacting virtual display imperative fully utilize potential vr offers means visualizing interacting complex information 
supported part national science foundation iri part electric industries 
interaction mode relevant manipulation physical objects hand motion called hand gestures 
hands act world grasp explore objects express ideas 
vr setup natural environment virtual objects computer control 
manipulate naturally humans prefer employ hand gestures possible combination speech 
psychological studies example indicate people prefer gestures combination speech virtual environment allow user interact special training special apparatus allow user concentrate virtual objects tasks done 
explore multimodal nature hci involved manipulating virtual objects speech gesture 
keep interaction natural desirable devices attached user possible 
motivated developing techniques enable simple free hand gestures spoken words interacting graphical objects virtual environment 
hand gestures detected pair strategically positioned cameras interpreted set computer vision techniques term automatic gesture recognition agr 
computer vision algorithms able extract user hand background extract positions fingers distinguish meaningful gesture unintentional hand movement context 
voice commands monitored microphone recognized automatic speech recognition asr techniques 
setting particular virtual environment place necessary constraints analysis robust develop command language attempts optimally combine gesture speech inputs 
introduce visualization environment section describe modifications help incorporate vision gesture analysis speech recognition 
particular techniques developed agr including experimental prototypes described section 
prototype asr agr interface visualization environment demonstrates integral approach combining hand gestures speech results natural interface individual interaction modes 
interface improved modalities 
possible improvements discussed section followed section 
virtual environment testbed gesture speech interface consider particular virtual environment built structural biologists theoretical biophysics group university illinois urbana champaign 
system called provides environment simulation visualization biomolecular systems structural biology graphic front called vmd 
projection system permits multiple users visualize interactively manipulate complex molecular structures 
helps process developing understanding important properties molecules viewing simulations molecular dynamics playing different combinations molecular structures 
potential benefit system reducing time discover new compounds research new drugs example 

visualization facility structural biologist experimental test bed developing gesture speech interface techniques researchers seen discussing structure protein dna complex 
photograph courtesy rich illinois state journal register springfield illinois 
older version system employs keyboard tracked pointer interface 
particularly inconvenient interface hinders interactive nature visualization system 
incorporating voice command control enable users free keyboards interact environment natural manner 
hand gestures permit users easily manipulate displayed model play different spatial combinations molecular structures 
integration speech hand gestures multi modal interaction mechanism powerful mode motivating development gesture speech interface 
goal minimize modifications needed existing vmd program incorporating new interface 
experimental prototypes built speech asr hand gesture analysis agr required addition vmd environment 
software 
order reduce complexity increase flexibility program design communications layer added external programs written maintained independently vmd code 
vmd text language query vmd information send new commands 
vmd text language tcl scripting language developed ousterhout 
tcl complete interpreted language variables control loops functions calls 
popular freely available language embedded programs command language extended call programmer defined functions 
common extensions tcl dp adds communications support unix sockets 
method vmd acts server experimental user interface programs clients 
tcl dp rpc method client send new text command vmd receive response normal procedure call 
capabilities vmd available script level external program control vmd way 
asr agr programs interact vmd method 
simple voice command rotate left asr converts phrase vmd text command rotate sends message vmd 
similarly agr pointing device sends commands change current position vector vmd graphical pointers 
setup visual gesture analysis 
facilitate development agr algorithms designed experimental platform shown gesture recognition experiments 
addition uniformly black background lighting arrangement red light hand distracting user main display 
setup additional advantage transported easily relatively unobtrusive 
sample pair images cameras shown 
setup enables users sit table hand gestures control graphics display 

experimental setup cameras gesture recognition 
top camera side camera 
sample pair images cameras agr 
setup speech analysis 
prototype asr system implemented integrated vmd 
system consisted blocks recorder front followed recognizer unit 
recorder employed memory implement recording duties sending output recognizer unit blocks 
digital volume meter accompanied provide feedback user indicating acceptable range loudness 
recognizer followed developed modifying htk software 
unit performed feature extraction viterbi decoding input blocks sending decoded speech directly tcl dp commands sgi onyx workstation vmd process resided 
information speech system 
gesture speech command language 
order effectively utilize information input user form spoken words simple hand gestures designed command language combines speech gesture 
command language uses basic syntax action 
object 
modifier 
action component spoken rotate object modifier specified combination speech gesture 
example speaking pointing followed modifier clarify pointed molecule helix atom followed speaking done moving hand desired motion 
example desired gesture speech capability voice command engage query vmd molecule nearest tip pointer molecule blink indicate selected save molecule 
engaged voice command rotate converts gesture commands rotations chosen molecule command translate converts translations 
finished command release molecule allows user manipulate molecule 
section concentrate agr techniques setup 

hand gesture input agr general agr problem hard involves analyzing human hand high degree freedom hand gesture understood see survey vision agr :10.1.1.53.6402
problem eased context particular virtual environment develop appropriate set gestural commands 
gesture recognition done analyzing sequence images pair cameras positioned table users sit participate session 
cameras positioned facilitate robust analysis hand images 
background set uniformly black help real time analysis specialized image processing hardware 
finger pointer 
developed agr techniques allow finger pointing device 
involves determining line emanating pointing finger graphic feedback fine position cursor 
pointing action conjunction speech discussed previous section 
experimental system consists major parts see 
part composed identical systems extract pointing direction single camera images 
second part combines information obtained output systems pointing direction appropriate format 
obtain pointing direction sequence operations performed input image data 
gray level image thresholded extract silhouette user lower arm background 
second image moments calculated information form bounding box extraction index finger 
finger pointing direction subimage moments centroid major axis tilt image moments finger segmentation thresholding moments image segmentation finger subimage moments major axis tilt centroid 
overview main steps involved agr 
segmented hand set image moments calculated time finger 
moments finger centroid finger direction produced 
pointing direction determined second level subsystem knowledge setup geometry centroids pointing directions 
information forwarded central display manager vmd displays cursor appropriate screen position 
implementation produced tracking rate frames second proved sufficient users achieve reasonable control display 
gestures manipulating display 
addition recognizing pointing finger developed hidden markov model hmm agr system recognizing basic set manipulative hand gestures 
gives examples gestures 
developed gesture command language mainly concerned manipulating controlling display molecular structures 
gesture commands categorized dynamic move back move forward static grab release 
forward back grab release left static gestures dynamic gestures 
examples images set hand gestures manipulating virtual object interpreted agr 
real time response requirement natural interfaces usually precludes features fingertip palm positions provide general description hand poses 
features hard extract real time require computationally intensive inverse procedures obtain desirable hand parameters joint angles 
case constrained vr systems small subset hand gestures sufficient convey interface role 
set gestures described sufficiently image geometry parameters 
radon transform image extract features 
order moments known center mass image 
higher order moments provide additional information image shape 
set gestures consisted static dynamic gestures see 
recognition system built training hidden markov models specific gestures example runs 
commercially available htk software package entropic research originally designed field speech recognition 
gesture vocabulary modeled single state hmm 
observations modeled gaussian mixture different sizes diagonal covariance matrix 
training sequences performance recognition system quite correct recognition rate 
performance expected improve better model hand exploiting multimodality discussed 

discussion gesture speech interface reported far part general multimodal framework modalities exploited interface natural efficient 
overview conceptual multimodal framework see 
shows main interacting components gaze speech gesture virtual environment 
elements involved desired natural interaction user virtual environment 
speech gaze virtual environment gestures 
multi modal framework interacting virtual environment 
example consider problem visual gesture analysis 
interactions exploited improve gesture recognition process multimodal framework interaction gesture speech interaction gesture virtual scene interaction gesture gaze direction interaction gesture graphical display 
interactions discussed detail form basis 
simple setup uniform background able segment hand image background 
require restriction user seated table quite appropriate system 
general vr setting need better segmentation techniques 
hand segmentation corresponding motion analysis benefit modalities mentioned 
experimental results gesture recognition show simple image moments hmm approach yields reasonable performance 
model approach significantly effect recognition performance 
example trade reliability speed gesture recognition different levels hand model see 
approach hand motion analysis agr image raw hand image image moments articulated model mesh model 
hand models varying degree complexity 
sider class motion called articulated motion analysis tracking hand 
prediction articulated motion analysis reliably derive minimal description hand image real time 
detailed hand model better prediction hand positions different gestures 
models develop suitable feature vector gesture classification recognition 
aim replace simple image moments current implementation feature vector define complicated set hand gestures needed manipulating virtual environment 
direction fusing multimodal inputs vr designing unified hidden markov models speech gaze gesture elements interact different levels 
goal utilize correlation different modalities improve interpretation individual modes improve recognition user intent regards virtual object manipulated 
require multi resolution hidden markov models desired properties fusing gesture signal signals speech gaze 
include considering different issues combining disparate signals composite hmm models 
example combine multi rate multiresolution variable delay signals 

describe application computer vision techniques enhanced speech recognition construct natural human computer interface vr environment free hand gestures spoken words 
vr setup molecular biologists chosen test bed developing multimodal interface defining gesture recognition agr speech recognition asr tasks 
prototype combined gesture speech interface lets researcher easily naturally explore displayed information 
gesture speech interface offers level interactive visualization possible 
hand gestures allow users easily handle displayed model play different spatial combinations molecular structures 
introducing voice command control enables users free keyboards interact environment natural manner 
integration speech hand gestures multi modal interaction mechanism proves powerful mode 
acknowledgments 
authors acknowledge phillips zeller humphrey vmd section zhao lo chu speech part project 
hauptmann 
gesture speech graphics manipulation 
international journal studies feb 
humphrey schulten 
vmd visual molecular dynamics 
journal molecular graphics 
appear 
huang 
vision hand modeling tracking 
proceedings international conference computer vision cambridge ma june 
lee kunii 
model analysis hand posture 
ieee computers graphics applications pages september 
nelson visual computing environment structural biology 
technical report uiuc bi tb univeristy illinois urbana champaign december 
ousterhout 
tcl tk toolkit 
addison wesley reading massachusetts 
pavlovic sharma huang 
visual interpretation hand gestures human computer interaction review 
technical report uiuc bi ai rcv university illinois urbana champaign december 
sharma huang pavlovic schulten phillips zeller humphrey zhao lo chu 
speech gesture interface visual computing environment molecular biologists 
appear proc 
icpr vienna austria aug 
sharma huang pavlovic 
multimodal framework interacting virtual environments 
park kim editors human interaction complex systems 
kluwer academic publishers 
smith rowe yen 
tcl distributed programming 
proceedings tcl workshop berkeley ca 

image analysis general theory moments 
journal optical society america 
