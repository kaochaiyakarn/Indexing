study query execution strategies client server database systems donald kossmann michael franklin department computer science umiacs university maryland college park md kossmann franklin cs umd edu technical report cs tr umiacs tr query processing client server database system raises question execute queries minimize communication costs response time query load balance system 
evaluates common query execution strategies data shipping query shipping policy referred hybrid shipping 
data shipping determines queries executed clients query shipping determines queries executed servers hybrid shipping provides flexibility execute queries clients servers 
experiments client server model confirm query execution policy critical performance system 
data query shipping optimal situations performance substantial 
hybrid shipping matches best performance data query shipping shows better performance cases 
performance hybrid shipping plans shown sensitive changes state system load machines contents caches 
initial experiments indicate extended version step optimization may effective strategy adjusting plans state system runtime 
growing realization needs large classes applications entirely met current generation relational object oriented database systems 
relational database systems excel providing high level associative query access large sets flat records 
contrast objectoriented database systems provide powerful data modeling capabilities designed support efficient navigation access data 
different ways complimentary strengths apparent database systems combining best aspects relational object oriented approaches gain acceptance larger range applications 
system builders approaching perceived need ways 
vendors relational systems moving integrating object oriented features systems emerging sql standard vendors object oriented systems adding powerful query facilities cat 
partially nsf iri 
donald supported humboldt 
furthermore new class hybrid object relational systems started emerge illustra sto kim 
efforts resulted significant progress integrating object relational concepts progress primarily language data model levels 
contrast relatively little attention paid development underlying system architectures efficiently support hybrid models particularly distributed environment 
approaches merging relational object technology different philosophies intended execute client server environment 
way particular systems client server resources typically product starting point system designed 
relational systems descendants typically query shipping policy majority query execution performed servers 
query shipping potential benefits ability reduce communication costs high selectivity queries allow lightweight 
low cost client machines 
furthermore query shipping provides relatively easy migration path existing single site systems architecture database engine remains largely unchanged 
objectoriented database systems hand typically data shipping required data faulted client processed 
data shipping advantages exploiting client resources cpu memory disk reducing communication presence large query results allowing lighter weight interaction applications database system 
object relational camps continue merge apparent dichotomy resolved logical levels system lower architectural levels 
initial step direction presents study query data shipping approaches scheduling executing queries 
terms cost resource usage trade offs approaches fairly straightforward 
considering response time parallelism play major role trade offs different 
furthermore data shipping query shipping extreme points space possible execution strategies 
cost expanding complexity query optimization due expanded search space flexible hybrid approach pursued 
study strategies compared focus ability exploit parallelism clients servers groups servers larger network interaction features client server environment dynamic client caching sensitivity changes run time state system 
remainder organized follows section shows options query processing client server system 
section defines data query hybrid shipping policies 
section describes experimental environment section presents performance experiments 
section discusses related 
section contains proposes 
execution plans query execution plans represented binary trees study nodes operators edges specify producer consumer relationships operators 
root plan display operator passes result query application graphical user interface 
leaves plan scan operators read base relations database 
plan specify dimensions join ordering exploiting commutativity joins join operators ordered arbitrarily 
site selection operator display executed site system 
study primarily intended demonstrate importance site selection 
site selection depend join order join order depend number servers system 
focus dimensions options dimensions taken account example indexes hybrid hash join method sha join method 
database systems join order restricted left deep tree sac inputs join result join 
study bushy trees allowed 
bushy trees relax condition allow joins executed independently parallel different sites distributed system 
site selection specified annotating operator location operator run 
examples query plans annotations shown section 
display operator root carried site query submitted execution specified client annotation 
kinds operators options exist 
join carried site outer relation site inner relation site consumer operator processes result join 
similarly select unary operator carried site producer consumer 
scan relation carried server owns primary copy relation primary copy annotation 
scan carried client client annotation 
execute scan client necessary relation cached client possible portions relations tuples cached client 
scan runs client cached pages main memory local disk contain tuples relations pages relation faulted server owns primary copy 
execution time locations display scan operators resolved locations operators resolved producer consumer annotations 
course site producer coincide site consumer consumer producer annotations operators distinguished plan relations migrate distributed system query submitted different client machines 
horizontal scan operator defined fragment relation 
taken account study entire relation unit scan 
scan scan scan scan display client consumer consumer consumer join join join client client client client example data shipping plan scan scan scan scan display primary copy inner relation primary copy primary copy primary copy relation outer relation outer client join join join client server server sites example query shipping plan execution policies section data shipping query shipping hybrid shipping query execution policies covered study described 
execution policy specifies options allowed site selection 
flexible policy allows operators query executed different sites complicates query optimization allows efficient execution query distributed system 
main characteristics policies shown table 
operator possible annotations supported policies listed 
operators listed table aggregations projections annotated manner joins selections 
data shipping query shipping hybrid shipping display client client client consumer inner relation consumer inner relation join client outer relation outer relation consumer select client producer consumer producer scan client primary copy client primary copy table site selection operators study data shipping data shipping ds specifies operator query executed client machine query submitted 
ds execution plans site annotation scan display operator client annotation operators consumer display operator root tree carried client operators carried client 
example data shipping plan shown 
annotation operator shown italics shading nodes indicates operator executed client 
advantage data shipping exploits caching data client machines data cached locally evaluate query scans carried client 
addition data shipping minimizes server machines potential bottlenecks 
ds cause servers utilized 
potential disadvantage data shipping induce unnecessary communication cost 
example select tuples large relation cached client relation shipped server client carrying selection server sending tuples qualify 
query shipping term query shipping widely context client server architecture server machine queries completely evaluated server query result shipped server client 
recognized definition query shipping systems servers 
defined query shipping qs policy places scan operators servers primary copies relations operators display site producers 
example join operator carried producer inner relation producer outer relation 
consequence execution plans support query shipping consumer annotations scans carried client machine 
example query shipping plan shown 
obviously query shipping efficient server machines powerful 
addition query shipping provides flexibility load balance system servers 
query shipping utilize client machines evaluate queries particular query shipping strategy exploit caching base relations clients scan carried server 
serious disadvantage systems server resources limited heavily loaded induce extra communication cost shipping large query results server client 
hybrid shipping hybrid shipping hy combines approaches data query shipping 
hybrid shipping operator annotated way allowed data shipping query shipping 
policies hybrid shipping allows efficient execution query difficult policy optimize 
shows example hybrid shipping plan 
shown hybrid shipping preclude relation shipped client server precluded data query shipping 
shipping relation server example beneficial relation cached client main memory processing efficient server 
guarantee site operator determined execution time site annotations optimizer take precautions generate defined hybrid shipping plans 
defined plan cycles consequence path producer consumer annotations node plan leaf scan root display 
cycle observed say operator scan scan scan display client primary copy scan primary copy primary copy client consumer relation outer inner relation join join join client server server sites example hybrid shipping plan produces input operator site annotation consumer producer plan specifies executed site executed site tree small cycles nodes occur easy sort non defined plans query optimization 
experimental environment order investigate relative performance data query hybrid shipping execution strategies developed test environment consisting analytical cost model randomized query optimizer model 
cost model captures resources cpu disk network group interconnected client server machines 
produce total resource usage cost response time estimates 
response time estimates produced model operator parallelism developed ganguly hasan krishnamurthy ghk 
query optimizer randomized phase query optimization po combines simulated annealing iterative improvement proposed ioannidis kang ik 
optimization aimed minimizing cost response time predictions cost model 
search space explored optimizer includes full range shipping strategies restricted optimizer produces data shipping query shipping plans 
study query optimizer generate data query hybrid shipping plans suite complex select project join queries varying system assumptions 
quality plans assessed cost response time estimates cost model 
experiments system state resource loads caching runtime assumed match optimizer expectations compile time 
experiments estimates produced optimization performance results 
experiments aimed investigating quality generated plans runtime system state differs expectations optimizer 
experiments generated query plans evaluated re applying cost model parameters changed reflect new system state 
describe cost model query optimizer benchmark database queries 
results performance study section 
system model cost model analytical cost model control query optimization evaluate quality resulting query plans capable estimating total cost response time query plan system configuration 
model lohman ml cost query plan defined sum total time read pages disks plus total time execute cpu instructions plus total time transmit messages network 
response time estimates generated model approach taken ghk 
response time query defined elapsed time initiation query execution time tuple query result displayed client 
operators plan executed sequentially response time query identical cost 
parallelism independent pipelined exploited response time query lower total cost 
independent parallelism arise operators different sub trees plan scan operators different base relations 
contrast pipelined parallelism arises producer consumer operators 
pipelined execution operator executing soon producer operators produced tuple 
case consumer run parallel producer operators 
model ghk estimates response times simplified notion parallelism resource contention 
operators run parallel considered complete time 
independent parallelism response time estimated follows total cost total resources computed independent operator 
model assumes overlapping resource usage single operator 
second total usage resources shared independent operators computed usage network example computed bandwidth network volume data transmitted carry operators account 
response time entire group independently parallel operators computed maximum individual cost operator maximum total usage shared resource 
response time pipelined parallel operators determined similar fashion additional consideration fact portions pipelined operators execute parallel 
calculations response time applied query plan tree bottom fashion ultimately resulting estimate response time entire plan 
model ghk intended capture affects operator parallelism coarse grained fashion computationally efficient allow complex query plans evaluated reasonable amount time 
model accurately predict absolute response time query plan provides detail demonstrate performance implications data query hybrid shipping 
reasons simple model chosen study 
addition assumptions response time model ghk environment constructed study simplifications 
include 
synchronization overhead parallel operators modeled 
example pipelined parallelism synchronization typically required ensure producer flood buffers consumer 
cost synchronization captured model 

joins performed hybrid hash join method sha 
indexes 

results obtained single queries running isolation 
result resource contention directly modeled resulting parallel execution operators single query 
restriction mitigated ways 
memory contention taken account restricting buffer allocation operator 
second experiments operator resource demands adjusted simulate load machines induced queries 

assumed main memory buffers empty query execution 
disk required read base relations disk 
data cached clients assumed initially resident client local disk 
system parameters execution model table shows parameters cost model default values study 
parameter values fra sc 
parameter value description pagesize size data page number machines system mips cpu bandwidth machine milliseconds read page disk cpu instructions read page disk cpu instructions send receive message cpu instructions send receive bytes mbit network bandwidth display cpu instructions display tuple compare cpu instructions apply predicate hash cpu instructions hash tuple move cpu instructions copy bytes factor hybrid hash joins table system parameters default settings database temporary relations organized kb pages pagesize 
pages unit disk data transfer sites 
producer operator executed site different consumer operator producer batches output pages sends page time consumer 
single client machine server machines experiment 
queries submitted client machine primary copies base relations 
client machine local disk cache data fcl temporary storage join processing 
servers responsible managing primary copies relations 
server responsible primary copy base relation 
primary copy relation resides single server relations declustered 
addition copy relation portion may cached client machine 
cpu disk resources machines modeled parameters mips respectively 
demand cpu resources computed dividing number instructions required operation mips rating 
cost reading page disk modeled usage milliseconds disk resources plus instructions cpu time 
distinction random sequential disk servers expected powerful resources clients resources typically shared multiple clients 
experiments server client resource parameter settings identical 
experiments server resource parameters varied simulate different loads system 
communication sites modeled cpu network costs 
cpu overhead senders receivers modeled fixed cpu cost message regardless message size plus additional size dependent component 
network cost sending message computed dividing message size network bandwidth 
cost displaying query result client modeled display parameter set zero study 
stated section joins modeled hybrid hash joins 
cost hybrid hash joins estimated cost formulas sha corresponding compare hash move parameters listed table 
simulate memory contention maximum mb buffer frames allocated join denotes size inner relation multiplied factor mb denotes size base relation pages multiplied factor 
buffer frames allocated order guarantee minimum buffer allocation mb buffer frames allocated model execution joins small relations realistically 
query optimization query plans evaluated performance study section obtained randomized phase query optimization po ik 
randomized query optimization chosen study reasons 
randomized approaches shown successful finding join orderings ik generating efficient plans parallel execution large search spaces 
second simplicity approach allowed optimizer constructed quickly easily configured generate plans different execution strategies 
third randomized noted limiting buffer allocation favors data query shipping hybrid shipping provides highest flexibility exploit aggregate main memory system 
approach optimizes complex queries reasonable amount time 
example takes approximately seconds sun sparcstation perform join ordering site selection way join servers 
purposes study practical situations necessary generated plans reasonable truly optimal 
order minimize impact randomness results experiments described section run different random seeds results averaged 
optimizer chooses random plan desired search space data query hybrid tries improve plan iterative improvement ii simulated annealing sa 
step optimizer performs transformation plan 
transformations correspond dimensions search space described section 
possible moves denote temporary base relations 






change site field join consumer outer relation inner relation 

change site field select consumer producer vice versa 

change site field scan form client primary copy vice versa 
optimizer configured generate plans search spaces enabling disabling restricting possible moves 
hybrid shipping moves enabled 
generate data shipping plans join order moves enabled operators executed client machine 
generate query shipping plans th th moves disabled scans carried primary copy relation selects executed site corresponding scan 
addition th move restricted join moved site consumer 
benchmark specification order highlight differences different execution strategies benchmark suite study consists complex queries involving way joins 
large number joins greatly expands query plan search space allowing options exploiting resources distributed system large number servers 
experiments effects reported section arise albeit dramatically complex queries wisconsin benchmark bdt 
queries large numbers joins increasingly common due study uses parameter settings control ii sa phases ik 
note move commutativity joins exploited ensure right outer relation join larger 
applications complex queries decision support data mining path expressions object relational query languages 
relation study tuples bytes 
queries result join projected size tuples temporary relations query result bytes 
joins equi joins different kinds join graphs chain star 
chain join graph relations arranged linear chain relation relation joined exactly relations 
star join graph center relation joined relations relations join center relation 
chain queries arise example path expressions emp dept manager salary 
inter operator parallelism exploited queries carrying functional joins emp dept manager salary parallel 
contrast independent inter operator parallelism difficult exploit star join graph joins depend data derived center relation 
benchmark contains different chain join queries small values join attributes joins unique relation taken range 
base relations tuples average fifth tuples relation qualify result way join 
result small way join query typically empty 
medium values join attributes joins unique relation taken range 
cardinality temporary relations query result case tuples size base relations 
large values join attributes joins taken range 
value occurs twice relation 
cardinality result join twice cardinality input relations 
size result large way join query benchmark approximately mb tuples 
mixed join attributes join chosen randomly small medium large join attributes 
performance experiments results section examine cost response time trade offs shipping policies 
experiments follow query selectivities join graphs number servers client caching system loads varied order study issues scalability larger distributed systems robustness compiled plans varying system state 
order minimize impact randomized query optimization random placement primary base relation copies servers data points reported average different trials experiment 
order compare shipping policies placements primary base relation copies policies data point 
experiment communication cost experiment examines cost query execution execution strategies 
experiments query optimizer configured minimize total query cost response time 
model experiments costs processing query strategies costs associated communication 
reason section focuses communication requirements 
general amount communication required execute query determined parameters ffl sizes base relations ffl sizes intermediate relations query result ffl amount relevant data cached client ffl number servers location base relations contribution communication total cost query execution dependent relative capacities network bandwidth resources system 
furthermore addition network cost messages require cpu resources sending receiving sites 
base relations stored single server communication trade offs fairly intuitive 
query shipping qs requires communication data shipping ds query results small compared size base relations little data cached client 
effects seen table shows number pages sent network execute small medium large queries system single server client caching 
table seen ds sends number pages regardless selectivity 
base relations sent client joins performed 
contrast number pages sent qs increases dramatically size query result small query example query result empty pages shipped server client control messages reported table sent 
table shows experiment communication cost hybrid shipping hy approach equal minimum pure approaches queries 
noted experiments network time wire seldom major factor total cost 
extreme case large query qs network time accounts total cost 
cases 
cached data introduced shown table ds hy approaches able exploit data reduce communication requirements pure qs policy 
example relation cached client ds sends pages query 
situation hy ignores client cached data small query exploits 
experiment due single server absence caching communication requirements chain star queries identical 
small query medium query large query ds qs hy table communication overhead pages single server relations cached communication trade offs somewhat different base relations distributed multiple servers 
particular communication required qs hy dependent location base relations increase relations distributed servers 
relations joined stored different servers relations sent order perform join 
ds contrast performs joins client regardless base relations stored communication requirements independent number servers 
effects demonstrated figures show network traffic required execute medium star chain queries system varying number servers randomly chosen base relations cached client 
pages sent number servers ds qs hy pages sent medium star varying servers relations cached number servers ds qs hy pages sent medium chain varying servers relations cached figures seen communication requirements ds independent number servers structure join graph 
cases relations cached client sent client query execution 
contrast ds communication requirements strategies impacted number servers join graph structure 
star query communication requirements qs increase linearly number servers 
chosen plans base relations located server containing center relation joined resulting intermediate relation shipped server joined relations located server 
plan intermediate result sent server contains non center relation 
results linear increase pages sent temporary results medium query size size base relations 
communication requirements qs chain query increase number servers higher star query servers 
behavior occurs stated earlier base relations placed servers randomly experiments cases relations stored particular server joinable chain query 
server sent base relations intermediate results query execution 
turning hy results seen queries hy matches better pure policies cases lower requirements policies 
advantage hybrid shipping primary copy relation carry joins server cached copy exists carry joins client 
additional flexibility allows hy send fewer base relations ds fewer intermediate results qs cases 
fundamental trade offs queries small large relative performance strategies differs due difference sizes intermediate results 
small query small intermediate results empty query result qs sends fewer pages sent ds server populations hy behaves qs case 
large query relatively huge intermediate results communication requirements qs orders magnitude greater ds hy behaves ds case 
experiment exploiting parallelism previous section shown pure data query shipping strategies perform unnecessary communication situations resulting excessive cost 
section response time execution strategies analyzed 
experiments query optimizer configured minimize response time estimates produced query plans cost previous section 
experiments disks typically important resources contributing response time 
due assumption main memory buffers empty query execution main memory allocation restricted 
experiments show pure policies qs ds fully exploit multiple disks multiple cpus system results demonstrated section apply cpu intensive workloads 
client caching response times execution strategies varying numbers servers relations cached client shown medium star chain queries figures respectively 
comparing figures seen trends join query graphs similar differences approaches pronounced chain query results 
parallelism server client sites plays large role determining response time stated previously chain query potential parallelism star query 
general response time ds seen independent number servers shape query graph experiment 
relations single server qs performs worse ds relations spread servers qs better exploits additional parallelism better performance ds servers 
trade ds exploits client resources qs exploits servers resources 
servers added client resources dominated server resources qs performs better ds 
hy best performance range server populations beating pure strategies servers ability client resources load balancing matching performance qs larger number servers 
response time number servers ds qs hy response time secs medium star varying servers caching number servers ds qs hy response time secs medium chain varying servers caching ds qs hy cpu disk usage medium chain client server caching ds qs hy cpu disk usage medium chain client servers caching response time results driven large part parallelism obtained approaches 
parallelism depicted figures show sum cpu disk usage site servers respectively medium chain query response time shown 
server case ds executes joins client faults pages base relations server disks ds exploit pipelined parallelism 
qs performs displaying result single server 
consequence qs exploit parallelism poorer performance case 
hy contrast able balance load client server obtaining best response time 
server case ds response time dominated client usage remains unchanged single server case 
qs able exploit independent parallelism servers significant improvement response time 
hy able better exploit resources sites resulting better response time pure approaches 
impact client disk caching results previous section demonstrate small numbers servers involved query client resources exploited provide substantial improvement response time aiding processing joins 
additional way clients improve query performance server resources limited performing scans cached data 
figures show impact client disk caching response time different types plans small medium chain queries respectively relations stored single server number relations cached client varied zero 
response time number relations cached client ds qs hy response time secs small chain single server varying caching number relations cached client ds qs hy response time secs medium chain single server varying caching response time qs independent number relations cached queries 
qs performs scans joins server ignoring cached copies 
contrast ds response time lesser extent hy response time affected number cached relations 
turning small chain query results seen response time ds improves number cached relations increased degrades point 
recall ds performs joins scans client relations cached client client disk scanning relations temporary storage hybrid hash joins 
small number relations cached ds exploit pipelined parallelism server client 
relations cached ds results increased load client disk decreased load server disk 
reason performance ds plans degrades caching relations 
relations cached client scan join performed single site client performance ds qs converge 
seen hy approach uses proper amount cached data case matches performance ds relations cached stabilizes point performance ds begins degrade 
results demonstrate client caching potential improve query performance best performance achieved ignoring cached data 
shows results medium chain query 
case performance ds plan harmed caching relations 
effect differs occurs small case amount done joins 
small query high selectivity joins results small inner relations joins processed single pass hybrid hash join algorithm 
contrast join results medium query size base relations 
medium queries minimum memory allocation joins require number passes hybrid hash algorithm resulting higher requirement small case 
ds performs joins client scans cached relations interfere required joins resulting degradation performance demonstrated 
case hy approach ignores cached copies uses client disk solely join processing resulting better performance ds qs 
robustness compiled plans previous sections shown hybrid shipping approach benefits cost response time effective exploiting resources client servers 
power hybrid shipping comes ability produce query plan tailored particular system configuration 
section investigates robustness hybrid shipping plans state system runtime differs expected query optimizer 
issues addressed section changes load server changes state client cache 
general results show expected performance hybrid shipping plan degrade significantly runtime state differs expected compile time 
demonstrates need dynamic approaches developing adjusting query plans addressed section 
server load section study performance compiled plans load server varied respect expected optimization time 
experiment load server simulated varying settings mips parameters described table compared cost model optimizer run 
experiment hybrid shipping query plan generated assuming default settings server resources mips ms executed system server resources varied default speeds mips ms times default speeds mips ms 
shows results experiment medium chain query single server client caching 
axis speed server resource runtime relative assumed optimizer axis response time pre compiled hybrid shipping plan relative response time plan optimized run time resource settings 
server cpu bandwidth relative response time medium chain single server caching axis value compile time assumptions run time settings relative response time equals 
moving left axis server slower heavily loaded relative optimizer settings 
case compiled plan relies heavily server resources resulting poorer performance 
case degradation performance plateaus slightly worse factor slower best case 
moving right server faster heavily loaded relative optimizer settings 
relative performance pre compiled plan degrades dramatically case factor slower best case 
optimizer underestimates server resources places large number joins client joins experiments results lower performance obtained fast server resources execute joins server 
client disk caching significant way run time state system differ assumed query optimization time contents client disk caches 
caching inherently dynamic process difficult predict particular client cache time 
described section client disk caching play important role determining query performance server resources limited relation scanning substantial part cost query execution 
reason experiment examines dynamic impact caching small chain query single server 
table shows response time pre compiled hybrid shipping plans assuming different client cache states executed systems cache states run time 
column shows best case experiment run time state matches assumption optimizer 
cache contents represented pairs represents number relations cached represents percentage relations cached 
plan hybrid shipping plan compiled assuming client cache contains compiled plans run time cache contents best relations portion case table response time secs small chain single server expected vs actual run time caching tuples relations 
experiment hybrid shipping plans sensitive client caching state server load shown section 
worst case experiment response time increase compared plan perfect knowledge cache contents 
assumes empty cache suffers penalty compared best case cases cache empty run time 
performs scans server joins client 
contrast assumes data cached client suffers penalty case client cache empty run time penalty cases 
sensitivity empty cache results fact plan executes joins server 
joins compete server resources required read non cached data 
plan pays high performance penalty relations fully cached optimizer places scans client addition places joins client assuming half pages scans read server disk 
execution time high contention client local disk observed expectation pages relations read client local disk 
robust plan experiment assumes relations cached client entirety 
plan pays penalty client cache empty cache contains half relations equal best plan cases 
step optimization results previous section show performance compiled plan degrade significantly server load client cache contents run time differ assumed query optimizer compile time 
main factor contributing performance degradation seen site selection join ordering 
observation indicates step optimization similar proposed carey lu cl similar xprs hs mariposa sad may basis generating query plans modified dynamically prior query execution order adapt changes run time environment 
step optimizer client server query processing environment perform 
join ordering compile time generate query plan assuming query going evaluated centralized system machine 

site selection execution time determine execute operator plan choose cached data 
join ordering carried existing query optimizer 
experiments reported section randomized query optimizer described section configured carry moves related join ordering 
simulated annealing sa site selection step execution time 
practice sa somewhat slow execution time takes approximately seconds sparcstation experiments 
sa sufficient purpose experiments investigate potential benefits limitations step approach client server query execution 
clear general step optimization generate optimal distributed plan 
example join ordering performed assuming single execution site step approach may choose left deep join tree shown bushy tree shown 
bushy tree higher cost single site lower response time distributed system join join carried different sites parallel 
join scan scan scan scan join join join join scan scan scan scan join deep tree balanced tree possible join orders performance hybrid shipping plans generated step optimization process join ordering done assuming centralized system shown variants small medium large mixed chain query 
shows performance step plans relative plan generated step optimizer perfect knowledge placement base relations servers 
medium mixed queries step plan increasingly worse performance step plan servers added 
small query join processing cheap intermediate results small performance step approach fairly small 
large query relative response time number servers small medium large mixed relative response time chain queries step centralized join ordering number servers small medium large mixed relative response time chain queries step distributed join ordering optimizers generate bushy tree plan low selectivity joins results plan having lowest cost centralized system 
contrast performance step plan medium query slower step plan servers 
step optimization chooses deep join order case step chooses bushy tree plan 
shape tree mixed query predictable joins different selectivities low high query 
case relative performance step optimization better medium query joins high selectivity carried intermediate relations smaller medium query 
problems encountered step optimization arise largely join ordering performed centralized model 
alternative approach perform join ordering step optimization assuming primary copy relation located different server assuming system servers 
net effect assumption join orders generated bushy trees 
performance results step optimization shown 
expected approach performs large medium mixed queries case better bushy tree join orderings 
addition relative performance queries tends improve servers added 
contrast small query performs best deep join ordering worst relative performance case 
results experiments show approach step optimization robust wide range queries system configurations 
case combination approaches appears sufficient choosing best variants suffers performance penalty chain queries 
environment step optimization robust star queries shown star queries parallelize case see 
experiments star query plan generated best variant step optimization noticeably high relative response time 
star queries pre compiled join order high communication cost take advantage fact relations located site joined locally sending result site 
simple way combine variants build step optimizer generates join orders compile time chooses best plan site selection run time 
results show step optimization potential approach addressing need dynamic query optimization client server environment significant additional required order develop practical robust implementations approach 
related distributed database systems investigated late seventies 
time prototype systems developed system wdh sdd bgw distributed ingres sto 
typically systems focused optimizing cost query particular effort minimize communication cost systems designed run slow networks 
concepts valid today 
eighties client server paradigm emerged standard kind distributed data processing leading shift research directions 
study uses client server environment 
addition cost study analyzes response time queries parallel execution operators query different sites load balancing systems 
load balancing investigated carey lu cl propose approach exploits replication data different sites 
system model workloads execution strategy different settings basically came system provide flexibility carry query different sites improve response time 
hagmann ferrari study query processing client server environment hf 
investigated different ways split functionality dbms query parsing optimization execution client front terminology server back machines 
study assumed functions dbms available sites system concentrated performance executing queries joins applications part query processing generate load system 
studies carried investigating various aspects client server databases fc 
studies influenced dichotomy relational object oriented systems carried pure query shipping pure data shipping 
related study analyzed utilization resources client server systems carried roussopoulos dr 
studies concentrated system server realize potential execute operators query different sites parallel 
examples research prototypes support multiple servers orion shore cdf mariposa sad sdk 
systems design execution policy plays important role 
current version shore uses data shipping 
mariposa supports query data ship distributed ingres parametrized optimize response time 
ping 
execution policies allow flexible decision execute query incorporated orion 
initial discussion execution policies specific task distributed object assembly mgs 
multidatabases sl examples distributed systems 
noticed multidatabase systems variant data shipping fixed set functions carried server systems operations processing data stored possibly heterogeneous databases system carried client 
study varies performance studies carried design parallel database systems 
emphasis studying parallel database systems exploit intra operator parallelism dg 
study showed inter operator parallelism exploited distributed system 
different execution policies identified evaluated client server database systems 
data shipping object oriented database systems 
query shipping relational systems 
hybrid shipping aims combine advantages data query shipping support navigation query access database 
performance experiments revealed depending number servers system caching data clients query characteristics execution policy influences performance system significantly 
data query shipping induce unnecessary communication overhead cases 
furthermore pure approaches fully utilize resources system result increased response time queries 
best performance achieved hybrid execution policy provides flexibility place operators query sites 
approach expands largely space possible plans evaluate query 
sensitive load machines amount data cached clients local disks 
initial experiments indicate dynamic site selection extended step approach generates join orders compile time support hybrid execution policy sufficiently 
study focused complex queries disk bound computation 
intend analyze effects navigation access updates utilization aggregate main memory 
addition plan investigate performance system applications run concurrently measuring queries isolation 
implementing query engine top shore storage system order investigate issues 
bdt bitton dewitt 
benchmarking database systems systematic approach 
proc 
conf 
large data bases vldb 
bgw bernstein goodman wong reeve 
query processing system distributed databases sdd 
acm trans 
database systems december 
cat cattell 
object database standard 
morgan kaufmann publ 
san mateo ca usa 
cdf carey dewitt franklin hall mcauliffe naughton schuh solomon tan white 
persistent applications 
proc 
acm sigmod conf 
management data pages minneapolis mi usa may 
cl carey lu 
load balancing locally distributed database system 
proc 
acm sigmod conf 
management data pages washington usa 
dewitt maier velez 
study alternative workstation server architectures object oriented database systems 
proc 
conf 
large data bases vldb pages brisbane australia august 
dg dewitt gray 
parallel database systems high performance database systems 
communications acm june 
dr roussopoulos 
performance scalability client server database architectures 
proc 
conf 
large data bases vldb pages vancouver canada 
epstein stonebraker wong 
query processing distributed relational database system 
proc 
acm sigmod conf 
management data 
fc franklin carey 
client server caching revisited 
ozsu 
international workshop distributed object management 
fcl franklin carey livny 
local disk caching client server database systems 
proc 
conf 
large data bases vldb pages dublin ireland 
fra franklin 
caching memory management client server database systems 
phd thesis university wisconsin madison wisconsin june 
ghk ganguly hasan krishnamurthy 
query optimization parallel execution 
proc 
acm sigmod conf 
management data pages san diego usa june 
hf hagmann ferrari 
performance analysis back database architectures 
acm trans 
database systems march 
hs hong stonebraker 
parallel query processing xprs 
technical report ucb erl department industrial engineering operations research school business administration university california berkeley ca may 
ik ioannidis kang 
randomized algorithms optimizing large join queries 
proc 
acm sigmod conf 
management data pages atlantic city usa april 
woelk kim lee 
query processing distributed orion 
proc 
intl 
conf 
extending database technology edbt pages venice italy march 
kim kim 
object oriented database systems promises reality 
proc 
conf 
large data bases vldb dublin ireland 
kulkarni 
object oriented extensions sql status report 
proc 
acm sigmod conf 
management data page minneapolis mi usa may 
valduriez zait 
effectiveness optimization search strategies parallel execution spaces 
proc 
conf 
large data bases vldb pages dublin ireland 
mgs maier graefe shapiro daniels keller vance 
issues distributed object assembly 
ozsu pages 
international workshop distributed object management 
ml lohman 
optimizer validation performance evaluation distributed queries 
proc 
conf 
large data bases vldb pages kyoto japan 
ozsu dayal valduriez editors 
distributed object management 
morgan kaufmann publ 
san mateo ca usa may 
international workshop distributed object management 
stonebraker third generation data base system manifesto 
technical report 
ucb erl uc berkeley berkeley ca 
sac selinger astrahan chamberlin lorie price 
access path selection relational database management system 
proc 
acm sigmod conf 
management data pages boston usa may 
sad stonebraker aoki devine litwin olson 
mariposa new architecture distributed data 
proc 
ieee conf 
data engineering pages houston tx 
sc shekita carey 
performance evaluation pointer joins 
proc 
acm sigmod conf 
management data pages atlantic city nj may 
sdk stonebraker devine litwin pfeffer sah staelin 
economic paradigm query processing data migration mariposa 
proc 
ieee conf 
parallel distributed information systems pages september 
sha shapiro 
join processing database systems large main memories 
acm trans 
database systems september 
sl sheth larson 
federated database systems distributed heterogeneous databases 
acm computing surveys 
moerkotte kemper 
optimizing join orders 
technical report mip universitat passau passau germany 
sto stonebraker 
design implementation distributed ingres 
stonebraker editor ingres papers anatomy relational database system 
addison wesley pub 
sto stonebraker 
miro dbms 
proc 
acm sigmod conf 
management data washington dc usa may 
wdh williams daniels haas lapis lindsay ng obermarck selinger walker yost 
overview architecture 
ibm research san jose ca rj december 
