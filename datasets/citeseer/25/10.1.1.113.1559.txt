animated conversation rule generation facial expression gesture spoken intonation multiple conversational agents justine cassell catherine pelachaud norman badler mark steedman brett becket brett douville scott prevost matthew stone department computer information science university pennsylvania describe implemented system automatically generates animates conversations multiple human agents appropriate synchronized speech intonation facial expressions hand gestures 
conversations created dialogue planner produces text intonation utterances 
speaker listener relationship text intonation turn drive facial expressions lip motions eye gaze head motion arm gesture generators 
coordinated arm wrist hand motions invoked create semantically meaningful gestures 
examples actual synthesized fully animated conversation 
faced task bringing life human character options currently available 
manually laboriously manipulate numerous degrees freedom synthetic write acquire increasingly sophisticated motion generation software inverse kinematics dynamics resort performance motions obtained live actor puppet 
emergence low cost real time motion sensing devices led renewed interest active motion capture position orientation trajectories may acquired directly tedious image 
facial gestural motions efficiently tracked suitably harnessed actor 
imply manual synthesized animation near 
raises challenge providing sophisticated toolkit human character animation require presence skill live actor freeing skilled animator challenging tasks 
system automatically animating multiple human agents appropriate synchronized speech intonation facial expressions hand gestures 
especially noteworthy linkage speech authors francisco chin seah john kim lam zhao 
gesture explored synthesizing realistic animation 
people speech facial expressions gestures physiologically linked 
expert animator may realize look properly animated character program automatically generate motions know rules advance 
presents working system realize interacting animated agents 
conversation interactive dialogue agents 
conversation includes spoken language words contextually appropriate intonation marking topic focus facial movements lip shapes emotions gaze direction head motion hand gestures handshapes points beats motions representing topic accompanying speech 
verbal non verbal behaviors realistic believable autonomous agents 
limit problems voice face recognition arise involvement real human conversants constrain dialogue form dialogue generation program copies identical program having different knowledge world cooperate accomplish goal 
agents conversation collaborate dialogue develop simple plan action 
interact exchange information ask questions 
background information necessary establish synchrony speech facial expression gesture 
discuss system architecture subcomponents 
background faces change expressions continuously changes going 
facial linked speech nose talking unpleasant emotion eyebrows worry personality time 
replace sequences words dressed nose stick tongue accompany serve help disambiguate said acoustic signal degraded 
occur randomly synchronized speech speech 
eye gaze important feature non verbal communicative behaviors 
main functions help regulate flow conversation signal search feedback interaction gazing person see follows look information express emotion looking downward case sadness influence person behavior staring person show power 
people produce hand gestures spontaneously speak gestures support expand information conveyed words 
fact gestures occur time speech carry meaning speech suggests production intimately linked 
fact meaning words gestures intimately linked discourse functions accomplishing conversational shown certain kinds gestures produced conversation act structure contributions participants signal utterance continues topic strikes new direction signal contribution particular utterances current discourse 
clear facial expression gesture performance independent speech simply translation speech 
gesture speech intimately connected say 
claimed arise single internal encoding process 
example section fragment dialogue complete dialogue synthesized animated intonation gesture head lip movements inter synchronization automatically generated 
example serve demonstrate phenomena described subsequent sections return phenomenon explain rule generation synchronization carried 
dialogue imagine gilbert bank teller george asked gilbert help obtaining 
dialogue repetitive explicit goals dialogue generation program produced conversational inferences allow humans follow leaps reasoning 
agents specify advance goals working steps see section 
gilbert blank check 
george blank check 
gilbert account check 
george account check 
gilbert account contain dollars 
george account contains dollars 
gilbert get check dollars withdraw dollars 
george right get check dollars 
gilbert asks question voice rises 
george replies question voice falls 
gilbert asks george blank check stresses word check 
asks george account check stresses word account 
time gilbert replies affirmatively turns floor gilbert right nods head raises eyebrows 
george gilbert look gilbert asks question question gilbert looks slightly 
brief pause affirmative statements speaker george fragment blinks 
mark questions gilbert raises eyebrows 
saying word check gilbert sketches outlines check air listener 
saying account gilbert forms kind box front hands metaphorical representation bank account keeps money 
says phrase withdraw dollars gilbert withdraws hand chest 
communicative significance face movements head facial expressions characterized placement respect linguistic utterance significance transmitting information 
set facial movement clusters contains syntactic functions accompany flow speech synchronized verbal level 
facial movements raising eyebrows nodding head blinking saying blank check appear accented syllable pause 
semantic functions emphasize said substitute word refer emotion nose talking smiling remembering happy event nice day 
functions regulate flow speech depend relationship people smooth turns occurrent mutual gaze blank check look 
functions modulated various parameters speaker listener characteristic functions convey information speaker social identity emotion attitude age friends spend time looking talking lying speaker avoid gaze 
listener functions correspond listener reactions speaker speech signals agreement attention comprehension saying see 
communicative significance hand gestures gesture described terms intrinsic relationship speech 
aspects relationship described go speak synchronization communicative channels 
basic types gestures occur speech estimates gestures occur speaker uttering 
represent feature accompanying speech sketching small rectangular space hands saying blank check represent feature concurrently spoken forming jaw shape hand pulling body saying withdraw dollars 
indicate point space 
persons places discourse entities 
example pointing ground saying account bank 
beats small waves hand occur heavily emphasized words occasions turning floor speaker kinds special linguistic 
example waving left hand briefly phrase right 
discourse contexts quarters clauses accompanied gestures kind iconic beats remaining divided deictic metaphoric gestures 
surprisingly proportion different gestures may change types gestures spontaneous gesturing general discourses speakers languages 
semantic pragmatic relationship media 
gesture speech manifest information idea convey complementary 
gesture may depict way action meaning listener interrupt overlap speaker 
carried aspect meaning depicted speech 
example speaker describing deposits checks bank account said list checks depicted hands deposit slip turned turned vertically order checks listed spaces provided back slip 
importance interdependence speech gesture shown fact speakers rely information conveyed gesture exclusion information conveyed accompanying speech try comprehend story 
hand gestures gaze behavior virtually absent attempts animate semi autonomous agents communicative contexts 
synchrony gesture facial movements speech facial expression eye gaze hand gestures communicative single utterances effects 
presence absence confirmatory feedback conversational participant gaze head movement example affects behavior 
conversation consists exchange meaningful utterances behavior 
person reinforces speech head nods smiles hand gestures person smile back shift gaze show participation conversation 
synchrony implies changes occurring speech body movements appear time 
example word begins articulated eye blinks hand movement head turning brow raising occur finish word 
synchrony occurs levels speech phonemic segment word phrase long utterance 
different facial motions characteristic different groups 
adapted phoneme level eye blink act word level 
example blank check raising eyebrow starts ends accented syllables check blink starts ends pause marking utterance 
facial expression emphasis match showing synchronization level sequence head nods emphasis 
movements reflect encoding decoding difficulties coincide pauses inside clauses 
hesitation pauses produced speech correlate avoidance gaze head speaker turns away listener help speaker concentrate going say 
gestures occur synchrony semantically parallel linguistic units cases pauses syntactically complex speech gesture appears 
local level individual gestures words synchronized time stroke energetic part gesture occurs just phonologically prominent syllable accompanying speech segment 
global level find hands speaker come rest speaking turn speaker begins turn 
intermediate level phenomenon articulation gestural units gestures performed rapidly production stretched time synchronize preceding gestures speech gestures accompany 
example gestural articulation relationship gestures phrase get check dollars withdraw dollars 
phrase right hand sketches writing gesture front speaker 
carrying gesture way completion hands coming rest gesture maintaining location hands space hand drops slightly pulls back speaker perform withdraw gesture 
occurrence phrase accompanying gesture affected occurrence gesture accompanied withdraw 
computer animation conversation literature facial control systems various systems proposed integrate different facial expression functions 
systems facs facial action coding system notational system 
system anatomical studies describes visible facial movements 
action unit au basic element system describes action produced group related muscles 
multi layer approach allows independent control level system 
lowest level geometric level geometry face modified free form deformation techniques 
highest level facial animation computed input utterance 
patel model facial animation done different levels representation 
done muscle level au level script level 
au user select starting points action intensity action start tensions interpolation method compute frames 
alternative approach proposed results 
building user interface propose categorization facial expressions depending communicative meaning 
facial functions list facial displays performed example remembering eye closure side mouth pull back 
user talks synthetic actor 
speech system recognizes words generates answer appropriate facial displays 
grammar rules small vocabulary set specific knowledge domain part speech analysis system 
responses actor selected pre established set utterances 
appropriate facial displays accompanying answer follow analysis conventional situation user speech recognized actor answer confident facial display 
literature gesture animation computer graphics literature sparse topic gesture animation 
animators frequently key parameter techniques create arm hand motions 
girard created handshapes automatically object 
improved hand model include better skin models deformations finger tips object 
lee kunii built includes handshapes simple pre stored facial expressions american sign language asl synthesis 
dynamics arm gestures asl studied loomis 
chen constructed virtual human shake hands interactive participant 
lee automatically generate lifting gestures considering strength comfort measures 
moravec calvert constructed system portrays gestural interaction agents pass greet 
behavioral parameters set personality attribute sliders interaction pre determined limited just type nonverbal encounter 
overview system current system model face face interaction generate behaviors implemented informational status intonation communicative function head nods symbolic gesture specification gesture pat net dialogue planner phoneme timings gesture utterance synchronization movement specification animation system graphic output symbolic intonation specification facial pat net interaction components world agent model speech synthesizer sound gaze hand gestures 
additionally system implements agents verbal nonverbal behaviors integrated turns speakers 
remaining parts explain different elements 
start top bottom 
currently gesture generated dialogue planner facial expression gaze generated facial pat net 
dialogue planner text dialogue automatically generated basis database facts describing way world works list goals agents set beliefs agents world including beliefs 
instance agents goals change course dialogue gilbert comes goal helping george get george comes goal writing check 
text generated pitch accents phrasal melodies placed generated text outlined 
text converted automatically form suitable input bell laboratories tts synthesizer 
dialogue generated information saved automatically timing phonemes pauses type place accents type place gestures 
speech timing information critical synchronizing facial gestural animation 
symbolic gesture specification dialogue generation program annotates utterances semantic content relate spatial expression literally metaphorically 
entities classified discourse status new discourse hearer new discourse hearer definites mention old 
rules annotations earlier ones determine concepts associated gesture 
gestures represent verbal elements roughly information spoken hearer new provided semantic content appropriate class receive gesture words literally spatial concrete content get check metaphorically spatial content get account words physically examples symbolic gesture specification content get bank 
beat gestures generated items semantic content represented spatially produced new definite dollars 
representational gesture called system accesses dictionary gestures motion prototypes associates semantic representations possible gestures represent details see 
see examples symbolic gestures generated discourse content 

blank check frame iconic gesture representing rectangular check generated mention new hearer entity blank check 

help get dollars second frame metaphoric gesture common propose gesture representing request help proposal offered listener generated mention new hearer request help 

write check third frame iconic gesture representing writing piece generated mention concrete action writing check 

wait withdraw dollars fourth frame beat gesture movement hand generated mention notion wait represented spatially 
gestural annotation gesture types lexicon look appropriate forms representational gestures information duration intonational phrases acquired speech generation time gestures 
gestures intonational phrase collected 
relationship gesturing dialogue representational gesture occurs intonational phrase 
representational gesture preparation set intonational phrase finish gesture intonational phrase nuclear stress solution provisional richer semantics include features relevant gesture generation form gestures generated algorithmically semantics 
note led believe gestures may standardized form previously thought 
default gesture info complete send beat beat pat net parsing beat signalled gesture info current parsed line gather gesture information file reached default gesture info complete close nets relax gesture send gesture gesture pat net default exit pat net synchronizes gestures dialogue phoneme level 
phrase whichever comes 
stroke phase set coincide nuclear stress phrase 
relaxation set sooner stroke beat intonational phrase relaxation occur intonational phrase 
beats contrast simply timed coincide stressed syllable word realizes associated concept 
timing rules applied intonational phrases utterance output series symbolic gesture types times performed 
instructions generate motion files run animation system 
underlying coordination model interaction agents synchronization gaze hand movements dialogue agent accomplished parallel transition networks pat nets allow coordination rules encoded simultaneously executing finite state automata 
pat nets call action simulation state transitions conditionally probabilistically 
pat nets scheduled simulation operating system allows invoke kill pat nets sleep desired time desired condition met synchronize running nets waiting finish waiting shared semaphore 
addition pat net notation object oriented net defined class actions transition conditions methods 
running networks instances pat net class take parameters instantiation 
notation allows pat nets hierarchically organized allows constructing new nets combining existing nets making simple modifications existing nets 
behaviors implemented specified sections head eye hand individual encoded pat nets 
pat net instance created control agent appropriate parameters 
agents pat nets synchronize agents dialogue interact unfolding simulation schedule activity achieves complex observed interaction behavior 
gesture generator gesture pat net sends information timing shape position hands arms animation system 
imation process produces file motions carried figures 
starting gesture timing speech rate surrounding gestures constrain motion proper articulation effect 
depicted signalling particular gesture parse net instantiate additional pat nets gesture beat finite state machine representing beats beat net called deictic iconic metaphoric network representing types gestures called 
separation motivated rhythm hypothesis posits beats arise underlying pulse speaking gestures arise meaning representations 
addition beats superimposed types gestures separation facilitates implementation superposition 
goals model reflect differences behavior gesture types system provides control freedom versus boundedness gestures iconic gesture tightly constrained particular standard formedness beats display free movement free gestures may easily generated separate pat net parameters include feature 
gesture beat finite state machines built necessary parser gestures represented arise 
newly created instances gesture beat pat nets exit immediately creating respective gestures pause await commands calling network case parse net 
allow gesture coarticulation gestures may occur utterance intermediary relaxation dropping hands cases relaxing handshape 
current utterance reached parser adds level control forces exit relaxation gestures gesture top stack final gesture followed relaxation arms hands wrists 
consider data intonation gesture streams 
examine gesture pat net acts input 
intonation blank check gesture pr beat sk rx example primary intonational stress phrase falls check secondary stress blank 
gesture line example shows preparation pr gesture begins stroke gesture st falls check gesturing relaxes rx check 
secondary stress new informational item blank beat gesture falls superimposed production 
due structure conversation speakers alternate turns assume similar alternation gesturing 
gesturing listeners non existent 
purposes gesture generation phoneme information ignored utterance barriers interpreted provide envelope timing particular gesture sequence gestures determine speaker gesturing 
timing information speech file allows pat net determine time complete gesture produced 
example iconic gesture accompanies utterance blank check sufficient time execute gesture occurring phrase shown 
timing insufficient allow full gesture production gesture allow reduced available timing beat gestures produced separate pat net system enter questions articulation 
common reason foreshortening anticipation gesture produced discourse 
anticipatory coarticulation effects relaxation phase iconic metaphoric deictic gesture preparation phase gesture 
process seen gestures phrase get check dollars withdraw dollars 
produced seconds phrase withdraw generated seconds 
causes foreshortening relaxation process gesture second gesture produced 
articulation constraints synchronizing gestures intonational surrounding gestures may gestures aborted little time available production physical constraints human model 
gesture motion specification graphics level gesture animation system accepts gesture instructions containing information location type timing handshape individual gestures 
current location hands arms space system attempt get close possible gesture goals time allowed may mute motions achieve time articulation effects 
animation system calls library predefined handshapes form primitives hand gesture 
chosen reflect shapes gesture conversational interaction 
animation system calls separate hand arm wrist control mechanisms 
gesture system divided parts hand shape wrist control arm positioning 
hand shape relies extensible library hand basic joint positions allows varying degrees relaxation neutral hand position 
speed hand may change shape limited allow modelling hand shape articulation 
large changes hand position restricted time allotted hand movement forcing faster hand gestures smooth 
wrist control system allows wrist maintain change position independently complex arm motions may occurring 
wrist limited model physically realistic range motion 
wrist direction specified terms simple directions relative point fingers left hand forward palm right 
arm motion system accepts general specifications spatial goals drives arms goals limits imposed arm range motion 
arm may positioned general directions chest high slightly forward far left 
expressiveness individual gesturing represented adjusting size gesture space graphical 
way parameters age children gestures larger adults culture cultures gestures tend larger implemented gesture animation 
symbolic facial expression specification current system facial expression movement lips eyebrows specified separately movement head eyes gaze 
section discuss facial expression turn gaze section 
ekman colleagues characterize set semantic syntactic facial meaning 
facial functions exist manipulators correspond biological needs face lips emotional facial expressions replacing word emotion directly linked intonation voice 
system facial expressions connected intonation automatically generated kinds expressions example specified hand 
symbolic gaze specification gaze classified primary categories depending role conversation 
give rules facial expressions gaze behavior corresponding right 
pause write check 
action functions categories see 
nodes pat net refer indicated 
planning corresponds phase turn speaker organizes thoughts 
tendency look away order prevent overload information turn 
hand execution phase speaker knows going say looks listener 
short turn duration sec speaker listener establish eye contact mutual gaze short turn 
comment accompanies comments speech occurring parallel accent emphasis 
accented emphasized items punctuated head nods speaker looks listener accent 
speaker gazes listener asks question 
looks question utterance question 
answering speaker looks away utterance answer 
control controls communication channel functions synchronization signal responses may demanded suppressed looking listener 
speaker wants give turn speaking listener gazes listener utterance turn 
listener asks turn looks speaker turn request 
feedback collect seek feedback 
listener emit different reaction signals speaker speech 
speaker looks listener grammatical pauses obtain feedback utterances received turn 
frequently followed listener looking nodding back channel 
turn speaker wants keep turn looks away listener continuation signal 
speaker doesn emit turn signal gazing listener listener emit back channel turn may followed signal speaker 
probability action listener varies action speaker particular decreases signal occurred speaker 
way listener reacts behavior speaker 
gaze generator functions appears sub network pat net 
outlines high level pat net gaze control single agent 
contains functions nodes define function associated actions 
definitions extract conditions actions charac short turn planning feedback turn comment utterance accent answer turn utterance question gaze control turn request turn back channel continuation signal gaze movement pat net actions defined nodes conditional probabilistic transitions occur arcs 
leaf nodes branch back root node unconditionally 
functions 
current version program differentiate head movement eye movement 
eyes follow head 
literature difference rarely 
follows gaze refer head eye movement 
node characterized probability 
person floor talking pausing loses soon person starts talking 
possible states person having floor 
floor listener pauses talking pausing 
states listener gaze 
gives possibilities dyad 
compute probability states 
nodes pat net characterized certain set states 
example occurrence turn signal defined corresponds action person looks person having floor pausing 
state sets correspond sub matrix 
compute probability sub matrix relation particular state having floor pausing arrive probability occurrence 
computation nodes pat net 
probabilities appropriate agent current role listener speaker set pat net executes 
turn change probabilities change values accordingly 
information determine rules transitional probabilities actions pat nets 
phoneme gaze pat net entered 
transition node condition true 
probability nodes allows action performed 
action different nodes pat net illustrated example gilbert get check dollars pause pause withdraw dollars 
planning phonemes example utterance example corresponds sub network planning applied 
utterance short turn entered 
turn entered condition turn true probability turn defined phonemes accented segment 
allow gazes away applied 
speaker gilbert keeps current gaze direction looking george 
comment example accented items check withdraw sub network comment reached actions speaker gazes listener nod performed gilbert 
instantiation action depends probability 
system easily represents parallel agent actions 
control example utterance corresponding dollars sub network control entered 
actions considered 
node turn corresponds action performed speaker speaker gazes listener 
node turn request affects listener gazes speaker performed 
feedback intonational phrases example get check dollars separated pause corresponds turn situation 
sub network feedback entered 
probability allows action speaker gazes listener performed delay sec specified program node back channel reached 
program checks probabilities associated actions 
actions happen listener gazes speaker listener nods 
case final step feedback sub network reached delay 
action speaker gazes away listener performed 
facial expression generator facial expressions belonging set semantic syntactic functions see section clustered functional groups lip shape conversational signal manipulator 
facs denote facial expressions 
represented parameters time occurrence type 
algorithm embodies rules described section automatically generate facial expressions principle synchrony 
program scans input utterance computes different facial functional groups 
computation lip incorporates coarticulation effects 
phonemes associated characteristic shapes different degree 
deformable elements temporal spatial constraints modify shapes consider surrounding context 
conversational signal movements occurring accents raising eyebrow starts ends accented word signal movement occurring pause happens pause 
blink signals synchronized phoneme level 
signals emotional performed consciously specified user 
varying parameters defining facial expression different speaker personalities obtained 
example persuasive person accented word raising eyebrows person 
gaze facial motion specification gaze directions generated previous stage instantiated 
discussed earlier gaze pat net run agent phoneme 
depending course taken network due probabilistic turn defined phonemes accented segment phonemes 
case action performed arc going channel immediately traversed waiting phonemic segment 
branching environmental state net may commit agent variety actions head nod change gaze point 
gaze supplying human model coordinate look time move scheduled motion begins current point simulation specified duration 
head nod accomplished scheduling sequence joint motions neck supplying angle angular velocity nod cycle 
note gaze controller schedules motions necessary reacting unfolding simulation fact semi real time generate motions advance 
gaze controller easy extend easy integrate rest system 
different functions may served action differ timing amplitude 
example accent speaker head nod larger amplitude feedback head nods emitted listener 
different head nod functions may characterized varying numbers cycles 
gaze direction sustained calling agent look pre defined point environment change action 
facial expressions program outputs list aus characterize phonemic element pause 
scanning input utterances actions performed specified 
animation files output 
final animation done combining different output files gesture face gaze jack 
automatically generating information intonation facial expression head movements hand gestures allows interactive dialogue animation created non real time animation guess construction appropriate motions avoided 
resulting motions demonstrated video actions timings cognitively physiologically justified guide refinement conversation participants interactions human animator 
argyle cook 
gaze mutual gaze 
cambridge university press 
badler barsky zeltzer editors 
making move mechanics control animation articulated figures 
morgan kaufmann san mateo ca 
badler phillips webber 
computer graphics animation control 
oxford university press june 
becket 
jack lisp api 
technical report ms cis graphics lab university pennsylvania 
tom calvert 
composition realistic animation sequences multiple human figures 
norman badler brian barsky david zeltzer editors making move mechanics control animation articulated figures pages 
morgan kaufmann san mateo ca 
cappella 
personal communication 
justine cassell mark steedman norm badler catherine pelachaud matthew stone brett douville scott prevost brett 
modeling interaction speech gesture 
proceedingsof cognitive science society annual conference 
justine cassell david mcneill 
gesture poetics prose 
poetics today 
justine cassell david mcneill karl erik mccullough 
kids don try home experimental mismatches speech gesture 
international communication association annual meeting 
chen pieper singh rosen zeltzer 
virtual implementation interactive human body modeling 
proc 
virtual reality annual international symposium seattle wa september 
ieee 
cohen massaro 
modeling coarticulation synthetic visual speech 
thalmann thalmann editors models techniques computer animation pages 
springer verlag 
collier 
emotional expression 
lawrence erlbaum associates 
condon 
speech body motion synchrony speaker hearer 
horton jenkins editors perception language pages 
academic press 
duncan 
signals rules speaking turns conversations 
editor nonverbal communication 
oxford university press 
ekman 
movements precise meanings 
journal communication 
ekman 
editors human ethology claims limits new contributions colloquium pages 
cambridge university press cambridge england new york 
ekman friesen 
coding system 
consulting psychologists press 
jean nadia magnenat thalmann daniel thalmann 
simulation object human skin deformations grasping task 
computer graphics 
magnenat thalmann thalmann 
smile multilayered facial animation system 
kunii editor modeling computer graphics 
springer verlag 
kendon 
movement coordination social interaction examples described 
editor nonverbal communication 
oxford university press 
adam kendon 
speech aspects process utterance 
key editor relation verbal nonverbal communication pages mouton 
lee kunii 
visual translation native sign language 
workshop visual languages seattle wa 
ieee 
philip lee wei zhao norman badler 
strength guided motion 
computer graphics 
mark liberman buchsbaum 
structure usage current bell labs text speech programs 
technical memorandum tm bell laboratories 
jeffrey loomis howard john hollerbach 
computer graphic modeling american sign language 
computer graphics july 
nadia magnenat thalmann daniel thalmann 
human body deformations joint dependent local operators finite element theory 
norman badler brian barsky david zeltzer editors making move mechanics control animation articulated figures pages morgan kaufmann san mateo ca 
david mcneill 
hand mind gestures reveal thought 
university chicago 
patel 
making faces 
phd thesis school mathematical sciences university bath bath avon uk 
pelachaud badler steedman 
linguistic issues facial animation 
magnenat thalmann thalmann editors computer animation pages 
springer verlag 
richard power 
organisation 
linguistics 
scott prevost mark steedman 
generating contextually appropriate intonation 
proceedings th conference european chapter association pages utrecht 
ellen prince 
zpg letter subjects definiteness information status 
thompson mann editors discourse description diverse analyses fund raising text pages john benjamins 
hans michael girard 
computer animation hands grasping 
computer graphics july 
barbara robertson 
easy motion 
computer graphics world december 
klaus scherer 
functions nonverbal signs conversation 
giles st editor social contexts language pages 
lawrence erlbaum associates 
mark steedman 
structure intonation 
language 
takeuchi nagao 
communicative facial displays new 
acm ifip interchi amsterdam 

production gesture 

research acknowledgments research partially supported nsf iri iri cise cda nsf graduate fellowships nsf ger aro daal including participation army research laboratory aberdeen air force depth contract hughes missile systems university iowa national defense science engineering graduate fellowship computer science daal nsf instrumentation laboratory improvement program 
