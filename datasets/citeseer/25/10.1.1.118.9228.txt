ieee transactions pattern analysis machine intelligence vol 
january generalized queries probabilistic context free grammars david pynadath michael wellman probabilistic context free grammars pcfgs provide simple way represent particular class distributions sentences context free language 
efficient parsing algorithms answering particular queries pcfg calculating probability sentence finding parse developed applied variety problems 
extend class queries answered ways allowing missing tokens sentence sentence fragment supporting queries intermediate structure presence particular nonterminals flexible conditioning variety types evidence 
method works constructing bayesian network represent distribution parse trees induced pcfg 
network structure mirrors chart standard parser generated similar dynamic programming approach 
algorithm constructing bayesian networks pcfgs show queries patterns queries network correspond interesting queries pcfgs 
network formalism supports extensions encode various context sensitivities probabilistic dependency structure 
index terms probabilistic context free grammars bayesian networks 
ost pattern recognition problems start observations generated structured stochastic process 
probabilistic context free grammars pcfgs provided useful method modeling uncertainty wide range structures including natural languages programming languages images speech signals rna sequences 
domains plan recognition nonprobabilistic grammars provided useful models may benefit explicit stochastic model 
created pcfg model process apply existing pcfg parsing algorithms answer variety queries 
instance standard techniques efficiently compute probability particular observation sequence find probable parse tree sequence 
section provides brief description pcfgs associated algorithms 
techniques limited types evidence exploit types queries answer 
particular existing pcfg techniques generally require specification complete observation sequence 
contexts may partial sequence available 
possible may evidence simple observations 
example natural language processing may able exploit contextual information sentence determining beliefs certain unobservable variables parse tree 
addition may interested computing authors artificial intelligence laboratory university michigan beal avenue ann arbor mi 
mail pynadath wellman umich edu 
manuscript received nov revised nov 
recommended acceptance ishida 
information obtaining reprints article please send mail tpami computer org ieeecs log number 
ieee ties alternate types events observations features parse extant techniques directly support 
restricted query classes addressed existing algorithms limit applicability pcfg model domains may require answers complex queries 
flexible expressive representation distribution structures generated grammar support broader forms evidence queries supported specialized algorithms currently exist 
adopt bayesian networks purpose define algorithm generate network representing distribution possible parse trees specified string length generated pcfg 
section describes algorithm algorithms extending class queries include conditional probability symbol appearing region parse tree conditioned evidence symbols appearing parse tree 
restrictive independence assumptions pcfg model limit applicability especially domains plan recognition natural language complex dependency structures 
flexible framework bayesian network representation supports extensions context sensitive probabilities probabilistic parse tables briscoe carroll 
section explores possible ways relax independence assumptions pcfg model approach 
modified versions pcfg algorithms support class queries supported context free case 
probabilistic context free grammars probabilistic context free grammar tuple disjoint sets specify terminal nonterminal symbols respectively ieee transactions pattern analysis machine intelligence vol 
january np vp pp prep np vp prep np noun verb swat np noun pp verb flies np noun np verb vp verb noun swat vp verb np noun flies vp verb pp noun ants vp verb np pp fig 

probabilistic context free grammar charniak 
start symbol 
set productions take form pr probability expanded string sum probabilities expansions nonterminal 
examples sample grammar charniak shown fig 

definition pcfg model prohibits rules form represents empty string 
rewrite pcfg eliminate rules represent original distribution long note probability pr 
clarity algorithm descriptions assume pr negligible amount additional bookkeeping correct nonzero probability 
probability applying particular production intermediate string conditionally independent productions generated string productions applied symbols string presence probability derivation simply product probabilities individual productions involved 
define parse tree representation derivation nonprobabilistic context free grammars 
probability string language sum taken possible derivations 
standard pcfg algorithms number possible derivations grows exponentially string length direct enumeration computationally viable 
standard dynamic programming approach probabilistic nonprobabilistic cfgs exploits common production sequences shared derivations 
central vp np vp np vp vp verb np pp vp verb np fig 

chart swat flies ants 
vp verb pp np noun pp np noun np vp verb np pp prep np structure table chart storing previous results subsequence input sentence 
entry chart corresponds subsequence observation string symbol entry contains probability corresponding subsequence derived symbol pr 
index refers position subsequence entire terminal string indicating start sequence 
index refers length subsequence 
bottom row table holds results subsequences length top entry holds result pr probability observed string 
compute probabilities bottomup know pr observed symbol define probabilities recursively sum productions product pr 
altering procedure take maximum sum yields probable parse tree observed string 
algorithms require time string length ignoring dependency size grammar 
compute probability sentence swat flies ants algorithm generate table shown fig 
eliminating unused intermediate entries 
separate entries production necessary interested final sentence probability 
top entry listings production np vp different subsequence lengths right hand side symbols 
sum probabilities productions left hand side entry yields total sentence probability 
algorithm capable computing inside probability probability particular string appearing inside subtree rooted particular symbol 
top analogous manner compute outside probability probability subtree rooted particular symbol appearing particular string 
probabilities compute probability particular nonterminal symbol appearing parse tree root subtree covering subsequence 
example sentence swat flies ants compute probability ants prepositional phrase combination inside np noun np noun np noun verb swat verb flies prep noun ants noun swat noun flies verb pynadath wellman generalized queries probabilistic context free grammars fig 

parse tree swat flies ants indices labeled 
outside probabilities 
left right inside lri algorithm specifies inside probabilities obtain probability initial subsequence probability sentence length words swat flies 
furthermore initial subsequence probabilities compute conditional probability terminal symbol prefix string 
indexing parse trees conceivable queries covered existing algorithms answerable straightforward manipulations inside outside probabilities 
example observations arbitrary partial strings unclear exploit standard chart directly 
similarly unaware methods handle observation nonterminals words form prepositional phrase 
seek mechanism admit observational evidence form part query pcfg requiring enumerate consistent parse trees 
require scheme specify events appearance symbols designated points parse tree 
indices delimit leaf nodes subtree standard chart parsing algorithms 
example pp node parse tree fig 
root subtree leaf nodes ants 
uniquely specify node indices 
branch parse tree passing np flies nodes 
differentiate introduce index defined recursively 
node child indices 
index index child 
flies node noun node parent np 
labeled node parse tree fig 
indices 
think index node level abstraction higher values indicating symbols 
instance flies symbol specialization noun concept turn specialization np concept 
possible specialization corresponds abstraction production form symbol right hand side 
parse tree involving production nodes identical values value 
denote set abstraction productions productions decomposition productions set symbols righthand side 
node expanded decomposition production sum values children equal value length original subsequence derived equal total lengths subsequences children 
addition child derive string nonzero length child index 
abstraction productions connect nodes indices match components decomposition productions connect nodes indices differ 
bayesian networks pcfgs bayesian network directed acyclic graph nodes represent random variables associated node specification distribution variable conditioned predecessors graph 
network defines joint probability distribution probability assignment random variables product probabilities node conditioned values predecessors assignment 
edges included graph indicate conditional independence specifically node conditionally independent immediate predecessors 
algorithms inference bayesian networks exploit independence simplify calculation arbitrary conditional probability expressions involving random variables 
expressing pcfg terms suitable random variables structured bayesian network principle support broader class inferences standard pcfg algorithms 
demonstrate expressing distribution parse trees probabilistic grammar incorporate partial observations sentence forms evidence determine resulting probabilities various features parse trees 
pcfg random variables base bayesian network encoding pcfgs scheme indexing parse trees section 
random variable ijk denotes symbol parse tree position indicated indices 
looking back example parse tree fig 
symbol labeled indicates ijk index combinations appearing tree correspond variables null value nil 
assignments variables ijk sufficient describe parse tree 
construct bayesian network variables dependency structure quite complicated 
example example pcfg fact value np influence takes value pp parent parse tree vp 
need additional link fact possible sibling nodes parents multiple expansions 
ieee transactions pattern analysis machine intelligence vol 
january simplify dependency structure introduce random variables ijk represent productions expand corresponding symbols ijk 
instance add node take value vp verb np pp example 
conditionally independent link siblings necessary case 
know production ijk corresponding children parse tree may conditionally independent 
instance chart fig 
entry separate probability values production np vp corresponding different subsequence lengths symbols right hand side 
production multiple possibilities connected variables np vp np vp 
sibling nodes conditionally dependent knowing determines values 
dictate variable ijk take different values breakdown right hand symbols subsequence lengths 
domain ijk variable consists productions augmented indices symbols right hand side 
previous example domain require possible values np vp np vp numbers brackets correspond values respectively associated symbol 
know np vp probability 
deterministic relationship renders child variables conditionally independent ijk 
describe exact nature relationship section 
having identified random variables domains complete definition bayesian network specifying conditional probability tables representing interdependencies 
tables variables represent deterministic relationship parent variables 
need conditional probability variable value corresponding variable pr ijk ijk 
pcfg specifies relative probabilities different productions nonterminal compute probability analogous inside probability symbol right hand side root node subtree abstraction level terminal subsequence length calculating algorithm calculate values modified version dynamic programming algorithm sketched section 
standard chart pcfg algorithms define function recursively dynamic programming compute values 
terminal symbols appear leaves parse tree terminal symbol 
nonterminal symbol nonterminals leaf nodes 
sum productions expanding probability production expanding producing subtree constrained parameters abstraction productions possible 
abstraction production need probabilities expanded derives string length abstraction level immediately probability associated production simply 
independence assumptions pcfg model expansion independent derivation joint probability simply product 
compute probabilities abstraction production expanding different expansions mutually exclusive events value merely sum separate probabilities 
assume abstraction cycles grammar 
sequence productions cycle existed recursive calculation halt 
assumption necessary termination standard parsing algorithm 
assumption restrict classes grammars algorithms applicable restrictive domains interpret productions specializations cycles render abstraction hierarchy impossible 
decomposition productions possible 
decomposition production em need probability expanded derives subsequence appropriate length 
computed values function 
consider possible subsequence length jt addition appear level abstraction kt consider possible values subsequence length 
obtain joint probability combination ues computing val derivation independent 
sum joint probabilities possible jt kt yields probability expansion specified production right hand side 
product resulting probability yields probability particular expansion events independent 
sum relevant decomposition productions find value 
algorithm fig 
takes advantage division abstraction decomposition productions compute values strings bounded length 
array kmax keeps track depth abstraction hierarchy subsequence length 
example calculations illustrate computation values consider result charniak grammar fig 
input 
initialize entries probability terminal symbol fig 

fill entries look abstraction productions 
symbols noun verb prep pynadath wellman generalized queries probabilistic context free grammars fig 

algorithm computing values 
fig 

final table sample grammar 
np np np np vp vp vp vp prep pp pp pp noun verb swat flies ants expanded terminal symbols nonzero values 
enter nonterminals values equal sum relevant abstraction productions product probability production value righthand symbol 
instance compute value noun adding product probability noun swat value swat noun flies flies noun ants ants 
yields value noun derive string length single level abstraction terminal string grammar 
abstraction phase continues find abstractions go decomposition phase 
illustrate decomposition phase consider value 
possible decomposition production np vp 
consider separate cases noun phrase covers symbols verb phrase noun phrase covers verb phrase 
subsequence length np vp nonzero probability bottom level abstraction length third 
compute probability subsequence length combination multiply probability production np vp 
probability second combination similar product sum values provides value enter abstractions decompositions proceed similar lines additional summation required multiple productions multiple levels abstraction possible 
final table shown fig 
lists nonzero values 
complexity analysis complexity computing values pcfg useful define maximum length possible chains abstraction productions maximum value maximum ieee transactions pattern analysis machine intelligence vol 
january fig 

procedure generating network 
fig 

procedure finding possible abstraction productions 
production length number symbols right hand side 
single run abstraction phase requires time subsequence length runs 
specific value decomposition phase requires time decomposition production consider possible combinations subsequence lengths levels abstractions symbol right hand side 
algorithm take time 
network generation phase function calculated described compute domains random variables ijk ijk required conditional probabilities 
specification random variables procedure create network described fig 
begins top abstraction hierarchy strings length starting position 
root symbol variable kmax start symbol indicating parse tree begins nil indicating parse tree begins 
allow parse tree start possibly derive strings length bounded language 
create network proceeds downward ijk random variables specifies domain corresponding production variables ijk 
production variable takes values set possible expansions possible nonterminal symbols domain ijk 
abstraction productions possible procedure abstraction phase described fig 
inserts possible expansions draws links ijk random variable ij takes value righthand side symbol 
procedure decomposition phase described fig 
performs analogous task fig 

procedure finding possible decomposition productions 
fig 

procedure handling start parse tree level 
fig 

procedure computing probability start tree occurring particular string length abstraction level 
decomposition productions consider possible length breakdowns abstraction levels symbols right hand side 
create network calls procedure start tree described fig 
handle possible expansions nil nil indicating tree starts immediately nil nil indicating tree starts 
start tree uses procedure start prob described fig 
determine probability parse tree starting current point expansion 
insert possible value domain production node add parent nodes corresponding symbol right hand side 
insert symbol right hand side domain corresponding symbol variable 
algorithm descriptions assume existence procedures insert state add parent 
procedure insert state node label inserts new state name label domain variable node 
procedure add parent child parent draws link node parent node child 
pynadath wellman generalized queries probabilistic context free grammars specification conditional probability table create network specified domains random variables specify conditional probability tables 
introduce lexicographic order set kmax 
purposes simplicity specify exact value probability pr specify weight pr compute exact probabilities normalization divide weight sum ta prior probability table top node parents defined follows pr kmax kmax pr kmax nil kmax 
state domain ijk node represents production corresponding assignment values symbols right hand side form define conditional probability state ijk ijk pr rn symbol domain ijk pr ijk ijk 
productions starting delaying tree probabilities pr jk nil ijk nil pr jk nil nil ijk nil 
probability tables ijk nodes simpler productions specified symbols completely determined 
entries zero 
example consider nodes ijk parent node 
rule representing em jm km pr ijk pi jt 
symbols domain nijk conditional probability zero 
fill entry configurations parent nodes represented ellipsis condition part probability know conflict ing configurations productions trying specify symbol nijk impossible 
configura tion parent nodes specify certain symbol indicates nijk node takes value nil probability 
network generation example illustration consider execution algorithm values fig 

start root variable 
start symbol value greater zero points domain include nil obtain pr simply divide sum values yielding 
domain partially specified abstraction phase symbol domain 
relevant production vp possible expansion vp 
insert production domain conditional probability possible expansions 
draw link domain includes vp conditional probability vp 
complete specification consider possible start tree domain includes nil conditional probability nil ratio sum 
link abstraction phase insert nil domain conditional probability appropriate value 
proceed bottom level abstraction perform decomposition phase 
production np vp possible combinations subsequence lengths add total length 
np derives string length vp string length possible levels abstraction respectively zero values 
insert production np vp domain numbers brackets correspond subsequence length level abstraction respectively 
conditional probability value product probability production np vp normalized probabilities possible expansions 
draw links domains insert np vp respectively 
values obtained noting subsequence np begins point original string vp begins point shifted length subsequence np 
occurs probability value appropriate production 
similar actions taken possible subsequence length combinations 
operations random variables performed similar fashion leading network structure shown fig 

complexity network generation resulting network nodes 
domain ni variable states represent possible terminal symbols nijk variables possible states 
variables 
variables domain pa states 
pij variables states possible decomposition production possible combination subsequence lengths possible level abstraction symbols right hand side 
pij variables domain states defined maximum value maximum production length 
ieee transactions pattern analysis machine intelligence vol 
january fig 

network example grammar maximum length 
unfortunately particular variable corresponding variable parent variable potentially variables parents 
size conditional probability table node exponential number parents determined interactions possible specify table linear number parameters 
define maximum number entries conditional probability table network abstraction phase algorithm requires time decomposition phase requires time 
handling start parse tree potential space holders requires time 
total time complexity algorithm ndt dt dwarfs time complexity dynamic programming algorithm function 
network created particular grammar length bound 
pcfg queries bayesian network compute joint probability express terms random variables included network 
standard bayesian network algorithms return joint probabilities form pr ijk conditional probabilities form pr ijk obviously interested symbol appeared particular location parse tree need examine marginal probability distribution corresponding variable 
single network query yield probability pr nijk 
results network query implicitly conditional event length terminal string exceed obtain joint probability multiplying result probability string language length exceeding probability expand start symbol terminal kmax string length sum obtain appropriate unconditional probability query network queries reported kmax section multiplied 
probability conjunctive events bayesian network supports computation joint probabilities analogous computed standard pcfg algorithms 
instance probability particular terminal string swat flies ants corresponds probability pr swat flies ants 
probability initial subsequence swat flies computed lri algorithm corresponds probability pr swat 
bayesian network represents distribution strings bounded length find initial subsequence probabilities completions length bounded case bayesian network approach requires modification answer query standard pcfg algorithm needs modification handle complex types evidence 
chart parsing lri algorithms require complete sequences input pynadath wellman generalized queries probabilistic context free grammars gaps uncertainty particular symbols require direct modification dynamic programming algorithms compute desired probabilities 
bayesian network hand supports computation probability evidence regardless structure 
instance sentence swat flies ants know third word single network query provide conditional probability possible completions pr swat flies ants probability specified evidence pr swat flies ants 
approach handle multiple gaps partial information 
example know exact identity third word sentence swat flies ants know swat bayesian network fully exploit partial information augmenting query specify domain values swat zero probability 
types queries rare natural language domains speech recognition require ability reason noisy observations 
answer queries nonterminal symbols 
instance sentence swat flies ants query network obtain conditional probability ants prepositional phrase pr pp swat flies ants 
answer queries specify evidence nonterminals parse tree 
instance know ants prepositional phrase input network query specify pp specifying terminal symbols 
alternate network algorithms compute probable state random variables evidence conditional probability 
example consider case possible word sentences phrase swat flies 
probability maximization network algorithms determine probable state terminal symbol variables flies swat flies nil 
probability disjunctive events compute probability disjunctive events multiple network queries 
express event union mutually exclusive events form query network compute probability sum results obtain probability union 
instance want compute probability sentence swat flies ants contains prepositions query network probabilities pr ni prep swat ants 
domain plan recognition query correspond probability agent performed complex action specified time span 
example individual events mutually exclusive sum results produce probability 
general ensure mutual ity individual events computing conditional probability conjunction original query event negation events summed previously 
example probability pr prep pr prep prep pr prep prep prep pr prep prep prep prep corresponds event sentence swat flies ants 
bayesian network provides unified framework supports computation probabilities described 
compute probability event set mutually exclusive events jt kt itm tmt tmt mtc compute probabilities events specify relative likelihoods strict subset restrictions 
addition event determine probable configuration uninstantiated random variables 
designing new algorithm query express query terms network random variables bayesian network algorithm compute desired result 
complexity network queries unfortunately time required standard network algorithms answering queries potentially exponential maximum string length exact complexity depend connectedness network particular network algorithm chosen 
algorithm current implementation uses great deal preprocessing compiling networks hope reducing complexity answering queries 
algorithm exploit regularities networks conditional probability tables ijk consist zeroes ones provide reasonable response time answering queries 
unfortunately compilation prohibitive produce networks exponential size 
exist bayesian network algorithms offer greater flexibility compilation possibly allowing limit size resulting networks providing acceptable query response times 
determining optimal tradeoff require research determining class domains bayesian network approach preferable existing pcfg algorithms 
clear standard dynamic programming algorithms efficient pcfg queries address 
domains requiring general queries types described flexibility bayesian network approach may justify greater complexity 
context sensitivity domains independence assumptions pcfg model overly restrictive 
definition probability applying particular pcfg production expand nonterminal independent symbols come expansions occur 
simplified example illustrates weaknesses assumption 
consider intermediate string swat ants noun 
implausible ieee transactions pattern analysis machine intelligence vol 
january probability expand noun flies ants independent choice swat verb choice ants object 
course may able correct model expanding set nonterminals encode contextual information adding productions expansion preserving structure pcfg model 
obviously lead unsatisfactory increase complexity design model 
alternate model relaxes pcfg independence assumptions 
model need complex production probability structure allow complete specification distribution modified inference algorithms manipulating distribution 
direct extensions network structure bayesian network representation probability distribution provides basis exploring context sensitivities 
networks generated algorithms implicitly encode pcfg assumptions assignment single nonterminal node parent production node 
single link indicates expansion conditionally independent nodes know value nonterminal 
extend context sensitivity expansions network formalism altering links associated production nodes 
introduce context sensitivity adding links 
production node conditional probability table define production probabilities function index values 
instance number words group strongly influences likelihood group forming noun phrase 
model belief varying probability np appearing different string lengths encoded index 
cases modify standard pcfg representation probability information associated production function constant 
dynamic programming algorithm fig 
easily modified handle production probabilities depend dependency index require adding parameter introducing additional loop possible values 
replace production probability dynamic programming network generation algorithm appropriate function alternatively may introduce additional dependencies nodes network 
pcfg extension conditions production probabilities parent left hand side symbol proved useful modeling natural language 
case production set associated probabilities nonterminal symbol possible parent symbol lefthand side 
new probability structure requires modifications dynamic programming network generation algorithms 
extend probability information function include parent nonterminal additional parameter 
straightforward fig 

subnetwork incorporating parent symbol dependency 
alter dynamic programming algorithm fig 
correctly compute probabilities bottom fashion 
modifications network generation algorithm complicated 
add parent symbol node add ijk ijk parent example dotted arrow subnetwork ijk fig 
represents additional dependency 
add link possible child nonterminal indicated link 
conditional probability tables node specify probabilities current nonterminal parent nonterminal symbols 
compute combining modified values conditional production probabilities 
returning example section may want condition production probabilities terminal string expanded far 
approximation context sensitivity imagine model production associated set probabilities terminal symbol language 
represents conditional probability particular expansion corresponding terminal symbol occurs immediately previous subsequence derived nonterminal symbol left hand side 
function requires additional parameter need modified version dynamic programming algorithm compute values 
network generation algorithm needs introduce additional link ni jk node 
dashed arrows subnetwork fig 
reflect additional dependencies introduced context sensitivity network example fig 

jk nodes special case preceding terminal steps original algorithm sufficient 
extend conditioning cover preceding terminal sequences individual symbols 
production associated set probabilities possible terminal sequence length bounded parameter function requires additional parameter specifying preceding sequence 
network generation algorithms add links nodes conditional probability tables specify probability particular expansion symbol left hand side preceding terminal sequence 
pynadath wellman generalized queries probabilistic context free grammars fig 

subnetwork capturing dependency previous terminal symbol 
cases may wish account external influences explicit context representation natural language problems influences current world state planning required plan recognition problems 
instance processing multiple sentences may want draw links symbol nodes sentence production nodes reflect thematic connections 
long network include random variables represent external context represent dependency adding links corresponding nodes appropriate production nodes altering conditional probability tables reflect effect context 
general bayesian networks currently generated contain set random variables sufficient expressing arbitrary parse tree events introduce context sensitivity adding appropriate links production nodes events wish condition expansion probabilities 
correct network query algorithms section produce corresponding conditional probability 
extensions grammar model context sensitivities expressed incremental changes network dependency structure represent minor relaxation conditional independence assumptions pcfg model 
global models context sensitivity require radically different grammatical form probabilistic interpretation framework 
history grammar provides rich model context sensitivity conditioning production probabilities potentially entire parse tree available current expansion point 
bayesian networks represent positions parse tree theoretically possible represent conditional probabilities introducing appropriate links 
model uses de cision tree methods identify equivalence classes partial trees produce simple event structures condition unclear exactly replicate behavior systematic generation algorithm 
restrict types context sensitivity find network generation algorithm 
case context sensitive grammars provide structured model general unrestricted grammar allowing productions form aa ba arbitrary sequences terminal nonterminal symbols 
restriction eliminates productions right hand side shorter left hand side 
production indicates expanded appears surrounding context immediately precedent immediately subsequent 
extension probabilistic context sensitive grammar similar pcfgs provide richer model types conditional probabilities briefly explored 
intuitive extension involves associating likelihood weighting context sensitive production computing probability particular derivation weights 
weights correspond probabilities know priori expansions may applicable point parse due different possible contexts 
set fixed production values may produce weights sum particular context 
weights determine probabilities know productions applicable 
probability particular derivation sequence uniquely determined sensitive order apply productions 
define probability distribution strings context sensitive language probability particular string sum probabilities possible derivation sequences string 
ieee transactions pattern analysis machine intelligence vol 
january definition appears theoretically sound unclear real world domains exist model useful 
create model able generate bayesian network proper conditional dependency structure represent distribution 
draw links production node potential context nodes conditional probability tables reflect production weights particular context possibility 
open question create systematic generation algorithm similar defined pcfgs 
proposed model account dependence position parent symbol described earlier section similar extensions account types dependencies 
result similar context sensitive probabilities pearl 
pearl conditions probabilities part ofspeech trigram sibling parent nonterminal symbols 
allow model specify conjunctions contexts may able represent types probabilities general contexts siblings trigrams 
clearly difficult select model powerful encompass significant set useful dependencies restricted allow easy specification productions probabilities particular language 
chosen grammatical formalism capable representing context sensitivities wish model define network generation algorithm correctly specify conditional probabilities production node 
network query algorithms section 
unified framework performing inference regardless form language model generate networks 
probabilistic parse tables stochastic programs provide alternate frameworks introducing context sensitivity 
approach uses finite state machine chart parser underlying structure introduces context sensitivity transition probabilities 
stochastic programs represent general stochastic processes including pcfgs ability maintain arbitrary state information support general context sensitivity 
unclear approaches advantages generality efficiency 
algorithms automatically generate bayesian network representing distribution parses strings bounded length parameter language pcfg 
stage uses dynamic programming approach similar standard parsing algorithms second stage generates network results stage specify probabilities 
network generated particular pcfg length bound 
created network answer variety queries possible strings parse trees 
standard bayesian network inference algorithms compute conditional probability probable configuration collection basic random variables event expressed terms variables 
algorithms implemented tested grammars results verified existing dynamic programming algorithms applicable enumeration algorithms nonstandard queries 
answering standard queries time requirements network inference comparable dynamic programming techniques 
network inference methods achieved similar response times types queries providing vast improvement slower brute force algorithms 
current implementation memory requirements network compilation limit complexity grammars queries unclear results hold larger grammars string lengths 
preliminary investigation demonstrated usefulness network formalism exploring various forms context sensitive extensions pcfg model 
relatively minor modifications pcfg algorithms generate networks capable representing general dependency structures required certain context sensitivities sacrificing class queries answer 
research need provide general model context sensitivity sufficient structure support corresponding network generation algorithm 
answering queries bayesian networks exponential worst case method incurs cost service greatly increased generality 
hope enhanced scope pcfgs useful model plan recognition domains require flexibility query forms probabilistic structure 
addition algorithms may extend usefulness pcfgs natural language processing pattern recognition domains successful 
acknowledgments grateful anonymous reviewers careful reading helpful suggestions 
supported part air force office scientific research 
gonzalez thomason syntactic pattern recognition 
reading mass addison wesley 
charniak statistical language learning 
cambridge mass mit press 
probabilistic languages review open questions computing surveys vol 
pp 

chou recognition equations dimensional stochastic context free grammar proc 
spie visual communications image processing iv int soc 
optical eng pp 
bellingham wash 
ney stochastic grammars pattern recognition speech recognition understanding eds pp 

berlin springer 
sakakibara brown underwood mian haussler stochastic context free grammars modeling rna proc 
th hawaii int conf 
system sciences pp 

pynadath wellman generalized queries probabilistic context free grammars vilain getting serious parsing plans grammatical analysis plan recognition proc 
eighth nat conf 
artificial intelligence pp 

briscoe carroll generalized probabilistic lr parsing natural language corpora unification grammars computational linguistics vol 
pp 
mar 
hopcroft ullman automata theory languages computation 
reading mass addison wesley 
jelinek lafferty mercer basic methods probabilistic context free grammars speech recognition understanding eds pp 

berlin springer 
pearl probabilistic reasoning intelligent systems networks plausible inference 
san mateo calif morgan kaufmann 
neapolitan probabilistic reasoning expert systems theory algorithms 
new york john wiley sons 
jensen bayesian networks 
new york springer 
dechter bucket elimination unifying framework probabilistic inference proc 
th conf 
uncertainty artificial intelligence pp 
san francisco 
charniak shimony cost abduction map explanation artificial intelligence vol 
pp 

dechter topological parameters time space tradeoff proc 
th conf 
uncertainty artificial intelligence pp 
san francisco 
darwiche provan query dags practical paradigm implementing belief network inference artificial intelligence research vol 
pp 

charniak carroll context sensitive statistics improved grammatical language models proc 
th nat conf 
artificial intelligence pp 
menlo park calif 
pynadath wellman accounting context plan recognition application traffic monitoring proc 
th conf 
uncertainty artificial intelligence pp 
san francisco 
black jelinek lafferty magerman mercer roukos history grammars richer models probabilistic parsing proc 
fifth darpa speech natural language workshop marcus ed pp 
feb 
magerman marcus pearl probabilistic chart parser proc 
second int workshop parsing technologies pp 

koller mcallester pfeffer effective bayesian inference stochastic programs proc 
th nat conf 
artificial intelligence pp 
menlo park calif 
david pynadath received bs degrees electrical engineering computer science massachusetts institute technology 
received ms degree computer science university michigan 
currently doctoral student computer science university michigan 
current research involves probabilistic grammars bayesian networks plan recognition 
michael wellman received phd computer science massachusetts institute technology qualitative probabilistic reasoning decision theoretic planning 
dr wellman conducted research areas usaf wright laboratory 
currently associate professor department electrical engineering computer science university michigan 
current research includes investigation computational market mechanisms distributed decision making 
received national science foundation national young investigator award 
