eurospeech geneva unlimited vocabulary speech recognition morphs discovered unsupervised manner ki mathias creutz neural networks research centre helsinki university technology hut fi hut fi mathias creutz hut fi hut fi study continuous speech recognition sub word units unsupervised fashion 
agglutinative languages finnish traditional word gram language modeling due huge number different word forms 
method minimum description length principle split words statistically subword units allowing efficient language modeling unlimited vocabulary 
perplexity speech recognition experiments finnish speech data show resulting model outperforms word syllable trigram models 
compared word trigram model vocabulary rate reduced word error rate 

word gram models common statistical language models speech recognition today 
languages simple morphology english coverage reasonably sized vocabulary sufficient general recognition 
agglutinative languages finnish vocabulary containing frequent word forms typically excludes considerable part words test sets 
difference explained properties languages 
english compound words usually written apart syntactic role meaning main word modified short words prepositions articles 
finnish number distinct word forms higher compound words written lengthy sequences suffixes indicating case number person appended word stem 
example word isi mme translated really know order increase effective coverage vocabulary lexicon containing smaller units entire words constructed 
ideally word form obtained concatenation suitable sub word units 
challenging find set units language model created 
morphological rules produce subword units 
rules language dependent prior assumptions stems suffixes 
additional methods tested 
methods coverage subword units maximized lexicon size 
common word forms taken basis rest words generated combination common words sub word units 
utilize entirely unsupervised algorithm discovers sub word units text corpus 
algorithm language independent simply assumes words consist sequences segments 
distinction different categories segments stems prefixes suffixes 
call segments morphs resemble actual morphemes language 
optimal set morphs obtained optimizing cost criterion derived minimum description length mdl principle 
experiments show morphs language models yielding practically unlimited vocabulary 
speech recognition experiments confirm considerable drop word error rates compared language models words syllables 

language modeling traditionally lexicons speech recognition contain frequent words lexical units language model assign probabilities word sequences 
approach build lexicon shorter units allow language model concatenate units generating larger possibly infinite vocabulary 
compare lexicons different lexical units words syllables morphs unsupervised splitting algorithm 
general term token lexical units word morph syllable applicable 
languages pronunciation word phoneme sequence roughly derived written form 
case finnish letter corresponds phoneme 
distinction short long sounds spelled double letters fire wind 
treat long short sounds separate phonemes allow token boundary middle phoneme 
large lexicons speech recognition process time memory consuming restricted size lexicons approximately tokens 

words words lexical units straightforward 
frequent word forms selected training corpus put lexicon 
due practical size limit lexicon word lexicon cover finnish language 

syllables segmentation finnish words syllables possible reasonably simple ruleset 
syllable lexicon gen eurospeech geneva erate practically words finnish origin misses foreign names 

morphs morphemes smallest meaning bearing elements language 
word form constructed combination morphemes morphemes appropriate lexical units huge vocabulary speech recognition 
unsupervised algorithm discovers segments bear resemblance actual morphemes language 
call segments morphs 
algorithm originally recursive mdl method 

mdl model algorithm learns set morphs text corpus training data 
task rewrite words corpus sequences morphs 
morph discovered added morph lexicon 
optimal segmentation corpus morphs representation segmented corpus representation morph lexicon compact possible 
corresponds mdl minimum description length principle 
optimization criterion written part cost function cost corpus cost lexicon log mi mj 
occurrences morphs cost corpus sum morph occurrences corpus 
idea corpus rewritten sequence morphs mi morph replaced morph pointer 
cost code length bits pointer determined probability morph mi computed maximum likelihood estimate morph corpus 
frequent morphs receive short pointers rare morphs receive long pointers 
length pointer bits obtained negative base logarithm probability log mi 
cost lexicon consists code length distinct morphs mj spelled 
takes mj bits code morph mj length phonemes morph 
number bits required code phoneme inthis value set log different phonemes selected uniform code length phoneme 
alternatively fact different phonemes different probabilities taken account 
tried model improve performance 

search optimal model finding set morphs minimizes cost function particular corpus non trivial task 
recursive segmentation algorithm exception search take place incrementally batch mode 
words corpus shuffled word possible split parts tested 
split location split yielding lowest cost selected case split parts recursively split 
corpus online demo available internet www cis hut fi projects morpho 
note long short sounds treated separate phonemes explains high number 
iteratively total cost model converges 
illustrates hypothetical recursive splitting english words 
reopen ed open minded re open mind ed re open mind ed hypothetical binary splitting trees words segmented re open ed open mind ed 
leaf nodes trees correspond morphs discovered algorithm 

lexicon pruning number distinct word forms finnish corpus high number morphs discovered algorithm turns exceeds limit 
prune morph lexicon contain common morphs corpus morphs 
means rare word forms may split small segments 
pruned morph lexicon contains token individual phoneme worst case word sequence phonemes 
vocabulary rate remains regardless pruning lexicon 

construction language models lexicons trigram language model generated lexical units 
cmu language modeling toolkit turing smoothing back lower order grams 
word lexicon contains words word break assumed token 
syllables morphs word break modeled explicitly 
added separate word break token syllable morph lexicons treated normal token language model training 

acoustics 
speech recognition system acoustic part recognizer traditional hidden markov model gaussian mixture models 
mixture centers initially placed self organizing maps initial model refined viterbi training 
triphone models trained simple back scheme sufficient data training triphone model trained 
diphone model 
data insufficient monophone model trained 
elaborate ways clustering triphones studied focus language modeling 
decoder take cross token phoneme contexts account triphone models truncated word morph syllable boundaries 
corresponding taken account training triphones 
ignoring results significantly worse performance 
finnish difference long short variant phoneme mainly expressed duration 
current acoustic model treats variants language model decide variant 
eurospeech geneva manage get reasonably recognition results phenomenon needs carefully modeled 

decoder pass decoder time synchronous search start synchronous trees terminology 
main idea group hypotheses frame store frame wise stacks 
benefits approach single token expansion shared hypotheses frame complex language models quite easily 
hypotheses stack may different phonological language model contexts hard exploit cross token triphones language model probabilities acoustic search 
illustrates decoding process 
step decoder selects earliest frame stack containing hypotheses 
acoustically promising tokens starting corresponding frame times viterbi search 
hypothesis stack expanded best tokens placed appropriate stacks best times search window 
point language model probabilities included 
see word breaks handled morphs syllables 
hypothesis placed stack decoder creates copy appends word break token 
word breaks scored language model explicit silence tokens 
continuous speech seldom clear acoustic information word breaks 
simplicity shows time token practice promising times token hypotheses created accordingly 
find minded open open open find open minded open find open minded time decoder expands hypotheses acoustically best tokens places appropriate stacks 
word breaks marked 

text speech data 
experiments text data training morph segmentation trigram language models sources short newswires finnish news agency stt books magazines newspapers finnish center science csc 
total data contained words distinct word forms 
speech data training acoustic models independent text data 
talking book read female speaker corresponding transcription 
hours book training acoustic models minutes tuning decoder parameters minutes testing 
hypotheses token sequences time cumulative log probability 
lexical number oov trigram token word unit units words hits 

word syllable morph table perplexity results 
oov vocabulary words 
trigram hits shows proportion test set trigrams model 
word break token common syllable morph models get low token perplexities 

perplexity perplexity measures language model fits test data 
trigram word model defined perp ww wi wi wi token perplexity syllable morph models calculated substituting words tokens summing number tokens number words word syllable morph models operate completely different token sets measures comparable 
perplexity results comparable computed word perplexity morph syllable models 
defined perp tn ti ti ti number word break symbols sequence tokens tn 
measure comparable models 
perplexity tests run transcription acoustic training data words results shown table 
results indicate morph syllable models cover test set far better word model give reasonable perplexities generate infinite number distinct word forms 
perplexities may sound high compared usual perplexities reported english text stress typical finnish word corresponds english word naturally perplexities higher 
example assumed finnish word correspond english words average word perplexity morph model computed double number words result square root original perplexity 
word model get lower perplexity models comparison fair 
high oov rate word model fifth word ignored perplexity computation 
words rarest ones account increase perplexity significantly 

speech recognition speech recognition experiments run trigram language models baseline word model eurospeech geneva lexical unit wer ler word syllable morph table speech recognition results trigram models 
syllable model morph model 
results comparable development data tune decoder parameters real time factor decoding process model 
setting real time factor equal test runs way comparisons fair different models required quite different pruning parameters best performance 
note system developed easy prototyping efficient memory real time recognition 
evaluation data divided segments order measure statistical significance results error rates computed segment traditional word error rate wer token error rate sub word units letter error rate ler 
finnish word corresponds english word average comparing word error rates languages fair 
morph error rate finnish closer word error rate english direct comparison impossible 
letter error rates may describe best quality recognition result result corrected manually proper error measure naturally depends application hand 
phoneme error rates papers depend highly size phonetic alphabet discussed 
results experiments shown table 
pairwise differences models statistically significant 

discussion results show morph model outperforms models margin 
remarkable noted decoder handle cross unit contexts word tokens longer exploit phonological contexts 
hand argued comparison fair word model rate start 
order reduce vocabulary rate significantly vocabulary size increased orders magnitude decoding computationally infeasible 
benefit word splitting probably greatest languages finnish hungarian turkish rich morphology 
approach applicable inflected languages czech german french english 
interesting compare morphs true linguistic morphemes 
unfortunately exist morpheme lexicons finnish software segmenting words morphemes 
intend explore higher order grams models 
trigram word model covers words trigram syllable model rarely covers word 
addition morph syllable models need back quite infrequently see table indicates higher order ngrams improve performance 
clustering similar syllables morphs improve language model 
sure language models units different size compared fairly cross token acoustic contexts implemented decoder 

due high number distinct word forms finnish traditional word pronunciation lexicons language models finnish speech recognition 
applied data driven unsupervised mdl method split words smaller units called morphs 
resulting morphs able generate word forms attaining reasonable perplexity results 
speaker dependent speech recognition experiments encouraging 
word error rate obtained morphs significantly lower word error rates syllables words 

finnish federation visually impaired departments phonetics general linguistics university helsinki providing speech data 
finnish news agency stt finnish center science csc text data 
research partly funded finnish national technology agency part project 

speech recognition huge vocabularies optimized sub word units proceedings eurospeech 
byrne jelinek khudanpur large vocabulary continuous speech recognition highly inflectional language czech proceedings eurospeech aalborg denmark pp 

fang morphological analysis continuous speech recognition computer speech language vol 

creutz lagus unsupervised discovery morphemes proceedings workshop morphological phonological learning acl pp 

rissanen stochastic complexity statistical inquiry world scientific series computer science vol 

clarkson rosenfeld statistical language modeling cmu cambridge toolkit proceedings eurospeech 
self organizing maps learning vector quantization mixture density hidden markov models ph dissertation helsinki university technology 
aubert overview decoding techniques large vocabulary continuous speech recognition computer speech language vol 
pp 
jan 
goodman bit progress language modeling computer speech language october 
