information retrieval kluwer academic publishers 
manufactured netherlands 
evaluation statistical approaches text categorization yiming yang yiming cs cmu edu school computer science carnegie mellon university pittsburgh pa usa received october revised may accepted july 
focuses comparative evaluation wide range text categorization methods including previously published results reuters corpus new results additional experiments 
controlled study classifiers knn llsf word conducted examine impact configuration variations versions reuters observed performance classifiers 
analysis empirical evidence suggest evaluation results versions reuters significantly affected inclusion large portion unlabelled documents results difficult interpret leading considerable confusions literature 
results evaluated versions reuters exclude unlabelled documents performance twelve methods compared directly indirectly 
indirect knn llsf word baselines evaluated versions reuters exclude unlabelled documents 
global observation knn llsf neural network method best performance naive bayes approach learning algorithms performed relatively 
keywords text categorization statistical learning algorithms comparative study evaluation 
text categorization tc problem assigning predefined categories free text documents 
growing number statistical learning methods applied problem years including regression models fuhr yang chute nearest neighbor classifiers yang bayesian probabilistic classifiers tzeras hartman lewis ringuette moulinier decision trees fuhr lewis ringuette moulinier inductive rule learning algorithms apte cohen singer moulinier neural networks wiener ng line learning approaches cohen singer lewis :10.1.1.54.6608:10.1.1.39.6139
methods available cross method evaluation increasingly important identify state art text categorization 
unified methodology empirical evaluations objective comparisons different methods difficult 
ideally researchers common collection comparable performance measures evaluate systems allow systems evaluated carefully controlled conditions fashion similar text retrieval conference research supported part nih lm nsf iri 
yang trec 
reality far ideal 
cross method comparisons attempted literature methods 
small scale comparisons lead overly general statements insufficient observations provide little insight global comparison wide range approaches 
alternative small scale comparisons integrate available results categorization methods global evaluation carefully analyzing test conditions evaluation measures establishing common basis cross collection cross experiment integration 
solution lead trec controlled evaluation text categorization contribute useful insights individual studies 
effort direction 
serious problem tc evaluations lack standard data collections 
common collection chosen ways introduce inconsistent variations 
commonly reuters news story corpus example different versions depending training test sets divided subsets categories documents evaluation forth 
number different configurations corpus growing 
unclear reported results different versions reuters comparable 
examine impact corpus configuration variations performance classifiers carefully controlled experiments categorization systems different versions reuters 
shown section variations certain versions reuters strong impact variations versions 
underlying reason analyzed 
important issue cross experiment evaluation comparability different performance measures individual experiments 
measures including recall precision accuracy error break point measure micro average macro average binary categorization point average precision category ranking forth see section definitions 
measures designed evaluate aspect categorization performance system convey identical information 
measures suitable text categorization 
published results text categorization methods best compared evaluated different performance measures 
questions addressed applying variety performance measures classifiers including measures category ranking evaluation measures binary category assignment 
show types measures informative complementary 
show carefully chosen performance measures baseline classifier reasonably indirectly compare relevant performance classifiers experiments relevant performance respect baseline classifier 
divided sections addition 
section describes classifiers reuters corpus 
section introduces analyzes performance measures category ranking evaluation binary categorization evaluation 
section describes novel experiments conducted word knn llsf 
section reports results classifiers evaluate published results classifiers 
summarize section 
evaluation statistical approaches 
classifiers evaluated reuters 
classifiers consider text categorization systems results various versions reuters corpus published literature hayes weinstein lewis ringuette apte wiener moulinier cohen singer yang pedersen ng :10.1.1.54.6608:10.1.1.39.6139
addition results new results systems 
systems briefly described grouped roughly theoretical foundations technical characteristics 

construe expert system developed carnegie group earliest system evaluated reuters corpus hayes weinstein 
impressive results recall precision average reported small subset corpus 
major difference construe approach methods considered manually developed domainspecific application specific rules expert system 
adapting construe application domains costly labor intensive 

decision tree dtree known machine learning approach automatic induction classification trees training data quinlan mitchell 
applied text categorization dtree algorithms select informative words information gain criterion predict categories document occurrence word combinations document 
evaluation result dtree algorithms reuters text categorization collection reported lewis ringuette ind package lewis ringuette moulinier moulinier respectively 

naive bayes naivebayes probabilistic classifiers commonly text categorization mitchell 
basic idea joint probabilities words categories estimate probabilities categories document 
naive part model assumption word independence 
simplicity assumption computation naivebayes classifier far efficient exponential complexity non naive bayes approaches word combinations predictors 
evaluation results naivebayes reuters reported lewis ringuette moulinier respectively 

inductive rule learning disjunctive normal form dnf tested wasp ripper charade systems apte moulinier cohen singer :10.1.1.39.6139
dnf rules equal power machine learning theory mitchell 
empirical results comparison dnf dtree approaches rarely available text categorization indirect comparison apte 


neural network nnet approaches text categorization evaluated reuters wiener 
ng 
respectively 
convenience system developed xerox parc referred nnet parc system named classi 
systems separate neural network category yang learning non linear mapping input words complex features singular vectors document space category 
parc group tried perceptron approach layered neural networks addition 
results layered neural networks available subset reuters categories common evaluations systems 
classi system uses perceptrons 

rocchio classic vector space model method document routing filtering information retrieval 
applying text categorization basic idea construct prototype vector category training set documents 
category vectors documents belonging category positive weight vectors remaining documents negative weight 
summing positively negatively weighted vectors prototype vector category obtained 
method easy implement efficient computation baseline evaluations lewis cohen singer 
potential weakness method assumption centroid category consequently rocchio perform documents belonging category naturally form separate clusters 

llsf stands linear squares fit mapping approach developed yang yang chute 
multivariate regression model automatically learned training set documents categories 
training data represented form input output vector pairs input vector document conventional vector space model consisting words weights output vector consists categories binary weights corresponding document 
solving linear squares fit training pairs vectors obtain matrix word category regression coefficients 
matrix defines mapping arbitrary document vector weighted categories 
sorting category weights ranked list categories obtained input document 

sleeping experts experts line learning algorithms applied text categorization cohen singer 
line learning aims reduce computation complexity training phase large applications 
experts updates weights gram phrases incrementally 

knn stands nearest neighbor classification 
arbitrary input document system ranks nearest neighbors training documents uses categories top ranking neighbors predict categories input document 
similarity score neighbor document new document classified weight categories sum category weights nearest neighbors category ranking 

word simple non learning algorithm ranks categories document word matching document category names 
purpose testing simple method quantitatively measure improvement obtained statistical learning compared non learning approach 
conventional vector space model representing documents category names name treated bag words smart system salton search engine 
evaluation statistical approaches classifiers divided types independent binary classifiers ary classifiers 
document independent binary classifier decision category independently decisions categories 
classifiers listed construe dtree naivebayes dnf nnet parc classi rocchio experts independent binary classifiers 
ary classifier hand typically uses shared classifier categories producing ranked list candidate categories test document confidence score candidate category binary decisions obtained desired thresholding ranks scores candidate categories 
classifiers listed knn llsf word primarily ary classifiers 
algorithmic solutions converting ary classification output binary decisions described section 
possible principle independent binary classifiers produce category ranking binary decisions confidence scores confidence scores meaningfully compared category ranking 
effectively combine output binary classifiers understood stage research 

reuters corpus reuters collection cross method comparisons commonly collection text categorization evaluation literature 
reuters corpus consists reuters newswire stories period 
original corpus reuters provided carnegie group 
cgi evaluate construe system hayes weinstein 
versions derived corpus varying documents corpus division training test set categories evaluation 
table summarizes versions 
reuters version called reuters prepared lewis lewis ringuette contains documents original corpus version test documents 
documents split chronologically contiguous chunks early training testing 
subset categories chosen evaluation 
peculiarity reuters inclusion large portion unlabeled documents training test test sets 
observed author randomly test documents cases documents belong table 
examination knn llsf word different versions reuters 
version prepared labelled version cgi version lewis version yang version apte version parc yang categories happen unlabelled 
known exactly unlabeled documents labelled category 
facilitate evaluation impact unlabeled documents text categorization evaluation created new corpus reuters called reuters 
reuters reuters unlabeled documents removed 
reuters version constructed apte evaluation swap removing unlabeled documents training test sets restricting categories training set frequency apte :10.1.1.39.6139
reuters version constructed research group xerox parc evaluation neural network approaches wiener :10.1.1.54.6608
version drawn reuters version eliminating unlabeled documents rare categories 
continuous chunks documents training testing slices collection small chunks overlap temporally 
subsets numbered odd numbered chunks training subsets testing 

evaluation measures discussed section classifiers category ranking automated category assignments 
type output preferable depends applications 
user interaction category ranking system useful fully automated categorization tasks type fine 
assuming particular application mind ranking performance binary classification performance informative evaluating classifiers 
evaluate performance knn llsf word types usage binary classification results comparison classifiers classifiers offer category ranking 

performance measures category ranking category ranking evaluated measures similar conventional measures evaluating ranking document retrieval systems recall precision point average precision 
classifier input document output ranked list categories assigned document recall precision computed threshold ranked list categories correct recall total categories correct categories correct precision total categories categories means categories decision threshold 
global evaluation classifier collection test documents adapt procedure conventional interpolated point average precision salton mcgill described evaluation statistical approaches 
document compute recall precision position ranked list correct category 

interval recall thresholds 
highest precision value interval representative precision value left boundary interval 

recall threshold representative precision exact precision value data point exists precision value closest point terms recall 
interval empty default precision value zero 

interpolation recall thresholds replace representative precision highest score representative precision values threshold higher thresholds 

interval averaging average document data points test documents recall thresholds respectively 
step results interval average precision scores 

global averaging average interval average precision scores obtain single numbered performance average pt avgp 

performance measures binary classifiers category assignments binary classifier evaluated way contingency table table category cells cell counts documents correctly assigned category cell counts documents incorrectly assigned category cell counts documents incorrectly rejected category cell counts documents correctly rejected category 
conventional performance measures defined computed contingency tables 
measures recall precision fallout accuracy acc error err undefined undefined undefined acc err 
table 
contingency table 
correct correct assigned assigned yang evaluating performance average categories conventional methods macro averaging micro averaging 
macro averaged performance scores computed computing scores category contingency tables averaging category scores compute global means 
micro averaged performance scores computed creating global contingency table cell values sums corresponding cells category contingency tables global contingency table compute micro averaged performance scores 
important distinction macro averaging micro averaging 
micro average performance scores gives equal weight document considered document average precisely average document category pairs 
likewise macro average performance scores give equal weight category regardless frequency category average 

analysis bep measure performance measures may misleading examined 
example trivial algorithm says category document perfect recall unacceptably low score precision 
conversely system rejects document category perfect score precision fall sacrifice recall extreme 
usually classifier exhibits trade recall precision internal parameters decision threshold classifier adjusted obtain high recall usually means sacrificing precision vice versa 
recall precision classifier tuned equal value value called break point bep system lewis ringuette 
bep commonly text categorization evaluations 
recall precision values exactly equal average nearest recall precision values interpolated bep 
problem interpolation nearest recall precision values far apart bep may reflect true behavior system 
measure defined van rijsbergen common choice single numbered performance measure rp 
balances recall precision way gives equal weight 
general form measure defined pr parameter allowing differential weighting precision recall 
measure optimization criterion threshold tuning binary decisions 
score maximized values recall precision equal close smaller recall precision dominates value 
noticed bep just specific value variable 
bep definition means bep score system equal optimal value system 
restricts kinds evaluation statistical approaches comparisons system performance measured performance measured bep 
specifically system bep value higher system optimal value definitely better performer balanced recall precision main consideration converse necessarily true 

analysis accuracy error accuracy error common performance measures machine learning literature evaluations text categorizations systems potential pitfall train evaluate binary classifier 
example illustrates pitfall 
reuters collection version categories document having categories assigned average 
means average probability document belonging category 
consequently trivial algorithm rejects document category global micro macro equal average error rate global average accuracy 
suggest trivial classifier accuracy error may sensible measure effectiveness usefulness classifier text categorization number categories large average number categories document small 
problem illustrated ohsumed collection hersh corpus commonly text categorization research 
ohsumed contains documents indexed unique categories categories document average 
collection trivial global average error rate accuracy 
global average accuracy error optimization criterion training categorization system system tend learn trivially reject documents category lead high global accuracy error rate 
fundamentally difficulties accuracy error performance measures arises definitions 
recall precision accuracy error number test documents divisor 
small change value true positive true negative produce small change value accuracy likewise small change produce small change value error 
rare categories maximum value small larger number documents belong category question 
consequently range zero maximum value having effect value accuracy error respectively 

comparative analysis consider value recall defined potential values small furthermore quantity constant equal number documents belong category question 
consequently change yang value produce relatively large change value recall 
correct incorrect classification document produce change compared change accuracy error proper erroneous classification document 
words recall sensitive measure performance rare categories accuracy error 
rare categories precision measure sensitivity accuracy recall 
precision measure value denominator quite large 
classifier performing value small precision measure sensitive misclassification documents fact larger measures sensitive errors classification process 
fallout suffers problem accuracy error value denominator constant large rare categories fallout sensitive recall precision measure rare categories 
suitable choice measures discussed expected number categories document small compared number categories recognized classifier sensitive classification errors zero trivial rejection algorithm small trivial acceptance algorithm 
bep similar choice true bep interpolation interpolated bep sufficiently close actual recall precision values 
accuracy error hand suitable measures insensitive performance variances return near optimal values trivial algorithm 
just particular measure may considered mean measure completely useless evaluation 
accuracy error insightful measures coupled sensitive performance scores bep 
general evaluations provide variety scores measuring performance algorithm compressing performance single score 

experimental design conducted novel experiments knn llsf word classifiers explore cross method evaluation problem aspects effect collection variability performance classifiers effect thresholding methods converting category ranking binary decisions sensitivity performance measures reflecting classifiers behavior scalability classifiers larger harder application ohsumed collection 
knn word classifiers applied versions reuters collection mentioned section 
llsf method evaluated versions computation costly knn word 
evaluation statistical approaches 
preprocessing feature selection bench marking retrieval system smart salton unified preprocessor knn llsf word systems 
removing words stemming term weighting term word stemming 
phrasing option available smart experiments 
term weighting schemes combine document term frequency tf inverted document frequency idf variety ways 
typical term weighting options tested including ltc atc ntc smart notation 
term weighting produced best results ltc cases cross method comparisons 
feature selection step words removed documents smart 
feature selection attempts remove non informative words documents order improve categorization effectiveness reduce computational complexity 
efficiency improvement feature selection especially important llsf computationally intractable training phase applied large collections 
tractability crucial issue knn improved performance noise reduction feature selection desirable 
feature selection criteria tested knn llsf including information gain mutual exclusion statistic document frequency term strength thorough evaluation feature selection methods reported yang pederson 
statistic effective information gain document frequency yielded similar results 
reuters collection version example feature selection reduced training set vocabulary unique words 
correspondingly category ranking performance knn improved point average precision category assignments knn improved measure 
best results knn llsf feature selection reported section 
aggressive vocabulary reduction applied word reduce chance matching words category names documents 

thresholding strategies binary categorization knn llsf word classifiers primarily ranking systems 
obtain binary assignments categories documents thresholding strategies examined named rcut pcut scut 
rcut stands rank thresholding 
target space categories ranking system knn llsf word produces ranking list categories document 
decisions obtained thresholding ranks candidate categories 
threshold predetermined empirically chosen integers performance scores recall precision vary different thresholds 
simple easily applied line category assignment particular document rcut suffers inability smoothly adjust trade recall precision discrete rank values 
test set documents yang category candidates rank assigned 
result optimization trade optimal value difficult obtain 
pcut abbreviation proportional assignment method previous text categorization research lewis ringuette wiener :10.1.1.54.6608
binary decision classifier produces confidence scores document category decision pairs number test documents number training set categories 
decision pairs sorted category resulting ranked list decisions category 
binary decision obtained assigning pi top ranking decision pairs list remaining pairs number documents test set pi training set probability ith category empirically chosen parameter 
varying value smooth trade recall precision obtained general 
pcut effectively adjust system bias assignments far proportion assignments categories little assignments 
decision thresholds training set probabilities categories learned optimized ranking confidence scores system 
addition pcut suffers inability perform line category assignment document classifiers pcut provide line assistance users computer aided text categorization 
scut stands optimal thresholding confidence scores category candidates 
done splitting original training set portions portion training portion validation test set learning optimal threshold category 
category optimal threshold score optimizes value system validation set documents 
optimal thresholds learned line optimal thresholds learned line category assignment 
thresholding methods tested knn llsf word reuters version results section 

parameter optimization parameters empirically determined llsf knn word include tw term weighting scheme choice atc ltc ntc ft number features selected vocabulary original training documents tr maximum length ranked list category ranked value tr confidence score zero rank threshold making decisions rcut average number system assigned decisions document pcut value knn number nearest neighbors category prediction test document value llsf number singular vectors computing approximated llsf regression model 
evaluation statistical approaches classifier specific parameters 
thorough investigations suitable choices parameter values reported previous papers main observations performance knn relatively stable large range values yang satisfactory performance llsf depends sufficiently large yang 
large number possible combinations parameter values exhaustive testing combinations practical necessary 
take greedy search strategy parameter tuning 
subjectively decide order parameters tuned empirically find best choice parameter time starting parameter order 
typical promising value subjectively chosen default parameter starting point process 
varying value parameter fixing values parameters identify best value parameter value fixed value parameter continued tuning process parameters 

evaluation 
effects thresholding strategies parameters performance variation word knn llsf respect choices thresholding strategies parameter values tested reuters version results summarized table 
original training set split portions portion training portion learning optimal value parameters 
parameters determined experiments word knn systems run relatively fast 
parameter tuned llsf parameters llsf set values chosen knn 
best choices produces equally performance scores choices 
observations obtained table tr length ranked list little impact performance scores long larger experiments word 
surprising number categories document average reuters corpus 
chose tr remaining experiments parameter tuning 
choices tw ltc atc ntc equally word knn 
chose ltc remaining experiments 
ft appears range optimal choices feature selection criterion 
chose ft training set vocabulary remaining experiments 
parameter knn values tested resulting difference scores knn negligible 
parameter llsf values tested performance llsf measured micro averaging approaching plateau 
yang table 
parameter tuning word knn llsf reuters version validation test set 
best best fixed parameters tested values best choice word tw ltc tr tr tr tw atc ltc ntc 
tw ltc atc ntc tr tw ltc scut optimal category specific tr tw ltc pcut tr tw ltc knn tr rcut rank rank tw ltc scut ft ft scut tw atc ltc ntc ltc atc ntc ft tw ltc scut ft tw ltc scut optimal category specific ft tw ltc pcut ft tw ltc llsf tr rcut rank rank ft tw ltc scut ft tw ltc pcut ft tw ltc rcut rank rank effects thresholding strategies varies different classifiers 
word pcut value yielded better results rcut 
knn llsf hand performance advantage pcut rcut 
classifiers scut yielded best results 
thresholding strategy parameters table range set values classifiers relatively stabilized optimal performance 
choosing value best range parameter obtained evaluation results word knn llsf table 
table 
results word knn llsf reuters version test set docs 
ranking scut pcut rcut system parameter settings word tr tw ltc rank knn tr tw ltc ft rank llsf tr tw ltc ft rank evaluation statistical approaches table 
examination knn llsf word different versions reuters 
version labelled knn llsf word version cgi version lewis version yang version apte version parc 
effects collection variability effects collection variability classifier performance evaluated results word knn llsf classifiers reuters versions shown table 
word knn llsf primarily ranking classifiers conventional point average precision scores 
scores reuters version slightly higher shown table complete ranking categories setting parameter tr inf experiments table 
believe collections statistically homogeneous performance classifier vary appreciably hand performance classifier changes dramatically switching collection supposedly similar careful analysis differences collections called 
results classifier may biased chose different classifiers word knn llsf evaluate different versions reuters collection 
chose classifiers fundamentally different classification algorithms closely control conditions run 
published results classifiers carefully control input data conditions classifiers tested 
looking table see versions appear relatively homogeneous performance classifiers varied slightly different versions 
results suggest inclusion version exclusion versions categories training set frequency appear significant impact performance classifier 
suggest different time slicing training test sets version vs version minor effect classifier performance 
differences performance classifiers version versions significant 
difference versions inclusion version exclusion version unlabeled documents cause performance variations classifiers clear 
examination randomly selected test documents version shows documents appear classified correctly knn cases counted incorrectly classified evaluation documents unlabeled 
unlabeled documents version appear cause problem classifier evaluation 
analyze problem assume unlabeled documents reuters version test set belong categories 
consider perfect yang classifier trivial classifier evaluated test set 
perfect classifier assessed error rate trivial classifier assessed error rate 
score accurate reflection performance corresponding classifiers drawn scores erroneous 
course know documents reuters version labeled categories unlabeled belong categories test training sets argument indicative problem 
sharp increase performance fundamentally different classifiers knn word going version strongly suggests large portion documents reuters version labelled 
reuters version outlier collection compared versions reuters collection 
contains documents test set unlabeled certain unlabeled documents labeled 
furthermore change performance word knn switching version version calls questions test set random sample reuters corpus 
statistical learning algorithm knn declined performance simple word matching algorithm word increased 
taken isolation performance changes clearly favor word matching statistical learning known case 
know criteria select test documents results suggest evaluations reuters version difficult interpret inconsistent evaluations collections 

cross method comparison observations section imply importance understanding nature test collections 
flawed collection large portion documents incorrectly assumed category labels lead classifier performance little true behavior classifier 
likewise comparisons collections analyzing performance classifiers affected collection differences equally misleading 
fundamental considerations discussions regarding cross method comparison 
table summarizes previously published results reuters versions results new experiments word knn llsf 
micro average bep scores performance measure widely reported score classifiers evaluated reuters 
scores word knn llsf interpolated bep values optimal parameters described section 
table reuters versions densest columns 
claims published evaluations results collections 
cohen concluded experts best performer reuters version collection cohen singer table agrees 
interestingly experts relatively insensitive removal unlabeled documents reuters version going classifier evaluated reuters reuters showed significant improvement going reuters reuters 
furthermore experts evaluation statistical approaches table 
results summary tc systems reuters versions 
reuters reuters reuters reuters system version version version version word scut pcut pcut knn scut scut scut llsf scut scut parc perceptron pcut classi perceptron ripper dnf scut scut swap dnf dtree ind pcut dtree charade dnf experts gram scut scut rocchio scut scut naivebayes pcut construe exp sys 
highest performing classifier reuters lowest reuters 
counter intuitive classifiers performance scores improve unlabeled documents removed test set experts continue best performer nearly best reuters 
apte 
compared results swap reuters version results naivebayes dtree lewis reuters version lewis ringuette concluded significantly better performance rule learning methods superior decision trees text categorization 
see knn performance version performance version 
knn algorithm score version lower swap higher version 
conclude swap better knn opposite 
interestingly moulinier reported result dtree algorithm close swap score bep reuters 
bep lower bound swap may better performer dtree 
case claim apte advantage rule learning algorithms non rule learning algorithms convincing 
similarly claim cohen singer advantage context sensitive classifiers ripper experts linear classifiers necessarily supported empirical results 
algorithms swap ripper charade similar performance reuters close result dtree knn llsf collection 
performance indirect comparison knn baseline reuters 
knn llsf specify explicit term combinations context implicitly 
classification function llsf example sensitive weighted linear combinations words occur yang training documents 
sensitivity llsf equivalent non linear classifier llsf fundamentally different methods assume terms independent naivebayes 
ability acquire context sensitivity implicitly classification functions may reason high performance knn llsf 

global observations scores clean versions reuters versions knn nnet parc llsf classifiers exhibited best performance classi dtree rule learning approaches ripper swap charade performed reasonably level far best performing classifiers 
naivebayes surprisingly worst performance version significantly outperforming word non learning method 
rocchio method showed relatively poor performance 
suggests rocchio commonly weak baseline comparisons learning methods knn challenging alternative 
global observations performance categorization systems informative solid specific learning algorithms difficult lack complete information performance evaluations reported classifiers 
example results knn llsf word different thresholding methods scut pcut rcut obtaining binary decisions 
methods results reported thresholding method 
ripper experts scut results nnet parc evaluated pcut 
observed scut better pcut knn reuters know generalizable nnet parc 
simply conclude knn equally nnet parc knowing pcut best possible thresholding strategy method 
missing piece information know pcut threshold value parameter described section nnet parc tuned test data reported performance system may may higher parameter tuned training data solely 
thresholds binary decisions experimental parameters contribute performance variations classifiers choices stemming term selection term weighting sampling strategies training data clear systems worse results reported ones parameter tuned test data 
detailed information sure percent difference scores break point measure indication theoretical strength weakness learning method 
unclear significance test designed performance method compressed single number break point optimized 
variance analysis difficult necessary information performance variation respect different parameter settings generally published 
point analysis show global cross method evaluation impossible futile 
contrary missing detailed information prohibit available information partial comparison certainly indication useful additional experiments 
carefully analyzing test conditions different experiments shown study factors underlying evaluation statistical approaches performance variations classifiers transparent leading better understanding evaluation problems improved methodology 
clearly carefully conducted comparative study methods experiments useful observation significant performance variations due different choices approaches parameter settings domains tasks 

efficiency word llsf knn word non learning method simply word matching algorithm utilizing inverted file indexing category names 
category ranking document fast proportional number unique words document 
observed total time cpu seconds categorization test documents reuters version yields line response cpu second test document average 
llsf eager learning method line training phase line testing phase 
training phase quadratic time complexity pn number singular vectors computing approximated llsf solution yang max larger number number training documents number unique terms training documents 
quadratic complexity computational bottleneck scaling method large applications 
training done line document categorization fast 
experiment reuters version observed training time cpu hours sparcstation ultra line response cpu second document testing phase 
knn lazy learning instance method line training phase 
main computation line scoring training documents test document order find nearest neighbors 
inverted file indexing training documents time complexity ln yang number unique words document number training documents number unique terms training collection 
experiments knn reuters version observed online response cpu second test document average 
scaling test knn ohsumed observed cpu minutes indexing training documents line response cpu second test document average micro average value yang 
text categorization method examined full domain ohsumed 
general terms scaling problem knn reduced scaling problem line document ranking number techniques studied literature including partial indexing ranking persin bell moffat document clustering iwayama tokunaga dimensionality reduction yang pedersen parallel computing 

reached study 
comparative evaluation methods experiments important understanding state art text categorization 
illustrated carefully yang analyzing empirical evidence test conditions classifiers evaluated factors underlying performance variations transparent better understood leading improved evaluation methodology 

impact collection variability classifier performance serious 
particular including large portion unlabeled documents training test set treating negative instances categories knowing ground truth caused considerable confusion text categorization research lead inconsistent observations 
status unlabelled documents need clarified results reported reuters version fully understood 

category ranking evaluation binary classification evaluation informative 
reflects usefulness classifiers interactive applications emphasizes batch mode 
providing types performance results ranking classifiers effects thresholding strategies explicitly observable 

global observation performance twelve classifiers versions reuters suggests learning methods performed reasonably significantly outperformed word non learning method 
finer level distinction knn llsf top performers followed group classifiers classi swap ripper dtree charade performance scores close 
naivebayes surprisingly worst performance rocchio relatively poor performance 

evaluation scalability classifiers large category spaces important rarely investigated area 
knn classifier learning method evaluated full set ohsumed categories demonstrating tractability method target space orders magnitude larger category set reuters 
acknowledgments jan pedersen infoseek david lewis william cohen isabelle moulinier university paris vi providing information experiments 
jaime carbonell carnegie mellon university suggesting improvement binary decision making chris buckley cornell making smart system available tom valuable suggestions improving writing 
notes 
focuses pre versions reuters collection commonly published evaluations newly refined version reuters evaluation results widely available 

personal contact carnegie group confirmed reuters categorize news stories 

formatted version collection prepared yang colleagues currently available carnegie mellon university web site moscow mt cs cmu edu reuters apte 

formatted version collection prepared yang colleagues electronically available moscow mt cs cmu edu reuters parc 
evaluation statistical approaches apte damerau weiss language independent automated learning text categorization models 
proceedings th annual acm sigir conference 
bell moffat design high performance information filtering system 
proceedings th ann 
int 
acm sigir conference research development information retrieval sigir pp 

cohen ww singer context sensitive learning text categorization 
sigir proceedings th annual international acm sigir conference research development information retrieval pp 

rh masand bm smith sj waltz dl trading mips memory knowledge engineering classifying census returns connection machine 
comm 
acm 
fuhr lustig tzeras air rule multistage indexing systems large subject fields 
proceedings riao pp 

hayes pj weinstein sp construe tis system content indexing database new stories 
second annual conference innovative applications artificial intelligence 
hersh buckley leone tj ohsumed interactive retrieval evaluation new large text collection research 
th ann 
int 
acm sigir conference research development information retrieval sigir pp 

iwayama tokunaga cluster text categorization comparison category search strategies 
proceedings th ann 
int 
acm sigir conference research development information retrieval sigir pp 

lewis dd ringuette comparison learning algorithms text categorization 
proceedings third annual symposium document analysis information retrieval sdair 
lewis dd schapire re callan jp papka training algorithms linear text classifiers 
sigir proceedings th annual international acm sigir conference research development information retrieval pp 

mitchell machine learning 
hill 
moulinier learning bias issue text categorization problem 
technical report lip universite paris vi page appear 
moulinier ganascia text categorization symbolic approach 
proceedings fifth annual symposium document analysis information retrieval 
ng ht goh wb low kl feature selection perceptron learning usability case study text categorization 
th ann 
int 
acm sigir conference research development information retrieval sigir pp 

persin document filtering fast ranking 
proceedings th ann 
int 
acm sigir conference research development information retrieval sigir pp 

quinlan jr induction decision trees 
machine learning 
salton automatic text processing transformation analysis retrieval information computer 
addison wesley reading pa salton mcgill mj modern information retrieval 
mcgraw hill computer science series 
mcgraw hill new york 
tzeras hartman automatic indexing bayesian inference networks 
proc 
th ann 
int 
acm sigir conference research development information retrieval sigir pp 

van rijsbergen cj information retrieval 
butterworths london 
wiener pedersen jo weigend neural network approach topic spotting 
proceedings fourth annual symposium document analysis information retrieval sdair 
yang expert network effective efficient learning human decisions text categorization retrieval 
th ann 
int 
acm sigir conference research development information retrieval sigir pp 

yang noise reduction statistical approach text categorization 
proceedings th ann 
int 
acm sigir conference research development information retrieval sigir pp 

yang yang evaluation statistical approach text categorization 
technical report cmu cs computer science department carnegie mellon university 
yang chute cg linear squares fit mapping method information retrieval natural language texts 
proceedings th international conference computational linguistics coling pp 

yang chute cg example mapping method text categorization retrieval 
acm transaction information systems tois pp 

yang pedersen jp feature selection statistical learning text categorization 
th international conference machine learning pp 

