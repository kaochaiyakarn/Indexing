building distributed full text index web sergey melnik sriram raghavan beverly yang hector garcia molina stanford university identify crucial design issues building distributed inverted index large collection web pages 
introduce novel pipelining technique structuring core index building system substantially reduces index construction time 
propose storage scheme creating managing inverted files embedded database system 
suggest compare different strategies collecting global statistics distributed inverted indexes 
performance results experiments testbed distributed web indexing system implemented 
categories subject descriptors information storage retrieval content analysis indexing indexing methods information storage retrieval systems software distributed systems general terms design performance additional key words phrases distributed indexing text retrieval inverted files pipelining embedded databases 
various access methods developed support efficient search retrieval text document collections 
examples include suffix arrays manber myers inverted files inverted indexes salton witten signature files faloutsos christodoulakis 
inverted files traditionally index structure choice web 
commercial search engines custom network architectures high performance shorter version appear proceedings th international www conference may 
authors address stanford university gates computer science department room serra hall stanford calif email melnik hector db stanford edu 
permission digital hard copy part personal classroom granted fee provided copies distributed profit commercial advantage copyright notice title publication date appear notice copying permission acm copy republish post servers redistribute lists requires prior specific permission fee 
acm acm transactions information systems vol 
july pages 
melnik hardware achieve sub second query response times inverted indexes 
inverted index collection web pages consists set inverted lists occurring word index term 
inverted list term sorted list locations term appears collection 
location consists page identifier position term page 
necessary track term occurrence page location include just page identifier option number occurrences page 
index term corresponding location refer pair conceptually building inverted index involves processing page extract postings sorting postings index terms locations writing sorted postings collection inverted lists disk 
collection small indexing rare activity optimizing index building critical optimizing run time query processing retrieval 
web scale index index build time critical factor reasons 
scale growth rate 
web large growing rapidly lawrence giles inktomi traditional build schemes unmanageable requiring huge resources days complete vulnerable system failures 
measure comparison page gb webbase repository hirai represents estimated size publicly indexable web january inktomi larger gb large trec collection hawking craswell benchmark large ir systems :10.1.1.24.8162
rate change 
content web changes extremely rapidly cho garcia molina need periodically crawl web update inverted index 
indexes updated incrementally rebuilt periodically crawl 
approaches key challenge handle large wholesale changes commonly observed successive crawls web 
efficiency simplicity commercial web search systems employ rebuilding approach burrows personal communication 
case critical build index rapidly provide access new data 
study evaluate index building context special challenges imposed web implemented testbed system operates cluster nodes workstations 
built testbed encountered challenging problems typically encountered working smaller collections 
report issues experiments conducted optimize build times massive collections 
propose technique constructing software pipeline indexing node enhance performance intra node parallelism section 
web link structure utilized produce high quality results text retrieval continues primary method identifying relevant pages 
commercial search engines combination text link methods employed 
acm transactions information systems vol 
july 
building distributed full text index web fig 

testbed architecture 
argue embedded database system berkeley database olson storing inverted files number important advantages 
propose appropriate format inverted files optimal features database system section 
distributed system building inverted indexes needs address issue collecting global statistics inverse document frequency idf 
examine different strategies collecting statistics distributed collection section 
issues appropriate experiments performance studies compare alternatives 
emphasize focus process building inverted index index process search queries 
result address issues ranking functions relevance feedback query expansion salton witten distributed query processing jeong omiecinski tomasic garcia molina 
focus presenting comprehensive performance feature list comparison testbed indexing system existing systems indexing web collections 
experience testbed identify key performance issues building web scale index propose generic techniques applicable distributed inverted index system 

testbed architecture testbed system building inverted indexes operates distributed shared architecture consisting collection nodes connected local area network 
identify types nodes system distributors 
nodes store collection web pages indexed 
pages gathered web crawler stored repository distributed disks nodes hirai :10.1.1.24.8162
indexers 
nodes execute core index building engine 
acm transactions information systems vol 
july 
melnik query servers 
nodes stores portion final inverted index associated lexicon 
lexicon lists terms corresponding portion index associated statistics 
depending organization index files query servers may involved answering search query 
note traditional information retrieval ir systems employ tier architecture building inverted indexes 
systems pages documents indexed placed disks directly attached machines build index 
tier architecture provides significant benefits context web search service 
web search service perform resource intensive tasks crawling indexing querying simultaneously 
existing indexes answer search queries newer indexes crawl constructed parallel crawler fresh crawl 
tier architecture clearly separates activities executing separate banks machines improving performance 
ensures pages indexed available querying quickly possible maximizing index freshness 
overview indexing process 
inverted index built stages 
stage distributor node runs distributor process disseminates collection web pages indexers 
indexer receives mutually disjoint subset pages associated identifiers 
indexers parse extract postings pages sort postings memory flush intermediate structures disk 
second stage intermediate structures merged create inverted files associated lexicons 
inverted file lexicon pair generated merging subset sorted runs 
inverted file lexicon pair transferred query servers 
simplicity assume indexer builds pair 
distributed inverted index organization 
distributed environment basic strategies distributing inverted index collection query servers martin ribeiro neto barbosa tomasic garcia molina 
strategy partition document collection query server responsible disjoint subset documents collection called local inverted files ribeiro neto barbosa 
option partition index terms query server stores inverted lists subset index terms collection called global inverted files ribeiro neto barbosa 
performance studies described tomasic garcia molina indicate large collections local inverted file organization uses system resources effectively provides query throughput cases 
employ local inverted file organization testbed 
testbed environment 
indexing testbed uses large repository web pages provided webbase project hirai test corpus performance experiments :10.1.1.24.8162
storage manager webbase system receives pages web crawler cho garcia molina populates distributor nodes 
indexers query servers single acm transactions information systems vol 
july 
building distributed full text index web fig 

logical phases 
processor pcs mhz processors mb main memory equipped multiple ide disks 
distributor nodes machines scsi disks housing repository 
machines interconnected mbps ethernet lan 

pipelined indexer design core indexing system index builder process executes indexer 
input index builder process sequence web pages associated identifiers 
output index builder set sorted runs 
sorted run contains postings extracted subset pages received index builder 
process generating sorted runs logically split phases illustrated 
refer phases loading processing flushing 
loading phase number pages read input stream 
processing phase involves steps 
pages parsed remove html tagging tokenized individual terms stored set postings memory buffer 
second step postings sorted place term location 
flushing phase sorted postings memory buffer saved disk sorted run 
phases executed repeatedly entire put stream pages consumed 
loading processing flushing tend disjoint sets system resources 
processing obviously cpu intensive flushing primarily uses secondary storage loading done directly network tape separate disk 
indexing performance improved executing phases concurrently 
execution order loading processing flushing fixed phases form software pipeline 
illustrates benefits pipelined parallelism index construction 
shows portion indexing process uses concurrent threads operates reusable memory buffers generates sorted runs disk 
key issue pipelining design execution schedule different indexing phases result minimal running time called makespan scheduling literature 
problem differs typical job scheduling problem chakrabarti muthukrishnan vary sizes incoming jobs loading phase urls normally replaced numeric identifiers compactness 
acm transactions information systems vol 
july 
melnik fig 

multi threaded execution 
choose number pages load 
rest section describe effective flexibility 
derive certain simplifying assumptions characteristics optimal indexing pipeline schedule determine theoretical speedup achievable pipelining 
describe experiments illustrate observed performance gains differ theoretical predictions 
theoretical analysis consider indexer node resource type single cpu single disk single network connection receive pages 
design pipeline shown minimize index construction time 
notice executing concurrent phases kind disk flushes futile resource type 
consider index builder uses executions pipeline process entire collection pages generate sorted runs 
execution pipeline refer sequence phases loading processing flushing transform set pages sorted run 
bi bethe buffer sizes executions 
sum bi fixed amount text input represents total size postings extracted pages 
aim come way choosing bi values minimize running time 
loading flushing take time linear size buffer 
processing time linear component representing time removing html tokenizing linear logarithmic component representing sorting time 
li bi fi bi pi bi bi log bi represent durations loading flushing processing phases ith execution acm transactions information systems vol 
july 
building distributed full text index web table measured constants constant value pipeline 
large indexing time determined resource cpu approximated tp max li pi fi 
shown see tp minimized pipeline executions buffer size bn log durations loading processing flushing phases respectively 
choose value maximizes speedup gained pipelining 
calculate speedup follows 
pipelined execution takes time tp max pin uses buffers size comparison sequential execution single buffer size take time ts log 
node single resource type maximal theoretical speedup achieve pipelining simplification ts tp log max max log max log typical values refer table 
ignore concentrate choosing value maximizes 
maximum value reached phases equal duration 
guarantee requires 
maximize choosing min max max example ratio phases 
setting 
improve changing ratio 
general setting log max obtain max lg expression represents size postings buffer maximize pipeline speedup indexer single resource type 
buffer size specified equation loading flushing depending relative magnitudes bottleneck processing phase forced periodically wait phases complete 
analogous effect take place buffer sizes greater rate pages loaded memory network average ratio size page total size postings generated page 
acm transactions information systems vol 
july 
melnik fig 

optimal buffer size 
prescribed equation 
generalize equation indexer identical processors identical disks input streams obtain lg max 
max experimental results study impact pipelining technique indexing performance conducted number experiments testbed single indexer supplied stream web pages distributor 
ran index builder process measurement mode recorded execution times various phases determined values table 
values constants equation evaluated mb 
optimal total size postings buffers predicted theoretical analysis mb 
impact buffer size performance 
illustrates performance index builder process varies size buffer 
highlights importance analytical result aid choosing right buffer size 
optimal total buffer size actual experiments turned mb 
predicted optimum size differed slightly observed optimum difference running times sizes minutes page collection 
buffer sizes loading proved bottleneck processing flushing phases wait periodically loading phase complete 
buffer size increased processing phase dominated execution time larger larger buffers postings sorted 
performance gain pipelining 
shows pipelining impacts time taken process generate sorted runs variety input acm transactions information systems vol 
july 
building distributed full text index web table ii 
speedup including time merging sorted runs collection size speedup generating sorted runs speedup including merging seconds seconds fig 

performance gain pipelining 
sizes 
note small collections pages performance gain pipelining noticeable substantial 
small collections require pipeline executions time dominated time required startup load buffers shutdown flush buffers 
reasons pipelined index building received attention systems dealt smaller collections 
collection sizes increase gain significant collection pages pipelining completes hours earlier purely sequential implementation 
experiments showed general large collections sequential index builder slower pipelined index builder 
note observed speedup lower speedup predicted theoretical analysis described previous section 
analysis ideal pipeline loading processing flushing interfere way 
practice network disk operations processor cycles access main memory 
concurrently running phases different types slow 
note total buffer size pipelined execution generates sorted runs approximately times smaller generated sequential indexer 
consequently times sorted runs need merged second stage indexing 
indicated table ii experiments indicate large collection sizes potential increase acm transactions information systems vol 
july 
melnik merging time offset time gained stage pipelining 
expect long memory merge time allocate buffers sorted runs merging performance significantly affected 

managing inverted files embedded database system building inverted indexes massive web scale collections choice efficient storage format particularly important 
traditionally approaches storing managing inverted files custom implementation leveraging existing relational object data management systems brown driscoll 
advantage custom implementation enables effective optimizations tuned specific operations inverted files caching frequently inverted lists compressing rarely inverted lists expensive methods may take longer decompress 
leveraging existing data management systems fine grained control implementation may possible 
extra overhead higher level abstraction provided data management system 
hand opportunity reduction development time complexity 
challenge lies designing scheme storing inverted files optimal storage structures provided data management system 
storage scheme space efficient ensure basic lookup operation inverted file retrieving inverted list index term efficiently implemented access methods data management system 
note custom inverted file structures described moffat zobel anh moffat brown potentially database systems managing opaque data blocks index implementations fully exploit capabilities underlying system 
instance applications typically need employ types data blocks custom link structures access methods superimposed top underlying database system 
example brown reports persistent object store managing inverted files 
implementation described uses different kinds blocks storing headers directories location lists forth 
basic lookup operations implementation translate traversals underlying object store 
section compare different storage schemes managing large inverted files embedded database system 
schemes suggest uniform block structures exploit native access methods features database system possible 
test schemes freely available embedded database system called berkeley db olson widely deployed commercial applications 
embedded database library toolkit provides database support applications defined programming api 
traditional database systems designed accessed applications embedded acm transactions information systems vol 
july 
building distributed full text index web databases linked compile time run time application act persistent storage manager 
provide device sensitive file allocation database access methods trees hash indexes optimized caching optional support transactions locking recovery 
advantage smaller footprints compared full fledged client server database systems 
briefly sketch capabilities berkeley db propose tree inverted file storage scheme called mixed list scheme 
qualitatively quantitatively compare mixed list scheme schemes storing inverted lists berkeley db databases 
rationale implementation berkeley db provides programming library managing key value pairs arbitrary binary data length 
offers access methods including trees linear hashing supports transactions locking recovery 
chose tree access method efficiently supports prefix searches retrieve inverted lists terms pre higher locality hash indexes 
standard organization tree inverted file involves storing index terms tree pointers inverted lists stored separately 
organization easy implement berkeley db fully utilize capabilities database system 
berkeley db efficiently handles arbitrary sized keys values efficient store index terms inverted lists database 
enables leverage berkeley db sophisticated caching schemes retrieving large inverted lists minimum number disk operations 
storage schemes 
challenge design efficient scheme organizing inverted lists tree structure 
considered schemes full list key index term value complete inverted list term 
single payload posting index term location pair separate key 
value empty may contain additional information posting 
mixed list key posting index term location 
value contains number successive postings sorted order referring different index terms 
postings value field compressed value field number postings chosen length field approximately 
note scheme inverted list index term may spread multiple key value pairs 
implementing mixed list storage scheme known encoding technique witten pack postings efficiently features turned efficiency desired 
storing indexing term key single location value viable option locations term guaranteed sorted order 
acm transactions information systems vol 
july 
melnik fig 

mixed list storage scheme 
value field long size value field kept approximately constant 
instance implementation encoding scheme adapted witten successive index terms value field represented prefix compression successive location identifiers represented terms numerical differences 
illustrates mixed list storage scheme encoding stores inverted lists 
simplicity example assume additional information maintained posting 
actual implementation allocated byte payload field store extra posting level information 
top half depicts inverted lists successive index terms bottom half shows stored key value pairs mixed list scheme 
example second key value pair stores set postings cat cat catch catcher forth posting stored key remaining postings stored value 
indicated index terms value field prefix compressed location identifiers represented differences 
example posting cat represented sequence entries empty field indicates length common prefix words postings cat cat empty field indicates postings refer word difference locations 
similarly posting catch represented sequence entries ch length common prefix ch remaining suffix catch location 
qualitative comparison storage schemes summarized table iii 
table symbols denote decreasing order qualitative goodness measures scheme relative performance metrics 
index size 
crucial factors determining index size number internal pages function height tree number overflow numerical differences turn compressed asn basic encoding rules specification ccitt 
acm transactions information systems vol 
july 
building distributed full text index web table iii 
comparison storage schemes scheme index size zig zag joins hot updates single payload full list mixed list pages 
single payload scheme posting corresponds new key resulting rapid growth number internal pages database 
large collections database size prohibitive berkeley db employs prefix compression keys 
query time performance impeding disk accesses needed 
situation significantly better full list scheme 
database key created distinct term value field compressed 
terms occur times collection may occur page 
large variations size value field overflow pages created database 
contrast mixed list scheme length value field approximately constant limiting number overflow pages 
total number keys number internal pages reduced choosing larger size value field 
value field contain postings different index terms compressed full lists 
zig zag joins 
ability selectively retrieve portions inverted list may useful processing conjunctive search queries inverted file moffat zobel 
example consider query green 
term green occurs web millions documents produces couple dozen hits 
zig zag join garcia molina inverted lists green allows answer query reading complete inverted list 
single payload scheme provides best support zig zag joins posting retrieved individually 
full list scheme entire list retrieved compute join mixed list scheme access specific portions inverted list available 
example retrieve locations cat starting read portion list locations 
obviously benefit partial retrieval decreases large portions inverted lists accessed individually moffat zobel 
demonstrate section optimal time retrieving inverted lists mixed list scheme achieved relatively small sizes value field bytes 
indicates mixed list scheme query processor effectively exploit zig zag joins reduce amount information read disk achieve improved performance 
hot updates 
hot updates refers ability modify index query time 
useful small changes need index values arbitrary length berkeley db uses overflow pages handle large value fields 
acm transactions information systems vol 
july 
melnik fig 

varying value field size 
successive index rebuilds 
example web search services allow users organizations register home pages 
additions immediately accommodated index hot update facility having defer index rebuilt 
schemes concurrency control mechanisms database support hot updates maintaining consistency 
crucial performance factor length inverted list read modified written back achieve update 
limit length value field hot updates faster mixed lists full lists 
single payload scheme provides best update performance individual postings accessed modified 
notice schemes significantly benefit fact postings sorted inserted 
inserting keys tree random order negatively affects page fill factor expensive tree reorganization needed 
berkeley db optimized sorted insertions high performance near page fill factor achieved initial index construction phase 
section quantitative comparison storage retrieval efficiency storage schemes discussed section 
experimental results experimental data section obtained building inverted index collection web pages 
collection contains distinct terms total postings 
illustrates choice storage scheme affects size inverted file 
shows variation index size value field size mixed list scheme 
dotted line represents index size database stored full list scheme 
note value field size applicable full list scheme graph just horizontal posting generated occurrences term page 
acm transactions information systems vol 
july 
building distributed full text index web table iv 
mixed list scheme index sizes number pages input size index size index size gb gb line 
single payload scheme viewed extreme case mixed scheme value field empty 
shows small large value fields adverse impact index size 
mixed list scheme small value fields require large number internal database pages potentially taller tree index accommodate postings 
hand large value fields cause berkeley db allocate large number overflow pages leads larger index 
indicated value field size bytes provided best balance effects 
full list scheme results moderate number overflow pages internal database pages 
requires storage space optimal mixed list inverted file 
examined storage schemes time write inverted file disk roughly proportional size file 
table iv shows index size mixed list scheme varies size input collection 
index sizes listed table iv include sum sizes inverted files associated lexicons 
numbers table iv generated mixed lists optimal value field size bytes derived 
table iv shows mixed list storage scheme scales large collections 
size index consistently size input html text 
compares favorably sizes reported vlc track crawled web pages trec hawking craswell best reported index size approximately size input html 
index sizes comparable reported sizes non web document collections compressed inverted files anh moffat 
note exact index sizes dependent type amount information maintained posting information handle proximity queries 
believe byte payload field implementation accommodate posting level information normally stored inverted indexes 
illustrates effect value field size inverted list retrieval time 
dotted horizontal line represents retrieval time fixed list scheme 
produced generating uniformly distributed query terms measuring time required retrieve entire inverted list query term 
optimal retrieval performance mixed list scheme achieved value field size warming period allowed measurements fill database file system cache 
acm transactions information systems vol 
july 
melnik fig 

time retrieve inverted lists 
bytes 
notice figures value field size bytes results maximum storage maximum retrieval efficiency mixed list scheme 
indicates fixed list mixed list optimal value field size schemes provide comparable retrieval performance 
note indicates raw inverted list retrieval performance different storage schemes 
true query processing performance affected factors caching inverted lists query processing techniques zig zag joins distribution query terms 

collecting global statistics text retrieval systems kind collection wide information increase effectiveness retrieval viles french 
popular example inverse document frequency idf statistics ranking functions 
idf term inverse number documents collection contain term 
query servers idf values local collections rankings skewed favor pages query servers return results 
depending particular global statistic ranking function nature collection may may necessary statistic computed accurately 
cases suffices estimate global statistic local values individual query servers sampling see related section 
section analyze problem gathering accurate collection wide information minimum overhead cases required 
techniques gathering different types collection wide information focus problem collecting term level global statistics idf values 
term level refers fact gathered statistic describes single terms higher level entities pages documents 
acm transactions information systems vol 
july 
building distributed full text index web table comparing strategies statistician memory phase load usage parallelism merging fl flushing design authors suggest computing global statistics query time 
require extra round communication query servers exchange local statistics 
communication adversely impacts query processing performance especially large collections spread servers 
query response times critical advocate precomputing storing statistics query servers index creation 
approach dedicated server known statistician computing statistics 
having dedicated statistician allows computation done parallel indexing activities 
minimizes number conversations servers indexers exchange statistical data statistician 
local information sent statistician various stages index creation statistician returns global statistics indexers merging phase 
indexers store global statistics local lexicons 
lexicon consists entries form term term id local statistics global statistics terms stored lexicon terms occurring associated inverted file section 
order avoid extra disk local information sent statistician memory 
identified phases occurs flushing sorted runs written disk merging sorted runs merged form inverted lists lexicon 
sending information phases leads different strategies various tradeoffs discussed section 
note sending information statistician phases additional huge fraction statistic collection eliminated 
sending information statistician optimized summarizing postings 
identified phases postings occur partially sorted order multiple postings term pass memory groups 
groups condensed term local aggregated information pairs sent statistician 
example indexer holds pages contain term cat sending individual postings statistician indexer count postings pass memory group send summary cat statistician 
statistician receives local counts indexers aggregates values produce global document frequency cat 
technique greatly reduces network overhead collecting statistics 
statistic gathering strategies describe compare strategies mentioned sending information statistician 
table qualitatively summarizes acm transactions information systems vol 
july 
melnik fig 

strategy 
fig 

fl strategy 
characteristics notation table iii 
column titled parallelism refers degree parallelism possible strategy 
strategy sending local information merging 
summaries term aggregated inverted lists created memory sent statistician 
statistician receives parallel sorted streams term information values indexer merges streams term aggregating sub aggregates term produce global statistics 
statistics sent back indexers sorted term order 
approach entirely stream require memory disk data structures statistician indexer store intermediate results 
streams means progress indexer synchronized statistician turn causes indexers synchronized 
result slowest indexer group bottleneck holding back progress faster indexers 
illustrates strategy collecting document frequency statistics term 
note bottom lexicon include statistics rat term local collection 
fl strategy sending local information flushing 
sorted runs flushed disk postings summarized summaries sent statistician 
sorted runs accessed sequentially processing statistician receives streams summaries globally unsorted order 
compute statistics unsorted streams statistician keeps memory hash table terms statistics updates statistics summaries term received 
processing phase statistician sorts statistics memory sends back indexers 
illustrates fl strategy collecting document frequency statistics 
acm transactions information systems vol 
july 
building distributed full text index web fig 

overhead statistics collection 
experiments demonstrate performance scalability collection strategies ran index builder merging processes testbed hardware configuration consisting indexers 
experimented different collection sizes pages respectively 
results shown see relative overhead defined time full index creation statistics collection time full index creation statistics collection strategies 
general experiments show fl strategy outperforms converge collection size large 
furthermore collection size grows relative overheads strategies decrease 
comparison strategies 
glance expected outperform fl 
statistician receives summary streams fl indexer performs comparison aggregation fl mentioned earlier merging progress synchronized servers 
portion computation done statistician done parallel merging activities indexer 
fl hand indexer simply writes summaries network continues 
statistician asynchronously process information network buffer parallel 
done parallel statistician consumes summaries slower rate indexer writes network network buffer generally hold summaries sorted run 
nontrivial waiting indexer flushing summaries sent statistician 
indexers specifications listed section 
acm transactions information systems vol 
july 
melnik fig 

varying lexicon buffer size 
enhancing parallelism 
strategy synchronization occurs indexer creates lexicon entry summary term sends summary statistician waits global statistic returned lexicon entry completed 
reduce effect synchronization merging process write lexicon entries lexicon buffer separate process wait global statistics include entries 
way process need block waiting processes operate parallel 
shows effect lexicon buffer size merging performance collection pages 
lexicon entries created faster global statistics returned indexers slowest lexicon buffer full 
occurs process creating lexicon entries block current state changes 
larger lexicon buffers reduce possibility saturation see expected initial increases size result large performance gains 
lexicon buffer size large performance slowly deteriorates due memory contention 
entire buffer need memory time lexicon buffer accessed cyclically lru replacement fast rate lexicon entries created cause buffer pages cycle rapidly memory swapping non buffer pages 
sub linear growth overhead 
constant decrease fl relative overhead fact number distinct terms page collection sub linear function collection size 
overhead incurred gathering statistics grows linearly number terms collection cost index creation grows linear logarithmically size collection 
result overhead statistic collection displays sublinear growth respect index creation time 
prediction consistent experimental results 
decreasing relative overhead fl subject constraint hashtable fit memory 
considering collection acm transactions information systems vol 
july 
building distributed full text index web pages require hash table roughly gb size constraint may problem large collections 
memory gb completely unreasonable simple alternative commodity hardware run statisticians parallel partition terms alphabetically statisticians 
way statistician collect moderately sized set global statistics 
implemented option system 

related interest motivated web designing scalable techniques speed inverted index construction distributed architectures 
ribeiro neto describe techniques efficiently build inverted index distributed architecture 
focus building global partitioning index term local partitioning collection inverted files 
furthermore address issues global statistics collection optimization indexing process individual node 
technique structuring index engine pipeline common pipelined query execution strategies employed relational database systems garcia molina 
chakrabarti muthukrishnan authors variety algorithms resource scheduling applications scheduling pipeline stages 
prior relational object oriented data stores manage process inverted files blair brown driscoll 
brown describe architecture performance ir system uses persistent object store manage inverted files 
results show shelf data management facility improves performance information retrieval system primarily intelligent caching device sensitive file allocation 
experienced similar performance improvements reasons employing embedded database system 
storage format differs greatly theirs utilize single tree storing inverted lists uniformly structured blocks 
mixed list scheme self indexing inverted list structures described moffat zobel skipped list anh moffat random access lists provides selective access portions inverted list 
moffat zobel propose dividing inverted list blocks containing fixed number postings 
extract postings block block needs sequentially decoded separate skip list compressed navigate block 
posting located navigating skip list identify block contained decoding block 
anh moffat fixed length blocks constant number bits collection statistics described melnik pages contain roughly distinct terms 
term uses bytes storage result hashtable gb 
acm transactions information systems vol 
july 
melnik blocks constant number postings develop scheme efficiently encode decode blocks 
conceptually blocks structures correspond value fields mixed list scheme 
synchronization points moffat zobel correspond key fields mixed list scheme 
couple significant differences 
value fields organized leaf nodes prefix compressed tree moffat zobel anh moffat blocks belonging inverted list organized sequentially 
second value field include postings inverted list case structures described moffat zobel anh moffat 
synchronization points moffat zobel contain just document identifiers keys contain index terms 
de different types global statistics may query processing 
focus types uses statistics actual process collecting 
viles viles french discuss maintenance global statistics distributed text index specifically addressing challenges arise incremental updates 
complementary strategies gathering statistics index construction 
global statistics important meta search environments lawrence giles craswell gravano ranked results possibly autonomous search servers merged produce global ranking 
environments alternative accurate global statistics craswell suggest statistics estimates true statistics derived sampling statistics different document collection 
statistics recommended mainly systems collection accurate statistics feasible extremely expensive instance merging results autonomous search services 
system collection accurate statistics feasible individual query servers indexers control 
great deal done issues relevant inverted index information retrieval discussed 
issues include index compression moffat bell anh moffat witten incremental updates brown jeong omiecinski tomasic witten zobel distributed query performance tomasic garcia molina tomasic garcia molina 

addressed problem efficiently constructing inverted indexes large collections web pages 
proposed new pipelining technique speed index construction demonstrated identify note leaf nodes tree sequentially linked list part tree implementation 
acm transactions information systems vol 
july 
building distributed full text index web right buffer sizes maximum performance 
showed large collection sizes pipelining technique speed index construction hours 
proposed compared different schemes storing managing inverted files embedded database system 
showed intelligent scheme packing inverted lists storage structures database provide performance storage efficiency comparable tailored inverted file implementations 
identified key characteristics methods efficiently collecting global statistics distributed inverted indexes 
proposed methods compared analyzed tradeoffs 
intend extend testbed incorporate distributed query processing explore algorithms caching strategies efficiently executing queries 
intend experiment indexing querying larger collections integration text indexing system indexes link structure web 
appendix proof optimality buffers tp max li pi fi 
loading flushing bottleneck tp value distributions bi including distribution 
processing critical phase tp bi bi log bi 
constraint bi absolute minimum tp reached bi buffers equal sizes 
global extremum easily determined standard analysis techniques lagrange multipliers 
anh moffat 
compressed inverted files reduced decoding overheads 
proceedings st international conference research development information retrieval august 
blair 
extended relational document retrieval model 
information processing management 
brown 
fast evaluation structured queries information retrieval 
proceedings acm conference research development information retrieval sigir acm press new york ny 
brown callan croft 
fast incremental indexing full text information retrieval 
proceedings st international conference large databases september 
brown callan croft moss 
supporting full text information retrieval persistent object store 
th international conference extending database technology march 
ccitt 

recommendation specification basic encoding rules syntax notation asn 

chakrabarti muthukrishnan 
resource scheduling parallel database scientific applications 
th acm symposium parallel algorithms architectures june acm press new york ny 
cho garcia molina 
evolution web implications incremental crawler 
appear th international conference large databases 
acm transactions information systems vol 
july 
melnik craswell hawking 
merging results isolated search engines 
proceedings th australasian database conference january 
de moffat zobel 
methodologies distributed information retrieval 
proceedings th international conference distributed computing systems 
faloutsos christodoulakis 
signature files access method documents analytical performance evaluation 
acm transactions office information systems october acm press new york ny 
garcia molina ullman widom 
database system implementation 
prentice hall cliffs nj 
driscoll 
structuring text relation system 
rd international conference database expert system applications september 
gravano chang garcia molina lagoze paepcke 
starts stanford protocol internet retrieval search 
www db stanford edu gravano starts html 
hawking craswell 
overview trec large collection track 
proceedings seventh text retrieval conference november 
hirai garcia molina paepcke raghavan 
webbase repository web pages 
proceedings th international world wide web conference may 
inktomi 

inktomi 
www inktomi com 
jeong 
omiecinski 
inverted file partitioning schemes multiple disk systems 
ieee transactions parallel distributed systems february iee computer society press los alamitos ca 
lawrence giles 
inquirus neci meta search engine 
proceedings th international world wide web conference 
lawrence giles 
accessibility information web 
nature 
manber myers 
suffix arrays new method line string searches 
proceedings st acm siam symposium discrete algorithms acm press new york ny 
martin macleod nordin 
design distributed full text retrieval system 
proceedings acm conference research development information retrieval september acm press new york ny 
melnik garcia molina yang raghavan 
building distributed fulltext index web 
technical report wp july stanford digital library project computer science dept stanford university 
available www stanford edu get wp 
moffat bell 
situ generation compressed inverted files 
journal american society information science 
moffat zobel 
self indexing inverted files fast text retrieval 
acm transactions information systems october acm press new york ny 
olson bostic seltzer 
berkeley db 
proceedings summer usenix technical conference june 
ribeiro neto barbosa 
query performance tightly coupled distributed digital libraries 
proceedings rd acm conference digital libraries june acm press new york ny 
ribeiro neto moura ziviani 
efficient distributed algorithms build inverted files 
proceedings nd acm conference research development information retrieval august acm press new york ny 
salton 
information retrieval data structures algorithms 
addison wesley reading massachussetts 
tomasic garcia molina 
performance inverted indices shared distributed text document information retrieval systems 
proceedings nd international conference parallel distributed information systems january 
tomasic garcia molina 
query processing inverted indices document information retrieval systems 
vldb journal 
acm transactions information systems vol 
july 
building distributed full text index web tomasic garcia molina 
incremental update inverted list text document retrieval 
proceedings acm sigmod international conference management data may acm press new york ny 
viles 
maintaining state distributed information retrieval system 
nd southeast conference acm acm press new york ny 
viles french 
dissemination collection wide information distributed information retrieval system 
th international acm conference research development information retrieval july acm press new york ny 
witten moffat bell 
managing gigabytes compressing indexing documents images nd ed 
morgan kauffman publishing san francisco 
zobel moffat sacks davis 
efficient indexing technique full text database systems 
th international conference large databases august pp 

received april revised may accepted july acm transactions information systems vol 
july 
