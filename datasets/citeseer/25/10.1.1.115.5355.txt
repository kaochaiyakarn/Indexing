proben set neural network benchmark problems benchmarking rules lutz prechelt prechelt ira uka de fakultat fur informatik universitat karlsruhe karlsruhe germany fax september technical report proben collection problems neural network learning realm pattern classi cation function approximation plus set rules conventions carrying benchmark tests similar problems 
proben contains data sets di erent domains 
datasets represent realistic problems called diagnosis tasks consist real world data 
datasets simple format attribute representation directly neural network training 
datasets proben de nes set rules conduct document neural network benchmarking 
purpose problem rule collection give researchers easy access data evaluation algorithms networks direct comparison published results feasible 
report describes datasets benchmarking rules 
gives basic performance measures indicating di culty various problems 
measures baselines comparison 
contents contents benchmark set 
benchmarking rules 
scope proben arti cial benchmarks 
related benchmarking rules general principles benchmark problem training set validation set test set input output representation training algorithm error measures network training results training times important details author quick benchmarking problems classi cation problems cancer card diabetes gene glass heart horse mushroom soybean thyroid summary approximation problems building flare summary learning results linear networks choosing multilayer architectures multilayer networks comparison multilayer results proben structure proben directory tree list tables proben le format data encoding architecture ordering bibliography list tables attribute structure classi cation problems attribute structure approximation problems linear network results classi cation problems linear network results approximation problems architecture nding results classi cation problems architecture nding results approximation problems pivot architectures datasets pivot architecture results classi cation problems pivot architecture results approximation problems shortcut architecture results classi cation problems shortcut architecture results approximation problems test comparison pivot shortcut results section discusses standardized datasets benchmarking rules neural network learning necessary scope proben real data addition arti cial problems today 
set 
study evaluation performed journal papers neural network learning algorithms showed aspect neural network research poor 
papers performance results new algorithm small number problems rarely 
cases problems meaningless synthetic problems instance parity symmetry encoder family 
comparisons algorithms suggested researchers cases done exception standard backpropagation 

explanations read possible 
training neural network usually takes quite long thorough evaluation takes large amount cpu time 

algorithms researchers available programs implementations stable exotic environment 

di cult get data real problems 

prepare data neural network training 

results obtained problem compared directly di erent problem representations di erent experimental setups 
arguments valid today 
discuss order 
really problem 
machines fast signi cant amount training runs days small moderately large datasets 
hey computer 

true 
probably easily avoid 
problem just compare results researchers directly making corresponding experiment new algorithm 

partially true 
researchers real data research willing give request 
publicly accessible collections data notably uci machine learning databases repository 

correct 
really everybody needs data preparation 
asa research community share results 

real problem comes variants experimental setups just plain wrong giving invalid results 
second experimental setups documented properly papers published making reproduction exact comparison impossible 
third documentation just looks obscure things expressed di erent ways di erent people 
need standard set conventions experiments documentation order ght problem 
see discussion need standard sets problems rules conventions applying learning algorithm evaluations 
proben meant rst step set standard benchmarks areas neural network training algorithm research 
benchmarking rules 
availability lays ground better algorithm evaluations enabling easy access example data real problems better comparability results everybody uses problems setup time reducing workload individual researcher 
aspects learning algorithms studied proben example learning speed resulting generalization ability ease user parameter selection network resource consumption 
assessed set problems xed representation aspects learning selection creation suitable problem representation 
lack standard problems widespread areas computer science 
elds standard benchmark problems exist frequently 
notable positive examples performance evaluation computing hardware compilers 
elds clear de ning reasonable set standard problems di cult task neural network training 
benchmarking rules 
clear discussion having standard set benchmark problems necessary su cient improve de facto scienti quality evaluations 
real improvement results published benchmark problems comparable reproducible 
trivial application neural network training algorithm particular problem involves signi cant number user selectable parameters various kinds dozen 
parameters published result experiment comparability results hampered 
parameters published comparability issue due fact descriptions ambiguous lacking standard terminology 
set benchmark problems complemented set benchmarking rules benchmarking conventions want describe standardize ways setting experiments documenting setups measuring results documenting results 
rules need reduce freedom choosing possible experimental setups just suggest core standard order maximize comparability experimental results show documented way deviates standard 
side ect thoroughly documented benchmarking rules reduce danger researcher major fault experimental setup producing invalid results 
scope proben neural network learning algorithm research wide eld trying tackle di erent classes problems 
sub elds vision optical character recognition speech recognition quite specialized require specialized benchmarks 
elds require forbid certain properties benchmark problem 
single set benchmark problems usable evaluation research eld 
scope proben problems characterized follows 
problems suited supervised learning input output values separated 
problems suited networks maintain internal state examples problem independent 
problems tackled pattern classi cation algorithms need capability multivariate function approximation 
problems continuous binary input values 
problems static problems sense data learn change learning 
problems mushroom problem consist real data real problem domains 
common properties learning tasks characterized call diagnosis tasks 
tasks described follows 
input attributes similar human order solve problem 

outputs represent classi cation small number understandable classes prediction small set understandable quantities 

practice problems fact solved human beings 

examples expensive get 
consequence training sets large 

attribute values missing 
scope proben rules characterized follows 
rules meant apply supervised training algorithms 
presentation biased training feed forward networks gradient descent similar algorithms 
aspects mentioned rules apply algorithms aspects relevant certain algorithms left 
rules suggest certain choices particular aspects experimental setups standard choices say report choices results experiments 
parts proben rules cover small part neural network learning algorithm research 
additional collections benchmark problems needed cover domains learning application domains vision speech recognition character recognition control time series prediction learning paradigms reinforcement learning unsupervised learning network types recurrent networks analog continuous time networks pulse frequency networks 
su cient benchmarks available today elds 
additions changes rules needed new domains learning paradigms network types 
digit included name proben day proben published eld mature 
arti cial benchmarks 
early days current era neural network research second half benchmark problems arti cial 
famous xor problem 
popularity originates fact able solve itwas great breakthrough achieved error back propagation algorithm compared situation faced rst era neural network research learning algorithm known solve linearly separable classi cation task 
training problems generalized xor problem bit parity bit encoder symmetry problem problem clumps problem 
de ciencies known problems purely synthetic strong apriori regularities structure unclear measure meaningful way generalization capabilities network respect problem problems solved correct realistic settings 
works synthetic problems exactly solved easily 
instances spirals problem discs problem 
problem problems related similar ones mentioned know priori simple exact solution exists right framework express 
unclear property uences observed capability learning algorithm network nd solution algorithms may biased kind regularity needed solution problems benchmarks algorithms having bias better realistic domains 
summing conclude main problem early arti cial benchmarks know results obtained tell behavior systems real world tasks 
way transcend limitation data generation process arti cial problems resemble realistic phenomena 
usual way replace complement data generation simple logic arithmetic formula stochastic noise processes realistic models physical phenomena 
compared real world data advantage properties dataset known making easier characterize kinds problems dataset characteristics particular algorithm works better worse 
problems left approach 
danger prefer algorithms happen biased particular kind data generation process 
imagine classi cation datasets point clouds generated multidimensional gaussian noise gaussian radial basis function classi er 
expected class models learning algorithm exactly class models employed data generation 
second unclear parameters data generation process representative real problems particular domain 
overlaying functional noise component questions answered strong non linear components function strong type non linearities components amount noise type added 
choosing wrong parameters may create dataset resemble real problem domain 
clearly arti cial datasets realistic models real data sets place algorithm development evaluation 
reason real data arti cially generated data choice guarantees get results relevant real domains ones tested 
multiple domains order increase con dence results obtained occur due particular domain selection 
related despite high importance benchmarks little done eld neural networks 
public benchmark collection available speci cally meant neural network research neural bench collection carnegie mellon university maintained scott fahlman collaborators anonymous ftp ftp cs cmu edu directory afs cs project connect bench 
created years ago contains sets data real world problems 
larger collection benchmark learning problems uci machine learning databases archive anonymous ftp ics uci edu directory pub machine learning databases 
archive maintained university california irvine patrick murphy david aha 
contains dozens problems multiple variants 
problems archive personal impression researchers consciously data generation known bias algorithm advocate order get better results 
benchmarking rules meant general machine learning programs readily learned neural networks encoding nominal attributes missing attribute values chosen rst 
collections individual datasets donated various researchers 
exceptions partitioning dataset training test data de ned archives 
case sub partitioning training data training set validation set de ned 
di erent variants exist datasets uci archive create lot confusion clear experiment 
proben benchmark collection contains datasets taken uci archive exception 
data encoded direct neural network pre partitioned training validation test examples exactly documented reproducible form 
zheng benchmark recommend everybody read include data de nes set problems predominantly uci archive benchmark collection classi er learning algorithms 
selection problems coverage taxonomy classi cation problems valued features type attributes number attributes number di erent nominal attribute values number irrelevant attributes dataset size dataset density level attribute value noise level class value noise frequency missing values number classes default accuracy entropy predictive accuracy relative accuracy average information score relative information score 
proben benchmark problems explicitly selected coverage aspects 
aspects problems collection 
benchmarking rules section describes conduct valid benchmark tests publish results 
purpose rules ensure validity results reproducibility researchers 
additional bene standardized benchmark setups results directly comparable 
general principles general principles guide formulation benchmarking rules validity need minimum standard experimentation guarantees results obtained valid sense artifacts created random factors faulty experimental setup 
invalid results useless 
proben benchmarking rules contain number dos don ts follow order avoid invalid results rules guarantee validity results 
reproducibility rules prescribe specify aspects experimental setup needed researchers repeat experiments 
results reproduced scienti results 
proben benchmarking rules attempt list relevant aspects benchmark problem benchmarking setup need published attain reproducibility 
aspects standard formulations suggested order simplify presentation comprehension 
comparability useful compare results obtained di erent researchers directly 
possible experimental setup 
rules suggest number called standard choices experimental setups recommended speci reasons stand 
standard choices reduces variability setups improves comparability results di erent publications 
rules phrases typeset sans serif font suggested formulations publications order reduce ambiguity setup descriptions 
sections proben benchmarking rules 
benchmark problem benchmark problem indicate exactly case proben problem just give name 
cases specify researchers get problem dataset 
done giving published earlier 
le containing dataset available anonymous ftp give ftp address get dataset 
prepare datasets publicly ftp possible 
problems proben just cite report 
researchers problem times refer natural language name instance test michalski soybean data 
kinds result confusion di erent versions data exist 
please refer named problem documented benchmark collection give address data le available ftp 
training set validation set test set data performing benchmarks neural network learning algorithms split parts part training performed called training data part performance resulting network measured called test set 
idea performance network test set estimates performance real 
means absolutely information test set examples test set performance network available training process benchmark invalid 
cases training data subdivided 
examples put actual training set called validation set 
pseudo test set order evaluate quality network training 
called cross validation necessary due tting overtraining phenomenon networks trained problem larger training set error may better concentrated peculiarities training set cost losing regularities needed generalization 
problem particular training examples available 
popular powerful form cross validation neural networks early stopping training proceeds minimum error training set reached minimum error validation set reached training 
training stopped point current network state result training run 
note actual procedure bit benchmarking rules complicated may local minima validation set error curve order recognize minimum train error rises resetting earlier state needed order minimum 
see section concrete description 
forms cross validation early stopping possible 
data validation set way training part training data 
actual name validation set appropriate set assess generalization performance network 
note di erentiation training data union training set validation set 
sure specify exactly examples dataset training validation test set 
insu cient indicate number examples set signi cant di erence ones 
drastic example think binary classi cation problem examples class happen training data 
proben suggested partitioning training validation test set dataset 
size training validation test set proben data les examples respectively 
note percentage information su cient exact determination sets total number examples divisible 
header proben data le lists explicitly number examples set 
assume numbers standard partitioning rst examples training set examples validation set nal examples test set 
validation set needed training set consists rst examples 
said problems small number examples results may vary signi cantly di erent partitionings see results section 
improves signi cance benchmark result di erent partitionings measurements results reported partitioning separately 
proben supports approach 
contains di erent permutations dataset 
instance problem glass available datasets glass glass glass di er ordering examples de ning di erent partitionings glass problem data 
additional partitionings completely independent ones de ned rules order examples dataset le training set validation set test set 
training set test set validation set 
validation set training set test set 
validation set test set training set 
test set validation set training set 
test set training set validation set 
list read follows partitioning say glass partitionings created re interpreting data di erent order training validation test set 
instance glass means take data le glass rst examples validation set test set nal training set 
obviously set ande available 
glass identical glass 
preferred name context 
note partitionings lower quality created permutations independent ofeach 
additional partitionings necessary cases just xx xx problem xx su ce 
want di erent partitioning standard ones proben problem specify input output representation exactly examples 
take data le order training examples validation examples test examples specify rule determine examples set 
examples glass examples training set examples test set standard order nonstandard size sets glass numbered examples training set odd numbered examples test set rst example number nonstandard size order sets 
proben conventions just say glass mention article benchmarks conform proben conventions benchmark problems taken proben benchmark set standard proben benchmarking rules applied 
imprecise speci cation partitioning known data set training validation test set probably frequent worst obstacle reproducibility comparability published neural network learning results 
input output representation represent input output attributes learning problem neural network implementation problem key decisions uencing quality solutions obtain 
depending kind problem may di erent kinds attributes represented 
attribute kinds multiple plausible methods neural network representation exist 
discuss attribute kind common methods represent attribute 
real valued attributes usually rescaled function maps value range roughly distribution range 
represented single network input range inputs topological encoding overlapping gaussian receptive elds 
proben uses single input real valued attribute rescaling function linear exception logarithm 
integer valued attributes handled real valued 
number di erent values small representations ordinal attributes may appropriate 
note attributes values integer numbers really integer valued ordinal cardinal 
proben treats integer valued attributes real valued 
ordinal attributes di erent values mapped equidistant scale making pseudo real valued represented inputs leftmost value represent th attribute value 
binary code dlog inputs 
ordinal attributes proben problems 
pseudo real valued pseudo nominal representation 
nominal attributes di erent values usually represented code binary code 
exception gene uses bit binary code proben employs representation nominal attributes 
missing attribute values replaced xed value mean non missing values attribute value em algorithm represented explicitly adding input attribute attribute value missing 
proben uses methods xed value method values missing 
methods possible extends training regime away static examples boltzmann machine 
benchmarking rules discussion applies outputs fact missing outputs 
proben problems classi cation problems encoded output representation classes 
problem representation proben xed 
improves comparability results reduces needed run benchmarks 
proben datasets meant exactly 
xed neural network input output representation major improvements proben previous situation 
past benchmarks consisting real data publicly available symbolic representation encoded representation suitable neural networks di erent ways 
fact comparisons di cult 
perform benchmarks problems de ned benchmark collection sure specify exactly input output representation 
description consumes lot space feasible way usually data le actual benchmark runs available publicly 
small changes representation proben problems benchmarks specify changes exactly 
common cases changes concerned output representation 
want single output binary classi cation problems say card output similar 
may want ignore outputs problems having classes output theoretically redundant outputs sum 
ignore output ignore output representation 
want outputs range somewhat reduced range order avoid saturation output nodes say example target outputs rescaled range 
assumed rescaling done linear transformation form ay possibilities include instance outputs rescaled mean standard deviation assumed linear transformation 
course rescaling modi cations done inputs tell 
recommend proben problems representations di er substantially standard ones nding representations important part 
input output representations proben certainly optimal meant reasonable ones 
di erences problem representation large di erences performance obtained see instance sure specify representation precisely 
training algorithm obviously exact speci cation training algorithm essential 
known algorithm specify giving describes algorithm exactly speci ed describe precisely alterations 
introduce new algorithm give algorithm name easier authors refer algorithm 
variants algorithm give name just appending digit letter primary name 
new algorithm clearly specify values free parameters algorithm 
introducing new algorithm clearly indicate prototype parameter vector including parameter names speci ed document algorithm 
common error parameter values algorithm remain unspeci ed 
error measures parameters may include depending algorithm learning rate momentum weight decay initialization temperature parameter clearly indicated unique name symbol 
parameters adaptive adaption rule parameters speci ed 
particularly important aspect training algorithm stopping criterion forget specify see section example 
user selectable parameters specify values try characterize sensitive algorithm choice 
note way performance test set searching parameter values invalidate results 
particular choosing parameters test set results error 
error measures di erent error measures called error functions objective functions cost functions loss functions network training 
commonly squared error oi ti actual output values oi th output node target output values ti example 
note researchers multiply order derivative simpler considered non standard 
measure gives error value example obviously data report 
usually reports sum average values set examples 
average called mean squared error 
advantage independent size dataset preferred 
note mean squared error depends number output coe cients problem representation range output values 
suggest normalize factors report squared error percentage follows px nx opi tpi minimum maximum values output coe cients problem representation assuming output nodes number output nodes network number patterns examples data set considered 
note networks early training phases produce squared error output nodes activation restricted range 
error measures include softmax error cross entropy classi cation gure merit linear error exponential error minimum variance error 
state error term explicitly 
idea error percentages applicable 
actual target function classi cation problems usually continuous error measure training classi cation performance 
neural networks continuous outputs able approximate posteriori probabilities useful network outputs processing steps classi cation performance measure 
space permits report actual error values addition classi cation performance 
classi cation performance reported percent incorrectly classi ed examples classi cation error 
better reporting percentage correctly classi ed examples classi cation accuracy important di erences insu ciently clear accuracy twice easier see errors reported compared 
classi cation accuracy far far accuracy better report error factor error function correct derivative large usually formulations backpropagation 
common derivative amounts halved learning rates 
benchmarking rules uncommon case 
avoid term classi cation performance classi cation accuracy classi cation error 
possibilities determine classi cation network computed outputs network 
assume encoding classes output values 
simplest classi cation method winner takes output highest activation designates class 
methods involve possibility rejection 
instance require exactly output larger designates class exists leads rejection 
put stronger requirement credibility network output set thresholds accept output reject exactly output interpretation 
possibilities 
rejection capability needed winner takes method considered standard 
cases describe classi cation decision function explicitly 
network specify exactly topology neural benchmark test 
topology network described graph nodes units vertices neurons connections weights edges synapses 
avoid terms neuron synapse inappropriate arti cial neural networks 
term weight refer parameter attached connection connection 
describe topology try refer common topology models 
instance common case called fully connected layered feed forward networks numbers nodes layer input output sequence network refers network input hidden output nodes 
confusion number layers network call network layer network counting groups nodes layer network counting groups nodes input connections 
call network hidden layer 
generalizes arbitrary numbers layers 
instance hidden layer network 
specifying number nodes su cient fully connected networks term people mean connections adjacent layers mean connections skip intermediate layers shortcut connections 
formulations feed forward connections adjacent layers feed forward connections including shortcut connections complement speci cation size layers 
examples network feed forward connections including shortcut connections networks hidden layer having hidden nodes feed forward connections adjacent layers 
networks bias threshold hidden output nodes 
bias implemented incoming connection node constant non zero output bias node adaptable parameter node activation function 
style implementation usually irrelevant networks bias exception bias need mentioned 
nodes bias specify 
note compute number free parameters network bias parameter hidden output node included 
may confuse reader mention bias case 
recurrent networks standard names elman network appropriate back explanation 
non standard network topologies non standard network models networks shared weights described detail 
training results properties network architecture speci ed range resolution weight parameters plain bit oating point activation function node network input nodes assumed identity function see section free parameters associated network 
training results usually interested training neural network generalization performance 
value usually characterize generalization performance error test set 
test set set examples way whatsoever training process see section 
test set error primary result learning problem 
corresponding errors training validation set marginal interest need reported 
training neural network usually involves kind random initialization results training runs algorithm dataset di er 
order reliable statements performance algorithm necessary runs report statistics distribution results obtained 
possible runs runs power numbers researchers numbers runs direct comparisons easier 
numbers don appropriate reason try runs power numbers 
commonly statistics report results runs primarily mean standard deviation test set error test set classi cation error best run see secondarily minimum maximum median data shall quartiles ne grained distribution histogram 
meaning best run result characterize get method model selection trained networks picked looked best 
contrast statistics characterize quality expect trains just network 
selection best run results test set mean test set error model selection process test set error conceptually result model selection process 
training set error validation set error quality measure computed exclusively network training data 
means best network minimum test error 
instance selection criterion validation set error report network lowest validation set error runs test set classi cation error 
reason want exclude runs results instance runs considered converged may mean exclude exactly half runs 
allows easier comparison results researchers 
runs excluded worst runs inverse sense best exclude runs worst test set error 
may want apply methods statistical inference training results instance order test algorithm signi cantly better 
case may necessary remove small number outliers samples compared order data satisfy requirement statistical procedure 
instance order apply test samples compared normal distribution 
sample say test errors runs approximately normal say outliers larger smaller errors standard deviation computed degrees freedom number runs 
benchmarking rules rest remove outliers sample 
remove values sample usually remove 
remove outlier resulting distribution satis es requirement 
data transformations removing outliers may appropriate satisfy requirements statistical procedure instance test errors log normally distributed logarithm test error test error order produce valid results 
see section 
training times algorithm perform lot additional propagating data neural network sensible measure training time number connection traversals connection crossings misleadingly called connection updates needed 
measure useful independent particular machine implementation 
forward backward propagation counts individually certain algorithms require quantity tobe propagated connection quantity counts traversal connection 
actual weight update steps count traversal updated connection 
possible report training times connection traversal measure 
algorithm performs traversing network actual cpu time spent best measure give 
disadvantage measure leaves free parameters speed machine ciency software implementation 
measure directly comparable software machine 
reporting cpu times give precise brand model number machine nominal performance spec marks give hint software regarded cient cient 
cpu time certainly useful gure computational size tackled problem 
useful measure number epochs number times example processed 
value misleading computational cost epoch di er signi cantly algorithm network 
ne epoch counts addition measures 
regarding non converging runs values report re ect actual amount computation time spent 
means algorithm de ne stopping restarting criterion sum computation performed restart reported training time 
important report precise stopping restarting criterion 
important details important details forgotten shortly mentioned 
activation function 
exactly specify activation function nodes units network 
say standard sigmoid mean say tanh mean standard choices 
activation functions explicitly 
specify output nodes network activation function identity function 
nodes input layer fan nodes perform computation input values specify computation 
author quick network initialization 
specify initialization conditions network 
important point initialization network weights done random values algorithms order break symmetry hidden nodes 
common choices initialization instance xed methods weights range distribution assumed stated methods adapt network topology random weights range connections nodes input connections 
just termination criterion initialization signi cant impact results obtained important specify precisely 
specifying exact sets weights hopelessly di cult usually tried 
termination phase transition criteria 
specify exactly criteria determine training training switch phase 
algorithms results sensitive criteria 
publications criteria speci ed roughly 
major weaknesses articles neural network learning algorithms 
see section example report stopping criteria gl family stopping criteria de ned section recommended early stopping method 
author quick quick check mentioned publication reporting benchmark test 
remember peculiar points listed may apply additionally particular benchmarks want report 

problem name address version variant 

training set validation set test set 

network nodes connections activation functions 

initialization 

algorithm parameters parameter adaption rules 

termination phase transition restarting criteria 

error function normalization results reported 

number runs rules including excluding runs results reported 
benchmarking problems subsections describe problems proben benchmark set 
problem rough description semantics dataset plus information size dataset origin special properties 
problems results previously published literature 
results exactly representation training set test set splitting proben versions documentation supplied original dataset part proben 
nal section reports results learning runs proben datasets 
benchmarking problems classi cation problems cancer diagnosis breast cancer 
try classify tumor benign malignant cell descriptions gathered microscopic examination 
input attributes instance clump thickness uniformity cell size cell shape amount marginal adhesion frequency bare nuclei 
inputs outputs examples 
inputs continuous examples benign 
entropy bits example dataset created breast cancer wisconsin problem dataset uci repository machine learning databases 
please mention publication presenting results data set data originally obtained university wisconsin hospitals madison dr william wolberg 
please cite publications mentioned detailed documentation original dataset proben cancer directory 
card predict approval non approval credit card customer 
example credit card application output describes bank similar institution granted credit card 
meaning individual attributes unexplained con dence reasons 
inputs outputs examples 
dataset mix attributes continuous nominal small numbers values nominal larger numbers values 
missing values examples 
examples positive entropy bits example 
dataset created crx data credit screening problem dataset uci repository machine learning databases 
diabetes diagnose diabetes pima indians 
personal data age number times pregnant results medical examinations blood pressure body mass index result glucose tolerance test try decide pima indian individual diabetes positive 
inputs outputs examples 
inputs continuous 
examples diabetes negative entropy bits example 
missing values dataset documentation values 
probably indicate missing data 
handle data real introducing errors noise want dataset 
dataset created pima indians diabetes problem dataset uci repository machine learning databases 
entropy classes log class probabilities classi cation problems gene detect intron exon boundaries splice junctions nucleotide sequences 
window dna sequence elements nucleotides decide middle intron exon boundary donor exon intron boundary acceptor 
inputs outputs examples 
nucleotide valued nominal attribute binary binary inputs input values inputs declared boolean 
dataset input values restricted range 
donors acceptors dataset entropy bits example 
dataset created splice junction problem dataset uci repository machine learning databases 
glass classify glass types 
results chemical analysis glass percent content di erent elements plus refractive index classify sample oat processed non oat processed building windows vehicle windows containers head lamps 
task motivated forensic needs criminal investigation 
inputs outputs examples 
inputs continuous hardly correlation result 
number examples quite small problem sensitive algorithms waste information 
sizes classes instances respectively entropy bits example 
dataset created glass problem dataset uci repository machine learning databases 
heart predict heart disease 
decide major vessels reduced diameter 
binary decision personal data age sex smoking habits subjective patient pain descriptions results various medical examinations pressure electro results 
inputs outputs examples 
attributes missing values quite attributes values missing respectively 
attributes missing values 
additional boolean inputs represent values 
data union datasets cleveland clinic foundation hungarian institute cardiology medical center long beach university hospital zurich 
alternate version dataset heart called heartc contains cleveland data examples 
dataset represents cleanest part heart data missing attribute values value missing inputs neural network input representation redundant 
furthermore versions data heartac corresponding heart heartc respectively 
di erence datasets described representation output 
binary outputs represent decision vessel reduced vessel reduced heartac single continuous output represents magnitude activation reduced zero 
versions heart problem approximation tasks 
benchmarking problems heart datasets patients vessel reduced entropy bits example heartc heartac value entropy bit example 
datasets created heart disease problem datasets uci repository machine learning databases 
note datasets requires include publication results name institutions persons collected data rst place hungarian institute cardiology budapest university hospital zurich switzerland william university hospital basel switzerland matthias medical center long beach cleveland clinic foundation robert ph mentioned heart datasets heartc heartac datasets 
see detailed documentation original datasets proben heart directory 
horse predict fate horse colic 
results veterinary examination horse having colic predict horse survive die 
inputs outputs examples 
examples horse survived died itwas entropy bits example 
problem missing values original attribute values represented missing explicitly additional inputs 
dataset created horse colic problem dataset uci repository machine learning databases 
mushroom discriminate edible poisonous mushrooms 
decision description mushroom shape color odor habitat 
inputs outputs examples 
attribute missing values missing 
dataset special benchmark set respects inputs examples easiest real sense examples actual observations real world hypothetical observations descriptions species book society field guide north american mushrooms 
examples correspond species mushrooms family 
book species identi ed de nitely edible de nitely poisonous unknown recommended 
class combined poisonous 
examples edible mean class attribute edible entropy bit example 
dataset created dataset mushroom directory uci repository machine learning databases 
mushroom dataset simple net performs linear combination inputs learn reliably classi cation error test set 
approximation problems soybean recognize di erent diseases 
discrimination done description bean size color normal plant size spots leafs spots halo plant growth normal roots plus information history plant life changes crop occurred year years seeds treated environment temperature 
inputs outputs examples 
problem highest number classes benchmark set 
attributes signi cant number missing values 
soybean problem machine learning literature di erent datasets making comparisons di cult 
past uses classes instances 
dataset instances versus classes entropy bits example 
dataset created soybean large problem dataset uci repository machine learning databases 
results learning problem reported literature large number di erent versions data 
thyroid diagnose thyroid hyper 
patient query data patient examination data task decide patient thyroid normal function 
inputs outputs examples 
various attributes missing values encoded separate input 
results dataset encoding reported literature thyroid original data retains original order 
class probabilities respectively entropy bits example 
dataset created ann version thyroid disease problem dataset uci repository machine learning databases 
summary quick overview classi cation problems look table 
table summarizes external aspects training problems seen individual descriptions 
discriminate inputs take di erent values binary inputs inputs continuous inputs inputs indicate values inputs missing 
addition table indicates number attributes original problem formulation input representation discriminated binary attributes continuous attributes nominal attributes values 
approximation problems building prediction energy consumption building 
try predict hourly consumption electrical energy hot water cold water date time day outside temperature outside air humidity solar radiation wind speed 
benchmarking problems problem problem attributes input values classes examples tot 
tot 
cancer card diabetes gene glass heart heartc horse mushroom soybean thyroid problems number binary continuous nominal attributes original dataset number binary continuous network inputs number network inputs represent missing values number classes number examples class entropy bits example 
continuous means di erent ordered values 
table attribute structure classi cation problems inputs outputs examples 
problem original formulation extrapolation task 
complete hourly data consecutive months training output data months predicted 
dataset building re ects formulation task examples chronological order 
versions building building random permutations examples simplifying problem interpolation problem 
dataset created problem great energy predictor rst building data analysis prediction problem contest organized ashrae meeting denver colorado 
flare prediction solar ares 
try guess number solar ares small medium large size happen hour period xed active region sun surface 
input values describe previous activity type history active region 
inputs outputs examples 
examples zero output values 
dataset created solar problem dataset uci repository machine learning databases 
analog version heart disease diagnosis problem 
see section page description 
examples vessels reduced respectively 
heartac values 
learning results summary quick overview approximation problems look table 
table summarizes problem problem 
input values outputs examples tot 
tot 
building heartac problems number binary continuous nominal attributes original problem representation number binary continuous network inputs inputs represent missing values number outputs number examples 
continuous means di erent 
table attribute structure approximation problems external aspects training problems seen individual descriptions 
discriminate inputs take di erent values binary inputs inputs continuous inputs inputs indicate values inputs missing 
addition table indicates number attributes original problem formulation input representation discriminated binary attributes continuous attributes nominal attributes values 
outputs continuous values 
learning results section see results neural network learning runs datasets described 
runs linear networks having direct connections inputs outputs various fully connected multi layer perceptrons layers sigmoidal hidden nodes 
method applied training cases summarized follows training performed rprop algorithm parameters indicated 
rprop fast backpropagation variant similar spirit quickprop 
fast quickprop requires adjustment parameters stable 
parameters determined trial error search just educated guesses 
rprop requires epoch learning weights updated epoch 
epoch updates desirable large training sets method small medium training sets proben allows acceleration techniques rprop 
conjugate gradient optimization methods class useful algorithms kind training problems 
squared error function 
dataset training training set error validation set measured fth epoch interval measurements validation set error called strip length see 
training stopped soon gl stopping criterion ful lled see training progress see maximum epochs trained 
test set performance computed state network minimum validation set error training process 
benchmarking problems method called early stopping tting network particular training examples reduce generalization performance 
optimal performance examples validation set training order waste valuable data 
optimal stopping point additional training clear performed experiments reported 
gl stopping criterion de ned follows 
squared error function 
etr average error example training set measured epoch eva error validation set epoch stopping criterion 
ete error test set known training algorithm characterizes quality network resulting training 
value validation set error obtained epochs min eva de ne generalization loss epoch relative increase validation error minimum far percent gl eva high generalization loss candidate reason training 
leads class stopping criteria soon generalization loss exceeds certain threshold de ne class gl gl rst epoch gl formalize notion training progress de ne training strip length sequence epochs numbered divisible training progress measured parts measured training strip pk etr mint etr average training error strip larger minimum training error strip 
note progress measure high instable phases training training set error goes 
progress guaranteed approach zero long run training globally unstable oscillating 
just progress gl evaluated training strip 
linear networks rst set results shown tables classi cation problems approximation problems 
tables contain results runs training linear neural network datasets 
network hidden nodes just direct connections input output 
output units identity activation function output just summed input 
rprop algorithm parameters randomly weight max min initial weights randomly 
training terminated gl stopping criterion strip length epochs 
results training runs give rst impression di cult problems 
interesting observations learning results problem training validation test test set total relevant set set set classi cation epochs epochs mean stddev mean stddev mean stddev mean stddev mean stddev mean stddev mean stddev cancer cancer cancer card card card diabetes diabetes diabetes gene gene gene glass glass glass heart heart heart heartc heartc heartc horse horse horse mushroom soybean soybean soybean thyroid thyroid thyroid training set mean standard deviation stddev minimum squared error percentage training set reached time training 
validation set ditto validation set 
test set mean stddev squared test set error percentage point minimum validation set error 
test set classi cation mean stddev corresponding test set classi cation error 
mean stddev gl value training 
total epochs mean stddev number epochs trained 
relevant epochs mean stddev minimum validation error 
table linear network results classi cation problems benchmarking problems problem training validation test total relevant set set set epochs epochs mean stddev mean stddev mean stddev mean stddev mean stddev mean stddev building building building heartac heartac heartac explanation table applies test set classi cation error data 
table linear network results approximation problems 
problems sensitive tting 
heavily linear network card card glass glass heartac heartac heartc heartc horse horse horse 
suggests cross validation technique early stopping useful proben problems 

problems quite large di erences behavior permutations dataset test errors card heartc heartac training times heartc tting glass 
illustrates dangerous compare results splitting data training test data 

problems solved pretty linear network 
aware real neural network 

mushroom problem boring 
single run 
reached zero test set classi cation error epochs zero validation set error epochs 
training stopped epoch limit errors fell fell fell 
due results mushroom problem excluded experiments 
mushroom problem may wants explore scaling behavior algorithm respect training examples 

problems exhibit interesting inverse behavior errors 
validation error lower minimum training error cancer cancer card card heart heartc thyroid thyroid 
cases extends test error cancer thyroid 
choosing multilayer architectures baseline comparison number runs multilayer networks sigmoidal hidden nodes 
problem di erent network topologies networks hidden nodes hidden layer networks hidden nodes rst second hidden layer respectively 
networks possible feed forward connections including shortcut connections 
sigmoid activation function jxj 
learning results topologies runs performed linear output nodes output nodes sigmoidal activation function 
note case sigmoid output nodes perform sided squashing outputs sigmoid range target output range 
parameters rprop procedure runs randomly weight max min initial weights randomly 
exchanging parameter set linear networks di erence 
training stopped epochs trained condition satis ed gl stopping criterion ful lled validation error increased successive strips quotient gl larger tables tables topology results network produced lowest validation set error runs dataset 
tables contain indication performance topologies giving number runs worse best run respect validation set error 
range test set errors obtained topologies indicated 
architectures tables probably optimal ones considered set runs 
due small number runs architecture problem suboptimal architecture decent probability producing lowest validation set error just chance 
experience early stopping method suggests network considerably larger necessary leads best results 
consequence architectures table shown table computed results runs suggested architectures various datasets training fully connected multi layer perceptrons 
architectures called pivot architectures respective problems 
rule computing architecture pivot architecture uses runs best category candidates 
largest architecture chosen 
largest topology appear candidates linear sigmoidal output units smaller validation set error chosen linear architecture appears twice case preferred regardless validation set error 
raw data architecture selection listed appendix noted pivot architectures necessarily 
particular problems appropriate train networks shortcut connections order networks smaller number parameters 
instance glass problems shortcut connections amount weights needed complete network hidden nodes shortcut connections 
problem examples training set may idea start shortcut connections 
similar argumentation applies problems 
furthermore pivot architectures largest architectures available selection runs networks hidden nodes may produce superior results problems 
section presents results multiple runs pivot architectures subsequent section presents results multiple runs architectures shortcut connections 
multilayer networks tables classi cation problems approximation problems show results training pivot architectures 
variant ofeach problem runs performed 
training reason complicated criterion set runs investigate behavior benchmarking problems problem arch validation set test set epochs test range err classif err err classif err cancer cancer cancer card card card diabetes diabetes diabetes gene gene gene glass glass glass heart heart heart heartc heartc heartc horse horse horse soybean soybean soybean thyroid thyroid thyroid arch nodes rst hidden layer nodes second hidden layer sigmoidal linear output nodes best network network run lowest validation set error 
validation set squared error percentage validation set classi cation error validation set best run missing values due technical historical reasons 
test set squared error percentage test set classi cation error test set best run 
number runs validation squared error percent worse best run shown second column 
ditto worse 
epochs range trained best run percent best runs 
test range range squared test set error percentages percent best runs excluding best run 
table architecture nding results classi cation problems learning results problem arch validation set test set epochs test range building building building heartac heartac heartac explanation table applies test set classi cation error data 
table architecture nding results approximation problems problem pivot arch problem pivot arch problem pivot arch building building building cancer cancer cancer card card card diabetes diabetes diabetes gene gene gene glass glass glass heart heart heart heartac heartac heartac heartc heartc heartc horse horse horse soybean soybean soybean thyroid thyroid thyroid pivot architecture corresponding number connections data set 
table pivot architectures datasets parameters linear networks indicated section 
interesting observations please compare discussion linear network results section 
results problems worse obtained linear networks 
notable gene problems severe horse problems ofthe heart disease problems 

surprisingly standard deviations validation test set errors tendency higher linear networks cases 

correlation validation set errors test set errors quite small problems cancer card glass heartac heartc horse horse soybean 
di erent stopping criteria 
results reported 
benchmarking problems problem training validation test test set total relevant set set set classi cation epochs epochs mean stddev mean stddev mean stddev mean stddev mean stddev mean stddev mean stddev cancer cancer cancer card card card diabetes diabetes diabetes gene gene gene glass glass glass heart heart heart heartc heartc heartc horse horse horse soybean soybean soybean thyroid thyroid thyroid training set mean standard deviation stddev minimum squared error percentage training set reached time training 
validation set ditto validation set 
test set mean stddev squared test set error percentage point minimum validation set error 
correlation validation set error test set error 
test set classi cation mean stddev corresponding test set classi cation error 
mean stddev gl value training 
total epochs mean stddev number epochs trained 
relevant epochs mean stddev minimum validation error 
table pivot architecture results classi cation problems learning results problem training validation test total relevant set set set epochs epochs mean stddev mean stddev mean stddev mean stddev mean stddev mean stddev building building building heartac heartac heartac explanation table applies test set classi cation error data 
table pivot architecture results approximation problems cases slightly negative card heartac 

correlation value di ers dramatically variants problems card heartac heartc horse 

low correlation necessary imply bad test error results see cancer card heartac horse 

training times exhibit dramatic uctuations cases building gene gene thyroid severely cancer cancer diabetes glass glass thyroid thyroid 

numbers training epochs tend order linear networks exceptions faster heart disease problems slower thyroid building building 

inverse error behavior observed linear networks longer cancer cancer card 
mentioned problems appropriate shortcut connections 
quantify ect training shortcut connections series runs dataset conducted parameters 
time network architecture modi ed include connections adjacent layers direct connections inputs outputs networks hidden layers connections inputs second hidden layer rst hidden layer outputs 
call architectures shortcut architectures 
results runs shown tables classi cation problems approximation problems 
interesting observations compare discussions linear network pivot architecture results 
leaving shortcut connections appropriate expected see section 

test error results gene problems better linear networks pivot architectures worse linear networks 
classi cation errors worse pivot architectures 
benchmarking problems problem training validation test test set total relevant set set set classi cation epochs epochs mean stddev mean stddev mean stddev mean stddev mean stddev mean stddev mean stddev cancer cancer cancer card card card diabetes diabetes diabetes gene gene gene glass glass glass heart heart heart heartc heartc heartc horse horse horse soybean soybean soybean thyroid thyroid thyroid explanation table applies table shortcut architecture results classi cation problems 
test error results horse problems improved worse linear networks 

correlations validation test error di erent pivot architectures see example card glass heartac 

correlation lower standard deviations test errors smaller compared pivot architectures 
learning results problem training validation test total relevant set set set epochs epochs mean stddev mean stddev mean stddev mean stddev mean stddev mean stddev building building building heartac heartac heartac explanation table applies test set classi cation error data 
table shortcut architecture results approximation problems comparison multilayer results table shows comparison pivot architecture shortcut architecture results 
comparison performed ttest procedure sas statistical software problem building cancer card diabetes gene glass heart heartac heartc horse soybean thyroid results statistical signi cance test performed di erences mean logarithmic test error pivot architectures shortcut architectures 
entries show di erences signi cant ona con dence level plus corresponding value percent letter indicates architecture better 
dashes indicate non signi cant di erences 
parentheses indicate unreliable test results due non normality samples 
test employed test cochran cox approximation unequal variance case 
data points removed outliers 
table test comparison pivot shortcut results package 
test assumes samples compared normal distributions logarithm test errors compared test errors test errors usually approximately log normal distribution 
logarithmic transformation change test result logarithm strictly monotone log normal distributions occur quite log transformations common statistical technique 
assumption test equal variance samples cochran cox approximation unequal variance availability proben case sample pairs cancer gene standard deviations di ered factor 
furthermore outliers removed order achieve approximate normal distribution log errors runs pivot architectures outliers low errors high errors 
shortcut architectures outliers low errors outliers high errors 
altogether outliers 
outliers removed single sample heartac heartc pivot horse shortcut 
samples deviated signi cantly log normal distribution results test unreliable interpreted care 
pivot architectures nonnormal samples building gene gene shortcut architectures building gene heartac soybean 
outliers removed non normal samples 
respective test results shown parentheses table order indicate unreliable 
discussion demonstrates important carefully applying statistical methods neural network training results 
applied statistical methods produce results may impressive fact just garbage 
sample pairs signi cant di erence test set errors con dence level signi cance level 
cases pivot architecture better cases shortcut architecture better 
result suggests search network architecture may problems architectures candidate architectures shortcut connections just removing shortcut connections probably best way improve 
summing network architectures performance gures provide starting point exploration comparison proben benchmark collection datasets 
noted results validation set training 
surely improvements results possible validation set training suitable way 
properties benchmark problems diverse proben useful basis improved experimental evaluation neural network learning algorithms 
hopefully similar collections follow 
availability proben proben benchmark set including report available anonymous ftp neural bench archive carnegie mellon university machine ftp cs cmu edu directory afs cs project connect bench contrib prechelt machine ftp ira uka de directory pub neuron 
le name cases proben tar gz 
le contains complete directory tree including data documentation techreport 
size le mb unpacked proben benchmark set needs mb disk space 
actual data les consume mb 
report available anonymous ftp machine ftp ira uka de directory pub papers techreports le ps original datasets proben datasets included tar les 
sources uci machine learning databases repository energy predictor maintained scott fahlman collaborators 
service 
le gnu gzip ed unix tar format le 
gnu gzip compression utility needed uncompress 
archive 
uci machine learning databases repository available anonymous ftp machine ics uci edu directory pub machine learning databases 
archive maintained university california irvine patrick murphy david aha 
valuable service 
databases donated various researchers 
see documentation les individual dataset directories details 
building problem energy predictor archive cs colorado edu directory pub energy 
publish article proben great dropped note prechelt ira uka de 
structure proben directory tree proben directory tree results unpacking archive le structure 
top directory called proben readme le quick overview doc subdirectory scripts subdirectory subdirectory problem named problem 
doc directory contains report tex dvi le postscript le 
scripts directory contains number small perl scripts preparation datasets 
include proben distribution people want generate additional datasets proben le format want representation original proben problems 
scripts needed normal proben datasets 
problem subdirectory problem xx contains les readme gives overview les directory plus short description attribute encoding proben representation problem compared original representation 
xx dt xx dt dt actual data les 
di erence examples di erent order random permutation building thyroid 
raw cod perl script convert original data le proben data le 
script de nitive documentation problem representation respect original data 
problems heart heartac heartc directory heart 
proben le format data encoding data le looks example glass dt bool real bool real training examples validation examples test examples data lines deleted architecture ordering line header lines represents example rst examples training set validation set test set 
sizes sets header lines partitioning total number examples 
rst header lines describe number input coe cients output coe cients example 
boolean coe cient represented false true 
real coe cient represented decimal number 
datasets bool real bool real 
coe cients separated multiple spaces examples including terminated single newline character 
line input coe cients follow output coe cients bool real bool real coe cients 
lines quite long 

encoding data les inputs outputs scaled range 
scaling chosen range completely examples occurring dataset 
gene datasets exception binary inputs encoded 
architecture ordering list gives problem order architectures increasing squared test set error 
architectures tried listed section listed test set error larger smallest test set error run 
architectures linear output units occur twice runs run considered separately 
building 
building 
building 
cancer 
cancer 
cancer 
card 
card 
card 
diabetes 
diabetes 
diabetes 



gene 
gene 
gene 
glass 
glass 
glass 
heart 
heart 
heart 



heartac 
heartac 
heartac 
heartc 
heartc 
heartc 
horse 
horse 
horse 
soybean 
soybean 
soybean 
thyroid 
thyroid 
thyroid 
yann le cun john denker sara solla 
optimal brain damage 
pages 
dietterich bakiri 
error correcting output codes general method improving multiclass inductive learning programs 
proc 
th national conference cial intelligence aaai pages anaheim ca 
aaai press 
scott fahlman 
empirical study learning speed back propagation networks 
technical report cmu cs school computer science carnegie mellon university pittsburgh pa september 
scott fahlman christian lebiere 
cascade correlation learning architecture 
technical report cmu cs school computer science carnegie mellon university pittsburgh pa february 
scott fahlman christian lebiere 
cascade correlation learning architecture 
pages 
william ferdinand hans georg zimmermann 
improving model selection methods 
neural networks 
stuart geman elie bienenstock rene doursat 
neural networks bias variance dilemma 
neural computation 
michael jordan robert jacobs 
hierarchical mixtures experts em algorithm 
neural computation 
lang waibel hinton 
time delay neural network architecture isolated word recognition 
neural networks 
lang witbrock 
learning tell spirals apart 
proc 
connectionist summer school 
morgan kaufmann 
martin ller 
scaled conjugate gradient algorithm fast supervised learning 
neural networks june 
morgan bourlard 
generalization parameter estimation feedforward nets experiments 
pages 
michael mozer paul smolensky 
skeletonization technique trimming fat network relevance assessment 
pages 
steven nowlan geo ry hinton 
simplifying neural networks sharing 
neural computation 
lutz prechelt 
study experimental evaluations neural network learning algorithms current research practice 
technical report fakultat fur informatik universitat karlsruhe karlsruhe germany august 
anonymous ftp pub papers techreports ps ftp ira uka de 
michael richard richard lippmann 
neural network classi ers estimate bayesian posteriori probabilities 
neural computation 
martin riedmiller heinrich braun 
direct adaptive method faster backpropagation learning rprop algorithm 
proceedings ieee international conference neural networks sanfrancisco ca april 
ieee 
david rumelhart john mcclelland editors 
parallel distributed processing explorations microstructure volume volume 
mit press cambridge ma 
steen sj 
approach generalisation dynamic neural networks 
phd thesis aarhus university aarhus 
brian harold 
energy functions minimizing misclassi cation error minimum complexity networks 
neural networks 
david touretzky editor 
advances neural information processing systems san mateo california 
morgan kaufman publishers david touretzky editor 
advances neural information processing systems san mateo california 
morgan kaufman publishers zheng 
benchmark classi er learning 
technical report tr basser department computer science university sydney australia november 
anonymous ftp ftp cs su oz au pub tr 
