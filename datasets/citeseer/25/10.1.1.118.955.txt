implement free interaction wall mounted display meredith computer science department brown university providence ri cs brown edu describe free handed interaction technique user control invocation system commands tools touch screen touching distinct hand postures 
screen infrared ir illumination video camera ir filter enable back projected smartboard commercially available touch sensing display identify respond distinct hand postures 
provides natural quick method interacting large wall mounted interactive surfaces 
keywords interaction technique user interface hand posture infrared image processing region growing smartboard interactive workspaces touch interaction interaction tool 
part project develop pervasive computing environment created interactive workspace integrates variety devices including laptops pdas large displays vertical wall mounted horizontal tabletop 
research focus providing integration system user interaction levels information interfaces associated user task particular device surface 
addresses issue effective interaction large touch sensitive surfaces employing hand posture recognition techniques 
key design criterion environment provide support variety devices existing modes henry berg jin terry winograd computer science department stanford university stanford ca winograd cs stanford edu interaction applications standard gui interfaces windows palmos 
expect real applications developed require special recoding environment 
time want support additional interactions current systems 
include device augmentation providing equivalent keyboard shortcuts non keyboard touch screen multi device actions bringing web page application screen interaction occurs pointing device laptop control cursor wall screen meta screen actions marking desktop display space global interactions global copy paste allows objects moved device 
environment control actions turning projectors re mapping input sources challenge add consistent uniform way create confusion 
approach create provides affordances actions allowing user interact normally underlying interfaces 
order underlying interface actions need distinguish kind action user intends 
done temporal modes user switches back forth interface mode spatial modes areas display support actions support interface actions physical modes holding button mode specific physical tool 
problems created temporal modes widely discussed hci literature exacerbated mu lti device multi user setting 
keeping track surface mode source confusion error 
spatial modes activity separated example controller lights projectors appears separate area screen actions require located application area freehand markup global copy paste 
physical modes extensively standard gui environments devices mouse multiple buttons keyboard modifiers shift ctrl 
physical modes avoid confusion temporal modes user directly aware mode effect pressed held 
bare hand touch screen interaction key component space wall adjacent back projected commercially available wall mounted touch sensitive displays 
users integrate individual devices pdas laptops connected wireless lan multiple people standing 
normally display standard windows desktop boards combined desktop covering 
users able run windows applications desirable tasks 
experience year boards recognized strong appeal direct hands manipulation implements 
smartboard provides set whiteboard tools see discussion users performing simple interactions touching finger board 
fact tried adjacent front projected wall touch sensors 
decided explore possibilities mechanisms provide appropriate interaction interface require user hold separate implements 
touch smartboard touch screen interpreted standard software left mouse click 
simultaneous touch multiple points interpreted single mouse click coordinates corresponding roughly center contact points 
achieve affordances ordinary workstations add limited form smartboard designers added temporal physical modes 
right button click implemented temporal mode requires user press physical button tray bottom righthand edge smartboard 
touch interpreted right mouse way indicate position button click affordances tool tips 
addition standard gui functionality smartboard accompanying software provide electronic whiteboard capabilities freehand geometrical markup display surface separate physical devices modeled conventional whiteboard marker pens 
number problems tools wanted see done tool free hands mechanism 
touch screen hardware identifies single center gravity point contact users easily produce different hand postures touching single finger multiple fingers side palm hand 
uses postures physical modes allowing touch trigger actions depending posture 
dynamic mapping allows posture mapped available actions including basic os interaction left button right button interaction markup global actions 
current stage experimentation established optimal mappings 
facilitate experimentation developed mapping interface allows posture mapped available actions including whiteboard tools windows events left right mouse click windows commands cut copy paste 
extend set distinguishable actions mapping posture invoke commercial system allows arbitrary number different screen dimensional gestures mapped desired actions 
research goal explore space hand postures gestures identify ones best suited different aspects interface 
previous developed sony computer science laboratory tokyo allows object recognition translucent wall surface 
ir illumination camera wall detect hands inanimate objects touching surface 
holding object wall may trigger associated system response projecting video wall response touching box 
special purpose device integrated standard displays interaction modes 
extended visual object tracking technique detect hand touched display classify touch categories 
currently system accurately identifies distinct postures finger fingers vertical edge horizontal edge entire palm 
users may map hand configurations windows commands left mouse button right mouse button cut copy paste smartboard whiteboard projection camera lighting setup side view 
infrared led arrays pulsed coordination camera shutter illuminate rear board including objects reflect light near front side 
camera records image analysis 
tools pen eraser rectangle tool ellipse tool line tool 
invoking selection tool available windows taskbar time 
touch example mapped send right mouse click right click message handled application window touch occurred 
similarly mapping ctrl hand postures ctrl user copy paste item simply touching screen twice copy posture paste posture 
allows easily integrate freeware gesture recognition tool system 
provides functionality recognizing responding different shapes drawn right mouse button held 
map posture fingers example mean right mouse button allows quickly intuitively augment interaction space 
alternative method sensing hands display laser 
recognition system produced paradiso able hand position way controlling audio output attempt hand postures distinguish actions sensing method difficult distinguish postures 
front view setup seen rear projection screen 
side displaced arrays spread lighting avoid direct reflection screen camera 
projector back reflection minimal vertically displaced projector ir cutoff filter 
rehg kanade camera front display surface analyze dimensional configuration hand 
kinematic modeling techniques model multiple degrees freedom hand configuration control dimensional dof mouse 
technique general efficiency accuracy range practical application 
issues related working large display surfaces addressed german national research center information technology gmd dynawall project part land endeavor 
system takes advantage touch sensitive nature smartboard translating certain pen motions shuffle throw messages move windows remote area display 
adopting spatial mode mechanism motions special handle portion icons displayed beach software framework developed specifically land project 
touching handle beach system icons trigger take action version traditional cut paste 
dynawall underlying infrastructure specially tailored beach system built top standard windows operating platform 
implementation order obtain images user hand touches display illuminate rear screen pair ir led arrays approximately board user touches smartboard vertical edge posture 
current recognized postures finger fingers vertical edge horizontal edge palm 
containing twelve rows mw str sli cp leds pulsed ma 
centered light sources approx board marshall video camera resolution pixels ir filter mm lens specially adjusted focus ir light figures 
standard video digitizing card capture image camera 
ir light led arrays reflected rear screen picked camera 
hand touches front display reflects additional ir light perceived camera region increased intensity illustrated figures 
initially constructed led arrays provide continuous illumination disabled camera shutter 
meant maximum continuous current allowed leds limited amount light 
protection ambient ir light 
solve problems modified arrays adjustable pulse 
built lighting control box analyzes video signal camera extracts shutter timing information necessary synchronize flash light camera electronic shutter 
presently flash arrays simultaneously designed control box allow independent field field control array support 
image processing user touches display identify pixels video image correspond hand camera image user hand rear board 
image processed produce characteristics area vertical ratio perimeter area ratio posture recognition 
examining pixels grayscale intensity filtering random noise 
take advantage touch sensing smartboard reduce image processing overhead 
receive continual input video camera analyze frames video occur immediately receive contact event smartboard driver 
contact event intercepted sent windows left mouse click event smartboard software default response touch 
able avoid processing entire image coordinates associated contact event seed region growing 
pixels fixed radius seed examined grayscale intensity similar seed included region 
process repeated exploring fixed radius new pixel near region contact 
allows detection contact regions discontinuities contact fingers spaced slightly apart result discontinuous region 
isolated pixels eliminated intensity threshold 
region characteristics height width ratio ratio region area area bounding box ratio perimeter area presence absence gaps region classify image finger fingers vertical edge horizontal edge palm unknown 
research investigate possible postures recognition features experimented machine learning systems recognition 
action mappings activated region classified particular hand posture appropriate action produced mapping currently associated posture 
posture mapped whiteboard tool send messages smartboard driver change current tool 
posture mapped windows command send appropriate combination keyboard mouse events 
icon displayed windows taskbar selected time bring dialog box allows user change posture action mappings 
dialog als allows user select particular mapping activated immediately posture detection touch 
initial experiments began purely physical mode hand posture touch determined interpretation motion touch 
example finger touch mapped gesture recognizer user touch fingers continue drawing gesture 
observed mappings awkward 
example vertical side hand touch activates drawing tool pen convenient drawing hand held position 
added temporal mode posture initial touch determines mapping applied immediately touch 
example user touch side hand indicate drawing tool single finger touch drawing 
touches immediately correlated change cursor indicates action taken touch creates mode confusion 
evaluation informal initial observations affirm system provides means interacting large display avoids inconvenience walking different area device push button grasping physical interaction tool 
mapping gestures commands copy paste user saves time motions traditionally required selecting commands menus 
system response time conducive real time interaction image processing time averaged ms set touches 
average posture classification accuracy rates expect uniform ir illumination configuration allow improved accuracy 
immediate visual feedback posture recognized opportunity correction system useable accuracy take experimentation determine best tradeoff accuracy number different postures recognized 
systematic user studies planned performed time submission due interactive room required lighting camera setup soon initial experiments 
evaluation effectiveness interaction technique carried completed autumn 
discussion key assumption underlying significant class users interactions particular interactions bare handed interaction better physical tools determine mapping touch action 
alternative approach exemplified tools come smartboard traditional colored marker pens 
order annotate screen colored mark user picks corresponding colored marker draws tip just plastic cone 
erase picks eraser uses conventional way 
advantages tool tool free approach obvious tools interactions mapping natural 
picking red pen obvious way draw red mark 
tools shaped better suited task 
drawing pointed pen tip accurate drawing fingertip 
appropriate tools avoid need augment physical mode temporal ones touch mode 
complementary advantages tool free approach bare hands tools misplaced available need handed user user multi user environment necessary invent tool actions naturally suggest making onscreen gesture 
specialized hardware required tool recognition activation course hardware bare hands visual recognition 
regard point actual smartboard tools highly unsatisfactory kind envision 
housed tray equipped detectors sense presence absence tool 
tool removed board tray subsequent touches board device including bare fingers interpreted mode associated tool picked tool replaced tray picked 
pseudo physical mode intended physical mapping user picks tool time replaces works relatively replacement applications primary target device 
confusion results example due picking pen eraser touches interpreted whichever picked 
environment confusion results multiple device context boards tray implements associated sensors people pick tool board mixing whiteboard actions sketching application interaction modes part simple pen activity 
flaws corrected different mechanism tool sensing long term research questions understanding criteria tool bare hand interaction appropriate different kinds situations actions 
lighting arrangements greatest technical challenge implementation 
setup shown figures employing arrays ir leds provides non uniform lighting light led spreads degree arc central regions board lit outer edges remain dark 
tried unsuccessfully solve problem various conventional lenses filters 
uneven light results lower recognition accuracy hand postures outside display central area 
set lighting interactive room complete plan experiment new arrangements ir light sources achieve uniform illumination 
source composed leds arranged geometries linear strings concentrated arrays 
experiment alternating lighting directions improve recognition 
planning experiment lighting schemes successive frames video lit different ways different directions enabling sophisticated image analysis 
uniform lighting facilitate accurate image processing enable expand current set recognized postures 
space recognizable postures large theoretically possible ones awkward uncomfortable 
user experiments look postures appropriate natural mappings actions side hand eraser 
addition recognizing static hand postures plan extend system recognize postural motions item board extend space potentially meaningful actions 
easily extend visual recognition algorithms identify objects hands 
physical object known shape touched board manipulated achieve desired tool specific interaction 
general approach emphasized implement free interaction may places specialized tools appropriate combination interaction 
indebted people research group worked create interactive workspace environment 
hill institute science provided invaluable assistance design pulsed lighting system 
doug hill smart technologies provided valuable information assistance 
special dan morris fran ois re improvements 

gei ler rg 
shuffle throw take 
working efficiently interactive wall 
chi summary acm press 

matsushita jun rekimoto 
designing finger hand body object sensitive wall 
chi banff canada october acm press 

rehg kanade digiteyes hand tracking human computer interaction 
proc 
workshop motion non rigid articulated objects austin texas november ieee computer society press pages 

streitz norbert land interactive landscape creativity innovation 
chi pittsburgh pa may acm press 

joshua joseph paradiso tracking hands large interactive low cost scanning laser rangefinder chi summary 

see graphics stanford edu projects 
see www com 
see www com 
