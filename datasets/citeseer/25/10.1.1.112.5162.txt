usenix association proceedings th symposium operating systems design implementation boston massachusetts usa december advanced computing systems association usenix association rights reserved information usenix association phone fax email office usenix org www www usenix org rights individual papers remain author author employer 
permission granted noncommercial reproduction educational research purposes 
copyright notice included reproduced 
usenix acknowledges trademarks 
resource overbooking application profiling shared hosting platforms shenoy timothy roscoe department computer science intel research berkeley university massachusetts avenue suite amherst ma berkeley ca shenoy cs umass edu intel research net techniques provisioning cpu network resources shared hosting platforms running potentially antagonistic third party applications 
primary contribution demonstrate feasibility benefits overbooking resources shared platforms maximize platform yield revenue generated available resources 
deriving accurate estimate application resource needs profiling applications dedicated nodes profiles guide placement application components shared nodes 
overbooking cluster resources controlled fashion platform provide performance guarantees applications combine techniques commonly qos resource allocation mechanisms provide application isolation performance guarantees run time 
compared provisioning worst case efficiency consequently revenue benefits controlled overbooking resources dramatic 
specifically experiments linux cluster implementation indicate overbooking resources little increase utilization cluster factor overbooking yields improvement providing useful resource guarantees applications 
motivation server clusters built commodity hardware software increasingly attractive alternative traditional large multiprocessor servers applications part due rapid advances computing technologies falling hardware prices 
portions research done timothy roscoe researcher sprint atl summer intern sprint atl 
research supported part nsf ccr eia gift sprint 
addresses challenges design type server cluster call shared hosting platform 
contrasted dedicated hosting platform entire cluster runs single application web search engine individual processing element cluster dedicated single application managed hosting services provided data centers 
contrast shared hosting platforms run large number different third party applications web servers streaming media servers multiplayer game servers commerce applications number applications typically exceeds number nodes cluster 
specifically application runs subset nodes subsets may overlap 
dedicated hosting platforms niche applications warrant additional cost economic reasons space power cooling cost shared hosting platforms attractive choice application hosting environments 
shared hosting platforms imply business relationship platform provider application providers pay resources platform 
return platform provider gives kind guarantee resource availability applications 
central challenge platform provider resource management ability reserve resources individual applications ability isolate applications misbehaving overloaded applications ability provide performance guarantees applications 
arguably widespread deployment shared hosting platforms hampered lack effective resource management mechanisms meet requirements 
hosting platforms today adopt approaches 
avoids resource sharing altogether employing dedicated model 
delivers useful resources application providers expensive machine re sources 
second approach shares resources manner applications consequently receive resource guarantees 
cheap resources value delivered application providers limited 
consequently approaches imply economic deploy viable hosting platforms 
resource management mechanisms shared hosting platforms proposed 
reports performed context significant differences goals 
firstly seek outset support diverse set potentially antagonistic network services simultaneously platform 
services heterogeneous resource requirements web servers continuous media processors multiplayer game engines different demands platform terms resource bandwidth latency 
evaluate system diverse application mix 
secondly aim support resource management policies yield management techniques employed airline industry 
yield management driven business relationship platform provider application providers results different short term goals 
traditional approaches important aim satisfy resource contracts making efficient platform 
yield management contrast concerned ensuring available resource possible generate revenue utilized free service idle 
analogy air travel may clarify point trying ensure passenger gets board chosen flight try ensure plane takes empty seat achieved overbooking seats 
immediate consequence goal treatment flash crowds shared hosting platform react unexpected high demand application economic incentive doing 
platform allocate additional resources application enhances revenue 
increase resource allocation application handle unexpected high demands expense contract violations applications economically undesirable 
research contributions contribution threefold 
show resource requirements application derived online profiling modeling 
second demonstrate efficiency benefits platform provider overbooking resources platform usefully done adversely impacting guarantees offered application providers 
thirdly show untrusted mutually antagonistic applications platform isolated 
rest section presents contributions detail 
automatic derivation qos requirements discuss techniques empirically deriving application resource needs 
effectiveness resource management technique crucially dependent ability reserve appropriate resources application overestimating application resource needs result idling resources underestimating degrade application performance 
consequently shared hosting platform significantly enhance utility users automatically deriving qos requirements application 
automatic derivation qos requirements involves monitoring application resource usage ii statistics derive qos requirements conform observed behavior 
employ kernel profiling mechanisms empirically monitor application resource usage propose techniques derive qos requirements observed behavior 
techniques experimentally profile server applications web streaming game database servers 
results show bursty resource usage server applications feasible extract statistical multiplexing gains overbooking resources hosting platform 
revenue maximization overbooking resource overbooking techniques application placement strategies shared hosting platforms 
provisioning cluster resources solely worst case needs application results low average utilization average resource requirements application typically smaller worst case peak requirements resources tend idle application utilize peak reserved share 
contrast provisioning cluster high percentile application needs yields statistical multiplexing gains significantly increase average utilization cluster expense small amount overbooking increases number applications supported hardware configuration 
designed hosting platform able provide performance guarantees applications proviso guarantee probabilistic instance application provided guarantee probability resource needs met 
different applications different tolerance overbooking latency requirements game server tolerant violations performance guarantees web server overbooking mechanism take account diverse application needs 
demonstrate feasibility benefits booking resources shared hosting platforms propose techniques provision resources controlled fashion application resource needs 
overbooking result transient overloads aggregate resource demand temporarily exceeds capacity techniques limit chances transient overload resources predictably rare occasions provide useful performance guarantees applications presence overbooking 
techniques describe general commonly os resource allocation mechanisms 
placement isolation antagonistic applications describe additional aspect resource management problem placement isolation antagonistic applications 
assume third party applications may antagonistic trusted platform due bugs 
demonstrates untrusted third party applications isolated shared hosting platforms ways 
local machine processing node platform employs resource management techniques sandbox applications restricting resources consumed application reserved share 
globally automated placement techniques allow platform provider exert sufficient control placement application components nodes cluster manual placement applications complex error prone large clusters 
system model terminology shared hosting platform assumed research consists cluster nodes consists processor memory storage resources network interfaces 
platform nodes allowed heterogeneous different amounts resources node 
nodes hosting platform assumed interconnected high speed lan gigabit ethernet see 
cluster node assumed run operating system kernel supports notion quality service reservations shares 
focus managing cpu network interface bandwidth shared hosting platforms 
points management resources inherently temporal nature disk bandwidth performed similar mechanisms 
spatial resources particular physical memory different challenge 
straightforward approach static partitioning sophisticated approaches implemented 
term application complete service running behalf application provider application frequently consist multiple distributed components term capsule refer compo app app app app cluster interconnect gigabit ethernet app app app architecture shared hosting platform 
application runs nodes shares resources applications 
nent application running single node 
application capsule possibly application distributed 
capsules provide useful abstraction logically partitioning application subcomponents exerting control distribution components different nodes 
illustrate consider commerce application consisting web server java application server database server 
components need colocated single node application consist single capsule components 
hand component needs placed different node application partitioned capsules 
depending number capsules application runs subset platform nodes subsets overlap resulting resource sharing 
rest structured follows 
section discusses techniques empirically deriving application resource needs section discusses resource overbooking techniques capsule placement strategies 
discuss implementation issues section experimental results section 
section discusses related section presents concluding remarks 
automatic derivation application qos requirements step hosting new application derive resource requirements 
problem qos aware resource management studied extensively literature problem resource allocate application received relatively little attention :10.1.1.41.1733:10.1.1.28.6923
section address issue proposing techniques automatically derive qos requirements application terms resource requirements qos requirements interchangeably pa cpu nic 
deriving qos requirements step process profiling techniques monitor application behavior ii empirical measurements derive qos requirements conform observed behavior 
application qos requirements definitions qos requirements application defined capsule basis 
capsule qos requirements specify intrinsic rate resource usage variability resource usage time period capsule desires resource guarantees level overbooking application capsule willing tolerate 
explained earlier concerned key resources cpu network interface bandwidth 
resources define qos requirements dimensions os independent manner 
section show map requirements various os specific resource management mechanisms developed 
formally represent qos requirements application capsule quintuple token bucket parameters capture basic resource requirements capsule modeling resource usage token bucket 
parameter denotes intrinsic rate resource consumption denotes variability resource consumption 
specifically denotes rate capsule consumes cpu cycles network interface bandwidth captures maximum burst size 
definition token bucket bounds resource usage capsule interval 
period third parameter denotes time period capsule desires guarantees resource availability 
put way system strive meet qos requirements capsule interval length 
smaller value stringent desired guarantees capsule needs guaranteed resources finer time scale 
particular token bucket parameters capsule requires allocated resources time units 
usage distribution token bucket parameters succinctly capture capsule resource requirements sufficiently expressive denote qos requirements presence overbooking 
consequently additional parameters specify resource requirements presence overbooking 
parameter denotes probability distribution resource usage 
note detailed specification resource usage token bucket parameters indicates probability capsule certain fraction resource probability capsule uses fraction resource 
probability distribution resource usage necessary hosting platform provide quantifiable probabilistic guarantees presence overbooking 
overbooking tolerance parameter overbooking tolerance capsule 
specifies probability capsule requirements may violated due resource overbooking providing resources required amount 
overbooking tolerance indicates minimum level service acceptable capsule 
illustrate capsule resource requirements met time probability interval 
general assume parameters specified application provider 
may contract platform provider application provider application provider willing pay resources stronger provided guarantees particular characteristics application streaming media server requires stringent guarantees tolerant violations guarantees 
rest section show derive remaining parameters profiling values 
kernel profiling resource usage techniques empirically deriving qos mechanisms monitor application behavior 
number application profiling mechanisms ranging os profiling run time profiling specially linked libraries proposed 
kernel profiling mechanisms context shared hosting platforms number reasons 
firstly kernel mechanisms application require changes application source binary levels 
especially important hosting environments platform provider may little access third party applications 
secondly accurate estimation application resource needs requires detailed information resources application fine timescale 
detailed resource allocation information difficult obtain application level techniques kernel techniques provide precise information various kernel events cpu scheduling instances network packet transmissions times 
profiling process involves running application set isolated platform nodes number nodes required profiling depends number capsules 
cpu quantum network transmission cpu quantum network transmission idle non capsule related activity busy period time example trace 
isolated mean node runs minimum number system services necessary executing application applications run nodes profiling process isolation necessary minimize interference unrelated tasks determining application resource usage 
application subjected realistic workload kernel profiling mechanism track resource usage 
important emphasize workload profiling realistic representative real world workloads 
techniques generating realistic workloads orthogonal current research note number different workload generation techniques exist ranging trace replay actual workloads running application live setting synthetic workload generators known benchmarks 
technique suffices purpose long realistically emulates real world conditions note business perspective running application real isolated machine obtain profile may preferable workload generation techniques 
linux trace toolkit kernel profiling mechanism 
toolkit provides flexible mechanisms trace variety kernel events system call invocations process memory file system network operations 
user specify specific kernel events interest processes profiled selectively log events 
purposes sufficient monitor cpu network activity capsule processes monitor cpu scheduling instances time instants capsule processes get scheduled corresponding quantum durations network transmission times packet sizes 
trace cpu network activity discuss derivation capsule qos requirements 
empirical derivation qos requirements trace kernel events obtained profiling process model cpu network activity simple process 
achieved examining time event occurs duration deriving sequence busy idle periods probability measurement interval cumulative resource usage time fraction resource usage time usage distribution token bucket parameters derivation usage distribution token bucket parameters 
information see 
trace busy idle periods derive resource usage distribution token bucket parameters determining usage distribution recall usage distribution denotes probability capsule uses certain fraction resource 
derive simply partition trace measurement intervals length measure fraction time capsule busy interval 
value represents fractional resource usage interval bucket normalized respect number measurement intervals trace obtain probability distribution 
illustrates process 
deriving token bucket parameters recall token bucket limits resource usage capsule interval 
trace general pairs satisfy bound 
intuitively understand compute cumulative resource usage capsule time 
cumulative resource usage simply total resource consumption far computed incrementing cumulative usage period 
cumulative resource usage step function depicted 
objective find line bounds cumulative resource usage slope line token bucket rate intercept burst size 
shown general curves valid descriptions observed resource usage 
algorithms mechanically compute valid pairs trace proposed 
variant algorithm research trace algorithm produces range values constitute valid token bucket rates observed behavior 
range algorithm computes corresponding burst size 
pair range conforms observed behavior choice particular important practical implications 
overbooking tolerance capsule choose particular pair 
illustrate capsule needs met time achieved reserving resources corresponding percentile usage distribution 
consequently policy shared hosting platforms pick corresponds percentile resource usage distribu tion pick corresponding computed algorithm 
ensures provision resources high percentile capsule needs percentile chosen specified overbooking tolerance 
profiling server applications experimental results section profile commonly server applications illustrate process deriving application qos requirements 
experimentally derived profiles illustrate inherent nature various server application demonstrate utility benefits resource overbooking shared hosting platforms 
test bed profiling experiments consists dell servers mhz pentium iii processor mb memory running red hat linux 
servers runs version linux kernel patched linux trace toolkit version connected mbps ethernet links dell model ethernet switch 
profile application run servers remaining servers generate workload profiling 
assume machines lightly loaded non essential system services mail services windows server turned prevent interference profiling 
parameters set sec experimentation 
profile server applications experiments apache web server specweb benchmark generate workload apache web server version 
specweb benchmark allows control dimensions number concurrent clients percentage dynamic cgi bin requests 
vary parameters study impact apache resource needs 
mpeg streaming media server streaming server stream mpeg video files multiple concurrent clients udp 
client experiment requests minute long variable bit rate mpeg video mean bit rate mb vary number concurrent clients study impact resource usage server 
quake game server publicly available linux quake server understand resource usage multi player game server experiments standard version quake popular multiplayer game internet 
client workload generated bot autonomous software program emulates human player 
publicly available terminator bot emulate player vary number concurrent players connected server study impact resource usage 
postgresql database server profile postgresql database server version benchmark 
benchmark part postgresql distribution emulates tpc transactional benchmark 
benchmark provides control number concurrent clients number transactions performed client 
vary parameters study impact resource usage database server 
results profiling study 
depicts cpu usage distribution apache web server obtained default settings specweb benchmark concurrent clients dynamic cgi bin requests 
plots corresponding cumulative distribution function cdf resource usage 
shown summarized table worst case cpu usage percentile cpu capacity 
percentiles cpu usage capacity respectively 
results indicate cpu usage bursty nature worst case requirements significantly higher high percentile usage 
consequently provisioning overbooking mere reduces cpu requirements apache factor overbooking yields factor reduction implying times web servers supported provisioning percentiles respectively profile 
small amounts overbooking potentially yield significant increases platform capacity 
depicts possible valid pairs apache cpu usage 
depending specified overbooking tolerance set appropriate probability apache web server specweb default fraction cpu probability cumulative probability apache web server specweb default cumulative probability fraction cpu burst rho msec valid token bucket pairs rate sigma fraction probability distribution pdf cumulative distribution function cdf token bucket parameters profile apache web server default specweb configuration 
percentile usage distribution corresponding chosen 
figures depict cpu network bandwidth distributions appropriate various server applications 
specifically shows usage distribution apache web server dynamic specweb requests streaming media server concurrent clients quake game server clients postgresql server clients 
table summarizes results presents profiles additional scenarios small subset dozen profiles obtained experiments due space constraints 
table lists worst case resource needs percentile resource usage 
table demonstrate server applications exhibit burstiness resource usage albeit different degrees 
burstiness causes worst case resource needs significantly higher high percentile usage distribution 
consequently find percentile smaller factor percentile yields factor reduction compared percentile 
results illustrate potential gains realized overbooking resources shared hosting platforms 
resource overbooking capsule placement hosting platforms having derived qos requirements capsule step determine platform node run capsule 
considerations arise making placement decisions 
platform resources platform ensure qos requirements capsule met presence overbooking 
second multiple nodes may resources necessary house applica probability apache web server cgi bin probability fraction cpu apache dynamic requests probability quake game server clients probability fraction cpu quake server probability probability streaming media server clients probability fraction network bandwidth streaming media server postgres database server clients probability fraction cpu postgresql server profiles various server applications tion capsule platform need pick set feasible mappings 
section techniques overbooking platform resources controlled manner 
aim ensure qos requirements application satisfied ii overbooking tolerances taken account making placement decisions 
resource overbooking techniques platform node accept new application capsule long resource requirements existing capsules violated sufficient unused resources exist meet requirements new capsule 
node resources requirement added application res 
res 
usage percentile ws default cpu ws dyn 
cpu sms net sms net gs cpu gs cpu dbs def cpu dbs cpu table summary profiles 
profiled cpu network usage application results constraining resource due space constraints 
abbreviations ws apache sms streaming media server gs quake game server dbs database server number clients dyn dynamic res resource 
overbooking tolerances individual capsules placed node exceeded result accepting new capsule 
verifying conditions involves tests test resource requirements new existing capsules met 
verify node meet requirements capsules simply sum requirements individual capsules ensure aggregate requirements exceed node capacity 
capsule node qos parameters require capsule allocated resources interval duration 
capsule overbooking tolerance worst case node allocate resources satisfy capsule needs overbooking tolerance represents fraction allocation may reduced node saturates due overbooking 
consequently worst case scenario resource requirements capsules met long total resource requirements exceed capacity denotes cpu network interface capacity node denotes number existing capsules node new capsule min period capsule desires stringent guarantees 
note capsule chosen percentile capsule resource usage distribution multiplication may penalizing capsule twice 
combination burst upper envelop requirements capsule 
multiplication allows resources node controlled manner 
test overbooking tolerances capsules met 
overbooking tolerance capsule met total amount overbooking smaller specified tolerance 
compute aggregate overbooking node compute total resource usage node 
usage distributions individual capsules known total resource node simply sum individual usages 
denotes aggregate resource usage distribution node 
assuming independent resulting distribution computed elementary probability theory 
total resource usage distribution probability total demand exceeds node capacity overbooking tolerance capsule denotes cpu network capacity node 
verifying condition individual capsule suffices tolerance capsule 
min note equation enables platform provide probabilistic guarantee capsule qos requirements met time 
equations easily handle heterogeneity nodes appropriate values cpu network capacities node 
new capsule placed node equations satisfied cpu network interface 
capsule placement algorithms consider application capsules needs placed shared hosting platform nodes 
capsules determine set feasible platform nodes 
feasible node satisfy capsule resource requirements satisfies equations cpu network requirements 
platform pick feasible node capsule capsules placed platform constraint capsules placed node definition capsules application colocated 
placement capsules nodes subject constraint handled follows 
model done transform 
transform random variable polynomial coefficient term represents probability random variable equals 
independent random variables distribution computed polynomial multiplication transforms placement problem graph contains vertex capsules nodes 
add edge capsule node node feasible node capsule sufficient resources house application 
result bipartite graph edge connects capsule node 
graph algorithm determine placement 
algorithm starts capsule constrained number edges feasible nodes places feasible nodes 
node edges deleted capsule placed 
algorithm picks constrained capsule repeats process capsules placed nodes 
shown greedy algorithm find placement exists see extended version formal proof :10.1.1.112.5162
property follows node place capsule algorithm terminates declaring placement exists application 
algorithm efficient capsules placed single linear scan sorted increasing order degree resulting complexity log description placement algorithm left unspecified node chosen capsule possible feasible nodes 
choice particular feasible node important implications total number applications supported platform 
consequently consider policies making decision 
policy random pick feasible node randomly 
second policy choose feasible node unused resources constitutes best fit capsule 
third policy worst fit place capsule feasible node unused resources 
general unused network cpu capacities node may different similarly capsule may request different amounts cpu network resources 
consequently defining best worst fits capsule take account unused capacities resources currently simply considering mean unused capacity resources compare mean requirements resources determine fit 
fourth policy place capsule node capsules similar overbooking tolerances 
node meet requirements tolerant capsule equation capsules similar overbooking tolerances permits platform provider maximize amount resource overbooking platform 
instance placing capsule tolerance node existing capsule reduces maximum permissible overbooking node min 
hand placing tolerant capsule node may allow tolerant capsules placed node allowing nodes resources greater extent 
experimentally compare effectiveness policies section 
handling dynamically changing resource requirements discussion far assumed resource requirements application run time change initial profiling phase 
reality resource requirements change dynamically time tandem workload seen application 
section outline approach dealing dynamically changing application workloads 
recall provision resources high percentile application resource usage distribution 
consequently variations application workload affect average resource requirements capsules tail resource usage distribution result violations probabilistic guarantees provided hosting platform 
contrast workload changes cause increase tail resource usage distribution certainly affect application qos guarantees 
platform deal changes resource requirements depends factors 
interested yield management platform increase resources allocated overload application increases revenues platform provider 
application provider pays fixed amount resources economic incentive platform provider increase resource allocation limit application overloaded 
contrast contract application platform provider permits usage charging charging resources actual usage high percentile usage allocating additional resources response increased demand desirable maximizing revenue 
scenario handling dynamically changing requirements involves steps detecting changes tail resource usage distribution ii reacting changes varying actual resources allocated application 
detect changes tail application resource usage distribution propose conduct continuous line profiling resource usage capsules low overhead profiling tools 
done recording cpu scheduling instants network transmission times packet sizes processes intervals suitable length 
interval data processed construct latest resource usage distributions capsules 
application probability apache web server offline profile cgi bin probability fraction cpu probability apache web server expected workload probability fraction cpu probability apache web server overload probability fraction cpu original profile profile expected load profile overload demonstration application overload may detected comparing latest resource usage profile original offline profile 
overload manifest increased concentration high percentile buckets resource usage distributions capsules 
results simple experiment illustrate 
shows cpu usage distribution apache web server obtained offline profiling 
workload web server generated specweb benchmark emulating concurrent clients dynamic cgi bin requests 
offline profiling done period minutes 
assumed overbooking tolerance web server capsule 
described section assigned cpu rate corresponding percentile cpu usage distribution 
remaining capacity assigned greedy dhrystone application application performs compute intensive integer computations greedily consumes resources allocated 
web server subjected exactly workload clients cgi bin requests minutes followed heavier workload consisting concurrent clients dynamic cgi bin requests minutes 
heavier workload minutes simulate unexpected flash crowd 
web server cpu usage distribution recorded periods length minute 
shows cpu usage distribution observed web server period expected workload 
find profile similar profile obtained offline measurements upper bounded cpu rate assigned capsule 
plots cpu usage distribution period web server overloaded 
find increased concentration high percentile regions distribution compared original distribution 
detection application overload trigger remedial actions proceed stages 
new resource requirements computed affected capsules 
actions taken provide capsules newly computed resource shares may involve increasing resource allocations capsules moving capsules nodes sufficient resources 
implementing evaluating techniques handling application overloads part ongoing research shared hosting platforms 
implementation considerations section discuss implementation issues integrating resource overbooking techniques os resource allocation mechanisms 
overview prototype implementation 
providing application isolation run time techniques described previous section allow platform provider platform resources provide guarantees qos requirements applications met 
task enforcing guarantees run time responsibility os kernel 
meet guarantees assume kernel employs resources allocation mechanisms support notion quality service 
numerous mechanisms reservations shares token bucket regulators proposed :10.1.1.41.1733:10.1.1.28.6923
mechanisms allow certain fraction resource cpu cycles network interface bandwidth reserved application enforce allocations fine time scale 
addition enforcing qos requirements application mechanisms isolate applications 
limiting resources consumed application reserved amount mechanisms prevent malicious overloaded application grabbing allocated share resources providing application isolation run time important requirement shared hosting environments running untrusted applications 
overbooking techniques exploit commonly qos aware resource allocation mechanisms 
qos requirements application defined os mechanism independent manner need map os independent qos requirements mechanism specific parameter values 
consider commonly qos aware mechanisms reservations proportional share schedulers rate regulators 
due space constraints mapping reservations point reader extended version remaining mappings :10.1.1.112.5162
reservation scheduler requires resource requirements specified pair capsule desires units resource time units effectively capsule requests fraction resource :10.1.1.28.6923
reasons feasibility sum requests allocations exceed 
scenario qos requirements capsule token bucket parameters overbooking tolerance translated reservation setting 
see recall denotes rate resource consumption capsule presence overbooking capsule request units resource time units worst case entire units may requested continuously set burst size 
equations simplify 
prototype implementation implemented linux shared hosting platform incorporates techniques discussed previous sections 
implementation consists key components profiling module allows profile applications empirically derive qos requirements ii control plane responsible resource overbooking capsule placement iii qos enhanced linux kernel responsible enforcing application qos requirements 
profiling module runs set dedicated isolated platform nodes consists vanilla linux kernel enhanced linux trace toolkit 
explained section profiling module gathers kernel trace cpu network activities capsule 
post processes information derive trace resource usage derives usage distribution token bucket parameters usage 
control plane responsible placing capsules newly arriving applications nodes overbooking node resources 
control plane keeps state consisting list capsules residing node qos requirements 
maintains information hardware characteristics node 
re newly arriving application specified control plane resource specification language 
specification includes cpu network bandwidth requirements capsule 
control plane uses specification derive placement capsule discussed section 
addition assigning capsule node control plane translates qos parameters capsules parameters commonly resource allocation mechanisms discussed previous section 
third component qos enhanced linux kernel runs platform node responsible enforcing qos requirements capsules run time 
purposes implement proportional share cpu scheduler 
hierarchical proportional share scheduler allows group resource principals processes lightweight processes assign aggregate cpu share entire group 
implement token bucket regulator provide qos guarantees network interface card 
rate regulator allows associate network sockets belonging group processes single token bucket 
instantiate token bucket regulator capsule regulate network bandwidth usage resource principals contained capsule parameters capsule network bandwidth usage 
section experimentally demonstrate efficacy mechanisms enforcing qos requirements capsules presence overbooking 
experimental evaluation section results experimental evaluation 
setup experiments identical described section employ cluster linux servers shared hosting platform 
server runs qos enhanced linux kernel consisting cpu scheduler leaky bucket regulator network interface 
control plane shared platform implements resource overbooking capsule placement strategies discussed earlier 
ease comparison set applications discussed derived profiles see table experimental study 
efficacy resource overbooking set experiments examine efficacy overbooking resources shared hosting platforms 
consider shared web hosting platforms type shared hosting platform runs web servers 
web server running platform assumed conform web server profiles gathered profiling study profiles shown table employed varying mixes static dynamic number web servers placed placement clusters different sizes overbooking number nodes number streaming servers supported placement clusters different sizes overbooking number nodes number applications supported cpu bound network bound capsules streaming server apache server postgres server cluster size web servers streaming media servers mix applications benefits resource overbooking bursty web server application bursty streaming server application application mixes 
specweb requests 
objective experiment examine web servers supported platform configuration various overbooking tolerances 
vary overbooking tolerance tolerance value attempt place web servers possible platform resources exhausted 
perform experiment cluster nodes identical hardware configuration repeat cluster sizes ranging nodes lack clusters sizes experiments examine applications accommodated platform run applications 
depicts results confidence intervals 
shows larger amount overbooking larger number web servers run platform 
specifically node platform number web servers supported increases overbooking employed overbooking factor increase 
modest overbooking see factor increase number web servers supported platforms various sizes 
modest amounts overbooking significantly enhance revenues platform provider 
examine benefits overbooking resources shared hosting platform runs mix streaming servers database servers web servers 
demonstrate impact burstiness overbooking focus streaming media server 
shown table streaming server clients exhibits burstiness typical web server consequently expect smaller gains due resource overbooking 
quantify gains vary platform size nodes determine number streaming servers supported overbooking 
plots results confidence intervals 
shown number servers supported increases booking compared overbooking case 
increasing amount overbooking yields marginal additional gain consistent profile streaming server shown table indicative tolerant nature soft real time application 
bursty applications yield smaller gains overbooking resources 
streaming server exhibit significant burstiness large statistical multiplexing gains accrue bursty non bursty applications 
streaming server heavily uses minimal amount cpu additional gains possible applications different bottleneck resources cpu bound applications 
examine validity assertion conduct experiment attempt place mix streaming web database servers mix cpu bound network bound bursty non bursty applications 
plots number applications supported platforms different sizes overbooking 
shown identical platform configuration able support large number applications scenario streaming servers placed platform 
specifically node cluster platform supports additional web database servers addition approximately streaming servers supported earlier 
note capsule placement algorithms automatically able extract gains specific tweaking part 
applications different bottleneck resources different amounts burstiness enhance additional statistical multiplexing benefits overbooking resources 
capsule placement algorithms experiment compares effectiveness best fit worst fit random placement algorithms discussed section 
profiles construct types applications replicated web server commerce application consisting front web server back database server 
arriving application belongs categories assumed consist capsules depending degree replication 
overbooking tolerance set 
determine number applications placed platform different placement strategies 
depicts results 
shown best fit random placement yield similar performance worst fit outperforms policies range platform sizes 
best fit places capsules nodes smaller unused capacity resulting fragmentation unused capacity node leftover capacity may wasted additional applications accommodated 
worst fit hand reduces chances fragmentation placing capsules nodes larger unused capacity 
effects prominent application capsules widely varying requirements observed experiment noticeable application similar resource requirements 
demonstrate behavior attempted place quake game servers platforms various sizes 
observe table game server profiles exhibit diversity mix web database servers 
shows due similarity application resource requirements policies able place comparable number game servers 
examine effectiveness overbooking tolerance account making placement decisions 
compare worst fit policy overbooking conscious worst fit policy 
policy chooses worst fits feasible nodes picks node best matches overbooking tolerance capsule 
experiment assumes web hosting platform types applications tolerant web servers permit overbooking tolerant web servers permit overbooking 
vary platform size examine total number applications placed policies 
shown overbooking tolerances account making placement decisions help increase number applications placed cluster 
find additional gains small cases indicating simple worst fit policy may suffice scenarios 
effectiveness kernel resource allocation mechanisms experiments far focused impact overbooking platform capacity experiment examine impact overbooking application performance 
show combining booking techniques kernel qos resource allocation mechanisms provide application isolation quantitative performance guarantees applications presence overbooking 
running apache web server dedicated isolated node examine performance measuring throughput requests default specweb workload 
run web server node running qos enhanced linux kernel 
allo cate resources percentile usage overbooking assign remaining capacity greedy dhrystone application 
measure throughput web server presence background dhrystone application 
reserve resources web server percentiles allocate remaining capacity dhrystone application measure server throughput 
table depicts results 
shown provisioning yields performance comparable running application dedicated node 
provisioning percentiles results small degradation throughput permissible limits degradation respectively due overbooking 
table shows provisioning average resource requirements results substantial fall indicating reserving resources mean usage advisable shared hosting platforms 
repeat experiment streaming server database server 
background load streaming server experiment generated greedy udp sender transmits network packets fast possible case database server generated dhrystone application 
cases run application isolated node qos enhanced kernel provisioning percentiles 
run application provisioning average resource usage distribution obtained offline profiling 
measure throughput transaction database server mean length playback violation seconds streaming media server 
table plots results 
web server provisioning percentile yields performance compa running application isolated node small amount overbooking results corresponding small amount degradation application performance 
scenarios computed application profiles presence background load overbooking compared profiles gathered isolated node 
shows set profiles 
seen combination second row table corresponds postgresql application 
depict performance number applications supported performance different placement heuristics random best fit worst fit cluster size number applications supported performance different placement heuristics random best fit worst fit cluster size number applications supported comparison worst fit close overbooking worst fit 
conscious cluster size placing diverse applications placing similar applications overbooking conscious placement performance various capsule placement strategies 
application metric isolated node average apache throughput req postgresql throughput transactions streaming length violations sec table effectiveness kernel resource allocation mechanisms 
results shown confidence intervals 
database server different levels cpu provisioning 
figures show cpu profiles database server provisioned percentiles respectively 
seen profiles look similar original profile shown 
correspondingly table shows levels cpu provisioning throughput received database server slightly inferior isolated node 
indicates provisioning resources high percentile presence background load interferes minimally application behavior 
show cpu profile database server provisioned average cpu requirement 
profile drastically different original profile 
corresponding low throughput table 
reinforces earlier observation provisioning resources average requirements result significantly degraded performance 
results demonstrate kernel resource allocation mechanisms able provide quantitative performance guarantees resources 
related research clustered environments past decade spanned number issues 
systems condor investigated techniques harvesting idle cpu cycles cluster workstations run batch jobs :10.1.1.28.6923
design scalable fault tolerant network services running server clusters studied :10.1.1.1.2034
virtual clusters manage resources contain faults large multiprocessor systems studied :10.1.1.40.7792
scalability availability performance issues dedicated clusters studied context clustered mail servers replicated web servers :10.1.1.116.6208
ongoing efforts grid computing community focused developing standard interfaces resource reservations clustered environments 
context qos aware resource allocation numerous efforts past decade developed predictable resource allocation mechanisms single machine environments :10.1.1.41.1733:10.1.1.28.6923
statistical admission control techniques resources studied context video ondemand servers atm networks little published date context shared cluster hosting platforms 
closely related aron presents comprehensive framework resource management web servers aim delivering predictable qos differentiated services 
new services profiled running lightly loaded machines contracts subsequently negotiated terms application level performance connections second reported application system 
cpu disk bandwidth scheduled lottery scheduling respectively physical memory statically partitioned services free pages allocated temporarily services :10.1.1.129.159
resource monitor running longer timescale examines performance cumulative probability cumulative probability postgres profile isolated node cumulative probability fraction cpu profile isolated node postgres cdf cumulative probability fraction cpu provision tile cumulative probability postgres profile cumulative probability fraction cpu provision tile cumulative probability postgres cdf cumulative probability fraction cpu provision average effect different levels provisioning postgresql server cpu profile 
reported application system performance information flags conditions violate contracts allow extra resources provided external means 
aron system resource allocation primarily driven application feedback primary concern allowing principal meet contract 
instructive compare goal maximizing yield system amounts maximizing proportion system resources satisfy contracts 
long time period new machines provisioned instance goals coincide clear short periods time 
difference corresponds different kind relationship service provider platform provider 
consequently aron system able take advantage uniform application reported performance metrics contrast oriented heterogeneous mixture services untrusted platform potentially antagonistic 
subtle important difference motivates differences design choices systems 
aron application overload detected resource usage exceeds predetermined threshold 
hand detect overload observing tail resource usage distributions 
hand features aron multiple random variables capture behavior services different time scales directly applicable system 
specific problem qos aware resource management clustered environments investigated 
effort builds single node qos aware resource allocation mechanisms propose techniques extend benefits clustered environments 
proposes system called muse provisioning resources hosting centers energy considerations 
muse economic approach managing shared server resources services bid resources function delivered performance 
provides mechanisms continuously monitor load compute new resources estimating value effects service performance 
economic approach sharing resources driven energy considerations 
salient difference muse approach muse provisions resources average resource requirements provision tail resource requirements 
authors consider model hosting platforms different considered 
visualize applications executing platforms constructed clustering multiple autonomous distributed servers resource access governed agreements owners users servers 
architecture distributed coordinated enforcement resource sharing agreements application independent way represent resources agreements 
looked hosting platforms consisting servers location connected fast network 
believe distributed hosting platforms popular resource management systems pose challenging research problems 
concluding remarks techniques provisioning cpu network resources shared hosting platforms running potentially antagonistic third party applications 
argued provisioning resources solely worst case needs applications results low average utilization provisioning high percentile application needs yield statistical multiplexing gains significantly increase utilization cluster 
accurate estimate application resource needs necessary provisioning resources techniques profile applications dedicated nodes possibly service profiles guide placement application components shared nodes 
proposed techniques cluster resources controlled fashion platform provide performance guarantees applications 
techniques conjunction commonly os resource allocation mechanisms provide application isolation performance guarantees run time presence overbooking 
implemented techniques linux cluster evaluated common server applications 
efficiency benefits controlled overbooking resources dramatic compared provisioning resources worstcase requirements applications 
specifically overbooking resources little increases utilization hosting platform factor overbooking results gains 
bursty application resources needs higher benefits resource overbooking 
generally results demonstrate benefits feasibility overbooking resources platform provider 
acknowledgments anonymous reviewers shepherd peter druschel comments 
aron 
differentiated predictable quality service web server systems 
phd thesis computer science rice university october 
aron iyer druschel 
resource management framework predictable quality service web servers 
submitted publication aron druschel zwaenepoel 
cluster reserves mechanism resource management cluster network servers 
proceedings acm sigmetrics conference santa clara ca june 
banga druschel mogul 
resource containers new facility resource management server systems 
proceedings third symposium operating system design implementation osdi new orleans pages february 
waldspurger 
memory resource management vmware esx server 
proceedings th symposium operating system design implementation osdi boston ma december 

statistical service assurances traffic scheduling algorithms 
ieee journal selected areas communications december 
chase anderson vahdat doyle 
managing energy server resources hosting centers 
proceedings eighteenth acm symposium operating systems principles sosp pages october 
fox gribble chawathe brewer gauthier :10.1.1.1.2034
cluster scalable network services 
proceedings sixteenth acm symposium operating systems principles sosp saint malo france pages december 
huang rosenblum :10.1.1.40.7792
cellular disco resource management virtual clusters sharedmemory multiprocessors 
proceedings acm symposium operating systems principles sosp kiawah island resort sc pages december 
goyal guo vin 
hierarchical cpu scheduler multimedia operating systems 
proceedings operating system design implementation osdi seattle pages october 
global grid forum scheduling resource management working group 
www unix mcs anl gov schopf ggf sched 
jones rosu rosu 
cpu reservations time constraints efficient predictable scheduling independent activities 
proceedings sixteenth acm symposium operating systems principles sosp saint malo france pages december 
leslie mcauley black roscoe barham 
design implementation operating system support distributed multimedia applications 
ieee journal selected areas communication september 
linux trace toolkit project page 
www com ltt 
litzkow livny mutka :10.1.1.28.6923
condor hunter idle workstations 
proceedings th international conference distributed computing systems pages june 
man page postgresql software distribution 
roscoe lyles 
distributing computing design considerations public computing platforms 
proceedings th acm sigops european workshop denmark september 
saito bershad levy :10.1.1.116.6208
manageability availability performance porcupine highly available scalable mail service 
proceedings th sosp kiawah island resort sc pages december 
smith 
yield management american airlines 
interfaces january february 
standard performance evaluation spec www spec org 
specweb benchmark documentation 
sundaram chandra goyal shenoy sahni vin 
application performance multimedia operating system 
proceedings eighth acm conference multimedia los angeles ca november 
tang tai 
network traffic characterization token bucket model 
proceedings ieee infocom new york ny march 
shenoy 
managing cpu network bandwidth shared clusters 
technical report tr department computer science university massachusetts october 
shenoy roscoe :10.1.1.112.5162
resource overbooking application profiling shared hosting platforms 
technical report tr department computer science university massachusetts may 
vin goyal goyal goyal 
statistical admission control algorithm multimedia servers 
proceedings acm multimedia san francisco pages october 
waldspurger weihl :10.1.1.129.159
lottery scheduling flexible proportional share resource management 
proceedings operating system design implementation november 
zhao 
enforcing resource sharing agreements distributed server clusters 
proceedings th international parallel distributed processing symposium ipdps april 
