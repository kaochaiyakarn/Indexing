speeding short data transfers theory architectural support simulation results yin zhang cs cornell edu cornell university today internet traffic dominated short web data transfers 
workload known interact poorly tcp protocol 
tcp uses slow start procedure probe network bandwidth connection start restart idle period 
usually requires inefficient duration transfer short 
propose new technique call tcp spand speed short data transfers 
tcp spand network performance information shared located hosts estimate connection fair share network resources 
estimation transfer size tcp sender determines optimal initial congestion window size 
doing slow start uses pacing scheme smoothly send packets initial congestion window 
extensive simulations evaluate performance resulting system 
results show tcp spand significantly reduces latency short transfers presence multiple heavily congested bottlenecks 
performance benefit come expense degrading performance connections standard tcp 
tcp spand tcp friendly 

numerous measurements show internet traffic dominated short bursty web data transfers 
workload interacts poorly tcp dominant transport protocol today internet 
tcp uses slow start procedure probe available network capacity connection start restart idle period 
usually requires 
short web data transfers typically span spending probing network state inefficient 
techniques proposed past speed short web transfers 
techniques help complete solutions 
propose new technique call tcp spand effectively eliminate slow start penalty short data transfers 
tcp spand network performance information shared located hosts estimate connection fair share network resources 
estimation file transfer size tcp sender determines optimal initial congestion window size connection start restart idle period 
doing slow start uses pacing scheme smoothly send packets initial window 
packets initial window paced sender switches back behavior standard tcp 
implement tcp spand ns simulator extensive simulations evaluate performance 
results show tcp spand significantly reduces latency short transfers lili qiu cs cornell edu cornell university srinivasan keshav keshav com presence multiple heavily congested bottlenecks 
tcp spand tcp friendly 
significant performance improvement expense degrading performance connections standard tcp 
deploying tcp spand web servers provide great performance benefit 
furthermore system designed incrementally deployable today internet 
involves modifications server side 
client side applications left untouched 
rest organized follows 
ground tcp 
overviews previous 
analytically derive optimal initial congestion window function certain network path characteristics transfer size 
presents design implementation tcp spand incrementally de gives back architecture allows apply analytical results today internet 
presents simulation results evaluate effectiveness approach 
concluding remarks 
background tcp currently dominant transport protocol internet forms foundation applications web browsing mail file transfer news distribution 
closed loop flow control scheme source dynamically adjusts flow control window response implicit signals network overload 
specifically source uses slow start algorithm probe available network capacity gradually growing congestion window congestion detected window size reaches receiver advertised window 
slow start terminated congestion window grows threshold 
case uses congestion avoidance open window loss occurs 
responds loss adjusting congestion window parameters 
success tcp relies feedback mechanism uses packet loss indication adapt adjusting variety parameters congestion window size slow start threshold smoothed round trip time variance 
feedback mechanism connection long 
transfers small compared bandwidth delay product link file transfers kilobytes satellite links typical sized web pages terrestrial links little feedback loss indications 
case connection performance primarily governed choice initial parameters 
original tcp initial values parameters chosen accommodate wide range network conditions 
may optimal specific network scenario 

previous number proposals improving start restart performance tcp connections 
typical examples application level approaches launching multiple concurrent tcp connections persistent 
multiple concurrent connections tcp overly aggressive environments lead congestive collapse shared networks :10.1.1.117.8087:10.1.1.112.5121
reuses single tcp connection multiple web transfers amortizing connection setup overhead pays slow start penalty 
average web document including inline web objects kb penalty significant limit performance benefit 
tcp bypasses way handshaking having sender start transmitting data segment sent syn 
addition tcp proposes temporal sharing tcp control block tcb state including maximum segment size mss smoothed rtt rtt variance 
mentions possibility caching congestion avoidance threshold offering details 
hoe proposes bandwidth delay product estimate initial packet pair scheme estimate network available bandwidth fifo networks 
allman propose increase initial window optionally restart window roughly bytes 
various studies support 
fixed initial window connections value conservative improvement inadequate situations bandwidth delay product larger 
tcp control block interdependence specifies temporal reusing tcp state including carrying congestion window information connection 
similar fast start reuses congestion window size slow start threshold smoothed round trip time variance 
advantage temporal locality approaches lead significant performance gain 
hand demonstrated optimal initial congestion window size depends network state transfer size 
directly reusing previous parameters optimal 
addition network condition changes reusing overly aggressive 
fast start addresses issue resorting router support 
final solution today internet 
approaches information sharing limited single host possibility inter host sharing mentioned 
summary tcp start performance received considerable attention 
proposals help complete solutions 

minimize latency choosing optimal initial section show determine optimal initial denoted minimizes completion time data transfer transfer size network path characteristics 
analytically derive simple scenario network path characteristics remain unchanged 
extend results general scenarios introducing technique called shift optimization 
derivation simple scenario consider simple network model tcp connection network path characteristics remain unchanged duration connection losses due network congestion 
notations derivations propagation delay bottleneck bandwidth 
buffer size bottle neck router 
clearly number packets link hold total number packets link buffer hold 
know slow start algorithm designed probe available network capacity 
throughput slow start low 
specifically delayed ack packets sent rtt slow start delayed ack throughput lower congestion window grows slowly 
network condition known stable try avoid slow start enter congestion avoidance directly 
achieved setting initial initial need consider congestion avoidance phase order find consider reno style congestion avoidance dominant tcp flavor today internet 
wc wc window size service rate time evolution service rate congestion window congestion avoidance tcp reno 
duration epoch 
consider tcp reno connection starts time initial infinite amount data send 
define service rate receives time tion window size depicts roughly evolve time going periodical epochs 
similar appeared 
simplicity ignore time required fast retransmission algorithm wait duplicated ack duration epoch number packets sent epoch average number packets acknowledged ack close inspection congestion window evolution allows estimate epoch congestion window size starts pack increases linearly time slope ets roundtrip time 
window size reaches sender injects packets network 
network hold packets packet get dropped 
sending packets corresponding ack packets dropped sender detects loss duplicated ack recovers fast retransmission 
window drops back new epoch begins 
total number packets sent epoch transfer size problem fitting block size choosing essentially curve minimize transfer time 
precisely want find minimize satisfies 
choose problem theorem cwnd opt minimize completion time having transfer epoch boundary 
theorem 
illustrated minimize completion time transfer size choosing ini tial appropriately transfer ends epoch boundary time integer detailed proof theorem appendix give intuition theorem 
consider transfer starts time completion time clearly cases ii illustrated comparing area shaded regions evident cases amount data transfered interval data transfered transfer size 
means original transfer time completion time increase 
fixing width shaded region maximize area region having region theorem derive value result summarized theorem theorem 
optimal initial mini completion time file transfer size determined largest integer satisfying defined equation 
derivation theorem appendix note theorem derived case transfer ends epoch boundary 
epoch boundary means connection experience loss final epoch 
theory loss detected recovered fast fast retransmission reality may desirable avoid additional loss 
achieved having transfer equal accordingly initial largest integer satisfying shift optimization prove theorem minimizes integer number required transfer 
assumption need remains unchanged duration connection 
course assuming constant unrealistic real world 
fortunately relax assumption technique call shift optimization 
specifically determined equation greater reduce initial increasing integer number required shifting entire transfer left 
exact amount reduction estimated follows suppose reduce initial takes roughly grow order keep integer number required 
gives total amount transfered data reduced reduction clearly shift optimization doesn increase integer number required 
slightly increase completion time roundtrip time 
believe marginal overhead acceptable return smaller safer initial importantly soon demonstrate section shift optimization algorithm sensitive exact value 
simple example shift optimization illustrated 
example transfer size equation obtain results completion time precisely full 
shift optimization get smaller initial completion time full slightly larger optimization 
optimization initial cwnd optimization initial cwnd simple example shift optimization 
transfer size demonstrate effect shift optimization keep transfer size packets plot computed initial shift optimization function results summarized 
initial cwnd packet initial cwnd packet optimization optimization effect shift optimization file size packets wc packet effect shift optimization file size packets optimization optimization wc packet effect shift optimization 
observations transfer sizes shift optimization initial conservative directly reusing corresponding curve 
second shift optimization computed insensitive value especially large 
multiple result initial insensitivity allows compute near optimal initial varies time accurate estimation available 
demonstrated shift optimization choice initial conservative insensitive value latency increased small amount rtt 
rest refer optimal initial shift optimization 
far considered non shared networks extend results shared networks redefining connection share available network resources estimated segment smaller congestion window size tcp sender detects loss congestion avoidance 
measurement study internet traces shows wan performance reasonably stable terms minutes nearby hosts experience similar identical throughput performance time period measured minutes 
level stability suggests sharing performance information temporarily spatially located hosts help accurately determine network performance particular connection fair share network resources 

tcp spand system design im plementation section design implementation tcp spand system allows applications web servers ftp servers effectively avoid slow start penalty applying theory develop 
design involves modifications server side 
client applications left untouched 
tcp spand incrementally deployable today internet 
system architecture design tcp spand similar spand uses performance gateway monitors traffic entering leaving organization network 
destination network gateway gathers network performance information active tcp flows destination 
aggregates information estimate current network state 
gateway needs track types performance information described reflects network resources available tcp flow 
required choosing optimal initial shown 
estimated segment smaller current congestion window size tcp sender detects loss congestion avoidance 
short data transfer possible entire transfer completes experiencing loss 
case estimated congestion window size connection terminates 
round trip time rtt information 
needed determine initial rate smoothly sending packets initial congestion window discuss detail 
useful determining initial tcp timeout value 
connection start restart idle period application sitting top tcp sender web server extracts current estimation performance gateway 
computes described estimation transfer size locally available 
uses system call initialize parameters underlying tcp sender 
doing slow start tcp sender directly enters congestion avoidance 
achieved setting 
mean tcp sender uses pacing scheme smoothly send packets initial window 
packets initial window paced switches back behavior standard tcp 
implementation issues number questions need answer order implement tcp spand right scope information sharing aggregation 
tcp flows performance information shared aggregated 
performance gateway collect performance infor mation active tcp flows 
collecting performance information algorithms performance gateway aggregate performance information estimate current network state 
applications sitting top tcp extract current estimation performance gate way 
pacing scheme tcp senders send packets initial congestion window 
scheme implemented 
remainder section discuss potential solutions different implementation strategies problems turn 
determining scope sharing aggregation problem discuss determine right scope information sharing aggregation 
ideally share performance information flows share bottleneck router time 
unfortunately current internet architecture difficult determine network flows share bottleneck easy way determine packet dropped 
get difficulty decide conservative approximations destination ip address 
possible approximations proposed host locality flows share common destination ip address network locality flows share destination network 
choose allows sharing 
note somewhat difficult determine network address ip address length network part vary 
simple heuristic assumes ip addresses sharing significant bits belong network 
evaluate accuracy bit heuristic access logs recorded msnbc news site busiest web sites internet today 
traces busy hours am noon consecutive weekdays tuesday august wednesday august 
consist requests msnbc requests inline images excluded 
client ip address reverse dns lookup resolve host name take segments host name domain name 
report client ip addresses sharing significant bits get resolved different domain names 
altogether ip addresses access logs successfully resolved host names reverse dns lookup 
ip addresses distinct bit subnet addresses subnet addresses contain ip addresses resolved different domain names 
demonstrates high accuracy bit heuristic 
collecting performance information second important problem performance gateway collects performance information active tcp flows 
possible implementation strategies problem tcp senders record performance information socket state variables 
application sitting top tcp periodically get information system call report performance gateway sending special performance report packet 
similar approach original spand system 
alternatively possible modify tcp tcp sender piggybacks performance information normal outbound data packets introducing new tcp option 
performance gateway captures packets extract performance information needs 
tcp receivers simply ignore option 
bandwidth processing overhead new tcp option cause performance concern performance information doesn reported frequently 
tcp senders may need negotiate option advance order interoperate existing implementation tcp receivers :10.1.1.31.3480
similar approach piggybacking performance information steal bits normal ip headers 
approach doesn require tcp option negotiation implemented sender side modifications 
third alternative performance gateway infer performance information passively monitoring traffic entering leaving organization network reconstructing tcp protocol state 
similar 
compared approaches passive approach advantage doesn consume extra bandwidth doesn require modification sender protocol stack 
information aggregation collecting performance information performance gateway needs aggregate information accurately estimate current network state 
currently simple sliding window averaging algorithm aggregate performance information 
specifically performance gateway keeps sliding window minutes duration 
uses average values past minutes estimation current case performance information sliding window performance gateway simply informs tcp senders slow start 
part research interested exploring possibility exponentially decaying estimation case 
control parameter algorithm size sliding window 
choice involves tradeoffs hand want large possible order maximize sharing hand large means performance gateway needs keep large amount state addition choice needs match level stability reported literature 
currently set minutes 
clearly matches level stability reported minutes 
msnbc traces demonstrate minute sliding window achieve significant sharing requiring moderate amount state kept performance gateway 
shows cumulative distribution time consecutive requests client network 
bit heuristic described earlier determine client network address 
see time time elapse consecutive requests client network minutes 
suggests minute sliding window web transfers able benefit congestion information accumulated previous transfers 
cumulative fraction cumulative fraction time consecutive requests network am noon aug am noon aug am noon aug time sec cumulative distribution time consecutive requests network 
bit heuristic determine network address ip address 
assess amount state performance gateway needs keep 
performance gateway keeps state destination network total amount required state proportional number different destination networks showing minute interval 
request msnbc traces count number different client networks appeared minutes 
plot cumulative distribution numbers 
evident performance gateway needs keep state different destination networks busiest periods easily handled modern computers 
retrieving current estimation network state problem discuss application sitting top tcp retrieve current estimation performance gateway 
possible solutions problem similar spand application explicitly query information sending special performance inquiry packet performance gateway 
alternatively performance gateway infers application needs current estimation actively cumulative fraction cumulative distribution number different client networks seen minutes am noon aug am noon aug am noon aug number different client networks cumulative distribution number different client networks seen minutes 
push information host application runs 
simple heuristics performance gateway determine application needs estimation 
example performance gateway captures incoming file transfer request get request simpler captures inbound packet new tcp connection connection idle safely infer corresponding tcp flow needs estimation 
heuristics implemented easily especially gateway uses windmill approach collect performance information passive monitoring protocol reconstruction 
pacing lastly discuss pacing 
tcp spand tcp senders don go slow start procedure initializing derived potentially large 
sending packets initial congestion window back back clearly unacceptable result large burst overflowing network bottleneck buffer 
natural solution problem tcp sender pacing scheme smoothly send packets initial window 
packets initial window sent sender switch back behavior standard tcp 
pacing schemes proposed literature :10.1.1.36.479
introduce alternative scheme leaky bucket 
scheme tcp sender uses leaky bucket specifically token bucket shape outgoing traffic 
sender packet send checks token bucket 
sufficient tokens packet sent immediately delayed fine grained timer tokens 
depth token bucket configured limit maximum burstiness outgoing traffic 
set segments simulations 
token filling rate set average sending rate packets roundtrip 
order implement bucket pacing scheme need fine grained timer reschedule segment transmission case sufficient tokens 
token filling rate inversely proportional need relatively accurate estimation achieved ms ms timer granularity standard tcp 
simulations ms timer 
tcp option available improve accuracy rtt estimation 
evidence suggest overhead software timers significant modern processor technologies 
reports overhead order microseconds 
timer overhead significant addition cost interrupts processing ack goes ack clocking 
implementation status currently implemented tcp spand ns network simulator 
implementation tcp newreno variant tcp uses partial new ack information recover multiple packet losses window rate rtt 
described performance gateway uses minute sliding window aggregate performance information 
simplicity assume communication performance gateway hosts organization network instantaneous 
reasonable compared large delay wan connection communication latency lan environment negligible 

simulation results section extensive simulations ns network simulator study performance tcp spand 
discuss simulation topology experiment methodology detailed results various simulation scenarios 
simulation topology simulations single bottleneck topologies uncover illuminate important issues realistic topologies evaluate performance tcp spand real world scenarios 
single bottleneck topology shown 
bursty connections established subset sources left sinks right 
bottleneck buffer kb 
bottleneck router uses fifo scheduling drop tail buffer management 
non bottleneck links mbps capacity ms way propagation delay 
consider scenarios shown table 
source source source bottleneck link router router mbps ms dest dest dest single bottleneck topology 
bottleneck buffer kb 
settings bottleneck link summarized table 
multiple bottleneck topology illustrated 
topology set user flows traverse congested network path consists hops 
cross traffic generated inter mediate router similar topology 
router kb buffer uses fifo scheduling drop tail buffer management 
links adjacent routers cross traffic sources 
mbps capacity ms way propagation delay 
links adjacent routers consider scenarios summarized table roughly correspond scenario topology 
note aggregated buffer size larger multiple bottleneck scenario 
user flows rk cross traffic sources cross traffic sinks cross traffic sources cross traffic sinks cross traffic sources cross traffic sinks user flow sinks multiple bottleneck topology 
bottleneck buffer kb 
settings bottleneck link summarized table 
experiment methodology set experiments way mimic behavior web transfers experiment consists rounds 
round sender transfers file start time uniformly distributed central point time interval denoted jitter 
round seconds idle time 
average completion time file transfers experiment performance metric 
simulation configuration report mean runs experiment 
looked variation small compared mean don report 
compare performance tcp spand variants tcp reno slow start restart reno ssr tcp reno enforces slow start restarting data flow idle period 
reno slow start restart reno nssr tcp reno reuses prior congestion window restarting idle period scheme sunos 
newreno slow start restart newreno ssr tcp newreno restart behavior similar reno ssr 
newreno slow start restart newreno nssr tcp newreno restart behavior similar reno nssr 
maximum window size tcp connections simulations set kb 
tcp segment size set kb 
order remove performance difference due different timer granularities tcp flavors timer granularity ms specified 
just tcp protocols experiment way connections way connections 
tcp classes derived derived ns simulator 
consequently overhead way handshaking connection setup 
believe removing connection setup overhead necessary better understand performance impact slow start procedure major focus tcp spand 
avoiding connection setup overhead orthogonal avoiding slow start penalty studied literature 
example effectively amortize overhead multiple transfers 
performance evaluation single bottleneck topology average completion time second average completion time second scenario bandwidth link delay descriptions mbps ms typical terrestrial wan links close speed mbps ms typical satellite links close speed mbps ms typical satellite links speed table different simulation scenarios single bottleneck topology scenario bandwidth link delay descriptions mbps ms roundtrip time rtt similar scenario mbps ms roundtrip time rtt similar scenario table different simulation scenarios multiple bottleneck topology 
number hops 
spand reno nssr reno ssr newreno nssr newreno ssr scenario transfer size kb spand reno nssr reno ssr newreno nssr newreno ssr number connections scenario transfer size kb number connections performance comparison different number connections 
bottleneck link setting scenario scenario defined table 
round file transfers start seconds jitter sec 
telnet sessions avoid deterministic behavior 
section evaluate performance tcp spand single bottleneck topology illustrated 
examine multiple bottleneck topologies section 
performance evaluation concurrent web transfers varying number competing connections compare performance number competing tcp connections varies transfer size kept kb average web transfer size 
telnet sessions compete main flows help avoid deterministic behavior 
inter arrival times telnet sessions drawn tcplib distribution implemented ns 
shows results different scenarios bot average completion time second average completion time second scenario competing transfer size kb spand reno nssr reno ssr newreno nssr newreno ssr number connections scenario competing transfer size kb spand reno nssr reno ssr newreno nssr newreno ssr number connections performance comparison different number connections udp flows cross traffic 
times udp sources drawn pareto distributions shape parameters set 
mean time second mean time seconds 
times sources transmit rate kbps 
jitter transfer start time round seconds 
link link mbps latency ms ms scenario table 
shown tcp spand leads significant reduction average completion time 
compared reno ssr newreno ssr tcp spand reduces latency cases means improvement average data rate 
compared reno nssr newreno nssr completion time reduction smaller significant cases 
notice reno nssr newreno nssr wellknown overly aggressive perform considerably worse tcp spand 
major reasons directly reusing previous optimal second sending packets initial window usually bursty cause losses tcp spand 
average completion time second average completion time second spand reno nssr reno ssr newreno nssr newreno ssr scenario competing tcp connections spand reno nssr reno ssr newreno nssr newreno ssr file size packet scenario competing tcp connections file size packet average completion time second average completion time second spand reno nssr reno ssr newreno nssr newreno ssr scenario competing tcp connections spand reno nssr reno ssr newreno nssr newreno ssr file size packet scenario competing tcp connections file size packet performance comparison different transfer sizes 
tcp connections competes bottleneck link setting scenario scenario defined table 
round file transfers start seconds jitter sec 
telnet sessions avoid deterministic behavior 
varying transfer size compare performance transfer size varies 
shown tcp spand reduces completion time wide range transfer sizes scenarios study 
percentage terms improvement decreases transfer size increases 
expect avoiding slow start penalty bigger impact small transfers larger ones 
improvement increases link delay due larger bandwidth delay product 
improvement tends decrease number connections increases 
mainly number connections increases connection share decreases impact slow start phase tcp performance significant 
performance evaluation udp flows cross traffic reported www related traffic tends self similar nature 
shown self similar traffic may created udp sources times drawn heavy tailed distributions pareto distribution 
section evaluate performance tcp spand udp flows cross traffic 
evaluate performance number competing connections varies transfer size kept kb 
simulation results illustrated 
scenarios tcp spand reduces latency compared reno ssr newreno ssr means improvement average data rate 
compared reno nssr newreno nssr latency reduction 
shows result varying transfer size keeping number connections constant 
see performance benefit tcp spand greater larger bandwidth 
performance evaluation bulk transfers ftp cross traffic compare performance bulk transfers ftp cross traffic 
simulation results summarized 
simulations number ftp connections bottleneck link heavily loaded 
shows results ftp sessions cross traffic create contention link ms latency 
tcp spand reduces average completion time compared reno ssr newreno ssr 
improvement smaller compared reno nssr newreno nssr known aggressive 
bottleneck link performance improvement significant shown 
notice case average completion time tcp spand connections slightly larger reno nssr average completion time second average completion time second scenario competing connection number spand reno nssr reno ssr newreno nssr newreno ssr file size packet scenario competing connection number spand reno nssr reno ssr newreno nssr newreno ssr file size packet performance comparison different transfer sizes udp cross traffic 
settings 
newreno nssr rtt connection number smaller 
mainly shift optimization pacing tcp spand conservative 
small number short connections tcp spand fully probe available bandwidth large scenario 
long lived connections problem 
shows results varying transfer size keeping connection number constant 
performance benefit tcp spand greater larger bandwidth 
performance evaluation multiple bottleneck topology section evaluate performance tcp spand underlying network path heavily congested multiple bottlenecks 
multiple bottleneck topology illustrated 
number hops fixed 
intermediate router udp connections 
just time udp sources drawn pareto distributions shape parameters set 
mean time second mean time seconds 
cross traffic generated performance evaluation kbps udp sources average completion time second average completion time second scenario competing transfer size kb spand reno nssr reno ssr newreno nssr newreno ssr number connections scenario competing transfer size kb spand reno nssr reno ssr newreno nssr newreno ssr number connections performance comparison different number connections ftp telnet sessions cross traffic 
jitter transfer start time round sec jitter sec 
evaluate performance udp source generates cross traffic rate kbps time single bottleneck case 
keep transfer size kb vary number competing connections 
illustrated scenario considered scenario tcp spand leads significant reduction completion time reno ssr newreno ssr reno nssr 
performance improvement comparable case shown 
fix number competing connections vary transfer size 
evident tcp spand achieves significant performance improvement similar case shown 
performance evaluation kbps udp sources investigate performance tcp spand heavy congestion increase sending rate udp sources time kbps redo experiments 
simulation results summarized 
significant increase completion time evident underlying network path highly congested 
heavy congestion tcp spand consistently performs average completion time second average completion time second scenario competing connection number spand reno nssr reno ssr newreno nssr newreno ssr file size packet scenario competing connection number spand reno nssr reno ssr newreno nssr newreno ssr file size packet performance comparison different transfer sizes ftp cross traffic 
settings 
tcp flavors 
course performance improvement decreases 
surprising impact initial congestion window significant network highly congested 
tcp friendliness section demonstrate performance improvement tcp spand come expense degrading performance connections standard tcp 
words tcp spand tcp friendly 
show considering mixture tcp topology 
half connections tcp spand equal number reno ssr aggressive tcp schemes 
compare performance case connections reno ssr 
jitter transfer start time round set second create maximum contention bottleneck bandwidth 
telnet sessions introduced avoid deterministic behavior 
ms timer granularity reno ssr tcp spand 
summarizes simulation results different settings bottleneck link link latency ms scenario ms scenario transfer size kept kb kb 
scenarios considered performance reno ssr mixed tcp spand virtually connections reno ssr 
demonstrates tcp spand tcp friendly average completion time second average completion time second scenario kbps udp cross traffic transfer size kb spand reno nssr reno ssr newreno nssr newreno ssr number connections scenario kbps udp cross traffic transfer size kb spand reno nssr reno ssr newreno nssr newreno ssr number connections performance comparison different number connections kbps udp flows cross traffic 
jitter transfer start time round seconds 
heavy contention 
worth mentioning scenario shown tcp spand performs reno ssr 
jitter second 
case connection share small due heavy contention 
consequently optimal initial close tcp spand behave reno ssr 
comparison performance benefit tcp spand greater scenario shown bandwidth delay product larger 
ms timer granularity reno ssr evaluate tcp friendliness tcp spand 
results illustrated 
settings tcp spand outperforms reno ssr 
reno ssr experiences little performance degradation presence tcp spand cases 
cases degradation occurs large number connections network highly congested 
cases reno ssr frequently needs timeout loss recovery 
ms timer granularity recovery unnecessarily slow degrades performance 
known problem traditional tcp 
summary simulation results summarize section extensive simulations evaluate performance tcp spand 
tcp spand consistently outperforms reno ssr newreno ssr reno nssr newreno nssr simulation scenarios presence multiple heavily congested links 
performance benefit greatest connection share large 
cases tcp spand reduce latency average completion time second average completion time second scenario kbps udp cross traffic connection number spand reno nssr reno ssr newreno nssr newreno ssr file size packet scenario kbps udp cross traffic connection number spand reno nssr reno ssr newreno nssr newreno ssr file size packet performance comparison different transfer sizes kbps udp flows cross traffic 
settings 
compared reno ssr newreno ssr compared reno nssr newreno nssr 
significant performance improvement come cost degrading tcp connections 
demonstrated tcp spand tcp friendly heavy contention 
major factors contribute performance tcp spand 
sharing aggregating performance information located hosts sender quite accurate estimation current network conditions 
second initial tcp spand chosen theoretical analysis optimal initial employ shift optimization described choice conservative insensitive accuracy estimation current network characteristics 
way tcp spand utilize available bandwidth efficiently safely connection share large 
network heavily loaded tcp spand tends conservative 
particularly connection share bytes choice initial tcp spand conservative proposed rfc 
pacing scheme send packets initial congestion window tcp spand effectively reduces burstiness tcp start restart 

investigate possibility speeding short data transfers effectively avoiding slow start penalty 
analyzing tcp start dynamics derive optimal initial congestion window function transfer size connection share network resources 
propose average completion time second average completion time second scenario kbps udp cross traffic transfer size kb spand reno nssr reno ssr newreno nssr newreno ssr number connections scenario kbps udp cross traffic transfer size kb spand reno nssr reno ssr newreno nssr newreno ssr number connections performance comparison different number connections kbps udp flows cross traffic 
jitter transfer start time round seconds 
incrementally deployable architecture called tcp spand accurately estimates connection fair share network resources sharing performance information large number colocated hosts 
estimation transfer size tcp sender compute optimal initial congestion window size 
doing slow start directly enters congestion avoidance uses pacing scheme smoothly send packets initial congestion window 
extensive simulations ns simulator evaluate performance resulting system 
results show tcp spand significantly reduces latency short transfers presence multiple heavily congested bottlenecks 
performance benefit come expense degrading performance connections standard tcp 
number directions want explore plan implement tcp spand real systems evaluate performance internet experiments 
run simulations evaluate tcp spand controlled environment 
particular interested understanding performance impact different router dropping policies red tcp spand 
secondly want better understand impact pacing tcp performance especially short tcp flows 
shows pacing lead lower throughput study simulations relatively long lived flows 
interesting understand impact pacing short flows dominant today internet traffic 
interested developing effective techniques average completion time second average completion time second spand mixed reno ssr mixed reno ssr scenario transfer size kb spand mixed reno ssr mixed reno ssr number connections scenario transfer size kb number connections average completion time second average completion time second spand mixed reno ssr mixed reno ssr scenario transfer size kb spand mixed reno ssr mixed reno ssr number connections scenario transfer size kb number connections tcp friendliness 
telnet sessions background traffic 
transfer start time round jitter sec 
transfer size kb kb 
timer granularity reno ssr tcp spand ms determining network flows share bottleneck 
determining network flows share bottleneck challenging research problem 
despite progress remains open problem find solution scales flows variety traffic conditions 
plan investigate better algorithms information aggregation 
particular want develop techniques exponentially decays estimated little performance information available active connections 
techniques proposed address similar problems 
interested investigating performance benefits sharing congestion information heterogeneous data streams proposed 

allman dawkins glover henderson heidemann kruse ostermann scott semke touch tran ongoing tcp research related satellites internet draft draft ietf res issues txt nov 
allman glover sanchez enhancing tcp satellite channels standard mechanisms rfc sept 
allman floyd partridge increasing tcp initial window rfc sept 
allman hayes evaluation tcp larger initial windows acm computer communication review july 
aggarwal savage anderson understanding performance tcp pacing proc 
ieee infocom mar 
braden extending tcp transactions concepts rfc nov 
braden tcp tcp extensions transactions functional specification rfc july 
balakrishnan rahul seshan integrated congestion management architecture internet hosts proc 
sigcomm sept 
balakrishnan seshan stemm katz analyzing stability wide area network performance proc 
sigmetrics 
balakrishnan padmanabhan katz effects asymmetry tcp performance proc 
acm ieee mobicom sept 
balakrishnan padmanabhan seshan stemm katz tcp behavior busy internet server analysis improvements proc 
ieee infocom mar 
dovrolis ramanathan proportional differentiated services delay differentiation packet scheduling proc 
sigcomm sept 
floyd fall promoting congestion control internet ieee acm transactions networking aug 
average completion time second average completion time second spand mixed reno ssr mixed reno ssr scenario transfer size kb spand mixed reno ssr mixed reno ssr number connections scenario transfer size kb number connections average completion time second average completion time second spand mixed reno ssr mixed reno ssr scenario transfer size kb spand mixed reno ssr mixed reno ssr number connections scenario transfer size kb number connections tcp friendliness 
configuration reno ssr uses ms timer granularity ms tcp spand uses ms timer granularity 
floyd henderson newreno modification tcp fast recovery algorithm rfc experimental april 
feng kandlur saha shin understanding tcp dynamics integrated services internet proc 
nossdav may 
gribble brewer system design issues internet middleware services deductions large client trace proc 
st usenix symposium internet technologies systems usits dec 
jacobson karels congestion avoidance control proc 
sigcomm aug 
lakshman new method analyzing feedback protocols applications engineering web traffic internet proc 
sigmetrics 
hoe improving start behavior congestion control scheme tcp proc 
sigcomm aug 
handley padhye floyd tcp congestion window validation technical report department computer science university massachusetts amherst 
jacobson braden borman tcp extensions high performance rfc may :10.1.1.31.3480
keshav control theoretic approach flow control proc 
sigcomm sept 
thompson miller wilder wide area internet traffic patterns characteristics ieee network nov 
lakshman madhow performance analysis window flow control tcp ip effect high bandwidth delay products random loss ifip transactions high performance networking pp 
north holland 
mah empirical model network traffic proc 
infocom 
malan jahanian extensible probe architecture network protocol performance measurement proc 
sigcomm 
www msnbc com 
ucb lbnl vint network simulator ns version 
www mash cs berkeley edu ns 
padmanabhan coordinated congestion management bandwidth sharing heterogeneous data streams proc 
nossdav june 
paxson measurements analysis internet dynamics phd thesis berkeley may 
padmanabhan addressing challenges web data transport ph thesis uc berkeley 
padmanabhan katz tcp fast start technique speeding web transfers proc 
ieee globecom internet mini conference nov 
park kim crovella relationship file sizes transport protocols self similar network traffic proc 
icnp 
padmanabhan mogul improving latency proc 
second international world wide web conference oct 
average completion time second average completion time second scenario kbps udp cross traffic connection number spand reno nssr reno ssr newreno nssr newreno ssr file size packet scenario kbps udp cross traffic connection number spand reno nssr reno ssr newreno nssr newreno ssr file size packet performance comparison different transfer sizes kbps udp flows cross traffic 
settings 
rubenstein kurose towsley detecting shared congestion flows measurement proc 
sigmetrics june 
savage cardwell anderson case informed transport protocols proc 
th workshop hot topics operating systems hotos mar 
seshan stemm katz spand shared passive network performance discovery proc st usenix symposium internet technologies systems usits dec 
shepard partridge tcp starts packets buffers rfc sept 
stoica zhang providing guaranteed services flow management proc 
sigcomm sept 
touch tcp control block interdependence rfc april 
heidemann improving restart idle tcp connections technical report university southern california nov 
willinger taqqu sherman wilson self similarity high variability statistical analysis ethernet lan traffic source level proc 
sigcomm 

acknowledgment special brad karp geoffrey voelker valuable comments 
venkata padmanabhan providing msnbc web server trace data measurement server overhead keeping state information 
appendix proof theorem proof suppose achieves mini mum completion time prove theorem prove equation equa tion demonstrate equation leads theorem 
take steps cases equation step proof equation 
need consider cases 
illustrated 
case equation follows naturally monotonicity 
illustrated 
monotonically increasing consequently completes proof equation 
step equation theorem 
periodicity equation means transfer file size period words transfer size completion time ends epoch boundary optimal completion time exactly completes proof theorem 
derivation theorem theorem derive follows calculate integer immediately integer consequently way derive equation get equation immediately get theorem 
