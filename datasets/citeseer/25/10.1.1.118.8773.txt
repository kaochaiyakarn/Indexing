clustering association rules brian lent arun swami jennifer widom consider problem clustering dimensional rules large databases 
geometric algorithm performing clustering em association rule clustering system arcs 
association rule clustering useful user desires segment data 
measure quality segment ation generated arcs minimum description length mdl principle encoding clusters databases including noise errors 
scale experiments show arcs algorithm scales linearly amount data 
data mining efficient discovery interesting pat terns large collections data recognized important area database research 
commonly sought patterns association rules introduced :10.1.1.40.6984
intuitively association rule identifies frequently occur ing pattern information database 
consider super market database set items purchased single customer check stand recorded transaction 
supermarket owners may interested finding asso items purchased check stand 
example association cus buys bread butter buy milk 
set transactions transaction set items association rule expression sets items 
meaning rule trans actions contain items tend contain items 
generally association rules conjunction transaction basket type data limited domain 
dealing customer demographic data example database schema defines fixed set research initiated authors silicon graphics computer systems continuing support author provided graduate fellowship department defense office naval research 
ieee department computer science stanford university stanford ca lent widom cs stanford edu arun cs stanford edu attributes record customer record 
record contains value attribute attribute value 
replacing sets items traditional definition association rules conjunctions attribute value equalities gen definition association rules include type non transactional data 
example age salary home 
mining association rules type non transactional data may find hundreds thousands rules corresponding specific attribute values 
introduce clustered association rule rule formed combining similar adjacent association rules form general rules 
set attribute value equalities clustered rules set value ranges inequalities 
example clustered rule age home formed association rules age home age home 
problem consider efficiently mine clustered association rules large databases rule mining algorithm step process 
practice important rules mined database understandable useful user 
clustered association rules helpful reducing large number association rules typically computed existing algorithms rendering clustered rules easier interpret visualize 
practical clusters perform segmentation large customer oriented databases 
example consider marketing sends direct mail catalog current cus base promoting products 
orders taken customer placed transactional database recording list items purchased demographic information purchaser 
point com decides expand current customer base 
group ing existing customers total sales instance groups excellent average average prof clustered association rules attributes demographic database segment customers 
segmentation selecting new customers target mail ings respond 
segmentation defines specific criterion custom ers rated excellent function attribute val ues 
corresponds considering clustered association rules form 
excellent average av erage ai attribute ranges age 
consider association rule clustering dimensional space axis represents attribute database left hand side lhs rule 
feel attribute segmentation easily un user section discuss possibilities handling higher dimensionality data 
fore processing algorithms lhs attributes chosen user 
statistical techniques identifying influential attributes dataset factor analysis principal component ana studied 
user selects value third attribute cri segmentation 
adjacency definition ensures clusters rectangular re data 
helps readability final clustered association rules 
clustering general difficult problem re search topic studied quite time 
dimensional attribute assumptions problem identifying fewest clusters dimensional grid specific instance decision set covering problem shown np complete 
clustering approach begins source data tuple form partitioning attributes take values continuous domain 
perform single pass data association rule engine derive set association rules 
cluster attribute association rules right hand side rules sat segmentation criteria 
approach clus tering problem heuristic geometric proper ties dimensional grid produces efficient lin ear time approximation optimal solution 
cluster ing produces desired segmentation 
test segment ation accuracy necessary modify certain system parameters produce better segmentation repeat process 
related problem sets attribute value pairs age salary points dimensional space finding optimal regions respect spe criteria space introduced 
authors considered types regions rectangles connected monotone focus 
fo cus rectangular regions usually understandable 
require user choose parameters necessary generating asso ciation rules provide fully automated system identifying clustered association rules 
authors consider problem mining quant attributes contrast previous algorithms designed transaction type items :10.1.1.40.8600
authors partition attributes equi depth bins bin contains roughly number tuples introduce new measure help user decide partitions attribute :10.1.1.40.8600
address issues com adjacent intervals greater expected value interest measure rules 
component requires partitioning quantitative attributes differs partitioned quantitative attrib means form clusters ultimately define seg mentation data 
system fully automated require user specified thresholds :10.1.1.40.8600
addition provided ive definition interesting association rule gives intuitive means segmenting data 
uses user specified parameters partial complete ness measure determine geo metric properties attribute space form clusters :10.1.1.40.8600
related problem classification data ized disjoint groups common ics attributes 
techniques classification include instance classifiers decision trees artificial neural networks genetic algorithms various statistical tech niques 
classification studied primarily ai community computational complexity algorithms generally inhibits performance efficiency ne mining large databases furthermore algorithms scale increasing database size 
database community fo designing efficient classification algorithms large databases 
goal classification compute predictive model groups 
emphasis produce accurate model predict group unseen instance belongs 
understanding model classification algorithm computes usu ally secondary importance 
contrast want segment space attribute values criterion grouping attribute manageable segments understandable user 
related area image processing 
rich literature exists traditional image segmentation gorithms tend focus obtaining exact boundaries clusters result limit lar clusters feel necessary understandability user 
system designed simple matter exchanging clustering algorithm 
organization section formal definitions view 
section describes association rule clustering system arcs describes gorithm clustering 
discuss preprocessing step smooth grid dynamic pruning removes un interesting clusters 
statistical measures setting ini tial threshold values described section 
sec tion experimental results synthetic data show scalability arcs large databases 
classifier alternative way segmenting data compared known classifier approach stead uses clustered association rules segmentation 
sec tion concludes presents ideas 
preliminaries section formal definitions termin ology problem mining clustered association rules give overview approach 
terminology attribute categorical non categorical 
categorical attributes finite number possible values ordering 
ex amples categorical attributes include zip code hair color car non categorical attributes call quantitative attributes im plicit ordering assume continuous values usually specified range 
examples quantitative attributes include salary age interest rate database tuples tuple set attribute values called items form attribute value 
association rule expression form sets attribute value items attribute appears 
refer left hand side lhs rule right hand side rhs rule 
common numeric measures assigned asso ciation rule support confidence 
support quantifies items occur tuple fraction total number tuples id denotes total number tuples 
confidence quantifies occur fraction number tuples occurs 
generating set association rules known algorithms user specify minimum threshold values support confidence 
example association rule age salary rating quantitative attributes typically assume wide range values respective domains par attributes intervals called bins 
pa consider equi width bins interval size bin 
choices possible equi depth bins bin contains roughly number tuples homogeneity bins bin sized tuples bin uniformly distributed 
approach easily extended handle cases 
quantitative attribute parti tioned bins bins mapped consecutive integers attribute values mapped bins value re placed corresponding integer bin 
cat attributes map attribute values set consecutive integers integers place categorical values 
mapping happens prior run ning association rule mining algorithm binning pro cess transparent association rule engine 
bin ning mapping approach :10.1.1.40.8600
clustering defined combination cent attributes values adjacent bins attribute values 
example clustering age age results age 
clustered association rule ex pression form xc yc 
xc yc items form attribute value attribute denotes lower bound values ith bin 
clustered association rules support confidence minimum threshold levels 
overview approach consider problem clustering rules form lhs attributes quantitative rhs attribute categorical rhs attribute quantitative require binning resulting bins treated categorical values 
define segmentation collection clustered association rules spe cific value criterion attribute 
set attribute association rules binned data form dimensional grid axis cor responds lhs attributes 
grid plot specific value rhs attribute cor responding association rules 
example grid shown 
goal find fewest number clusters shown circles cover asso ciation rules grid 
clusters represent clustered association rules define segmentation 
consider quantitative lhs attributes lack categorical attributes introduces additional complexity 
currently extending handle categorical lhs attributes 
xx xxxxxx xx xxxx tx xx xx xx xx ok age 
sample grid clustered associ ation rules 
algorithm introduce cluster association rules grid solves part problem 
recall order mine collection association rules define minimum thresholds support confidence 
quantitative attributes determine number bins partition attribute domain 
finding values parameters gives best segmentation difficult combinatorial optimization problem 
unifying framework uses heuristics searching space ef results 
shows high level view entire system compute clustered rules describe 
source data read attribute values par described earlier 
num ber bins changed user doing restarts system 
association rule engine special purpose gorithm operates binned data 
minimum sup port minimum confidence generate association rules 
association rules discovered particu lar level support confidence form grid rules give information group rhs segmenting 
apply algorithm section grid certain techniques described sections form clusters cent association rules grid 
clustered associ ation rules tested accuracy verifier sample tuples source database 
ac supplied heuristic optimizer section adjusts minimum support threshold minimum confidence threshold restarts mining process association rule engine 
heuristic adjustments con verifier detects significant improvement resulting clustered association rules verifier de time expired 
record data bins bins array binned data min 
support min 
confidence 
engine rules rule bitmap heuristic conversion optimizer clustering test data verifier cluster analysis clustered association rules 
architecture association rule clustering system association rule clustering system arcs arcs framework shown 
detail components system 
binning data reads tuples database re places tuples attribute values corresponding bin number previously described 
determine bin numbers lhs attributes az ay 
corresponding bin numbers bin index array bin pair maintain number bin tuples having pos sible rhs attribute value total number binx tuples 
size array ny ns nx number bins ny number bins cardinality rhs segmentation attribute 
system assume array fit main memory 
typically interested value segmentation criteria time customer rating excellent maintaining data structure memory compute entirely new segmentation different value segmentation criteria need re bin original data 
memory space premium set ns maintain tuple counts value segmentation criteria interested 
association rule engine possible existing association rule mining algorithms mine binned data describe efficient algorithm special case mining twodimensional association rules data structure constructed binning process 
deriving association rules binned data straightforward 
gk rhs criterion attribute 
cell represented association rule lhs values bins define cell rhs value gk ga represents range bin represents range lower bounds th attribute bin jth attribute bin respectively 
support rule confidence ak total number tuples source data total number tuples mapped location gk number tuples mapped location criterion attribute value gk 
derive association rules support confidence threshold need check occupied cells see conditions hold 
thresholds met output pair corresponding association rule binned data shown 
pairs create bitmap grid algorithm described section locate clusters association rules 
algorithm shown requires single pass data contrast existing algorithms may need passes find association rules 
important note maintaining data structure apply different support confidence thresholds reexamining data making re mining process dramatically faster previous algorithms 
system changing thresholds nearly instantaneous 
clustering presenting simple example clustering problem illustrate idea 
consider association rules rhs attribute group label value age salary group label age salary group label age salary group label age salary group label lhs age bins lhs salary bins sl rules binned form binned association rules input ii computed binning component 
value gk criterion segmentation 
min support threshold 
min confidence threshold 
total number tuples source data 
number bins 
ny number bins 
output set pairs bin numbers representing association rules form gk 
procedure min support count min support association rule generation binned data ny gk min support count ga total min conf output 
association rule mining gorithm age salary group label age salary age salary ss group label age az salary group label represent rules grid 
clearly linear adjacent cells combined form line segment naturally extend idea lar regions 
doing original association rules clustered subsumed rule age salary assuming bin mappings shown final clustered rule output user age salary group label intuitively starting grid searching rectangular clusters best cover occupied cells 
example grid algorithm select clusters shown interested finding fewest number clusters 
problem investigate find non overlapping clusters precisely find grid constructed directly ai pairs output association rule engine 
sj age 
grid showing association rules xx 
clustering rules criterion 
example simple criterion minimizing total number clusters section describe criterion 
process clustering difficult noise outliers 
noise occurs data tuples belong groups group currently clustering 
example customer database contain data cus group label rhs attribute values customer rating average aver age excellent excellent may cri value segmenting data clusters 
tuples having value considered noise af fect support confidence clusters com pute 
outliers tuples belong group lie outside existing clusters group 
give examples occurrences show clustering system mitigate effects sections 
algorithm algorithm enumerates clusters grid 
select largest cluster enumerated list applying algorithm clusters remain 
shown greedy approach pro duces near optimal clusters se isi time final set clusters 
experimented pure greedy cluster selection complete search possible clusters greedy approach produced similar results non greedy approach saving significant amount computation 
creating bitmap grid association rules setting bit value association rule 
greedy approach remove iteration algorithm single cluster set candidate clusters covers remain ing unclustered cells 
cluster cells removed consideration clustering algorithm algorithm considers new grid 
algorithm shown cluster enumeration 
performs bitwise operations locate clusters bitmap grid 
examine row bits bitmap turn bitwise anding re rows 
step analyze row ded bits determine location possible clusters 
consider example row bits just row tells cluster size mask bit position cluster size bit positions 
consider mask shown bitwise rows starting row bit map denoted mask number rows bitmap 
cluster dimensions respectively bit positions set rows 
algorithm begins defining mask mask row bitmap bitwise anding second row producing second mask mask 
continue bitwise anding mask successor row reach row mask zero containing set bits 
consider second row starting row apply algorithm successor rows 
step mask changes indicating bits cleared know cluster report 
example consider simple bitmap masks starting row row mask row mask mask mask defined row second mask mask mask bitwise anded second row 
mask identical mask evaluate mask clusters finding cluster indicated solid circle 
see mask identifies cluster single bit set second mask meaning cluster extends rows 
cluster indicated dashed circle 
mask identifies clusters mask contains set bits signifying clusters gin row extend row 
repeat process second row bitmap producing clusters shown bitmap masks starting row row mask mask row process ends mask row com puted 
algorithm implemented efficiently uses arithmetic registers bitwise bit shift machine instructions 
assume size bitmap fits memory easily case xl bitmap 
grid smoothing preprocessing step clustering apply smoothing function bitmap grid 
practice grids contain jagged edges small holes missing values association rule 
typical example shown 
features inhibit ability find large complete clusters 
reduce effects caused anomalies image processing technique known low pass filter smooth grid prior processing 
essentially low pass filter dimensional grid replaces value average value adjoining neighbors smoothing large variations inconsistencies grid 
smoothing filters reduce noise known domains communications computer graphics 
details filtering algorithm omitted brevity nicely illustrates res 
experiments association rule support values binary values performed yielding prom ising results see section 
cluster pruning clusters algorithm meet certain criteria dynamically pruned set final candidate clusters 
typically clusters smaller graph ful creating generalized segmentation 
pruning smaller clusters aids reducing outliers effects noise eliminated smoothing step 
case algorithm finds clusters suf large pruning performed 
likewise input number bins attribute number bins attribute bm bitmap representation grid 
bm ith row bits bitmap output clusters association rules row row set bits bm row height row bm row locate clusters process row height break process row height height height extend height possible clusters process row height 

algorithm iiii iiii attribute attribute 
typical grid prior smoothing smoothing 
function age salary group age salary age salary group group 
function generate syn data gorithm locate sufficiently large cluster termin ates 
idea pruning reduce error reduce size result ai community cially decision trees 
cluster accuracy analysis determine quality segmentation set clustered association rules measure quantities number rules computed ii summed error rate rules sample data 
quantities combined minimum description length mdl principle arrive quantitative measure quality compared optimal segmentation 
describe experiments describe error measure rule describe application mdl principle 
set quantitative attributes salary sion age loan categorical attrib education level car zip code test database defined :10.1.1.41.6931
attributes functions various com plexity listed 
function shown generate synthetic data experiments 
optimal segmentation data clustered association rules represents disjuncts function 
clustering process dif introduce noise random perturbations tribute values error due binning input attributes age salary 
intuitive measure accuracy resulting clustered rules see rectangular clusters overlap precise disjuncts function 
define notion false positives false negatives graphically shown seek minimize sources error 
light grey rectangle represents actual cluster function dark grey rectangle represents computed cluster 
note general optimal cluster need rectangular 
false positive results com puted cluster incorrectly identifies outside op cluster belonging specified group false negatives tuples belong group identified computed cluster 
total summed error particular cluster total false computed cluster false positives false negatives 
error overlapping regions positives false negatives 
optimal clustering known func tion generate data exact measure error possible 
interested real world data optimal clustering known se lect random sample tuples database samples determine relative error com puted clusters 
relative error approximation exact error counting number false negatives false positives sample original database 
order get approximation actual error repeated sampling stronger statistical technique 
strategy measure quality tion set clustered association rules mdl principle 
simplified model mdl worked practice 
mdl principle states best model encoding data minimizes sum cost describing model cost describing data model 
goal find model results lowest cost cost typ ically measured bits 
context clustering models descrip tions clusters data sampled data de scribed 
greater number clusters segmentation higher cost necessary describe clusters 
cost encoding sampled data set clusters model defined sum errors clusters 
intuition tuple error identified particular cluster cost included description cluster 
tuple error specifically identify incurs cost 
follow ing equation determine cost set clustered association rules cost log ici log errors ci number clusters errors sum false positives false negatives clusters logarithmic factor having clusters re quires logarithmically increasing number bits logarithmic factor provides favorable non linear separation close near optimal solutions 
empirical evidence simplifying sumption clusters uniform encoding cost 
constants wc allow user impart bias optimal cluster selection providing greater flex finding representation segmentation usable 
wc large segmentations clusters penalized heavily higher associated cost segmentations data fewer clusters greater probability ing optimal 
likewise large system favor segmentations error rate lowest 
con equal wc default case term bias cost 
heuristic optimizer recall means de scribed section seeks minimize mdl cost 
parameter heuristics section describe algorithm sys tem uses adjust minimum support confidence thresholds accuracy analysis previ ous section 
currently number bins attribute preset 
discuss issue section 
desire values support confidence result segmentation data optimizes mdl cost function 
search process involves successive iterations feedback loop shown 
identify actual support confidence values appear binned data values adjusting arcs parameters 
enumerating unique support thresholds binned data pass unique confidence thresholds support thresholds second pass 
data structure sim ilar shown maintain val ues 
note support increases fewer fewer cells support association rule similar decrease variability confidence values cells 
choice low support threshold search upwards high sup port threshold search downwards chose optimal segmentations derived grids lower support thresholds 
previous association rule mining algorithm efficiency preferable start high support threshold downwards efficient mining algorithm lows discover segmentations starting low sup port threshold working upwards 
search starts low minimum support threshold consider lar ger number association rules initially allowing dy namic pruning performed clustering algorithm re support list confidence list 
ordered lists confidence support thresholds move unnecessary rules 
support gradually increased remove background noise outliers im provement clustered association rules 
experimental results arcs system algorithm implemented comprising approximately lines code 
assess performance results gorithms system performed experiments intel pentium workstation cpu clock rate mhz mb main memory running linux 
describe synthetic rules generating data initial results 
briefly compare results known classifier perform segmentation task 
show perform ance results sizes databases scale 
generation synthetic data generated synthetic tuples rules func tion 
parameters affect distri bution synthetic data 
include fraction number tuples assigned value criterion attribute perturbation factor model fuzzy boundaries disjuncts outlier percentage defines tuples assigned group label match defining rules group 
parameters shown table 
accuracy performance results generated set data function idi perturbation second set data function outliers data outliers obey generating rules 
ex run performed arcs produced clustered association rules similar gener ating rules effectively removed noise outliers attribute value salary uniformly distributed age uniformly distributed idi number tuples fraction tuples group fraction tuples group perturbation factor outlier percentage table 
synthetic data parameters database 
clustered association rules generated group clusters set data containing outliers minimum support threshold minimum confidence threshold age salary grp age salary grp age salary grp reader compare similarity rules generate synthetic data 
measured error rate arcs databases compared rules 
known building highly accurate decision trees classifying new data trees routine called rules constructs generalized rules 
rules form similar clustered association rules comparison accuracy speed generation 
figures graph error sys tems number tuples scale sets gen erated data 
missing bars larger database sizes due depletion virtual memory ex periments resulting inability obtain results clearly suited large scale data sets 
see rules generally slightly lower error rate arcs clustered association rules outliers data 
data appearing outliers error rate slightly higher arcs shown 
comes cost producing significantly rules shown figures 
mentioned earlier targeting environments rules processed users keeping number rules small im portant 
primary cause error arcs rules due granularity binning 
coarser granularity computed rules boundary generating rules 
test hypo thesis performed separate set identical experiments bins attribute 
general trend optimal clusters number bins increases 
arcs outliers 
number tuples 
scalability arcs idj table 
comparative execution times sec scaleup experiments test scalability ran arcs databases increasing numbers tuples 
shows ex ecution time increases linearly size database 
arcs maintains bitmap grid arcs requires constant amount main memory regardless size database ing number bins 
gives system significantly better linear performance seen close inspection overhead ex initially data streamed faster device larger requests 
example num ber tuples scales factor execution time increases seconds seconds factor 
comparison requires entire database times factor fit entirely main memory 
results paging eventual depletion virtual memory prevented obtaining execu tion times accuracy results rules databases greater tuples 
gether rules take exponentially higher execu tion times arcs shown table 
arcs number cf tuples 
error rate 


number tuples 
number rules produced investigated clustering attribute association rules identify generalized segments large databases 
contributions sum automated system compute clustering attribute space large databases 
demonstrated association rule mining technology applied clustering problem 
proposed specialized mining algorithm pass data partitioning input attributes allows sup port confidence thresholds change ing new pass data 
new geometric algorithm locating clusters dimensional grid introduced 
approach shown run linear time size number tuples 
error rate rr number tuples 
number rules produced clusters 
parallel implementations algorithm straightforward 
apply minimum description length mdl principle means evaluating clusters metric describing optimal clustering associ ation rules 
experimental results show usefulness clustered association rules demonstrates proposed system scales better linear time amount data 
algorithm system implemented platforms including intel dec sgi 
far performed tests ing synthetic data intend examine real world demo graphic data 
plan extending fol lowing areas may desirable find clusters attributes 
way extend pro posed system iteratively combining overlapping sets attribute clustered association rules pro duce clusters arbitrary number attrib 
handle categorical quantitative attributes lhs rules 
obtain best clustering need consider feasible orderings categorical tributes 
clustering algorithm extended handle case attribute categorical quantitative achieved results 
ordering quantitative attribute con sider subsets categorical attribute yield densest clusters 
preliminary experiments show segmentation improved association rule support values binary values considered smooth ing filter advanced filters purposes detecting edges corners clusters 
may beneficial apply measures information gain entropy determining attributes select segmentation op threshold values support confidence 
technique factorial design fisher greatly reduce number experiments necessary searching optimal solutions 
tech nique applied heuristic optimizer re duce number runs required find values minimum support minimum confidence 
search techniques simulated annealing optimization step 
grateful dan liu extending functionality synthetic data generator ex periments 
agrawal ghosh imielinski iyer swami 
interval classifier database mining applications 
proceedings th international conference large data bases vancouver canada 
agrawal imielinski swami :10.1.1.41.6931
database mining performance perspective 
ieee transactions know ledge data engineering volume pages dec 
agrawal imielinski swami :10.1.1.40.6984
mining associ ation rules sets items large databases 
pro ceedings acm sigmod international confer ence management data washington 
box hunter hunter 
statistics ex design data analysis model building 
john wiley sons 
cormen rivest 
gorithms 
mit press 
fisher 
design experiments 
hafner publishing 
fukuda morimoto morishita 
data mining dimensional optimized association rules scheme algorithms visualization 
proceed ings acm sigmod international conferenceon management data montreal canada june 
gonzalez woods 
digital image processing 
addison wesley 
klemettinen mannila ronkainen andh 
toivonen 
finding interesting rules large sets discovered association rules 
confer ence information knowledge management cikm nov 
kruskal 
factor analysis principle components bi linear methods 
kruskal editors interna tional encyclopedia statistics 
free press 
lawley 
factor analysis statistical method 
american elsevier publishing second edition 

discovery databases review ai statistical techniques 
ijcai workshop know ledge discovery databases pages 
mehta agrawal rissanen 
sliq fast scal able classifier data mining 
proceedings th ternational conference extending database technology edbt avignon france mar 
dewitt 
statistical profile estima tion database systems 
acm computing surveys sept 
piatetsky shapiro 
discovery analysis presentation strong rules 
knowledge discovery databases 
quinlan 
induction decision trees 
machine learning volume pages 
quinlan 
programs machine learning 
morgan kaufmann san mateo california 
rissanen 
stochastic complexity statistical inquiry 
world scientific publishing 

cluster analysis researchers 
life time learning publications wadsworth 
shafer agrawal mehta 
fast serial paral lel classification large data bases 
proceedings nd conference large databases bombay india 
spath 
classification objects 
ellis horwood publishers 
srikant agrawal :10.1.1.40.8600
mining quantitative association rules large relational tables 
proceedings cm sigmod international conference management data montreal canada june 
whang kim wiederhold 
dynamic ance data distribution selectivity estimation 
vldb journal jan 
