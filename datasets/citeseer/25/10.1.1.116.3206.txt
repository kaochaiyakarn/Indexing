sketching probabilistic data streams graham cormode labs research park avenue florham park nj graham research att com management uncertain probabilistic data emerged useful paradigm dealing inherent real world application domains including data cleaning information integration pervasive multi sensor computing 
conventional data sets set probabilistic tuples defines probability distribution exponential number possible worlds grounded deterministic databases 
possible worlds interpretation allows clean query semantics raises hard computational problems probabilistic database query processors 
complicate matters scenarios large scale process environmental monitoring multiple sensor modalities probabilistic data tuples arrive need processed streaming fashion limited memory cpu resources benefit multiple passes static probabilistic database 
probabilistic data streams raise host new research challenges stream processing engines date remain largely unaddressed 
propose space time efficient algorithms approximating complex aggregate queries including number distinct values join self join sizes probabilistic data streams 
possible worlds semantics aggregates essentially define probability distributions space possible aggregation results goal characterize distributions efficient approximations key moments expectation variance 
algorithms offer strong randomized estimation guarantees sublinear space size stream rely novel concise streaming sketch synopses extend conventional sketching ideas probabilistic streams setting 
experimental results verify effectiveness approach 
categories subject descriptors data data structures theory analysis algorithms general terms algorithms performance reliability keywords data streams uncertain data 
done intel research berkeley permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigmod june beijing china 
copyright acm 
minos garofalakis yahoo 
research uc berkeley mission college blvd santa clara ca minos yahoo com 
conventional database systems query processing tools designed idea static collections exact data tuples 
unfortunately data generated diverse set real world applications uncertain imprecise 
instance data integration record linkage tools generate distinct degrees confidence output data tuples quality match underlying entities structured information extractors typically assign different confidences rules identifying meaningful patterns unstructured input pervasive multi sensor computing applications need routinely handle noisy sensor rfid readings 
motivated new application requirements research efforts probabilistic data management aim incorporate uncertainty probabilistic information class citizens database system 
different approaches managing uncertainty inside database tuple level uncertainty models essentially associate independent existence probabilities individual tuples seen wide adoption research papers system prototypes 
due simplicity representation current relational systems just adding existence probability column simple intuitive query semantics 
nutshell probabilistic database concise representation probability distribution collection possible worlds representing possible grounded deterministic instance database flipping appropriately biased independent coins select uncertain tuple 
possible worlds semantics implies clean semantics queries probabilistic database essentially result probabilistic query defines probability distribution space possible query results possible worlds 
unfortunately despite simple intuitive semantics paradigm shift tuple level uncertainty appears imply huge jump computational complexity simple query processing operations demonstrated suciu correctly evaluating resulting tuple probabilities duplicate eliminating projections simple way join give rise problems hard data complexity exponential number database tuples 
query processing efficiency issues course exacerbated streaming nature target applications probabilistic data management tools 
example large scale process environmental monitoring tools rely continuous collection processing large amounts noisy uncertain readings numerous sensor modalities suggested attaching tuple level probabilities explicit indicators data quality 
due continuous online nature applications large data volumes involved probabilistic data tuples arrive continuously need pro cessed streaming fashion query results available real time limited memory cpu resources benefit passes static probabilistic database 
efficient stream processing algorithms system architectures deterministic tuple streams formed active research area years 
static database case probabilistic data streams raise host new difficult research challenges stream processing engines mandate novel algorithmic approaches 
prior 
efficient algorithms developed processing different classes complex queries massive data streams examples include computing quantiles estimating distinct value counts counting frequent elements heavy hitters approximating large haar wavelet coefficients estimating join sizes stream norms :10.1.1.19.8594
works consider issues raised uncertain streaming tuples 
probabilistic database systems focused different aspects managing uncertain data tuples relational dbms architectures including complexity algorithmic problems query evaluation data modeling issues managing lineage probabilistic query results 
issue efficient aggregate query evaluation stringent constraints streaming model considered papers 
propose architecture cleaning sensor readings attaching explicit correctness probabilities techniques essentially complementary 
jayram studied problem evaluating simple aggregate functions focusing particular average streams uncertain data 
model uncertainty richer capture value level uncertainty probability existence 
simple aggregates average techniques analyses rely sophisticated mathematical tools generating functions unclear extended broader complex class aggregate queries considered 
independently concurrent jayram showed results expectation versions quantiles problems studied improve results average 
contributions 
initiate study time efficient techniques approximating broad class complex aggregate queries continuous probabilistic tuple streams 
possible worlds semantics probabilistic aggregates define probability distributions exponentially large space possible results goal characterize distributions efficient streaming approximations key moments expectation variance possible worlds collection 
propose novel randomized sketching synopses estimation algorithms probabilistic data streams conventional data streaming methods employ sublinear space size domain probabilistic stream offer strong randomized estimation guarantees key moments underlying complex aggregate 
concretely contributions summarized follows 
generic streaming probabilistic aggregate estimator possible worlds sampling 
universal aggregate estimation algorithm probabilistic data streams intuitive idea sampling possible worlds deterministic streams input running conventional streaming estimators sampled streams 
obvious appeal scheme allows directly leverage existing space efficient algorithms deterministic data streams probabilistic setting 
unfortunately analysis experimental results show approach severe limitations comes estimating moments complex aggregates streaming probabilistic data 
probabilistic fm pfm sketch synopses estimators probabilistic count distinct aggregates 
count aggregates expected tuple counts heavy hitters allow simple solutions due linearity case complex aggregate queries probabilistic stream 
initially focus class count distinct queries introduce novel randomized estimation algorithm probabilistic data streams 
algorithm relies new hash sketch synopsis structure streaming probabilistic data termed probabilistic fm pfm sketch inspired known flajolet martin fm sketch counting distinct deterministic values :10.1.1.12.7100
introduce analyze pfm sketch estimators probabilistic count distinct demonstrate strong error guarantees small space sketch large probabilistic data stream 
streaming estimators probabilistic self join join sizes higher frequency moments ams techniques 
second moment probabilistic data stream corresponding expected self join size related quantity join size independent probabilistic streams develop new insights expressing expectation variance terms cumulants appropriate distributions 
cumulants computed easily component stream show represent compactly manipulate variations alon matias szegedy ams sketch data structure 
show accuracy power approach able track higher moments cumulant analysis 
experimental results validating approach 
perform thorough evaluation techniques mixture real synthetic data 
observe methods highly practical typically obtain small error streams millions items tens kilobytes seconds cpu time 
show simple techniques suffice estimating expectations understand higher moments involved algorithms necessity 
due space constraints proofs detailed technical arguments omitted complete details deferred full version 

probabilistic data stream model consider simple model probabilistic data streams stream renders multi set relational tuples independent tuple level uncertainties existence probabilities 
mentioned earlier independent probabilistic tuples form basis studies probabilistic data management naturally represented relational systems allow clean intuitive query semantics furthermore simple models uncertainty raise intractable computational problems probabilistic query processing 
formally define probabilistic data stream sequence uncertain tuples semantics tuple occurs instance database probability independently tuples database 
tuples drawn finite domain size loss generality assumed integer domain 

typical data stream analysis focus case large stream query processor observe streaming tuples fixed order arrival simplicity assume arithmetic exact address issues precision assume probabilities represented exactly small constant number machine words 
space time sublinear maintain concise synopsis probabilistic data stream 
results show relatively simple techniques case min space available advanced tools needed sublinear space constraints 
model special case general model tuple encodes compact probability distribution pdf comment results immediately apply general setting simplicity concentrate discussion simpler case 
aggregate estimation probabilistic streams 
earlier probabilistic databases view probabilistic data stream defining probability distribution collection possible worlds implicitly probabilistic stream encodes exponentially conventional deterministic data streams occurring probability determined individual existence probabilities constituent tuples 
refer possible deterministic instantiations probabilistic data stream grounded streams denoted 
specifically consider probabilistic stream ti pi denote possible outcome comprising sequence tuples index subset ti tuple independence easy see probability possible outcome computed simply pr pi pj 
note course tuples ti necessarily distinct stream renders bag tuples distinct index subsets fact map grounded stream probability grounded stream instance defined pr pr 
straightforward show pr defines valid probability distribution 
example 
consider simple probabilistic stream 
encodes possible outcomes covering distinct grounded stream instances denotes empty stream 
probabilities possible distinct grounded stream easily computed grounded stream pr focus computing complex aggregates probabilistic data streams 
mentioned earlier aggregates essentially define probability distribution exponentially large space aggregation results possible worlds 
potentially enormous size complexity distributions goal effectively characterize probabilistic data aggregates efficient streaming approximations key distribution moments expectation variance possible worlds collection 
formally consider probabilistic data stream denote result evaluating aggregate function random variable ranging possible grounded streams expectation variance naturally defined pr varg pr subscript denote underlying probability space possible worlds 
naturally naive way compute varg time space explicitly grounding computing pr deterministic aggregate value 
goal stronger aim perform computations time exponentially essentially single pass probabilistic tuples space significantly sublinear poly logarithmic typical requirements efficient query processing algorithms deterministic streaming model 
specific class aggregate queries interest frequency moments stream closely related streaming problems 
frequency moments formed basis algorithmic studies non probabilistic data streams techniques developed computation heart algorithms data stream query processing 
formally consider grounded stream ft denote number occurrences element 
tuple element interchangeably remainder 
th frequency moment fk defined fk pm 
treat implies number domain elements ft non zero number distinct tuples stream similarly simply total number tuples size self join attributes streaming tuples 
th frequency moment fk probabilistic stream defined naturally random variable earlier 
course important note distinction fk frequency moments corresponding distribution moments fk varg fk goal devise streaming algorithms estimating distribution moments single pass data stream algorithmics approach design efficient randomized schemes ideally guarantee approximation bounds quantity estimated stream aim produce estimate pr 

warm basic stream estimates section start describing general aggregate estimation scheme probabilistic data streams idea sampling possible worlds 
briefly discuss simple streaming estimator frequency moment probabilistic stream implications probabilistic aggregate queries including quantiles heavy hitters 
universal sampling algorithm possible worlds interpretation probabilistic stream aggregates natural sampling scheme emerges obtaining streaming estimators varg aggregate computed accurately approximated deterministic data stream 
idea randomly sample small subset possible worlds input probabilistic stream grounded stream chosen probability pr 
simple implement target sample size initialize gj 
incoming probabilistic tuple ti pi simply perform independent biased coin flips success probability pi setting gj gj ti th coin flip succeeds 
universal probabilistic stream estimator store possible worlds gj tuples generated grounded streams fed parallel instances streaming estimation algorithms 
gj 
de note outputs streaming estimators estimate varg sample mean sample variance respectively sx gj sx gj theorem establishes accuracy properties universal probabilistic stream estimator 
theorem 
unbiased streaming estimator unbiased estimators varg respectively 
varg samples provides approximation 
words sampling varg possible worlds passing separate instance streaming estimation algorithm deterministic data streams sample mean estimator guarantee relative error constant probability 
amplify user defined success probability simply repeating log times median result standard chernoff bounds arguments guarantee probability failure 
sample size requirement easy see estimation quality universal estimator depends crucially ratio varg 
see subsequently frequency moments consider varg fk fk varg 
ratio small decreasing fk increases 
tempting try apply technique derive bounds accuracy approximating distribution variance varg probabilistic aggregate variance just expectation 
unfortunately bounds resulting approach considerably worse 
observe variance computation equivalent computing difference values ps gj unbiased estimator quantity varg second quantity 
frequency moments study fk larger varg fk stated varg fk fk 
suppose chose large ensure fk approximated fk approximated 
quantity estimating smaller need accurate approximation order approximate varg fk 
need choose fk varg fk 
bound theorem means need fk samples varg varg fk samples varg 
bounds analysis weak little practical 
shall see experimentally estimations variance universal sampling algorithm poor practice 
remainder show cases intelligent aggregate aware streaming estimation algorithms developed perform significantly better universal sampling strategy 
start discussing solutions applications simple case frequency moment 
counts quantiles heavy hitters conventional deterministic data stream computing frequency moment trivial just count elements stream computed exactly single counter 
similarly computing exact distribution moments probabilistic stream turns quite straightforward 
specifically consider probabilistic stream ti pi 
purposes moment estimation streaming uncertain tuple ti pi seen bernoulli variable bi takes value 
tuple possible world probability pi 
linearity expectation independence probabilistic tuples stream pn xi pn pi varg var xi pi pi varg 
linearity immediately implies compute exact expectation variance variables 
earlier probabilistic data similar observations linear aggregates case computing expectation see 
difficult see linearity leverage known deterministic stream synopses results provide strong estimation guarantees important count aggregates probabilistic data streams 
summarize key results setting 
probabilistic data stream tuple ft denote point frequency number occurrences random variable 
advance easily compute ft varg ft simple counters 
interestingly known possible build small space streaming synopses estimate point frequency moments factors corresponding stream moments 
words estimate point frequencies accurately small space long large respect expected count elements stream correspond typical streaming error guarantees point estimation deterministic setting :10.1.1.19.8594
lemma 
space possible build synopsis probabilistic data stream return estimates probability ft ft varg ft varg ft varg 
proof linearity aggregate difficult see estimating ft varg ft corresponds standard point query data stream containing fractional values pi values ft pi pi values varg ft 
immediately apply known streaming synopses count min sketch 
provides estimates errors proportional pn pi varg expectation variance respectively probabilistic guarantees 
known techniques lossy counting misra gries naturally accommodate stream fractional values assume stream unitary updates 
algorithms suri allow arbitrary update values applied extract point estimates stream 
implemented update takes log expected time uses space amd re spectively 
provide required estimates time space 
standard streaming arguments lemma directly implies space time efficient probabilistic stream estimation algorithms interesting count aggregates approximate heavy hitters approximate quantiles 
development resembles conventional streaming version problem details 
corollary 
assume constant desired accuracy guarantee 
state results 
approximate heavy hitters return elements ft item ft done space 

approximate quantiles return items pt fi done space log 
estimation guarantees hold variance estimates replacing varg 

estimating count distinct noted section case frequency moment related count estimation problems easy reduce prior streaming due linearity aggregate 
unfortunately frequency moments straightforward 
section consider case number distinct items probabilistic stream important note computing different computing number distinct tuples seen instance comprise millions tuples distinct values pi minuscule say order 
linearity property allowed simply sum probabilities case longer valid intuitively number occurrences distinct tuple stream immaterial long tuple appears 
streaming algorithms track probabilities occurrence distinct tuples domain 
tuple independence turns quite simple assumes linear space 
lemma 
space streaming algorithm compute exact values varg probabilistic data stream proof pt denote probability element observed grounded instance stream ti pi 
pt pr 
tuple independence difficult see probabil ity expressed pt pi minus probability instances materialized 
probability incrementally computed tuples ti pi streaming 
initially set pt 
suppose tuple ti pi ti update pt pt pi pi reflect updated probability seeing tuple 
easy verify rule correctly maintains probability occurrence defined 
expected number distinct items exactly pt 
varg observe count distinct estimation just bernoulli random variable parameter pt variance simply pt pt 
basically summation bernoulli random variables tuple independence varg pt pt varg 
example 
consider example probabilistic stream 
px py varg verify re sults probabilities grounded streams pr see example 
probabilities pr pr pr pr pr 
similarly varg universal sampling estimator 
show guarantees universal estimation algorithm possible worlds sampling section provide estimation theorem know universal estimator guarantee approximation sampling varg grounded streams efficient guaranteed error streaming estimator 
analysis independent bernoulli random variables see varg pm pt pt pm pt pt pt words number grounded stream samples estimators needed guarantee small relative errors inversely proportional quantity want estimate 
quite intuitive consider probabilistic stream comprising distinct tuples ti tuples probability pi small course implies small large number samples needed ensure sampling estimate small relative error instance sam ples needed average just sample non empty possible world give non zero estimate 
tuples deterministic single instance estimator 
experiments show practice typically moderate size small sample size sufficient get approximation 
hand discussed section error guarantees unfortunately carry case variance varg 
probabilistic fm pfm sketch introduce novel algorithm estimation probabilistic data streams 
algorithm guarantees randomized estimates varg space poly logarithmic size stream independent value 
technique inspired popular flajolet martin fm algorithm estimating number distinct elements deterministic data stream briefly letting denote domain stream earlier fm algorithm employs family hash functions :10.1.1.12.7100
log pr probability defined family hash function choices 
basic stream synopsis maintained fm algorithm known fm sketch bitmap size log maintained specific hash function specifically sketch initialized zeros incoming element stream bit location turned 
properties expect fraction distinct values stream map location sketch expect distinct values land bit bit 
denote highest bit location turned bitmap indicator number distinct elements independent fm sketches different hash function choices possible boost estimation accuracy confidence user defined levels 
proposed sketch synopsis probabilistic data streams termed probabilistic fm pfm sketch similar ideas 
employ class hash functions basic fm algorithm define pfm sketch array pfm comprising log real valued probability entries maintained hash function procedure 

input matrix independent probabilistic fm sketches probabilistic stream log 
output approximate estimate 

dij basic pfm estimate sketch see eqn 

dij 
log find inference level 

yj ps 
return median 
ys estimation algorithm 
pfm array initialized zeros streaming pair ti pi probabilistic data stream update pfm ti entry setting pfm ti pfm ti pi pi 
set tuples map bit 
simple inductive argument prove update rule pfm ti pi pr equality follows tuple independence 
compute basic estimate pfm array log log pfm pfm 
intuitively formula computes expectation estimates possible bitmap locations probability highest non empty location bitmap 
sense seen probabilistic expectation version original fm idea 
basic pfm estimate shown guarantee constant estimation error constant probability theorem 
single pfm sketch size log basic pfm estimation algorithm outputs estimate pr approximate estimator 
give streaming approximate estimation algorithm 
briefly algorithm employs number independent pfm sketches built probabilistic stream 
basic idea estimation process constant factor probability basic estimator described order identify appropriate inference level pfm sketch structures 
goal determining inference level ensure probability distinct elements map level possible worlds choices hash function small 
achieve choosing levels higher log estimate returned averaging basic estimates individual pfm sketches 
averaging median selection probabilities level pfm sketches order produce accurate estimate 
pseudocode estimation algorithm 
theorem 
algorithm returns approximate estimate log independent pfm sketch synopses probabilistic data stream proof sketch briefly discuss main ideas proof complete details optimizations constant factors deferred full 
start notation 
fix specific level pfm sketch 
xk indicator random variable rv event distinct stream elements map level zk denote rv number distinct values stream mapping level fix specific choice hash function pk pfm denote incrementally computed probability level sketch exactly fraction possible worlds th bit corresponding fm sketch pk xk 
words pk sample point fixed distribution xk note expectation xk highly non linear relationship specifically xk pr distinct element maps independently level probability 
subscripts denote expectation taken space possible worlds hash functions respectively 
sample points pk estimate xk obvious way go target quantity pr 
hand expectation zk easy linear relationship zk pr pr level goal pick inference level constant probability xk zk 
achieve initial constant factor approximation analysis additional averaging step iid instantiations reduce variance probability error chebyshev bound factor get estimate probability follows assume mc approximation bounds hold add probability mc error 
define log 
bounds imply consider rv zk 
equations application markov inequality gives prg zk level zk zk probability 
assume zk adjust final probability error adding 
case level zk xk eh pk equality follows equation 
possible choices rv pk satisfies pk eh eh pk 
assuming iid instantiations independently chosen hash functions 
hm probabilistic fm sketch define sample average estimator pm pk hi expectation eh pk line algorithm 
chebyshev bound pr pk pk inequality follows equation 
randomized relative error estimator error probability upper bounded mc number iid pfm sketches averaging pk hi instances constant 
assuming small say choose ensure error probability upper bounded constant 
log iid instantiations procedure bring error probability lines 
randomized estimator log pfm sketch summaries 
estimating varg 
computing varg initially harder computing 
demonstrate complexity building estimator harder reduction expectation estimation problem 
lemma 
method approximate quantity varg estimated space error probability 
proof probabilistic stream ti pi 
define new stream ti pi compute 
claim varg 
prove claim studying properties pt pt denotes probability occur ground stream pt pr pi 
pm pt pm pt pm pt pr pm pm pm pt pm pt pt varg lemma showed varg pm pt pt 
observe pt pt mx mx pt 
approximate error probability 
combining approximation yields approximation varg probability union bound 
proof argument demonstrates compute varg distinct pfm sketches estimating original stream ai pi estimating modified stream ai pi 
space efficient observe pfm sketch summaries find pfm pr pr built pfm summary pfm hash function want find pfm pt pfm estimate information stored single pfm sketch data structure 

second moment join size consider complexity computing expectation variance second frequency moment probabilistic stream 
go study related question expected join size probabilistic streams 
expectation pams introduce estimation technique randomized sketches alon call probabilistic ams pams short 
proceed reducing problem computing exponentially ground streams tracking information distinct tuples stream show approximate information sublinear space 
theorem 
compute estimator probability space log 
proof analyze problem show algorithm computes exact value space linear st denote substream corresponding tuples st ti pi ti 
xt random variable captures distribution occurrences ft 
pi st thought defining independent bernoulli random variable write xt ft pi 
st bernoulli variable variance equal pi pi summation variances var xt pi pi 
var xt xt st pi pi st pi sum tracked constant space vt pi wt pi st ti pi st need compute wt vt vt wt easy update tuple pi seen set vt vt pi wt wt observe mx mx vt wt showing exactly space 
order compute small space sublinear number domain size define random variable linearity expectation mx ti pi st pi st pi term precisely varg shown computed exactly constant space tracking sum variances tuple pi pi 
ti pi term streaming second frequency moment computation applied stream probabilities treat nonprobabilistic stream defines vector vt pi pi ti write term square norm vector alon sketching technique find estimator space log 
define estimator varg 
varg provided pi sum third terms non negative quantity summing estimator exact values varg yields estimator factor probability 
words probabilistic ams technique pams guaranteed estimator 
importantly space independent number distinct items stream length stream 
example 
stream 
compute ground streams analysis vx wx vy wy confirm variance pams compute facts expectation sum independent random variables equal sum expectations linearity expectation variance sum equal sum variances linearity variance 
cases general properties random variables cumulants variables denoted 
cumulant random variable just mean distribution 
second cumulant variance var 
higher cumulants expressed terms central moments variable example var important property cumulants extensive independent random variables cumulants generalize linearity expectation variance higher moments independent variables 
theorem 
approximate varg additive error space log 
proof expanding rearranging write var writing bernoulli random variable parameter equalities var note may negative random variable var non negative bernoulli random variable var var 
summation cumulants rv xt corresponding number occurrences xt st pi 
write vectors kj kj xt 
summation variance write varg mx term denote computed exactly constant space sum function pi turn 
terms complex dealt techniques computing deterministic streams 
second third terms inner product vectors dimension entry sum values derived individual tuples approximated sketching technique alon 
fourth term thought way join relations encoded vectors happens approximated technique dobra 
build estimator building ams sketches vectors needed estimate term plus exact computation constant space 
estimator formed dvar approximate dot product vectors approximate way dot product vectors 
probability error varg var 
observations relative size cumulants vectors formed 
variable xt formed sum bernoulli random variables giving xt xt xt 
result error approximation bounded 
write terms quantities estimating observe stream note note similar line reasoning cumulant representation show varg meaning bound reasonable 
conclude pams technique build estimator constant space independent rescaling constant pr varg varg 
example 
study computing var demonstrate reduction computation cu 
ground streams compute varg cumulant approach vectors confirm claimed varg 
expected join size pams consider streams wish evaluate expected join size possible grounded streams 
initially challenging reasoning space possible worlds 
fact pams sketches 
theorem 
pass compute estimate probability space log 
proof vectors cumulants defined 
expanding definitions independence find dot product vectors 
sketches compute estimate properties sketches error bounded 
probability summary stream size log independent summary maintained incrementally new ti pi read 
note case pi deterministic stream identical regular join size estimation sketches hope 
example 
consider example stream independent streams happen distribution 
tiny example somewhat laborious evaluate possible combinations grounded streams order compute comparison straightforward find px px py py compute note different answer compared stream ground stream computations size join stream equal second frequency moment stream 
contradiction note independent streams 
join independent streams distribution different self join single probabilistic stream consider possible combinations ground streams 
fact sure write example 
consider computing varg 
equality occurs probabilities deterministic streams 
highlights important example intuitions dealing deterministic streams directly carry world probabilistic streams 
usual 
find 
compute varg cumulants approach find 
computing 
completely characterized central moments exactly turn attention central moments aggregate section showed estimate varg reducing estimation derived stream 
approach 
theorem 
estimator quantity estimated error probability 
proof define ti pi additionally define ti pi observe new streams generate new probabilities behaved lie range 

claim 
defining pt pt pm simplifying definition xt pm pt 
lemma 
similarly observe 
higher moments estimation extend approach higher frequency moments fk higher central moments 
higher central moments central moments distribution defined ck follows var 
higher central moments define distribution 
analogy earlier definitions define probabilistic streams aggregate ck pr written terms cumulants 
example compute constant space 
continuing computed exactly constant space compute exactly constant space computing pi individual bernoulli random variable defined ti pi tuple summability cumulants get correct result 
method works higher cumulants central moments ck completely characterize th central moments space 
pt pt pt pt 

consequently net error estimate bounded probability union bound 
note idea keeping single pfm sketch deriving sketch pfm pfm works meaning estimation single sketch 
similar techniques adapted higher central frequency moments ck involved terms harder approximate relevant constants increase omit lengthy details 
likewise build estimators ck generalizing technique varg quite involved lesser value compared varg discuss 
higher frequency moments similar technique cam applied approximate expected value higher frequency moments 
focus expected value third frequency moment defined pr 
properties third cumulant written 
find compute pm xt xt xt xt address terms turn 
know compute third cumulant stream exactly single variable 
second term inner product vectors defined section estimating varg 
ams sketching technique quantity estimated error space log 
lastly need estimate pm xt pm ti pi st pi generalized version third moment computation stream pi order approximate define variation generic ams estimator general problem estimating fk prove gives necessary accuracy note original estimator defined unary streams arrival item counts increment exactly frequency item requires careful analysis proof 
estimator fk streams fractional values 
define generalized th frequency moment fk st pi 
note quite distinct definition fk question respect semantics probabilistic stream treating deterministic stream fractional non negative updates 
think terms vector norm vector defined stream 
define estimator follows 
pj pj pj pi stream seen far 
stream randomly sample th tuple tj pj probability pj pj 
done weighted version standard reservoir sampling track value pj pj pi sample tuple replacing currently sampled item probability pj pj 
follows inductively probability item surviving process ex pj pj required 
compute pt pi sum probabilities tuples containing occur sampled th tuple 
output estimator ej pj pt pj pj 
theorem 
mean copies estimator ej median log means gives approximation fk pass 
estimate xt term expression space sublinear support size stream independent stream length putting form estimator 
probability 
note term may negative show non negative 
assume average value recalling see proof theorem prove giving bound error 
rescaling constant relative error approximation sublinear space conclude theorem 
pass find estimator space log 
experimental results implemented algorithms main frequency moments probabilistic fm pfm probabilistic ams pams universal sampling algorithm fm ams comment algorithm ganguly obtain improved dependency higher dependency 
time time cost estimation pfm sampling total space kb time estimation estimators results fairly compared 
exhaustively computed exact answers aggregates order compare approximate values obtain algorithms 
experiments performed standard desktop class machines 
algorithms efficient report timings general guide relative performance exact behavior vary depending optimizations cache policy 
data sets 
considered variety real synthetic data 
synthetic data created tuple ti pi independently drawing ti zipfian distribution pi uniform range 
captures settings data drawn distributions skew variety uncertainty values 
vary skewness parameter zipfian distribution uniform highly skewed 
experiment generated tuples distribution 
real data set project includes approximately probabilistic tuples 
tuple links film imdb database product amazon com inventory includes probability match value 
expected number distinct matched titles matched expected self join size 
experiments estimation 
experiments estimation shown 
see fixed amount space universal sampling algorithm consistently obtains approximation percentage points probabilistic fm approach typically relative error uniform skewed data 
partly due space efficiency algorithms universal algorithm fm sketches bitmaps bit regular fm sketch pfm structure uses bit integer uses times structures space 
trend accuracy improve space available 
fm algorithm randomized accuracy improve uniformly space trend variability decrease space seen clearly 
appears task estimating universal algorithm accurate space bound 
price pay terms time cost 
times data structures time update correspondingly slower 
shows processing time increases linearly space algorithms predicted analysis 
universal algorithm times slower process tuples implementation manipulates bit vectors floating point numbers fully times slower 
see www cs washington edu homes suciu project html authors sharing data 
relative error relative error accuracy estimation synthetic data pfm sampling zipf distribution parameter kb space accuracy var estimation synthetic data probabilistic fm ground streams zipf distribution parameter varg kb space relative error relative error accuracy estimation synthetic data pfm pfm sampling sampling total space kb zipfian data accuracy probabilistic fm var estimation zipfian zipfian zipfian total space kb varg zipfian data results varg estimation real synthetic data comes computing varg tables turned quite dramatically 
probabilistic fm algorithm consistently achieves relative accuracy moderate amount memory recall guarantee terms varg 
computing variance samples universal algorithm yields estimates orders magnitude 
reason section studying output algorithms verified obtains accurate estimate terms large compared varg final error huge relative terms 
probabilistic fm algorithm gives guarantee error proportional give better estimates 
true broad range synthetic data figures real data trend improving accuracy space increases 
experiments estimation 
experimental results estimation shown 
universal algorithm average error estimating data types improving accuracy space increases figures 
data moderate skew challenging probabilistic ams algorithm obtained accuracy better 
timing results quite comparable implementation pams bit floating point values universal algorithm uses structure bit integers 
universal algorithm twice hashing operations uses integer arithmetic update counts 
set time cost algorithms approximately second algorithms completely process data set items estimation independent total summary size 
increases seconds varg algorithm requires sketches vectors relative error relative error accuracy estimation imdb data pfm sampling total space kb imdb data accuracy var var imdb data var estimation var estimation total space kb varg varg imdb data perform estimation 
algorithm scales large quantities data restricted resources 
varg estimation see limitation universal algorithm 
data set extremely skewed chance making reasonable estimate 
reason case error estimate proportional large comparison varg 
analysis shows error pams estimation depends worst case edge estimates quite accurate 
hard case algorithms uniform data 
shows increasing space probabilistic fm improves accuracy hard data error skewed data close zero 
shown imdb data 
likewise increasing amount space available tend improve accuracy universal algorithm sufficiently reliable levels highly skewed data 
interestingly increasing number ground streams estimate reliably improve quality fact tended reduce accuracy 
lastly looked estimating varg universal algorithm 
note compute exactly constant space analysis section 
useful example study error introduced computing ground stream precisely number items observed stream consequently skewness synthetic zipfian distribution irrelevant aggregate 
shows increasing number ground streams improve accuracy somewhat slowly 
ground streams expected accuracy relative error 
aggregates drawing ground streams feasible entails storing separate ams fm summary structures typically kbs relative error relative error accuracy estimation synthetic data pams sampling zipf distribution parameter kb space accuracy var estimation synthetic data probabilistic ams ground streams zipf distribution parameter varg kb space relative error relative error accuracy estimation sketch size varies pams zipfian sampling zipfian pams zipfian sampling zipfian total space kb zipfian data accuracy probabilistic ams var estimation zipfian zipfian zipfian zipfian total space kb varg zipf skewness results varg varg estimation 
throughput decreases factor compared probabilistic sketching methods propose 
experimental 
experiments conclude fixed amount space universal sampling algorithm obtains high accuracy computing central moment 
cases times slower probabilistic equivalent somewhat accurate 
second central moment varg varg dramatically better methods tailored aggregate 
way obtain efficient estimates quantities amount space estimate universal algorithm greater space needed run exact algorithm 

alon gibbons matias szegedy 
tracking join self join sizes limited storage 
acm pods 
alon matias szegedy 
space complexity approximating frequency moments 
acm stoc 
babcock babu datar motwani widom 
models issues data stream systems 
acm pods 
bar yossef jayram kumar sivakumar 
counting distinct elements data stream 
random 
das sarma halevy widom 
databases uncertainty lineage 
vldb 
cormode korn muthukrishnan srivastava 
time efficient deterministic algorithms biased quantiles data streams 
pods 
cormode muthukrishnan 
improved data stream summary count min sketch applications 
alg 
suciu 
efficient query evaluation probabilistic databases 
vldb 
dobra garofalakis gehrke rastogi 
processing complex aggregate queries data streams 
sigmod 
relative error relative error accuracy estimation real data pams sampling total space kb imdb data accuracy var estimation ground streams data synthetic data number ground streams varg feigenbaum kannan strauss viswanathan 
approximate difference algorithm massive data streams 
ieee focs 
flajolet martin :10.1.1.12.7100
probabilistic counting algorithms database applications 
computer system sciences 
ganguly saha 
simpler algorithm estimating frequency moments data streams 
soda garofalakis gehrke rastogi 
querying mining data streams get look 
sigmod 
gilbert kotidis muthukrishnan strauss 
surfing wavelets streams pass summaries approximate aggregate queries 
vldb 
greenwald khanna 
space efficient online computation quantile summaries 
sigmod 
jayram vee 
efficient aggregation algorithms probabilistic data 
soda 
jayram raghavan vaithyanathan zhu 
avatar information extraction system 
ieee data eng 
bulletin 
jayram mcgregor muthukrishnan vee 
estimating statistical aggregates probabilistic data streams 
pods 
balazinska suciu 
correcting input data errors probabilistically integrity constraints 

manku motwani 
approximate frequency counts data streams 
vldb 
agrawal el abbadi 
efficient computation frequent top elements data streams 
icdt 
misra gries 
finding repeated elements 
science comp 
programming 
das sarma halevy widom 
working models uncertain data 
ieee icde 
shrivastava agrawal suri 
medians new aggregation techniques sensor networks 
sensys 
