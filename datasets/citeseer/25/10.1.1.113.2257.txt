holistic udafs streaming speeds graham cormode rutgers university graham dimacs rutgers edu muthukrishnan rutgers university cs rutgers edu algorithms proposed approximate holistic aggregates quantiles heavy hitters data streams 
little done explore techniques required incorporate algorithms data stream query processor useful practice 
study performance implications user defined aggregate functions udafs incorporate sketch algorithms holistic aggregates data stream management system query processing architecture 
identify key performance bottlenecks tradeoffs propose novel techniques holistic udafs fast high speed data stream applications 
evaluate performance generated actual ip packet data focusing approximating quantiles heavy hitters 
best current implementations process streaming queries oc speeds gbps 

phenomenon data streams research evident 
led research directions database community 
powerful algorithms developed processing data stream 
abstracted model data streams items small amount storage compute various holistic aggregates stream provide accuracy guarantees 
high level algorithms divided categories data driven universe driven 
data driven algorithms select data items appear stream maintain statistics distribution stream 
typically space accuracy bounds func supported nsf itr nsf eia 
supported nsf eia nsf itr nsf eia 
term holistic describe functions median mode constant bound size storage needed exactly compute :10.1.1.120.4505
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigmod june paris france 
copyright acm 

theodore johnson labs research research att com oliver spatscheck labs research research att com flip korn labs research flip research att com divesh srivastava labs research divesh research att com tion number data items stream 
examples algorithms :10.1.1.7.8618:10.1.1.6.6513:10.1.1.19.8594
refer selection algorithms 
typically order data influences performance algorithms 
universe driven algorithms virtual array attribute values maintain various inner products sketches data stream 
typically space accuracy bounds function size universe attribute values drawn 
examples algorithms :10.1.1.119.5031:10.1.1.29.634
refer sketch algorithms 
typically order data affect sketch algorithms maintain identical data values different universe sizes may different sketches 
selection sketch algorithms known range holistic aggregates including quantiles heavy hitters count distinct rare counts correlated aggregates second concerted effort build data stream management systems dsmss general purpose streaming application 
traditional database systems store data maintain transactions support query processing consistent view data evolving transactions 
emerging applications data streams shift emphasis database system 
data stream applications data arrives fast rate high may wish able store data 
dsmss devise methods pipeline tuples query processing mechanisms schedule operations maximize throughput dsmss motivated monitoring applications 
example dsmss :10.1.1.11.8839:10.1.1.68.4467
application processing ip traffic data network 
routers forward ip packets great speed spending typically nanoseconds packet 
processing ip packet data variety monitoring tasks keeping track statistics provisioning billing detecting network attacks speed packets forwarded illustrative example data stream processing 
see need holistic aggregates scenario quantiles provide simple statistical summary traffic carried link heavy hitters nicely describe significant portion traffic link count distinct count rare indicators normal activity vs activity denial service attack 
monitoring holistic aggregates ip traffic data streams compelling application 
straightforward holistic aggregates interactions gigascope users reveals need composition grouping holistic aggregates 
example common network analysis query source ip hour interval report median th percentile th percentile tcp round trip time 
similar grouping queries different holistic aggregates count distinct military monitoring applications 
despite convergence compelling application ip traffic data analysis development principles dsmss little attention paid task computing holistic aggregates dsms real application network monitoring 
engineering holistic aggregation dsms real high speed data streams challenge 
query optimization simple holistic aggregate computation data stream understood 
address gap principles methods versus real needs practical application 
study performance implications user defined aggregate functions udafs incorporating selection sketch algorithms holistic aggregates data stream management system query processing architecture 
streaming database gigascope testbed network traffic data source :10.1.1.68.4467
contributions follows 

identify key performance bottlenecks tradeoffs propose novel techniques holistic udafs sketch ones fast space efficient high speed data stream applications 
techniques rely judicious combination low level aggregation ip traffic data streams network router level higher level composition adapting data characteristics 

evaluate performance generated actual ip packet data live dsms gigascope running ip router focusing approximating quantiles heavy hitters 
derive half dozen different implementation strategies holistic aggregates test real simulated data 
best current implementations process streaming queries oc speeds gbps practical ip network data stream analysis engine large isps 
implementation necessity closely tied gigascope architecture 
general lessons learned 
early data reduction critical complex querying high speed data streams 
believe level architecture query processing highly suitable general context dsms 

range early data reduction strategies choose processing approximate complex aggregates including appropriate partial 

appropriate strategy depends streaming rate available processing resources choosing best strategy complex query optimization problem 

approximate complex aggregates quite effective providing accuracy guarantees vastly reducing processing load 

adaptive implementations heavy weight approximations sketches practical presence highly skewed data potential general purpose dsmss 
sheds light broader intricacies query optimization dsms 
simple holistic udafs query optimizer large number choices 

related area data stream algorithms solutions known computing specific holistic aggregates 
described earlier known algorithms divided categories data driven universe driven selection sketch algorithms respectively 
selection sketch algorithms known holistic aggregates interest finding quantiles heavy hitters :10.1.1.7.8618:10.1.1.6.6513:10.1.1.131.3373:10.1.1.19.8594
results relevant 
selection sketch algorithms known holistic aggregates correlated aggregates distinct counting :10.1.1.12.7100
generally data stream algorithms known variety problems including wavelets histograms set expressions complex queries clustering decision trees overview area relevant study tutorials :10.1.1.119.5031:10.1.1.106.9846:10.1.1.29.634:10.1.1.4.5550:10.1.1.119.3124:10.1.1.100.9995:10.1.1.32.1927
algorithms typically tested synthetic datasets cases real ip network traces 
aware methods directly incorporated live dsms 
area dsmss seen extensive activity 
number dsmss proposed built prototypes including aurora telegraph stream tribeca gigascope :10.1.1.11.8839:10.1.1.68.4467
dsmss provide methods random sampling collection continuous queries military application accumulated stanford presents examples holistic aggregates 
know detailed study performance holistic aggregates dsmss 
dsmss specific applications streaming data sensors financial applications detailed performance study holistic aggregates known application streaming data speeds consider 
proposed atlas udaf specification supports interesting features streaming udafs 
see section discussion 

integrating udafs gigascope gigascope special architecture handling high speed data streams :10.1.1.68.4467
section discuss relevant aspects gigascope architecture integrate udafs gigascope 
gigascope architecture gigascope designed monitoring high speed data streams inexpensive processors 
accomplish goal gigascope uses architecture optimized particular applications 
gigascope stream database support stored relations continuous queries 
restriction greatly simplifies streamlines implementation 
continuous queries implemented explicit query evaluation windows necessary unblock operators aggregation join 
attributes streams labeled monotone increasing 
query planner uses information determine blocking operator unblocked 
aggregation query group attributes say monotone increasing 
attribute changes value existing groups aggregates flushed operator output similar operator 
values group attributes define epochs aggregation occurs flush epoch 
second gigascope level query architecture low level data reduction high level performs complex processing 
approach employed keeping high streaming rates controlled way guaranteed accuracy contrast existing dsmss employ load shedding 
high speed data streams network interface card nic placed large ring buffer 
streams called source streams distinguish data streams created queries 
data volume source streams far large provide copy query stream 
queries shipped streams 
query executed source stream gigascope creates subquery directly accesses transforms executed output general subquery created table variable aliases source stream query current query set 
subqueries read directly ring buffer 
output streams smaller source stream level architecture greatly reduces amount copying simple queries evaluated directly source stream 
subqueries called low level queries gigascope intended fast lightweight data reduction queries 
deferring expensive processing expensive functions predicates joins large scale aggregation high volume source stream quickly processed minimizing buffer requirements 
expensive processing performed output low level queries data volume smaller easily buffered 
depending capabilities nic push subquery processing nic 
testbed described section nic synthetic data capable processing type projection operator nic live data special processing capabilities 
general appropriate strategy depends streaming rate available processing resources 
choosing best strategy complex query optimization problem goal maximize amount data reduction low level processor causing packet drops 
ensure aggregation fast low level aggregation operator uses fixed size hash table maintaining different groups group 
hash table collision occurs existing group aggregate ejected tuple new group uses old group slot 
gigascope computes partial aggregate low level completed higher level 
query decomposition aggregate query similar data cube computations :10.1.1.120.4505
third gigascope creates queries generating code compiled linked executable queries 
integrate udaf gigascope add udaf functions gigascope library augment gigascope query generation properly handle udafs section 
udaf specification discussed section incorporating udaf gigascope matter incorporating udaf calls gigascope library providing query planner specification udaf 
modified gigascope understand udaf specifications calls udaf functions appropriate places 
udaf commonly composed functions initialize function initializes state scratchpad space iterate function adds value state udaf terminate function releases udaf resources returns value 
order support multiple return values udaf computation discussed split terminate function output function destroy function 
low level gigascope queries require additional function 
recall low level queries simple fast queries data reduction 
holistic aggregate data structures large require occasional expensive restructuring 
call low level udaf indicate full flushed high level query complete processing 
small fast data structure low level partial processing completed higher level 
inform gigascope udafs occur query providing udaf declarations 
udaf declaration include udaf name return type types parameters scratchpad type 
example int udaf char approx median int declares approx median udaf accepts integer uses bytes scratchpad storage returns integer 
order apply approx median values derived source data stream specify low level query high level query 
example int udaf char low approx med high approx med approx median int udaf char low approx med int int udaf char high approx med declares low approx med high approx med approx median 
query approx median value derived source stream transformed low approx med high approx med low approx med note return value low approx med variablelength string represents udafs state value accepted high approx med 
queries want udaf return values 
example query ask median th percentile th percentile values packet round trip times 
computing udaf times inefficient extractor functions declare udaf needs computed 
extractor function just macro specifying function called udaf 
example int extr percentile fcn approx quantile percentile int int macro transforms percentile len percentile fcn approx quantile len 
duplicate approx quantile easily recognized 
approx quantile aggregate returns searchable data structure output function called 
percentile fcn function performs search structure 
aggregate call release resources return value necessary 
designed udaf specification easily implemented extension conventional udaf specification support aggregate query decomposition multiple return values 
sophisticated specification atlas proposed 
benefits atlas specification udaf functions defined sql declaration 
property highly desirable general purpose dbms extensibility reasons felt traditional method language udaf function definitions appropriate purposes 
easier implement fewer demands query optimizer 
gigascope specialized system 
udafs written experts highest possible performance critical issue familiar sql 
easy extensibility described lesser concern 
query similar experiments median packet length computed source ip address minute interval select tb median length udp group time tb udp source data stream query broken query query planner 

streaming algorithms selection quantiles greenwald khanna proposed novel data structure quantile summary effectively maintains lower ranks respectively value input stream :10.1.1.7.8618
input values data struc ture consists ordered sequence tuples correspond subset observations input stream ini tially empty 
tuple consists components value corresponds element data stream ii value equals iii equals ensuring summary structure satisfies property quantile query answered precision rank 
achieve input stream conceptually divided buckets width value current bucket inserted tuples values periodically space compressed merging adjacent pairs tuples analysis algorithm showed space bound implementation gigascope 
implemented quantile udaf variants quantile summaries gigascope processing hierarchy 
algorithms span range simple complex preprocessing low level query divide low level query high level query different amounts follows 
algorithm lite 
algorithm minimal buffering incoming tuples array ordered arrival time sent batch processing 
algorithm heavy 
algorithm maintains linked list samples ordered item values 
insertion reduces size sweeping full compress phase 
storage space full outputs data structure sent call discards space starts new data structure 
algorithm medium 
algorithm attempts find happy medium algorithms 
trades processing processing time algorithm linear number tuples strategy updates logarithmic expected time maintaining skiplist directory tuples ordered item values 
partially compresses insertion performing local probe new element inserted probe random location list done constant time 
merge summary size summary size result size merge algorithm describe output processed maintains quantile summary tuples 
algorithm output simple ar ray values inserted algorithms output quantile summary tuples update procedure involved 
algorithm compresses tuples compressed 
merged single summary size values maximum ranks adjusted pseudocode 
merge adjacent pairs tuples compressed reduce space 
resulting quantile summary guaranteed report quantiles rank error 
guarantee space bound due worst case scenarios merging experiments indicate bound tends hold practice 
sketch heavy hitters different sketch methods proposed computing frequency moments count distinct queries join size estimation heavy hitters :10.1.1.12.7100:10.1.1.131.3373
focus computing heavy hitters streams values updated counts finding large flows grouped source ip address counts coming packet sizes 
count min sketch method described gives probabilistic approach approximating count item error proportional sum counts items 
easily incorporated scheme find heavy hitters items count exceed threshold fraction total count simple top search procedure 
implementation gigascope fix parameters sketch determine size data structure test divide processing low level high level 
implementation gigascope 
sketch implemented array counts different hash functions map item ids new packet interpreted update sketch way determined user query example query heavy hitters source ip addresses packet size means packet interpreted update source ip packet size bytes 
update sketch updated estimate sum values take error estimate proportional probability higher error proportional sketches summed entry wise sketch sum streams 
property needed implementations 
find items highest counts keep sketches items different levels granularity sketch sketch 
search values greater proceeds similar way binary search 
space cost proportional update cost scales tradeoffs settings sketch parameters increasing gives better accuracy uses space increasing gives fewer errors cost update time space smaller gives faster updates cause errors take time extract results 
set giving expected error factor ing counts choosing power hash functions efficient compute set fix keeping sketches full bit items bit prefixes items 
kept exact counts bit prefixes giving total sketch size kb 
parameter settings basis experimentation 
plan investigate impact parameter settings comparison scope 
low level query strategies low level considered methods order increasing complexity 

buffer 
buffer strategy simply keeps kb array pairs arrive flushes buffer values 
buffer flushed partially full occupied prefix array passed high level 

hash 
hash strategy uses array pairs uses hash table 
update arrives test add current count 
slot empty put slot search empty slot 
aggregate counts expected show improvement buffering skewed data sources aggregating insertions particular item single update required high level 

compress 
disadvantage hash strategy flushed sparsely populated table copied high level small amount needs sent 
compress augments hashing approach structure flushed count non zero entries low table compacted moving entry available free slot populated prefix copied high level 
affect high level processing reduces memory transfer 

low sketch 
intensive low level strategy computes sketch low level 
requires kb space allocated group may high overhead terms space large numbers groups bottleneck transfers especially epoch boundaries 
design feature experiments output strategies interchangeable compare effect different choices low level different choices high level 
search exceeds consecutive locations routine requests flush 
high level strategies high level considered different ways sketch routines 
low sketch 
strategy partner routine low sketch low level keeps sketch high level 
low level flushed sketch received low level set uses property summability sketches 
direct sketch 
direct sketch strategy accepts array low level updates sketch pair described 
adaptive sketch 
skewed sparse data previous methods automatically allocate space sketching return approximate results space efficient keep exact data return exact answers groups 
adaptive approach designed smoothly adapt input distribution 
initially keeps exact results list pairs new updates received low level list searched update append list 
length list exceeds set length sketch allocated list populate sketch 
default threshold set distinct values experiments compared values 
skewed distributions seen real data streams may observe thousands millions observed packets distinct values seen see section quantitative results 

experimental environment evaluate performance approximate quantile heavy hitter algorithms modified gigascope accept udafs described section incorporated algorithms streaming algorithms gigascope library 
performance testing data sources 
data source agilent technologies traffic generator 
generate gbit sec traffic links 
traffic generator sophisticated source randomness 
vary source ip address packet packet length independently uniformly random 
average packet length bytes channels driven maximum rate produce packets second 
monitored generated stream modern inexpensive server comprised ghz pentium processors gbytes memory 
system configured gigascope report number packets dropped low level queries 
addition alerted packets sent low level queries high level queries dropped collect precise statistics 
experiments aggregates collected second intervals 
measuring cpu load collect cpu time processes second interval 
traffic generator provides controlled environment measuring cpu overhead represent realistic data source 
alternative data source monitor span port router connects institution internet mbit sec link span port mirrors traffic monitoring purposes 
monitored stream older single cpu mhz pentium mbytes ram previously set network administrators 
experiments query section varying udaf minute intervals accuracy experiments 
experiment ran hour 
experiments ran normal business hours traffic link varied considerably experiment experiment experiments 
shows traffic volumes number groups high volume run 
typical low volume run averaged packets minute second high volume run averaged packets minute second 
average number groups minute respectively exhibiting considerably variation number packets 
evident statistics chart nature traffic changes rapidly 
packets packets groups minute time high traffic volume 
groups packets groups distribution tuples groups extremely skewed 
sample distribution packets group plotted log log scale shows straight line indicating power law distribution 
property data samples 
skewed distributions important implications implementing fast udafs 
groups tuples represented exactly small simple fast data structures 
packets processed groups large number packets 
property clearly seen shows cumulative distribution number groups number packets packets group 
packets group boundary small large groups large process packets 
boundaries produce similar results 

low level query performance critical optimization gigascope splitting aggregation queries low level high level queries 
operation query large impact performance section examine algorithms performance detail 
queries evaluated fixed size buffer store groups aggregate data udafs fixed size scratchpad space group tuple malloc deprecated low level queries 
limited number groups memory query acts aggregation cache 
mechanism examined aggregate cache replacement policy 
early versions gigascope lru cumulative distribution packets group packets groups cumulative distribution packets groups 
replacement policy 
lru caused overhead changed replacement policy direct mapped 
policy groups mapped hash table chaining 
collision hash table old group flushed space new group 
able recover lru replacement policy empirically determine actual overhead lru 
notice direct mapped policy cause excessive number cache invalidations due hash table collisions 
implemented simple modification direct mapped policy term second chance 
try hash collision replacement policy rehash 
second try results collision group hash position ejected 
ran experiment traffic generator 
created simple aggregation query collecting count min max 
varied number groups source ip addresses packet stream decreased number cache slots lowlevel query minimum cache size packet loss occurred 
results table 
active groups direct mapped second chance table minimum cache size packet loss 
second chance policy effective direct mapped policy especially working set source stream large 
policy simple fast effective substitute lru 
remaining experiments run second chance replacement policy second chance replaced direct mapped production version gigascope 
discussed section aggregation gigascope divides time sequence epochs 
epoch groups closed converted tuples subject having clause flushed output 
point tends performance bottleneck potentially large number tuples created flushed output stream involving lot memory copies 
holistic udafs bottleneck worse processing finalize aggregate output function expensive 
noticed earlier implemented lazy cache flush policy low level queries similar policy implemented high level queries examination scope 
epoch changes full hash table entries labeled old 
tuple arrives new epoch old full hash table entry flushed 
new group collides old hash table entry old group flushed 
new group collides new hash table entry old entries flushed immediately preserve attribute output stream 
able evaluate effectiveness lazy flush policy simple matter disable enforce eager flush 
reused aggregation query replacement policy experiment 
subscribed increasing number queries ensuring common subqueries shared measured packet loss rate low level queries 
varied number groups measured loss rate cpu utilization report values smallest number groups packets dropped 
results table 
loss loss cpu groups queries eager lazy util table packet loss rate eager lazy flush lazy flush policy provides small significant reduction packet loss rate especially number groups large 
improvement difference unacceptable acceptable packet loss rate 
holistic udafs tend large state expensive output functions effects occur smaller number groups 
note cpu utilization low low packet drops occur 
fact indicates group flush epoch bottleneck 
solution lies scheduling buffering reducing cpu costs 
schedulability queries improves significantly number groups decreases 
wish perform controlled load shedding respond handle overload conditions better sample groups packets 

holistic udaf performance evaluated different udaf implementations quantiles heavy hitters respect performance space usage accuracy 
synthetic traffic generator experiments allow better control data characteristics 
generator created uniformly distributed values grouping attribute groups group number distinct values attribute aggregated varied 
remainder experiments live tcp traffic data 
goal run queries possible high data rate possible dropping packets 
evaluation algorithms schedulability varying data characteristics server architectures 
selection quantiles report experimental results algorithms described section 
considered parameters scratchpad size low level query small medium large 
performance results 
data traffic generator performance differences methods pronounced case groups number tuples group largest 
default high level query algorithm drops packets yield meaningful numbers 
true experiments 
report results section 
performance remaining algorithms including null udaf baseline summarized 
algorithm clearly fastest cases regardless scratchpad size marginally slower null udaf 
algorithm slowest twice slow algorithm scratchpad sizes 
recall section algorithm lightweight low level followed algorithm algorithm 
ranking performance expected 
ordering reversed cases algorithm giving slowest performance followed algorithm algorithm 
observe choice strategy low level inversely impacts performance high level 
negative correlation due data reduction quantile summaries employed algorithms reduction fewer smaller transfers low high level 
trade may desirable large increase processing cost buys modest decrease 
shared processor system environment experiment low level queries executed processor high level queries bottleneck 
shows additional cost justified algorithm large scratchpad size cases savings offset extra 
summarizes performance algorithms traffic generator groups 
observe ordering algorithms respect performance varying degrees 
instance see payoffs extra processing medium scratchpad size 
due larger number groups versus previous experiment transfers data reduction significant impact 
large scratchpad size extra algorithms caused processor drop packets 
fact algorithm loss measurements computed 
algorithm best choice certain conditions 
algorithm provide benefits large scratchpad size relatively small number groups 
algorithm safest choice respect packet loss low level achieves amount data reduction scalable high level 
traffic characteristics live tcp data varied experiments comparisons difficult 
algorithms exhibited similar behavior synthetic data 
algorithm best performance followed alg alg worst performance tuple processing time summarized table 
interestingly tradeoff extra processing beneficial algorithm lowest total packet cost making scalable single cpu system 
data highly skewed cpu utilization simple quantile udaf performance groups alg alg alg alg alg alg alg alg small med large alg high low cpu utilization simple quantile udaf performance groups alg alg alg alg alg alg alg alg small med large performance quantile udaf algorithms data traffic generator 
alg alg alg table average processing time tuple sec tcp data 
udafs query 
data traffic generator 
small fraction groups dominate transfer costs 
groups pays expend effort aggregate quantile summaries delay transfers groups active flushed full 
space usage 
mentioned section algorithms provide tight worst case space bound quantile summary algorithm due merging 
experiments space usage comparable algorithms far pessimistic worst case 
fact looked ratio group basis size quantile summary appeared independent number stream tuples group 
consistent observation values arriving random order space depends number stream tuples despite logarithmic dependence worst case bound :10.1.1.7.8618
sketch heavy hitters ran series experiments determine cost sketches experimental setups selection methods 
looked effect combinations different strategies proposed effect higher system load modeled varying number active groups 
looked cost terms space accuracy attainable approaches 
experiments show sketches practical network streams network line speeds 
performance results 
set results shown shows experiment traffic generated traffic generator described 
looked combinations low level high level strategies possible dual processor cpu usage alg system load groups distinct values uniform distribution high level usage low level usage high low null buf direct buf adapt hash direct hash adapt cmpr direct cmpr adapt adapt low sketch sketch performance uniform generated traffic testbed 
experiment shown show effect large number groups large number values 
compare cost null udaf merely computes sum values seen show strategies low level add cost gigascope 
experiments extremes give bad results default approach running query solely high level solely low level bad solution 
observed trying run query completely high level low sketch strategy caused significant number packet drops intermediate approaches drops 
high level approach costly high low level causing cpu usage processor low level causes packet drops explore 
low sketch strategy caused packet drops put heaviest strain low level system experiments 
low level query system tends bottleneck behavior undesirable 
leads conclude best performance come picking combination buffer hash compress low level direct adaptive sketching high level 
concentrate methods remainder analysis 
data generated plot large number unique values meaning cause adaptive sketching approach create sketch quickly seen high level costs strategies similar slight disadvantage adaptive approach create populate sketch part way test 
little difference low level strategies keep kb buffer traffic distribution fill approximately rate buffer approach slight advantage lower processing costs get effect compress hash methods 
cpu usage system load sketching groups distinct values uniform traffic null low level usage high level usage buf direct buf adapt hash direct hash adapt cmpr direct cmpr adapt low sketch sketch performance skewed generated traffic practice noted network data displays strongly skewed distribution data see distinguish high level methods 
little difference low level different strategies choice strategy low level impact cost high level buffering causes hashing expensive compressing hash table 
interestingly best performance achieved adaptive approach combined compressing hash table cost high level negligible 
strategies adaptive approach little expensive direct approach weighed potential space savings accuracy improvements adaptive approach 
time packet usec buf direct processing time real data block buffer buf adapt low level time high level time hash direct hash adapt cmpr direct cmpr adapt average processing time real traffic stream udafs experience leads focus strategies pairing low level strategies high level strategies experiment real data 
timing results shown show hash compress strategies preferred 
note harder cross compare results experiments record replay real traffic streams 
data cost hash direct hash adaptive low level fluctuations stream monitoring affected distributions 
conclude apparent benefits adaptive strategy total cost corresponding direct version trying aggregation low level bring significant reductions cost high level 
combination strategies works best levels right balance struck amount done cost doing 
recorded packet drops methods running powerful system 
modern processor times scale cost nanoseconds packet 
cpu usage system load increasing number groups distinct values uniform distribution high level usage low level usage buf adapt hash adapt cmpr adapt low sketch number groups cpu usage number groups effect number groups 
shows cost methods scale number groups increases 
show low sketch adaptive strategy data set low level strategy cost virtually identical direct adaptive strategies plot clarity 
see buffering hashing approach scale logarithmically number groups 
compress strategy similar hash strategy number groups large point clear advantages compressing 
attempting push computation low level form low sketch approach uniformly costly significant margin 
doing processing low level hashing hashing compressing shows moderate noticeable improvements 
parameters adaptive sketch method 
experimented switch keeping exact counts items making sketch adaptive strategy 
see clear correlation log number groups sketching default distinct values 
values cost grow quickly reflecting additional cost converting list exact values sketch threshold values exceeded 
hand definite space advantages choosing larger value size sketch kb higher cost item bytes item count cpu usage average bytes packet system load adaptive sketch strategies high level low level sketch distinct values sketch sketch distinct values number groups distinct values varying sketch adaptive strategy space usage different data types distinct values sketch small range large range space cost adaptive strategy pair 
shown increasing threshold sketching reduces average number bytes packet processed 
especially clear data analyzed drawn larger range say ip addresses port numbers chance creating sketch lower threshold average cost higher quickly sketch 
accuracy results 
ensure results keeping sketches answer queries reasonable accuracy 
heavy hitters queries able compute exact answers queries traffic generator compared output sketching strategies 
queried system find top heavy hitters various distributions compared exact top top sketching 
computed proportion approximate answers correct top approximate heavy hitter true top heavy hitter third heavy hitter ranked second fourth sketch method heavy hitter returned sketch method rank missed fifth heavy hitter returned sketch method 
results shown adaptive strategy direct strategy note low level strategy irrelevant sketch computed whichever low level strategy employed 
see advantage adaptive strategy cases accuracy sketching strategies correct adaptive sketch direct sketch missed accuracy sketches uniform traffic threshold exceeded sketch exact results kept results correct 
reduces fraction misses 
improvements accuracy increasing size sketch 
expect results accurate real data synthetic data generated uniformly challenging case approximate methods values counts similar making finding heavy hitters harder realistic skewed distribution 

examined problem integrating streaming algorithms holistic aggregates dsms 
modified gigascope system recognize udafs incorporated algorithms computing approximate quantiles heavy hitters 
tested algorithms best versions ran comfortably gbit sec input stream challenging conditions leading conclude algorithms monitor oc links 
udafs quantiles heavy hitters incorporated gigascope library production systems 
achieving high performance required significant amount design testing research 
default implementation udaf fed tuples derived source stream unacceptably bad performance 
complicating factor extreme skew network data 
groups small containing tuples tuples contained large groups 
large space udafs sketches unacceptably large space overheads due small groups exact algorithms unacceptably large space overheads due large groups 
applied set techniques achieve practical implementations may summarized 
break udaf processing simple fast low level runs close data stream highlevel computes desired result 
approach allows write fast code deal complexities handling large data integer arithmetic compact cacheable data structures 
running data reduction query close data source critical performance 
situations code running routers nics low level query system resources compute simple 

split gives considerable flexibility devising udaf algorithms 
need experiment find best combination algorithms particular architecture 
factors include streaming rate data skew characteristics architecture sub run shared separate processors 

properties data stream dictate choice best algorithm requiring adaptivity performance 
live ip data stream showed large variations behavior particularly extremely skewed distribution tuples groups 
writing adaptive sketch algorithm heavy hitters udaf overcame space problems associated sketch algorithms 
properly sketches effective technique practice 

performance limiting bottleneck aggregation gigascope occurs aggregates flushed epoch boundaries 
problem significant simple aggregates holistic udafs require expensive output functions large data copies transfer state 
gigascope problem degree lazy flush epoch boundaries point lot required short amount time 
improve schedulability udafs keeping state small especially low level queries steps possibly proactive ones ensure output function fast 
observe crucial udafs adapt resource consumption stream encounter 
selection methods behavior inherent operation methods engineer property 
necessary find right division low level high level 
quantile udaf best approach usually small amount aggregation low level 
heavy hitters udaf trying high level low level caused unacceptable packet drops 
skewed nature real data meant doing simple hash table aggregation data sufficiently powerful reduce cost computing sketch high level sufficiently inexpensive strain low level system 
combining techniques successful application sketching methods real time high speed network data 
computing approximations holistic aggregates incorporating udafs data stream management system provides great amount flexibility writing expressing queries 
write ad hoc queries output streams purposes 
example simple matter write query computes heavy hitters median packet lengths packets source ip addresses chaining queries 
udaf specification language developed allows additional flexibility return value aggregate udaf state 
example compute sketches data streams join compute change detection function joined stream 
directions 
curious aspect approach break holistic aggregates supposed sub 
approach effective computing approximations holistic aggregates approximations algebraic 
decomposition approximate holistic aggregates opens new direction query optimization 
direction ing evaluation plan 
example computing heavy hitters faster pre aggregated data stream 
best heavy hitters udaf fact limited pre aggregation 
depending data characteristics collection possible algorithms 
choosing evaluation algorithm part query optimization 
note possible decompose holistic aggregates levels 
example want compute heavy hitters traffic flowing collection routers 
need combine aggregate data router computed udaf 
query planner needs set optimize query way transparent user 

agilent technologies 

advanced agilent com 
alon gibbons matias szegedy 
tracking join self join sizes limited storage 
proc 
acm pods conf pages 
alon matias szegedy 
space complexity approximating frequency moments 
proc 
acm stoc pages 
journal version journal computer system sciences 
arasu stream stanford stream data manager 
ieee data engineering bulletin 
babcock babu datar motwani widom 
models issues data stream systems 
proc 
acm pods pages 
carney monitoring streams new class data management applications 
proc vldb pages 
chandrasekaran telegraphcq continuous dataflow uncertain world :10.1.1.11.8839
proc 
cidr 
charikar chen farach colton 
finding frequent items data streams 
proc 
icalp pages 
cormode datar indyk muthukrishnan 
comparing data streams hamming norms 
proc 
intl 
conf 
vldb pages 
cormode muthukrishnan 
improved data stream summary count min sketch applications 
proc 
latin american informatics latin 
journal version appear journal algorithms 
cranor johnson spatscheck shkapenyuk 
gigascope high performance network monitoring sql interface 
proc 
acm sigmod page 
cranor johnson spatscheck shkapenyuk :10.1.1.68.4467
gigascope stream database network applications 
proc 
acm sigmod pages 
cranor johnson spatscheck shkapenyuk 
gigascope stream database 
ieee data engineering bulletin pages 
dobra garofalakis gehrke rastogi 
processing complex aggregate queries data streams 
proc 
acm sigmod pages 
domingos hulten :10.1.1.119.3124
mining high speed data streams 
proc 
kdd 
flajolet martin :10.1.1.12.7100
probabilistic counting algorithms database applications 
jcss 
garofalakis gehrke rastogi 
querying mining data streams get look 
proc 
acm sigmod 
gehrke korn srivastava 
computing correlated aggregates continual data streams 
proc 
acm sigmod conf pages 
gibbons 
distinct sampling highly accurate answers distinct value queries event reports 
proc 
vldb pages 
gibbons matias poosala 
fast incremental maintenance approximate histograms 
proc 
intl 
conf 
vldb pages 
gilbert kotidis muthukrishnan strauss :10.1.1.119.5031
surfing wavelets streams pass summaries approximate aggregate queries 
proc 
intl 
conf 
vldb pages 
gilbert kotidis muthukrishnan strauss 
summarize universe dynamic maintenance quantiles 
proc 
intl 
conf 
vldb pages 
gray bosworth layman pirahesh :10.1.1.120.4505
data cube relational aggregation operator generalizing group cross tab sub totals 
proc 
th intl 
conf 
data engineering pages 
greenwald khanna :10.1.1.7.8618
space efficient online computation quantile summaries 
acm sigmod record 
guha koudas shim 
data streams histograms 
proc 
acm symp 
theory computing pages 
guha mishra motwani callaghan :10.1.1.32.1927
clustering data streams 
proc 
focs pages 
iso dbl lhr ansi 
iso ansi working draft database language sql 
karp papadimitriou shenker 
simple algorithm finding frequent elements sets bags 
acm tods 
koudas srivastava 
data stream query processing tutorial 
proc 
vldb page 
lerner shasha 
virtues challenges ad hoc streams querying finance 
data engineering bulletin 
madden franklin 
stream architecture queries streaming sensor data 
proc 
ieee icde conf 
manku motwani 
approximate frequency counts data streams 
proc 
vldb pages 
manku rajagopalan lindsay 
approximate medians quantiles pass limited memory 
acm sigmod pages 
muthukrishnan 
data streams algorithms applications 
acm siam symp 
discrete algorithms rutgers edu stream ps 
stanford stream data manager 
www db stanford edu stream sqr 
widom sullivan 
tribeca system managing large databases network traffic 
proc 
usenix technical conf 
indyk guha koudas 
dynamic multidimensional histograms 
proc 
acm sigmod pages 
wang zaniolo 
atlas native extension sql data mining 
siam intl 
conf 
data mining 
