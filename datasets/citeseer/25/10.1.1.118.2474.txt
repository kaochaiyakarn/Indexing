link prediction supervised learning mohammad hasan vineet salem mohammed zaki rensselaer polytechnic institute troy new york zaki cs rpi edu social network analysis attracted attention years 
link prediction key research direction area 
study link prediction supervised learning task 
way identify set features key performance supervised learning setup 
identified features easy compute time surprisingly effective solving link prediction problem 
explain effectiveness features class density distribution 
compare different classes supervised learning algorithms terms prediction performance various performance metrics accuracy precision recall values squared error fold cross validation 
results practical social network datasets shows known classification algorithms decision tree nn multilayer perceptron svm rbf network predict links comparable performances svm outperforms narrow margin performance measures 
ranking features popular feature ranking algorithms shows small subset features plays significant role link prediction 
background social networks popular way model interaction people group community 
visualized graphs vertex corresponds person group edge represents form association corresponding persons 
associations usually driven mutual interests intrinsic group 
social networks dynamic objects new edges vertices added graph time 
understanding dynamics drives evolution social network complex problem due large number variable material funded part government opinions findings recommendations expressed material author necessarily reflect views government 
supported part nsf career award iis doe career award de fg er nsf eia emt 
parameters 
comparatively easier problem understand association specific nodes 
variations problems interesting research topics 
instance interesting questions posed association pattern change time factors drive associations association nodes affected nodes 
specific problem instance address research predict likelihood association nodes knowing association nodes current state graph 
problem commonly known link prediction problem 
coauthorship graph scientific publication data experiments 
prepare datasets coauthorship graphs data point corresponds pair authors coauthored training years 
depending fact coauthored testing year data point positive label negative label 
apply different types supervised learning algorithms build binary classifier models distinguish set authors coauthor testing year rest coauthor 
predicting prospective links coauthorship graph important research direction identical conceptually structurally practical social network problems 
primary reason coauthorship network true example social network scientists community collaborate achieve mutual goal 
researchers shown graph obeys power law distribution important property typical social network 
name practical problems closely match study research consider task analyzing monitoring terrorist networks 
objective analyzing terrorist networks conjecture particular individuals working interactions identified current information base 
intuitively predicting hidden links social network formed group terrorists 
general link prediction provides measure social proximity vertices social group known optimize objective function entire group especially domain collaborative filtering knowledge management systems help modeling way disease rumor fashion joke internet virus propagates social network 
research contributions 
explain procedural aspect constructing machine learning dataset perform link prediction 

identify short list features link prediction particular domain specifically coauthorship domain 
features powerful provide remarkable accuracy general applicable social network domains 
inexpensive obtain 

experiment set learning algorithms evaluate performance link prediction problem perform comparative analysis 

evaluate feature visually comparing class density distribution algorithmically known feature ranking algorithms 
ment results 
compare different machine learning algorithms link prediction task 
faloutsos directly perform link prediction worth mentioning context 
introduced object called connection subgraph defined small subgraph best captures relationship nodes social network 
proposed efficient algorithm electrical circuit laws find connection subgraph large social network efficiently 
connection subgraph effectively compute topological feature values supervised link prediction problem especially network large 
interesting efforts related social network targeted explicitly solve link prediction problem 
experiences ideas papers helpful aspects 
bayesian networks analyze social network graphs 
graph clustering approach identify sub communities social network 
cai concept relation network project social network graph relation graphs mine graphs effectively answer user queries 
model extensively optimization algorithms find optimal combination existing relations best match user query 
related early research social network data experimental setup done social scientists psychologists numerous efforts computer consider social network edge 
concentrated represents interaction analyzing social network graphs 
efforts particular time experimental domain solve link prediction problem interaction defined research specially social network domain 
closest match article 
article bears author information liben publication year 
predict link partition authors extracted features network range publication years non overlapping topology coauthorship network 
experiments sub ranges 
sub range selected training evaluated effectiveness features link years testing years 
prediction problem 
effectiveness judged prepare classification dataset choosing factor prediction accuracy im author pairs appeared training years proved random predictor 
provides publish papers years 
excellent starting point link prediction fea pair represents positive example tures extracted supervised learning negative example depending author framework perform link prediction system pairs published testing years manner 
features network 
testing years pair topology 
hand added authors establishes link non topological features improve training years 
classification model accuracy link prediction substantially 
prac link prediction problem needs predict link tice non topological data available exam successfully distinguishing positive classes ple overlap interest persons dataset 
link prediction problem posed exploited achieve substantial improve binary classification problem solved employing effective features supervised learning framework 
research bibliographic datasets elsevier www elsevier com dblp dblp uni trier de xml information different research publications field biology computer science respectively 
years data years training testing 
dblp years data 
years training years testing 
pairs authors represent positive class negative class chosen randomly list pairs qualify 
constructed feature vector pair authors 
detailed description features sub section 
datasets summarized table 
dataset number papers number authors dblp table statistics datasets feature set choosing appropriate feature set critical part machine learning algorithm 
link prediction choose features represent form proximity pair vertices represent data point 
definition features may vary domain domain link prediction 
research name proximity features 
example case coauthorship network authors close sense social network research evolves larger set identical keywords 
similar analogy terrorist network suspects close experts identical set dangerous skills 
research restrict discussion feature set coauthorship link analysis generic definition proximity measure provides clear direction choose conceptually identical features network domains 
favorable property features cheap compute 
proximity measure exist individual attributes provide helpful clues link prediction 
attributes pertain node social network aggregation functions need combine attribute values corresponding nodes node pair 
name aggregated features 
illustrate consider example 
choose arbitrary scientists social network 
probability coauthor say 
choose scientist network works multi disciplinary research established rich set connections community 
probability coauthor value higher available information prolific researcher 
summarize idea statement scientists prolific collaborate 
aggregation individual measure prolific particular scientist corresponding individual feature number different areas worked 
summing value combine yields aggregated feature meaningful pair authors link prediction 
example higher attribute value collaborate 
similar individual feature terrorist network number languages suspect speak 
aggregating value produces aggregated feature link prediction terrorist network 
discuss important set features arise network topology 
importantly applicable equally domains values depends structure network 
name topological features 
initiatives studied network topological features different application areas link analysis collaborative filtering link prediction obvious feature shortest distance pair nodes considered 
shorter distance better chance collaborate 
similar measures number common neighbors jaccard coefficient edge disjoint shortest distances detailed list see 
features part category 
example aggregate topological feature corresponds single network node 
discussion place category consider appropriate 
provide short description features link prediction coauthorship network 
describe intuitive argument choosing feature link prediction problem 
note features applied datasets due unavailability information 
proximity features database feature 
keyword data available dblp dataset feature 
keyword match count feature directly measures proximity pair nodes authors 
list keywords individual authors introduced papers take intersection sets 
larger size intersection related areas better candidate coauthor pair 
aggregated features described earlier features usually related single node 
simplest aggregation function sum convert feature meaningful candidate link prediction 
complex aggregation function introduced appropriate 
sum papers value feature calculated adding number papers pair authors published training years 
authors appear training years normalized count author years appeared 
choice feature comes fact authors having higher count prolific 
authors prolific probability higher pair coauthor compared probability case random pair authors 
sum neighbors feature represents social connectivity pair authors adding number neighbors 
neighborhood obtained coauthorship information 
variants feature exist 
accurate measure consider weighted sum neighbors weights represent number publication node specific neighbor 
considered weights 
feature intended embed fact connected person establish new coauthor links 
note feature placed topological features number neighbors degree node 
sum keyword counts scientific publication keywords play vital role representing specific domain researchers 
researchers wide range interests interdisciplinary research usually keywords 
sense better chance collaborate new researchers 
sum function aggregate attribute author pair 
sum classification code usually research publication categorized code strings organize related areas 
similar keyword count publication multiple codes interdisciplinary researchers area usually collaborators 
sum log secondary neighbors count number primary neighbors significant number secondary neighbors play important role especially scientific research collaboration 
author directly connected author highly connected consider new graduate student known adviser person better chance coauthor distant node person 
number secondary neighbors social network usually grow exponentially take logarithm secondary neighbor count pair authors sum individual node values 
attribute placed topological feature computed network topology 
calculation feature somewhat costly 
topological features features research features useful 
shortest distance feature significant link prediction research 
kleinberg discovered social network nodes connected short distance 
remarkable characteristic feature link prediction 
smallest hop count shortest distance nodes 
variants feature 
computing shortest distance compute edge disjoint shortest distance 
feature 
importance feature gradually decreases increases 
shortest distance weighted edge actual weight value unweighted shortest distance 
pair nodes weight edge chosen reciprocal number papers corresponding author pair coauthored 
variants costly compute 
clustering index initiatives social network research indicated clustering index important features node social network 
reported node dense locally grow edges compared located sparse neighborhood 
clustering index measures localized density 
newman defines clustering index fraction pairs person collaborators collaborated 
mathematically node graph clustering index number triangles node number connected triples node shortest distance author kw graph considered topological attribute requires extended social network compute 
compute attribute extended social network adding keyword kw nodes 
kw node connected author node edge keyword author papers 
keywords appear connected edge 
shortest distance nodes extended graph computed get attribute value 
addition features tried features jaccard coefficient adamic adar related network topology 
unfortunately provide significant improvement classifier performance 
normalize feature values zero mean standard deviation classification model 
classification algorithms exist plethora classification algorithms supervised learning 
performances comparable usually better specific dataset domain 
research experimented different classification algorithms 
tried variation reported result showed best performance 
algorithms svm different kernels decision tree multilayer perceptron nearest neighbors different variations distance measure naive bayes rbf network bagging 
svm svm light implementation svmlight joachims org 
nearest neighbors programmed algorithm matlab 
rest algorithms known machine learning library weka 
compared performance classifiers different performance metrics accuracy precision recall value squared error algorithms fold cross validation results reported 
algorithms tunable parameters svm nearest neighbors separate validation set find optimum parameter values 
svm trade training error margin optimum 
nearest neighbor value yielded best performance dataset value dblp dataset 
default parameter values weka worked quite 
models classifier performance sensitive respect model parameter values quite optimal setting 
results discussions table show performance comparison different classifiers dblp datasets respectively 
datasets counts positive class negative class 
baseline classifier accuracy classifying testing data points equal models tried reached accuracy 
indicates features selected discriminating ability 
dataset features dblp dataset features 
information available dblp dataset 
name feature dataset available table 
accuracy metrics svm rbf kernel performed best datasets accuracy respectively 
naturally performance dblp dataset worse compared fewer features dataset 
dblp dataset obtained years published articles accuracy link prediction deteriorates longer range time span institution affiliations coauthors research areas researchers may vary time 
predicting links dataset comparably difficult dataset years data 
datasets popular classifiers decision tree nearest neighbors multilayer perceptron similar performances usually accurate svm 
small difference statistically significant drawn accuracy metric suited algorithm link prediction 
analyze performance applied popular ensemble classification techniques bagging link prediction 
bagging groups decisions number classifiers resulting model susceptible variance errors 
performance improvement bagging independent classifiers high overlap misclassification sets independent classifiers small 
bagging accuracy datasets indicates improvements 
implies majority misclassifications bias error introduced inconsistent feature values samples 
classifiers failed samples 
understand inconsistency feature values investigate distribution positively negatively labeled samples important features dataset shown 
distribution feature values plotted axis distribution positive data points distribution negative data points keyword match distribution positive data points distribution negative data points distribution positive data points distribution negative data points sum neighbors count sum papers count shortest distance evaluation features class density distribution dataset distribution positive data points distribution negative data points shortest distance distribution positive data points distribution negative data points distribution positive data points distribution negative data points distribution positive data points distribution negative data points sum count sum neighbors count second shortest distance evaluation features class density distribution dblp dataset distribution positive data points distribution negative data points classification model accuracy precision recall value squared error decision tree svm linear kernel svm rbf kernel nearest neighbors multilayer perceptron rbf network naive bayes bagging table performance different classification algorithms database classification model accuracy precision recall value squared error decision tree svm linear kernel svm rbf kernel nearest neighbors multilayer perceptron rbf network naive bayes bagging table performance different classification algorithms dblp dataset various feature values 
comparison sake normalize distribution area curves 
features distribution positive negative class exhibit significant difference facilitating classification algorithm pick patterns feature value correctly classify samples 
small overlap region distributions features 
fraction population lies critical overlap region features candidates misclassification 
shall discuss distribution 
classifiers rbf network model performs worst datasets may suitable link prediction problem 
rbf networks usually affected severely irrelevant inconsistent features link prediction datasets heavily noisy performance value rbf poor 
hand naive bayes algorithm performed bad 
naive bayes probably powerful catch patterns data set helpful classification 
tables list precision recall value positive class 
value harmonic mean precision recall considered better performance measure classification model comparison accuracy especially pop ulation classes biased training dataset 
considering value metric rank classifiers really change indicating models similar precision recall behavior 
comparing precision recall columns find classifiers precision value significantly higher recall value positive class 
indicates models false negatives false positives 
intuitively models missing actual links predicting false links 
coauthorship network sense exist coauthor pairs coauthor merely coincidence 
happen link real life dataset name aggregation 
note dataset names spelling considered person correct 
problem addressed concurrent researches entity disambiguation methodologies proposed cope 
better performance observed methodologies applied dataset preprocessing step feeding learning algorithms 
average squared error performance comparison metric 
research shows metric remarkably robust attribute name information gain gain ratio chi square svm feature avg 
rank attribute eval 
evaluator sum papers sum neighbors sum kw count sum classification count kw match count sum log sec 
neighbor 
count shortest distance clustering index shortest dist kw author graph table rank different attributes different algorithms dataset attribute name information gain gain ratio chi square svm feature avg 
rank attribute eval 
evaluator sum papers sum neighbors shortest distance second shortest distance table rank different attributes different algorithms dblp dataset higher average correlation metrics excellent metric compare performance different classifiers 
finding average squared error binary classification setup requires predicting posterior probability predicting just class label 
fact model predict true underlying probability test case optimal 
probability squared error computed easily 
unbiased environment cost associated misclassification positive negative class calibration probability required 
value predicting probability sample predicted positive class difference value considered error 
contrast value sample predicted negative class difference value considered error 
worst case error value label predicted tossing fair coin 
root mean squared error computed samples 
discussed approach computing squared error 
observe dramatic difference performances different classifiers 
svm rbf outperforms metric healthy margin datasets 
datasets squared error svm second best algorithm 
confirms effectiveness classification algorithms link prediction task 
objectives compare features judge relative strength link prediction task 
ran algorithms 
table provide comparison features showing rank importance obtained different algorithms 
column shows average rank rounded nearest integer 
result shown table dataset keyword match count top ranked attribute 
sum neighbors sum papers come order significance 
shortest distance top ranked topological features 
shows distribution powerful features easily understand reasoning ranking 
instance keyword match feature negative class sample keyword matches samples match value equal zero 
positive class samples keyword match values distribution mean equal 
similar noticeable differences distribution observed features 
ranking algorithm clustering index author keyword distance lowest ranked attributes 
researchers indicated clustering index significant attribute link prediction dataset promising effect 
results shown table shortest distance best feature dblp dataset 
strength feature distribution shown 
positive class mean distance author pairs negative class 
dataset second shortest distance distance calculated shortest path common edge shortest path 
mean value positive class negative class 
similar differences distribution observed features sum papers sum authors 
note features negative class concentrated heavily smaller feature values compared positive class 
ranking algorithms ranks attributes order shortest distance second shortest distance sum papers sum neighbors 
order properly reflects distribution patterns shown 
number samples positive classes exceptionally low 
highly imbalanced dataset deteriorate performance classification algorithms special care taken 
fortunately algorithms adapted imbalanced datasets approach outlined algorithms followed situation 
link prediction specially security applications missing actual links poses severe threat compared predicting false links 
high value recall desired 
requires bias model predicting positive class predicting negative class 
easily achieved classification model specially svm nearest neighbors assigning suitable higher cost misclassification positive class 
terrorist social networks finding samples train supervised classification model poses big challenge 
huge efforts employed obtain terrorism related information strong counter effort terrorist groups hide connections undermines effectiveness data extraction 
situation data highly noisy worse attribute values unknown 
performance link prediction deteriorate significantly case 
fortunately classification algorithms developed missing values 
information datasets changing real time classifier models need updated frequently 
issues regarding real life dataset results discussions previous section readers convinced link prediction solved high accuracy features supervised learning setup 
real life exists issues dealt obtain satisfactory performance 
serious applications link prediction days research currently considers link prediction domain security anti terrorism majority coauthorship domain 
discussions implicitly assume application 
consider number datasets different domains experiments standard cross better understand link prediction problem 
validation approach report performance train define degree confidence link ing testing datasets drawn dis prediction providing hard binary 
real life data comes heterogeneous tion 
sources analyst needs sure clas current attribute set model testing dataset built attributes capture causal relationships 
dataset distribution possible attribute values result algorithms completely consider time dependent values 
distribution feature values analyzed evaluated different weights different years 
understand noticeable differ consider kind attributes 
ences training testing dataset 
sus online social networks pected distribution different probability www com value class label predicted 
www com useful 
probability calibrated accordingly online networks predict users testing dataset predict class label 
share common interests 
interests datasets highly imbalanced 
change time affect likelihood looking links represent rare events link users 
similar keeping track dynamic user groups 
link prediction social network important problem helpful analyzing understanding social groups 
understanding lead efficient implementation tools identify hidden groups find missing members groups common problems security criminal investigation research 
research suggest categories features considered link prediction social network application 
course exact value feature depend application hand 
example terrorist network terrorists strong proximity skills complementary skills 
shown link prediction problem handled effectively modeling classification problem 
shown popular classification models solve problem acceptable accuracy state art classification algorithm svm beats performance metrics 
provided comparison features ranked prediction ability different feature analysis algorithms 
believe ranks meaningful help researchers choose attributes link prediction problem similar domain 
acknowledgment central intelligence agency cia ibm providing support research ibm contract 
dataset provided cia kdd challenge program 
adamic adar friend neighbors web social networks pp 

barabasi jeong neda schubert evolution social network scientific collaboration physica pp 

ismail finding communities clustering graph overlapping subgraph intl 
conf 
applied computing 
bhattacharya getoor deduplication group detection links 
cai shao yan han mining hidden communities heterogeneous social networks 
caruana niculescu data mining metric space empirical analysis supervised learning performance criteria kdd 
caruana niculescu crew ensemble selection libraries models intl 
conf 
machine learning 
cross knowing know supporting knowledge creation sharing social networks organizational dynamics pp 

dorogovtsev mendes evolution networks advan 
physics pp 

faloutsos mccurley tomkins fast discovery connection subgraphs intl 
conf 
knowledge 
discovery data mining 
moore bayes net graphs understand authorship networks 
gu chang aligning boundary kernel space learning imbalanced dataset icdm 
hu zhang saha modeling virus anti virus dynamics topology aware networks globecom ieee 
huang li chen link prediction approach collaborative filtering join conference digital libraries denver huang zeng collaborative filtering 
recommendation model validation selection analyzing bipartite random graphs workshop information technologies systems las vegas nv kleinberg navigation small world nature pp 
liben nowell kleinberg link prediction problem social networks 
malin unsupervised name disambiguation social network similarity 
workshop link analysis counter terrorism security 
milgram small world problem psychology today pp 
myers laskey dejong learning bayesian networks incomplete data evolutionary algorithms fifteen conf 
uncertainty artificial intelligence toronto canada newman structure scientific collaboration networks proc 
national acad 
sciences pp 
newman fast algorithm detecting community structure networks 
matsumoto accelerating cross project knowledge collaboration collaborative filtering social networks intl conf 
software engineering 
witten frank data mining practical machine learning tools techniques morgan kaufmann san francisco 
zheng wu srihari feature selection text categorization imbalanced data sigkdd explorations pp 

