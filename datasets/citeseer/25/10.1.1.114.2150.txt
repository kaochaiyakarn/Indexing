dialogue act modeling automatic tagging recognition conversational speech andreas stolcke klaus ries sri international carnegie mellon university university karlsruhe noah elizabeth shriberg university colorado boulder sri international rebecca bates daniel jurafsky university washington university colorado boulder paul taylor rachel martin university edinburgh johns hopkins university carol van ess marie meteer department defense bbn technologies describe statistical approach modeling dialogue acts conversational speech units statement question backchannel agreement disagreement apology 
model detects predicts dialogue acts lexical collocational prosodic cues discourse coherence dialogue act sequence 
dialogue model treating discourse structure conversation hidden markov model individual dialogue acts observations emanating model states 
constraints sequence dialogue acts modeled dialogue act gram 
statistical dialogue grammar combined word grams decision trees neural networks modeling idiosyncratic lexical prosodic manifestations dialogue act 
develop probabilistic integration speech recognition dialogue modeling improve speech recognition dialogue act classification accuracy 
models trained evaluated large hand labeled database conversations switchboard corpus spontaneous human human telephone speech 
achieved dialogue act labeling accuracy automatically recognized words prosody word transcripts compared chance baseline accuracy human accuracy small reduction word recognition error 
speech technology research laboratory sri international ravenswood ave menlo park ca 
mail stolcke speech sri com 
association computational linguistics computational linguistics volume number table fragment labeled conversation switchboard corpus 
speaker dialogue act utterance question go college right 
abandoned yo answer statement year laughter 
declarative question re re senior 
answer statement working projects trying graduate laughter 
appreciation oh 
backchannel 
appreciation great question um university uh state statement state 
signal non understanding say 
statement state 

ability model automatically detect discourse structure important step understanding spontaneous dialogue 
hardly consensus exactly discourse structure described agreement exists useful level analysis involves identification dialogue acts das 
da represents meaning utterance level illocutionary force austin 
da approximately equivalent speech act searle conversational game move power adjacency pair part schegloff sacks schegloff jefferson 
table shows sample kind discourse structure interested 
utterance assigned unique da label shown column drawn defined set shown table 
das thought tag set classifies utterances combination pragmatic semantic syntactic criteria 
computational community usually defined da categories relevant particular application efforts way develop da labeling systems domain independent discourse resource initiative architecture core allen 
understanding deep sense da tagging clearly useful range applications 
example meeting summarizer needs keep track said conversational agent needs know asked question ordered 
related das processing step infer dialogue games carlson levin moore levin slightly higher level unit comprises small number das 
interactional dominance measured accurately da distributions simpler techniques serve indicator type genre discourse hand 
cases da labels enrich available input higher level processing spoken words 
important role da information feedback lower level processing 
example speech recognizer constrained expectations das context constraining potential recognition hypotheses improve accuracy 
goal article twofold hand aim comprehensive framework modeling automatic classification das founded known statistical methods 
doing pull previous approaches stolcke dialogue act modeling table dialogue act labels 
da frequencies percentages total number utterances corpus 
tag example statement legal department 
backchannel acknowledge uh huh 
opinion think great abandoned uninterpretable agreement accept exactly 
appreciation imagine 
question special training 
non verbal laughter throat clearing answers 
conventional closing nice talking 
wh question wear today 
answers response acknowledgment oh okay 
hedge don know making sense 
declarative question afford get house 
give break know 
backchannel question right 
quotation pregnant cats summarize reformulate oh mean switched schools kids 
affirmative non answers action directive don go collaborative completion aren contributing 
repeat phrase oh open question 
rhetorical questions steal newspaper 
hold answer agreement drawing blank 
reject negative non answers uh lot 
signal non understanding excuse answers don know conventional opening 
clause 
answers 
rd party talk goodness diane get 
offers options commits ll check self talk word looking right 
accept part tag question right 
declarative wh question kind buff 
apology sorry 
hey lot new ideas 
example model draws da grams hidden markov models conversation earlier nagata morimoto waibel see section 
framework generalizes earlier models giving clean probabilistic approach performing da classification unreliable words evidence 
speech recognition task framework provides mathematically principled way condition speech recognizer conversation context dialogue structure information correlated da identity 
methods domain independent framework part treats da labels arbitrary formal tag set 
presentation highlight simplifications computational linguistics volume number assumptions achieve tractable models point fall short reality 
second results obtained approach large widely available corpus spontaneous conversational speech 
results validating methods described interest reasons 
example previous da labeling corpus task oriented nature amount data utterances exceeds previous studies order magnitude see table 
keep presentation interesting concrete alternate description general methods empirical results 
section describes task data detail 
section presents probabilistic modeling framework central component framework discourse grammar discussed section 
section describe experiments da classification 
section shows da models benefit speech recognition 
prior related summarized section 
issues open problems addressed section followed concluding remarks section 
dialogue act labeling task domain chose model switchboard corpus human human conversational telephone speech godfrey mcdaniel distributed linguistic data consortium 
conversation involved randomly selected strangers charged talking informally self selected topics 
train statistical models corpus combined extensive effort human hand coding das utterance variety automatic semiautomatic tools 
data consisted substantial portion switchboard waveforms corresponding transcripts totaling conversations 
utterance segmentation hand labeling utterance corpus da needed choose utterance segmentation raw switchboard data segmented linguistically consistent way 
expedite da labeling task remain consistent switchboard research efforts version corpus hand segmented sentence level units prior independently da labeling system meteer 
refer units segmentation utterances 
relation utterances speaker turns single turn contain multiple utterances utterances span turn case speaker mid utterance 
utterance unit identified da annotated single da label 
da labeling system special provisions rare cases utterances combine aspects da types 
automatic segmentation spontaneous speech open research problem right mast stolcke shriberg 
rough idea difficulty segmentation problem corpus definition utterance units derived study shriberg 
automatic labeling word boundaries utterance combination lexical prosodic cues obtained accuracy correct word transcripts accuracy automatically recognized words 
fact segmentation labeling tasks interdependent warnke finke complicates problem 
considerations decided confound da classification stolcke dialogue act modeling task additional problems introduced automatic segmentation assumed utterance level segmentations 
important consequence decision expect utterance length acoustic properties utterance boundaries accurate turn important features das shriberg see section 
tag set chose follow standard shallow discourse structure annotation dialogue act markup layers tag set designed natural language processing community auspices discourse resource initiative core allen 
began markup system modified ways relevant corpus task 
aims provide domain independent framework dialogue annotation reflected fact tag set mapped back categories jurafsky shriberg 
labeling effort showed content task related distinctions play important role effective da labeling 
switchboard domain essentially task free giving external constraints definition da categories 
primary purpose adapting tag set enable computational da modeling conversational speech possible improvements conversational speech recognition 
lack specific task decided label categories inherently interesting linguistically identified reliably 
focus conversational speech recognition led certain bias categories lexically syntactically distinct recognition accuracy traditionally measured including lexical elements utterance 
modeling techniques described formally independent corpus choice tag set success particular task course crucially depend factors 
different tasks techniques study prove useful greater importance 
believe study represents fairly comprehensive application technology area serve point departure 
resulting tag set multidimensional approximately basic tags question statement combined diacritics indicating orthogonal information example dialogue function utterance related task management communication management 
approximately possible unique combinations codes coders jurafsky shriberg 
obtain system somewhat higher agreement data class statistical modeling purposes fine grained tag set devised 
tag set distinguishes mutually exclusive utterance types experiments reported 
table shows categories examples relative frequencies 
original infrequent classes collapsed resulting da type distribution highly skewed 
occurs largely basis subdividing dominant da categories task independent reliable criteria 
tag set incorporates traditional sociolinguistic discourse theoretic notions rhetorical relations adjacency pairs form labels 
furthermore tag set structured allow labelers annotate switchboard conversation transcripts listening minutes 
study focusing prosodic modeling das reported shriberg tag set reduced categories 
computational linguistics volume number constraints da labels included finer distinctions felt drawback balanced ability cover large amount data 
labeling carried month period linguistics graduate students cu boulder 
agreement label tag set resulting kappa statistic 
kappa statistic measures agreement normalized chance siegel castellan jr 
argued carletta kappa values higher desirable detecting associations coded variables satisfied level agreement achieved 
note single variable da type coded study goal things model associations instances variable adjacent das 
total switchboard conversations labeled comprising utterances words 
data partitioned training set conversations words utterances estimating various components model test set conversations words utterances 
remaining conversations set aside test set uncompromised tuning effects 
major dialogue act types frequent da types briefly characterized 
discussed focus nature das computational framework recognition full details da tag set numerous motivating examples separate report jurafsky shriberg 
statements opinions 
common types utterances statements opinions 
split distinguishes descriptive narrative personal statements state ment directed opinion statements opinion 
distinction designed capture different kinds responses saw opinions countered disagreed opinions statements elicit backchannels dialogue act example utterance statement cat um statement probably oh years old big old fat 
statement months old opinion 
opinion think kind stressful 
opinions include hedges think believe mean 
combined statement opinion classes studies dimensions differ shriberg 
questions 
questions types 
question label includes utterances having pragmatic force question syntactic mark effect lacking acoustic information labeling accuracy assessed relabeling subset data listening fairly small shriberg 
conservative estimate relabeling study da types labels changed listening 
da types higher uncertainty backchannels agreements easily confused acoustic cues rate change 
stolcke dialogue act modeling table common realizations backchannels switchboard 
frequency form frequency form frequency form uh huh sure okay um right oh huh uh oh huh uh ings question subject inversion sentence final tags 
declarative questions utterances function pragmatically questions question form mean declarative questions normally wh word argument verb echo question format declarative word order subject precedes verb 
see weber survey declarative questions various realizations 
dialogue act example utterance question special training 
question doesn eliminate 
question uh guess year ago re probably watching lot right 
declarative question re government course 
wh question old 
backchannels 
backchannel short utterance plays discourse structuring roles indicating speaker go talking 
usually referred conversation analysis literature studied extensively jefferson schegloff 
expect recognition backchannels useful discourse structuring role knowing hearer expects speaker go talking tells course narrative occur certain kinds syntactic boundaries detecting backchannel may help predicting utterance boundaries surrounding lexical material 
intuition backchannels look table shows common realizations approximately types tokens backchannel switchboard subset 
table shows examples backchannels context switchboard conversation speaker dialogue act utterance statement uh re point financial income consider putting away backchannel uh huh 
statement college statement going starting regular payroll deduction backchannel um 
statement fall statement money making summer ll putting away college fund 
appreciation um 
sounds 
computational linguistics volume number turn exits abandoned utterances 
abandoned utterances speaker breaks finishing followed restart 
turn exits resemble abandoned utterances syntactically broken mainly way passing speaker 
turn exits tend single words 
speaker dialogue act utterance statement re uh ohio statement wife florida turn exit backchannel uh huh 
hedge don know abandoned statement glad kind problem come answer answers agreements 
answers include uh huh variations acting answer question declarative question 
similarly coded answers 
detecting answers help tell previous utterance question 
answers semantically significant contain new information 
agreement accept reject accept part mark degree speaker accepts previous proposal plan opinion statement 
common agreement accepts 
look lot answers 
answers follow questions agreements follow opinions proposals distinguishing important discourse 

hidden markov modeling dialogue describe computational framework study 
goal perform da classification tasks probabilistic formulation giving principled approach combining multiple knowledge sources laws probability ability derive model parameters automatically corpus statistical inference techniques 
available evidence conversation goal find da sequence highest posterior probability evidence 
applying bayes rule get argmax argmax argmax represents prior probability da sequence likelihood evidence 
likelihood usually straightforward model posterior 
fact models generative causal nature describe evidence produced underlying da sequence estimating requires building probabilistic discourse grammar statistical model da sequences 
done familiar techniques language stolcke dialogue act modeling table summary random variables dialogue modeling 
speaker labels introduced section 
symbol meaning sequence da labels evidence complete speech signal prosodic evidence acoustic evidence spectral features asr sequence words speakers labels modeling speech recognition sequenced objects case da labels words discourse grammars discussed detail section 
dialogue act likelihoods computation likelihoods depends types evidence 
experiments sources evidence combination transcribed words likelihoods equation ju refers true hand transcribed words spoken conversation 
recognized words evidence consists recognizer acoustics seek compute 
described involves considering multiple alternative recognized word sequences 
prosodic features evidence acoustic features capturing various aspects pitch duration energy speech signal associated likelihoods ju 
ease random variables summarized table 
variables subscripts refer individual utterances 
example wi word transcription ith utterance conversation ith word 
modeling search best da sequence feasible require likelihood models decomposable utterance 
means likelihood complete conversation factored likelihoods individual utterances 
ui ith da label sequence ui un number utterances conversation 
addition ei portion evidence corresponds ith utterance words prosody ith utterance 
decomposability likelihood means ju applied separately types evidence ai wi fi mentioned clear assumption strictly true 
example speakers tend reuse words earlier conversation fowler answer relevant question violating independence 
similarly speakers adjust pitch volume time conversation partner structure discourse boyce violating independence 
areas statistical modeling count fact violations small compared properties modeled dependence ei ui 
computational linguistics volume number ei en start 

ui 
un 
discourse hmm bayes network 
markov modeling returning prior distribution da sequences convenient certain independence assumptions 
particular assume prior distribution markovian ui depends fixed number preceding da labels ui ui order markov process describing 
gram discourse grammars property 
described choice conditioning da types removed current improve quality model amount data available experiments 
importance markov assumption discourse grammar view system discourse grammar local utterance likelihoods kth order hidden markov model hmm rabiner juang 
hmm states correspond das observations correspond utterances transition probabilities discourse grammar see section observation probabilities local likelihoods 
represent dependency structure implied conditional independences special case bayesian belief network pearl 
shows variables resulting hmm directed edges representing conditional dependence 
keep things simple order hmm bigram discourse grammar assumed 
dialogue act decoding hmm representation allows efficient dynamic programming algorithms compute relevant aspects model probable da sequence viterbi algorithm posterior probability various das utterance considering evidence forward backward algorithm viterbi algorithm hmms viterbi finds globally probable state sequence 
applied discourse model locally decomposable likelihoods markovian discourse grammar find precisely da sequence highest posterior probability argmax combination likelihood prior modeling hmms viterbi decoding fundamentally standard probabilistic approaches speech recognition bahl jelinek mercer tagging church 
maximizes probability stolcke dialogue act modeling getting entire da sequence correct necessarily find da sequence da labels correct kokkinakis 
minimize total number utterance labeling errors need maximize probability getting da label correct individually need maximize compute utterance posterior da probabilities summing ui summation sequences ith element matches label question 
summation efficiently carried forward backward algorithm hmms baum 
th order unigram discourse grammars viterbi decoding forward backward decoding necessarily yield results 
higher order discourse grammars forward backward decoding consistently gives slightly absolute better accuracies expected 
method 
formulation experiments uses entire conversation evidence da classification 
obviously possible offline processing full conversation available 
paradigm follows historical practice switchboard domain goal typically offline processing automatic transcription speaker identification indexing archival entire previously recorded conversations 
hmm formulation supports computing posterior da probabilities partial evidence utterances preceding current required online processing 

discourse grammars statistical discourse grammar models prior probabilities da sequences 
case conversations identities speakers known switchboard discourse grammar model turn behavior 
straightforward approach model sequences pairs ui ti ui da label ti represents speaker 
trying model speaker idiosyncrasies conversants arbitrarily identified model symmetric respect choice sides replicating training sequences sides switched 
discourse grammars vocabulary labels plus tags conversations 
example second da tag table predicted trigram discourse grammar fact speaker previously uttered question turn preceded start conversation 
gram discourse models computationally convenient type discourse grammar gram model da tags allows efficient decoding hmm framework 
trained standard backoff gram models katz frequency smoothing approach witten bell 
models various orders compared perplexities average number choices model predicts tag conditioned preceding tags 
note passing viterbi baum algorithms equivalent formulations bayes network framework pearl 
hmm terminology chosen mainly historical reasons 
computational linguistics volume number table perplexities das turn information 
discourse grammar jt unigram bigram trigram table shows perplexities types models das combined da speaker id sequence das conditioned known speaker ids appropriate switchboard task 
expected see improvement decreasing perplexities increasing gram order 
incremental gain trigram small higher order models prove useful 
observation initially perplexity confirmed da tagging experiments reported section 
comparing see speaker identity adds substantial information especially higher order models 
relatively small improvements higher order models result lack training data inherent independence das das removed 
near optimality bigram discourse grammar plausible conversation analysis accounts discourse structure terms adjacency pairs schegloff sacks schegloff jefferson 
inspection bigram probabilities estimated data revealed conventional adjacency pairs receive high probabilities expected 
example questions followed answers answers confirming 
commands followed agreements cases statements elicit backchannels cases 
discourse models investigated non gram discourse models various language modeling techniques known speech recognition 
motivation alternative models grams enforce dimensional representation da sequences saw event space really multidimensional da label speaker labels 
motivation grams fail model long distance dependencies fact speakers may tend repeat certain das patterns conversation 
alternative approach standard cache model kuhn de mori boosts probabilities previously observed unigrams bigrams theory tokens tend repeat longer distances 
true da sequences corpus cache model showed improvement standard gram 
result somewhat surprising unigram dialogue grammars able detect speaker gender accuracy baseline switchboard ries indicating global variables da distribution potentially exploited cache dialogue grammar 
clearly dialogue grammar adaptation needs research 
second built discourse grammar incorporated constraints da sequences nonhierarchical way maximum entropy estimation berger della pietra della pietra 
choice features informed similar ones commonly statistical language models general intuitions potentially information bearing elements discourse context 
model designed current da label constrained features unigram statistics previous da da removed das occurring window stolcke dialogue act modeling past previous utterance speaker 
model gram constraints performed slightly better corresponding backoff gram 
additional constraints da triggers distance bigrams separate encoding speaker change bigrams da channel improve relative trigram model 
model confirms adequacy backoff gram approach leads conclude da sequences switchboard domain characterized local interactions modeled low order gram statistics task 
structured tasks situation different 
exploitable structure 

dialogue act classification describe detail knowledge sources words prosody modeled automatic da labeling results obtained knowledge sources turn 
results combination knowledge sources 
da labeling accuracy results compared baseline chance accuracy relative frequency frequent da type statement test set 
dialogue act classification words da classification words observation different das distinctive word strings 
known certain cue words phrases hirschberg litman serve explicit indicators discourse structure 
similarly find distinctive correlations certain phrases da types 
example uh huh occur backchannels trigrams start occur questions 
leverage information source hand coding knowledge words indicative das statistical language models model full word sequences associated da type 
classification true words 
assuming true hand transcribed words utterances evidence compute word likelihoods ju straightforward way building statistical language model das 
das particular type training corpus pooled da specific trigram model estimated standard techniques katz backoff katz witten bell discounting witten bell 
classification recognized words 
fully automatic da classification approach partial solution able recognize words spontaneous speech perfect accuracy 
standard approach best hypothesis speech recognizer place true word transcripts 
conceptually simple convenient method optimal information recognizer fact maintains multiple hypotheses relative plausibilities 
thorough recognized speech derived follows 
classification framework modified recognizer acoustic information spectral features appear evidence 
compute decomposing acoustic likelihood word likelihood ju summing frequency statements labeled data slightly different cf 
table 
computational linguistics volume number ai wi wn start 

ui 
un 
modified bayes network including word hypotheses recognizer acoustics 
word sequences ju ju second line justified assumption recognizer acoustics typically cepstral coefficients invariant da type words fixed 
note approximation modeling 
example different das common words may realized different word pronunciations 
shows bayes network resulting modeling recognizer acoustics word hypotheses independence assumption note added wi variables summed comparison 
acoustic likelihoods correspond acoustic scores recognizer outputs hypothesized word sequence summation approximated experiments summed best hypotheses generated recognizer utterance 
care taken scale recognizer acoustic scores properly recognizer acoustic scores language model weight recognizer 
results 
table shows da classification accuracies obtained combining word recognizer likelihoods gram discourse grammars described earlier 
best accuracy obtained transcribed words encouraging comparable human performance agreement see section 
observe relative increase classification error recognizer words remarkably small considering speech recognizer word error rate test set 
standard recognizer total log score hypothesis computed log ijw log jw ij jw ij number words hypothesis parameters optimized minimize word error rate 
word insertion penalty represents correction language model allows balancing insertion deletion errors 
language model weight compensates acoustic scores variances effectively large due severe independence assumptions recognizer acoustic model 
rationale appropriate divide score components experiments computed summand equation logarithm log log jw ij approach give better results standard multiplication log note selecting best hypothesis recognizer relative magnitudes score weights matter summation equation absolute values important 
parameter values standard recognizer specifically optimized da classification task 
stolcke dialogue act modeling table da classification accuracies transcribed recognized words chance 
discourse grammar true recognized relative error increase unigram bigram trigram compared best da classification approach straightforward best approach 
experiment single best recognizer hypothesis effectively treating true word string 
best method increased classification error relative best algorithm accuracy bigram discourse grammar 
dialogue act classification prosody investigated prosodic information information independent words standard recognizer acoustics 
prosody important da recognition reasons 
saw earlier word classification suffers recognition errors 
second utterances inherently ambiguous words 
example questions word sequences identical statements distinguished final rise 
detailed study aimed automatic prosodic classification das switchboard domain available companion shriberg 
investigate interaction prosodic models dialogue grammar word da models discussed 
touch briefly alternative machine learning models prosodic features 
prosodic features 
prosodic da classification large set features computed automatically waveform word phone information 
features broadly grouped referring duration utterance duration pauses pauses total mean nonspeech regions exceeding ms pitch mean range utterance slope regression line energy mean range rms energy signal noise ratio snr speaking rate measure morgan gender speaker listener 
case utterance duration measure correlates length words speaking rate 
gender feature classified speakers male female test potential inadequacies normalizations 
appropriate included raw features values normalized utterance conversation 
included features output pitch accent boundary tone event detector taylor number pitch accents utterance 
complete description prosodic features analysis usage models shriberg 

prosodic decision trees 
prosodic classifiers cart style decision trees breiman 
decision trees allow combination discrete continuous features inspected help understanding role different features feature combinations 
illustrate area prosody aid classification task applied trees da classifications known ambiguous words 
frequent example corpus distinction backchannels agreements computational linguistics volume number ling dur ling dur minus min pause cont speech frames ling dur ling dur minus min pause cont speech frames snr mean utt ling dur snr mean utt ling dur snr mean utt snr mean utt decision tree classification backchannels agreements 
node labeled majority class node posterior probabilities classes 
features queried tree number frames continuous speech regions cont speech frames total utterance duration ling dir utterance duration excluding pauses ms ling dur minus min pause mean signal noise ratio snr mean utt 
see table share terms right 
shown prosodic tree trained task revealed agreements consistently longer durations greater energy reflected snr measure backchannels 
hmm framework requires compute prosodic likelihoods form utterance ui associated prosodic feature values fi 
apparent difficulty decision trees classifiers neural networks give estimates posterior probabilities 
problem overcome applying bayes rule locally fi ui ui note fi depend ui treated constant purpose da classification 
quantity proportional required likelihood obtained dividing posterior tree probability prior ui training tree uniform prior distribution da types 
chose second approach downsampling training data equate da proportions 
counteracts common problem tree classifiers trained skewed distributions target classes low frequency classes modeled sufficient detail majority class dominates tree growing objective function 
results decision trees 
preliminary experiment test integration prosody knowledge sources trained single tree discriminate bourlard morgan approach integrate neural network phonetic models speech recognizer 
stolcke dialogue act modeling table da classification prosodic decision trees chance 
discourse grammar accuracy unigram bigram table performance various prosodic neural network classifiers equal priors class da set chance 
network architecture accuracy decision tree hidden layer linear output function hidden layer softmax output function unit hidden layer softmax output function da types statement backchannel opinion abandoned agreement totaling data category comprising remaining da types 
decision tree trained downsampled training subset containing equal proportions da classes 
tree achieved classification accuracy independent test set uniform class distribution 
chance accuracy set tree clearly extracts useful information prosodic features 
decision tree posteriors scaled da likelihoods dialogue model hmm combining various gram dialogue grammars testing full standard test set 
purpose model integration likelihoods class assigned da types comprised class 
shown table tree dialogue grammar performs significantly better chance raw da distribution word methods cf 
table 
neural network classifiers 
chose decision trees prosodic classifiers relative ease inspection suitable probabilistic classifier model estimates posterior probabilities das prosodic features 
conducted preliminary experiments assess neural networks compare decision trees type data studied 
neural networks worth investigating offer potential advantages decision trees 
learn decision surfaces lie angle axes input feature space standard cart trees split continuous features dimension time 
response function neural networks continuous smooth decision boundaries allowing avoid hard decisions complete fragmentation data associated decision tree questions 
important related ries indicated similarly structured networks superior classifiers input features words plug replacement language model classifiers described 
neural networks candidate jointly optimized classifier prosodic word level information show generalization integration approach 
tested various neural network models class downsampled data decision tree training variety network architectures output layer functions 
results summarized table baseline result obtained decision tree model 
experiments softmax network computational linguistics volume number ai wi wn start 

ui 
un 
fi fn bayes network discourse hmm incorporating word recognition prosodic features 
bridle hidden units resulted slight improvement decision tree 
network hidden units afford additional advantage optimized number hidden units indicating complex combinations features far network learn predict das better linear combinations input features 
believe alternative classifier architectures investigated prosodic models results far confirm choice decision trees model class gives close optimal performance task 
intonation event likelihoods 
alternative way compute da likelihoods uses pitch accents boundary phrases taylor 
approach relies intuition different utterance types characterized different intonational tunes kowtko successfully applied classification move types map task corpus wright taylor 
system detects sequences distinctive pitch patterns training continuous density hmm da type 
unfortunately event classification accuracy switchboard corpus considerably poorer map task domain da recognition results coupled discourse grammar substantially worse decision trees 
approach prove valuable intonation event detector robust corpora 
multiple knowledge sources mentioned earlier expect improved performance combining word prosodic information 
combining knowledge sources requires estimating combined likelihood ai utterance 
simplest approach assume types acoustic observations recognizer acoustics prosodic features approximately conditionally independent ui ai wi ai wi ui ai recognizer acoustics modeled way dependence words particularly important avoid prosodic features directly correlated word identities features modeled discourse grammars utterance position relative turn changes 
depicts bayes network incorporating evidence word recognition prosodic features 
important respect independence assumption violated modeling utterance length 
utterance length prosodic feature important feature condition examining prosodic characteristics utterances best included decision tree 
utterance length captured stolcke dialogue act modeling table combined utterance classification accuracies chance 
columns correspond tables respectively 
discourse grammar accuracy prosody recognizer combined unigram bigram directly tree various duration measures da specific lms encode average number words utterance indirectly gram parameters accurately violate independence significant way finke 
discussed section problem best addressed joint lexical prosodic models 
need allow fact models combined equation give estimates differing qualities 
introduce exponential weight controls contribution prosodic likelihood likelihood 
second exponential weight combined likelihood controls dynamic range relative discourse grammar scores partially compensating correlation likelihoods 
revised combined likelihood estimate ai wi fp ai experiments parameters optimized twofold 
test data split roughly half speaker overlap half separately optimize parameters best values tested respective half 
reported results aggregate outcome test set halves 
results 
experiment combined acoustic best likelihoods recognized words top tree classifier mentioned section 
results summarized table 
shown combined classifier presents slight improvement classifier 
experiment discourse grammar indicates combined evidence considerably stronger knowledge source improvement largely redundant priors discourse grammar 
example definition declarative questions marked syntax subject auxiliary inversion confusable statements opinions 
prosody expected help disambiguate cases ambiguity removed examining context utterance noticing utterance answer answer 
focused classifications 
gain better understanding potential prosodic da classification independent effects discourse grammar skewed da distribution switchboard examined binary da classification tasks 
choice tasks motivated analysis confusions committed purely da detector tends mistake questions statements nels agreements vice versa 
tested prosodic classifier word classifier transcribed recognized words combined classifier tasks downsampling da distribution equate class sizes case 
chance performance experiments 
results summarized table 
computational linguistics volume number table accuracy individual combined models subtasks uniform priors chance 
classification task true words recognized words knowledge source questions statements prosody words words prosody agreements backchannels prosody words words prosody shown combined classifier consistently accurate classifier words 
gain accuracy statistically significant small recognizer test set lack power replication larger test set showed gain highly significant subtasks sign test tailed respectively 
additional subtasks relative advantage adding prosody larger recognized true words suggesting prosody particularly helpful word information perfect 

speech recognition consider ways da modeling enhance automatic speech recognition asr 
intuition approach discourse context constrains choice das utterance da type turn constrains choice words 
leveraged accurate speech recognition 
integrating da modeling asr constraints word sequences hypothesized recognizer expressed probabilistically recognizer language model lm 
provides prior distribution wi finding posteriori probable hypothesized words utterance acoustic evidence ai bahl jelinek mercer argmax wi argmax wi wi ai argmax wi wi likelihoods recognizer acoustic model 
standard recognizer language model wi utterances idea obtain better quality lms conditioning da type ui presumably word note similarity equations 
identical fact operating level individual utterance evidence acoustics targets word hypotheses da hypotheses 
stolcke dialogue act modeling distributions differ depending da type 
wi argmax ui wi ui argmax wi argmax wi da classification model tacitly assume words wi depend da current utterance acoustics independent da type words fixed 
da conditioned language models readily trained da specific training data da classification words 
problem applying equation course da type ui generally known applications user interface engineered allow kind da utterance 
need infer da types utterance available evidence entire conversation 
leads formulation wi argmax wi argmax wi argmax wi ui ui ui ui step equation justified shown figures evidence acoustics prosody words pertaining utterances affect current utterance da type ui 
call mixture posteriors approach amounts mixture posterior distributions obtained da specific speech recognizers equation da posteriors weights 
approach quite expensive requires multiple full recognizer rescoring passes input da type 
efficient mathematically accurate solution obtained combining guesses correct da types directly level lm 
estimate distribution da types utterance entire conversation evidence sentence level mixture iyer ostendorf rohlicek da specific lms single recognizer run 
words replace equation ui weighted mixture da specific lms 
call mixture lms approach 
practice estimate da posteriors utterance forwardbackward algorithm models described section conversation rescore recognizer output new posterior weighted mixture lm 
fortunately shown section mixture lms approach give results identical mixture posteriors approach 
equation section gloss issue proper weighting model probabilities extremely important practice 
approach explained detail footnote applies 
computational linguistics volume number computational structure mixture modeling instructive compare expanded scoring formulae da mixture modeling approaches asr 
mixture posteriors approach yields ui mixture lms approach gives ai see second equation reduces crude approximation ai 
practice denominators computed summing numerators finite number word hypotheses wi difference translates normalizing summing das 
normalization takes place final step omitted score maximization purposes shows mixture lms approach computationally expensive 
experiments results tested mixture posteriors mixture lms approaches switchboard test set conversations 
decoding data scratch modified models manipulated best lists consisting best hypotheses utterance 
approach convenient approaches require access full word string hypothesis scoring model longer markovian inconvenient decoding stage lattice rescoring 
baseline experiments obtained standard backoff trigram language model estimated available training data 
da specific language models trained word transcripts training utterances type smoothed interpolating baseline lm 
da specific lm interpolation weight obtained minimizing perplexity interpolated model held da specific training data 
note smoothing step helpful da specific lms word recognition da classification renders da specific lms discriminative 
table summarizes word error rates achieved various models perplexities corresponding lms rescoring note perplexity meaningful mixture posteriors approach 
comparison included additional models best lm refers da specific lm corresponding probable da type utterance 
approximation mixture approaches top da considered 
second included oracle lm lm corresponds hand labeled da utterance 
purpose experiment give upper bound effectiveness mixture approaches assuming perfect da recognition 
somewhat disappointing word error rate wer improvement oracle experiment small relative statistically highly significant tailed sign test matched utterance pairs 
da classification experiments observed smoothed da specific lms yield lower classification accuracy 
stolcke dialogue act modeling table switchboard word recognition error rates lm perplexities 
model wer perplexity baseline best lm mixture posteriors mixture lms oracle lm table word error reductions da oracle da type 
dialogue act baseline wer oracle wer wer reduction answer backchannel backchannel question abandoned uninterpretable wh question question statement opinion statement relative contributions test set word counts da type 
uninterpretable backchannel question opinion wer reduction achieved mixture lms approach achieve statistical significance 
best da mixture models differ significantly test set 
interpreting results realize wer results depend complex combination factors notably interaction language models acoustic models 
experiments varied language models rescoring informative compare quality models reflected perplexity 
measure see substantial relative reduction achieved oracle mixture lms 
perplexity reduction best lm showing advantage mixture approach 
better understand lack substantial reduction word error analyzed effect da conditioned rescoring individual das grouping test utterances true da types 
table shows wer improvements da types ordered magnitude improvement achieved 
shown frequent da types saw improvement highest wins observed typically short das answers backchannels 
expected das tend syntactically lexically highly constrained 
furthermore distribution computational linguistics volume number number words da types uneven 
statements opinions da types dominating frequency number words total see absolute improvement explaining small improvement 
hindsight surprising bulk training data baseline lm consists das allowing little improvement da specific lms 
detailed analysis effect da modeling speech recognition errors van ess ries 
summary experiments confirmed da modeling improve word recognition accuracy quite substantially principle certain da types skewed distribution das especially terms number words type limits usefulness approach switchboard corpus 
benefits da modeling pronounced corpora da distribution typically case task oriented dialogues 
task oriented dialogues feature specific subtypes general da categories constrained discourse 
prior research task oriented dialogues summarized section small reductions wer order 
suggests task oriented domains research needed realize potential da modeling asr 

prior related indicated builds number previous efforts computational discourse modeling automatic discourse processing occurred half decade 
generally possible directly compare quantitative results vast differences methodology tag set type amount training data principally assumptions information available free hand transcribed versus automatically recognized words segmented versus unsegmented utterances 
focus conceptual aspects previous research efforts offer summary previous quantitative results interpreted informative datapoints fair comparisons algorithms 
previous research da modeling generally focused task oriented dialogue tasks particular research effort 
map task corpus anderson bard consists conversations speakers slightly different maps imaginary territory 
task help speaker reproduce route drawn speaker map able see maps 
da modeling algorithms described taylor 
wright map task 
verbmobil corpus consists scheduling dialogues 
number da modeling algorithms described developed verbmobil including mast 
warnke 
reithinger 
reithinger samuel carberry vijay shanker 
atr conference corpus subset larger atr dialogue database consisting simulated dialogues secretary international conferences 
researchers corpus include nagata nagata morimoto kita 

table shows commonly versions tag sets tasks 
discussed earlier domains differ switchboard corpus task oriented 
tag sets generally smaller problems balance occur 
example map task domain words occur das instruct 
table shows approximate size corpora tag set tag estimation accuracy rates various models da prediction 
stolcke dialogue act modeling results summarized table illustrate differences inherent difficulty tasks 
example task warnke 
simultaneously segment tag das results rely prior manual segmentation 
similarly task wright study determine da types speech input hand transcribed textual input 
grams model probabilities da sequences predict upcoming das online proposed authors 
employed nagata follow papers nagata morimoto atr dialogue database 
model predicted upcoming das bigrams trigrams conditioned preceding das trained corpus das 
subsequently relied enhanced grams das approach applying standard techniques statistical language modeling 
reithinger 
example deleted interpolation smooth dialogue grams 
chu carroll uses knowledge structure selectively skip previous das choosing conditioning da prediction 
nagata morimoto may word grams miniature grammar das improving speech recognition 
idea caught quickly suhm waibel mast 
warnke 
reithinger taylor 
variants backoff interpolated class gram language models estimate da likelihoods 
kind sufficiently powerful trainable language model perform function course reithinger propose automatically learned stochastic context free grammars 
jurafsky shriberg fox curl show grammar das captured finite state automata part speech tags 
gram models likelihood models das compute conditional probabilities word sequence da type 
word posterior probability estimators possible common 
mast 
propose semantic classification trees kind decision tree conditioned word patterns features 
ries shows neural networks unigram features superior higher order gram da models 
warnke 
niemann related discriminative training algorithms language models 
waibel suhm waibel followed chu carroll note combination word dialogue grams viewed dialogue hmm word strings observations 
exception samuel carberry vijay shanker models listed table rely version hmm metaphor 
researchers explicitly hmm induction techniques infer dialogue grammars 
waibel example trained ergodic hmm expectation maximization model speech act sequencing 
kita 
attempts unsupervised discovery dialogue structure finite state grammar induction algorithm find topology dialogue grammar 
computational approaches prosodic modeling das aimed automatically extract various prosodic parameters duration pitch energy patterns speech signal taylor 
approaches model patterns techniques vector quantization gaussian classifiers help disambiguate utterance types 
extensive comparison prosodic da modeling literature shriberg 

da modeling geared automatic da classification computational linguistics volume number done applying da models automatic speech recognition 
nagata morimoto suggest conditioning word language models das lower perplexity 
suhm waibel eckert niemann condition recognizer lm left right da predictions able show reductions word error rate task oriented corpora 
similar task oriented domain taylor 
combines da likelihoods prosodic models best recognition output condition recognizer lm achieving absolute reduction word error rate similarly disappointing improvement experiments 
related computational tasks da classification speech recognition received attention date 
mentioned warnke 
finke 
showed utterance segmentation classification integrated single search process 

investigate augmenting da tagging detailed semantic concept tags preliminary step interlingua dialogue translation system 
levin 
couple da classification dialogue game classification dialogue games units da level short da sequences question answer pairs 
mentioned far uses statistical models various kinds 
shown models offer fundamental advantages modularity composability discourse grammars da models ability deal noisy input speech recognizer principled way 
classifier architectures applicable tasks discussed particular da classification 
nonprobabilistic approach da labeling proposed samuel carberry vijay shanker transformation learning brill 
noted tasks mathematical structure similar da tagging shallow parsing natural language processing munk dna classification tasks niemann techniques borrowed 
approach differ various earlier models particularly hmms 
apart corpus tag set differences approach differs primarily generalizes simple hmm approach cope new kinds problems bayes network representations depicted figures 
da classification task framework allows classification unreliable words marginalizing possible word strings corresponding acoustic input prosodic evidence 
speech recognition task generalized model gives clean probabilistic framework conditioning word probabilities conversation context underlying da structure 
previous models address speech recognition relied intuitive best approximation model allows computation optimum word sequence effectively summing possible da sequences recognition hypotheses conversation evidence past 

discussion issues research approach dialogue modeling major components statistical dialogue grammars modeling sequencing das da likelihood models expressing local cues lexical prosodic das 
number significant simplifications arrive computationally statistically tractable formulation 
formulation das serve hinges join various model components decouple components statistical independence assumptions 
conditional stolcke dialogue act modeling das observations utterances assumed independent evidence different kinds utterance lexical prosodic assumed independent 
da types assumed independent short span corresponding order dialogue gram 
research framework characterized simplifications addressed 
dialogue grammars conversational speech need aware temporal properties utterances 
example currently modeling fact utterances conversants may overlap backchannels interrupting ongoing utterance 
addition model nonlocal aspects discourse structure despite negative results far 
example context free discourse grammar potentially account nested structures proposed grosz sidner 
standard gram models da discrimination lexical cues probably suboptimal task simply trained maximum likelihood framework explicitly optimizing discrimination da types 
may overcome discriminative training procedures warnke niemann 
training neural networks directly posterior probability ries principled approach offers easier integration knowledge sources 
prosodic features example simply added lexical features allowing model capture dependencies redundancies knowledge sources 
keyword techniques field message classification applicable rose chang lippmann 
eventually desirable integrate dialogue grammar lexical prosodic cues single model predicts da da history local evidence 
study automatically extracted prosodic features da modeling likewise infancy 
preliminary experiments neural networks shown small gains obtainable improved statistical modeling techniques 
believe progress improving underlying features terms better understanding speakers ways reliably extract data 
regarding data saw distribution das corpus limits benefit da modeling lower level processing particular speech recognition 
reason skewed distribution nature task lack thereof switchboard 
remains seen fine grained da distinctions reliably corpus 
noted da definitions really arbitrary far tasks da labeling concerned 
suggests unsupervised self organizing learning schemes choose da definitions process optimizing primary task may 
hand labeled da categories may serve important role initializing algorithm 
believe dialogue related tasks benefit corpus driven automatic learning techniques 
enable research need fairly large standardized corpora allow comparisons time approaches 
despite shortcomings switchboard domain serve purpose 
inadequacy gram models nested discourse structures pointed chu carroll suggested solution modified gram approach 
computational linguistics volume number table dialogue act tag sets extensively studied corpora 
verbmobil 
high level das verbmobil abstracted total specific das experiments verbmobil das set 
examples 

tag example greet hello dan introduce bye bye request comment look 
suggest thirteenth seventeenth june reject friday booked day accept saturday sounds fine request suggest day week 
init wanted appointment give reason meetings afternoon feedback okay deliberate check calendar confirm okay wonderful clarify okay mean tuesday rd 
digress meet lunch eat lots ice cream motivate go visit subsidiary munich garbage oops map task 
das move types map task 
examples taylor 

tag example instruct go round horizontally underneath diamond mine explain don align okay 
check going indian country 
query yn got written 
query 
acknowledge okay clarify want go diagonally reply 
reply don reply fand pyramid 
ready okay atr 
das illocutionary force types atr dialogue database task models extended set das 
examples english translations nagata 
tag example hello expressive response right promise send registration form request please go station subway inform giving discount time announcement conference 

transferred registration fee right 
stolcke dialogue act modeling table data da tagging experiments 
number da tokens reflects training set size accuracy refers automatic tagging correctness 
error rates compared tasks quite different 
comment field indicates special difficulties due type input data 
source number da tokens number da types tag set accuracy comments waibel 
nagata morimoto atr reithinger 
verbmobil mast 
verbmobil warnke 
verbmobil unsegmented reithinger verbmobil chu carroll wright map task speech taylor 
map task samuel carberry vijay shanker verbmobil 
star japanese 
star english study speech computational linguistics volume number 
developed integrated probabilistic approach dialogue act modeling conversational speech tested large speech corpus 
approach combines models lexical prosodic realizations das statistical discourse grammar 
components model automatically trained applicable domains labeled data available 
classification accuracies achieved far highly encouraging relative inherent difficulty task measured human labeler performance 
investigated modeling alternatives components model backoff grams maximum entropy models discourse grammars decision trees neural networks prosodic classification performance largely independent choices 
developed principled way incorporating da modeling probability model continuous speech recognizer constraining word hypotheses discourse context 
approach gives small reduction word error corpus attributed preponderance single dialogue act type statements 
note research described project workshop innovative techniques lvcsr center speech language processing johns hopkins university jurafsky jurafsky 
da labeled switchboard transcripts project related publications available www colorado edu ling jurafsky ws 
acknowledgments researchers support staff johns hopkins summer workshop especially bill byrne fred jelinek joe kimberly chuck wooters 
additional support came nsf iri iri uk engineering physical science research council gr 
mitch weintraub nigel ward james allen julia hirschberg marilyn walker advice design tag set discourse labelers cu boulder debra marion bond curl anu michelle gregory lori metzler intonation labelers university edinburgh helen wright kurt rob clark cassie mayo matthew bull 
andy kehler anonymous reviewers valuable comments draft 
jan norbert reithinger 

learning dialogue structures corpus 
kokkinakis editors proceedings th european conference speech communication technology volume pages rhodes greece september 
anderson anne miles bader ellen bard elizabeth boyle doherty simon stephen isard jacqueline kowtko jan mcallister jim miller catherine henry thompson regina 

hcrc map task corpus 
language speech 
austin 
things words 
clarendon press oxford 
bahl frederick jelinek robert mercer 

maximum likelihood approach continuous speech recognition 
ieee transactions pattern analysis machine intelligence march 
bard ellen catherine anne anderson taylor 

map task corpus spontaneous dialogues sleep deprivation drug treatment 
isabel roger moore editors proceedings esca nato tutorial workshop speech stress pages lisbon september 
baum leonard ted petrie george soules norman weiss 

maximization technique occurring statistical analysis probabilistic functions markov chains 
annals mathematical statistics 
stolcke dialogue act modeling berger adam stephen della pietra vincent della pietra 

maximum entropy approach natural language processing 
computational linguistics 
bourlard herv nelson morgan 

connectionist speech recognition 
hybrid approach 
kluwer academic publishers boston ma 
breiman friedman olshen stone 

classification regression trees 
wadsworth brooks pacific grove ca 
bridle 
probabilistic interpretation feedforward classification network outputs relationships statistical pattern recognition 
soulie herault editors neurocomputing algorithms architectures applications 
springer berlin pages 
brill eric 

automatic grammar induction parsing free text transformation approach 
proceedings arpa workshop human language technology nj march 
carletta jean 

assessing agreement classification tasks kappa statistic 
computational linguistics 
carlson lari 

dialogue games approach discourse analysis 
reidel 
chu carroll jennifer 

statistical model discourse act recognition dialogue interactions 
jennifer chu carroll nancy green editors applying machine learning discourse processing 
papers aaai spring symposium 
technical report ss pages 
aaai press menlo park ca 
church kenneth ward 

stochastic parts program noun phrase parser unrestricted text 
second conference applied natural language processing pages austin tx 
core mark james allen 

coding dialogs annotation scheme 
working notes aaai fall symposium communicative action humans machines pages cambridge ma november 
evangelos george kokkinakis 

automatic stochastic tagging natural language texts 
computational linguistics 
eckert wieland florian heinrich niemann 

combining stochastic linguistic language models recognition spontaneous speech 
proceedings ieee conference acoustics speech signal processing volume pages atlanta may finke michael maria lapata alon lavie lori levin laura mayfield thomas polzin klaus ries alex waibel klaus zechner 

clarity inferring discourse structure speech 
jennifer chu carroll nancy green editors applying machine learning discourse processing 
papers aaai spring symposium 
technical report ss pages 
aaai press menlo park ca 
fowler carol jonathan 

talkers signaling new old words speech listeners perception distinction 
journal memory language 
detlef koll alex waibel 

probabilistic dialogue act extraction concept multilingual translation systems 
robert jordi robert editors proceedings international conference spoken language processing volume pages sydney december 
australian speech science technology association 
godfrey mcdaniel 

switchboard telephone speech corpus research development 
proceedings ieee conference acoustics speech signal processing volume pages san francisco march 
grosz sidner 

attention intention structure discourse 
computational linguistics 
hirschberg julia diane litman 

empirical studies disambiguation cue phrases 
computational linguistics 
iyer mari ostendorf robin rohlicek 

language modeling sentence level mixtures 
proceedings arpa workshop human language technology pages nj march 
jefferson gail 

notes systematic deployment tokens mm hm 
papers linguistics 
susanne alexandra klein elisabeth maier marion mast joachim quantz 

dialogue acts verbmobil 
verbmobil report universit hamburg dfki gmbh universit erlangen tu berlin april 
jurafsky dan rebecca bates noah rachel martin marie meteer klaus ries computational linguistics volume number elizabeth shriberg andreas stolcke paul taylor carol van ess 

automatic detection discourse structure speech recognition understanding 
proceedings ieee workshop speech recognition understanding pages santa barbara ca december 
jurafsky daniel rebecca bates noah rachel martin marie meteer klaus ries elizabeth shriberg andreas stolcke paul taylor carol van ess 

switchboard discourse language modeling project final report 
research note center language speech processing johns hopkins university baltimore january 
jurafsky daniel elizabeth shriberg debra 

switchboard labeling project coder manual 
technical report university colorado institute cognitive science boulder www colorado edu ling jurafsky manual august html 
jurafsky daniel elizabeth shriberg barbara fox curl 

lexical prosodic syntactic cues dialog acts 
proceedings acl coling workshop discourse relations discourse markers pages 
association computational linguistics 
katz slava 
estimation probabilities sparse data language model component speech recognizer 
ieee transactions acoustics speech signal processing march 
kita kenji nagata morimoto 

automatic acquisition probabilistic dialogue models 
timothy william editors proceedings international conference spoken language processing volume pages philadelphia october 
ralf 

prosody speech understanding systems 
springer berlin 
kowtko jacqueline 
function intonation task oriented dialogue 
ph thesis university edinburgh edinburgh 
kuhn roland renato de mori 

cache base natural language model speech recognition 
ieee transactions pattern analysis machine intelligence june 
levin joan johanna moore 

dialogue games structures natural language interaction 
cognitive science 
levin lori klaus ries ann alon lavie 

tagging speech acts dialogue games spanish callhome 
standards tools discourse tagging proceedings workshop acl pages college park md june 


power dialogue dynamics 
markov klaus editors dynamics dialogue 
harvester new york london pages 
mast kie ling niemann th warnke 

dialog act classification help prosody 
timothy william editors proceedings international conference spoken language processing volume pages philadelphia october 
lise suzanne boyce 

fundamental frequency discourse structure 
language speech 
meteer marie ann taylor robert macintyre iyer 

annotation switchboard corpus 
distributed ldc ftp ftp cis upenn edu pub treebank doc dfl book ps february 
revised june ann taylor 
morgan nelson eric 

speech recognition line estimation speaking rate 
kokkinakis editors proceedings th european conference speech communication technology volume pages rhodes greece september 
munk marcus 

shallow statistical parsing machine translation 
diploma thesis carnegie mellon university 
nagata 

pragmatics rule recognition errors cooperative task oriented dialogues 
john bruce grace wiebe editors proceedings international conference spoken language processing volume pages banff canada october 
nagata morimoto 

experimental statistical dialogue model predict speech act type utterance 
shirai kobayashi harada editors proceedings stolcke dialogue act modeling international symposium spoken dialogue pages tokyo november 
nagata morimoto 

steps statistical modeling dialogue predict speech act type utterance 
speech communication 
uwe stefan heinrich niemann 

discriminative training language model classifiers 
proceedings th european conference speech communication technology volume pages budapest september 
pearl judea 

probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann san mateo ca 
power richard 
organisation purposeful dialogues 
linguistics 
rabiner juang 

hidden markov models 
ieee assp magazine january 
reithinger norbert ralf engel michael martin 

predicting dialogue acts speech speech translation system 
timothy william editors proceedings international conference spoken language processing volume pages philadelphia october 
reithinger norbert martin 

dialogue act classification language models 
kokkinakis editors proceedings th european conference speech communication technology volume pages rhodes greece september 
ries klaus 

hmm neural network speech act classification 
proceedings ieee conference acoustics speech signal processing volume pages phoenix az march 
ries klaus 

detection description textual meaning indicators spontaneous conversations 
proceedings th european conference speech communication technology volume pages budapest september 
rose chang lippmann 

techniques information retrieval voice messages 
proceedings ieee conference acoustics speech signal processing volume pages toronto may sacks schegloff jefferson 

simplest semantics organization turn conversation 
language 
samuel ken sandra carberry vijay shanker 

dialogue act tagging transformation learning 
proceedings th annual meeting association computational linguistics th international conference computational linguistics volume pages montreal 
schegloff 
sequencing conversational openings 
american 
schegloff 
discourse interactional achievement uses uh huh things come sentences 
deborah tannen editor analyzing discourse text talk 
georgetown university press washington pages 
searle 
speech acts 
cambridge university press london new york 
shriberg elizabeth rebecca bates andreas stolcke paul taylor daniel jurafsky klaus ries noah rachel martin marie meteer carol van ess 

prosody aid automatic classification dialog acts conversational speech 
language speech 
shriberg elizabeth andreas stolcke khan 
prosody automatic segmentation speech sentences topics 
speech communication appear september 
special issue accessing information spoken audio 
siegel sidney john castellan jr 
nonparametric statistics behavioral sciences 
mcgraw hill new york second edition 
stolcke andreas elizabeth shriberg 

automatic linguistic segmentation conversational speech 
timothy william editors proceedings international conference spoken language processing volume pages philadelphia october 
suhm waibel 

better language models spontaneous speech 
proceedings international conference spoken language processing volume pages yokohama september 
taylor paul simon king stephen isard helen wright 

intonation dialog context constraints speech recognition 
language speech 
taylor paul simon king stephen isard helen wright jacqueline kowtko 
computational linguistics volume number 
intonation constrain language models speech recognition 
kokkinakis editors proceedings th european conference speech communication technology volume pages rhodes greece september 
taylor paul 
analysis synthesis intonation tilt model 
journal acoustical society america 
van ess carol klaus ries 

linguistically engineered tools speech recognition error analysis 
robert jordi robert editors proceedings international conference spoken language processing volume pages sydney december 
australian speech science technology association 
viterbi 
error bounds convolutional codes asymptotically optimum decoding algorithm 
ieee transactions information theory 
warnke niemann th 

integrated dialog act segmentation classification prosodic features language models 
kokkinakis editors proceedings th european conference speech communication technology volume pages rhodes greece september 
warnke volker stefan th heinrich niemann michael 

discriminative estimation interpolation parameters language model classifiers 
proceedings ieee conference acoustics speech signal processing volume pages phoenix az march 
weber elizabeth 
varieties questions english conversation 
john benjamins amsterdam 
witten ian timothy bell 

zero frequency problem estimating probabilities novel events adaptive text compression 
ieee transactions information theory july 
waibel 

inferring linguistic structure spoken language 
proceedings international conference spoken language processing volume pages yokohama september 
wright helen 

automatic utterance type detection suprasegmental features 
robert jordi robert editors proceedings international conference spoken language processing volume pages sydney december 
australian speech science technology association 
wright helen paul taylor 

modelling intonational structure hidden markov models 
intonation theory models applications 
proceedings esca workshop pages athens september 
victor 
getting word 
papers sixth regional meeting chicago linguistic society pages chicago april 
university chicago 
takashi satoru hiroshi tanaka 

pitch pattern clustering user utterances human machine dialogue 
timothy william editors proceedings international conference spoken language processing volume pages philadelphia october 
