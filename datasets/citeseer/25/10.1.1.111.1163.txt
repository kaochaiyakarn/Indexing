complete system simulation characterize specjvm benchmarks tao li john vijaykrishnan narayanan anand murthy laboratory computer architecture department electrical computer engineering university texas austin austin tx tli ece utexas edu complete system simulation understand influence architecture operating systems application execution identified crucial systems design 
previous attempts understanding architectural impact java programs prior investigating operating system kernel activity executions 
problem particularly interesting context java application invoke kernel services underlying java virtual machine jvm implementation runs programs 
jvm style jit compiler interpreter manner different jvm components garbage collector class loader exercised significant impact kernel activities 
investigate issues research uses complete system simulation specjvm benchmarks simos simulation platform 
execution benchmarks jit compilers interpreters profiled detail identify quantify time spent component 
kernel activity specjvm applications constitutes execution time large dataset small dataset 
average kernel activity large dataset approximately comparison specint benchmarks studied 
kernel services tlb handling dominant applications 
tlb rates jit compiler dynamic class loader garbage collector portions jvm individually analyzed 
addition execution profiles ilp user kernel mode quantified 
java code seen limit exploitable parallelism aggressive instruction issue seen efficient specjvm benchmarks comparison spec programs 
kernel mode execution exhibit ilp user mode 
research supported part national science foundation eia ccr ccr career award mip state texas atp sun microsystems dell intel microsoft ibm 
pond lab department computer science engineering pennsylvania state university university park pa vijay anand cse psu edu 
java offers write run promise helps develop portable software standardized interfaces spanning spectrum hardware platforms 
java virtual machine jvm cornerstone technology efficiency executing portable java bytecodes crucial success widespread adoption java 
step building efficient jvm understand interaction underlying system hardware operating system identify bottlenecks 
study provide information optimize systems software architectural support enhancing performance jvm 
addition closer look execution profile jvm give revealing insights help restructure implementation 
knowledge existing studies confined examining jvm profiles architectural perspective attempt understanding influence operating system activities 
increasingly clear accurate performance analysis requires examination complete system architecture operating system behavior 
adhering philosophy presents results depth look complete system profiling specjvm benchmarks focusing operating system activity 
different jvm implementation styles focuses popular techniques interpretation just time jit compilation 
interpretation portable java byte codes approach easiest implement 
contrast jit compilers represent state art translate byte codes machine native code runtime sophisticated techniques direct execution 
jit compilers known outperform interpreters important understand performance interpretation process popular paradigm java execution integral part sophisticated jit compilers 
interpreters need lower amount memory jit compiler counterparts important resource constrained environments hand held devices 
complete system simulation study workloads context java programs jvm implementations 
jvm environment significantly different required support traditional fortran code 
major differences due object oriented execution frequent virtual method calls dynamic binding dynamic object allocation garbage collection dynamic linking loading classes program level multithreading consequent synchronization overheads software interpretation dynamic compilation byte codes 
differences affect behavior operating system kernel different manner conventional applications 
instance dynamic linking loading classes result higher file activities dynamic object allocation garbage collection require memory management operations 
similarly multithreading influence synchronization behavior kernel 
detailed profile interaction hardware operating system help understand intricacies jvm restructured better performance 
profiles useful architectural operating systems perspective identify enhancements boosting java performance 
example opt provide multi ported cache memory bandwidth related stall cycles major impediment increasing instruction level parallelism 
goal studying profiling complete system architecture operating system behavior executing java programs specifically attempts answer questions time spent user kernel modes 
kernel activities exercised execution overhead incurred activities 
java studies os activity representative aggregate java execution behavior 
time spent executing instructions useful opposed spent stalls synchronization idling 
profiles different jit compilation interpreter modes 
attribute kernel activities specific phases class loading garbage collection jvm execution 
kernel user parts jvm execution suited underlying parallelism modern microprocessors 
characteristics portions influencing instruction level parallelism ilp exploit 
ideal speedup get portions 
set answer questions specjvm benchmarks simos complete system simulator 
find kernel activities insignificant studied spec benchmarks 
average specjvm workloads spend execution time kernel contrasting kernel time studied spec benchmarks 
kernel time spent tlb handling significant fraction due java specific features jit compiler mode 
architectural improvements notable gain achieved ported cache 
find dynamic scheduling wide issue retirement effective specjvm codes due inherent ilp limitations java code 
rest organized follows 
section gives overview experimental platform workloads 
section presents execution time detailed statistics user kernel activities workloads 
section explores ilp issues 
section summarizes contributions implications identifies directions research 

experimental methodology experimental platform perform study simos complete simulation environment models hardware components detail boot run commercial operating system 
study simos version runs silicon graphics irix operating system 
interpreter jit compiler versions java development kit sun microsystems simulated top irix operating system 
studies programs specjvm suite see table set programs intended evaluate performance combined hardware cpu cache memory platform specific performance software aspects efficiency jvm jit compiler os implementations jvm client platform 
specjvm uses common computing features integer floating point operations library calls include awt window networking graphics 
benchmark run different input sizes referred observed data sizes scale linearly naming suggests 
table 
specjvm workloads benchmarks description compress modified lempel ziv method lzw compress decompress large file jess java expert shell system nasa clips expert system db performs multiple database functions memory resident database javac jdk java compiler compiling lines code mpegaudio decoder decompress mpeg audio file mtrt jack dual threaded raytracer parser generator lexical analysis early version javacc simos includes multiple processor simulators embra mipsy mxs model cpu different levels detail 
fastest cpu simulator embra boot os perform initialization mipsy mxs detailed cpu models simos conduct performance measurements 
large complex workloads booting initialization phase may cause execution tens billions instructions 
simos checkpointing ability allows hardware execution status contents register file main memory devices saved set files dubbed checkpoint simulation may resume checkpoint 
feature allows conduct multiple runs identical initial status 
ensure simos accurately simulates complete execution workload write annotations allow simos automatically invoke studied workload checkpoint restored exit simulation soon execution completes os prompt returned 
techniques avoid need interactive input control simulation begins completes run complete accurate comparable 
performance results study generated mipsy mxs detailed cpu models simos 
mipsy models simple single issue pipelined processor cycle result latency cycle repeat rate 
mipsy effective model perspective detailed processor performance investigations provide valuable information tlb activities instruction counts detailed memory system behavior 
mipsy generate basic characterization knowledge memory system behavior studied workloads 
performance evaluation microarchitecture level optimizations done mxs models superscalar microprocessor multiple instruction issue register renaming dynamic scheduling speculative execution precise exceptions 
baseline architectural model issue superscalar processor mips instruction latencies 
mips processor model entry instruction window entry reorder buffer entry load store buffer 
additionally functional units handle type instructions 
branch prediction implemented entry table bit saturating counter predictors 
default branch prediction algorithm allows fetch unit fetch unresolved branches 
memory subsystem consists split instruction data cache unified cache main memory 
processor mips tlb base page size kb 
instruction cache kb cache line size bytes 
data cache kb byte lines 
cache mb byte lines 
hit cache serviced cycle hit cache serviced cycles 
caches way associative lru replacement write back write allocation policies status handling registers mshr 
main memory consists mb dram cycle access time 
simulated machine includes validated hp disk model single console de vice 
described architecture simulated cycle cycle 
instruction data accesses applications operating system modeled 

execution profile specjvm workloads jit compiler dataset execution time workload separated time spent user kernel idle idle modes simos mipsy cpu model 
user kernel modes subdivided instruction execution user instr kernel instr memory stall user stall kernel stall synchronization kernel sync kernel mode 
jvm specjvm ported simos straightforward manner simos environment allows binary compatible irix operating system 
able investigate complete executions real world workloads due reason 
order validate experimental environment early stages study worked pmake splash spec benchmarks compared experimental results published 
results validated switched specjvm suite 

kernel activity specjvm execution profile jit compiler interpreter shows execution time profile specjvm benchmarks jit compiler mode execution 
measured period includes time loading program verifying class files compiling fly jit compiler executing native instruction stream simulated hardware 
profile terms time spent executing user instructions stalls incurred execution instructions due memory pipeline stalls time spent kernel instructions stalls due kernel instructions synchronization operations kernel remaining idle times 
applications compress jack javac iterate multiple times input contributes repetitive shape graphs 
table summarizes breakdown execution time spent kernel user idle specjvm benchmark 
kernel activity seen constitute mpegaudio intr jack jit execution time 
average specjvm programs spend jit intr execution time kernel contrasting specint benchmarks 
fact implies ignoring kernel instructions specjvm workloads study may represent complete accurate execution behavior 
table 
execution time percentages dataset jit compiler interpreter benchmarks comp jess db javac mpeg mtrt jack user user inst 
user stall kernel kernel inst 
kernel stall kernel sync 
idle tables break kernel activities specific services 
tables give number invocation services number cycles spent executing routine average break cycles actual instruction execution stalls synchronization 
memory cycles instruction mcpi executing services breakdown instruction data portions 
read write kernel may involve disk accesses subsequent copying data file caches user data struc tures 
noted time spent disk accesses accounted read write kernel calls idle times execution profile process blocked activity 
read write overheads mainly due memory copy operations 
execution profile graphs see bulk time spent executing user instructions 
particularly true mpeg spends execution user instructions interpreter profile graphs interpreter omitted lack space jit compiler modes 
mpeg benchmark decompresses audio files mpeg layer audio specification 
read needed load audio files subsequent executions entirely user operations 
operations mainly compute intensive substantial spatial temporal locality seen significantly lower user stalls compared applications table 
locality results high tlb hit rates making tlb handler utlb invocation infrequent 
reason percentage kernel time spent utlb lower execution modes compared applications see tables 
result service routines clock read constitute reasonable fraction kernel execution time 
user execution constitutes time compress observe spikes kernel activity execution 
benchmark reads tar files compresses 
operations followed decompression compressed files 
spikes introduced file activities attributed application loading tar files jvm characteristics 
time spent spikes read memory stalls particularly reading data file buffers 
reflected higher mcpi compared mcpi read routine tables 
kernel routines demand zero initialize new pages allocation process clock interrupt clock routines contribute stalls 
despite spikes activity constitutes kernel execution time 
addition spikes see relatively uniform presence kernel instructions course execution 
evident tables due handling tlb misses 
user mode jit compiler find time spent stalls 
jit compiler generates installs code dynamically execution resulting bursty writes memory leading increased memory stalls jit mode 
general relatively flat kernel activity lower portion mainly due tlb handling spikes attributed services read particular 
kernel activity mtrt jess dominated tlb handling small part spent read initial class loading 
hand read component jack kernel execution time stalls component showing execution profile graphs 
tlb handling constitutes major portion 
benchmark jack performs iterations building live heap structure collapsing repeatedly generating parser input 
behavior explains repeated pattern observed kernel activity 
tlb handling overhead javac uniform applications 
application java compiler compiles code jess benchmark repeatedly times 
observe non uniformity user stalls top portion profile 
attributed code installation spikes code generation compiler application 
similar reason differences stall behaviors jit compiler interpreter mode compress 
code installation worsens locality application resulting higher tlb misses phases 
shows memory stall time expressed memory stall time instruction mcpi 
stall time shown separately kernel user modes decomposed instruction data stalls 
stalls shown occurring due caches 
jit compiler interpreter modes execution observed kernel routines experience higher mcpi user code indicating worse memory system behavior kernel 
example mpeg mcpi kernel compared negligible mcpi user mode touches number different kernel routines see tables data structures 
fortunately kernel portion forms maximum execution time specjvm benchmarks mitigates impact mcpi 
observed mcpi user mode interpreter mode compared jit mode 
bursty writes dynamic compilation additional instructions executed interpreting bytecodes result behavior 
observed stalls due data significant due instruction accesses 
mcpi due cache accesses quite small compress mpeg workloads exhibit significant data locality 
specjvm benchmarks benefit stall reduction techniques employed cache 
table 
os kernel characterization specjvm workloads jit compiler dataset utlb fault reloads tlb user addresses 
demand zero block clear operation occurs operating system allocates page data 
page zeroed 
read system calls responsible transferring data kernel address space application address space 
clock clock interrupt page fault handler respectively 
benchmarks service kernel num 
cycles exec stall sync mcpi mcpi mcpi compress jess db javac mpeg mtrt jack utlb read clock demand zero utlb clock read utlb clock read utlb dbl fault clock read utlb clock read demand zero bsd open fork utlb clock read utlb read bsd clock memory cycles instruction mcpi jess jess db db javac javac mpeg mpeg mtrt mtrt jack jack memory cycles instruction mcpi jit intr 
memory stall time kernel user modes jit intr dataset jess jess db db javac javac mpeg mpeg mtrt mtrt jack jack table 
os kernel characterization specjvm workloads interpreter dataset benchmarks service kernel num 
cycles exec stall sync mcpi mcpi mcpi compress jess db javac mpeg mtrt jack utlb clock read demand zero utlb clock read utlb clock utlb clock dbl fault clock utlb read fork demand zero utlb clock read demand zero utlb read bsd clock differences jvm execution styles dataset sizes general observations regardless jvm execution style 
identify differences behavior interpreters jit compilers 
general looking table ratio time spent executing instructions time spent stalls user mode lower jit compiler compared interpreter mode 
behavior due code installation jit compiler increases stall times due better data instruction locality interpreter loop compared native code execution 
important difference modes shown 
observe applications tlb rate higher jit compiler 
previous observation table better locality interpreter loop translates higher tlb hit rate compared jit compiler 
tlb rates db jack lower jit compiler appears somewhat counter intuitive 
detailed investigation interpreter behavior codes leads reasoning 
benchmark db methods unique methods called times execute repeatedly accessing data items random perform database transac tions 
modes locality data items relatively poor 
poor data locality interferes access locality bytecode stream interpreter mode bytecodes treated data interpreter loop 
method reuse bytecode stream high db effect amplified resulting higher tlb rate interpreter mode 
executing jack significant amount time spent user kernel stalls reading files execution 
difference tlb behavior style execution 
differences tlb rate automatically translate differences percentage kernel execution times modes shown table particularly applications tlb handling kernel services 
observations data set specjvm suite 
conducted similar study data sets 
table shows kernel activities applications data set 
interesting observation fact idle times due file reads seen smaller data sets 
mentioned earlier idle times due disk activity operation misses file cache 
larger data set operates set files blocks smaller data set longer execution time difficult give prominence idle times 
applications operation invoked repeatedly files blocks leading higher hit percentage file cache data sets 
result observed percentage kernel time spent read call goes smaller data sets 
tlb misses second tlb misses microsecond bench marks jit intr jit intr jit intr jit compress jess db javac mpeg mtrt jack intr jit intr jit intr jit intr 
tlb misses behavior specjvm benchmarks table 
execution time breakdown jit input user user inst 
user stall kernel tlb tlb kernel inst 
kernel stall kernel sync 
comp jess db javac mpeg mtrt jack tlb activity different parts jvm tlb handler contributes kernel activity jvm execution modes investigated tlb characteristics detail analyze causes tlb misses 
tlb misses see table occurred jvm execution executing user code split occurred class loading garbage collection dynamic compilation jit mode 
misses unified tlb split resulting instruction data accesses 
results section performed data set due time consuming nature selective profiling 
believe tlb behavior parts jvm due java unique characteristics hold data set 
percentage contribution tlb misses due dynamic compilation loading decrease increased method reuse data set 
key observations study summarized tlb rate due data accesses higher due instruction accesses execution modes 
suggests instruction access locality better data ac idle cesses consistent cache locality behavior exhibited specjvm benchmarks 
observed behavior true different parts jvm execution studied 
particular behavior accentuated garbage collection phase data rate order magnitude instruction rate 
due garbage collection objects scattered heap space relatively small code sequence 
tlb locality better interpreter mode compared jit mode instruction data accesses 
reasons behavior higher rate dynamic compilation due instruction data accesses compared tlb rate jit compiler mode 
example rate due instruction data accesses dynamic compilation db compared tlb rate 
observed relative tlb rates db interpreter jit compiler mode data set different data set due reduced method reuse 
main reason poor tlb locality dynamic compilation due drastic change working set jvm 
code data structures associated dynamic compiler quite different rest jvm execution 
dynamic compilation incurs tlb misses codes installed new locations time 
reason better performance interpreter due better locality interpreter loop 
generally tlb rates data accesses higher rates instrumented parts jvm modes 
particular tlb data rates highest garbage collection 
frequent garbage collectors memory constrained systems impact jvm performance significantly 
jit mode tlb instruction rate dynamic loading typically instruction rate 
interpreter loading instruction rate higher general instruction rate 
behavior due increased instruction locality interpreter change behavior loading routine 
comparison specint behavior set study kernel activity specjvm benchmarks different traditional applications 
shows frequently kernel routines benchmarks specint suite 
percentage kernel execution time utlb clock demand zero clock utlb demand zero write fork du poll write clock du poll demand zero intr utlb read fork compress ksim ijpeg perl clock write du poll fork intr execve cow fault 
kernel routines distribution specint benchmarks observed tlb handler constituted major part kernel activity specjvm benchmarks quite insignificant ijpeg perl benchmark 
observed earlier features java class loading garbage collection dynamic loading affect tlb application exhibits tlb locality 
application behavior plays important role kernel activity 
example utlb activity contributes kernel activity executing compress kernel activity jit mode executing compress specjvm suite 
compress compress implement essentially algorithm differences data sets 
differences dy namic class loading behavior compress result higher kernel activity read routine 
find specjvm benchmarks spend execution time average kernel contrast specint benchmarks spend execution kernel 
table 
instruction data misses fully associative entry unified tlb lru replacement policy dataset tlb misses occur jvm execution dataset split due data accesses data instruction accesses inst 
decompose tlb misses part jvm executed class loading garbage collection dynamic compilation 
row benchmark execution mode gives number tlb misses part second row gives rate part jvm num number misses ratio 
total loading gc compilation total benchmarks inst data inst data inst data inst data inst data number comp jess db javac mpeg mtrt jack jit intr jit intr jit intr jit intr jit intr jit intr jit intr num 
num 
num 
num 
num 
num 
num 
num 
num 
num 
num 
num 
num 
num 

instruction level parallelism java workloads section analyzes impact instruction level parallelism ilp techniques specjvm suite executing complete workload detailed superscalar cpu simulator mxs 
effectiveness microarchitectural features wide issuing retirement multi ported cache studied 
additionally investigate bounds available parallelism java workloads studying nature dependencies instructions computing program parallelism 
due large slowdown mxs cpu simulator reduced data size data input section 
just model instruction data accesses application os 
effectiveness aggressive ilp architectures illustrates kernel user aggregate execution speedup single pipelined sp issue superscalar ss issue superscalar microprocessor normalized corresponding execution time sp system 
issue ss simulates machine model described section 
ss uses aggressive hardware exploit ilp 
instruction window reorder buffer hold instructions load store queue hold instructions branch prediction table entries 
furthermore caches support cache accesses cycle 
focus study performance cpu differences memory subsystem 
shows microarchitectural techniques exploit ilp reduce execution time specjvm workloads issue ss 
total ilp speedup jit mode shows wide variation jess mtrt 
average ilp speedup original applications user kernel integrated 
see kernel speedup average ilp processor somewhat lower speedup user code average 
issue width increased observe factor performance improvement specjvm applications 
compared specint specfp performance gains obtained wider issuing retirement results suggest aggressive ilp techniques efficient specjvm applications workloads spec 
features specjvm workloads help explain poor speedup stack isa results tight dependencies instructions 
execution spec java workloads involve jit compiler runtime libraries os tends contain indirect branches runtime library routines os calls exceptions 
benchmark db significant idle component data set causes aggregate ipc low kernel user code individually exploit reasonable ilp 
ipc ilp speedup ilp speedup kernel user sp issue ss issue ss jess db javac mtrt jack jess db javac mtrt jack jess db javac mtrt jack sp simple pipelined ss superscalar compress jess db javac mpeg mtrt jack 
ilp speedup jit ipc compress jess db javac mpeg mtrt jack issue issue 
ipc breakdown issue issue superscalar processors total kernel user dataset jit compiler breakdown ipc cycles gone 
give detailed insight breakdown ideal ipc actual ipc achieved ipc lost instruction data cache stall ipc lost pipeline stall 
classification techniques described attribute graduation unit stall time different categories data cache stall happens graduation unit stalled load store outstanding data cache 
entire instruction window empty fetch unit stalled instruction cache instruction cache stall recorded 
stalls normally caused pipeline dependencies attributed pipeline stall 
shows breakdown ipcs issue issue superscalar processors 
issue superscalar microprocessor see jess db javac jack lost ipc instruction cache stall 
partially due high indirect branch frequency tends interrupt control flow 
programs contain indirect branches 
studied applications show ipc loss data cache stall 
data cache stall time includes misses bytecodes compilation jit compiler actual execution compiled code data set 
shows significant amount ipc lost due pipeline stalls ipc loss pipeline stall issue processor significant issue processor 
fact implies aggressive complex ilp hardware may achieve desired performance gains specjvm due cache stall cache stall pipeline stall actual ipc total inherent ilp limitation applications 
applications show limited increase instruction cache ipc stall data cache ipc stall issue processor 
impact multi ported cache speculative dynamically scheduled microprocessors require high instruction data memory bandwidth 
viable solution employ multiple cache ports accessed simultaneously processor load store unit 
section characterizes performance benefits multi ported cache specjvm applications 
performance kb multi ported cache benchmark user kernel mode jit shown 
user mode increasing number cache ports shows improvement performance compress mpeg improvement javac jack improvement jess db mtrt 
average performance improvement approximately equivalent number specint reported 
average performance improvement increase cache ports respectively 
kernel mode observe notable ipc speedup increasing cache ports 
average additional improvement performance cache ports respectively 
results suggest dynamic superscalar processor port cache cost effective specjvm workloads 
impact multiple cache ports java user code different specint applications studied worth noting kernel code benefits ports cache user code 
ipc ipc impact multi ported cache user port ports ports ports db javac mpeg mtrt jack specjvm benchmarks impact multi ported cache kernel port ports ports ports db javac mpeg mtrt jack specjvm benchmarks 
impact multi ported cache jit compiler dataset limits available parallelism order understand instruction level parallelism issues involving stack oriented java code investigated limits available parallelism java workloads 
compare ilp java benchmarks specint applications programs 
focused logical limits implementation issues assume ideal machine infinite machine level parallelism mlp 
mlp defined maximum number instructions machine capable scheduling single cycle 
dynamic dependence analysis order compute limits ilp previous parallelism investigations 
construct dynamic dependency graph ddg partially ordered directed acyclic graph representing execution program particular input 
executed operations comprise nodes graph dependencies realized execution form edges graph 
edges ddg force specific order execution dependent operations forming complete ddg weak ordering program required operations 
ddg contains data dependencies constrained resource control limitations called dynamic data flow graph 
lacks total order execution serial stream remains weakest partial order successfully perform computations required algorithms 
machine constructed optimally execute ddg performance represent upper bound performance attainable program 
study critical path length defined height scheduled ddg absolute minimum number steps required evaluate operations scheduled ddg determined 
available parallelism computed dividing total number nodes critical path length 
give upper bound available parallelism available machine level parallelism mlp infinity considered mlp studied comparative purposes see table 
consider true dependencies raw dependencies scheduling instructions absolute limit parallelism potentially exploited program best renaming latency operations set cycle 
perfect memory disambiguation perfect branch prediction assumed 
details experiments 
study specjvm benchmarks invoked interpreter 
table shows java code exhibits low ilp comparison workloads analyzed 
average available parallelism terms harmonic mean observations different suites programs different window sizes summarized 
table 
available instruction level parallelism different benchmarks specjvm benchmarks invoked interpreter available ilp spec int spec jvm dsp benchmarks mlp mlp mlp mlp mlp mlp compress gcc go li ksim ijpeg deltablue eqn idl richards db javac jess mpeg mtrt compress dot fir audio adpcm infinite mlp mean ilp specint benchmarks programs java programs dsp benchmarks 
extremely low ilp java programs control machine constraints attributed stack implementation java virtual machine jvm 
stack nature jvm imposes strict ordering execution bytecodes 
observation supported behavior compress benchmark specint specjvm suites 
text compression programs java version java port integer benchmark 
seen mlp infinity cpu compress benchmark highest ilp specint benchmarks java compress program ilp specjvm benchmarks 
infinity available ilp specint specjvm dsp mlp infinity 
average available parallelism specint specjvm dsp benchmarks different mlp 
popularity wide spread adoption java necessitated development efficient java virtual machine 
study provided insights interaction jvm implementations underlying system hardware operating system 
knowledge characterize kernel activity java applications analyze influence architectural enhancements 
major findings research kernel activity specjvm applications constitutes execution time large data set small data set 
average kernel activity case approximately comparison specint benchmarks studied 
generally jit compiler mode consumes larger portion kernel services execution 
exception db data set high method reuse interference bytecode data locality interpreter mode 
specjvm benchmarks spend time executing instructions user mode spend time stall cycles user execution 
kernel stall mode specjvm benchmarks jack significantly higher file activity small 
mcpi kernel execution higher user mode 
kernel activity specjvm benchmarks mainly due invocation tlb handler routine utlb read service routine 
particular utlb routine consumes kernel activity specjvm benchmarks dataset 
dynamic compilation garbage collection class loading phases jvm execution utilize utlb routine faster rate exhibit higher tlb rate rest jvm 
observed dynamic class loading behavior influences kernel activity significantly smaller datasets increases contribution read service routine 
average ilp speedup issue superscalar processor specjvm benchmarks executed jit compiler mode times 
speedup kernel routines average times lower speedup user code average times 
behavior attributed significant fraction kernel activity spent utlb routine highly optimized sequence interdependent instructions 
aggressive ilp techniques wider issue retirement effective specjvm benchmarks spec 
observe performance improvement specjvm moving issue issue width times com pared times times performance gains achieved specint specfp benchmarks respectively 
pipeline stalls due dependencies major impediment achieving higher speedup increase ilp issue width 
specjvm workloads involve dynamic compiler runtime libraries os tend contain indirect branches runtime library routines os services 
indirect branches constitute dynamic branches specjvm suite tend increase instruction cache stall times 
specjvm benchmarks inherently poor ilp compared classes benchmarks 
ideal machine infinite machine level parallelism mean ilp approximately java programs interpreted mode compared speedup specint dsp benchmark suites 
results help providing insight designing systems software architectural support enhancing performance jvm 
example single address virtual space eliminate tlb activity critical path cache access may useful jvm implementations 
utlb handler forms major part specjvm kernel activity moving tlb access cache help reduce kernel activity 
addition closer look results help restructure jvm implementation 
example high tlb rates occur collecting garbage reduced collecting objects page wise 
simple modification depth search breadth search objects mark phase garbage collection algorithm may help improve 
key efficient java virtual machine implementation synergy designed software jvm system software support supportive architecture efficient runtime libraries 
looked kernel activities specjvm benchmarks plan characterize java applications particularly garbage collection network communication multi threading operations 

hsieh conte johnson gyllenhaal hwu study cache branch performance issues running java current hardware platforms proceedings compcon pages 
radhakrishnan vijaykrishnan john architectural issue java runtime systems proceedings th international conference high performance computer architecture pages 
vijaykrishnan ranganathan object oriented architectural support java processor proceedings th european conference object oriented programming pages 
vijaykrishnan ranganathan tuning branch predictors support virtual method invocation java proceedings th usenix conference object oriented technologies systems pages 
bellotti ultrasparc instruction level characterization java virtual machine workload nd annual workshop workload characterization workload characterization computer system design kluwer academic publishers pages 

kim hsu analyzing memory traces java programs nd annual workshop workload characterization workload characterization computer system design kluwer academic publishers pages 
connor tremblay java virtual machine hardware ieee micro pages mar 
radhakrishnan rubio john characterization java applications bytecode ultra sparc machine code levels proceedings ieee international conference computer design pages 
gharachorloo bugnion memory system characterization commercial workloads proceedings th annual international symposium computer architecture pages 
herrod complete machine simulation understand computer system behavior ph thesis stanford university feb 
rosenblum herrod witchel gupta complete computer system simulation simos approach ieee parallel distributed technology systems applications vol pages winter 
rosenblum bugnion herrod witchel gupta impact architectural trends operating system performance proceedings th acm symposium operating system principles pages 

hsieh gyllenhaal hwu java bytecode native code translation caffeine prototype preliminary results proceedings th international symposium microarchitecture pages 
cramer friedman miller wilson wolczko compiling java just time ieee micro vol 
pages may 
krall efficient just time compilation proceedings international conference parallel architectures compilation techniques pages 
adl tabatabai cierniak fast effective code generation just time java compiler proceedings conference programming language design implementation pages 
connor direct execution engine java bytecode ieee computer pages oct 
vijaykrishnan issues design java processor architecture 
phd thesis college engineering university south florida july 
trick george gyllenhaal hwu hardware driven profiling scheme identifying program hot spots support runtime optimization proceedings th annual international symposium computer architecture pages 
spec jvm benchmarks www spec org osg jvm spec cpu benchmarks www spec org osg cpu herrod rosenblum bugnion devine bosch chapin witchel verghese simos user guide simos stanford edu overview java platform product family www javasoft com products ov html witchel rosenblum embra fast flexible machine simulation proceedings acm sigmetrics conference measurement modeling computer systems 
bennett flynn performance factors superscalar processors technical report csl tr computer systems laboratory stanford university feb 
mips technologies incorporated microprocessor product overview mips open risc technology oct 
mips ieee micro vol pages apr 
farkas jouppi complexity performance tradeoffs non blocking loads proceedings th international symposium computer architecture pages 
olukotun hammond wilson 
chang case single chip multiprocessor proceedings th international conference architectural support programming languages operating systems pages 
hammond olukotun evaluation design alternatives multiprocessor microprocessor proceedings rd international symposium computer architecture pages 
tao li complete system simulation characterize execution behaviors specjvm benchmarks www ece utexas edu tli tao jvm ps austin sohi dynamic dependency analysis ordinary programs proceedings th annual international symposium computer architecture pages 
franklin available parallelism data value prediction proceedings international conference high performance computing pages 
study instruction level parallelism contemporary computer applications master report university texas austin dec 
lzle study allocation behavior specjvm java benchmarks proceedings th european conference object oriented programming springer verlag 
wilson olukotun rosenblum increasing cache port efficiency dynamic superscalar microprocessors proceedings rd international symposium computer architecture pages 
