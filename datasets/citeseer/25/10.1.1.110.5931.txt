model head pose tracking yang university north carolina chapel hill north carolina usa email cs unc edu robust model stereo head tracking algorithm operates real time commodity pc 
individualized dimensional head model coupled epipolar constraint stereo image pair greatly improves robustness tracking 
experimental results shown method able track degrees freedom rigid part head motions extended period time presence large angular translational head motions partial occlusions dramatic facial expression changes 
applications include human computer interaction eye gaze correction video conferencing 
motivated desire establish eye contact video conferencing desktops 
plan attack track head pose intelligently warp face image generate virtual view preserves eye contact 
successful tracking able track degrees freedom accurately eliminates real time tracking methods simplistic schemes color histogram ellipsoidal fitting operates real time places considerable constraints type processing performed 
approach reconciling seemingly incompatible requirements incorporate detailed individualized threedimensional head model stereoscopic analysis 
detailed dimensional head model provides tracker rich geometric knowledge subject able track head pose feature points label tracked feature semantic meaning 
semantic information allows deal gracefully occlusions facial deformations 
hand stereoscopic analysis provides important epipolar constraint 
applying constraint stereo image pair easily reject outliers false matches monocular tracking mainly conducted author microsoft research summer intern 
zhengyou zhang microsoft research redmond wa usa email zhang microsoft com avoiding robust estimation techniques tend time consuming 
furthermore demonstrated experimental section extra camera dramatically improves tracking accuracy simplifies tracking algorithm 
recognize tradeoff equipment requirement tracking accuracy 
today wide availability inexpensive video cameras increasingly better support streaming video os level believe system cameras justified 
related works wide variety related head tracking 
virtually face tracking takes advantage constrained scenario generic tracking framework views observed face arbitrarily object model approach favored incorporates knowledge facial deformations motions appearance 
tracking techniques classify previous works categories optical flow black yacoob developed regularized optical flow method head motion tracked interpretation optical flow terms planar dimensional patch 
basu generalized approach interpreting optical flow field model avoid singularities model 
better results obtained large angular translational motions 
tracking results accurate reported angular errors high degrees 
decarlo metaxas optical flow hard constraint deformable detailed model 
approach produced excellent results 
heavy processing frame realtime implementation difficult 
flow methods include 
features templates pentland recursive estimation method tracking small facial features corners eyes mouth extended kalman filter framework 
fast method estimate head pose tracking salient facial points eye corners nose top 
template methods include darrell tian 
template methods usually limitation points visible entire image sequence limiting range head motions track 
skin color yang techniques tracking human faces adaptive stochastic model human skin color 
approach general fast 
drawback usually accurate sufficient applications 
newman related falls features templates category 
uses stereo vision system configuration different vertical setup higher disambiguation power feature matching 
tracking technique different 
take snapshots frontal left right reconstruct features selected face 
points templates extracted corresponding snapshots feature face tracking 
case detailed face model features selected runtime making system robust lighting change occlusion varying facial expression 
system overview face modeler camera calibration feature tracker feature tracker estimate pose auto recovery add features 
model stereo tracking system illustrates block diagram tracking system 
images captured stereo camera pair 
experimental setup digital video cameras mounted vertically top bottom display screen 
connected pc links 
calibrate cameras method :10.1.1.145.7481
choose vertical setup provides higher disambiguation power feature matching 
matching ambiguity usually involves facial features eyes lip contours aligned horizontally 
user personalized face model acquired rapid face modeling tool 
calibration model acquisition require little human interaction novice user complete tasks minutes 
furthermore need done user fixed setup 
entire tracking process automatic initialization requires user select landmark features pair frames 
subject required remain relative maintain neutral expres sion 
marked features face model registered images 
system tracks optical flow salient features rejects outliers epipolar constraint updates head pose frame basis 
feedback loop supplies fresh salient feature points frame tracking stable various conditions 
furthermore automatic tracking recovery mechanism implemented system robust extended period time 
stereo head pose tracking provide details tracking system 
models face model triangular mesh consisting approximately triangles 
vertex mesh semantic information eye chin build personalized face model user rapid face modeling tool developed liu 
shows sample face model note face model contains properties textures geometric semantic information tracking system 

sample face model 
wireframe right reveals artificial eyes month tracking system 
camera modeled pinhole intrinsic parameters captured matrix 
intrinsic matrices stereo pair denoted respectively 
loss generality camera camera coordinate system world coordinate system 
second camera camera coordinate system related rigid transformation 
point space projected image planes stereo cameras image coordinates second camera projection function uvw method determine :10.1.1.145.7481
face model described local coordinate system 
goal tracking system determine system try model ears back head 
rigid motion head head pose world coordinate system 
head pose represented rotation matrix translation vector rotation degrees freedom head pose requires parameters 
stereo tracking stereo head tracking problem formally stated follows pair stereo images time sets matched points image pair corresponding model points pair stereo images time determine subset corresponding matches denoted ini ii head pose projections show schematic diagram tracking procedure 
camera camera frame tracked features frame updated features frame features comply ec frame epipolar constraint ec frame corresponding model points feature tracking ready matched model points update head pose tracked features frame generate new features feature tracking updated features frame features comply ec frame ready time 
model stereo head tracking conduct independent feature tracking camera time 
klt tracker works quite :10.1.1.135.7147
matched points may drifted wrong 
apply epipolar constraint remove stray points 
epipolar constraint states point expressed homogeneous coordinates image point second image correspond point physical world satisfy equation fp fundamental matrix encodes epipolar geometry images 
fact fp defines epipolar line second image equation means point pass epipolar line fp vice versa 
practice due inaccuracy camera calibration feature localization expect epipolar constraint satisfied exactly 
triplet distance epipolar line greater certain threshold triplet considered outlier discarded 
distance threshold pixels experiments 
removed stray points violates epipolar constraint update head pose re projection error minimized 
re projection error defined rmi rmi solve levenberg marquardt algorithm head pose time initial guess 
feature regeneration head pose determined replenish matched set adding feature points 
select feature point criteria texture feature point images rich texture information facilitate tracking 
select points image criteria back project back face model get corresponding model points 
visibility feature point visible images 
implemented intersection routine returns visible triangle image point 
feature point visible intersection routine returns triangle projections images 
rigidity careful add feature points non rigid regions face month region 
define bounding box tip nose covers forehead eyes nose cheek region 
points outside bounding box added feature set 
fundamental matrix related camera parameters regeneration scheme improves tracking system ways 
features points lost due occlusions non rigid motion tracker sufficient number features start frame 
improves accuracy stability 
secondly alleviates problem tracker drifting adding fresh features frame 
tracker initialization auto recovery tracker needs know head pose time start tracking 
user interactively select landmark points image initial head pose determined 
show example selected feature points epipolar lines second image drawn 
manual selection accurate 
automatically refine selection locally satisfy epipolar constraint 
initial selection tracking recovery tracker loses tracking 
may happen user moves camera field view rotates head away cameras 
turns back cameras prefer continue tracking minimum human intervention 
tracker recovery process initial set landmark points templates find best match current image 
match high confidence value tracker continues normal tracking 

manually selected feature points epipolar lines overlayed nd image 
furthermore activate auto recovery process current head pose close initial head pose 
alleviates tracker drifting problem accumulative error reduced tracker recovery 
scheme extended include multiple templates different head poses 
expected improve robustness system 
experiment results implemented tracking algorithm ms windows environment tested live real data 
current implementation runs real time fps pc ghz pentium cpu 
results test sequences collected resolution frame second 
sequences captured pair inexpensive web cameras captured pair sony digital video camera 
sony camera produces better images low lighting conditions 
bright light image qual ity web cameras comparable sony camera 
shot relatively bright lighting 
consequently noticeable difference tracking quality sequences 
figures shows results sequence 
face mesh projected estimated head pose overlayed input stereo images 
sequence contains large head rotations close degrees 
type plane rotation usually difficult head tracking see algorithm determines accurately head pose mesh model 
second sequence shown contains predominantly non rigid motion dramatic facial expressions 
show original images better appreciate non rigid motion 
classify face rigid non rigid areas features rigid areas tracker insensitive non rigid motion 
shows sequence large occlusions plane head motions frequently appear 
system maintains accurate tracking entire second sequence 
validation purpose comparison implemented model monocular tracking technique 
prevalent methods formulate optimization problem seeks minimize re projection errors projected features points actual tracked features 
notions monocular cost function defined em rmi solve optimization problem levenberg marquardt method 
run monocular tracking algorithm sequences 
know ground truth head motions meaningless compare absolute values algorithms 
compare approximate velocity ti ti head motion expected smooth velocity curve 
plot velocity curves sequences 
axis frame number axis speed inches frame 
velocity curve computed monocular algorithm plotted red stereo blue 
red curves spikes exceed limit normal head motion maximum cap inches frame put plots spikes higher 
suspect indicate tracking lost optimization trapped local minimum 
hand blue curves significant spikes 
spikes blue curves sequence contains abrupt head motions 
visually compare results sequence monocular stereo tracking method 
images selected corresponding spikes red curve sequence top 
stereo tracking result sequence fps 
images camera shown upper row second camera shown lower row 
left right frame numbers 

stereo tracking result sequence fps row shows input images upper camera 
second third rows show projected face model overlayed images upper lower camera respectively 
left right frame numbers 
row shows monocular tracking results second row shows stereo tracking results 
row obviously lost tracking poor accuracy head pose estimation 
point plots show results monocular tracker reported optimization routine failed converge consecutive frames 
hand stereo tracker continued sequence 
rich information stereo cameras enables stereo tracker achieve higher level robustness monocular version 
discussions robust method real time face tracking 
combined detailed head model stereoscopic analysis allows accurate full head pose estimation presence partial occlusions dramatic facial deformations demonstrated real sequences 
furthermore compared method monocular tracking method 
experiment results shown significant improvements robustness accuracy 
places want improve 
way deal facial deformations 
current simple fixed classification rigid non rigid facial regions 
dynamic classification actual facial expression preferred 
looking techniques automatically locating face various feature points integrated initialize tracker entire system interframe velocity interframe velocity interframe velocity 
stereo tracking result sequence fps frame numbers left right top bottom 
monocular tracking stereo tracking frame number monocular tracking stereo tracking frame number monocular tracking stereo tracking frame number 
comparison monocular stereo tracking terms estimated velocity head motion 
results sequence shown top bottom 
fully automatic 
rapidly reduced cost video cameras expect find variety applications multimedia user interfaces video coding 
azarbayejani horowitz pentland 
recursive estimation structure motion relative orientation constraint 
proceedings computer vision pattern recognition conference pages 

visual comparison monocular upper row vs stereo lower row tracking method 
left right frame numbers 
sumit basu irfan essa alex pentland 
motion regularization modelbased head tracking 
proceedings international conference pattern recognition wien austria 
black yacoob 
tracking recognizing rigid non rigid facial motions local parametric model image motion 
proceedings international conference computer vision pages cambridge ma 
choi 
analysis synthesis facial image sequences model image coding 
ieee circuits systems video technology 
darrell moghaddam pentland 
active face tracking pose estimation interactive room 
ieee computer vision pattern recognition pages 
douglas decarlo dimitris metaxas 
optical flow constraints deformable models applications face tracking 
international journal computer vision july 

computing head orientation monocular image 
international conference automatic face gesture recognition pages 
li 
motion estimation modelbased facial image coding 
ieee pattern analysis machine intelligence june 
liu zhang jacobs cohen 
rapid modeling animated faces video 
third international conference visual computing visual pages mexico city september 
available technical report msr tr 
newman matsumoto zelinsky 
real time stereo tracking head pose gaze estimation 
proceedings fourth ieee international conference automatic face gesture recognition fg pages grenoble france 

real time facial analysis synthesis chain 
bichsel editor international workshop automatic face gesture pages zurich switzerland 
shi tomasi 
features track 
ieee conf 
computer vision pattern recognition pages washington june 

tian kanade cohn 
recognizing action units facial expression analysis 
pattern analysis machine intelligence 
yacoob davis 
computing spatio temporal representations human faces 
proceeding cvpr pages 
yang stiefelhagen meier waibel 
real time face facial feature tracking applications 
proceedings pages australia 
yuille cohen 
feature extraction faces deformable templates 
international journal computer vision 
zhengyou zhang :10.1.1.145.7481
flexible new technique camera calibration 
ieee transactions pattern analysis machine intelligence 
