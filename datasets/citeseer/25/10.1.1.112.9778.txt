multiflow trace scheduling compiler geoffrey lowney stefan freudenberger thomas lichtenstein robert nix john donnell john multiflow computer multiflow compiler uses trace scheduling algorithm find exploit instruction level parallelism basic blocks 
compiler generates code vliw computers issue operations cycle maintain operations flight 
multiflow compiler generated code different target machine architectures compiled lines fortran applications systems code 
requirement finding large amounts parallelism ordinary programs trace scheduling algorithm unique features multiflow hardware placed novel demands compiler 
new techniques instruction scheduling register allocation memory bank management intermediate code optimizations developed refinements reduce overhead trace scheduling 
describes multiflow compiler reports multiflow practice experience compiling instruction level parallelism basic blocks 
keywords trace scheduling compiler optimization instruction scheduling register allocation memory analysis vliw performance analysis instruction level parallelism speculative execution 
authors current addresses geoffrey lowney digital equipment swanson rd ma stefan freudenberger hewlett packard laboratories page mill road palo alto ca thomas shaw th floor tower west th street ny ny lichtenstein thinking machines st cambridge ma robert nix digital equipment swanson rd ma john donnell equator technologies th avenue east seattle wa john silicon graphics cherry st ct 
tjs final years declining hardware costs encouraged computer scientists engineers seek increased performance parallelism 
area single cpu performance search yielded high performance computers early performed fly data precedence analysis keep multiple functional units busy 
great interest focused upper limits parallelism existing software 
studies years old confirmed show small benefits available parallelism sought basic blocks 
limitation troublesome scientific programs regularity operation independence intuitively obvious cpu performance critical 
practical technique scheduling individual operations basic blocks known data parallel operations vector instructions added scientific computers 
compiler techniques developed recognizing vector opportunities loop patterns operations 
techniques known vectorization suffered limitations applicability 
fisher described algorithm called trace scheduling proved basis practical generally applicable technique extracting scheduling parallelism basic blocks 
fisher group yale particularly ellis showed large potential speedups parallelism available wider range applications amenable vectorization 
multiflow computer founded build line research develop processors similar envisioned yale research vliw machines execute operations 
overview machines provided detailed discussion see 
multiflow closed doors march 
reports compiler developed multiflow 
multiflow compilers key component computer systems utilize instruction level parallelism larger scale attempted 
parallelism achieved wider range applications vectorization handle 
furthermore parallelism achieved relatively simple hardware complexities attendant identifying scheduling operation ordering handled software hardware simply carries pre determined schedules 
techniques developed multiflow compiler applicable generations risc processors integrate functional units single chip 
trace scheduling overview trace scheduling algorithm permits instruction scheduling basic blocks 
provides framework unified approach scheduling simple loops loops conditionals loop free stretches code 
multiflow demonstrated possible single instruction scheduling strategy yielded benefits complex approaches loop scheduling 
algorithm allows natural separation global local correctness issues 
leads compiler structure closely resembles traditional basic block scheduling compiler addition trace scheduling module 
summary description basic algorithm follows detail 
tjs final load load add store load add store code scheduling basic block boundaries intermediate optimization done operations expanded machine level opcode sequences flow graph operations passed trace scheduler ts 
annotates graph expected execution frequencies 
generated linear combination branch probabilities loop trip counts obtained heuristics measurements prior runs application 
ts enters loop select sequence operations scheduled 
sequence called trace 
traces limited length kinds boundaries significant ones module boundaries entry return loop boundaries trace includes operations loop previously scheduled code 
remove trace flow graph passing instruction scheduler called code generator bulldog 
instruction scheduler returns finished schedule trace place schedule flow graph replacing operations originally trace 
schedule boundaries main entry exit correct logical inconsistencies arise operations moving splits joins 
require generating copies operations scheduled trace see 
loop operations included trace traces replaced schedules 
select best linear order object code emit 
load load load tjs final load load add store load select trace schedule code trace add store load load load replace trace scheduled code analyze state split join points tjs final generate compensation code resolve split join state differences nd trace st trace iterate selecting trace successive priority task instruction scheduler framework follows 
receives trace invocation 
builds data precedence graph dpg represent data precedence constraints execution order adds various heuristic edges dpg constrain schedule 
entire scheduling problem solve incorporated dpg represent single basic block sequence basic blocks complicated conditionals possibly unrolled body loop 
special handling particular kind code effected adding heuristic edges dpg 
tjs final scheduler attempts build fastest possible sequence instructions dpg 
operations frequently moved past splits joins issue greedily speculatively order shorten length expected execution path 
simple picture complicated somewhat register allocation management machine resources multiple execution paths 
issues discussed sections 
outline section overview multiflow trace machines 
section gives history compiler section describes structure 
describe phases compiler front section optimizer section back section 
back detail describe trace scheduler section instruction scheduler section machine model section calling sequence section disambiguator section 
evaluate performance compiler sections close retrospective section 
trace machines basics multiflow computers share set common architectural features 
encode operations single long instruction 
operations risc fixed bit length fixed format register operations memory accessed explicit loads stores 
operations completed single cycle explicitly pipelined pipelines self draining 
machines machine resources 
memory system interleaved 
compiler avoid register conflicts schedule machine resources manage memory system 
series multiflow machines models 
series shipped january 
implemented cmos gate arrays ttl logic cmos floating point chips 
ns cycle time 
series shipped july 
redesign bipolar integrated technologies bit ecl floating point parts 
cycle time remained ns 
series 
ecl semi custom implementation fully designed completely fabricated tested closed march 
targeted ns cycle time 
series come widths wide bit instruction issuing operations wide bit instruction wide bit instruction 
designed wide wide versions 
wider processors organized multiple copies wide functional units call wide group functional units cluster 
focus series 
shows shows 
tjs final pc branch opcode br br br memory mb banks int mem opcode memory mb banks ialu ireg int mem opcode memory mb banks bit instruction word integer opcode memory mb banks multiflow trace integer opcode floating opcode fmul floating opcode fmul tjs final ialu ireg memory mb banks interleaved memory total mb total banks memory mb banks memory mb banks memory mb banks pc memory mb banks memory mb banks memory mb banks memory mb banks multiflow trace memory mb banks interleaved memory total mb total banks memory mb banks memory mb banks memory mb banks series instructions issued ns ns beats instruction 
integer operations issue early late beats instruction floating point operations issue early beat 
integer alu operations complete single beat 
load pipeline beats 
floating point pipelines beats 
branches issue early beat branch target reached instruction effectively beat pipeline 
instruction issue multiple branch operations particular branch taken determined precedence encoded long instruction word 
functional units cluster integer units floating units 
addition cluster contribute branch target 
integer units issue early late beat cluster resources issue operations instruction 
tjs final register files cluster register files 
see 
data going memory moved store file 
branch banks control conditional branches select operation 
register file type number elements size integer floating store integer branch floating branch register files cluster instruction cache holds instructions mb 
data cache 
memory system supports mb physical memory way interleaving 
gb virtual address space 
io processors 
supports mb sec dma channel main memory mb vme busses 
presents basic performance figures series 
mops mflops main memory mb linpack linpack na sustainable ops flight hardware performance trace family shows instructions code extracted inner loop linpack benchmark 
operation listed separate line 
fields identify cluster functional unit perform operation remainder line describes operation 
note destination address qualified register bank name sb alus target register bank machine restrictions 
extra latency reaching remote bank 
instr cl ialu st sb cl ialu cgt li bb cl add lsb cl add lsb cl ialu dld fb cl ialu dld fb cl ialu cgt li bb zero cl add lsb cl add lsb cl ialu st sb cl ialu add lib cl br true cl br false instr cl ialu dld fb tjs final data types cl ialu cgt li bb cl cl cl ialu st sb cl ialu dld fb cl ialu cgt li bb cl cl cl ialu st sb cl ialu bor ib zero cl br false cl br true trace code fragment natural data types machine bit signed unsigned integers bit pointers bit ieee format single precision bit ieee format double precision 
bit integers characters supported extract merge operations bit strings shifts bitwise long integers add carry booleans normalized 
support extended ieee precision denormalized numbers gradual underflow 
accesses memory return bits 
natural alignment required high performance mod bit mod bit 
misaligned supported trap code substantial performance penalty 
memory byte addressed 
byte addresses eases porting programs byte addressed processors vax 
low bits address ignored load store read extract merge operations 
accessing small integers expensive 
load character requires ld ext sequence store requires ld mrg st sequence 
shows schedule generated character copies 
void copy char mark trace instr cl ialu ld ib zero cl ialu sub lib auto size instr cl ialu bor lib zero cl ialu ld ib zero cl ialu add lib instr cl ialu bor lib zero cl ialu add lib instr cl ialu ext lib tjs final cl gc instr cl ialu mrg lsb cl ialu st sb zero instr cl ialu ld ib cl ialu ld ib cl gc instr cl ialu ext lib instr cl ialu mrg lsb cl ialu st sb instr cl ialu add lib auto size return sequence copying characters memory system data paths multiflow trace level interleaved memory hierarchy exposed compiler 
memory go directly main memory data cache 
memory cards contains banks 
bank hold mb total capacity mb 
memory interleaved cards banks 
low byte address determines bank bits ignored bits select card bits select bank 
data returned memory set global busses approximately shown 
busses shared moves data clusters maintain full memory bandwidth number placement data moves carefully planned 
level interleaving potential conflict 
card bus conflict 
single beat distinct cards distinct busses 
conflict card bus result undefined program error 
bank conflicts 
memory bank busy beats time accessed 
touches bank beat window entire machine stalls 
achieve maximum performance compiler schedule successive distinct banks 
generate beat properly scheduled full memory bandwidth machine sustained stalling 
asymmetric perform stores beat compatible loads need paired stores achieve maximum bandwidth 
global resources addition functional units register banks trace machines number global shared resources need managed compiler 
register file write ports 
integer floating register file accept writes beat come local alu 
branch bank accept write beat 
store file accept writes beat 
global busses 
global busses hold distinct bit value beat 
hardware contains routing logic compiler need guarantee number busses beat 
busses come types type separately scheduled 
global control 
set global controller resources control access link registers subroutine calls indirect branches 
detailed presentation trace memory system see 
tjs final integer units integer units execute set traditional risc operations 
number features added support trace scheduling set load opcodes 
opcodes set flag exception handler indicates load operation performed speculatively see 
operations compute booleans invertible 
trace scheduler prefers invertible branches layout trace straight line code inverting branch conditions necessary 
input output select operation provided 
permits short forward branches mapped straight line code 
conditional branch operation sequence 
operation targets branch bank register branch reads register 
conditional branch requires beats branch issue instruction boundary sparse code require 
having separate register files branch units relieves pressure integer register files provides additional operand bandwidth support simultaneous branch operations 
integer alus cluster asymmetric issue memory 
problems instruction scheduler discuss section 
due limits size gate arrays integer alus shared register file 
fact coupled low latency integer operations difficult instruction scheduler exploit parallelism integer code 
cost moving data register files offsets gains parallelism 
shows simple parallel integer sequence slower alus separate register files alu 
single register file parallelism easily exploited 
alu alu alu rf rf rf cmp cmp mov bank cmp mov back multiple register file dilemma floating units floating units series bit ecl floating point parts 
units cluster execute repertoire floating operations 
implements full complement integer operations move select operations compiler 
floating units relatively small register files bit registers file available compiler 
pipelines trace self draining interrupt occurs pipelines drain interrupt serviced 
means operations may complete earlier determined compile time schedule subsequent operation target destination register operation operation completed 
load latency beats floating point latency 
load issue beat flop beat 
distinct destination registers required floating bank keep pipelines full 
leaves registers bank hold variables common subexpressions results operations immediately consumed 
pipelined floating move 
move floating registers takes beat consumes register write port resource 
prevent floating point operation issued beats earlier write port floating move situations lock floating point operations 
address pipelined move operation added series 
floating units special modes multiply accumulate mode pair mode 
multiply accumulate mode operation perform multiply add 
mode added late tjs final machine design unusual constraints compiler 
pair mode supported compiler allows bit register treated element vector single precision operands 
instruction encoding instruction encodings large especially code functional units 
save space memory disk object code stored nop operations eliminated 
instructions grouped blocks non nop operations stored preceding mask word indicates nops eliminated 
instruction loaded icache expanded full width 
save space icache instruction encode multi beat nop instructs processor stall specified number beats executing instruction 
large instruction format permits generous number immediate operands 
full bit word worth immediates cluster beat 
word divided bit pieces construct shorter offsets 
addition source register specifiers integer operation interpreted bit immediate 
compiler uses immediates heavily 
constants loaded memory constructed instruction word 
double precision constants immediate fields 
global pointer scheme risc machines required 
due large number branches memory packed single instruction immediate resource 
tuned keep offsets created induction variable simplification small wide machine care taken place targets loop exits reached short branch offset 
trap code timings trap hardware trap code supports virtual memory trapping unmapped pages stores write protected pages 
prevent unwarranted memory faults speculative loads compiler uses load operation 
load traps trap code signal exception returns nan integer zero computation continues necessary translation buffer page fault serviced 
propagated floating units checked written memory converted integers booleans 
correct programs exhibit correct behavior speculative execution trace incorrect program may signal exception signaled compiled speculative execution 
hardware supports precise floating exceptions compiler move floating operations conditional branches mode 
mode compiling debugging 
trap code supports access misaligned data piecing referenced datum multiple bit words 
doing places bit quantities correct place bit word extracts merges correctly 
series supports performance counters beat counter cache counter bank stall counter 
accessible software provide accurate measurements program execution 
compiler issues summary main compiler issues trace machines follows 
large number pipelined functional units requiring data independent operations flight fill machine 
large amount instruction level parallelism requires scheduling basic blocks strategy finding parallelism loop iterations 
addition functional unit bandwidth support speculative execution 
machine resources pipelines resources beat 
compiler precisely model cycle cycle state machine situations model critical performance 
tjs final interleaved memory system managed compiler 
card conflicts cause program error bank conflicts affect performance 
functional unit register file 
costs operation move value registers remote register files may targeted directly cost extra beat latency 
compiler history roots multiflow compiler technology fisher thesis trace scheduling bulldog compiler developed fisher ellis nicolau yale 
bulldog implements fisher algorithm prototype compiler 
presents complete design optimization memory analysis register allocation instruction scheduling trace scheduling compiler hypothetical vliw 
multiflow bulldog experiments guide design trace architecture 
served high level design production compiler 
deviated design bulldog profitable necessary numerous changes 
changes reasons 
changes due different goals scope projects 
bulldog compiler line lisp program compiling small fortran subset hypothetical machine goal explore issues compiling vliw 
multiflow compiler line program compiling fortran series production 
goal compiler generate high performance code vliw traditional fortran environment workstation mini computer 
different goals scope compilers led major changes 
internal representations bulldog adequate represent full programming language semantics fortran led rethinking front optimizer 
memory analyzer redesigned exploit complex view memory relationships fortran machine model recreated represent multiflow trace series machines instruction scheduler complex 
heuristics compiler developed tuned new optimizations introduced 
high level compiler structure bulldog particularly implementation trace scheduling algorithm 
second source changes fundamental issues addressed bulldog relative memory bank disambiguation spilling registers 
memory bank disambiguation 
bulldog performs static bank disambiguation compiler determines memory bank addressed memory 
requires compiler able compute address mod number banks compile time bank determined central sequential memory controller 
static bank disambiguation impractical languages pointers arguments 
multiflow trace permits relative bank disambiguation 
compiler ensure issued simultaneously distinct banks need know banks 
relative conflicts frequently resolvable compile time 
example aligned double precision array known refer different banks typically know bank 
bulldog bank disambiguation performed single pass memory program 
multiflow compiler memory bank management needs integrated scheduling functional units major complication instruction scheduler 
spilling registers 
bulldog compiler spill registers memory assumes machine provides registers routine compiled 
experience multiflow registers critical resource machine 
routines simple kernels large amount parallelism compiler decision spill restore values important achieving high performance 
context compiler frequently refer bus card bank conflicts bank conflicts 
tjs final compiler structure phase phase phase fortran source structure multiflow compiler multiflow compiler phase structure 
phase fortran front produces high level intermediate representation called il 
phase analyzes optimizes program lowers representation il 
phase performs trace scheduling algorithm produces machine code 
phase phase operate il semantics independent source language 
operations il tuples op code followed list written operands list read operands 
operands constants virtual registers called temporaries 
ary operations provide opportunity flexible expansions binary operations optimizer find parallelism potential loop invariants common subexpressions 
provide simple solution requirements fortran parentheses 
il interface phase phase defines high level virtual machine 
level attempt capture memory access model defined programming language defer lowering memory phase useful performing memory analysis 
memory referenced explicit load store operations 
stack pointer argument pointer introduced phase 
array index lists preserved 
addressing expanded required language semantics 
accessing address data object marked explicit operation 
data objects grouped packets packet represents group variables language defined storage relationship 
packets unit storage allocation 
direct memory storage packet 
indirect define template packet describes template pointer wants impose memory 
similar pascal record type structure union type 
restrictions alias relationships fortran arguments associated template 
packet known mod alignment mod address packet definition packet derived definition 
front source analysis optimization code selection memory disambiguation trace scheduler instruction scheduler machine model tjs final il il address packet form integer refer packet seed 
packet seeds useful determining refer bank 
il operations successively lowered optimization 
output optimizer flow graph il operations correspond machine operations assigned functional units perform operations registers hold operands 
front ends multiflow compiler includes front ends ansi fortran vax vms extensions 
languages pascal ada lisp supported translators generate front ends derived att pcc compiler suite mapping pcc intermediate representation il 
il higher level pcc intermediate 
implemented tree synthesis algorithms recapture array semantics pointer arithmetic pcc 
retrospect may easier generate il directly semantic actions 
implemented user level directives fortran structured comments 
loop unrolling directives allow user specify loop unrolled 
inline directives allow functions inlined 
memory directives allow user assert facts addresses 
trace picking directives allow user specify branch probabilities loop trip counts 
addition front instrument program count basic block executions 
instrumentation saved data base read back subsequent compilations 
information guide trace 
support berkeley unix run time environment 
care structure layout rules ease porting vax base systems 
despite unusual architecture trace easier port bsd vax systems trace contemporary risc systems 
fortran io library distributed att compilers adequate high performance computing 
new high performance fortran io library written integrated fortran front 
optimizer goal optimizer reduce amount computation program perform run time increase amount parallelism trace scheduler exploit 
computation reduced removing redundant operations rewriting expensive ones goal optimizers 
parallelism increased removing unnecessary control data dependencies program unrolling loops expose parallelism loop iterations 
multiflow compiler accomplished goals standard dragon book style optimization technology enhanced powerful memory disambiguator 
organization optimizer designed set independent cooperating optimizations share common set data structures analysis routines 
analysis routines compute control flow dominators loops data flow reaching defs uses live variables reaching copies 
addition disambiguator computes symbolic derivations address expressions 
optimization records analysis information needs information destroys 
order optimizations quite flexible fact controlled small interpreter 
order full optimization 
tjs final basic optimizations expand entries returns il find register variables expand memory ops il eliminate common subexpressions propagate copies remove dead code rename temps transform ifs selects prepare loop unrolling generate automatic assertions move loop invariants find register memory eliminate common subexpressions transform ifs selects find register expressions remove dead code unroll unroll optimize loops rename temps propagate copies simplify induction variables eliminate common subexpressions propagate copies remove dead code second unroll unroll optimize loops rename temps prepare phase expand calls il walk graph allocate storage analyze dead code removal remove assertions remove dead code expand remaining il ops il propagate copies remove dead code rename temporaries optimizations invoked multiflow compiler control dependence control dependence mean barriers instruction level parallelism caused control flow program 
control dependence introduced conditional branches function calls loops 
control dependence introduced conditional branches directly addressed trace scheduling performs speculative execution branch works best highly predictable branches 
addition series tjs final supports predicated execution input select operation branches compiler generates select clause expensive 
example compiler maps cond removes short forward branches trace scheduling effective 
series includes predicated stores predicated floating point operations 
function calls addressed inlining 
compiler inline small leaf procedures 
addition removing overhead procedure call increases size traces provides opportunities parallelism 
aggressive inlining performed user command line arguments directives 
loops addressed unrolling 
loops unrolled copying loop body including exit test see 
compilers remove exit tests unrolling loop preconditioning 
unroll pre loop added handle trip count mod iterations loop processes loop bodies time 
machines trace large amount branch resource advantage removing exit branches 
leaving branches eliminate short trip count penalty caused preconditioning 
addition loops data dependent loop exits preconditioned loops unrolled optimized iterations 
loops constant trip count exit test removed small loops unrolled completely 
preconditioning separate optimization support pair mode hardware feature allowed vectors length math intrinsics explained 
practice preconditioning postcondition loop possible assertions alignment loop entry 
series branch bandwidth required achieve peak performance 
loop unrolled pre cond post cond goto goto goto goto body body body body goto goto goto body body body body goto goto body body body goto goto goto goto body body body goto body goto body body body goto goto body styles loop unrolling cond loops unrolled heavily 
loop unrolled expose sufficient parallelism loop body enable instruction scheduler fully utilize machine 
unrolling controlled set heuristics measure number operations loop number internal branches number function calls 
loop unrolled desired unroll amount reached heuristic limits exceeded 
example target unroll amount operation limit unroll loop body operations times 
body contains operations unrolled times 
contained operations unrolled twice contained operations unrolled 
default unrolling fortran trace wide highest level optimization unroll 
corresponding limits 
tjs final optimization level total unrolling unrolling second unrolling max operations max branches max calls fortran unrolling trace limits determined experimentally small set benchmarks worked practice 
compiler includes set heuristics controlled unrolling utilization machine resources loop body practice outperform simpler scheme 
loop unrolling done steps unrolling loop body copied second unrolling unrolled bodies copied unit 
step approach allows keep relatively small unroll heavily 
ordering optimizations heavily influenced phase loop unrolling design see 
standard optimizations performed unrolling permits accurate estimate loops size heuristics 
unrolling induction variables rewritten optimization performed unrolled bodies achieving effect predictive 
induction variable simplification loop bodies may increase register pressure 
keeping unrolling small prevent register pressure loop exceeding available registers 
keep constant displacements introduced induction variable simplification small immediate resource instruction 
data dependence compiler strategy eliminating unnecessary data dependence map variables possible temporaries virtual registers easily analyzed optimized 
major optimizations removing data dependence copy propagation temporary renaming 
compiler rewrites reduction loops minimize recurrences loop iterations 
allocating variables temporaries optimizer attempts place variable value temporary semantics program requires memory includes aggregates structures arrays 
instruction scheduler spill values memory needed allocating registers 
eliminates possible program permits instruction scheduler place necessary ones spills restores optimal points program 
minimizing memory important trace systems data cache 
attempt place values temporaries done entire program loop 
done straightforward analysis il program phase places scalars aggregates registers routine wide loop loop basis 
optimizations disambiguator place loop invariant array indirect registers 
enhance capabilities disambiguator compiler assert condition tested conditional branch branch 
particular compiler assert induction variable loop loop bounds 
example compiler asserts inner loop 
permits disambiguator know location safely moved loop 
tjs final classes loop varying array indirect maintained registers achieving effect similar scalar replacement 
called register memory detection detected address invariant loop 
second called register expression detection detects recurrences form maintains corresponding array element temporary 
expression tree 
original loop body transformed body 


initialized loop pre header transformations enable loops rewritten reductions discussed 
removing data dependence memory removed compiler attempts remove data dependence temporary renaming copy propagation 
temporary renaming splits temporaries disjoint def webs 
copy propagation propagates copied value 
optimizations invoked multiple times 
prepare induction variable simplification unrolled loop 
initially unrolled loop little parallelism dependencies induction variables see dependencies 
renaming copy propagating remove dependencies 
propagating integer additions constant express secondary induction variables primary induction variable set loop successful induction variable simplification 
tjs final unrolled renamed copy propagated goto exit goto exit goto exit ld ld ld st st st goto exit goto exit goto exit ld ld ld st st st goto exit goto exit goto exit ld ld ld st st st goto exit goto exit goto exit ld ld ld st st st goto goto goto removing dependencies induction variable variable live loop exit unrolling loop create situation multiple definitions variable reach 
various definitions independently renamed definitions able issued speculatively preceding loop exit 
remove problem insert self assignment loop exit variable defined loop live exit 
permits variables renamed 
pay extra move exit loop enable parallelism loop iterations 
see 
unrolled self assignments renamed goto exit goto exit goto exit ld ld ld goto exit goto exit goto exit ld ld ld tjs final goto exit goto exit goto exit ld ld ld goto exit goto exit goto exit ld ld ld goto goto goto removing dependencies variable live loop exit reductions compiler rewrite loop containing reduction reduction recurrence form op fn op commutative associative 
reduction rewritten interleaved reductions results combined loop exit 
example dot product transformed goto exit goto exit goto exit goto exit goto exit goto exit goto exit interleave amount determined number reduced operations simultaneously active machine pipeline latency times number functional units 
dot product interleaved trace 
give instruction scheduler freedom optimizer unroll loop twice interleave amount insert self assignments loop exits rename described 
floating point operations performed reductions strictly speaking illegal fortran semantics cases performing operations loops order unimportant 
provide switch prevent optimization cases result differ floating point addition subtraction inhibiting cases min max integer operations tjs final compiler detect parasite reductions desired value maintained parallel reduced value 
example returns index maximum vector recognized parasite max reduction interleaved 
see 
dmax dx dx le dmax goto dmax dx continue dmax abs dx dmax dx dmax dmax goto exit goto exit dx dx gt 
dmax gt 
dmax dmax dmax dmax dmax goto exit goto exit dx gt 
dmax dmax dmax goto reduction reducing computation exit dmax gt 
dmax dmax eq 
dmax lt dmax dmax dmax basic optimizations reduce computation standard interesting features 
loop invariant motion common subexpression elimination cse disambiguator detect location conflicts memory allows optimizations deal effectively array indirect 
discussed induction variable simplification performed heavily unrolled loops 
addition strength reducing address expressions minimize number live registers required loop bodies induction variables loop invariants best constants instruction 
common subexpression elimination performed extended basic blocks 
performed tjs final loop unrolling detect redundant computations loop bodies 
example livermore kernel new loads required iteration compiler detects corresponding redundant flops 
loop continue common subexpression algorithm performs local addition 
extended basic block performs constant folding copy propagation operation simplification dead code removal 
optimizations easy perform data dependency graph extended basic block built 
copy propagation dead code removal performed globally separate optimizations 
cse detects optimizes calls math intrinsics 
core math intrinsics atan atan cos cos sin exp log pow sin implemented time versions 
arguments passed intrinsics values returned 
cse look multiple calls intrinsic substitute call time function 
loop postconditions loops contain intrinsic allow intrinsic called speculatively producing equivalent vector intrinsics 
sin sin sin cos cos sin sin sin sin shown approach applied programs structured intrinsics 
example calls sin cos replaced calls cos cos sin sin cos sin 
tht tht zr ee rr bet wep del tht tht tht tht tjs final tht tht tht tht tht tht gj gj non vector candidate time intrinsics 
dead code removal iterative mark sweep algorithm removes operations contribute final result program deletes dead control flow conditional branches go way due constant condition branches true false successors 
dead code removal profitable conjunction constant propagation procedure inlining 
additionally clean information maintained disambiguator 
enhance memory analysis maintain subscript information phase 
array lowered twice form contains base displacement addressing subscript list form contains base displacement 
induction variable simplification inserts special deriv assign operations relate new induction variables original subscript expressions 
second lowering code maintained subscript expressions dead removed 
similarly assertions addresses maintained flow graph phase 
final code expansions assertions removed dead code removal eliminates dead code maintained values asserted 
back output phase flow graph il operations lowered machine level 
phase performs functional unit assignment instruction scheduling register allocation 
divided modules trace scheduler manages flow graph assures inter trace correctness instruction scheduler tjs final schedules trace assures intra trace correctness machine model provides detailed description machine resources disambiguator performs memory analysis 
structure phase trace scheduler 
algorithm trace scheduler performs steps copy flow graph produced phase estimate times operation executed 
perform loop entire flow graph scheduled 

execution estimates guide pick trace sequence basic blocks flow graph 

pass trace instruction scheduler 
instruction scheduler schedules trace returns machine language schedule 

replace trace schedule flow graph necessary add copies operations compensate code motions past basic block boundaries 
emit schedules depth order 
describe steps detail instruction scheduler described section 
expect machine model il trace scheduler instruction scheduler disambiguator execution estimates called expect calculated loop trip count frequencies probabilities conditional branches 
rules tjs final file operation entry routine expect number entries operation head loop expect sum prob expect sum sum preds pred loop entrance 
prob probability traversing edge pred op 
expect expect pred 
operation loop head expect iter count sum le prob expect iter count expected iteration count loop 
sum le sum loop entrances loop 
prob probability traversing edge loop entrance expect expect loop entrance 
loop entrance operation loop successor loop 
insert pseudo op ensure loop entrance successor 
calculating expect handle irreducible loops treating reducible 
formulas operation loop head ignore loop entrances predecessors operation loop head treat loop entrances loop predecessors 
probabilities conditional branches obtained database collected previous executions program user directive simple heuristic conditional branch loop exit 
probability exit loop set iteration count iteration count expected iteration count loop 
expected iteration count loop assumed 
trace picking traces picked selecting scheduled operation highest expect 
operation seed trace trace grown forward direction flow graph backward 
grow trace picking successor predecessor moving backward satisfies current trace picking heuristic 
successor predecessor satisfies current heuristic trace ends 
traces hit operation scheduled operation trace 
traces cross backedge loop explained 
addition trace length equal max trace length varies operations depending width machine level optimization 
trace picking heuristics defined terms edges operations flow graph 
criteria determine edge added trace regardless direction growing trace 
apply heuristic edge pred succ 
growing trace forward pred trace backward succ trace 
implemented large number trace picking heuristics listed 
mutual 
conditions met edge pred succ highest probability exits pred pred go succ 
edge pred succ contributes expect succ predecessors succ succ come pred 
tjs final compensation 
want compensation code required instruction scheduling 
pred succ rejoin split edge ok rejoins splits require special attention succ rejoin multiple predecessors trace compensation required succ moved pred schedule 
pred rejoin edge ok succ split multiple successors trace compensation code required succ moved pred schedule 
pred split edge ok mutual heuristic default 
compensation heuristic avoid creation compensation code restricts traces variant basic blocks 
compiler switch heuristic compensation code created see section 
compensation code picking trace trace scheduler passes instruction scheduler 
instruction scheduler returns schedule 
trace scheduler examine code motions instruction scheduler performed see operations copied 
splits branches trace joins branches trace determine basic block boundaries flow graph 
copy necessary associated split join 
discuss compensation code need introduce notation 
trace position position operation trace 
cycle position cycle operation schedule 
cycle position cycle operation schedule 
split operation split operation successor example conditional branch operation indirect branch 
instruction scheduler moves operation split schedule trace scheduler copy operation trace edge 
example copied 
examples machine instruction denoted op op 
trace split compensation code split tuple compensation copies trace position trace position cycle cycle 
copies placed split edge source order order operations appeared trace 
notation adapted ellis 
schedule tjs final joined operation join operation trace target branch operation 
instruction scheduler moves operation join trace scheduler insert copy operation trace joining edge 
example copied 
join compensation code join compensation code generated trace scheduler determine rejoin schedule 
rejoin cycle join trace position satisfy constraint operations appeared prior trace trace position complete cycle schedule 
example join trace moved instruction schedule 
rejoin instruction determined trace scheduler determine join compensation code 
join trace position rejoin cycle tuple compensation copies trace position cycle placed join edge source order 
split copied rejoin edge additional copies required 
consider join rejoin instruction 
copy needed trace edge path incorrect 
general operations join split trace rejoin instruction schedule copied trace edge copied split 
split copied join trace position rejoin cycle tuple compensation code jm trace position ji trace position ji trace position cycle ji trace trace split copied rejoin edge schedule tjs final schedule go speculative code motion speculative execution moving operation split trace split schedule produce compensation code 
common code motion multiflow compiler 
high priority operations late trace moved splits scheduled early trace 
instruction scheduler perform move safe operation move split writes memory sets variable live trace path 
hardware provides support suppressing deferring exceptions generated speculative operations 
suggested compiler insert code trace path undo effects speculative operation done 
simple register operations incrementing counter operation best un done targeting register live trace path 
operations write memory transfer control complexity un doing outweighs potential benefits 
emitting schedules traces selected frequently traveled paths program trace scheduling gives effect profile guided code positioning 
entire flow graph scheduled graph transformed graph schedules 
trace scheduler depth walk entries emitting schedules 
avoid unnecessary branches schedules emitted code visit fall successor schedule performing depth walk 
trace immediate resource instruction shared operations obtaining peak performance unrolled loop requires short branches loop exits order free immediate space memory offsets 
vliw instructions large fully packed instructions kb loop exits positioned shortly loop body keep reach short branch offset 
encounter schedule begins loop change depth breadth walk graph collect position loop exits 
exit loop resume depth walk 
restrictions trace scheduling multiflow compiler places number restrictions trace scheduling order limit amount compensation code problem engineering compiler tractable 
loops trace cross backedge loop 
restriction partly historical fisher consider picking traces back edge definition trace scheduling 
number advantages 
simplifies instruction scheduler trace scheduler deal complexities scheduling multiple iterations loop simultaneously trace loop body treated identically trace sequence loop free code 
simplifies memory analysis discuss section 
addition nicolau relies restriction proof trace scheduling terminates 
practice restriction impact performance 
popular algorithm scheduling back edge loop software pipelining 
software pipelined loop scheduler integrated multiflow compiler straightforward manner 
may improve performance vector kernels perform address weaker points compiler 
attraction software pipelining algorithm finding optimal schedule loop kernel 
unrolling strategy cross backedge loop start loop bodies head loop wind bottom portions schedule machine optimally 
tjs final software pipelined schedule move wind wind portions schedule outside loop 
see 
loop unrolling software pipelining multiflow compiler unroll loops heavily times amortize loop wind wind bodies mitigating performance effect 
unrolling increase code size due large instruction cache multiflow machines affect performance significantly 
low trip count loops software pipelining advantage 
wind wind dominate execution time loop software pipelining simple unrolling 
software pipeline algorithms require pre loop special hardware support supplied overhead pre loop amortized number iterations spent software pipelined kernel 
multiflow unrolling strategy require pre loop 
suggested software pipelining extended speculative execution require pre loop 
low trip count loops best served peeling iterations trace picked bypasses loop entirely 
permits peeled iterations scheduled code preceding loop 
testing zero trip case performance advantage peeling additional iterations guided feed back previous executions program 
unfortunately multiflow compiler implement optimization 
splits wu wu wu wu controlling split compensation unrolled software pipelined wd wd wd wd limit split compensation multiflow trace scheduler requires operations precede split trace precede split schedule stores 
store operations appear split compensation code amount split compensation code program small 
restriction limits parallelism available scheduler small effect performance 
intuitive explanation executing split early typically speed execution trace path speeds trace path 
multiflow compiler achieves speed ups predicts trace path correctly 
scheduler attempts schedule split soon predecessors scheduled control leaves trace early conventional basic block compiler 
trace path penalized trace scheduling may sped 
permit stores move splits avoid serialization schedule stores permitted move splits 
consider alternating sequence branches stores 
required stores complete preceding branch store branch scheduled instruction 
multiflow trace issue stores branches instruction 
allowing stores move tjs final wu wu wu wd wd wd splits gain parallelism trace exchange small amount split compensation code 
see 
note unrolled vector loop contain sequence branches stores intermixed operations 
st trace exit exit st exit st exit st exit st exit st exit st br scheduling store branch constraint source order splits schedule store branch constraint exit st exit st exit st exit st exit st exit st exit st br schedule store branch constraint exit st exit st goto exit st st exit st goto exit st st exit st goto exit st br constraining split trace predecessors stores splits scheduled source order 
important consequences 
source order splits restrict compensation code required nicolau proof trace scheduling terminates stronger restriction required 
second source order splits ensure paths created compensation code subsets paths possibly compiler machine issue branch store cycle need move stores splits 
tjs final re arranged flow graph trace scheduling 
fact relied memory analyzer 
proof fact requires case case analysis nicolau scope 
shows rearranging splits create potential trace correspond flow path original flow graph 
consider compensation code rejoin creates path contains original flow graph path 
splits scheduled source order indirect branches indirect branches treated splits indirect branches target label 
case compensation code generated motion permitted 
branches location address previously computed stored variable 
potentially branch location impossible redirect new target location redirecting 
example tag predecessors place insert compensation code tag executed path tag compensation code allowed 
indirect branches common target inserting multiple tag pseudo ops front optimizer avoid flow graph construct common uses indirect branching switch statements fortran computed goto 
translation fortran assigned goto may require flow graph targets label 
instruction scheduler restricts code motion prevent copied join edge cause copy trace share targets 
joins trace determining rejoin point schedule stated section rejoin cycle join trace position satisfy constraint operations appeared prior trace complete cycle schedule 
machine tjs final goto goto tag tag tag goto self draining pipelines trace permit cycle operations preceded join trace started 
example rejoin cycle 
avoid copying rejoin edge 
early rejoin beneficial trace path unfortunately schedules early rejoin incurs execution time penalty trace path 
consider schedule 
rejoin cycle slow trace path avoid rejoin compensation code 
early rejoin slows trace path note instruction scheduler consider placement rejoins creating schedule analysis performed schedule created 
avoid penalizing trace code want wait pipelines operations rejoin drain point longer constrain operations schedule rejoin schedule 
avoid complicated heuristic delay rejoin operations preceded join trace complete creating necessary rejoin copies 
multiple joins trace trace possible actual possible ri actual ri schedule joined operation serves target multiple branch operations 
case decide separate compensation copy joining edge joining edges share single instance compensation copies 
separate copies inserted possible copies merged trace code 
furthermore single branch instruction needed transfer control cycle 
single copy compensation code hand reduces amount code growth 
tjs final schedule multiflow compiler opted place separate set join copies joining edge 
control code growth allow code motion operation predecessors 
see trace compensation code alternatives multiple joins copy suppression unrolling loops internal branches cause large amount join compensation code 
see 
loop join compensation code redundant potential rejoin copy scheduled instruction dominates rejoin 
problem noted motivation copy suppression algorithm 
copy suppression detects operation moved point schedule dominates rejoin 
result operation live rejoin copy necessary 
details algorithm implementation described 
copy suppression compiler profitably unroll loops internal branches 
fail safe trace scheduling shutdown schedule schedule number copies program twice number original operations trace scheduler longer permit compensation code generated 
ensures program finish compiling relatively rapidly 
rarely activated normal compilation fail safe recovery worst case copying generated heavily unrolled loop internal branches copy suppression algorithm successful 
tjs final join compensation code scheduling loop internal branches 
communication schedules instruction scheduler schedules trace time requires information neighboring traces correctness optimize performance inter trace transitions 
addition trace trace scheduler passes information instruction scheduler information pipelines memory neighborhood split join 
information register bindings live variables partial schedules exit exit exit exit exit exit exit br exit functional unit pipelines multiflow machines machine resources beat 
example integer alu operation writes remote register file beat pipeline 
tjs final exit exit exit exit exit exit br beat uses ialu register file read ports possibly immediate field 
beat uses bus ialu remote register file 
beat uses write port remote register file 
result bypassed read local functional unit beat 
hardware check resources compiler precisely model resource utilization beat 
resources operations trace modeled instruction scheduler creates schedule 
split may leave schedule pipelines flight 
compiler track resources wind pipelines 
similarly join schedule may require winding pipelines 
information pipelines flight associated split join schedule 
call set pipelines bisected split join partial schedule 
creating partial schedules partial schedule upper lower half set pipelines bisected split join 
notation nth beat pipeline operation 
join bisects split bisects join partial schedule split partial schedule 
trace partial schedules schedule join upper half bisected pipeline copied edge 
operation join partial schedule join trace position rejoin cycle trace position cycle cycle targeting rejoin sure branch added cycle join partial schedule 
insert new instruction branch partial schedule schedule shift resources pipelines may disrupt schedule joining 
branch added cycle partial schedule try join subsequent cycles find compatible cycle reach schedule know rejoin 
example locks branch example join cycle try join cycle locks branch join schedule 
split bottom half bisected pipeline copied split edge 
operation split partial schedule split cycle cycle cycle cycle 
note include operations speculatively scheduled split bisected split edge 
tjs final merging partial schedules trace predecessor previously scheduled code may associated wind partial schedule 
partial schedule passed instruction scheduler trace placed instructions schedule 
see 
trace wind partial schedule similarly trace successor previously scheduled code may associated wind partial schedule 
partial schedule passed instruction scheduler trace placed instructions schedule 
see 
wind partial schedule trace schedule schedule information machine resources schedule joined wind partial schedule maintained 
permits traces tightly merged 
machine self draining pipelines tail pipelined operation consumes resources require operation initiated 
tail placed flow path effect cycle operation executed 
cycles placed schedule join 
control flows instruction tjs final flight continues pipeline 
control falls instruction instruction nop 
compiler performs merge creating schedule trace 
merging partial schedules memory information instruction scheduler creates partial schedule saves information memory partial schedule memory beat bank stall window split join 
permits instruction scheduler perform card bank analysis merging partial schedules 
register bindings trace scheduling trace instruction scheduler decide read variables live entry trace write variables live exit trace 
trace binding decisions instruction scheduler free variables locations result best schedule 
subsequent traces entered branch machine code schedules binding decisions 
trace entered machine code schedule read upward exposed variables locations machine code wrote 
trace branches machine code schedule write downward exposed variables locations read machine code 
analysis applied register candidates il temporaries constants term value describe 
value location bindings schedule information value location bindings scheduled code recorded communicated data structure called value location mapping 
maps set values set locations value may location location value 
created instruction scheduler generated machine code trace 
distinct required split join schedule 
split describes schedule placed downward ellis called defs uses 
tjs final exposed values 
join describes schedule reads upward exposed values 
example shows created instruction scheduler simple trace 
created added flow graph guard borders schedule surrounding intermediate code 
trace treats operations 
element trace 
operation trace instruction scheduler read upward exposed values locations 
final operation trace instruction scheduler leave copy value associated locations 
delayed bindings trace schedule ireg ireg ireg ireg ireg ireg values live top bottom trace referenced trace 
want avoid making binding decisions values time trace scheduled 
eventually decide location value schedules live range 
necessary desirable value reside location schedules live range 
delaying binding decision value schedule operation advantages implicitly prioritize values expected frequency access 
allows weigh benefits keeping different values registers conflict keep values registers accessed highest frequency code spills restores low frequency 
achieves effect similar hierarchical coloring 
wait choose locations scheduler sees particular value accessed 
especially important presence function calls require arguments return values certain prespecified locations 
trace machines separate register banks functional unit connected distinct register bank 
value proper register bank functional unit operand 
better register assignment defer assignment know functional unit value reader 
order delay binding decisions unreferenced live values devised mechanism call delayed bindings 
delayed binding pseudo location may assigned unreferenced value instruction scheduler 
delayed binding represents connected subset value live range set schedules generated value pass data motion 
value delayed binding boundaries connected set schedules 
connected subgraph schedules grows delayed bindings value merged 
binding decision delayed binding updated reflect assigned location 
delayed binding accumulates information needed choose physical location value 
schedule maintain set registers allocated schedule 
resolve delayed binding pick register intersection unallocated register sets delayed binding set schedules 
register exists memory location chosen 
tjs final example delayed binding resolution 
binding decision delayed schedules created delayed bindings merged 
point exist entry exit subgraph map delayed binding spanning schedules subgraph 
trace containing assignment entry scheduled register chosen binding resolved 
binding propagated exit 
trace db db resolution delayed binding instruction scheduler instruction scheduler transforms trace il operations schedule wide instructions encompasses scheduling register allocation phases compilers 
operations lowered machine level phase 
operation instruction scheduler assign registers operands assign functional unit operation place operation wide instruction 
performs step algorithm 
build data precedence graph dpg trace 
walk dpg assign operations functional units values register banks 
perform list scheduling creating schedule allocating registers 
scheduling group memory minimize memory bank conflicts 
data precedence graph schedule resolved delayed bindings instruction scheduler basic data structure data precedence graph 
node graph represents value associated defining operation edge represents scheduling constraint 
types edges dpg operand edges describe creation value 
edges require register assignment 
memory edges describe definite possible conflicts load store store store pairs 
constraining edges define scheduling constraints inserted correctness performance 
scheduling trace basic block extended basic block introduces little complexity instruction scheduler 
building dpg edges added constrain operations moving splits 
scheduling trace scheduler compensates global code motions performed instruction scheduler 
tjs final clustering assigning functional units register banks want cluster assignments neighbors dpg assigned neighbors machine 
spreading computation machine functional units peak performance achieved 
clustering algorithm trades benefit parallelism cost global data motion 
width trace difficult problem 
expensive spread computation machine 
functional unit register bank accesses inputs 
operand local register bank register transfer required 
register transfer adds latency calculation consumes functional unit resource preventing operation scheduled 
functional units write local remote register banks writing remote bank increases latency consumes global bus 
busses load values memory critical resource trace machines 
functional units overlapping non identical repertoire 
particular cluster integer alus perform memory operations 
presents conundrum induction variables memory 
induction variable kept locally memory alu incrementing consumes resource required memory operation 
hand keeping induction variable local simple integer alu requires operations induction variable update increment induction variable move memory alu 
fortunately strategy worked vector loops unrolled strength reduced frequently induction variable update shared group memory 
bug bottom greedy algorithm original approach clustering problem taken directly bulldog compiler bottom greedy bug algorithm 
bug complex algorithm described 
idea trial schedule focusing issue minimizing amount data transfer latency 
algorithm greedy chooses best functional unit available time operation considered 
resulting schedule discarded functional unit register bank assignments retained 
bug algorithm depth traversal dpg recursive function bug assign starting outputs typically stores working inputs typically loads 
search guided level latency weighted depth nodes critical path computation searched 
bug assign op destination fus op upwards exposed return op fu assigned return foreach predecessor priority order operand op possible fus best fus op destination fus bug assign possible fus bug assign nil op fu choose fu op destination fus bottom greed bug assignment algorithm outline bug assign works tjs final invoked operation destination fus list possible destinations passed 
list non null functional units reader operation result final assignments 
predecessors visited priority order determined latency weighted depth dpg 
depth measured entries dpg lower bound earliest time scheduled 
items greater depth visited visit predecessors order maximum delay imposed scheduling op 
bug assign recursively invoked operand op list best functional unit assignments op computed passed functional unit list equally assignment op compute result deliver destinations early 
estimate completion time 
scheduled times assigned operands 
latency weighted depths unassigned operands 
functional unit assignments assigned operands time required move operand functional unit produced 
earliest availability functional unit operands optimistically accessed 
latency functional unit 
earliest time deliver result destination functional units 
predecessors scheduled register banks assigned operands op op assigned functional unit placed schedule 
problems greedy algorithm greedy algorithm inappropriate types computations attain peak performance wider multiflow machines 
computations parallel example vector loops unrolled compiler 
codes single critical path computations peers 
goal layout computations machine manner maximizes throughput minimizing latency particular thread 
general problem number concrete manifestations 
greedy algorithm schedule non critical path operations component result delaying critical path operations components 
example consider unrolled daxpy ld ld daxpy unrolled times st ld ld greedy depth traversal visit ld ld 
assign schedule ld potentially delaying start ld completion second tree 
ld critical path tree scheduling advantage 
tjs final st optimizing completion time component visited may result spreading component machine 
resulting data motion require global busses reducing number memory issued 
example daxpy shown loads multiplies performed parallel separate functional units component completed early 
results multiplies moved common functional unit perform adds 
data motion competes loads components global memory busses effectively cuts memory bandwidth half 
ld ld st ld component daxpy bug consider parts computation fit holes created schedule 
example consider unrolled interleaved dot product 
ld ld dot product unrolled times ld ld ld operations tree assigned bug decision load operands multiply parallel targeting register bank 
completely subscribes register bank write ports beats 
prevents multiply shorter pipeline issued beats targeting register bank 
better schedule load operand multiply beat leaves write port available operation 
addition bug consider memory bank conflicts assigning functional units problem discussed 
discussion assume memory bank conflicts 
tjs final ld ld ld ld ld controlling greed bug order address problems imposed system constraints bug 
idea impose high penalty bug latency calculation considers identical resource particular thread computation 
keeps members thread subset machine achieves parallelism spreading threads machine 
detail partition machine number equivalent virtual clusters virtual cluster subset hardware clusters described section 
virtual cluster contains functional unit kind represents simple target placement choices 
partition computation components contains relatively little parallelism relatively large amount shared data 
partition code components depth search terminals dpg traversing operand edges 
unique component assigned terminal operation encountered time search terminal 
effect associating common subexpressions descendent terminals 
examples previous section tree component 
assign components virtual clusters spread computation evenly machine 
existence common subexpressions components nontrivial 
consider livermore kernel shown 
assign component different cluster ignoring inter component reads data motion required 
hand assigning components cluster utilize clusters machine 
best solution problem perform successive components cluster switch clusters 
effect reducing inter cluster move cost factor kernel difference 
ld ld difference common subexpressions achieve assignment introduce third data structure st st ld create partitioning components equivalence classes 
components equivalence class contains operation result read 
computations components belong equivalence class 
hand computations partition cleanly component equivalence class 
bug uses system virtual clusters components equivalence classes impose penalties dynamically associating virtual cluster equivalence class 
initially association undefined 
time functional unit chosen operation equivalence class assigned virtual cluster containing functional unit 
alternative functional units considered operation estimated completion times calculated penalty imposed operation equivalence class associated virtual cluster different functional unit 
desired effect keeping members equivalence class virtual cluster threshold opportunity reached 
tjs final st ld st ld scheduling register allocation functional unit register bank assignments complete second scheduling pass data precedence graph 
result pass schedule returned trace scheduler 
pass performs tasks 
schedule machine resources functional units register write ports busses complete detailed model machine 
trace machines resources register dependencies checked hardware 
schedule created compiler accurate 
allocate registers inserting spills restores necessary 
schedule memory avoid card conflicts minimize bank conflicts 
instruction scheduler design choices instruction scheduler implementors face decisions basic structure scheduler 
choices operation driven versus cycle driven 
cycle driven schedulers maintain list data ready operations consider cycles turn trying fill high priority operations data ready list 
contrast operation driven schedulers topological sort operations driven priority heuristic usually critical path considerations 
consider operations time trying find instruction cycle place operation 
bug operation driven scheduler 
scheduling register allocation pass cycle driven 
forward versus backward scheduling 
forward schedulers start placing leaves typically loads computation earliest possible cycles schedule moving downward data precedence graph roots typically stores 
backward schedulers turn 
schedulers forward 
backtracking 
extent decisions scheduler final 
bug backtracking 
scheduling register allocation pass limited amount backtracking 
separate register allocation scheduling passes versus integration register allocation scheduling 
register allocation instruction scheduling performed separate passes due complexity 
separate register allocation pass scheduling target machine registers 
pipeline depth issue width increase number registers stays constant difficult condition fulfill 
instruction scheduler integrates scheduling tightly register allocation 
various priority functions 
topological sorts dpg breadth parallelism versus depth register allocation major performance implications 
priority functions depth 
rely clustering heuristics bug natural breadth orientation list scheduling algorithm give breadth scheduling passes 
bug walk dpg component performing depth traversal 
visit components order occur trace earliest depth traversal guided latency weighted depth predecessor dpg 
instruction scheduler form total ordering operations performing similar walk bug ordering priority function 
operations earlier component higher priority operations component 
ordering gives higher priority earlier basic blocks trace particular operation unrolled loop body higher priority operations second forth 
static vs dynamic scheduling priority assignments 
priorities operations change scheduling 
scheduling register allocation pass limited amount dynamic priority assignment 
tjs final integration scheduling register allocation goal integrating register allocation scheduling able treat registers resource par types resources 
important registers scarce resource 
trace machines long pipelines multiple operations instruction floating point registers critical resource generating peak performance 
addition trace machines require detailed scheduling machine resources quite expensive compile time 
provides additional motivation integrating scheduling register allocation 
performing register allocation scheduling requires second scheduling pass spills restores 
allocating registers scheduling practical parallel machine introduces constraints code 
cycle driven scheduling particularly suited integration register allocation 
organization allows registers treated resources 
point scheduling process registers occupied available 
process checking resources schedule particular operation cycle include check free register result 
resources available schedule operation register resources reserved 
major complication trying integrate kind simple come served register allocation operation driven scheduling 
operation scheduling follow instruction order leave gaps register available certain number cycles 
scheduler decide operation target register gaps 
reader operation data ready resource ready time read value gap 
difficult operation driven scheduler gaps backtracking 
spilling register allocator able deal computations fit available registers 
solution ensures scheduler progress 
scheduling operation check required resources available check register free result 
free register heuristically select victim occupying register 
compare priority operation trying schedule priority victim 
victim lower priority schedule spill victim 
delay operation 
important priority assignments topological sort data precedence relationship 
victim lower priority operation trying schedule chosen operation depend victim victim spilled 
similarly victim higher priority delay operation risking deadlock 
mechanism picking victim grew complexity time 
operations assigned priority scheduling 
operation scheduled priority adjusted priority urgent unscheduled reader 
victim choosing strategy chose urgent operation occupied register right type unscheduled operation 
refined victim choosing strategy take advantage limited backtracking facility 
observation values easier spill having spilled easier restore 
particular loads memory reloaded original locations requiring spill possibly conflicting store scheduled interim 
results immediate moves easy recreate 
result strategy shorten live range memory presence register pressure 
scheduler greedily fills unused memory bandwidth loads register allocator removes premature 
effect similar achieved backward scheduling 
limited backtracking scheduler employs limited form backtracking proved quite useful 
memory operations replicated split dpg scheduled multiple times 
splitting occurs scheduling proceeds different situations trigger register allocation pressure cause scheduled load replicated order reclaim target register higher priority operation 
happens original load removed schedule tjs final readers scheduled 
cases load common subexpression scheduled readers urgent priority unscheduled readers lower urgency 
splitting case gives effect similar live range splitting coloring register allocators 
difference splitting responsive needs instruction scheduler 
memory splitting spread values different register banks 
depending balance memory floating point operations better load value times different register banks load value distribute series tree register transfers 
floating point load initially scheduled location requirements readers analyzed 
small number memory relative floating point operations trace decide deliver data remote register banks reloading direct register transfers 
strategy works concert bug clustering limit amount intercluster register transfers required code memory common subexpressions 
splitting reclaim resources lower priority operations behalf higher priority ones 
particularly troublesome form due mismatch latencies floating point memory operations shown 
example double precision loads issued cycle completely subscribe write ports register bank cycles prevents floating multiply cycle targeting register bank 
assume multiply higher priority loads data ready cycle 
undo lower priority loads allow higher priority multiply scheduled 
unscheduled load returned data ready queue 
issue loads reg bank issue multiply reg bank reg bank write ports loads reg bank write ports loads lockout scheduling unlimited backtracking form limited backtracking introduce large algorithmic time complexity scheduler 
operation refill issue slot guarantee operation unscheduled 
practice operations split 
scheduling memory bank disambiguation described section series level interleaved memory hierarchy exposed compiler 
card conflicts result program error 
memory beat distinct memory cards result undefined 
bank conflicts result loss performance 
series memory bank beats second bank beat window cause entire machine stall busy time 
strategy managing bank card conflicts divide memory trace equivalence classes knowledge offsets relative 
equivalence classes formed querying disambiguator scheduling 
equivalence class understand potential bank card conflicts different equivalence classes known 
example simple vector kernel vector add know relative offsets successive successive interprocedural information understand relative offset tjs final subroutine double precision vector add subroutine 
scheduling code trace schedule group equivalence class group alternating classes minimize bank stalls 
schedule batch memory equivalence class risk bank stall 
naive order batched order memory ordering 
batching groups increases register pressure 
batch groups schedule requires registers risks bank stall memory 
naive schedule order requires registers risks bank stall memory 
tradeoff requires heuristic limit memory batching 
memory card conflicts result program error avoid scheduling code 
scheduler keeps track memory scheduled cycle consults disambiguator new candidate operation definite possible conflict exists 
memory bank conflicts cause program slow batching strategy minimize number conflicts 
scheduler models beat bank stall window tracking memory cycle scheduled previous cycles 
memory selected scheduled call disambiguator compare memory scheduled current bank stall window 
bank conflict schedule 
definite bank conflict operation cycle 
possible bank conflict set aside lower priority operations considered cycle 
operations cycle considered revisit list possible bank conflicts 
control degree batching limiting number memory delayed favor lower priority 
limit exceeded reconsider memory set aside time regard possible memory bank conflicts 
main problem approach managing bank conflicts bug consider bank conflicts performing functional unit assignment consider bank conflicts forming final schedule 
means bug frequently assumes scheduling order dramatically different produced list scheduler causes poor functional unit assignments 
scheduler particular implementation bank scheduling flaws 
form equivalence classes explicitly tjs final compute schedule cycle 
means equivalence classes guide scheduling decisions correct moment 
case vector loops bank disambiguation mechanism reconstruct higher level information pattern memory communicated instruction scheduler directly 
pair mode series pair mode feature bit floating registers treated element single precision vectors results computed simultaneously 
coupled bit loads memory element vector operations generated 
doubles peak single precision performance machine applications exploit feature 
instruction scheduler supports pair mode making special pass dpg 
pairs operations dpg dpg depth 
single precision floating point operations memory candidates pairing 
order search operations pair memory 
disambiguator called ask 
address mod address address 
pair operations readers paired inputs paired store 
pair operations operands paired adds paired loads 
pair opportunistically dpg 
works loops aligned post conditioned memory loop iterations paired 
optimizations doing automatically completed 
pair mode feature tune benchmarks libraries house appropriate loop directives added hand 
feature widely applicable system supported bit memory mod byte boundaries 
machine model machine model compiler view architecture 
sole source machine specific information operation set encoded il 
compiler model machine abstracted actual hardware 
absence hardware resource management trace machines forces compiler machine model match hardware aspects precisely 
compiler models machines widths families series 
models built compiler single executable generate code machines 
components machine model machine elements resources connections 
machine elements functional units register banks constant generators 
different functional unit created pattern resource utilization set connections machine model functional unit hardware functional unit 
example series chips floating adder floating multiplier integer alu execute floating operation repertoire compiler models complex distinct functional units different resource patterns 
course functional units share common resource scheduled beat 
different register bank created set registers unique set connections functional units register banks 
different constant generator created width immediate field 
resources exist express limitations machine elements busses multiplier cores instruction words 
series modeled classes resources instruction word limits describe resources instruction encoding functional unit internal core limits floating point cores bus write port limits enumerate busses write ports machine virtual resources introduced tjs final compiler convenience 
example compiler introduced branch resource expressed primitives 
connections describe paths machine elements 
paths start register bank constant generator 
types connections functional unit sources destinations describe paths connecting functional units constant generators register banks copies describe paths register bank register bank constant generator register bank procedure linkage describe paths hardware link registers virtual paths pass values procedure call 
resources associated connections 
copy connections require functional unit scheduled treated specially instruction scheduler synthesizes scheduling 
calling sequence register partition modern risc runtime models register file divided partitions preserved scratch 
preserved registers preserved call scratch registers possibly changed call registers available general stack pointer zero register registers reserved operating system 
registers pass arguments scratch 
multiflow uses pure caller saves register partition register scratch registers available general 
originally implemented pure callee saves partition preserved registers 
unsatisfied performance partition switched caller saves 
change gave performance improvement procedure call intensive programs typically scientific applications 
changed argument passing memory registers time register design described 
change contributed speedup 
improvement explanations 
compiling parallelism requires registers sequential compilation want pay penalty procedure entry exit 
registers preserved lifetimes values registers typically cross function calls 
second saving restoring scratch registers intermixed operations call wide machine large amount memory bandwidth saves restores scheduled free 
trace scheduling selects traces priority order saving restoring registers moved frequently executed paths program 
contrast pure callee saves partition saving preserved registers occur procedure entry registers written 
similarly exit restoring preserved registers delayed operand registers read 
operations intermixed critical path 
retrospect wish kept integer preserved registers hold induction variables loop invariants referenced tight loops function calls 
see compelling need preserved floating registers 
argument passing multiflow uses registers cluster passing arguments returning values 
integer values double precision floating values passed returned registers 
larger argument lists return values overflow memory 
aggregates structures passed returned registers 
large number registers available procedure linkage allowed write time math library high performance linkage time functions 
fortran passes arguments registers overflow block 
supports modes passing arguments registers memory 
routines require arguments passed memory older programs 
routines prefer arguments passed registers performance 
provide ease port default pass arguments memory registers called procedure reads tjs final arguments memory required registers 
users request arguments passed registers linker checks caller callee pairs compatible 
passing arguments registers memory surprisingly small effect performance programs 
reason access arguments procedure entry critical path arguments read directly registers procedures 
storing arguments call site critical path scheduled alongside operations little cost 
addition series load pipeline long beats store pipeline short effectively zero data item stored 
disambiguator compile time memory analysis done vectorizing parallelizing compilers 
compilers want know loop loop nest vectorize parallelize interested knowing exists conflict iterations loop 
contrast trace scheduling compiler looking fine grained parallelism trace body unrolled loop 
want know load iteration move store previous iteration 
disambiguator queried phase phase 
optimizer performs location conflict analysis common subexpression elimination loop invariant motion allocation array elements register variables loops 
instruction scheduler analyze possible location conflicts possible bank conflicts 
example consider loop unrolled approximate source transformation compiler 

subroutine test 
double precision 






generate vliw code loop loads statements move stores statements 
particular disambiguator determine load refer location store iteration loop 
answer question constructs derivations addresses referenced store load asks derivations equal 
derivations symbolic equations terminals corresponding induction variables loop invariants 
array derivation address address subtract derivations see result equal zero 
simplifying get 
tjs final diophantine equation 
gcd test conclude integer solution addresses equal 
allows move load store scheduling code 
notice able solve equation knew value leading dimension lda unknown get lda lda 
equation solution example lda differ 
case program bounds dimension array 
lost dimension information expanding index polynomial 
avoid problem construct derivations index expression perform index index check analyzing pair memory location conflict 
checks fail analyze full addresses 
case index derivations dimension 
difference clearly equal 
disambiguator queries disambiguator answers questions location conflict ref ref 
ref ref possibly refer overlapping memory locations 
bank conflict ref ref 
ref ref possibly refer memory bank 
answers returns 
questions answered terms phase flow graph trace scheduling 
disambiguator model sequential execution program represented phase flow graph answer question pair dynamic instances ref ref executed crossing loop back edges 
prevent instruction scheduler asking question back edge permit trace cross back edge 
executed dynamic path disambiguator give meaningful answer 
consider example identical derivations clearly refer different memory locations value cond cond cond cond derivations derivation symbolic equation address memory terminals equation constants definitions sets definitions variables program 
derivations constructed walking recursively chain reaching definitions address 
example consider code fragment 

subroutine test 
double precision 


gt 


compiler default behavior 
fortran programs arrays dimension provide ability dis able index index check 
tjs final 



load statement refers address 
construct derivation walk tree reaching definitions stopping reach leaf tree reach operation able analyze equation solver reach variable multiple reaching definitions suggested 
example statement definition subroutine entry predecessors statement definition analyze division statement multiple reaching definitions 
substitute equation defining equation address load get derivation represents definition statement 
address derivation normalized canonical form arithmetic operations easily implemented 
derivation expressed sum products terminals reaching definitions sets reaching definitions packet seeds constants 
prevent derivation wrapping back edge loop insert derivation fences loop head 
derivation fence self assignment terminates recursive walk chain reaching definitions 
create derivation fence variables defined loop live entrance loop head 
includes induction variables 
derivations computed derivation fences removed flow graph 
packet checks asked location conflict ref ref disambiguator performs heuristic check referenced packets 
defined section packet represents group variables language defined storage relationship 
packet check unsuccessful uses equation solver compare derivations 
bank conflicts relevant packet information packet seed incorporated derivation skip packet check query equation solver directly 
packet checks test simple facts memory rule location conflict 
example direct distinct packets conflict different non overlapping variables packet 
pointer refer variable address taken 
template packets representing fortran arguments location referenced dynamic path flow graph store due restrictions placed fortran standard 
fortran array arguments frequently location practice 
handle provide way disable ansi restriction 
aliased array arguments refer exactly portions array added equal disjoint option handle case 
true compiler assume fortran array arguments refer array completely disjoint assumes refer different offsets array 
equal disjoint option sufficient applications encountered 
equation solver equation solver algorithmically simple 
location conflict want know address ref address ref 
answer question subtract derivations normalize result find gcd coefficients non constant terms check gcd divides constant term possible conflict 
tjs final bank conflict want know addresses possibly equal modulo number banks times number bytes word 
write address ref address ref 
integer answer question compute ignoring term 
fold computation gcd coefficients non constant terms effectively treating additional term coefficient gcd divides constant term possible conflict 
size alignment size alignment differ may different addresses conflict memory 
example consider fortran equivalence statement double precision integer equivalence overlaps second half difference addresses 
answer define window possible conflict size alignment check possibly located window 
disambiguator returns indicating may conflict 
applies location bank conflict 
assertions example pairs disambiguator answer questions derivations 
example sets array call fft routine 
performance code trace disappointing inner trace loop unrolling loads iteration move stores iteration forces sequential evaluation 
subroutine unpack real half odd odd tjs final temp odd temp odd temp odd temp temp temp odd return potential location conflicts stores loop body loads top loop body 
comparing store body loads top body disambiguator gives answers 
remember incremented bodies substituted incremented value second column 
body body disambiguator conflict conflict possible conflict conflict analyzing memory row disambiguator trying solve equation address address 
simplifying get 
integer solution 
programmer knows 
compiler provides assertion facility allows programmer tell compiler facts relationships program variables 
example assert equal loop head 
subroutine unpack real half mf 
assert le return loop unrolled assertion duplicated statements 
path store body third load body looks tjs final store body increment body assert assertion body 
load body substitute increment assert 
assertion rewritten directly answers question 
know equal zero location conflict 
compiler knew half generate assertion 
implemented optimization shortly multiflow closed experience 
definition types assertions eq ne gt ge lt le eq mod ne mod 
assert relationship integer pointer expressions 
assert modulus relationship expressions base modulus constant integer expression restricted powers 
modulus assertions useful asserting bank conflicts 
derivations constructed assertions memory 
normalize assertion construct derivation side subtract factor gcd non constant terms 
example assertion equivalent integers turn equivalent disambiguator uses 
discard useless assertions 
assertion useless trivially false trivially true 
gt ge lt le mapped gt commuting operands adding necessary 
induction variable simplification introduces deriv assign pseudo ops map strength reduced induction variables back original subscript expressions 
allows derivations refer original induction variables turn permits assertions applied ivs performed 
deriv assigns help loops assertions allow different induction variables compared regarded unrelated 
meaning assertion defined terms execution program 
asserted relationship assumed true point assertion executed program 
means assertion answering question memory dominates 
dominates executed generate code execute assertion 
allow program portability assertions represented fortran comments 
keep track assertions apply memory chain assertions apply point program 
chains form tree mirrors dominator tree flow graph 
applicable assertion exact match subtract derivation assertion derivation equation trying solve result constant 
assertion tjs final testing resulting constant 
faster theorem prover encountered real life examples restriction problem 
disambiguator trace scheduling instruction scheduler queries disambiguator contexts 
building data precedence graph dpg trace asks disambiguator location conflicts load store store load store store pairs trace 
minimize number questions edges dpg constructed disambiguator queried pairs constrained 
scheduling code instruction scheduler asks bank conflicts 
instruction scheduler models beat bank stall window placing memory queries disambiguator possible bank conflicts window 
window greater instruction instruction scheduler may need perform bank conflict analysis adjacent traces split trace rejoins 
permit record describing bank stall window associated split rejoin schedule trace 
motion splits instruction scheduler moves code splits 
location disambiguate loads moved split restrictions instruction scheduler 
instruction scheduler move operation split side effect affects trace path 
store move split load move split register variable written dead trace path 
disambiguation location conflicts involving load may incorrect executions take trace path precisely situations care value returned load 
bank stall feature trace allows instruction scheduler disambiguator heuristic bank conflicts memory moved split 
instruction scheduler assumes trace path followed run time 
bank disambiguation questions defined answers correct 
program jumps trace may take unexpected bank stalls 
experience shown disambiguator answer usually correct trace branch taken 
tracking motion splits thesis nicolau proved iteration trace scheduling algorithm pick trace schedule update flow graph flow graph path new flow graph corresponds path new path may contain extra operations results eventually discarded examination nicolau proof shows operations result motion splits 
induction see trace corresponds path phase flow graph extra operations moved split 
tracking motion splits identify operations may disambiguated correctly 
operation move split instruction scheduling trace scheduler creates compensation code 
happens instruction scheduling instruction scheduler aware motion queries disambiguator records fact record describing bank stall window split join 
operation moves split creating compensation code trace scheduler flags operation having moved split information preserved operation passed instruction scheduler copied 
competitive evaluation section compare trace contemporary systems convex mips 
summarize hardware characteristics systems 
second look relative performance mini supercomputer workloads 
third compare systems common ground synthetic scientific benchmarks 
prefer compare systems real tjs final applications large standard benchmarks spec suite 
systems sold largely non overlapping markets different important applications convex published spec results 
analytical model model captures ability compilers systems exploit operation level parallelism 
comparisons lead conclude vliw architecture trace scheduling compiler superior vector architecture single stream scientific problems 
vliw equal vector machine vector codes outperform floating point integer scalar codes 
systems applications instruction level parallelism exploited modest scale vliw 
sufficient overcome architectural organizational advantages risc system tuned types applications 
competitive system overview quite different processors designed different markets optimized different workloads 
summarizes characteristics compares 
convex vector processor 
mini supercomputer market leader direct competitor trace 
hardware technology generation ahead faster gate speed faster cycle time 
higher peak lower peak memory bandwidth 
data cache scalar bypassed vector 
convex excellent vector compiler technology 
scalar performance difficult characterize convex released standard scalar benchmarks integer 
year extended multiprocessor system processors 
concerned single processor performance focus 
mips mips microprocessor chipset fastest circa risc processor 
mips excellent compiler technology 
marketed network server 
designed maximize price performance general purpose workloads constraints chip cpu 
comparable cycle times 
trace data cache mips interleaved memory system 
load latency trace longer latency cache hit mips 
floating latencies roughly comparable mips floating units fully pipelined 
peak memory bandwidth lower 
unfortunately complete performance data section substitute performance data mips 
released shortly similar cache subsystem cycles ns ns 
trace convex mips processor year architecture vliw risc vector risc cycle time ns ns ns peak operation issue rates cycle ops memory ops floating ops bandwidth memory mb sec floating mflop sec latencies cycles measures vector unit 
tjs final load flop branch instruction cache size bytes instructions operations data cache bytes vector registers bytes number banks bank stall penalty beats summary trace convex mips performance mini supercomputer workloads mini supercomputers class computer systems designed primarily run simulation component computer aided design applications cad 
simulations embody theories techniques disciplines including physics mechanical engineering electrical engineering chemistry physics mathematical signal processing geology 
codes expressed simulations development time years cases grown quite large complex functional computer programs 
multiflow founded widely believed increase cad result tremendous increase demand high speed computers specifically designed run simulations 
early market systems attracted roughly companies intent delivering compute servers designed sell price range 
market analysts divided machines produced companies classes mini run existing simulation codes known decks little modification parallel processors require development new simulation codes 
convex mini super market leader followed alliant scs fps host 
multiflow late market managed break grow third largest vendor 
exhaustive exploration reasons multiflow relative success consider factors aren relevant relative financial viability believe essential reason multiflow managed technical quite relevant 
multiflow able architecture compiler technology exploit fine grained parallelism simulation codes way vendors ability fostered success albeit limited temporary success 
contains set benchmark times drawn mini supercomputer workload mechanical engineering computational chemistry signal processing applications 
large commercial packages approximately source lines performing structural analysis finite element method 
similar worth considering separately respective developers quite different policies allowing modifications computer systems vendors vendor swanson analysis allows vendors virtually unlimited time port consider quite extensive modifications extensions source convex replaced simultaneous equation solver line package vendor typically allows vendors access application source code accepts limited modifications 
relative performance better due deck nature 
gaussian computational chemistry package roughly lines ab initio molecular modeling 
amber molecular mechanics dynamics program semi empirical electronic structure calculation program performs ray crystallography calculations 
outperforms chemistry codes 
tjs final application signal processing kernel performs single precision complex fast fourier transforms varying sizes 
handcoded subroutine libraries application vliw architecture better match needs fft algorithm fully utilizes memory floating point bandwidth 
benchmark test trace convex name case mechanical engineering seconds computational chemistry seconds gaussian amber case case case scf columbia signal processing milliseconds elem elem elem performance mini super workload vs 
tjs final win loss relative performance vs 
graphically summarizes performance data 
benchmarks listed abscissa square plotted point ordinate represents percentage faster slower 
percentages computed symmetrically 
suppose example ran application seconds ran seconds percentage ran seconds percentage 
hardware technology generation manages eke rough single processor performance parity 
performance parity guarantee market success 
multiflow series due late expected achieve performance step convex series built gallium delivered late achieved performance step vector codes 
series processor twice performance processor 
mini supercomputer applications suited multiprocessing 
lack multiprocessing weakness particularly competitive situations convex 
series introduced dual processor capability fully configured machine run dual processor wide single processor wide 
performance synthetic scientific workloads case columbia case case scf mechanical engineering chemistry signal proc linpack livermore fortran kernels standard scientific kernel benchmarks mini supercomputers risc systems 
benchmarks small received large amount attention vendor indicative peak system performance tuned code 
shows circa results benchmarks trace convex mips 
tjs final benchmark test trace convex mips name case livermore fortran kernels means average geometric harmonic linpack synthetic scientific workload tjs final win loss harm geo ave livermore fortran kernels comparison performance vs square vs triangle 
comparison ordered left right relative performance vs 
graphically compares performance results 
relative performance varies traditional scalar vector mix help clarify trend results sorted left right vector performance vs scalar 
left side chart shows relative performance vs scalar codes right hand side compares performance vectorizable codes 
twelve vectorizable taken measure scalar floating point performance twelve vectorizable taken measure vector floating point performance scalar vector floating point harmonic mean mega flops follows scalar fp vector fp comparing systems pairwise shows faster scalar floating point processor faster vector floating processor quite vector processor 
vs vs vs scalar fp vector fp differences implementation technologies factored normalizing machines linearly cycle time sees relative performance tjs final vs vs vs scalar fp vector fp normalized substantially faster scalar floating point processor better vector processor slightly better vector processor 
far outperforms vector floating point fast scalar floating point engine 
analyzing parallelism general purpose workloads fall authors worked joel emer digital equipment richard multiflow computer create performance analysis trace machines 
developed performance model compare trace mips 
analysis measured achieved parallelism trace mips set benchmarks 
discovered trace compiler significant parallelism code averaging scheduled operations flight runs entire programs 
performance model performance model defines execution time program product cycles executed cycle time 
cycles executed partitioned scheduled cycles compiler static schedule cpu pipeline dynamic cycles dynamic stalls introduced memory system 
scheduled cycles dynamic cycles cycle time equation rewritten follows dynamic cycles expressed overhead factor scheduled cycles expressed terms scheduled parallelism 
execution time number operations average scheduled parallelism ops scheduled cycle cycles include compile time interlocks ignore dynamic stalls due memory system execution overhead cache stall cache stall bank stall cycle time scheduled parallelism rewritten ratio scheduled operations flight average scheduled latency little law 
exposing latency measure parallelism compiler finding average number scheduled operations flight 
scheduled operations flight average scheduled latency substituting get final equation analysis equation identifies key components single processor performance 
tjs final cycle time 
number operations executed 
average latency operations ignoring effects memory system 
instruction level parallelism 
overhead memory system 
highlights fact operation issue rate latency operations contribute equally parallelism particular latency operations increases compiler find parallelism performance system remain 
described superscalar 
gathering data techniques gather data 
time 
execution time measured running programs stand systems 
cycle time known machine confirmed simple timing loops 
scheduled cycles 
mips pixie tool instrument mips executable measure scheduled cycles 
wrote similar tool multiflow 
tools measure total number scheduled cycles ignoring memory effects total number operations executed dynamic distribution operations opcode number operations direct output pixie 
scheduled cycles scheduled cycles measured pixie 
op latency op count op count dynamic count type operation direct output pixie op latency latency type operation published architecture manuals machines 
dynamic cycles 
computed scheduled cycles scheduled cycles scheduled cycles multiflow trace measure component parts 
hardware counters measured stall due bank conflicts instruction cache mips partition dynamic cycles data cache instruction cache programs measured classes programs shown 
spec benchmarks addition linpack known vector benchmark grep version unix utility tuned multiflow machine 
linpack modeled source blocking transformation multiflow optimizer performing mips optimizer compiled ran blocked linpack machines 
tjs final vector floating linpack gaussian elimination tomcatv fluid flow analysis scalar floating doduc nuclear calculations fpppp quantum chemistry spice circuit simulator vector integer grep unix pattern search eqntott cad tool convert boolean equations truth table scalar integer li lisp interpreter gcc compiler espresso cad tool pla generator optimizer benchmark programs results complete set results shown 
operations reported millions cycles reported nanoseconds time reported seconds 
benchmark ns espresso gcc li eqntott grep doduc fpppp spice linpack tomcatv benchmark performance benchmark ns espresso gcc li eqntott grep doduc fpppp spice linpack tomcatv benchmark performance tjs final benchmark ns espresso gcc li eqntott grep doduc fpppp spice linpack tomcatv speedup benchmark ic bank stall espresso gcc li eqntott grep doduc fpppp spice linpack tomcatv decomposition aggregate results normalizing program seconds runtime mips prevents bias vectors programs run faster multiflow machine 
presents aggregate summary 
rows model data mips trace bottom row presents ratio performance 
average trace machine faster mips 
biggest contributor speed scheduled ops flight 
average trace maintained scheduled operations flight 
average operation latency mips multiflow machine dynamic overhead memory system 
ns speedup normalized aggregate benchmarks comparison yields dramatically different results depending workload 
workload speedup scalar integer vector integer scalar floating point vector floating point speedup workload tjs final presents results vector programs 
trace faster mips 
largest factor due scheduled operations flight 
trace averages scheduled operations flight benchmarks 
significant achievement just measuring inner loops entire run program 
large factor performance differential memory system overhead twice speed 
advantage largely offset shorter scheduled latencies mips due data cache 
large number extra operations performed mips due lack double precision load store operations 
ns speedup aggregate vector floating linpack tomcatv presents results scalar floating programs 
trace outperforms mips factor 
performance differential due parallelism achieved compiler 
presents results vector integer programs 
trace compiler finds significant amount scheduled parallelism accounts factor performance advantage 
ns speedup aggregate scalar floating doduc fpppp spice ns speedup aggregate vector integer programs grep eqntott presents results scalar integer programs 
slower 
largely due reasons 
trace executes large number additional operations 
partially explained architectural differences machines multiflow trace bit bit memory operations branch equal 
tasks require operation sequences trace done operation mips 
second data cache mips significantly lowers average scheduled latency operations 
offsets scheduled parallelism trace compiler 
ns speedup aggregate scalar integer programs espresso gcc li presents scheduled operations flight measured benchmarks 
programs measured trace compiler finds significant amount parallelism relative risc machine 
tjs final ops flight cycle operations flight cycle compiler evaluation displaying dpg gcc li espresso spice doduc course developing compiler directed acyclic graph drawer display dpg constructed instruction scheduler 
drawings graphically display parallelism exposed compiler 
dags nodes operations solid lines operand edges dotted lines constraining edges memory conflicts 
inputs dpg drawn top dag outputs bottom 
looking various compilations daxpy illustrate effectiveness loop unrolling strategy 
show inner trace daxpy loop unrolling 
little parallelism single loop body 
shows inner trace daxpy 
graph clearly illustrates parallelism vector kernel 
shows daxpy unrolled loop exits left trace compiler default 
shows equal amount parallelism daxpy exception constraint stores preceding loop exit 
shows daxpy unrolled traditional optimizations applied multiflow optimizations eliminate dependencies unrolled loop bodies performed 
amount parallelism heavily constrained 
vector kernels multiflow compiler effectively eliminates dependencies loop bodies due induction variables resulting unrolled loop parallelism 
tjs final grep eqntott fpppp linpack tomcatv dy dy da dx trace add add add add ld ld add fmul add st trace inner trace daxpy unrolling ld ld ld ld ld ld ld ld ld ld ld ld ld ld ld ld add add fmul fmul fmul fmul add fmul fmul fmul fmul inner trace daxpy inner trace daxpy unrolled add add add add add add add add st st st st st st st st trace ld ld ld ld ld ld ld ld ld ld ld ld ld ld ld ld rel rel rel rel rel rel rel fmul fmul fmul fmul add fmul fmul fmul fmul leq tjs final add add add add add add add add add st leq leq st leq st st leq leq st st leq st add st add add add add add add inner trace daxpy unrolled traditional optimization shows large amount parallelism vectorizable kernel livermore loops 
unrolled times default 
stores constrained exit tests limitation parallelism 
shows surprising amount parallelism inner trace livermore kernel unrolled times compiler 
control flow loop body appears inhibit parallelism feedback previous runs compiler unroll loop select dominant path 
loop zx zx kernel trace add ld ld add add add add add fmul add add add add ld ld add add add add add add ld ld fmul add st add add add add ld ld fmul add add add add add add ld ld fmul add st add add add add add ld ld fmul add st add add add add add ld ld fmul add st ld ld fmul add st fmul add st add st st trace tjs final ii lb ii ii loop zone ii lb plan plan plan zone zone zone continue continue continue continue kernel trace tjs final shows parallelism inner trace recursive program inlining large kernels significant amount 
queens problem try int int false 
false false false false try true true true true tjs final queens compile speed trace rel add ld eqt sub add add leq add leq st ld ld ld st leq leq leq leq st st st st st st st st multiflow compiler slow 
measure speed compiler developed compile speed metric line fortran program composed routines culled various applications combined single file 
comments blank lines stripped file line source line 
results compiling metric shown 
chart presents speed compiling metric multiflow fortran compiler running multiflow targeting widths series optimizer 
presents speed native mips compiler running decstation 
mips slightly faster 
demonstrated section mips somewhat faster systems applications 
compile speed lines minute mips optimized checkout performance ratio mips optimized checkout compile speed fortran metric tjs final st xa ld leq st st st factors contribute slow speed compiler 
foremost design decision implementation ambitious nature project separated major phases compiler narrow functional interfaces 
result source program built multiflow compiler passed distinct representations information recomputed stage pcc trees front flow graph il passed optimizer flow graph il produced optimizer flow graph built trace scheduler dpg built code generator machine level representation built emit code 
overhead interfaces multiple representations shows speed checkout compiler times slower checkout compiler decstation 
checkout compiler bypasses trace scheduler substitutes code generator program compiled representations 
factor compile speed amount unrolling compiler performs width target machine 
ratio optimized decstation compile speed compilation roughly ratio checkout compiler speeds 
arguably compile speed problem entirely explained interface overhead 
slower slower 
unroll heavily wider machines instruction scheduler functional units register banks consider 
third factor compile speed algorithms compiler 
compared compilers optimizer performs repeated analysis optimizations uses expensive algorithms 
particular common subexpression loop invariant implementation slower partial redundancy algorithm mips compiler reif tarjan algorithm 
addition instruction scheduler schedules longer sections code wider machine mips compiler scheduling passes 
attention paid complexity scheduling algorithms constant factors large 
trace scheduler implemented efficiently flow graph nodes individual operations basic blocks 
final factor compile speed coding style compiler 
high level object oriented style particularly trace scheduler code generator lisp style 
high level style enabled write large program small number engineers contributed memory usage speed result 
retrospect formed opinions 
fine grained parallelism practical 
fine grained parallel processor effectively scheduled compiler relatively little input applications programmer 
multiflow developed system exploiting fine grained parallelism scientific applications 
particularly systems applications applications written style language compile time memory dependency analysis difficult 
limitations due design goals system 
machines designed explicitly provide largest possible potential parallel speedup 
design tradeoffs arose cost latency performance sequential code traded away issue execute bandwidth ability achieve high speeds parallel codes 
compiler able find significant amounts static parallelism systems applications believe relatively simple implementations current risc instruction set architectures designed exploit parallelism 
tjs final trace architecture implementation 
fast cycle time important 
wide cluster nice balance functional units exploited compiler 
authors pursuing similar designs considerably faster cycle times 
value wider machines questionable 
poor connectivity difficult effectively parallel code 
appears codes effectively addressed traditional vector parallel computers 
wide machine better connectivity may widely applicable 
better connectivity particularly register files important narrower machines 
reducing latency operations helps 
primary incentives series reduce latency floating point operations 
data cache nice possible implement coherent highly correlated memory access streams 
wise limit amount processor organizational detail defined architecture 
compiler schedule underlying organization order maximize performance clear relatively narrow vliw organization simple stable superscalar style risc architecture 
speculative execution important 
reach wider acceptance better solution exceptions speculative operations need discovered 
multiflow customer complained exception behavior optimized program 
select operation idea 
predicated features conditional store conditional flop operations series added machines 
compiler scheduling bank conflicts works reasonably 
bank stalls major drag performance memory system highly interleaved long compiler batches avoid risking stall 
multiflow card conflict scheme works poorly limits usable memory bandwidth vectors unknown stride 
fixed series design card conflicts cause beat stall program error 
multiflow trace machines designed compiler model machine 
successful scientific applications focus design compiler machine formed effective system delivering performance 
trace compiler 
trace scheduling worked 
algorithm simple described 
surprised way compilers 
measured effectiveness speculative execution 
extension consider multiple control flow paths suggested idea trace algorithm described improvement basic block schedulers 
feedback directed compilation profitable 
integrated register allocation instruction scheduling strategy implements important ideas 
high priority allocating registers frequently executed regions code described hierarchical coloring captures idea 
second registers critical resource need scheduled machine resources 
question pass schedule allocate schedule algorithms ibm hp compilers extend parallel machines 
machines large amounts instruction level parallelism effectively utilize calling sequence register partition large number scratch registers 
greedy schedulers scale high degrees parallelism 
tjs final weakness loop strategy unrolling done independently instruction scheduler 
independence coupled complicated topology wide machines performance compiler somewhat fragile unroll times performance loop may drop 
software may able address problem directly 
clear software pipelining practical machine constraints wide trace machines particularly multiple register banks pipeline resource contention compiler managed memory interleaving 
compiler management memory system works reasonably feel done better job designing implementation 
approach directly applicable cache memory systems high performance risc machines regardless execute instructions parallel 
batch avoid conflicts machines want group cache line avoid possible 
disambiguator effective fortran programs programs pointers 
significant drag compile speed originally feared 
assertion mechanism designed difficult customers wanted eventually provided 
multiflow compiler high level loop transformations loop interchange loop splitting loop fusion outer loop unrolling unroll jam performed best vector compilers 
major weakness product 
difficult find parallelism fill wide machines 
widespread kuck associates pre processor demonstrates value transformations machines trace benefited 
highly vectorizable codes multiflow compiler deliver peak speed machine requires tuning vector compiler 
non vectorizable codes potential parallelism multiflow compiler better compiler instruction level parallel machines 
tjs final multiflow compiler people 
john ellis employee multiflow bulldog compiler got running start coding style set high standard live 
engineering team led john geoff lowney focusing instruction scheduler lowney focusing trace scheduler early phases compiler 
il designed tom geoff lowney mike ward stefan freudenberger implemented freudenberger 
joe wrote il interpreter compiler debug 
front implemented mike ward 
fortran front implemented mike ward cindy collins jose marshall bob nix 
fortran libraries designed cindy collins implemented collins ellen 
time math library designed implemented woody lichtenstein malik lee campbell 
chandra joshi doug gilmore david chris wrote math functions 
tom designed implemented optimizer assisted ray ellis 
woody lichtenstein contributed design reductions 
stefan freudenberger designed implemented cse code expansions 
geoff lowney designed implemented trace scheduler thomas gross mike ward added copy suppression optimization 
john stefan freudenberger designed implemented instruction scheduler machine model 
woody lichtenstein worked extensions necessary get performance wider machines 
cindy collins contributed implementation pair mode optimization partial schedules 
cindy collins original retarget compiler series david original retarget series stefan freudenberger polished 
tom invented delayed binding algorithm contributions john actual implementation 
tom designed implemented disambiguator 
jim wrote checkout code generator 
enhanced linker 
ben cutler wrote assemblers instruction set simulators trace models 
wrote trap code 
chris wrote debugger ray ellis brian wrote profiling tools 
dan wrote static resource checker 
pat clancy implemented icache optimizer linker 
joe implemented dag drawer draw figures section enhanced stefan freudenberger bob nix 
rich wrote experiments reported section 
taught honest way cheat linpack 
bob nix john donnell led wide performance war gave detailed feedback quality compiler 
cindy collins designed test system joe wrote original tests 
neda managed testing releases 
multiflow compiler technology purchased intel hewlett packard digital equipment fujitsu hughes hal computer silicon graphics 

josh fisher encouraged write 
rich john ellis michael adler provided detailed reviews early drafts 
tjs final bibliography aho alfred jeffery ullman principles compiler design addison wesley publishing reading mass 
aiken alexander alexandru nicolau 
optimal loop parallelization 
proceedings sigplan conference programming language design implementation 
atlanta georgia june pp 

allen carter fabri ferrante harrison experimental compiling system ibm journal research development november pp 
allen john ken kennedy 
automatic loop interchange 
proc 
acm sigplan symposium compiler construction montreal june 
acm new york pp 
allen randy ken kennedy 
automatic translation fortran programs vector form 
acm transactions programming languages systems october pp 
american national standard programming language fortran american national standards institute new york new york data dependence ordinary programs 
thesis university illinois urbana champaign department computer science report november 
speedup ordinary programs 
ph thesis university illinois urbana champaign department computer science report october 
callahan david steve carr ken kennedy improving register allocation subscripted variables 
acm sigplan conference programming language design implementation 
white plains ny june 
pp 
callahan koblenz register allocation hierarchical graph coloring 
proc 
acm sigplan conf 
programming language design implementation toronto june 
acm new york pp 

chaitin auslander chandra cocke hopkins markstein register allocation coloring 
comput 
lang 
january pp 

chaitin register allocation spilling graph coloring 
proc 
acm sigplan symposium compiler construction boston june 
acm new york pp 
mike gary jim steve wallach 
convex architecture 
ieee supercomputing conference pp 

chow frederick portable machine independent global optimizer design measurements 
technical report computer systems laboratory stanford university 
chow killian weber 
addressing modes 
proceedings second international conference architectural support programming languages operating systems asplos ii 
palo alto ca october 
chow killian weber 
engineering risc compiler system 
ieee compcon 
chow frederick john hennessy 
register allocation priority coloring 
proc 
acm sigplan symposium compiler construction montreal june 
acm new york pp 

chow hennessy priority coloring approach register allocation 
acm trans 
program 
lang 
syst 
october pp 

tjs final nix donnell rodman vliw architecture trace scheduling compiler ieee trans 
comput vol pp 
august 
hall joshi rodman architecture implementation vliw supercomputer proceedings ieee acm supercomputing october pp 

james peter 
hsu joseph bratt 
overlapped loop support 
third international conference architectural support programming languages operating systems boston massachusetts april 
pp 

dongarra jack performance various computers standard linear equations software 
cs computer science department university tennessee september 
ellis john bulldog compiler vliw architectures 
mit press cambridge ma 
ph thesis yale univ new haven conn february 
ferrante jeanne karl ottenstein joe warren 
program dependence graph optimization acm transactions programming languages systems july pp 

feldman stuart implementation portable compiler modern tools proceedings sigplan symposium compiler construction august pp 

fisher joseph optimization horizontal microcode basic blocks application processor scheduling resources 
ph thesis new york univ new york 
fisher joseph trace scheduling technique global microcode compaction 
ieee transactions computers july 
fisher joseph 
ellis john john 
nicolau alexandru 
parallel processing smart compiler dumb machine 
proc 
acm sigplan symp 
compiler construction montreal june 
acm new york pp 

foster riseman percolation code enhance parallel dispatching execution ieee trans 
comput vol pp 
freudenberger phase ordering register allocation instruction scheduling 
code generation concepts tools techniques edited robert susan graham 
springer verlag london 
gibbons phillip steven efficient instruction scheduling pipelined architecture 
proceedings sigplan symposium compiler construction 
palo alto ca june pp 

gross thomas 
code optimization pipeline constraints 
technical report 
computer systems laboratory stanford university december 
gross ward suppression compensation code 
proceedings third workshop languages compilers parallel processing irvine august pp 
hennessy gross 
postpass code optimization pipeline constraints 
acm transactions programming languages systems july 
mark compiler tail ends 
tutorial notes sigplan conference programming language design implementation june 
ibm rs assembler language order number sc ibm 
johnson tour portable compiler 
bell laboratories murray hill nj 
jouppi norman david wall 
available instruction level parallelism superscalar machines 
third international conference architectural support programming languages operating systems boston massachusetts april 
pp 
tjs final joshi chandra brad john 
memory system statically scheduled supercomputer 
international conference parallel processing vol pp 

kane gerry 
mips risc architecture 
prentice hall englewood cliffs nj 

kernighan brian 
ritchie dennis programming language prentice hall englewood cliffs 
knuth donald knuth 
algorithms 
art computer programming volume second edition 
addison wesley publishing reading mass 
kuck kuhn padua wolfe 
dependence graphs compiler optimizations 
eighth annual acm symposium principles programming languages 
williamsburg virginia january pp 

lam monica 
software pipelining effective scheduling technique vliw machines 
proceedings sigplan conference programming design implementation 
atlanta georgia june 
pp 

lam monica systolic array optimizing compiler kluwer academic publishers boston ma 
joseph compaction generalization trace scheduling increase global context information 
proceedings th annual microprogramming workshop october 
pp 

joseph horizontal microcode compaction 
microprogramming firmware engineering methods edited stanley 
van nostrand reinhold new york pp 

little proof queuing formula dw opns 
res 
may pp 

cited edward coffman jr peter denning 
operating systems theory prentice hall englewood cliffs new jersey 
olaf supercomputer performance theory practice results 
la ms los alamos national laboratory los alamos new mexico january 
mcmahon frank livermore fortran kernels computer test numerical performance range 
lawrence livermore national laboratory university california livermore california december 
mercer randall 
convex fortran compiler 
proceedings supercomputing international supercomputing institute st petersburg florida 
morel renvoise 
global optimization suppression partial redundancies communications acm february pp 
nicolau alexandru joseph fisher 
oracle measure parallelism single instruction stream programs 
th annual microprogramming workshop october pp 

nicolau alexandru 
parallelism memory anti aliasing correctness trace scheduling compilers 
ph thesis yale univ new haven conn 
brien kevin bill hay hartmann schaffer bob schloss shepherd advanced compiler technology risc system architecture 
ibm risc system technology ibm pp 

robert hansen mark 
architecture compiler enhancements pa risc workstations 
ieee compcon spring pp 

pa risc procedure calling convention manual order number hewlett packard 
padua david michael wolfe 
advanced compiler optimizations supercomputers 
communications acm december pp 
tjs final pettis karl robert hansen profile guided code positioning 
acm sigplan conference programming language design implementation 
white plains ny june 
pp 
rau 
scheduling techniques easily schedulable horizontal architecture high performance scientific computing 
proceedings fourteenth annual microprogramming workshop october pp 

rau ramakrishna david yen wei yen ross 
departmental supercomputer design philosophies decisions trade offs 
ieee computer january pp 

reif john combinatorial aspects symbolic program analysis tr center research computing technology cambridge massachusetts 
reif john code motion 
siam journal computing may pp 

reif john tarjan 
symbolic analysis linear time 
siam journal computing february rodman paul 
high performance ffts vliw architecture 
symposium computer architecture digital signal processing hong kong 
iee hong kong centre gpo box hong kong 
spec newsletter fall associates ca 
thornton design computer control data 
il scott 
lee schlansker 
parallelization loops exits pipelined architectures 
proceedings supercomputing new york november 
ieee computer society press los ca 
pp 

flynn detection parallel execution independent instructions 
ieee trans 
comput vol pp 
oct 
efficient algorithm exploiting multiple arithmetic units computer structures principles examples 
new york mcgraw hill pp 

wall david limits instruction level parallelism 
fourth international conference architectural support programming languages operating systems santa clara california april 
pp 
warren instruction scheduling ibm risc system processor 
ibm journal research development january pp 
wolfe michael 
optimizing supercompilers supercomputers 
mit press cambridge massachusetts 
tjs final 
