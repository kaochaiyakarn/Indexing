international journal computing information sciences vol april line lip localization viseme classification visual speech recognition walid ben lip localization viseme classification visual speech recognition walid ben multimedia information systems advanced computing laboratory higher institute computer science multimedia yahoo fr walid tn need automatic lip reading system increasing 
infact today extraction reliable analysis facial movements important part multimedia systems videoconference low communication systems lip reading systems 
addition visual information imperative people special needs 
imagine example dependent person ordering machine easy lip movement simple syllable pronunciation 
people hearing problems compensate special needs lip reading listening person talking 
new approach automatically localize lip feature points speaker face carry spatial temporal tracking points 
extracted visual information classified order recognize uttered viseme visual phoneme 
developed automatic lip feature extraction prototype alife 
experiments revealed system recognizes french vowels uttered multiple speakers female male natural conditions 
keywords visual information lip reading system human machine interaction lip spatial temporal tracking 

received may revised july accepted september visual speech cues play important role human speech perception especially noisy environments 
phenomena perceptive illusions speakers confronted auditory stimuli ba visual stimuli ga perceive stimuli da cocktail party effect attention centered special speaker surrounded multiple speakers time show significance visual information speech perception 
context works literature oldest ones proved movements mouth speech recognition channels 
recognizing content speech observing speaker lip movements called lip reading 
requires converting mouth movements reliable mathematical index possible visual recognition 
thematic alife automatic lip feature extraction system appears 
alife allows visual speech recognition video locution sequence 
precisely implements approach composed steps proceeds localizing lips tracking 
secondly extracts precise pertinent visual features speaker face 
extracted features visemes visual phoneme classification recognition 
alife beta version system covers totality visual speech recognition steps shown 
camera lip localization lip tracking visual features extraction speech unit recognition 
overview complete alife system speech recognition section overview visual speech recognition labial segmentation methods currently proposed literature 
section international journal computing information sciences vol april line details lip localization lip tracking methods 
section different features recognition stage different stage alife viseme classification recognition system 
section evaluate lip tracking method comparing tracking approaches 
secondly alife system visual recognition viseme corpus 
rates viseme recognition matrix confusion visemes shown 
conclude summary current state 

visual speech recognition labial segmentation methods overview human perception world inherently multisensory information provided multimodal 
perception spoken language exception 
auditory information visual speech information provided facial movements result moving articulators speech production 
complementary nature visual auditory percepts speech comprehension pushed research teams automatic speech recognition asr visual channel 
sub sections discuss different methods evoked literature labial segmentation visual speech recognition systems 
labial segmentation methods research works stressed objectives research automatic semiautomatic methods extraction visual indices necessary recognize visual speech lip reading 
types approaches lipreading depending descriptors recognition visemes low level approach image approaches controlled data directly image mouth region 
approach supposes lip pixels different feature compared ones skin pixels 
theoretically segmentation done identifying separating lips skin classes 
practice methods type allow rapid locations interest zones simple measures width height lips example 
permit carry precise detection lip edges 
high level approach model approaches directed physical extraction distance uses model 
example mention active edges widely lip segmentation 
approaches exploit pixel information image integrate regularity constraints 
big techniques allows easily adapted variety forms 
property interesting matter segmenting objects form predicted advance vessels clouds appears handicap object structure known mouth face hand 
visual speech recognition system approaches speech modeling features modeling techniques widely acoustic speech recognition 
template matching static images simple method visual speech recognition 
comparison features extracted static images stored templates 
approaches ignore temporal evolution features assume image representing important features utterance captured image sequence 
petajan compared extracted sequence geometric parameters stored templates feature sequences 
time wrapping align sequences 
system extended vector quantization dynamic time warping dtw 
quantized images dtw algorithm find best path unknown sequence stored template 
disadvantages dtw speech modeling techniques distance measures features 
measures don consider feature distribution temporal modeling specific heuristic penalties 
petajan system extended continuous system discrete hmm hidden markov model 
distinct viseme groups determined hmm similarity metric clustering algorithm 
system reported bregler modular time delay neural network tdnn consists input layer hidden layer phone state layer 
network trained back propagation 
bergler described connectionist approach combining acoustic visual information hybrid multi layer perceptron mlp hmm speech recognition system 
audio visual data mlp trained estimate posterior probabilities phonemes 
likelihoods obtained posterior probabilities emission probabilities hmm 
tokuda continuous density hmm method 
ordinary approach conventional normalization provide criterion independently hmm apply normalization learning 
approach normalization ml maximum likelihood criterion considered 
normalized training proposed way normalization processes elements position size inclination mean brightness contrast lips integrated training model 
lip localization viseme classification visual speech recognition discussion potamianos matthews proved image approaches allowed better performances terms recognition rates image approaches different conditions 
hand promising methods labial segmentation model approaches lip models 
proceeds detecting full contour lips necessary doubt interest extraction labial contours entirety recognition stage 
speech specialists pertinent features verbal communication expression heights widths inter labial surface 
interpretation notice judicious opt extraction method features detection tracking points interest poi sufficient characterize labial movements 
problem labial segmentation detect poi lips track speech sequence 
sections new hybrid approach lip feature extraction 
approach applies stage active contour method automatically localize lip feature points speaker face 
second stage propose spatial temporal tracking method points freeman coding directions voting techniques 
poi tracking carry visual information describing lip movements locution video sequence 
visual information classify recognize uttered viseme 

alife lip poi localization tracking phase start localization external contours lips image video sequence 
identify contours set poi followed video locution sequence 
problems lip poi localization poi tracking video sequence 
details approach sections 
lip poi localization approach lip poi localization proceed detecting lip contour secondly contour identify set poi 
efficient solutions detect lip contour lip region active contour techniques commonly named snakes 
technique appeared mid conjoined works kass witkin terzopoulos physical constraint model picture treatment 
method meets lot successes capacity mix classic stages detection contours extraction chaining 
active contours snakes deformable curves evolving order minimize functional energy associated 
move image initial position final configuration depends influence various terms energy 
snake energy consists internal energy named regularization smoothing energy external energy data adequacy 
snake detection active contour method consists placing detected shape initial line contour 
line deforms progressively action strengths push shape 
implied strengths derived energies associated snake exclusive energy due contour shape called internal energy eint 
potential energy imposed image 
energy attracts snake line real contours image 
energy expresses supplementary constraints imposed user 
objective localize different poi lips speaker face frame video sequence 
definition different energy terms necessary take consideration objective description 

different poi extraction core contribution active contour technique applied just frame video sequence addition cont direction snake evolution 
follows adapt terms energies problem 
details lip localization approach accessible 
energies defined follows 
consider snake composed vi points parameter spatial evolution contours picture example curvilinear abscissa 
international journal computing information sciences vol april line internal energy eint going depend shape snake 
regularity constraint curve 
calculate equation 
int equation respectively weights second derivative 
adjust find flexible contour able wedge corners sharp angles corners bow regular contour follow contour false alarm 
potential energy imposed image characterized strong gradient depicted equation 
ext equation fort gradient 
original image gradient image constraint energy defined user specificities problem 
cores contribution definition 
aims pushing evolution snake gravity centre xg yg active contour 
represents euclidian distance vi computed follows cont equation xs ys xg yg respective cartesian coordinates snake points gravity center snake 
principal goal energy ensure evolution snake picture zones having weak gradient 
total energy snake total energy point vi snake calculated follows ei tot int ext equation cont total energy snake tot computed equation tot ei tot ei int ei ext equation ei cont 

snake directional energy principle definition terms active contour energy snake going evolve progressively order minimize total energy 
snake progression reaches minimal value attending fixed number iterations 
experimentation method 

snake evolution energy minimisation principle snake progression stopped reaches minimum value external contours lips extracted proceed detection initialization different poi 
employ word initialization poi entries tracking step 
intend employ technique projection horizontal vertical various points snake detect different poi 
precisely maximum projection horizontal axis indicates position corners lips maximum projection vertical axis indicate position lower lip points form arc cupid 
illustrates localization process 
lip localization viseme classification visual speech recognition 
points interest detection projection final contour horizontal vertical axis poi tracking video sequence problem poi tracking context poi defined block size pixels detect poi successive images video sequence 
problem consists looking block image maximum similarity block detected image knowing number image video sequence number block define different poi 
shows example poi tracking different images sequence 

example tracking poi successive image initialized image detection different poi image sequence literature find methods searching tracking pattern video sequence 
approaches advocated various authors fewer comparisons 
generally different methods confronted dilemma high low precision delicate problem difficult find compromise criteria 
distinguish disadvantages methods template matching 
resume disadvantages points energy image varies position search model fail 
example correlation regions looked model inferior correlation model effect luminance 
methods depend enormously size model 
sensitive abrupt luminance variation occur video sequence 
serious disadvantage problematic lip movement cause big variation luminance mouth region 
clearly notice search method model applicable cases judge sufficient convincing problematic details important movements rapid luminance variations susceptible especially poi concerns inferior lip 
lead decided different approach poi tracking study 
approach poi tracking template matching technique take spatial temporal indices video account 
principle approach consists seeking gray level image gi similar block block pattern forming point interest poi defined section 
originality technique labial movement tracking lies case limited set poi 
algorithm tracking principle steps poi tracking done different directions freeman coding localize candidate points describing potential poi movements second steps vote technique identify candidate points corresponds better origin poi 

poi tracking freeman coding order follow better lips movements suppose head speaker respect camera 
head problem resolved fixed camera 
today video conference cameras capture centered shot labial zone 
shows headset project synthesis clone conceived 

headset project synthesis clone conceived dia assumption avoid camera movement problems focus objective tracking algorithm lip movements complex fast especially directions 
different directions easily represented directions freeman coding principle consists presenting connection successive pixels 
international journal computing information sciences vol april line 
different directions freeman coding pn poi pm point describing potential movement pn displacement pn pm done possible directions coding freeman 
order increase precision technique poi movement predictions spread research candidate points poi set pm points located directions freeman coding ray points number block direction 
experimentation set value 
illustrates principle 
number blocks direction 
different research directions coding freeman ray points 
technical research voting principle contribution tracking approach voting system selection similar block pattern block 
major stages constitute voting system step consists calculating list measures bn gray level candidate blocks model search potential point 
bn values saved accumulator treated second part approach 
accumulator yw 
bn bn xw yw bn block size 
accumulator table luminance measure different candidate blocks second step add accumulator new columns stock number voices block vote block having maximum voices 
calculate luminance variation measure similarity ssd ncc 
case calculate follows 
accumulator nb 
voice xw bm bm xw block elected research model bn bn xw 
accumulator table luminance measure vote principle equation bn luminance variation measure pixel block bn poi respective pixel original poi 
number image sequence 
gi luminance model looked 
fi luminance image research model 
votes attributed algorithm min acc initialization minimal distance column research minimal distance column number different directions freeman coding number blocks direction block size acc min min acc endif enddo attribution voices blocks having minimal distance column direction acc min acc acc endif enddo enddo method highlight details model looking result independent size block lip localization viseme classification visual speech recognition diminish noise effect influence entirety candidate blocks 
fact vote principle noise affect voices affecting result 

alife lip feature extraction classification application french vowels section different visual descriptors characterization labial movements 
visual descriptors entries information recognition phase depend 

lip feature extraction choice syllabic descriptors relevant accurately describing movement viseme corpus 
follows consider physical natural descriptors horizontal distance lip corners dh vertical distance lower upper lip dv dark surface dark area inside mouth da 
extraction descriptors tracking points section 
illustrates example extraction distances speaker corpus 
da dh dv da 
different descriptors extraction recognition stage variation vertical distance upper lower lip gives clear idea opening degree mouth syllabic sequence 
measure significant recognition syllables containing vowels open mouth example ba 
variation horizontal distance right left lip corners describes stretching intensity lips locution sequence 
measure significant recognition visemes containing vowels stretch mouth example bi 
da descriptor spite irregular appearance dark surface relevant descriptor labial movement characterization 
section justify relevance intelligibility descriptor method extraction measure calculate recognition phase 

intelligibility dark area speech result vocal combinations symbolic value language 
speech happens expiry 
compression intra air closing opening emission air hear voice 
air expelled lungs crosses put vibration successive opening closing vocal cords probably membrane covers 
precisely configuration mouth organs take air ejected lungs outside pass organs produce speech 
information gave idea develop measure named dark area da 
dark area defines inter labial surface air ejected outside mouth 
see experiments descriptor relevant constitutes discriminating criteria configuration visemes bou 

extraction dark area extract dark pixels inside mouth seek pixels region interest roi described polygonal form 
region formed poi defined section 

roi region interest main problem separate dark non dark pixels 
question finding method operate various conditions sequence acquisition different configurations colours regular speakers 
propose extraction dark areas method adaptive threshold 
threshold calculated equation dark roi yi equation number pixel roi 
coefficient fixed experimental results carried audio visual corpus 
discrimination dark international journal computing information sciences vol april line non dark pixels done equation dark pixel equation non dark pixel presents results dark area extraction various speakers distinct colours different lighting conditions 
obtain image sequence number dark pixels inside roi 
infact number dark pixels discriminating various configurations visemes 
spatial position pixels inside roi interesting relevant 
develop criterion spatial position proceed weighting dark pixels position compared roi midpoint 
values dark area feature da calculated rule da equation xc yc cartesian coordinates roi midpoint 

result dark area various speakers different lighting conditions left right top bottom images detection images dark area detection approach exploit density spatial position dark pixels inside roi 

lip feature classification recognition robustness speech recognition system depends largely relevance descriptors training stage 
addition great number data necessary ensure effective training system 
experiments carry test data different training data possible characterize performances alife system 
development recognition systems imposes considerable size data 
literature audio visual visual corpuses available speech recognition rare 
constitution corpus posed material storage problems 
case viseme recognition existing corpus increasingly difficult hand focus strictly visual data hand nature speech unit recognize viseme 
obliged build audio visual corpus 
section audio visual corpus detail lip feature classification method 
consider classification features defined section 

viseme corpus presentation alife prototype evaluated multiple speakers natural conditions 
created specific audio visual av corpus constituted different french vowels 
av corpus composed native speakers various age sex 
capture done ccd camera resolution mega pixels frames fps 
cadence widely capture major important lip movement 
french language note identical lip movement group vowels different lip movement groups 
table illustrates different lip configurations french language vowels 
different lip movements table note confusion zone groups 
distinguish differentiable lip movements french vowels group opening movement group forward movement group stretch movement tab 

specificity corpus consists syllable sequences visually differentiable uttered female male speakers ba bi bou 
justify choice treated cases section 
articulator gestures vowels generally stationary configurations required particular vowel constrained tab 

production vowels natural speech generally lax depends articulation stress 
furthermore speaker vary visible configuration vowels changing auditory characteristics 
stevens classical works quantitative description vowel articulation affirm possible range formant frequency combinations producing lip localization viseme classification visual speech recognition vowels obtained varying parameters distance maximum constriction cross sectional area constriction ratio area lip opening length lip passage er lip movement opening lip movement opening forward lip movement forward lip movement stretch position vowels lip movement group group group ou eu group tab lip movement french vowel main problem parameters third clearly visible demonstrates difficulty visual vowel recognition 
working syllable cv recognition system judge reasonable evaluate time alife beta version prototype vowels especially conceived da feature described section compensate visibility parameters producing vowels 
just characterizing vowel production certainly think enlarge alife recognition system cover totality french language visemes 
case predict imperative add features describe perfectly visual production consonants 
addition affect structure alife recognition system 
section detail different stages new approach classification recognition visemes 

alife classification recognition confusion zone recognition system alife majority recognition systems composed sub systems training recognition 
training stage consists building recognition models viseme corpus 
second stage classify viseme descriptors comparison models built stage 
final objective recognition viseme 
details new approach viseme classification recognition 
training sub system principle goal stage construct different syllable descriptive templates sdt basis recognition sub system 
example take syllable ba create templates horizontal variation dh vertical opening distance dv dark region variation rate da described section 
poi tracking stage section obtain vectors describing features variation belonging speech sequence exp dh 
distance value dv speaker nw ba nb image ba 
tracking vertical variations distance dv syllable ba speaker nw see curve dv value remains steady frame values correspond pause start speech sequence 
dv values ignored order influence final recognition template 
hand note syllable sequence duration necessarily speakers 
mouth size people 
construct robust recognition template important apply spatial temporal normalization distance variation tracking curves 
operation maintained appearance tracking variation curve linear interpolation operations curve points 
goal process assure representation tracking variation curve number points 
case fixed 
choice value random number choose widely sufficient give faithful representation syllable tracking variation curve 
value depend duration speech unit recognize 
syllables image sample number depend syllable duration 
international journal computing information sciences vol april line french language study temporal structuring corpus largely depends conditions speech flow 
describes duration syllable various rhythms 
notice average duration syllable ms 

syllabic duration french language flow conditions slow normal fast captured sequence frames fps syllable duration seconds number frame gives faithful representation labial movements equal 
generally speech unit duration frame capture cadence cd value calculated equation cd equation spatial normalization common factor opted initial horizontal vertical distance features dh dv maximal maximal value dark pixel rate speech sequence feature da 
shows result curve spatial temporal normalization vertical distance variation curve syllable ba 
mentioned principle aim training sub system build feature recognition templates viseme corpus 
templates generated average retrieved variation curves syllable feature 
distance value normalized dv speaker nw syllable ba normalized nb image normalized 
normalization vertical distance variations dv syllable ba speaker nw shows generated syllable template sdt syllable ba vertical variation distance feature 
id id describes vertical distance variation obtained form native speakers 
generated recognition template vertical variation distance feature viseme ba id id id id id moy ba id id id id id id id id id id id id id id id id id id id id id id id id id 
generation vertical distance variation template sdt syllable ba 
recognition sub system accomplishing poi localization tracking extraction feature normalization feature vectors input speech sequence characterized feature vectors fvi feature index 
normalized fvi characterized points described see section 
consequently recognition system consists comparing fvi respective sdt shown 
sdt sdt fvi distance value recognition di 
distances calculate sdt fvi dv syllable ba lip localization viseme classification visual speech recognition comparison generates distances dij dij feature index syllable index 
obtained distance input neural network transformation function equation ijw ijw equation constant coefficient distance di scaling parameter 
recognition sub system composed neural network precisely define feature syllable neural network composed input layers identity output layers 
ei ei ei feature index syllable index 
neural network architecture distance vector classification neural network outputs compute probability speech sequence corresponding syllable 
recognition syllable posteriori maximum probability pmp calculated equation 
arg max equation number observations related different descriptors fi 
add weight coefficient ci descriptor syllable 
coefficient indicate influence rate chosen descriptor recognition syllable 
detail equation way wt equation probability fi calculated bayes theorem fi fi equation equation ignore denominator fi descriptors 
probability supposed constant syllables corpus 
consequently conditional probability equation calculated way ijw si equation si neural network output 
recognize syllable highest probability 
experimental results section composed experimental parts experimentation compare spatial temporal lip tracking method techniques second experimentation evaluation alife system visual recognition viseme corpus 
rates recognition viseme matrix confusion visemes shown 

alife lip tracking experimentation simi image processing software automatic movement tracking 
pattern matching algorithm utilized video clips automatically track user defined patterns 
approach simi normal cross correlation ncc 
software situate spatial temporal voting algorithm model search techniques 
experimental results shown 
results notice deficiencies simi system especially movements lower lip due luminance variations important zone 
international journal computing information sciences vol april line 
experimental results different speakers followed vote algorithm followed software simi 
alife viseme recognition experimentation evaluated alife system audio visual corpus 
audiovisual corpus training stage recognition 
experimental results tab 
tab 
tab 
tab recognition rate french vowel training stage tab recognition rate french vowel recognition stage training stage recognition rate recognition stage ba bi bou recognition rate ba bi bou recognition rate ba bi bou ba bi bou recognition rate ba bi bou tab recognition rate french vowel training recognition stage rate confusion ba input viseme confusion bi bou ba bi bou ba bi bou output 
experimental results viseme confusion training stage rate confusion ba bi input viseme confusion bou ba bi bou ba bi bou output 
experimental results viseme confusion recognition stage results notice recognition rate viseme bou addition dark area feature case visemes 
poor rate recognition due big confusion rate visemes ba bi shown 

experiments show visual channel carries useful information speech recognition 
works literature oldest ones proved efficiency visual speech recognition systems particularly noisy audio conditions 
research visual information automatic speech recognition 
major difficulty lip reading system extraction visual speech descriptors 
fact ensure task necessary carry automatic tracking labial gestures 
lip tracking constitutes important difficulty 
complexity consists capacity treat immense variability lip movement speaker various lip configurations different speakers 
alife beta version system visual speech recognition 
alife system extraction visual speech features modeling visual speech lip localization viseme classification visual speech recognition recognition 
system includes principle parts lip localization tracking lip feature extraction classification recognition viseme 
system tested success audiovisual corpus tracking characteristic points lip contours recognition viseme 
carried improve efficacy lip reading system 
perspective propose add consistent features example appearance rate tooth tongue 
propose enhance recognition stage adequate definition feature coefficients viseme principal component analysis acp 
plan enlarge content audio visual corpus cover totality french language visemes discover languages 
petajan bischoff improved automatic lipreading system enhance speech recognition chi pp 

mod les posteriori de la forme de des vres pour la reconnaissance automatique de la parole 
th se universit de maine france 
stereo vision lip tracking algorithm subsequent statistical analyses audio video correlation australian english 
thesis research school information sciences engineering 
australian national university canberra australia january 
mcdonald 
hearing lips seeing voice 
nature 
matthews andrew stephen cox 
audiovisual speech recognition multiscale nonlinear image decomposition 
proc th icslp volume page philadelphia pa usa 
meier stiefelhagen yang 
unrestricted lip reading 
proc nd international conference multimodal interfaces hong kong jan 
prasad stork wolff preprocessing video images neural learning lipreading technical report crc tr california research center september 
rao merging hidden markov models deformable templates icip washington 
extraction des contours des vres un par contours application la communication 
th se institut national de polytechnique de grenoble 
potamianos graft 
image transform approach hm automatic lipreading 
proc icip volume iii pages chicago il usa 
matthews andrew cox 
comparaison active shape models scale decomposition features visual speech recognition 
lncs 
segmentation des vres par un mod le th se de doctorat de grenoble 
accurate quasi automatic lip tracking ieee transaction circuits video technology mai 
rabiner 
tutorial hidden markov models selected applications speech recognition 
proceedings ieee february 
anandan computational framework algorithm measurement visual motion int 
computer vision 
silverman class algorithms fast digital image registration ieee trans 
computers pp 

shi tomasi features track proc 
ieee conf 
computer vision pattern recognition 
lucas kanade iterative image registration technique application stereo vision ijcai 
lindsey non existence wavelet function admitting wavelet international journal computing information sciences vol april line transform convolution theorem fourier type rome laboratory technical report bb 
le est pas tude pr de influence du bit de parole sur la structuration partement de universit de rennes avenue gaston berger cs rennes france 
simi reality motion systems gmbh germany 
www simi com stevens house 
quantitative description vowel articulation 
journal acoustical society america 
nakata ando 
lipreading method color extraction method eigenspace technique systems computers japan vol 

wu tamura kawai 
neural network vowel recognition jointly voice features mouth shape image 
pattern recognition 
petajan bischoff 
improved automatic lipreading system enhance speech recognition 
soloway sheppard editors proc 
human factors computing systems pages acm 
garcia petajan 
continuous optical automatic speech recognition lipreading th annual conference signals systems computer 
bregler konig 
robust speech recognition 
proc 
ieee int 
conf 
acoust speech signal processing pages adelaide 
tokuda 
normalized training hmm visual speech recognition 
electronics communications japan part vol 

spatial temporal technique viseme extraction application speech recognition ieee international conference signal image technology internet system 
alife automatic lip feature extraction new approach speech recognition application nd ieee international conference information communication technologies theory applications 

alife new approach automatic lip feature extraction application speech recognition rd ieee international symposium image video communications fixed mobile networks 
preparing doctorate degree computer science des sciences de gestion de 
teaching assistant higher institute computer science multimedia 
research image video processing focused visual speech recognition lipreading system 
walid received ph computer information science ecole de lyon france 
currently assistant professor higher institute computer science multimedia university 
research image video processing 
ben professor computer science director higher institute computer science multimedia 
director laboratory 
research interests include automatic processing natural language objectoriented design component software specification image video processing 
