gamma database machine project david dewitt ghandeharizadeh donovan schneider allan hui hsiao rick rasmussen computer sciences department university wisconsin research partially supported defense advanced research projects agency contract national science foundation dcr darpa nasa sponsored graduate research parallel processing research intel scientific computers tandem computers digital equipment 
describes design gamma database machine techniques employed implementation 
gamma relational database machine currently operating intel ipsc hypercube processors disk drives 
gamma employs key technical ideas enable architecture scaled processors 
relations horizontally partitioned multiple disk drives enabling relations scanned parallel 
second novel parallel algorithms hashing implement complex relational operators join aggregate functions 
third dataflow scheduling techniques coordinate queries 
techniques possible control execution complex queries minimal coordination necessity configurations involving large number processors 
addition describing design gamma software thorough performance evaluation ipsc hypercube version gamma 
addition measuring effect relation size indices response time selection join aggregation update queries analyze performance gamma relative number processors employed sizes input relations kept constant speedup sizes input relations increased proportionally number processors scaleup 
speedup results obtained selection join queries linear doubling number processors halves response time query 
scaleup results obtained quite encouraging 
reveal nearly constant response time maintained selection join queries workload increased adding proportional number processors disks 

years gamma database machine project focused issues associated design implementation highly parallel database machines 
number ways design gamma learned earlier database machine direct dewi 
direct demonstrated paral successfully applied processing database operations number serious design deficiencies scaling architecture processors impossible primarily shared memory centralized control execution parallel algorithms 
solution problems encountered direct gamma employs appear today relatively straightforward solutions 
architecturally gamma shared ston architecture consisting number processors interconnected communications network hypercube ring disks directly connected individual processors 
generally accepted architectures scaled incorporate processors 
fact teradata database machines tera incorporating shared architecture processors 
second key idea employed gamma hash parallel algorithms 
algorithms employed direct algorithms require central ized control hardware architecture scaled indefinitely 
best limited bandwidth provided current generation disk drives gamma employs concept hor partitioning ries termed declustering distribute tuples relation multiple disk drives 
design enables large relations processed multiple processors concurrently incurring communications overhead 
design gamma software completed fall began prototype operational fall 
version gamma implemented top existing multi computer consisting vax processors dewi 
period prototype enhanced addition number new operators aggregate update operators new parallel join methods hybrid grace sort merge schn complete concurrency control mechanism 
addi tion conducted number performance studies system period dewi dewi 
spring gamma ported processor intel ipsc hypercube vax prototype retired 
gamma similar number active parallel database machine efforts 
addition teradata tera bubba cope tandem tand utilize shared architecture employ concept horizontal partitioning 
teradata tandem rely hashing decentralize execution parallel algorithms systems tend rely relatively conventional join algorithms sort merge processing fragments relation site 
gamma xprs ston volcano util ize parallel versions hybrid join algorithm dewi 
remainder organized follows 
section describe hardware gamma prototypes experiences 
section discusses organization gamma software describes queries controlled 
parallel algorithms employed gamma described section techniques employ transaction failure management contained section 
sec tion contains performance study processor intel hypercube prototype 
research directions described section 
hardware architecture gamma 
overview gamma concept shared architecture ston processors share disk drives random access memory communicate sending messages interconnection network 
mass storage architecture generally distributed processors con disk drives processor shown 
number reasons shared approach architecture choice 
prevent architecture scaling processors shared memory machines scaling processors may impossible 
second demonstrated dewi cope tand associating small number interconnection network 
disks processor distributing tuples relation disk drives possible achieve high aggregate bandwidths custom disk controllers kim patt 
furthermore employing shelf mass storage technology employ latest technology small disk drives embedded disk controllers 
advantage shared approach longer need roll hardware 
intel ncube added mass storage hypercube multiprocessor products 

gamma version initial version gamma consisted vax processors megabytes memory 
megabit second token ring prot connect processors vax running unix 
processor acted host machine gamma 
attached processors megabyte fujitsu disk drives storing database 
diskless processors processors disks execute join aggregate function operators order explore diskless pro cessors exploited effectively 
encountered number problems prototype 
token ring maximum network packet size bytes 
version prototype size disk page set bytes order able transfer intact disk page processor copy 
required example disk page contain space protocol header interprocessor communication software 
initially appeared idea quickly realized benefits larger disk page size offset cost having copy tuples disk page network packet 
second problem encountered network interface bottlenecks dewi 
bandwidth token ring megabits second network interface attached bandwidth megabits second 
pro cessing join query selection predicate input relations bottleneck transfer rate pages disk higher speed dewi 
network interface bottleneck buffer incoming packets time 
packet transferred vax memory incoming packets rejected retransmitted com protocol 
eventually constructed interface token ring plugged directly backplane vax time board operational vax obsolete elected spend additional funds upgrade entire system 
serious problem encountered prototype having megabytes memory processor 
especially problem operating system gamma provide virtual memory 
problem exacerbated fact space join hash tables stack space processes buffer pool managed separately order avoid flushing hot pages buffer pool 
advantages having spaces managed separately software configuration memory tight balancing sizes pools memory proved difficult 

gamma version fall replaced vax prototype processor ipsc hypercube intel 
processor configured cpu megabytes memory megabyte maxtor disk drive 
disk drive embedded scsi controller provides kbyte ram buffer acts disk cache read operations 
nodes hypercube interconnected form hypercube custom vlsi routing modules 
module supports full duplex serial reliable communication channels operating megabytes second 
small messages bytes sent datagrams 
large messages hardware builds communications circuit nodes entire message transmitted software overhead copying 
message completely transmitted circuit released 
length message limited size physical memory processor 
table summarizes transmission times gamma process different hypercube nodes variety message sizes 
packet size bytes transmission time ms ms ms ms ms table conversion gamma software hypercube began early december 
users intel hypercube tend run single process time numerical data operating system provided intel supports limited number heavy weight processes 
began conversion pro cess porting gamma operating system nose see section 
order simplify conversion elected run nose thread package inside single nx process order avoid having port nose run bare hardware directly 
configurations mix compute nodes channels dedicated communication subsystem 
nose running began converting gamma software 
process took man months lasted months process conversion discovered interface scsi disk controller memory able transfer disk blocks larger bytes pitfall beta test site 
part conversion gamma software trivial porting nose differences systems initiating disk message transfers completely hidden gamma software 
porting code discover number hidden bugs vax version code vax trap null pointer dereferenced 
biggest problem encountered nodes vax multicomputer numbered hypercube uses logical address node 
thought making necessary changes tedious ward half way port realized find change loop system loop index address machine message set 
sounds silly took weeks find places changed 
retrospect nose mask differences addressing schemes 
database system perspective number areas intel improve design ipsc 
light weight process mechanism provided alternative nx 
certainly increased time required port long run avoided maintaining nose 
serious problem current version system disk controller perform dma transfers directly memory 
block read disk disk controller dma transfer byte fifo 
fifo half full cpu interrupted contents fifo copied appropriate location memory 
block instruction copy opera tion measured available cpu cycles wasted doing copy operation 
addition cpu interrupted times transfer kbyte block partially scsi disk controller partially fifo disk controller memory 

software architecture gamma section overview gamma software architecture describe techniques gamma employs executing queries dataflow fashion 
describing alternative storage struc tures provided gamma software 
system architecture described top 
describing process structure illustrate operation system describing interaction intel forced design system added system completed way doing empty socket board dma access memory 
processes execution different queries 
detailed presentation techniques control execution complex queries section 
followed example illustrates execution query 
briefly describe wiss storage system provide low level database services nose underlying operating system 

gamma storage organizations relations gamma horizontally partitioned ries disk drives system 
key idea horizontally partitioning relation enable database software exploit bandwidth provided hardware 
declustering tuples relation task parallelizing selection scan opera tor trivial required start copy operator processor 
query language gamma provides user alternative declustering strategies round robin hashed range partitioned 
strategy tuples distributed round robin fashion disk drives 
default strategy relations created result query 
hashed parti strategy selected randomizing function applied key attribute tuple specified partition command relation select storage unit 
third strategy user specifies range key values site 
example disk system command partition employee emp id result distribution tuples shown table 
partitioning information relation stored database catalog 
range hash partitioned relations name partitioning attribute kept case range partitioned relations range values partitioning attribute site termed range table 
distribution condition processor emp id emp id emp id emp id example range table table relation partitioned gamma provides normal collection relational database system access methods including clustered non clustered indices 
user requests index created relation system automatically creates index fragment relation 
vsam tandem file system gamma require clustered index relation constructed declustering term horizontal partitioning coined bubba project 
partitioning attribute 
query optimized partitioning information source relation query incor query plan produced query optimizer 
case hash range partitioned relations partitioning information query scheduler discussed restrict number processors involved execution selection queries partitioning attribute 
example relation hash parti tioned attribute possible direct selection operations predicates form constant single site avoiding participation sites execution query 
case range partitioned relations query scheduler restrict execution query processors ranges overlap range selection predicate may equality range predicate 
retrospect serious mistake choosing decluster relations nodes disks 
better approach proposed cope heat relation determine degree relation declustered 
unfortunately add capability gamma software point time require fairly major effort undertake 

gamma process structure structure various processes form gamma software shown 
role process described briefly 
operation distributed deadlock detection recovery mechanism sections 
system initialization time unix daemon process catalog manager cm initiated set scheduler processes set operator processes deadlock detection process recovery process 
catalog manager function catalog manager act central repository conceptual internal schema information database 
schema information loaded memory database opened 
multiple users may database open user may reside machine catalog manager executing catalog manager responsible insuring consistency copies cached user 
query manager query manager process associated active gamma user 
query manager responsible caching schema information locally providing interface ad hoc queries gdl variant quel ston query parsing optimization compilation 
scheduler processes executing query controlled scheduler process 
process responsible activating operator processes execute nodes compiled query tree 
scheduler processes run processor insuring processor bottleneck 
practice scheduler processes consume resources possible run large number single processor 
centralized dispatching process assign scheduler processes queries 
queries optimizer detect single site queries sent directly appropriate node execution passing scheduling process 
operator processes query manager recovery process 
catalog manager scheduler processes query manager deadlock detection process 
operator schema processes processes operator operator processes database database database database gamma process structure host gamma processors operator process operator query tree operator process employed processor participating execution operator 
operators primed system initialization time order avoid overhead starting processes query execution time additional processes forked needed 
structure operator process mapping relational operators operator processes discussed detail 
scheduler wishes start new operator node sends request special communications port known new task port 
request received port idle operator process assigned request communications port operator process returned requesting scheduler process 

overview query execution ad hoc embedded query interfaces interfaces gamma available ad hoc query language embedded query language inter face queries embedded program 
user invokes ad hoc query interface query manager qm process started immediately connects cm process unix internet socket mechanism 
compiled query interface preprocessor translates embedded query compiled query plan invoked run time program 
mechanism passing parameters program compiled query plans run time provided 
query execution gamma uses traditional relational techniques query parsing optimization code generation 
optimization process somewhat simplified gamma employs hash algorithms joins complex operations 
queries compiled left deep tree operators 
execution time operator executed operator processes participating site 
designing optimizer vax version gamma set possible query plans considered optimizer restricted left deep trees felt memory support right deep bushy plans 
combination left deep query trees hash join algorithms able insure join operations active simultaneously able maximize amount physical memory allocated join operator 
memory limitation really artifact vax prototype begun examine performance implications right deep bushy query plans schn 
discussed section process optimizing query query optimizer recognizes certain queries directed subset nodes system 
case single site query query sent directly qm appropriate processor execution 
case multiple site query optim establishes connection idle scheduler process centralized dispatcher process 
dispatcher process controlling number active schedulers implements simple load control mechanism 
established connection scheduler process qm sends compiled query scheduler process waits query complete execution 
scheduler process turn activates operator processes query processor selected execute operator 
qm reads results query returns ad hoc query interface user embedded query interface program query initiated 

operator process structure algorithms relational operators written run single processor 
shown input operator process stream tuples output stream tuples structure term split table 
process begins execution continuously reads tuples input stream operates tuple uses split table route resulting tuple process indicated split table 
process detects input stream closes output streams sends control message scheduler process indicating completed execution 
closing output streams side effect sending stream messages destination processes 
stream tuples process executing operator control packet split table outgoing streams tuples split table defines mapping values set destination processes 
gamma uses different types split tables depending type operation performed dewi 
example form split table consider split table shown conjunction execution join operation processors 
process producing tuples join apply hash function join attribute output tuple produce value 
value index split table obtain address destination process receive tuple 
tuples sent byte batches batch 
example value destination process processor port processor port processor port processor port example split table example queries executed consider query shown 
processes execute query shown flow data various processes gamma configuration consisting processors disks processors disks 
input rela tions partitioned disks attached processors selection scan operators ini processors 
split tables select scan operators contain entries processors join operation 
split tables selection scan identical routing tuples join attribute values hash dashed lines hash solid lines 
join operator executes phases 
phase termed building phase tuples inner relation example inserted memory resident hash table hashing join attribute value 
phase completed probing phase join initiated tuples outer relation probe hash table matching tuples 
result relation partitioned disks split table join operator contains entries tuples distributed round robin fashion 
select join scan description simple hash join algorithm 
operation hybrid hash join algorithm contained section 
join build store select scan select scan store hash table join probe join build hash table join probe main problems direct prototype data page processed required control message centralized scheduler 
gamma bottleneck completely avoided 
fact number control messages required execute query approximately equal times number opera tors query times number processors execute operator 
example consider depicts flow control messages scheduler process processes processors identical set messages flow scheduler 
scheduler begins ing building phase join selection operator relation operators com scheduler initiates store operator probing phase join scan relation operators completed result message returned user 
initiate message sent new operator port processor 
dispatching processes accepts incoming messages port assigns operator process 
process assigned replies scheduler id message indicates private port number operator process 
communications operator scheduler private port number 
initiate initiate done join initiate hash done done done initiate initiate id id store scheduler select 
operating storage system join build table probe id id scan done gamma built top operating system designed specifically supporting database management sys tems 
nose provides multiple lightweight processes shared memory 
non preemptive scheduling policy help prevent blas occurring 
nose provides communications nose processes reliable message passing hardware intel ipsc hypercube 
file services nose wisconsin storage system wiss chou 
critical sections wiss protected semaphore mechanism provided nose 
file services provided wiss include structured sequential files byte stream files unix indices long data items sort utility scan mechanism 
sequential file sequence records 
records may vary length page length may inserted deleted arbitrary locations sequential file 
optionally file may associated indices map key values record identifiers records file contain matching value 
indexed attribute may designated clus tering attribute file 
scan mechanism similar provided system rss astr predicates compiled query optimizer machine language maximize performance 

query processing algorithms 
selection operator relations declustered multiple disk drives parallelizing selection operation involves simply initiating selection operator set relevant nodes disks 
predicate selection clause partitioning attribute relation relation hash range partitioned scheduler direct selection operator subset nodes 
relation round robin partitioned selection predicate partitioning attribute selection operator initiated nodes rela tion declustered 
enhance performance gamma employs page read ahead mechanism scanning pages file sequentially clustered index 
mechanism enables processing page overlapped subsequent page 

join operator multiprocessor join algorithms provided gamma concept partitioning relations joined disjoint subsets called buckets kits brat 
applying hash function join attribute tuple 
partitioned buckets represent disjoint subsets original relations important characteristic tuples join attribute value bucket 
imple mented parallel versions join algorithms gamma prototype sort merge grace kits simple dewi hybrid dewi 
algorithms employ concept hash partitioning actual join computation depends algorithm 
parallel hybrid join algorithm described section 
additional information parallel algorithms relative performance schn 
study hybrid hash join provides best performance default algorithm gamma described detail section 
hash join algorithms execute non equijoin operations operations currently sup ported 
remedy situation process designing parallel non equijoin algorithm gamma 
hybrid hash join centralized hybrid hash join algorithm dewi operates phases 
phase algo rithm uses hash function partition inner smaller relation buckets 
tuples bucket build memory hash table remaining buckets stored temporary files 
hash function produces just buckets ensure bucket tuples small fit entirely main memory 
second phase relation partitioned hash function step 
buckets stored temporary files tuples bucket immediately probe memory hash table built phase 
third phase algorithm joins remaining buckets relation respective buckets relation join broken series smaller joins hopefully computed experiencing join overflow 
size smaller relation determines number buckets calculation independent size larger relation 
parallel version hybrid hash join algorithm similar centralized algorithm described 
partitioning split table separates joining relations logical buckets 
number buckets chosen tuples corresponding logical bucket fit aggregate memory joining pro cessors 
buckets intended temporary storage disk partitioned available disk sites 
likewise joining split table route tuples respective joining processor processors necessarily attached disks parallelizing joining phase 
furthermore partitioning inner relation buckets overlapped insertion tuples bucket memory resident hash tables join nodes 
addition partitioning outer relation buckets overlapped joining bucket bucket requires partitioning split table enhanced joining split table tuples bucket sent processors effect join 
course remaining buckets joined joining split table needed 
depicts relation partitioned buckets disk sites bucket joined processors may equal greater 

aggregate operations gamma implements scalar aggregates having processor compute piece result parallel 
partial results sent single process combines partial results final answer 
aggregate functions computed steps 
processor computes piece result calculating value partitions 
processors redistribute partial results hashing group attribute 
result step collect partial results partition single site final result partition computed 

update operators part update operators replace delete append implemented standard tech niques 
exception occurs replace operator modifies partitioning attribute tuple 
case writing modified tuple back local fragment relation modified tuple passed split table determine site contain tuple 

transaction failure management section describe mechanisms gamma uses transaction failure management 
locking mechanisms fully operational recovery system currently implemented 
expect implementation failure management mechanism early 

concurrency control gamma concurrency control gamma phase locking gray 
currently lock granularities file page lock modes ix provided 
site gamma local lock manager deadlock detector 
lock manager maintains lock table transaction wait graph 
cost setting lock varies approximately instructions conflict instructions lock request conflicts granted group 
case wait graph checked deadlock transaction requested lock suspended semaphore mechanism 
order detect deadlocks gamma uses centralized deadlock detection algorithm 
periodically centralized deadlock detector sends message node configuration requesting local transaction wait graph node 
initially period running centralized deadlock detector set second 
time deadlock detector fails find global deadlock interval doubled time deadlock current value interval halved 
upper bound interval limited seconds lower bound second 
collecting wait graph site centralized deadlock detector creates global transaction wait graph 
cycle detected global wait graph central ized deadlock manager chooses abort transaction holding fewest number locks 

recovery architecture log manager algorithms currently implemented coordinating transaction commit abort rollback operate follows 
operator process updates record generates log record records change database state 
associated log record log sequence number lsn composed node number local sequence number 
node number statically determined system configuration time local sequence number termed current lsn monotonically increasing value 
log records sent query processors log managers running separate pro cessor merges log records receives form single log stream 
number log processors query processor direct log records mod log processor 
algorithm selects log processor statically query processor sends log records log pro cessor recovery process query processing node easily determine request log records processing transaction abort 
page log records filled written disk 
log manager maintains table called flushed log table contains node lsn log record node flushed disk 
values returned nodes request piggybacked processors bucket entries entries entries disk disk partitioning logical buckets hybrid hash join 
partitioning split table bucket bucket message 
query processing nodes save information local variable termed flushed lsn 
buffer managers query processing nodes observe wal protocol gray 
dirty page needs forced disk buffer manager compares page lsn local value flushed lsn 
page lsn page smaller equal flushed lsn page safely written disk 
wise different dirty page selected message sent log manager flush corresponding log record dirty page 
log manager acknowledges log record written log disk dirty data page written back disk 
order reduce time spent wait ing reply log manager buffer manager keeps pre selected threshold clean buffer pages available 
buffer manager notices number clean buffer pages fal len process termed local log manager activated 
process sends message log manager flush log records number clean pages plus number dirty pages safely written disk greater scheduler process query responsible sending commit abort records appropriate log managers 
transaction completes successfully commit record transaction generated scheduler sent relevant log manager employs group commit protocol 
hand transaction aborted system user scheduler send abort message query processors parti execution 
recovery process participating nodes responds requesting log records generated node log manager lsn log record contains originating node number 
log records received recovery process undoes log records reverse chronological order aries undo algorithm 
aries algorithms basis check pointing restart recovery 

failure management help insure availability system event processor disk failures gamma employs new availability technique termed chained declustering hsia 
tandem mirrored disk mechanism teradata interleaved declustering mechanism tera cope chained declustering employs primary backup copy relation 
systems sustain failure single processor disk suffering loss data availability 
hsia show chained declustering provides higher degree availability interleaved declustering event processor disk failure better job distributing workload broken node 
mirrored disk mechanism providing highest level availability poor job distributing load failed processor 
data placement chained declustering chained declustering nodes processor disks divided disjoint groups called relation clusters tuples relation declustered drives form relation clusters 
physical copies relation termed primary copy backup copy maintained 
exam ple consider number disks relation cluster equal 
tuples primary copy relation declustered gamma partitioning strategies tuples th primary fragment designated ri stored mod th disk drive 
backup copy declustered partitioning strategy th backup fragment designated ri stored mod th disk 
term data replication method chained declustering disks linked fragments relation chain 
node primary copy backup copy chained declustering relation cluster size difference chained interleaved declustering mechanisms tera cope illus 
fragments primary copy declustered disk drives hashing key attribute 
interleaved declustering mechanism set disks divided units size called clusters 
illustrated backup fragment subdivided sub fragments placed different disk cluster disk containing primary fragment 
cluster cluster node primary copy backup copy interleaved declustering cluster size interleaved chained declustering sustain failure single disk processor difference mechanisms 
case single node processor disk failure chained interleaved declustering strategies able uniformly distribute workload cluster remaining operational nodes 
example cluster size processor disk fails load remaining node increase th 
conclude cluster size large possible course overhead parallelism starts benefits obtained 
true chained declustering availability interleaved strategy inversely proportional cluster size 
failure processors disk render data unavailable 
doubling cluster size order halve approximately increase load remaining nodes failure occurs quite tive side effect doubling probability data unavailable 
reason teradata recom cluster size processors 
illustrates workload balanced event node failure node example chained declustering mechanism 
normal mode operation read requests directed frag ments primary copy write operations update copies 
failure occurs pieces pri mary backup fragments read operations 
example failure node primary fragment longer accessed backup fragment node processing queries normally directed 
requiring node process accesses chained declustering ths accesses redirecting node 
turn ths access node sent 
dynamic reassignment workload results increase th workload remaining node cluster 
relation cluster size increased penalty possible load increase small desired 
node primary copy backup copy fragment utilization chained declustering failure node relation cluster size scheme attractive reassignment active fragments incurs disk data movement 
bound values pointers indices memory resident control table changed modifications done quickly efficiently 
example shown provides simplified view chained declustering mechanism balances workload event node failure 
reality queries simply access arbitrary fraction data fragment especially variety partitioning index mechanisms provided gamma software 
hsia describe combinations query types access methods partitioning mechanisms handled 

performance studies 
experiment overview evaluate performance hypercube version gamma different metrics 
set wisconsin benchmark queries run processor configuration different sizes relations tuples 
absolute performance measure database system speedup scaleup useful metrics multiprocessor database machines engl 
speedup interesting metric indicates additional processors disks results corresponding decrease response time query 
subset wisconsin benchmark queries conducted speedup experiments varying number processors size test relations fixed mil lion tuples 
set queries conducted scaleup experiments varying number proces sors size test relations increased tuples respectively 
scaleup valuable metric indicates constant response time maintained workload increased adding proportional number processors disks 
engl describes similar set tests release tandem nonstop sql system 
benchmark relations experiments standard wisconsin benchmark relations 
relation consists tuples bytes wide 
constructed mil lion tuple versions benchmark relations 
copies relation created loaded 
noted tuples declustered hash partitioning unique attribute 
cases results represent average response time number equivalent queries 
gamma configured disk page size bytes buffer pool megabytes 
results queries stored database 
avoided returning data host order avoid having speed communications link host database machine host processor affect results 
storing result relations database impact factors minimized expense incurring cost declustering storing result relations 

selection queries performance relative relation size set selection tests designed determine gamma respond size source relations increased machine configuration kept processors disks 
ideally response time query grow linear function size input result relations 
tests different selection queries run sets relations containing respectively tuples 
queries selectivity factor employ indices 
third fourth queries selectivity factors clustered index locate qualifying tuples 
fifth query selectivity factor employs non clustered index locate desired tuples 
selection non clustered index query gamma query optimizer chooses sequential scan query 
query uses clustered index retrieve single tuple 
query predicate query specifies range values input relations declustered hashing query sent nodes 
results tests tabulated table 
part execution time query scales fairly linear function size input output relations 
cases scaling perfectly linear 
consider non indexed selection 
increase response time size input relation increased tuples perfectly linear secs 
secs increase tuples tuples sec 
sec sub linear 
selection clustered index example increasing size input relation factor results fold increase response time query 
query takes seconds tuple relation seconds tuple relation 
understand happens consider impact seek time execution time query 
copies relation loaded tuple relations declustered disk drives fragments occupy approximately cylinders disk drive 
tuple relations fill cylinders drive 
page result relation written disk disk heads moved current position input relation free block disk 
tuple relation cost writ ing output page higher 
expected clustered tree index provides significant improvement performance 
observation table relative consistency execution time selection queries clustered index 
notice execution time selection tuple relation identical execution time selection tuple relation 
cases tuples retrieved stored resulting identical cpu costs 
final row table presents time required select single tuple clustered index return host 
selection predicate partitioning attribute query directed single node avoid ing overhead starting query processors 
response query increases significantly table selection queries processors disks execution times seconds number tuples source relation query description selection selection selection clustered index selection clustered index selection non clustered index single tuple select clustered index relation size increased tuples height tree increases levels 
speedup experiments section examine response time indexed selection queries tuple relation affected number processors execute query 
ideally see linear improvement performance number processors increased 
increasing number processors increases aggregate cpu power bandwidth available reducing number tuples processed processor 
average response times non indexed selection queries tuple relation 
expected response time query decreases number nodes increased 
response time higher selection due cost declustering storing result relation 
store result tuples locally partitioning result relations round robin hashed fashion ensure fragments result relation contain approximately number tuples 
speedup curves corresponding 
average response time function number processors queries selection clustered index selection clustered index selection non tuple relation experiments tuple relation fit disk drive 
response time seconds selection selection speedup selection selection processors disks processors disks clustered index accessing tuple relation 
corresponding speedup curves 
speedup curves figures queries superlinear slightly sublinear significantly sublinear 
consider selection relation scan selection non clustered index selection clustered index 
discussed source super linear speedups exhibited queries due significant differences time various configurations spend seeking 
processor tuple relation occupies approximately disk 
relation declustered disk drives occupies disk 
case non clustered index selection tuple selected requires random seek 
processor range random seek approximately cylinders processors range seek limited cylinders 
seek time proportional square root distance traveled disk head gray reducing size relation fragment disk significantly reduces amount time query spends seeking 
similar effect happens clustered index selection 
case index locate tuples satisfying query input page produce output page point buffer pool filled dirty output pages 
order write output page disk head moved response time seconds non clustered index selection clustered index selection clustered index selection speedup non clustered index selection processors disks processors disks clustered index selection clustered index selection position input relation position disk output pages placed 
relative cost seek decreases proportionally number processors increases resulting superlinear speedup query 
non indexed selection shown superlinear similar reasons 
reason query affected degree index seek time smaller frac tion execution time query 
selection clustered index exhibits sublinear speedups cost initiating select store operator processor total seconds processors significant fraction total execution number processors increased 
scaleup experiments final set selection experiments number processors varied size input relations increased tuples respectively 
shown response time selection queries remains constant 
slight increase response time due overhead initiating selection store operator site 
single process initiate execu tion query number processors employed increased load process increased proportion ally 
switching tree query initiation scheme distribute overhead processors 

join queries response time seconds selection non clustered index selection selection clustered index selection clustered index selection processors disks selection queries previous section conducted sets join experiments 
different join queries varied size input relations configuration processors kept con stant 
join query series speedup scaleup experiments conducted 
tests different partitionings input relations 
case input relations declustered hashing join attribute 
second case input relations declustered different attribute 
hybrid join algorithm queries 
performance relative relation size join query simple join relations 
relation contains tuples 
relation contains respectively tuples 
result relation number tuples relation 
second query composed join selection 
number tuples join operation result relation contains fields input relations result tuples bytes wide 
selection reduces size size relation corresponding query 
result relation query number tuples corresponding query 
example tuples joins relation contains tuples selection restricts tuples tuples joins result variation join queries tested involved indices non partitioning attribute join selection attributes 
join performed input relations hashing join attribute value tuple 
results tests contained rows table 
second variation join queries employ indices case rela tions hash partitioned joining attribute enabling redistribution phase join skipped 
results tests contained rows table 
results table indicate execution time join query increases fairly linear fashion size input relations increased 
gamma exhibit linearity tuple queries size inner relation megabytes twice large total available space hash tables 
hybrid join algorithm needs buckets process queries 
tuples bucket placed directly memory resident hash tables second bucket written disk see section 
expected version query partitioning attribute join attribute ran faster 
results estimate lower bound aggregate rate data redistributed intel ipsc hypercube 
consider version query tuple relation table join queries processors disks execution times seconds number tuples relation query description non partitioning attributes join attributes non partitioning attributes join attributes partitioning attributes join attributes partitioning attributes join attributes joined tuple relation 
query requires seconds join partitioning attri 
execution query byte tuples redistributed hashing join attribute yielding aggregate total transfer rate megabytes second processing query 
construed accurate estimate maximum obtainable interprocessor communica tions bandwidth cpus may limiting factor disks limiting factor table estimate aggregate bandwidth disks megabytes second 
speedup experiments join speedup experiments query tuple relation tuple relation 
number processors varied 
fewer processors buckets needed including execution time processor needs buckets response times processors appear artificially fast resulting superlinear speedup curves 
resulting response times plotted corresponding speedup curves 
shape graphs obvious execution time query significantly reduced additional processors employed 
factors prevent system achieving perfectly linear speedups 
response time seconds hash partitioned non join attribute hash partitioned join attribute speedup processors disks processors disks hash partitioned non join attribute hash partitioned join attribute cost starting operator tasks scans join store processor increases function number processors 
second effect short circuiting local messages diminishes number processors increased 
example consider processor configuration non partitioning attribute version query 
processor tuples hashing join attribute th input tuples processes destined short circuited communications software 
addition query produces tuples result relation partitioned round robin manner short circuited 
number processors increased number short circuited packets decreases point processors th packets short circuited 
intra node packets expensive corresponding inter node packets smaller configurations benefit short circuiting 
case partitioning attribute joins input tuples short circuit network fraction output tuples 
scaleup experiments query join scaleup experiments 
tests number pro cessors varied size relation varied tuples increments tuples size relation varied tuples incre ments 
configuration join bucket needed 
results tests 
factors contribute slight increase response times 
task initiating processes site performed single processor 
second number processors increases effects short circuiting messages execution queries diminishes especially case join attribute partitioning attribute 
response time may limited speed com network 

aggregate queries response time seconds hash partitioned non join attribute hash partitioned join attribute processors disks aggregate tests included mix scalar aggregate aggregate function queries run processor configuration 
query computes minimum non indexed attribute 
queries compute respectively sum minimum attribute partitioning relation subsets 
sizes input relations tuples 
results tests contained table 
scalar aggregates aggregate function operators executed algorithms similar selection join operators respectively speedup scaleup experiments conducted 
table aggregate queries processors disks execution times seconds number tuples source relation query description scalar aggregate min aggregate function partitions sum aggregate function partitions 
update queries set tests included mix append delete modify queries different sizes relations tuples 
results tests table 
gamma recovery mechanism operational results viewed accordingly 
query appends single tuple relation indices exist 
second appends tuple relation index exists 
third query deletes single tuple relation clustered tree index locate tuple deleted 
query indices exist indices need updated second third queries index needs updated 
fourth sixth queries test cost modifying tuple different ways 
tests non clustered index exists unique attribute addition clustered index exists unique attri 
case modified attribute partitioning attribute requiring modified tuple relocated 
furthermore tuple relocated secondary index updated 
second modify query modifies non partitioning attribute 
third modify query modifies attribute non clustered index constructed index locate tuple modified 
table update queries processors disks execution times seconds number tuples source relation append tuple indices exist append tuple index exists delete tuple modify tuple modify tuple modify tuple 
research directions described design implementation gamma database machine 
gamma employs shared architecture processor disks processors com sending messages interconnection network 
previous version gamma software ran collection vax interconnected mbit second token ring currently system runs intel ipsc hypercube processors disk drives 
gamma employs key ideas enable architecture scaled processors 
relations horizontally partitioned multiple disk drives attached separate processors enabling relations scanned parallel specialized hardware 
addition order enable database design tuned needs application alternative partitioning strategies provided 
second major contribution gamma software extensive hash parallel algorithms processing com plex relational operators joins aggregate functions 
system employs unique dataflow scheduling techniques coordinate execution queries 
techniques possible control execution complex queries minimal coordination necessity configurations involving large number processors addition describing design gamma software thorough performance evaluation ipsc hypercube version gamma 
sets experiments performed 
constant machine configuration processors response standard set wisconsin benchmark queries measured different sizes relations 
subset queries measured performance system relative number processors sizes input relations kept constant speedup sizes input relations increased proportionally number processors scaleup 
speedup results obtained selection join queries perfectly linear dou number processors halves response time query 
scaleup results obtained quite encouraging 
reveal constant response time maintained selection join queries workload increased adding proportional number processors disks 
currently number new projects underway 
plan implementing chained tering mechanism evaluating effectiveness 
respect processing queries designed schn currently evaluating alternative strategies processing queries involving multiple join opera tions 
example consider query involving joins machine processors 
better processors join allocating memory processor join processors join case join operator full memory processor 
studying new partitioning mechanisms combine best features hash range partitioning stra 

large systems projects large number people listed authors possible 
bob gerber deserves special recognition design gamma plus leadership implementation prototype 
query optimizer implemented 
rajiv implemented read ahead mechanism improve performance sequential scans 
anoop sharma implemented aggregate algorithms embedded query interface 
goetz graefe joanna chen implemented predicate compiler 
deserve special credit willing debug machine code produced compiler 
jim gray susan tandem computers wisconsin benchmark relation generator 
generator tests conducted simply possible previously way generating relations larger tuples 

agrawal dewitt recovery architectures multiprocessor database machines proceedings sigmod conference austin tx may 
astr astrahan system relational approach database management acm transactions database systems vol 
june 
bitton dewitt benchmarking database systems systematic approach proceedings large database conference october 
blas gray price convoy phenomenon operating system review vol 
april 
transaction monitoring encompass tm reliable distributed transaction processing proceedings vldb 
brat hashing methods relational algebra operations proceedings large database conference august 
chou chou dewitt katz klug design implementation wisconsin storage system wiss software practices experience vol 
october 
cope copeland alexander keller data placement bubba proceedings acm sigmod international conference management data chicago may 
cope copeland keller comparison high availability media recovery techniques proceedings acm sigmod international conference management data portland oregon june 
dewi dewitt direct multiprocessor organization supporting relational database management systems ieee transactions computers june 
dewi dewitt katz olken shapiro stonebraker wood implementation techniques main memory database systems proceedings sigmod conference boston ma june 
dewi dewitt finkel solomon crystal multicomputer design implementation experience ieee transactions software engineering vol 
se august 
dewi dewitt gerber multiprocessor hash join algorithms proceedings vldb conference stockholm sweden august 
dewi dewitt gerber graefe kumar gamma high performance dataflow database machine proceedings vldb conference japan august 
dewi dewitt ghandeharizadeh schneider performance analysis gamma database machine proceedings acm sigmod international conference management data chicago may 
engl gray kocher shah benchmark nonstop sql release demonstrating near linear speedup scaleup large databases tandem computers technical report tandem part may 
programming manual tandem part tandem computers march 
gerber dewitt impact hardware software alternatives performance gamma database machine computer sciences technical report university wisconsin madison july 
ghandeharizadeh dewitt multiuser performance evaluation selection queries single processor database machine july submitted publication 
ghandeharizadeh dewitt performance analysis alternative declustering strategies proceedings th international conference data engineering los angeles ca february 
goodman investigation multiprocessor structures algorithms database management university california berkeley technical report ucb erl may 
graefe volcano compact extensible dynamic parallel dataflow query evaluation system working oregon graduate center portland february 
gray gray notes database operating systems rj ibm research laboratory san jose california february 
gray gray shortest seek vs shortest service time scheduling mirrored disks tandem computers december 
hsia hsiao dewitt chained declustering new availability strategy multiprocessor database machines proceedings th international conference data engineering los angeles ca february 
jarke koch query optimization database system acm computing surveys vol 
june 
kim kim synchronized disk interleaving ieee transactions computers vol 
november 
kits kitsuregawa tanaka oka application hash data base machine architecture new generation computing vol 

livny khoshafian boral multi disk management algorithms proceedings sigmetrics conference banff alberta canada may 
mohan pirahesh schwarz aries transaction recovery method supporting fine granularity locking partial rollbacks write ahead logging rj ibm almaden research center san jose california january 
patt patterson gibson katz case redundant arrays inexpensive disks raid proceedings acm sigmod international conference management data chicago may 
prot associates operation maintenance manual model waltham mass 
ries ries epstein evaluation distribution criteria distributed database systems ucb erl technical report uc berkeley may 
schn schneider dewitt performance evaluation parallel join algorithms shared multiprocessor environment proceedings sigmod conference portland june 
schn schneider dewitt design tradeoffs alternative query tree representations multiprocessor database machines computer sciences technical report university wisconsin madison august submitted publication 
selinger access path selection relational database management system proceedings sigmod conference boston ma may 
ston stonebraker case shared database engineering vol 

ston stonebraker katz patterson ousterhout design xprs proceedings fourteenth international conference large data bases los angeles ca august 
tand tandem performance group benchmark non sql debit credit transaction proceedings sigmod conference chicago il june 
tera teradata dbc database computer system manual release document 
teradata nov 
wagner indexing design considerations ibm system journal vol 
dec pp 


