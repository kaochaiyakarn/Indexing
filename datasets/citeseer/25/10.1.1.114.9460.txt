content soft annotation multimodal image retrieval bayes point machines edward chang electrical computer engineering university california santa barbara ece ucsb edu gerard computer science university california santa barbara gerard cs ucsb edu propose content soft annotation procedure providing images semantical labels 
annotation procedure starts labeling small set training images single semantical label forest animal sky 
ensemble binary classifiers trained predicting label membership images 
trained ensemble applied individual image give image multiple soft labels label associated label membership factor 
select base binary classifier experiment learning methods support vector machines svms bayes point machines compare class prediction accuracy 
empirical study category image set shows bpm ensemble provides better annotation quality svm ensemble supporting multimodal image retrievals 
keywords bayes point machines support vector machines image annotation multimodal image retrieval 
content image retrieval supports image searches perceptual features color texture shape 
users articulating content query low level features non intuitive difficult 
users prefer keywords conduct searches 
believe combined keyword content approach benefit strengths paradigms 
user start query entering keywords 
images relevant query image system uses images perceptual features annotation perform multimodal query refinement 
images annotated order support combined keyword content queries refinement 
propose content soft annotation approach provide images multiple semantical labels 
initial input training image set image manually annotated single semantical label 
mission propagate labels unlabeled images labeled ones 
annotation process image annotated label vector assigned confidence goh electrical computer engineering university california santa barbara engineering ucsb edu gang wu electrical computer engineering university california santa barbara engineering ucsb edu factor 
instance image training set initially labeled labels forest tiger sky 
process image annotated label vector labels 
image label vector forest tiger sky means image believed contain semantics forest tiger sky confidence respectively 
text search issued keywords images ranked retrieved combined confidence factors matching labels pointed automatic annotation may attain extremely high accuracy state computer vision image processing technology 
providing images reliable initial semantical labels refining unconfirmed labels relevance feedback believed effective approach 
discuss refinement methods improve annotation accuracy section ii 
aims initialize images set semantical words reliability significantly better chance 
empirical study shows initial annotation may perfect assists user find relevant images rapidly keyword search 
relevant images query refinement method mega employed zoom quickly user query concept 
specifically consists steps 
summarize steps follows highlight contributions manually labeling training images pre selected semantic labels 
labeling scheme simple involve segmenting images manual annotating image multiple keywords probabilities 
train classifiers 
labeled instances train ensemble binary classifiers bayes point query keyword label set multiple senses query refinement expansion needed translate initial query 
detailed treatment query refinement expansion scope study 
machines support vector machines svms 
classifier assumes task determining confidence score semantic label 
class ensemble automatically adapts kernel parameters laplacian kernel idiosyncrasies individual class 
empirical study shows employing base classifier outperforms svms accuracy 
provide theoretical justification superiority 
automatically annotating images classifiers 
image classified classifiers assigned confidence score label classifier attempting predict 
result nary label vector consisting class membership generated image 
rest organized sections 
section ii discuss related explaining approach differs 
section iii svms class opc ensemble schemes annotating images 
kernel parameters selection method tends minimize generalization errors 
section iv presents annotation method 
section discuss experimental results 
offer concluding remarks section vi ideas research 
ii 
related discuss related classification ensembles annotation 
related classification ensembles regression approach classification considers discrimination problem classes simultaneously 
method computationally expensive may impose universal assumption class boundaries 
flexible cheaper approach ensemble schemes 
ensemble methods divided categories design goals 
goal category reduce prediction variance caused training data selection 
known methods category include bagging arcing boosting 
goal second ensemble category reduce prediction error decomposition reconstruction methods error correction capability 
representative schemes 
class opc 
scheme trains binary classifiers classes 
classifier gives largest output determines class data point 

pairwise coupling pwc 
method trains binary classifiers provides partial decision classifying data point 
pwc combines output classifiers form class prediction 
study shows combining decision outputs differently may yield different class decisions 

error correcting output coding ecoc 
ecoc proposed dietterich bakiri reduce classification error exploiting redundancy coding schemes 
class assigned codeword length value larger number classes allows pair codewords large hamming distance error correction 
pairing possible codewords designed row column separation 
large optimal set codewords generated deterministically 
previous study schemes listed shows simple scheme opc performs elaborate schemes pwc ecoc applied image classification 
opc effectiveness substantially small number base classifiers training efficiency employ opc ensemble combining binary classifiers 
related annotation multimedia systems employ semantical information retrievals lexicon requiring framework extract represent semantics multimedia object 
provision intuitive interface users important 
oftentimes user provide example represents query concept system initial examples user choose 
interaction users refine existing annotations 
major challenge faced systems propagating semantical annotations small number labeled data large number unlabeled data 
semantics extraction semantical information mainly extracted ways 
image methods 
image segmentation techniques employed detect predefined objects image 
approach proposed chang uses semantic visual templates collection regional objects video shot express semantical concept user query 
templates refined twoway interaction user system 
tekalp propose extracting objects image color edge detection 
wang propose simplicity system captures semantics robust integrated region matching metric :10.1.1.29.3735
semantics classify images broad semantical categories textured graph photograph 
classification support semantics sensitive image retrievals 
ibm research develops semiautomatic video annotation tool 
tool provides interface user annotate different regions video shot 
annotation automatically propagated similar shots 

text methods 
text surrounding images analyzed system extracts appear relevant 
benitez chang method extract semantical concepts disambiguating words senses help lexical database wordnet 
addition relationships keywords extracted relations established wordnet 
approach proposed chang combines text image methods attach annotations images 
system able separate images main semantical concepts indoor outdoor 
semantics extracted naphade huang propose probabilistic framework represent video indexing retrieval 
probability density function denotes presence multimedia object 
interaction modeled bayesian network form multinet 
approaches mentioned rely local features turn rely high segmentation accuracy 
segmentation hardly done reliably especially compressed images 
performs annotation global features uses bpm opc ensemble provide multiple semantical labels image need segmentation 
empirical results show global features perform salient object recognition semantical understanding reasonably 
category image dataset images training data annotation accuracy remaining testing data respectively 
annotation propagation image annotation techniques involve sort propagation 
small subset images manually annotated 
annotation propagated rest database machine learning statistical methods 
picard minka image texture propagate annotation 
user labels patch image label propagated images similar patches texture 
object extracted image compared set predefined object templates match template annotation object 
naphade lin smith system contains lexicon learnt users annotated examples 
formulation semantical relationships lexicon modeled classification problem 
resulting retrieval system able support keyword queries detect multimodal events 
relevance feedback improve annotation quality 
user types keywords query user picks positive negative examples 
positive examples query keywords added strengthened negative examples keywords weakened removed 
schemes depend availability reasonable set initial image labels provide effectively efficiently 
iii 
choice classification scheme regression approach classification considers discrimination problem classes simultaneously 
discussed section ii regression approach computationally expensive may impose universal assumption class boundaries 
flexible computationally inexpensive approach ensemble schemes 
schemes decompose class problems number binary sub problems simpler binary classifier solve smaller sub problems 
conducting content soft annotation bayes point machines binary simple effective ensemble scheme known class 
call combination bpm opc 
section statistical learning methods support vector machines svms 
svms regarded approximation bootstrap svms set context discussing theoretical differences emerging learning methods 
kernel parameter selection algorithm 
svms employ kernel function project training data higher dimensional feature space data different classes separated hyperplane 
discuss proper kernel classifying images algorithm adaptively tune kernel parameters minimize generalization error 
details opc ensemble scheme 
learning methods svms svms core machine learning technology strong theoretical foundations excellent empirical successes 
consider svms binary classification setting 
training data 
xn vectors space labels 
yn yi 
simplest form svms hyperplanes separate training data maximal margin 
vectors lying side hyperplane labeled vectors lying side labeled 
training instances lie closest hyperplane called support vectors 
generally svms allow project original training data space higher dimensional feature space mercer kernel operator words consider set classifiers form ik xi 
classify classify 
satisfies mercer condition write denotes inner product :10.1.1.117.3731:10.1.1.117.3731:10.1.1.117.3731
rewrite xi 
svm computes correspond maximal margin hyperplane choosing different kernel functions project training data different spaces hyperplanes correspond complex decision boundaries original space commonly kernel functions include polynomial kernel gaussian radial basis function rbf kernel laplacian rbf kernel ui vi :10.1.1.117.3731
image concepts linearly separable projected space need allow training errors 
need gives rise soft margin svm algorithm :10.1.1.15.9362
soft margin svms formulated special case hard margin version modified kernel adding factor penalize training errors 
bayes point machines proposed herbrich approximate bayesian inference lin fig 

difference svm bpm classifiers 
hypersphere left svm approximates bayes point star symbol center largest sphere embedded version space 
hypersphere right see svm solution far bayes point 
happens largest embedded sphere cover large volume version space 
ear classifiers kernel space 
illustrate difference svms define terms 
hypothesis commonly referred classifier function maps input vector output label set consistent hypotheses training set called version space point version space constitutes plausible classifier 
svm hypothesis constructed finding hyperplane maximizes margin positive negative training examples 
version space margin examples distance classifier closest boundary space 
maximal margin radius largest sphere embedded version space svm classifier center sphere 
contrast construct hypothesis attempting find center entire version space 
center called bayes point 
illustrates scenario hypothesis obtained svms quite inaccurate respect theoretically optimal bayes point 
discuss bayes point computed 
bayes solution bayes point adopt strategy bayes classification classifier considering valid solutions entire version space 
training set 
xm ym size bayes classification aims assign new test data label minimal expected loss weighted posterior probability ph zm arg min eh zm loss function defined bayes solution equation optimal classification task 
generally impossible find unique hypothesis order obtain 
herbrich attempts find classifier closest requiring classifier lie fixed hypothesis space approximation hbp arg min ex 
fig 

illustration billiard algorithm 
small ball represents estimate wi center mass wcm bounce step 
final wcm obtained averaging estimates 
classifier hbp called bayes point approximates optimal best 
weight vector hbp 
center mass computing equation requires knowledge input training distribution px hard obtain 
fortunately class classification problem suggests method find center mass assumption follows wcm ew zm 
ew zm note hypothesis weight vector synonymously called classifier oneto correspondence 
equation approximation bayes point hbp find optimal weight vector calculating wcm 
order calculate center mass wcm suggests order markov chain compute expectation equation approximated uniformly sampling weight vectors averaging 
difficult perform samplings points exist convex polyhedron unit sphere 
algorithms proposed achieve sampling described follows billiard ball algorithm 
algorithm billiard method 
entering version space perceptron svm algorithm classifier envisioned billiard ball bounced convex polyhedron 
playing possible training point xi yi defines hyperplane yi xi see 
bounces billiard ball bayes point esti mated wcm wi 
details gleaned 
perceptron algorithm 
billiard algorithm shows generalization performance suffers large computational costs 
suggested approximate uniform sampling version space sufficient finding wcm 
suggestion fact classifier optimal 
second method uses perceptron algorithm obtain different classifiers wis simply training set 
center mass averaging wis bpm opc implementation svms delimit version space billiard ball algorithm approximate center mass kernel parameters selection image classification works show distance function effective similarity measure high dimensional data 
empirical result shows laplacian rbf utilizes distance function works high dimensional image data 
uses laplacian rbf kernel 
choice laplacian kernel soft margin svms initialize version space ensemble tunable parameters laplacian kernel controls shape kernel 
larger value narrower shape ui vi :10.1.1.117.3731
high value leads narrow shape possible overfitting 
lower value wider shape produces low prediction accuracy 
controls trade offs margin maximization error minimization 
increasing may decrease training error lead poor generalization 
parameters control generalization ability svms 
algorithmically predict best set parameters minimize generalization error remains open research problem 
machine learning community provided bounds produced training results estimate generalization error 
widely accepted approach leave bound 
leave procedure removes instance training set testing instance 
suppose training set consists training instances 
procedure constructs decision rule remaining training data tests rule testing instance 
procedure repeated times instances training set tested 
error average error tests 
known leave procedure gives unbiased estimate expected generalization error 
unfortunately computationally intensive run training times 
study summarizes practical approximations leave error 
choices nsv nsv denotes number support vectors estimate generalization error 
burges shows parameter setting maximizes necessarily minimize generalization error find derivative denoted respect useful ways :10.1.1.117.3731
incrementally increase rbf kernel increases 
near encounters sharp decline setting tends produce minimal generalization error maximal accuracy accuracy leave bound accuracy leave bound leave bound accuracy gamma leave bound accuracy fig 

leave bound indicates parameters 
shown 
believe problem overfitting may start place point 
increase lead increase number support vectors increasing counter productive reasons 
may improve generalization error shown 
second larger longer training time 
cost effective choose flats 
observations propose algorithm depicted adaptively select optimal kernel parameters 
algorithm begins default parameters repeatedly trains training images order find setting 
setting algorithm find setting 
class ensemble scheme classification problem involves function 
defines partition input space sets called classes denoted class problem hyperplane svms partition sgn equivalent 
svms mainly applied class problems adapted multi class problems ensemble schemes 
scheme called class opc 
opc simple gives satisfactory performance 
number classes large need train binary classifiers opc 
pwc scheme requires binary classifiers 
ecoc schemes error correction capability length codewords determines number binary classifiers needs larger requiring large number classifiers impacts training time speed classification 
opc fastest ensemble scheme classification performance compares favorably complex schemes 
algorithm select svm parameters input training set images output opt optimal rbf width copt optimal training error penalty variables rbf width iteration ci training error penalty iteration ti leave bound nsv iteration op ci svm classifier iteration procedure calls train svm calculate init initialize small values default init repeat increase op ci train svm ti calculate ti ti ti opt repeat increase flattens training error ci ci op ci train svm opt ci ti calculate ti ti training error copt ci return opt copt fig 

algorithm selecting svm kernel parameters 
classes train classifiers separates class classes 
point decision outputs fk class point arg maxk fk 
iv 
image annotation section explain method assigns labels unannotated images bpm opc 
describe image features propagating image labels 
content soft annotation image classification systems classifying image predefined categories 
usually confidence score associated category 
highest chosen image category rest ignored 
interested category scores 
define set labels label characterizes representative semantics image category 
table appendix shows category names number images belonging 
top level categories images architecture animal food landscape objects people plants 
unannotated image classified categories bpm opc 
produces ranking categories category assigned confidence probability 
labels categories probabilities annotation image 
probability represents weight label description image 
rationale image say landscape clouds sky classified classifier assign highest probability landscape label second highest probability clouds label 
ranking useful retrievals 
image annotated associated nary label vector 
element vector keyword value element weight keyword 
typical vector may look landscape cloud tiger 
image features section describes system characterizes images 
image features help propagate annotation trained images unlabeled images 
believe image characterization emulate human perception insofar possible 
perception works multi resolution fashion 
visual tasks human eyes may select coarse filters obtain coarse image features select finer features 
similarly image applications detecting image replicas employing coarse features sufficient applications classifying images employing finer features may essential 
image search engine flexibility model subjective perceptions fulfill variety search tasks 
image retrieval system characterize images main features color texture 
consider shape attribute main features 
color wavelength visible light ranges research shows colors named cultures generally limited eleven 
addition black white discernible colors red yellow green blue brown purple pink orange gray 
divide color color bins including bins culture colors common cultures bin outliers 
coarsest resolution characterize color color mask bits 
record color information finer resolutions record additional features color 
features color histograms color means channels color variances channel shape characteristics elongation 
color elongation characterizes shape color characterizes color scatters image 
table summarizes color features coarse medium fine resolutions 
table multi resolution color features 
filter name resolution representation masks coarse appearance culture colors spread coarse spatial concentration color elongation coarse shape color histograms medium distribution colors average medium similarity comparison culture color variance fine similarity comparison culture color texture texture important cue image analysis 
studies shown characterizing texture features terms structuredness orientation scale coarseness fits models human perception 
wide variety texture analysis methods proposed past 
computational efficiency choose discrete wavelet transformation dwt quadrature mirror filters 
wavelet decomposition image yields subimages scaled image input image wavelets orientations horizontal vertical diagonal 
decomposing scaled image obtain tree structured wavelet packet decomposition 
wavelet image decomposition provides representation easy interpret 
subimage contains information specific scale orientation retains spatial information 
obtain texture combinations subimages scales orientations 
subimage retains spatial information texture compute elongation texture channel 
summarizes texture features 
coarse level medium level fine level vertical horizontal diagonal energy mean energy variance texture elongation texture energy mean energy variance texture elongation texture fig 

multi resolution texture features 
energy mean energy variance texture elongation texture image extract color texture information produce dimension vector numbers 
vector represent image 
input space bpm classifiers dimension space image database corresponds point space 
experimental results experiment divided major parts classification schemes evaluation 
evaluate performance adaptive parameters selection algorithm 
best parameters setting compare classification performance svm opc bpm opc soft annotation 
assign bag probabilities derived bpm opc test image 
test correctness soft annotation test image 
empirical studies image dataset contains images accumulated corel image cds internet 
corel images widely computer vision image processing research communities 
order fulfill experimental goals divide dataset subsets image dataset 
smaller set images evaluate bpm svm classifiers various kernel parameters 
set contains representative images fifteen corel categories architecture bears clouds elephants fabrics fireworks flowers food landscape people objectionable images textures tigers tools waves 
categories added increase learning difficulty classifiers 
landscape category difficult learn placed images tigers elephants landscape water backgrounds 
objectionable image category differentiated people category image people wearing little clothing 
added colorful fabrics food interfere flowers 
various texture images skin brick grass water added raise learning difficulty categories 
image dataset 
set contains images manually classified categories 
see table appendix details 
set contains images diversified challenging learning algorithm 
dataset show classification scheme scalable large number categories 
dataset train classifiers provide probabilities soft annotations 
classification schemes experiments classification experiment divided parts conduct extensive analysis parameters svms laplacian rbf kernel 
adaptive parameters selection algorithm find set parameters second part experiment 
compare classification performance svm classifiers bpm parts experiment image dataset 
evaluate scalability performance svm bpm classifiers image dataset 
measure classification performance experiments classification error 
ran experiment times 
run randomly selected percentage images testing recall testing recall gamma shape predicts optimal 
fig 

data representative class 
scaled factor 
testing recall testing recall shape indicates value dataset training examples classifiers 
remaining images classification 
results represent average runs 
analysis analytical purposes look affect classification results number ways 
various combinations train svm classifiers data test remaining 
classes 
class gather training testing recall leave bound recall defined number positive instances correctly labeled annotated positive number positive instances dataset 
examine effectiveness adaptive algorithm evaluating selected kernel parameters improve svm opc testing recall 
plot scaling factor testing recall representative class 
vary fix 
shows leave bound increases increased knee curve predicts optimal value class 
recall decreasing rbf width nsv grows 
shows similar experiment fix vary graph testing recall increases increases flattens 
value bound flattens closely matches value optimizes testing recall 
increases recall remains unchanged 
plot increase 
values correspond small correctly approximate optimal 
algorithm picks value 
figures illustrate iterations algorithm 
distribution svm training output display training recall testing recall 
shows sub optimal trained classifier cleanly separate training data classes training instances fall svm margin axis 
increase figures number instances margin decreases training error 
fix reaches knee 
increase 
gamma increased small 
table ii adaptively generated parameters class 
category architecture bears clouds elephants fabric fireworks flowers food landscape obj 
images people texture tigers tools waves testing recall achieves best result 
algorithm select classes see table ii 
classification performance svm opc vs bpm opc parameters table ii evaluate classification performance svm opc bpm opc classifiers 
image dataset training classifiers remaining testing 
bpm opc tolerance parameter termination billiard algorithm set 
table iii shows classification error rate categories 
error rates svm opc low observe bpm opc obtain lower error rate categories 
decrease average 
training time bpm classifier substantially longer svm classifier 
apply classification schemes larger category dataset 
set aside images testing data remaining images training 
perform rounds svm opc bpm opc classification round different percentage training images 
generated classifiers tested image testing set 
shows classification error svm bpm opc test set 
despite having categories closely related svm bpm classifiers able provide acceptable classification performance 
frequency frequency svm output training recall testing recall svm output training recall testing recall fig 

iteration improved classification 
just training data maintain relatively low classification error rate svm opc bpm opc 
increase training percentage errors drop svm opc bpm opc 
performance gap bpm opc svm opc category dataset significant 
training bpm opc takes times longer training svm opc bmp opc better choice conduct class prediction offline 
table iii classification error rates svm opc bpm opc image dataset training 
category svm opc bpm opc architecture bears clouds elephants fabric fireworks flowers food landscape obj 
images people texture tigers tools waves average analyze effect category size error rates 
divide categories groups small group categories fewer images medium group cate frequency frequency svm output training recall testing recall svm output 
training recall testing recall fig 

error rates image testing set 
frequency svm output training recall testing recall search space best gories fewer images large group categories images 
table iv shows average error rates categories groups dataset training 
see error rate small group worse svm opc bpm opc large group difference medium large groups smaller compelling 
phenomenon due class imbalance large group provide positive examples represented training set 
small group number positive examples training set insignificant compared number negative examples class boundary formed classifier may generalize 
soft annotation results classifiers generated training data image dataset produce set bpm opc values unannotated image 
values converted table iv error rates different category sizes dataset training 
percentage training svm opc bpm opc small images medium images large images probabilities order depict likelihood category label describing image correctly 
probability greater implies annotation shows high level confidence probability implies low confidence level 
probabilities greater may provide useful secondary annotation image 
label gives highest probability denoted second label second highest probability 
texture texture apple texture bead texture tree texture seed useful nd labels texture deer texture leaf texture sky texture useless nd labels fig 

examples texture query 
images confidently annotated 
images useful second labels 
images wrong second labels 
mountain mountain canyon mountain field mountain lake mountain snow useful nd labels mountain goat mountain lizard mountain lake mountain coast useless nd labels fig 

examples mountain query 
images confidently annotated 
images useful second labels 
images wrong second labels 
examples annotation results 
example texture images second mountain images example city images 
row images figures portrays scenarios city city coast city lake city garden city skyscraper useful nd labels city desert city castle city goat city temple useless nd labels fig 

examples city query 
images confidently annotated 
images useful second labels 
images wrong second labels 
case 
see row figures 
label able provide annotation may confident 
see examples row label accurately describes images 
second label label supersedes labels 
case 
see row figures 
case high greater 
see images row second label enrich description image 
texture images second label adds semantical context texture label 
secondary annotations snow semantically close word mountain frequently give additional information 
general label lake trusted time 
case 
see row figures 
case see examples label correctly annotates image secondary annotation completely wrong 
probability case usually 
remarks just labeled data train bpm opc classifiers achieve label propagation un annotated images reasonable accuracy 
provides suitable initial labeling improved methods users relevance feedback 
multiple keyword searches supported combined confidence level second label high 
combined confidence level computed multiplying 
obtain high combined confidence level greater close 
high confidence level diluted combined probability 
second label 
addition effect indicates low confidence annotation second label 
value low discard second label annotation 
vi 
order support multimodal image retrievals semi automate process annotating unlabeled images multiple soft labels 
uses small percentage manually labeled data train bpm opc ensemble 
ensemble applied images ensemble outputs mapped probabilities 
image characterized bag words 
words relevancy image indicated probability values 
approach associating probabilities labels establishes baseline initial labeling improved users relevance feedback active learning 
expanded directions 
improve query effectiveness system adding query expansion text lexical system wordnet domain specific thesaurus 
way query confined initial labels 
second improve effectiveness efficiency bpm opc ensemble 
effectiveness enhancement investigating statistical methods deal challenges unbalanced training set class substantially smaller binary classification setting 
efficiency enhancement investigating methods improving computational time approximate bayes point 
works perceptual feature mining perceptual distance functions active learning indexing methods believe provides glue integrate content keywords supporting effective multimodal image retrievals 
aggarwal hinneburg keim 
surprising behavior distance metrics high dimensional spaces 
proceedings icdt pages january 
allwein schapire singer 
reducing multiclass binary unifying approach margin classifiers 
journal machine learning research dec 
barnard forsyth 
learning semantics words pictures 
int 
conf 
computer vision volume pages 
barnard forsyth 
clustering art 
cvpr pages dec 
benitez 
chang 
semantic knowledge construction annotated image collection 
proceedings ieee international conference multimedia august 
breiman 
bagging 
machine learning pages 
breiman 
arcing classifiers 
annals statistics pages 
burges :10.1.1.117.3731
tutorial support vector machines pattern recognition 
data mining knowledge discovery 
chang li 
mega maximizing expected generalization algorithm learning complex query concepts extended version 
technical report stanford edu mega pdf nov 
chang li li 
perception image retrieval 
ieee content access image video libraries pages june 

chang chen sundaram 
semantic visual templates linking visual features semantics 
proceedings ieee international conference image processing 
chapelle vapnik bousquet mukherjee 
choosing multiple parameters support vector machines 
machine learning 
cortes vapnik :10.1.1.15.9362
support vector networks 
machine learning 
dietterich bakiri 
solving multiclass learning problems error correcting output codes 
journal artifical intelligence research 
friedman 
approach classification 
stanford university technical report 
goh chang cheng 
svm binary classifier ensembles image classification 
proc 
acm cikm pages november 
goh li chang 
dynamic nonmetric space indexer 
acm international conference multimedia pages december 
goldstein 
sensation perception th edition 
brooks cole 
herbrich graepel campbell 
bayes point machines estimating bayes point kernel space 
international joint conference artificial intelligence workshop support vector machines pages 
herbrich graepel campbell 
bayes point machines 
journal machine learning research pages 
hinneburg aggarwal keim 
nearest neighbor high dimensional spaces 
proceedings th vldb pages september 
hua vu 
oh 
flexible efficient sampling image retrieval technique image databases 
proceedings acm multimedia pages november 
joachims 
transductive inference text classification support vector machines 
proceedings sixteenth international conference machine learning pages 
morgan kaufmann 

leu 
computing shape moments boundary 
pattern recognition 
li chang 
discovery perceptual distance function measuring image similarity 
acm multimedia journal special issue appear 
li chang 
wu 
dynamic partial function 
ieee conference image processing september 
li 
lai chang 
cheng 
mining image features efficient query processing 
proc 
ieee data mining pages november 

estimation characters obtained statistical procedure re cognition 
russian 
ma zhang 
benchmarking image features content retrieval 
proceedings asilomar conference signal systems computers 
manjunath wu shin 
texture descriptor browsing similarity retrieval 
journal signal processing image communication september 
moreira 
improving pairwise coupling classification error correcting classifiers 
proceedings tenth european conference machine learning april 
mori takahashi oka 
automatic words assignment images image division vector quantization 
proc 
riao content multimedia information access april 
naphade huang 
probabilistic framework semantic indexing retrieval video 
proceedings ieee international conference multimedia pages august 
naphade 
lin smith tseng basu 
learning annotate video databases 
spie electronic imaging storage retrieval media databases january 
naphade 
lin smith 
learning semantic multimedia representations small set examples 
proceedings ieee international conference multimedia 
paek sable hatzivassiloglou schiffman chang mckeown 
integration visual approaches content labeling classification photographs 
workshop multimedia indexing retrieval 
picard minka 
vision texture annotation 
journal multimedia systems 

playing billard version space 
neural computation 
marchand 
computing bayes kernel classifier 
advances large margin classifiers pages 
tekalp 
region affine shape matching automatic image annotation query example 
journal visual communication image representation mar 
schapire freund bartlett lee 
boosting margin new explanation effectiveness voting methods 
annals statistics volume pages 
shen ooi tan 
giving meanings www images 
proc 
acm multimedia pages november 
smith 
chang 
automated image retrieval color texture 
columbia university technical report tr july 
chang 
goh 
effective image annotation active learning 
proceedings ieee international conference multimedia 
tamura mori 
texture features corresponding visual perception 
ieee transaction systems man smc 
tong chang 
support vector machine active learning image retrieval 
acm international conference multimedia pages october 

upper bounds training error ecoc svm ensembles 
technical report feb 
vapnik 
nature statistical learning theory 
springer new york 
vapnik 
statistical learning theory 
wiley 
wang li wiederhold :10.1.1.29.3735
simplicity integrated matching picture libraries 
ieee transactions pattern analysis machine intelligence 

optimal learning neural network 
letters 
dumais sun zhang czerwinski field 
semi automatic image annotation 
proc 
interact conference human computer interaction pages jul 
appendix table category names sizes image dataset 
couple ship apple crane lighthouse sign bead deer lion sky bear desert lizard skyscraper berry dish machine snake beverage dog man snow dolphin monkey space bridge duck mountain squirrel buffalo eagle mushroom stone bug elephant orange sunset building field temple butterfly owl texture cactus fish tiger cake forest parrot tool camel fox pattern tower canyon frog penguin train castle furniture pig tree cat garden pyramid tulip giraffe rabbit turtle cave goat ram vegetable cheetah grass waterfall chicken group rock wave child hippo 
rose whale china horse church industry seal city instrument windmill cliff island seed wolf cloud lake shark woman coast leaf sheep zebra 
