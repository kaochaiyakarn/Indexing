ieee journal selected areas communications vol 
february turbo decoding instance pearl belief propagation algorithm robert mceliece fellow ieee david mackay jung fu cheng describe close connection celebrated iterative turbo decoding algorithm berrou algorithm known artificial intelligence community decade relatively unknown information theorists pearl belief propagation algorithm 
shall see pearl algorithm applied belief network parallel concatenation codes turbo decoding algorithm immediately results 
unfortunately belief diagram loops pearl proved algorithm works loops explanation excellent experimental performance turbo decoding lacking 
shall show pearl algorithm routinely derive previously known iterative suboptimal decoding algorithms number error control systems including gallager low density parity check codes serially concatenated codes product codes 
belief propagation provides attractive general methodology devising low complexity iterative decoding algorithms hybrid coded systems 
index terms belief propagation error correcting codes iterative decoding pearl algorithm probabilistic inference turbo codes 
summary turbo codes introduced berrou exciting potentially important development coding theory years 
structural properties turbo codes put firm theoretical footing innovative variations turbo theme appeared 
lacking satisfactory theoretical explanation turbo decoding algorithm performs 
announce solution problem believe answer may come close study pearl belief propagation algorithm largely unknown information theorists known artificial intelligence community 
mention belief propagation communications manuscript received september revised may 
supported nsf ncr afosr qualcomm portion mceliece contribution done visiting sony tokyo 
collaboration mackay mceliece begun partially supported newton institute mathematical sciences cambridge mceliece department electrical engineering california institute technology pasadena ca usa 
mackay cavendish laboratory department physics darwin college cambridge university cambridge cb 
cheng salomon brothers new york ny usa 
publisher item identifier 
ieee motivated mackay neal 
see 
review turbo decoding algorithm originally expounded berrou explained 
describe pearl algorithm natural ai setting show applied belief network turbo code turbo decoding algorithm immediately results 
unfortunately belief network loops pearl algorithm gives exact answers loops existing body knowledge pearl algorithm solve central problem turbo decoding 
interesting suggestive pearl algorithm yields turbo decoding algorithm easily 
furthermore shall show pearl algorithm derive effective iterative decoding algorithms number error control systems including gallager low density parity check codes introduced generator matrix codes serially concatenated codes product codes 
bp decoding algorithms agree ones previously derived ad hoc methods new prove remarkably effective 
short belief propagation provides attractive general method devising low complexity iterative decoding algorithms hybrid coded systems 
message 
similar message kschischang frey issue 
outline 
section ii derive simple important results introduce compact notation optimal symbol decision decoding algorithms 
section iii define mean turbo code review turbo decoding algorithm 
definitions deliberately general previously appeared literature 
particular transmitted information binary comes ary alphabet means deal ary probability distributions traditional log likelihood ratios furthermore reader may surprised find discussion essential component turbo coding systems 
articulate fully concluding remarks believe interleaver contribution turbo code code directly fact turbo decoding algorithm approximation optimal decoder 
section iv change gears give tutorial overview general probabilistic inference problem special bayesian belief networks 
section mceliece turbo decoding pearl algorithm fig 

codeword ia transmitted memoryless channel received describe pearl bp algorithm defined belief network gives exact solution probabilistic inference problem belief network loops 
section vi show turbo decoding algorithm follows routine application pearl algorithm appropriate loopy belief network 
section vii briefly sketch decoding algorithms derived bp considerations 
section viii summarize findings venture 
ii 
preliminaries section describe general class ary systematic encoders derive optimal symbol symbol decoding rule memoryless channel 
dimensional random vector independent necessarily equiprobable symbols letter alphabet vector represents information transmitted reliably unreliable channel 
suppose encoded systematically mapped codeword form systematic part nonsystematic part codeword rest call codeword fragment 
assume codeword transmitted noisy channel transition probabilities received portion corresponding systematic part codeword portion corresponding codeword fragment assume channel memoryless implies conditional density factors rule denotes th component situation depicted fig 

decoding problem infer values hidden variables evidence viz 
observed values variables optimal decision minimizes probability inferring incorrect value conditional probability belief information symbol question value communication theorist term posteriori probability belief decoder infers straightforward computation central results 
computation rest pearl notation 
definition vectors nonnegative real numbers notation means words probability vector components proportional nonnegative real valued functions defined finite set notation defined similarly 
lemma likelihood denoted belief defined proof definition notation lines calculation assertions lemma 
see product terms 
term called systematic evidence term 
second term takes account priori distribution note effect systematic evidence effect change prior distribution third term encoder systematic uncoded information symbols transmitted likelihoods set equal 
ieee journal selected areas communications vol 
february table update rules pearl algorithm iy real numbers complicated takes account geometry code 
call term extrinsic term denote extrinsic term important follows shall introduce special notation 
notation prove useful section shall describe pearl algorithm see table line 
finite alphabets denote set real numbers 
function mapping words vector real valued functions suppose real valued function defined set call kernel 
transform vector defined summarize writing vector valued functions define adjacent product simple componentwise product circle adjacent notation express result lemma compactly 
take define kernel assume adjacent takes precedence circle order minimize parentheses 
codeword fragment deterministic function lemma summarized follows iii 
systematic parallel concatenated turbo codes section define mean turbo code general version turbo decoding algorithm 
setup section ii suppose systematic encodings way combine single code mapping called parallel concatenation turbo code formed combining assume codeword transmitted noisy channel transition probabilities received component corresponding component corresponding component corresponding assume channel memoryless implies conditional density factors rule situation depicted fig 

mceliece turbo decoding pearl algorithm fig 

generic turbo code codeword iy pa transmitted memoryless channel received iy lemma optimal decisions turbo code beliefs simplicity accordance engineering practice assume priori probability density uniform assumption notation introduced section ii kernels defined celebrated turbo decoding algorithm iterative approximation optimal beliefs performance demonstrably suboptimal proved nearly optimal impressive array experiments 
heart turbo algorithm iteratively defined sequence product probability densities defined list uniform densities odd 
th turbo belief vector defined general form shown fig 

practical decoder decision information bits usually fixed number iterations 
hope limit exist general vain examples observed earlier effect change prior distribution follows nonuniform prior accounted replacing occurrence formulas fig 

block diagram turbo decoding procedure 

decision iterations th turbo decision defined conclude section observing stated turbo algorithm appear significantly simpler optimal algorithm example general easier compute theorem discussion follows shed light problem 
theorem components assumed independent odd proof consider case odd proof essentially 
reasoning similar lemma find divide sides obtain theorem follows 
significance theorem tells appropriate components vectors computed decoder capable computing probabilities observation noisy codeword optimal soft symbol decision decoder 
th component message passed second decoder module extrinsic information referred earlier 
ieee journal selected areas communications vol 
february keys success turbo codes component codes low complexity soft bit decision algorithm exists 
example app decoding algorithm provides algorithm code block convolutional represented trellis 
far known code low complexity optimal decoding algorithm achieve high performance means individually codes relatively weak 
brilliant innovation berrou devise code type shown fig 
individual codes relatively weak low complexity decoding algorithm way code powerful 
roughly speaking accomplished making encoder identical random permutation accomplished interleaver inputs 
encoders short constraint length systematic convolutional encoders feedback 
object study decoding algorithm regard resulting performance shall discuss constructive aspect turbo codes 
iv 
background probabilistic inference bayesian belief networks pearl algorithm section give tutorial overview called probabilistic inference problem artificial intelligence community brief discussion pearl algorithm solves probabilistic inference problem important special cases 
set discrete random variables assumes values finite alphabet joint density function mapping set real numbers assume marginal densities known 
marginal density function represents priori belief random variable suppose random variables measured observed means subset evidence set random variable known particular value say evidence defined event fundamental probabilistic inference problem compute updated beliefs posteriori conditional probabilities brute force approach computing sum terms involve shall see section iv algorithm variations special cases pearl algorithm 
application algorithm provably exact corresponding belief diagram loops 
upper case denote codeword components example 
upper case denote arbitrary random variables hope confusion occur 
fig 

simple example dag represents variable directed markov field see 
dag loopy vertices iy qy ry forming loop 
simplify notation assume assume different values computing sum possible value requires additions impractical small numbers 
idea bayesian belief network approach inference problem exploit partial independencies may exist simplify belief updating 
simplest case random variables mutually independent case avoided altogether observation variable affect belief 
generally partial independencies described directed acyclic graph dag 
dag finite directed graph directed cycles 
example fig 
shows dag vertices edges 
agree directed edge called parent called child set parents vertex denoted describe graph fig 
follows dag set random variables correspondence vertices joint density function said factor denotes value assignment parents example variable density function mceliece turbo decoding pearl algorithm fig 

bayesian network interpretation decoding problem 
factors graph fig 
set random variables density functions factor dag called directed markov field 
example directed chain ordinary markov chain 
dag associated random variables called bayesian belief network network short 
point observe general coding framework fig 
represented bayesian network shown fig 

decoder viewpoint observed noisy information bits probabilistic functions hidden information bits similarly observed noisy codeword fragment probabilistic function codeword turn deterministic function hidden input bits 
fig 
implies information bits independent 
decoder problem infer values hidden variables evidence variables bayesian networks lead considerable simplifications probabilistic inference problem 
important simplifications purposes pearl belief propagation algorithm 
kim pearl showed dag tree loops efficient distributed algorithms solving inference problem 
alphabets size pearl algorithm solves inference problem trees computations maximum number parents vertex number unknown random variables required brute force method 
efficiency belief propagation trees stands sharp contrast situation general dag cooper showed inference problem general dag np hard 
see np hardness probabilistic inference bayesian networks 
network fig 
tree pearl algorithm apply 
result uninteresting pearl algorithm applied bayesian network merely gives alternative derivation lemma 
loop cycle underlying undirected graph 
example dag fig 
loop 
fig 

bayesian network hidden markov chain problem 
iy form markov chain iy noisy versions iy xx problem compute conditional probabilities hidden variables evidence variables profitable application pearl algorithm classic hidden markov chain inference problem appropriate bayesian network shown fig 

result linear time exact solution functionally identical celebrated forward backward algorithm discovered important feature pearl bp algorithm defined arbitrary dag necessarily tree guarantee algorithm perform useful calculation loops dag 
believe key success turbo codes potentially important research area ai community experimentally observed fact pearl algorithm works approximately loopy dag shall explain connection turbo codes bp section vi describing bp algorithm detail section preview coming attractions fig 
loopy bayesian network appropriate turbo decoding problem 
detailed description pearl algorithm section give detailed functional description pearl algorithm described ch 

forward backward algorithm long convoluted history merits attention science historian 
appeared unclassified literature independent publications 
soon appeared papers map detection digital sequences presence intersymbol interference 
appeared explicitly algorithm tracking states markov chain early see survey papers 
similar algorithm form appeared equalization 
algorithm connected optimization literature 
activity appears completely independent developments ai led pearl algorithm 
exact inference algorithm arbitrary dag developed lauritzen spiegelhalter solves inference problem computations number cliques undirected triangulated moralized graph derived qy maximum number vertices clique proves helpful turbo decoding problem appropriate dag produces moralized graphs huge cliques 
example turbo codes associated clique size 
fig 
compared wiberg fig 
describes tanner graph turbo code 
figures similar key difference 
wiberg incorporates turbo code interleaver citing interleaver necessary ensuring short cycles graph 
fig 
hand short cycles 
belief presence short cycles cases compromise performance decoding algorithm may degrade quality code 
expand remarks 
ieee journal selected areas communications vol 
february fig 

bayesian network interpretation turbo decoding problem 
note presence loops ix pearl belief propagation algorithm decentralized message passing algorithm processor associated vertex processor communicate parents children 
furthermore processor associated variable assumed know conditional density function parents parents knowledge assumed marginal density function local environment node shown fig 

processor activated reads messages received parents children updates belief messages sends new messages back parents children 
message node receives parent denoted form list probabilities probability value informally probability event conditioned evidence tree known similarly message receives child denoted form list nonnegative real numbers likelihoods likelihood value informally probability evidence knows conditioned event simplicity adopt vector notation incoming messages situation summarized fig 

activated message passes child denoted list probabilities value roughly speaking probability event evidence tree known includes new evidence may contained incoming messages 
similarly message passes parent denoted probability evidence knows fig 

summary pearl algorithm 
boldface symbols denote random vectors ordinary symbols represent random variables 
event adopt vector notation situation summarized fig 

additionally node graph keeps track number quantities mceliece turbo decoding pearl algorithm quantities particular intrinsic significance quantity heart algorithm algorithm terminates gives value desired conditional probability complete description pearl algorithm 
node activated reads incoming messages updates order update rules table initial values table ii 
table notation vector real numbers 
node activated incoming messages exist 
order node activation arbitrary 
pearl proved dag tree number iterations equal diameter tree node correctly computed belief probability associated random variable conditioned evidence tree changes beliefs occur 
network tree algorithm definite termination point practice termination rule chosen predetermined number iterations computed beliefs cease change significantly 
vi 
turbo decoding instance bp section show formally pearl bp algorithm applied belief network fig 
result algorithm identical turbo decoding algorithm described section iii 
precisely show network fig 
initialized rules table ii nodes updated table order results summarized table iii 
particular sequence beliefs table ii initialization rules pearl algorithm table iii pearl algorithm applied belief network fig 
nodes activated order shown column information symbols agreement 
verify entries table iii 
discuss necessary initializations 
source node parents assuming prior distribution independent uniform line table ii quantity permanently set follows permanent direct evidence nodes evidence nodes parent line table ii message sends permanently set follows permanent nodes evidence nodes line table ii messages send ieee journal selected areas communications vol 
february initially set follows temporary appears vector notation line table iii 
simultaneously activate nodes source node necessary evaluate messages 
line table similarly line table vector notation equivalent appears line table iii 
message sends line table vector notation appears line table iii 
similar calculation gives appears line table iii 
update quantities required update evidence node evidence node line table ii message permanently fixed line table fixed permanent compute line table deterministic function follows equal value produces code fragment permanent definition 
update messages line table appears line table iii 
update definition previous values table iv pearl algorithm applied slightly different way belief network fig 
nodes activated order shown column similarly definition previous values vector notation agreement line table iii 
update values ones line table iii 
matter routine verify rest values table iii correct 
order chose update nodes fig 
arbitrary orders give different algorithms 
example easy verify update order yields results table iv sequences defined odd odd 
interesting experiment alternative version turbo decoding algorithm 
parallel update rule fact rule derived decoding algorithm multiple turbo codes discussed section vii 
mceliece turbo decoding pearl algorithm fig 

belief network appropriate decoding multiple turbo code code fragments 
vii 
decoding algorithms derived belief propagation seen sections iv pearl algorithm applied belief network just fig 

fruitful exercise apply pearl algorithm belief networks variety hybrid coding schemes see results 
section briefly outline proofs discovered lines 
multiple turbo codes defined turbo codes involve encodings information shown fig 

researchers experimented parallel encodings 
parallel encodings appropriate belief network shown fig 

applying bp algorithm belief network update order obtain generalized turbo decoding algorithm identical employed successfully 
gallager low density parity check codes earliest suboptimal iterative decoding algorithm gallager devised method decoding low density parity check codes 
algorithm generalized elaborated tanner wiberg 
mackay neal pointed citation belief propagation coding theorists gallager algorithm special kind bp fig 
appropriate belief network 
fig 
codeword satisfies parity check equations noisy version syndrome defined perpetually observed 
ldpc codes largely forgotten coding theorists rediscovery mackay neal simulations gallager original decoding algorithm powerful modern computers show performance remarkably cases rivaling turbo codes 
sipser spielman replaced random parity check gallager mackay neal deterministic parity check matrices desirable properties expander graphs obtained stronger results 
low density generator matrix codes cheng mceliece experimented bp decoding certain fig 

belief network decoding gallager low density parity check code 
fig 

belief network decoding systematic low density generator matrix codes 
systematic linear block codes low density generator matrices 
class codes appeared earlier mackay study modulo arithmetic inference problems spielman connection error reduction decoding algorithm devised cheng mceliece adapted described mackay neal cited results quite especially high rates 
cheng ideas construct class block codes yield remarkably efficient multilevel coded modulations 
fig 
shows belief network low density generator matrix codes mceliece cheng 
serially concatenated codes defined turbo code parallel concatenation components codes 
originally defined forney concatenation serial operation 
researchers investigated performance serially concatenated codes turbo style decoding 
nontrivial variation original turbo decoding idea iterative decoding algorithms differ significantly original berrou algorithm considered original invention 
decoding algorithms derived routinely bp viewpoint network fig 

information encoded outer encoding inner second encoding noisy version product codes number researchers successful turbo style decoding product codes dimensions 
product code ieee journal selected areas communications vol 
february fig 

belief network decoding pair serially concatenated codes 
information arranged dimensional array encoded separately dimension 
appropriate belief network ones figs 
product code definition systematic 
experimented bp decoding product codes obtained results similar cited 
case appears bp algorithms differ small details turbo style decoding currently investigating phenomenon 
tail biting convolutional codes class convolutional codes introduced solomon van natural candidate bp decoding 
briefly tail biting convolutional code block code formed truncating trellis conventional convolutional code pasting ends trellis 
parent convolutional code code truncation depth resulting tail biting code block code 
fig 
show belief diagram tail biting code truncation depth assuming parent convolutional code code fig 
bit information words bit codeword segments 
observed noisy versions nodes intermediate information words codeword segments pairs encoder states 
encoder state pair information word encoder rules deterministically produce pair codeword states codeword segment tail biting edge belief net loops represent ordinary convolutional code 
bp algorithm applied result identical app decoding algorithm 
apply pearl algorithm belief diagram fig 
obtain iterative decoding algorithm tail biting code 
knowledge done exactly wiberg applied algorithm tanner connection note wiberg observed algorithm applied tanner graph similar fig 
tail biting edge implies algorithm 
min sum form wiberg algorithm applied graph closely related viterbi algorithm 
incidentally min sum version pearl algorithm described ch 
called belief revision thing 
fig 

belief network decoding tail biting convolutional code illustrated truncation length sx graph tail biting code success functionally approaches yield virtually identical algorithms 
forney discussed iterative decoding codes tanner wiberg approach 
viii 
concluding remarks shown pearl algorithm provides systematic method devising low complexity suboptimal iterative decoding algorithms wide variety error control systems 
guarantee algorithms give useful results great body experimental done turbo code literature suggests performance 
interesting historical aspects turbo decoding problem past inventors decoding algorithms hit bp algorithm 
earliest occurrence papers gallager 
tanner realizing importance gallager construction important generalization low density parity check codes gallager iterative decoding algorithm 
hindsight especially view wiberg evident viterbi algorithm algorithm viewed kind belief propagation 
wiberg generalized gallager algorithm point resembles pearl algorithm closely 
particular wiberg shows algorithm adapted produce gallager tanner algorithm turbo decoding algorithm 
having noticed similarity gallager tanner wiberg algorithm pearl algorithm aji mceliece relying heavily post pearl improvements simplifications bp algorithm devised simple algorithm distributing information graph simultaneous generalization algorithms includes classic algorithms including viterbi algorithm subsumed wiberg algorithm min sum form fft 
natural predict algorithm close relatives soon mceliece turbo decoding pearl algorithm standard tool scientists communications signal processing related fields 
conclude view turbo coding successful 
believe separable essential contributing factors 
presence pseudorandom component codes ensures resulting code behaves long random code shannon theorems long random code sense having potential optimal decoding achieve performance near channel capacity 
optimal decoding complex 
brings second essential factor 
second believe general undiscovered theorems performance belief propagation algorithms loopy dag theorems may directly coding decoding show sense bp converges high probability near optimum value desired belief class loopy dag includes diagrams figs 

theorems exist doubt find applications realms far information theory 
acknowledgment authors wish smyth post pearl developments belief propagation algorithm referees supplying history forward backward algorithm appears section iv 
aji mceliece general algorithm distributing information graph proc 
ieee int 
symp 
inform 
theory ulm germany june 
generalized distributive law proc 
th int 
symp 
commun 
theory appl july pp 

revised version available www systems caltech edu ee faculty 
andersen turbo coding scheme unpublished manuscript distributed ieee int 
symp 
inform 
theory trondheim norway june 
bahl cocke jelinek raviv optimal decoding linear codes minimizing symbol error rate ieee trans 
inform 
theory vol 
pp 
mar 
barbulescu interleaver design dimensional turbo codes proc 
ieee int 
symp 
inform 
theory whistler canada sept 
baum petrie statistical inference probabilistic functions finite state markov chains ann 
math 
statist vol 
pp 

benedetto turbo codes results parallel concatenated coding schemes ieee trans 
inform 
theory vol 
pp 
mar 
serial concatenation block convolutional codes electron 
lett vol 
pp 
may 
benedetto serial concatenation interleaved codes performance analysis design iterative decoding jpl progr 
rep vol 
aug 
berrou glavieux near shannon limit error correcting coding turbo codes proc 
int 
conf 
commun geneva switzerland may pp 

chang hancock receiver structures channels having memory ieee trans 
inform 
theory vol 
pp 
oct 

cheng mceliece unit memory hamming turbo codes proc 
ieee int 
symp 
inform 
theory whistler canada sept 
near capacity codecs gaussian channel generator matrices submitted allerton conf 

cheng construction efficient multilevel coded modulations submitted ieee int 
symp 
inform 
theory 
iterative decoding ph dissertation caltech pasadena ca mar 
cooper computational complexity probabilistic inference bayesian belief networks artif 
intell vol 
pp 

dagum luby approximating probabilistic inference bayesian belief networks np hard artif 
intell vol 
pp 

turbo codes deep space communications progr 
rep vol 
pp 
feb 
multiple turbo codes deep space communications progr 
rep vol 
pp 
may 
mceliece transfer function bounds performance turbo codes progr 
rep vol 
pp 
july 
mceliece effective free distance turbo codes electron 
lett vol 
pp 
feb 
forney jr concatenated codes 
cambridge ma mit press 
viterbi algorithm proc 
ieee vol 
pp 
mar 
forward backward algorithm proc 
th allerton conf 
commun contr computing allerton il oct 
gallager low density parity check codes ire trans 
inform 
theory vol 
pp 
jan 
low density parity check codes 
cambridge ma mit press 
hagenauer offer iterative decoding binary block convolutional codes ieee trans 
inform 
theory vol 
pp 
mar 
heckerman wellman bayesian networks commun 
acm vol 
pp 

jensen lauritzen olesen bayesian updating recursive graphical models local computations computational statist 
quart vol 
pp 

jensen bayesian networks 
new york springer verlag 
kim pearl computational model combined causal diagnostic reasoning inference systems proc 
th int 
joint conf 
ai ijcai karlsruhe germany pp 

kindermann snell markov random fields applications 
providence ri american mathematical society 
kschischang frey iterative decoding compound codes probability propagation graphical models issue pp 

lauritzen spiegelhalter local computations probabilities graphical structures application expert systems roy 
statist 
soc ser 
vol 
pp 

lauritzen dawid larsen 
independence properties directed markov fields networks vol 
pp 

mackay free energy minimization framework inference problems modulo arithmetic fast software encryption preneel ed 
berlin germany springer verlag lecture notes computer science vol 
pp 

mackay neal codes sparse matrices proc 
th ima conf 
cryptography coding boyd ed 
berlin germany springer lecture notes computer science vol 
pp 

mackay error correcting codes sparse matrices submitted ieee trans 
inform 
theory 
preprint available wol ra phy cam ac uk 
mackay neal near shannon limit performance low density parity check codes electron 
lett vol 
pp 
aug 
reprinted electron 
lett vol 
pp 
mar 
welch weber bit decoding convolutional codes abstr 
papers ieee int 
symp 
inform 
theory asilomar ca jan 
mceliece 
cheng turbo decision algorithm proc 
rd allerton conf 
commun contr computing oct pp 

pearl bayes inference engines distributed hierarchical approach proc 
conf 
nat 
conf 
ai pittsburgh pa pp 

ieee journal selected areas communications vol 
february fusion propagation structuring belief networks artif 
intell vol 
pp 

probabilistic reasoning intelligent systems networks plausible inference 
san mateo ca morgan kaufmann 
perez costello jr distance spectrum interpretation turbo codes ieee trans 
inform 
theory vol 
pp 
nov 
performance turbo decoded product codes multilevel coding proc 
ieee icc dallas tx june 
hidden markov models guided tour proc 
ieee int 
conf 
acoust speech signal processing 
new york ieee press vol 
pp 

glavieux near optimum decoding product codes proc 
ieee globecom san francisco ca nov vol 
pp 

rabiner tutorial hidden markov models selected applications speech recognition proc 
ieee vol 
pp 

robertson illuminating structure code decoder parallel concatenated recursive systematic turbo codes proc 
ieee globecom pp 

shachter probabilistic inference influence diagrams oper 
res vol 
pp 

shafer shenoy probability propagation ann 
mat 
artif 
intell vol 
pp 

shimony finding maps belief networks np hard artif 
intell vol 
pp 

free distance turbo codes related product codes ph dissertation swiss fed inst 
technol zurich switzerland aug final rep diploma project ss 
smyth heckerman jordan probabilistic independence networks hidden markov probability models neural computation accepted publication 
solomon van connection block convolutional codes siam appl 
math vol 
pp 
oct 
sipser spielman expander codes ieee trans 
inform 
theory vol 
pp 
nov 
spiegelhalter lauritzen sequential updating conditional probabilities directed graphical structures networks vol 
pp 

spiegelhalter dawid lauritzen cowell bayesian analysis expert systems statist 
sci vol 
pp 

spielman linear time encodable decodable error codes ieee trans 
inform 
theory vol 
pp 
nov 
tanner recursive approach low complexity codes ieee trans 
inform 
theory vol 
pp 
sept 
nonlinear equalization binary signals gaussian noise ieee trans 
commun 
technol vol 
com pp 
dec 
poor dynamic programming models commutativity conditions siam contr 
vol 
pp 
july 
viterbi error bounds convolutional codes asymptotically optimum decoding algorithm ieee trans 
inform 
theory vol 
pp 
apr 
whittaker graphical models applied multivariate statistics 
chichester wiley 
wiberg 
loeliger tter codes iterative decoding general graphs europ 
trans 

vol 
pp 
sept oct 
wiberg codes decoding general graphs link ping studies sci 
technol dissertations 
link ping sweden 
robert mceliece sm born washington dc 
received ph degrees mathematics california institute technology pasadena respectively attended trinity college cambridge university 
employed california institute technology jet propulsion laboratory supervisor information processing group 
professor mathematics research professor coordinated science laboratory university illinois urbana champaign 
faculty caltech allen professor electrical engineering 
served executive officer electrical engineering caltech 
regular consultant communications research section caltech jet propulsion laboratory 
research interests include deep space communication communication networks coding theory discrete mathematics 
david mackay born trent april 
education newcastle school trinity college cambridge received ph degree computation neural systems california institute technology pasadena 
lecturer department physics cambridge university fellow darwin college cambridge 
interests include construction implementation hierarchical bayesian models discover patterns data development probablistic methods neural networks design decoding error correcting codes 
jung fu cheng born taipei taiwan march 
received degrees electrical engineering national taiwan university taipei taiwan respectively ph degree electrical engineering subject minor social science california institute technology pasadena 
academic research interests focused coding communications theory 
july employed research analyst fixed income research department salomon brothers new york ny 
