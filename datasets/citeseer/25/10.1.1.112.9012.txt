massachusetts institute technology artificial intelligence laboratory memo november complex feature recognition bayesian approach learning recognize objects paul viola publication retrieved anonymous ftp publications ai mit edu 
developed new bayesian framework visual object recognition insight images objects modeled conjunction local features 
framework derive object recognition algorithm algorithm learning features 
approach called complex feature recognition cfr unique reasons broadly applicable wide range object types constructing object models easy capable identifying class identity object computationally efficient requiring time proportional size image 
single simple feature edge cfr uses large set complex features learned experience model objects 
response single complex feature contains class information single edge 
significantly reduces number possible correspondences model image 
addition cfr takes advantage type image processing called oriented energy 
oriented energy efficiently pre process image eliminate difficulties associated changes lighting pose 
copyright massachusetts institute technology report describes research done artificial intelligence laboratory massachusetts institute technology 
support research provided part advanced research projects agency department defense office naval research contract 
ai memo essential problem object recognition image known object generated 
huge variety approaches problem 
extract critical insight 
simple relationship image objects 
confounding influences pose lighting clutter occlusion 
result researchers image representation recognition 
choose define identify simple image features supposed capture important characteristics image ballard bolles cain grimson lozano perez 
typical example feature intensity edge 
main motivations simple features 
assumed simple features detectable wide variety pose lighting changes 
second resulting image representation compact discrete consisting list features positions 
third hypothesized position features novel image object predicted knowledge positions images 
ways motivations justified 
main difficulty associated simple features recognition 
difficult determine feature image corresponds feature object correspondence problem 
feature simple provide constraint match 
propose novel approach image representation single predefined feature 
large set complex features learned experience model objects 
response single complex feature contains class information single edge 
significantly reduces number possible correspondences model image 
order better understand clearly derive results probabilistic framework formation images defined 
framework predict image particular object looks 
framework bayes theorem derive cfr recognition algorithm 
believe formal approach assumption underlying cfr related techniques clear 
sections 
describe bayesian framework cfr respectively 
performance cfr recognition procedure critically depends having appropriate set complex features 
features generative process fail accurately capture appearance object recognition performance cfr rapidly degrade 
additional side benefit formal framework cfr derive principled mechanism learning appropriate features 
novel aspect research learning rule features derived description cfr framework complete 
discussion paul viola generative process images learning rule section 
order improve generalization cfr novel poses different illumination images processed extract information rapid changes intensity 
similar pre processing visual cortex primates see kandel schwartz example underlies computational definition intensity edge marr hildreth 
discrete detection intensity edges cfr uses continuous measure edge ness pixels 
edge ness pixel proportional energy number oriented band pass filters centered pixel 
representation advantages described section 
section number cfr experiments described 
experiments cfr shown human faces real objects 
number extensions cfr framework proposed 
generative process images generative process computer graphics rendering system 
rendering system takes object description information illumination pose generates life image object 
naive procedure recognizing novel image generate possible images result model object 
synthetic images matches novel image evidence novel image example model 
computer graphics deterministic process object pose single unique image world unpredictable 
noise unmodelled variable may changed rendered image recorded camera 
address lack predictability probabilistic generative process defines probability density space possible images 
formally image object model pose generative process allows compute probability image know object pose 
bayes theorem tells define object recognition algorithm returns object probable argmax 
know pose object choose integrate unknown variable 
alternatively find 
explore option 
ai memo schematic depiction image set complex features partial representation image features 
arrows different features left white boxes lie image describe positions features best represent image 
type approach new 
known object recognition systems formulated search model image see example wells iii analogy explicit 
course details algorithms quite different 
algorithms input image directly comparing input image predicted image directly 
techniques correlation image matching fall category 
algorithms assume images described positions simple image features edges 
image features compared predicted features generative process 
generative process really direct feature approaches 
feature approaches uses features represent images 
extracting localizing single type simple feature complex local set features defined 
direct techniques detailed predictions intensity pixels image 
emphasize features system complex typical call complex feature recognition cfr 
cfr image collection distinct complex features see 
complex features chosen distinct stable 
distinct feature appears times image correlated particular object class objects 
simple features especially edges decidedly distinct 
stability related meanings position stable feature changes slowly pose object changes slowly ii stable feature range views object canonical view 
simple features intended aren stable 
current implementation analysis complex features resemble templates formulation general admit number different feature representation mechanisms 
paul viola generative process images typical set images single person 
case fifteen views centered direct forward view 
face images take form 
face data came david beymer mit ai laboratory 
examples simple examples help motivate thinking cfr 
clearly picture person suitably normalized remove dependency lighting excellent complex feature 
distinct aren objects look person aren picture stable complex feature 
intuition tells small change object pose rapidly picture poor predictor image 
instance see images canonical poses person poses numbered left right top bottom starting 
see soon quantify appearance images changes quite rapidly pose varies 
picture entire object may poor complex feature local pictures better 
addresses question empirically 
left labeled representative images different people 
top right labeled candidate local feature graph representing response canonical poses people 
feature selected pose number person 
chosen fairly arbitrarily roughly largest possible square sub region image contain lot background non face regions 
graph plots people pose number versus measure nearness complex feature image note feature taken pose feature nearest pose person 
unfortunately feature act distinguish people 
simple threshold feature response maximal value normalized correlation feature image measure image distance 
normalized correlation widely matching metric eliminates dependency lighting brunelli poggio 

examples ai memo response response person pose pose person responses simple grey level features 
see text complete description 
example images people 
feature pose person response versus fifteen views people slightly smaller feature taken person responses 
suffice identify person 
sort feature entirely useless 
may useful identifying images person limited number poses ones near pose notice poses similar 
shown threshold type discrimination line 
labeled feature similar graph 
feature selected arbitrarily time represent smaller localized part face 
see feature recognition 
possible build complex features distinct stable 
extra machinery answer qualified 
show graph output arguably better feature 
see large number poses feature acts discriminate person 
furthermore larger margin 
position feature appears stable pose changes 
contains representative images 
labeled location feature responds strongly white square 
feature clearly responding true location face respond local region forehead 
universal behavior learned features 
features better job localization expense generalization views 
cfr complex features differ simple image templates shown major ways 
complex features matched directly paul viola generative process images response pose person graph performance learned complex feature data graphs 
white square labels location forehead feature detector responds strongly 
raw untrained oriented energy feature selected person pose 
feature represents area near forehead 
oriented energy feature images orientations 
measures vertical energy fourth horizontal energy 
remaining orientations evenly distributed 
notice eyebrows third horizontal image accentuated 
feature trained respond strongly person number 
starting shown previous taken person number cfr learned salient properties person number 
ai memo pixels image 
match easily computed intermediate representation called oriented energy 
oriented energy representation image fact images number orientations 
value particular pixel vertical energy image related likelihood vertical edge near pixel original image 
shows typical oriented energy feature 
orientations critical 
feature representation discussed detail section 
second difference image template complex feature result feature learning procedure 
complex feature adjusted responds strongly example images person number 
learning process allows cfr discover features effective classifying object wide variety poses 
shows feature result tuning feature closely model person 
details feature learning algorithm described section 
clearly attempt build recognition system single feature 
cfr uses features trained wide variety objects poses 
types features cfr uses different flavor simple recognition systems 
feature correlated exclusively particular objects classes objects 
feature detectable set poses nominal pose 
feature poses 
allows relative positions features additional information recognition 
section theory complex feature recognition outlined 
theory provides means analyzing understanding computations represent recognize images 
theory complex features random variable images drawn 
image vector pixel values bounded range pixels images need intensities measured camera 
may representation image 
multiple representation available case oriented energy pixel viewed having vector value dimension representation 
explicit vector notation pixel values leads additional notational complexity derivations scalar notation pixels 
difficult rederive theory vector valued pixels 
set complex features fi ni number pixels fi 
object represented collection models 
object may require models order capture variation appearance due changes pose 
model drawn pair random variables indicator vector vector locations 
feature fi paul viola theory complex features diagrammatic depiction operation sub window function feature image location returns sub window lies location size image di 
di li location fi image 
sub window function images li sub window lies position li see 
define conditional probability particular image sub window li di li li fi li fi li di li li fi normal distribution pixels li mean covariance matrix 
equations interpreted way di probability image function distance pixels li assume pixels li uniformly distributed pixel density 
reiterate variables considered random variables 
vectors components li di random variables 
events drawn distributions denoted small letters especially di li 
derivations simplify notation denote thing probability random variable take value assume features overlap independent probability density image li di li fi ai memo number pixels image remain unexplained feature 
bayes theorem compute probability model image di li di li di li di li li di li di li max li note equation sum vectors locations split separate sums feature location moved inside product 
done features assumed independent 
equation define algorithm recognizing set objects appears image 
collection models dm find model 
course significant difficulty remains finding computing object models 
straightforward scheme building model obtain segmented image object pick di li image di li di di li li 
di li pleasing simplicity wary case di significantly greater di 
true presence absence fi ambiguous 
picking single value di case misleading 
real situation di equally 
worse confuses distinct types models di di di di 
experiments type maximum posteriori model 
clarity derivation assumes features overlap independent 
alternative formulation exists dependent overlapping features 
computation tractable independent formulation significantly tractable dependent formulation 
paul viola theory complex features alternative type object model retains explicit information di di maxp di di li li li li di di li li 
li note vector numbers zero event binary vector 
longer value di estimate distribution di 
resulting object models dm probabilistic 
probability image model really mixture distribution 
distinct ways define recognition algorithm probabilistic model 
simply bayes theorem 
alternatively find model probability density feature indicator variables closely matched image density function distance measure returns equal larger values diverge 
defining measure compares vectors number reasonable candidates best motivated cross entropy asymmetric divergence see cover thomas excellent review entropy divergence 
simplicity chosen squared difference 
resulting recognition algorithm called cfr mem explicitly memorizes distribution features model images 
explored scheme classifying images 
experiments shown large number object models necessary correctly classify novel object images 
currently formal analysis problem manifest issue features correlated object ai memo identity 
distractor features vary widely similar views object 
feature treated uniformly distance function distractor features corrupt fit model image 
attempt generalize weights features distracting features 
object feature object distractor 
force find different object 
direct approach learn classifier 
classifier function computes object identity 
chosen multi layer perceptron known neural network learn classifier rumelhart hinton williams 
briefly neural network clever way parameterizing function set weights weights learned defining training set pairs vj label input vector corresponding object 
vectors th component th object 
set weights selected minimize error training set form gradient descent 
call recognition algorithm cfr disc disc discriminator 
interestingly need train network compute identity object 
object class face versus car equally defined target 
section derived algorithms recognizing objects set complex features 
derivations assumed set complex features available 
practice algorithms depend selection appropriate features 
section derive algorithm learning set features fit images 
learning features bayesian approach detection recognition critically depends effectiveness generative process 
words set training images cfr model 
impossible model training images object difficult recognize novel images object 
furthermore novel image object model unambiguously fits best 
generative process poor small models 
best models low probability may reliable difference likelihood correct incorrect models 
result recognition performance certainly suffer 
cfr framework likelihood image dependent particular features available 
features fit particular training image object model image 
different appropriate set features model image 
features form models entire set training images 
order insure cfr able model wide variety object types automatic technique finding features necessity 
paul viola learning features technique principle maximum likelihood 
sequence images simply index sequence section explicitly assume fact time 
probabilities images independent maximum likelihood estimate fi maximizing likelihood di li fi 
know di li integrate choose best fi di li fi di li di li max di li di li fi di li 
cases convenient maximize log maximum log max di li log di li fi log di li 
computing maximum quite difficult resort gradient maximization 
starting initial estimate fi compute gradient respect fi fi take step direction 
may complex calculation simple implementation find li maximizes di li fi 
implemented convolution point largest response chosen 
extract li time step 
compute gradient respect fi 
notational simplicity dropped functional notation time dependence li di 
variables functions fi di max li df di li fi di max li di li fi di li li fi li fi li fi 
see equations definition probability image feature 
equation written simply fi li fi weighted combination differences 
learning useful features ai memo take small step direction gradient new repeat fi stabilizes 
learning useful features old fi 
algorithm learn set features model class images 
insures feature suited problem visual object recognition 
encourages features stable distinct 
similar views object may modeled different feature representations 
order support general object recognition cfr features similar views object represented similar identical models 
optimally unachievable cfr feature representation object constant changes pose constant representation certainly stable 
condition encouraged approach 
take variety different views object attempt maximize likelihood set di 
somewhat different previous approach di unknown 
disadvantages 
assumes possible build object representation invariant pose difficult impossible task 
furthermore difficult determine apriori features belong objects 
attempting learn constant cfr feature representation may impractical learning stable representation 
useful definition stable object slowly changes pose large changes representation rare small changes representation common 
formulate way similar smoothness prior common regularization theory poggio torre koch 
assuming sequence images object smoothly varying pose express bias stability way di di di di pc di di di di pt li li di di li li di equations determine prior probability di remain constant time pc probability di remain constant pt probability di transition 
third equation determines probable changes location changes location distributed gaussian probabilities implicitly conditioned fact contain images object similar pose 
paul viola oriented energy feature matching previous location 
ldi becker suggested temporal continuity may serve mechanism learning object identity 
difference sources information likelihood feature representation combined 
new stable form likelihood image formation max di di li li logp di li fi logp di li logp di di di di logp li li li li di di di di similar algorithm detailed compute derivative likelihood image sequence 
gradient fi log li fi weighted sum differences 
currently exploring possibility optimizing trajectory di li longer periods time 
case appropriate formulation hidden markov model 
priors added embody assumption image sequence contains slowly varying images object followed slowly varying images object 
sequence contain images collected different objects 
oriented energy feature matching cfr may effective technique representing images learning features generalization performance dependent input representations 
effective representation insensitive foreseeable variations observed images retaining necessary information required recognition 
example image pixels object vary rapidly illumination pose object changes 
order insure generalization representations insensitive changes 
sensitivity pose directly related spatial smoothness representation 
images smooth pixel values change slowly pose varied 
effective representation recognition enforce pixel smoothness removing information critical discriminating features 
conflicted goal 
hand want smooth ai memo attenuating high frequencies reducing information 
want preserve information higher frequencies preserve selectivity 
oriented energy separates smoothness representation frequency sensitivity representation 
high frequency information preserved way allows positional flexibility 
calculation oriented energy proceeds stages linear nonlinear 
input image convolved gabor functions orthogonal oriented linear part 
filters share spatial window orientation frequency characteristics 
vary phase see 
second sum squares outputs filters collected image non linear part 
filters form quadrature pair result viewed energy 
gabor filters localized frequency space 
convolution output gives information frequencies input image locations 
outputs filters directly alternative representation image 
filters band pass correlation outputs may larger original image 
squaring summing outputs get measure energy band pass frequencies invariant phase 
maximum energy corresponds classical definition intensity edge energy image frequency signature window function gaussian 
gaussian essentially low pass filter resulting energy image spatial smoothness input image 
return attention features shown figures 
oriented energy allows selective description face overly constraining location important properties 
strongly vertical pixels surrounded strongly horizontal pixels eyebrows 
shows feature responds strongly right eye head 
feature eye eyebrow right represented 
important note physical structure complex feature responds enforced teacher 
cfr feature learning procedure settled right eye stable 
major aspect image variation illumination 
value pixel change significantly changes lighting 
assume part lighting varies slowly scene 
result large portion variation modeled locally purposes feature matching additive multiplicative effect 
fortunately oriented energy invariant additive offset 
multiplicative effects eliminated normalizing length li fi comparison 
fact freeman adelson oriented energy input canny edge detector performance significantly improved freeman adelson canny 
paul viola experiments contains diagrammatic depiction computation oriented energy 
bottom input image case 
oriented energy computed banks filters odd bank shown right bank shown left 
image convolved separately filters 
resulting images squared 
resulting maps constructed summing squared outputs odd filters orientation 
feature learned respond right eye head 
note due production difficulties white oriented energy maps printed 
experiments ways contains collection related insights object recognition oriented energy effective means representing images ii features learned stable iii images represented complex features 
address issues order 
handwritten digits oriented energy effective representation pixels image see example digits 
constructed nearest neighbor classifier simplest possible feature recognizer 
works classifying novel digit class closest training digit 
training set examples digit completely separate test set 
pixels images directly performance 
oriented example digits 
example images object dataset 
example faces face dataset 
ai memo energy representation changes performance jumped 
complex features learned data unsupervised fashion 
features shown figures examples features 
locations estimated typical expected features learned motion sequences 
tested cfr number different recognition tasks 
obtained databases real objects set images small objects taken controlled conditions nayar columbia see database people david beymer mit ai lab see 
object database contains different views object training 
face dataset contains views face training testing 
tested cfr mem cfr disc datasets 
cases features 
datasets contained views fairly close pose space 
allowed treat motion sequence 
features trained maximize likelihood sequences 
initial paul viola related estimates features snap shots randomly chosen training set 
face data ran classification experiments initial random features trained features 
chance cfr mem cfr disc cfr mem cfr disc random learned random learned features features features features objects faces results results nayar reports data results beymer reports data murase nayar beymer 
general cfr easy 
part cfr runs requiring intervention 
features learned models created images recognized supervision 
exact code runs objects faces 
trained cfr quite efficient couple seconds recognize image 
cfr tested totally natural images 
cases control lighting little control pose camera parameters 
experiment tested class recognition 
goal experiment take novel image label regions image may contain face 
training data included positive examples face data mentioned negative examples variety random backgrounds taken real images 
test image broken overlapping regions labeled containing face 
region twice large largest face training set 
test image shown see white square placed center region cfr estimate probability face larger probability background 
test image taken different camera different conditions training set 
people test image training set 
related complete review related object recognition far scope 
certainly concept feature representation images new 
majority related falls disjoint groups techniques simple local features edges techniques complex global features 
edge techniques proven widely successful believe drawbacks 
feel cfr infancy may open paths recognition general classes objects 
addition appropriate features cfr efficient brute force matching simple features 
ai memo preliminary result demonstrates cfr complex cluttered scenes class recognition tasks 
system trained views different people 
asked identify regions images face 
regions labeled white square 
square corresponds region times size largest head image 
techniques complex global features come wide variety types 
examples include color histograms swain ballard shape measures proposed sclaroff pentland monolithic neural networks proposed le cun 
techniques distinguished capable different types information color texture 
share sensitivity clutter frequently assume object segmented background 
fact concept global pre supposes extent object known 
hope cfr combines best properties global local techniques 
rao ballard proposed type pre processing similar oriented energy images matched models 
significant differences rao ballard representation object model cfr representation single pixel single feature 
recognition proceeds manner similar cfr memorize algorithm 
hope formal model cfr applicable 
addition insights feature learning may prove useful construction object models 
paul viola formal framework different object recognition algorithms derived 
framework constructed insight images represented collections complex local features 
framework dependent quality features additionally derived algorithm capable automatically learning set features appropriate object recognition 
novel algorithm learning features requires outside supervision 
random initial hypotheses ineffective features discarded effective features refined 
recognition performance improved pre processing input images intensity changes different frequencies orientation enhanced 
ballard 

generalizing hough transform detect arbitrary shapes 
pattern recognition 
becker 

learning categorize objects temporal coherence 
hanson cowan giles editors advances neural information processing volume denver 
morgan kaufmann san mateo 
beymer 

face recognition varying pose 
ai memo artificial intelligence laboratory massachusetts institute technology 
bolles cain 

recognizing locating partially visible objects local feature focus method 
international journal robotics research 
brunelli poggio 

face recognition feature versus templates 
ieee transactions pattern analysis machine intelligence 
canny 

computational approach edge detection 
ieee transactions pattern analysis machine intelligence pami 
cover thomas 

elements information theory 
john wiley sons 
ldi 

learning invariance transformation sequences 
neural computation 
freeman adelson 

design steerable filters 
ieee transactions pattern analysis machine intelligence 
ai memo grimson lozano perez 

model recognition localization sparse range tactile data 
international journal robotics research 
kandel schwartz 

principles neural science 
elsevier new york second edition 
le cun boser denker henderson howard hubbard jackel 

backpropagation applied handwritten zip code recognition 
neural computation 
marr hildreth 

theory edge detection 
proceedings royal society london 
murase nayar 

learning recognition objects brightness images 
aaai fall symposium series working notes 
aaai 
poggio torre koch 

computational vision regularization theory 
nature 
rao ballard 

object indexing iconic sparse distributed memory 
proceedings international conference computer vision pages cambridge ma 
ieee washington dc 
rumelhart hinton williams 

learning internal representations error propagation 
rumelhart editors parallel distributed processing exploration microstructure cognition chapter 
mit press 
sclaroff pentland 

modal matching correspondence recognition 
ieee transactions pattern analysis machine intelligence 
swain ballard 

color indexing 
international journal computer vision 
wells iii 

map model matching 
proceedings computer society conference computer vision pattern recognition pages maui hawaii 
ieee 

