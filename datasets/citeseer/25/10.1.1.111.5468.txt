beat behavior expression animation toolkit justine cassell mit media laboratory ames st cambridge ma justine media mit edu behavior expression animation toolkit beat allows animators input typed text wish spoken animated human obtain output appropriate synchronized nonverbal behaviors synthesized speech form sent number different animation systems 
nonverbal behaviors assigned basis actual linguistic contextual analysis typed text relying rules derived extensive research human conversational behavior 
toolkit extensible new rules quickly added 
designed plug larger systems may assign personality profiles motion characteristics scene constraints animation styles particular animators 
keywords animation systems facial animation speech synthesis gesture 
association speech communicative behaviors poses particular challenges procedural character animation techniques 
increasing numbers procedural animation systems capable generating extremely realistic movement hand gestures facial expressions silent characters 
voice called issues synchronization appropriateness render adequate techniques 
cases may want animate speaking character 
spontaneous gesturing facial movement occurs naturally effortlessly daily conversational activity forced think associations nonverbal behaviors words explicit terms trained eye called 
example untrained animators autonomous animated interfaces generate pointing gesture listener speaking character says 
want come get coat 
point sort occurs life try see contrasted somebody pointing gesture occur permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
acm siggraph august los angeles ca usa acm hannes mit media laboratory ames st cambridge ma hannes media mit edu timothy bickmore mit media laboratory ames st cambridge ma bickmore media mit edu worse animated speaking character speaking language 
fact reason animators rely video footage actors text rely motion captured data drive speaking characters 
expensive methods may involve crew people addition expert animator 
may worth doing characters play central role screen justified crowd 
cases may opportunity capture animation 
embodied conversational agents interfaces web content animated non player characters interactive role playing games animated avatars online chat environments demand kind procedural animation 
may access database phrases character utter necessarily know context words may said may able link speech appropriate context sensitive nonverbal behaviors 
beat allows animate human body just text input 
uses linguistic contextual information contained text control movements hands arms face intonation voice 
mapping text facial intonational body gestures contained set rules derived state art nonverbal conversational behavior research 
importantly system extremely tunable allowing animators insert rules concerning personality movement characteristics features realized final animation 
way text speech tts systems realize written text spoken language beat realizes written text embodied expressive behaviors 
way tts systems allow experienced users tweak intonation pause length speech parameters beat allows animators write particular gestures define new behaviors tweak features movement 
section gives background motivation beat 
section describes related 
section walks reader implemented system including methodology text annotation selection nonverbal behaviors synchronization 
extended example covered section 
section presents describes directions 

conversational behavior communicate words course rely intonation melody language hand gestures beats pointing gestures facial displays lip shapes eyebrow raises eye gaze head movements body posture 
form modalities rising tone vs falling tone pointing oneself vs pointing essential meaning 
occurrence behaviors equally important 
tight synchrony different communicative modalities humans 
speakers accentuate important words speaking forcefully gesture word gesture illustrates turn eyes listener coming thought 
listeners nod milliseconds speaker gaze shifts 
synchrony essential meaning conversation 
speakers go great lengths maintain repeat gesture manage utter accompanying speech correctly listeners take synchrony account understand 
readers contrast stellar siggraph big head nod stellar 
stellar siggraph big head nod silence 
synchrony different communicative modalities destroyed low bandwidth videoconferencing satisfaction trust outcome conversation diminished 
synchrony different communicative modalities maintained manages nod right places policeman directions despite understanding word conversation comes successful 
communicative behaviors convey meaning communicative intention timing essential communicative activity speech 
behaviors fact quite different meanings depending occur spoken language similar meanings expressed quite differently language part mix 
researchers people tried tell story words gestures demonstrated entirely different shape meaning characteristics essence began resemble american sign language compared gestures accompanied speech 
skilled animators intuitive grasp form different communicative behaviors synchrony 
animators turn motion capture re animate cases actual videos human intimate portrayal communication essence 

related mid animators manually enter phonetic script result lip facial model speech 
today take granted ability system automatically extract accurate visemes typed text order synchronize lip shapes synthesized recorded speech 
able animate synthetic face voice faces accordance recorded audio 
go direction communicative action generate just visemes syntactic semantic facial movements 
gains considerable talking heads high quality lip significantly improve comprehensibility synthesized speech willingness humans interact synthesized speech decrease need animators spend time time consuming tasks 
animators spend enormous amount effort task synchronizing body movements speech intuition motion capture 
seen attempts automatically specify basis text automatically synchronize body face behaviors synthesized recorded speech 
task natural step significant existent renders communication human motion realistic absence speech text balloons 
researchers concentrated low level features movement aspects humans intentionality emotion personality 
devised method interpolating modifying existing motions display different expressions 
concentrated providing tool controlling expressive shape effort characteristics gestures 
existing gestures input system change gesture perceived 
concentrated realistic emotional expression body 
developed behavioral animation systems generate animations multiple creatures varying personalities intentionality 
constructed system portrays gestural interaction agents pass greet behavioral parameters set personality attribute sliders concentrated challenge representing personality synthetic human interacted real humans specification coordinated body actions layers motions defined relative set periodic signals 
smaller number attempts synthesize human behaviors specifically context communicative acts 
implemented graphical chat environment automatically generates poses comic book format basis typed text 
successful system relies conventions chat room conversations chat acronyms relying linguistic contextual features text 
output system depends understanding comic book conventions authors say characters pointing waving occur relatively infrequently real life come synthesis animated communicative behavior started underlying computation heavy intention communicate set natural language instructions state machine specifying avatar human participant speaking direction human participant gaze 
starting intention communicate computation heavy requires presence linguist staff 
natural language instructions guide synthetic human actions speech 
state speech essential content speech addressed assignment nonverbal behaviors 
current describe toolkit automatically suggests appropriate gestures communicative facial expressions pauses intonational contours input text provides synchronization information required animate behaviors conjunction character speech 
layer analysis designed bridge gap systems specify natural expressive movement contours systems suggest personality emotional realms expression 

system beat system built modular user extensible operate real time 
written java input output pipeline approach support user defined filters knowledge bases uses xml primary data structure 
processing decomposed modules operate xml transducers xml object tree input producing modified xml tree output 
module pipeline operates reading xml tagged text representing text character script converting parse tree 
various knowledge bases system encoded xml easily extended new applications 
text input discourse model knowledge language tagging behavior base suggestion generator set behavior generation behavior selection filter set word timing behavior scheduling 
beat system architecture translator animation new pipeline xml transducers nonverbal behavior generators filters discussed sections authored java subclassing facilitate extensibility 
system real time time produce utterance typically natural pause speaker turns dialogue typically ms 
enabled pipeline architecture operations performed single xml tree single java program 
xml provides natural way represent information spans intervals text facilitates modularity extensibility allowing users add tags parse tree stage processing 
combination xml java provide cross platform portability designed primary design goal 
nonverbal behavior generators filters authored xsl xml scripting language provides extensibility having program java 
validating xml parser enables automatic testing output module development 
tools available parsing generating displaying xml provide great leverage system development 
overview system shown 
main processing modules language tagging behavior generation behavior scheduling 
stages xml translation produced modules shown 
behavior generation module divided suggestion module selection module approach generation process suggest plausible behaviors user modifiable filters trim set appropriate particular character 
user definable data structures indicated dotted line boxes 
discuss components turn 
theme object action utterance kind virtual actor 
input language tagging module user provides string text 
utterance clause rheme object object actor new new new kind virtual actor output language module input generation module language structure tags added objects actions identified 
virtual actor identified instance actor kb 
gaze away tone utterance speech pause eyebrows gesture beat accent gaze tone gesture iconic eyebrows gesture beat accent accent kind virtual actor output generation module input scheduling module behaviors assigned 
iconic gesture raised eyebrows span virtual actor high pitch accents virtual actor gaze spec away hearer gaze spec hearer eyebrows start spec null gesture start spec beat gesture start spec iconic virtual gesture start spec iconic virtual eyebrows start spec null gesture spec null gesture spec null eyebrows spec null output scheduling module flattened tree behaviors compiled linear script 
name behavior word index time utterance start optional specs 
xml trees passed modules knowledge base knowledge base adds basic knowledge world understand text allows draw inferences typed text consequently specify kinds gestures illustrate kinds places emphasis created 
currently knowledge base stored xml files describing objects describing actions 
knowledge bases seeded descriptions generic objects actions easily extended particular domains increase efficacy nonverbal behavior assignment 
object knowledge base contains definitions object types instances types 
shows example entries 
defines new object type professional person class vs object place symbolic features type describing professional real virtual role describing actual profession 
feature typical values described real professionals typical virtual ones important people tend generate iconic gestures unusual aspects objects describe 
second knowledge base entry defines object instance provides values feature defined type 
entry description gesture represent value virtual 
type name professional class person name role typical name type typical real name age typical type instance professional id actor role actor type virtual gesture type iconic value virtual handshape virtual trajectory virtual gesture 
example kb entries describe instance professional surprisingly virtual attribute defined gesture form 
action knowledge base contains associations domain actions hand gestures depict 
example entry gesture name move type iconic handshape trajectory moves cc gesture simply associates particular gesture specification verb move 
mentioned system comes loaded generic knowledge base containing information objects actions common kinds gestures prototypical form 
common gestures include beat flick hand deictic pointing gesture contrast gesture see section 
major kind gesture iconic represents object action may performed differently different speakers different contexts 
gestures added database animator 
gestures specified compositional notation hand shapes arm trajectories arm specified independently 
addition new gestures easier existing trajectories hand shapes re 
language tagging language module toolbox responsible annotating input text linguistic contextual information allows successful nonverbal behavior assignment scheduling 
toolkit constructed animators need concern linguistic analysis 
follows briefly describe essential fundamental units analysis system 
language module automatically recognizes tags units text typed user 
noted described section similar places identical kind tagging allows tts systems produce appropriate intonational contours phrasing typed text 
additional annotations allow just intonation facial display hand gestures generated 
annotations allow just generation synchronization scheduling multiple nonverbal communicative behaviors speech 
largest unit utterance operationalized entire paragraph input 
utterance broken clauses held represent proposition 
detect clause boundaries tagging module looks punctuation placement verb phrases 
clauses divided smaller units information structure theme rheme 
represents part clause creates coherent link preceding clause part contributes new information discussion 
example 
student part second clause clause theme student rheme 
identifying rheme especially important current context gestural activity usually rheme utterance 
language module uses location verb phrases clause information words seen previous clauses assign information structure heuristics described 
smallest unit word phrase current implementation describes action object 
correspond grammatical verb phrase noun phrase respectively 
actions objects linked entries knowledge base possible follows 
actions language module uses verb head corresponding verb phrase key look action description action database 
exact match verb sent embedded word ontology module wordnet creates set hypernyms find matching descriptions knowledge base 
hypernym word related generic broader term 
case verbs say certain verb specific way accomplishing hypernym verb 
example walking way moving hypernym 
expanding search action action database hypernyms possible find descriptions may available super class action 
database doesn describe possible actions focus word high level categories action categories 
lemmas action description match description identifier added action tag 
objects module uses noun head accompanying adjectives find unique instance object object database 
finds matching instance adds unique identifier instance object tag 
smallest units language module handles words 
tagger uses parser www fi word 
module keeps track previously mentioned words marks incoming noun verb adverb adjective new seen 
word newness helps determine words emphasized addition intonation eyebrow motion hand gesture 
words stand contrast words example went buy red apples green ones property marked hand gesture intonation important label 
language module currently labels contrasting adjectives wordnet supply information words synonyms antonyms 
word contrast pair tagged contrast tag 
sum language tags currently implemented clause theme rheme word newness contrast objects actions behavior suggestion behavior suggestion module operates xml trees produced language tagging module shown augmenting suggestions appropriate nonverbal behavior 
augmentation intended liberal inclusive nonverbal behavior possibly appropriate suggested independent 
resulting generated behaviors filtered stage processing final set animated 
independence behavior suggestions allows filters defined different personality types situations scenes example animator may choose filter fewer gestures animating personality animating 
behavior suggestion proceeds applying extensible set nonverbal behavior generators nodes xml tree meet criteria specified generator 
criteria completely satisfied suggestion added appropriate node 
pseudocode generator suggests beat gestures shown behavior generators implemented java 
rheme node tree rheme node contains new node suggest beat coincide object phrase 
example behavior generator pseudocode states beat gestures appropriate description objects noun phrases objects part rheme new information contain new words 
behavior suggestions specified tree node defining time interval active priority conflict resolution required animation degrees freedom specific information needed render gesture specification 
suggestions specify occur behaviors degrees freedom 
example beat gestures articulate gestures addition relative hand displacement 
current set behavior generators implemented toolkit includes beat beats default gesture additional form information available generate specific kind gesture account roughly naturally occuring gestures observed contexts 
typically redundantly generated types gestures appropriate low priority relative types gestures selected gestures available 
gestures occur speech beats occur primarily new material rheme 
surprising feature iconic gesture generator study individuals describing house floor plans showed gestures representing feature described accompanying speech time description house features surprising unusual way 
results generator determines objects identified tagger rheme unusual features information object knowledge base generates iconic representational gesture gesture specification defined unusual feature value knowledge base 
action iconic gesture generator generator determines actions verb phrase roots occurring rheme gestural descriptions available action knowledge base 
action iconic gesture suggested gesture specification knowledge base 
contrast gesture generator tagger identifies objects contrast nearby objects don know thing bad thing 
objects occur theme typically marked beats contrastive gesture exactly objects contrasted gestures literally form hand hand 
generator suggests beats contrast items exactly items contrasted case special contrast gesture suggested 
eyebrow flash generator raising eyebrows signal new material 
generator suggests raising character eyebrows description objects rheme 
gaze generator studied relationship eye gaze theme rheme turn results define algorithm controlling gaze behavior conversational character 
gaze generator implements algorithm shown fig 

theme utterance time suggest gazing away user rheme utterance time suggest gazing user 
algorithm controlling conversational gaze intonation generator intonation generator implements different strategies controlling text speech tts engine 
strategy assigns accents boundary tones theme rheme analysis described shown 
theme suggest accent new objects suggest lh boundary tone theme rheme suggest accent new objects suggest ll boundary tone rheme 
algorithm accent boundary tone generation second intonation strategy suggests accents contrast objects identified tagger 
final intonation strategy simply suggests tts pauses clause boundaries 
behavior behavior word word word word final gesture text sp timing estimates behavior selection behavior selection module analyzes tree contains potentially incompatible gesture suggestions reduces suggestions set animation 
selection process utilizes extensible set filters applied tree turn delete behavior suggestions meet criteria 
general filters reflect personalities affective state energy level characters regulating nonverbal behavior exhibit 
currently filter strategies implemented conflict resolution priority threshold 
conflict resolution filter conflict resolution filter detects nonverbal behavior suggestion conflicts physically occur resolves conflicts deleting suggestions lower priorities 
conflicts detected determining animation degree freedom dof suggestions cooccur require dof specified different levels xml tree 
pair conflicting suggestions decreasing order priority lower priority deleted articulated beat gesture top iconic gesture 
case articulation behaviors permitted start dof point time 
types nonverbal behaviors required dofs articulation relationships expressed xml file referenced filter 
filter operates time scheduling event scheduling follows 
dof behaviors dof considered order decreasing priority 
behavior check see behavior uses dof conflicts overlaps word indices articulation allowed starts word index coarticulation allowed 
conflict exists lower priority behavior removed tree 
operation nd nd maximum number behaviors dof typical sentences 
priority threshold filter priority threshold filter simply removes behavior suggestions priority falls user specified threshold 
behavior scheduling animation module xml pipeline converts input tree set instructions executed animation system recorded audio timing analysis 
scheduling process speech behavior behavior behavior tim nim ation event beg behavior event behavior event behavior anim ation edited animator prior rendering 
general ways achieve synchronization character animation subsystem subsystem producing character speech tts engine recorded audio samples 
obtain estimates word phoneme timings construct animation schedule prior execution see 
second approach assume availability real time events tts engine generated tts producing audio compile set event triggered rules govern generation nonverbal behavior 
approach recorded animation tts engines festival second tts engines microsoft whistler 
approaches systems current toolkit capable producing kinds animation schedules focus discussion absolute scheduling tts engine festival 
step time scheduling extract text intonation commands xml tree translate format tts engine issue request word phoneme timings 
implementation tts runs separate process 
part scheduling continue timings computed 
step scheduling process extract non intonation nonverbal behavior suggestions tree translate intermediate form animation command order word index linear animation 
word phoneme timings available instantiated mapping word indices execution times relative start schedule 
schedule augmented facial animation commands lip sync phonemes returned tts engine 

shows fragment animation schedule stage compilation 
viseme time spec gaze word time spec away hearer viseme time spec viseme time spec viseme time spec th viseme time spec gaze word time spec hearer gesture start word time spec beat eyebrows start word time 
example animation schedule fragment final stage scheduling involves compiling animation schedule set legal commands whichever animation subsystem 
final compilation step modularized toolkit 
addition simply translating commands concern issues enabling initializing disabling different animation subsystem features gn projects beat gesture approach duration relax times schedule specifies peak time start phrase phrase relax time time offsets speech production animation subsystems 
extensibility described beat designed fit existent animation systems exist layer lower level expressive features motion higher level specification personality emotion 
tests system beat animator export dope sheet professional animators hand animate see accompanying video currently collaborating alias wavefront integrate beat maya beat maya integration module see www media mit edu gr 
designed extensible significant ways 
new entries easily knowledge base add new hand gestures correspond domain object features actions 
second range nonverbal behaviors strategies generating easily modified defining new behavior suggestion generators 
behavior suggestion filters tailored behavior particular character particular situation particular animator style 
animation module compilers swapped different target animation subsystems 
entire modules easily re implemented example new techniques text analysis available simply adhering xml interfaces 
kind flexibility system derives ability override output modules simply including appropriate tags original text input 
example animator force character raise eyebrows particular word simply including relevant eyebrows tag wrapped word question 
tag passed tagger generation selection modules compiled appropriate animation commands scheduler 
example system extensibility consider deal issue multiple animated characters 
suppose construct simulation training session animated teacher telling animated student various control panels 
instance beat need generate listener behaviors speaker behaviors 
utterance tag specifies name speaker hearer xml attributes 
nonverbal behavior generators simply copy attribute suggestions leave tree 
specific listener nonverbal behavior generators built suggest eyebrow movement certain key places speaker turn similar rules currently implemented speaker behavior generators 
animation command translator receives tree collect speaker designated behaviors followed listener behaviors compile separate scripts executed individual animated characters 
incorporate visual scene behaviors pointing controls looking displays objects representation knowledge base 
language module map objects text identified generators decide react presence gesture gaze 
scenario allows discuss deal creating individual styles behavior characters 
done ways modifying behaviors discrete continuous manner 
take place behavior selection stage custom filter rules built keep filter certain behaviors speaker listener filter rule example simply decrease amount gesturing character employ 
occur point pipeline behavior generation stage 
instance intermediate module built behavior generator scheduler tweak tune assigned behaviors modifying parameters add news ones interpreted particular animation engine 
intermediate module set amplitude values insert information motion quality gesture 
long new module return behavior suggestion tree back pipeline structurally intact flow won affected 

example animation demonstrate system works section walk couple example utterances 
full animated example accompanying video tape 
example trace happens beat receives input subsequent sentences kind virtual actor just type text actor able talk gesture 
lets look sentence turn 
language tagging module processes input generates xml tree tagged relevant language information described section 
output language tagger shown 
particular interest sentence classification virtual actor object ability system give unique identifier actor 
looking object knowledge base user defined type professional instance actor fact virtual type instance matching attribute instance name actor copied value id object tag 
behavior generator receives xml tree language tagger applies generator rules annotate tree appropriate behaviors described section 
eyebrow raising suggested object virtual actor previously identified actor 
beats intonational accents suggested new lexical items words contained rheme kind virtual actor 
eye gaze behavior intonational boundary tones suggested division theme rheme 
particular interest suggestion iconic gesture accompany actor 
suggestion generated examining database entry actor generator attributes type hold value typical range 
value virtual considered typical actor type 
form suggested gesture retrieved database entry value virtual database entry specified animator way gesture highlights surprising feature object 
utterance speech pause speech pause gaze away tone gaze tone gaze away tone gesture iconic eyebrows gesture beat eyebrows acct acct just type text actor 
part output xml tree example 
just type text behavior selection module receives suggestions generator module notices beats iconic gesture suggested inside actor 
beat coincides onset iconic filtered rule gesture class priority beats lowest class gesture family second beat left different onset time gesture type allows articulation 
conflicts noticed filters included example 
resulting tree shown 
lastly behavior scheduling module compiles xml tree including suggestions filtered action plan ready execution animation engine described section 
final schedule viseme codes shown 
second sentence processed way 
part output behavior generator shown 
particular situations arise sentence note 
action type identified language module action description typing action database 
gesture suggestion module suggest iconic gesture description action occurs rheme 
see snapshot generated typing gesture 
second actor actor identified gesture suggested object time located inside theme opposed rheme part clause having mentioned dialogue longer news 
utterance speech pause gaze away tone gaze tone eyebrows eyebrows acct thing bad thing 
part output xml tree second example 
don know thing bad thing example different kind nonverbal behavior assignment look system processes sentence don know thing bad thing 
output behavior generation module shown 
suggesting typical behaviors seen previous examples language tagger identified contrasting adjectives clause bad assigned contrast group 
gesture suggestion module receives tagged text generation rules suggest contrast gesture thing object bad thing object 
furthermore shape suggested contrast gestures right hand pose object left hand pose second object exactly members contrast group 
filtering gesture selection module notices contrasting gestures scheduled peak exactly moment couple hand beats 
beats filtered gesture class priority rule deciding contrasting gestures important beats 
see 
snapshot contrast gesture 

beat toolkit new generation beat generation animation tool extracts actual linguistic contextual information text order suggest appropriate gestures eye gaze nonverbal behaviors synchronize behaviors 
animators wish maintain control output beat seen kind snap grid communicative actions animators input text set eye face head hand behaviors phrases system correctly align behaviors send timings animation system 
animators wish concentrate higher level concerns personality lower level concerns motion characteristics beat takes care middle level animation choosing nonverbal behaviors best convey message typed text scheduling 
terms evaluation beat system useful think evaluating tool professional animators way doing interactive animation 
terms asked professional animators evaluate system extensive making beat video 
sense beat digital assistant way animation animator applies art 
animator told beat suggested natural movements animator necessarily consider 
instance surprised beat inserted particular gaze away command 
resulting animation looked natural 
hand animator said definitely places wanted override output generally didn want beat take away kind invention happened head listened dialogue track 
reason beat system invites input animator stage affect final output 
interactive animation harder compare beat existent systems 
note games interactive applications may require users speak voice may require passing large amounts text time linear animation 
cases expect beat serve important role 
system design decisions beat led inefficiencies 
primary goal support generality extensibility run time performance system optimized slow real time applications 
choice xml primary data structure prohibits direct representation behaviors overlap tree spans nonverbal behaviors require 
biggest obstacle beat producing perfectly appropriate natural behavior inputs set linguistic analyses performed language tagging module 
computational linguistics imperfect science beat output behaviors perfect linguistic results 
language tagging module designed extensible new linguistic algorithms tools available incorporated system 
includes addition improving automatic linguistic tagging expanding gesture ontology including basic spatial configuration gesture elements 
stands hand gestures assembled smaller gestural parts shortened 
gesture descriptions read knowledge base currently placed animation schedule unchanged 
behavior scheduler sure stroke gesture aligns correct word attempt stretch rest gesture instance span phrase needs illustrated 
similarly attempt slow pause speech accommodate complex gesture phenomenon observed people 
additional nonverbal behaviors added wrinkles forehead smiles ear 
system benefit visual interface displays timeline scheduled events moved rules modified 
hope demonstrated animator toolbox enhanced knowledge gesture nonverbal behaviors linguistic structure incorporated literally embodied behavior expression animation toolkit 

members gnl group particular ian nakano contribution comments 
special geoffrey beatty denny bromley steve tinsley galyean ryan jerome alias wavefront 
research leading preparation article supported france telecom generous sponsors mit media lab 

amaya bruderlin calvert emotion motion 
proc 
graphics interface pp 

badler schuler zhao palmer parameterized action representation virtual human agents embodied conversational agents cassell sullivan prevost churchill eds 
cambridge ma mit press pp 

thalmann behavioral animation system autonomous actors emotions proc 
st workshop embodied conversational characters 
blumberg galyean multi level direction autonomous creatures real time virtual environments 
siggraph conference proceedings pp 
acm siggraph addison wesley 
rose cohen verbs adverbs multidimensional motion interpolation ieee computer graphics applications vol 
pp 

brand voice 
siggraph conference proceedings pp 
acm siggraph addison wesley 
bregler slaney video rewrite driving visual speech audio 
siggraph conference proceedings pp 
acm siggraph addison wesley 
calvert composition realistic animation sequences multiple human figures making move mechanics control animation articulated figures badler barsky zeltzer eds 
san mateo ca morgan kaufmann pp 

cassell nudge nudge elements face face conversation embodied conversational agents embodied conversational agents cassell sullivan prevost churchill eds 
cambridge mit press pp 

cassell pelachaud badler steedman becket douville prevost stone animated conversation rule generation facial expression gesture spoken intonation multiple conversational agents 
siggraph conference proceedings acm siggraph addison wesley pp 

cassell prevost distribution semantic features speech gesture humans computers 
proc 
workshop integration gesture language sp newark de 
pp 
cassell torres prevost turn vs discourse structure best model multimodal conversation machine conversations wilks ed 
hague kluwer pp 

chang action scheduling humanoid conversational agents thesis electrical engineering computer science 
cambridge ma mit 
chi costa zhao badler emote model effort shape 
siggraph conference proceedings acm siggraph addison wesley pp 

cohen drucker role eye gaze avatar mediated conversational interfaces 
msr tr 
microsoft research halliday explorations functions language 
london edward arnold 
hirschberg accent discourse context assigning pitch accent synthetic speech 
proc 
aaai pp 

prevost cassell semantic discourse information text speech intonation 
proc 
acl workshop concept speech generation madrid 
huang hon goldsmith liu whistler trainable text speech system 
proc 
th int conf 
spoken language processing icslp pp 
piscataway nj 
salesin comic chat siggraph conference proceedings acm siggraph addison wesley pp 

lenat guha building large knowledge systems representation inference cyc project 
reading ma addison wesley 
massaro perceiving talking faces speech perception behavioral principle 
cambridge ma mit press 
mcneill hand mind gestures reveal thought 
chicago il london uk university chicago press 
miller beckwith fellbaum gross miller wordnet line lexical database 
nagao takeuchi speech dialogue facial displays multimodal human computer conversation 
proc 
acl pp 

pearce wyvill wyvill hill speech expression computer solution face animation 
proc 
graphics interface pp 

pelachaud badler steedman generating facial expressions speech cognitive science pp 

perlin noise antialiasing gesture texturing modeling procedural approach ebert ed 
cambridge ma ap professional 
perlin goldberg improv system scripting interactive actors virtual worlds proceedings siggraph pp 

prevost steedman specifying intonation context speech synthesis speech communication vol 
pp 

specification standard humanoid version group ed 
ece uwaterloo ca anim spec 
taylor black architecture festival speech synthesis system 
proc 
rd esca workshop speech synthesis pp 
caves australia 
waters automatic lip synchronization algorithm synthetic faces 
proc 
nd acm international conference multimedia pp 
san francisco ca 
yan paired speech gesture generation embodied conversational agents thesis media lab 
cambridge ma mit 
