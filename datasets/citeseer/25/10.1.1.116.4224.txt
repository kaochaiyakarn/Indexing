risk minimization language modeling text retrieval zhai july school computer science carnegie mellon university pittsburgh pa submitted partial fulfillment requirements degree doctor philosophy 
thesis committee john lafferty chair jamie callan jaime carbonell david evans bruce croft university massachusetts amherst copyright zhai research sponsored part advanced research development activity information technology arda statistical language modeling information retrieval research program 
views contained document author interpreted representing official policies expressed implied nsf darpa government entity 
keywords information retrieval text retrieval risk minimization bayesian decision ory language modeling yan acknowledgments wish express greatest advisor john lafferty 
john excellent guidance absolutely essential completion thesis 
treated peer friend right amount freedom guidance 
joy 
years learned things learned truly appreciate high quality research learned technical skills developing applying statistical language models learned improve technical writing 
am grateful john extremely constructive technical guidance especially direct contribution formulation retrieval problem statistical risk minimization framework basis thesis 
john high research standard principled methodology influenced research philosophy fundamentally 
reasons grateful david evans initial ph thesis advisor person inspire initial interest exciting research ar eas natural language processing information retrieval 
david supervised early research areas including master thesis exploring different levels noun phrases document indexing mentor ning graduate study 
unique insights identifying important ir problems forming practical solutions deeply influenced way looking realistic solutions real world problems 
david provided opportunities working real world ir systems participating trec sponsoring reg ular employment 
industrial research experiences learned importance users solid evalua tion reflected thesis 
david served member thesis committee provided valuable comments 
am grateful members committee jamie callan jaime car bruce croft constructive feedback thesis 
jamie helpful time thesis proposal 
provided useful comments helped plan thesis research realistically 
gave concrete comments evaluation thesis solid 
jaime gave insightful comments risk minimization framework specific suggestions exploring maximal marginal relevance approaches language modeling framework 
am grateful bruce pioneering encouraging research applying statistical language models ir 
discussions helpful validating research ideas developed thesis 
people useful discussions ideas thesis 
especially mention stephen robertson william cohen victor lavrenko rong jin yi zhang roni rosenfeld tom minka jerry zhu paul luo si collins thompson bob carpenter 
lauri lafferty carefully proofreading thesis helped improve presentation significantly 
am grateful friends fellow students colleagues spent time graduate student carnegie mellon university 
particular xiang tong years carnegie mellon univer sity 
xiang shared lot times discussing virtually aspect life research 
special burger won years ph study lending desktop initially waiting desktop come 
thi truong great teammate lemur project 
great time debugging releasing lemur toolkit 
yiming yang guy lebanon bing zhao judith klein lu stoica yan qu klaus zechner stimulating technical discussions 
owe great deal parents brother love support achievements possible 
parents fostering desire pursue scientific inquiry persistence working confident optimistic life philosophy 
brother tremendous help financially transition china smooth 
am deeply indebted dear wife yan love strong support graduate study 
yan influenced life positively fundamentally met 
high quality stimulated set goals high 
am grateful encouraging pursue second ph degree carnegie mellon university continuing support long journey finish 
thesis dedicated 
acknowledgments complete sons alex david adding pleasure life pushing positive way finish thesis 
dramatic increase online information years text re trieval increasingly important 
significant scientific challenge develop principled retrieval approaches form empirically far theoretically motivated models rarely led directly performance 
great challenge develop models go traditional notion topical relevance capture user factors topical redundancy sub topic diversity 
thesis presents new text retrieval framework bayesian deci sion theory 
framework unifies existing retrieval models including proposed language modeling approach general prob framework 
facilitates development new principled ap proaches text retrieval potential going traditional notion topical relevance 
framework queries documents modeled statistical language models probabilistic models text user preferences modeled loss functions retrieval cast risk minimization problem 
traditional retrieval models rely heavily ad hoc parameter tuning achieve satisfactory retrieval performance language models risk minimization framework possible exploit statistical esti mation methods improve retrieval performance set retrieval parameters automatically 
special case framework stage language model extensive evaluation achieves excellent re trieval performance ad hoc parameter tuning 
language models retrieval provides guidance improve retrieval performance reasonable language models accurate estimation methods 
spe cial case risk minimization framework derive kullback leibler divergence retrieval model exploit feedback documents improve estimation query models 
feedback far dealt heuristically language modeling approach retrieval 
kl divergence model provides principled way performing feedback treating query model updating 
propose specific query model updating algorithms feedback documents 
evaluation indicates algorithms effective feedback updated query models outperform original query models significantly 
risk minimization retrieval framework allows incorporating user factors traditional notion topical relevance 
language models capture redundancy sub topics documents study loss functions rank documents terms relevance sub topic diversity 
evaluation shows proposed language models effectively capture redundancy outperform relevance ranking method aspect retrieval task 
risk minimization framework opens new possibilities de principled approaches text retrieval possible ex different retrieval models systematically considering dif ferent loss functions different language models framework 
contents review existing retrieval models similarity models 
probabilistic relevance models 
probabilistic inference models 
summary 
risk minimization framework text retrieval bayesian decision theory 
statistical language models 
retrieval decision problem 
set retrieval 
rank retrieval 
independent loss 
dependent loss 
discussion 
decision theoretic view retrieval 
risk minimization probability ranking principle 
notion relevance 
statistical language models text retrieval 
ix smoothing language modeling approach 
language modeling approach 
smoothing methods 
experimental setup 
behavior individual methods 
interpolation vs backoff 
comparison methods 
dual role smoothing 

stage language models 
derivation 
stage smoothing method 
empirical exploration stage smoothing 
parameter estimation stage smoothing 
estimating 
estimating 
effectiveness parameter estimation methods 

kl divergence retrieval models derivation 
interpretation model 
estimation document language model query language model 
query model distillation 
model feedback 
generative model feedback documents 
divergence minimization feedback documents 
evaluation model pseudo feedback 

independent topical relevance 
aspect retrieval task 
description 
data set 
evaluation 
maximal marginal relevance mmr models 
novelty redundancy measures 
combining relevance novelty 
evaluation 
maximal diverse relevance mdr models 
general aspect retrieval model 
query model 
document model 
evaluation 

summary 
research directions 
list figures generative model query document 
generative model query document relevance 
performance jelinek mercer smoothing 
optimal range jelinek mercer smoothing 
performance dirichlet smoothing 
performance absolute discounting 
interpolation versus backoff 
example topic keyword section 
sensitivity pattern ap 
sensitivity pattern wsj 
sensitivity pattern ziff 
sensitivity pattern stage smoothing 
performance distilled query ap 
performance distilled query web 
precision recall curves distilled queries 
effect pseudo feedback ap trec web 
influence precision model feedback 
sensitivity precision feedback parameters 
comparison novelty measures aspect coverage 
xiii comparison novelty measures aspect uniqueness 
correlation precision aspect coverage aspect uniqueness 
effectiveness cost combination relevance novelty 
effectiveness query background model method 
effectiveness marginal query model method 
effectiveness marginal document model method 
aspect generative model query document 
influence number aspects plsi 
average aspect performance model likelihood 
correlation difference aspect performance likelihood 
influence novelty weight plsi 
influence novelty weight lda 
influence number aspects lda 
list tables summary smoothing methods 
statistics text collections study top queries testing bottom 
labels test collections 
comparison smoothing methods title queries 
comparison smoothing methods long queries 
comparison long queries title queries 
stability stage smoothing parameter setting 
estimated parameter values dirichlet prior smoothing 
performance stage smoothing small collections 
performance stage smoothing large collections 
effectiveness model feedback 
comparison rocchio feedback model feedback 
novelty measures language models 
comparison novelty measures relevance ranking 
comparison simple baseline feedback baseline 
effectiveness cost combination relevance novelty 
effectiveness query background model approach 
effectiveness marginal query model approach 
effectiveness marginal document model approach 
xv comparison mmr models 
effectiveness aspect loss function plsi 
comparison basic plsi relevance baseline 
effectiveness improved plsi 
effectiveness aspect loss function lda 
comparison lda relevance baseline 
chapter years seen explosive growth volume information 
example december february web doubled size pages encompassing terabytes information lawrence giles 
year google index documents web pages sherman 
types textual information books newspapers periodicals growing rapidly 
study berkeley lyman varian worldwide production original content stored digitally standard compression methods terabyte year books terabytes year newspapers terabyte year periodicals terabytes year office documents 
high volume information effectively efficiently managing online information significant challenge causes information overload inability extract needed knowledge immense quantity information wurman 
formation retrieval far useful technique address problem information overload 
retrieval textual information text retrieval especially important frequently wanted information textual techniques ing textual information useful retrieving media information companion text 
document collection set unordered text documents task text retrieval tr defined user query description user formation need identify subset documents satisfy user information need 
major difficulty tr accurately judge particular set docu ments satisfy user information need 
criterion inherently impossible formalize generally hard user prescribe exact information need completely precisely query difficult computer understand meaning query precisely 
tr really defined task sense correctness solution retrieval problem evaluated user empirically 
traditionally documents satisfy user information need called rel documents retrieval task find relevant documents query 
notion relevance complicated 
user information need relevance generally imprecise depends situation context retrieval task 
assumptions simplify retrieval task 
relevance document assumed independent documents including ready retrieved independent relevance assumption 
second relevance document assumed mean level topical relevance document respect query topical relevance assumption 
constraints retrieval task essentially evaluate topical relevance value document independently respect query retrieval task tractable 
reality assumptions expected hold 
example user interested seeing duplicates document duplicates topically relevant query 
means utility retrieving document depends previously retrieved documents user seen 
topical relevance attributes document user may care 
example user child readability documents matter 
suggests highly desirable develop retrieval models go notion independent topical relevance 
need go topical relevance recognized literature saracevic 
ranking documents considering redundancy carbonell goldstein non topical factors considered top existing retrieval model 
fair say existing retrieval models focused topical relevance 
explicitly mentioned relevance mean topical relevance 
larger scope ir tr taken include narrow sense retrieval routing categorization clustering lewis 
thesis define ir retrieving documents collection satisfy user information need referred ad hoc retrieval task trec voorhees harman due inherent vagueness uncertainty relevance argued having retrieval system clear distinction relevant non relevant documents tr system rank selected documents order de relevance user deciding robertson 
modern retrieval systems generally assign relevance value document rank documents accordingly 
ranked list documents user 
af ter viewing documents user may able tell system documents relevant 
feedback information system im prove retrieval process resulting presumably better ranking results 
procedure called relevance feedback 
compute relevance value document respect query retrieval sys tem assume retrieval model formally defines relevance measure certain representation query documents 
decades different types retrieval models proposed tested sparck jones willett 
great diversity approaches methodology developed single unified re trieval model proven effective 
field progressed different ways 
hand theoretical studies underlying model developed direction example represented various kinds logic models van rijsbergen 
hand empirical studies models including variants vector space model salton buckley 
significant scientific challenge develop theoretically motivated models perform empirically 
interesting direction develop ment bm retrieval function motivated poisson probabilistic retrieval model proven quite effective practice robertson walker robertson 
new approach language modeling successfully applied problem ad hoc retrieval ponte croft 
new approach promising foundations statistical theory great deal complementary language modeling speech recognition natural language processing fact simple language modeling retrieval methods performed quite empirically 
great potential statistical language models develop new principled retrieval models 
thesis new text retrieval framework bayesian decision theory facilitates development new principled approaches text retrieval statistical language models 
framework queries documents modeled statistical language models probabilistic models text user preferences modeled loss functions retrieval cast risk minimization problem decision problem 
framework incorporates language models natural components retrieval provides general connection problem retrieval statistical language modeling 
framework address limitations traditional retrieval mod els 
choosing different loss functions different query document language models obtain different special cases risk minimization framework 
show risk minimization framework unify existing retrieval models including lan guage modeling approach proposed general probabilistic framework 
viewing traditional models general framework see clearly sumptions understand better limitations enabling improve models 
traditional retrieval models rely heavily ad hoc parameter tuning achieve satisfactory retrieval performance language models possible exploit statistical estimation methods improve retrieval performance set retrieval parameters automatically 
special case risk minimization framework stage language model extensive evaluation achieves excellent retrieval performance ad hoc parameter tuning 
language models retrieval provides guidance improve retrieval performance reasonable language models accurate estimation methods 
special case risk minimization framework derive kullback leibler divergence retrieval model exploit feedback docu ments improve estimation query models 
feedback far dealt heuristically language modeling approach retrieval 
kl divergence model provides natural way performing feedback treating query model updating 
propose specific query model updating algorithms feedback documents 
evaluation indicates algorithms effective feedback outperform baseline methods significantly 
risk minimization retrieval framework allows incorporating user fac tors traditional notion topical relevance 
language models capture redundancy sub topics documents study loss functions rank documents terms relevance sub topic diversity 
evaluation shows proposed language models effectively capture redundancy outperform relevance ranking method aspect retrieval task 
thesis gives new perspective tr models 
risk minimization framework provides general probabilistic retrieval framework unifies different existing tr models including proposed language modeling approach 
framework provides general connection text retrieval statistical language models making possible apply statistical estimation methods text retrieval 
furthermore go traditional notion topical relevance potentially incorporate user factors retrieval criteria 
risk minimization framework opens new possibilities developing principled approaches text retrieval 
allows exploring different retrieval models systematically considering different loss functions different language models framework demonstrated special cases explored thesis 
chapter review existing retrieval models identify relevant documents tr system assume specific measure rele vance document query 
operational definition relevant document respect query needed 
fundamental problem tr formalize concept relevance 
different formalization relevance generally leads different tr model 
decades different retrieval models proposed studied tested 
mathematical basis spans large spectrum including algebra logic probabil ity statistics 
existing models roughly grouped major categories depending define measure relevance 
category relevance sumed correlated similarity query document 
second category binary random variable model relevance probabilistic models estimate value relevance variable 
third category relevance un certainty modeled uncertainty inferring queries documents vice versa 
discuss categories details 
similarity models similarity retrieval model assumed relevance status document respect query correlated similarity query docu ment level representation similar query document relevant document assumed 
practice similarity measure preserves correlation generate relevance status value rsv document rank documents accordingly 
vector space model known model type salton salton mcgill salton 
vector space model document query represented term vectors high dimensional term space 
term assigned weight reflects importance document query 
query relevance status value document similarity query vector document vector measured vector similarity measure cosine angle formed vectors 
formally document may represented document vector xn total number terms xi weight assigned term similarly query represented query vector yn 
weight usually computed called tf idf weighting combination factors singhal local frequency term document query global frequency term collection document length 
cosine measure similarity function document query sim vector space model naturally decomposes retrieval model components term vector representation query term vector representation document similarity distance measure document vector query vector 
synchronization components generally unspecified particular similarity measure dictate representation document query 
vector space model general retrieval framework representation query documents similarity measure arbitrary principle 
related generality vector space model regarded ral model retrieval task retrieval naturally divided separate stages indexing search 
indexing stage explicitly representing document query indexing terms extracted document query 
indexing terms assigned different weights indicate impor tance describing document query 
search stage evaluating relevance value similarity document vector query vector 
flexibility vector space model easy incorporate different indexing mod els 
example poisson probabilistic indexing model select indexing terms assign term weights harter bookstein swanson 
latent semantic indexing applied reduce dimension term space cap ture semantic closeness terms improve representation documents query deerwester :10.1.1.108.8490
document represented multinomial distribution terms distribution model indexing proposed wong yao 
vector space model feedback typically treated query vector updating 
known approach rocchio method simply adds centroid vector relevant documents query vector subtracts centroid vector non relevant documents appropriate coefficients rocchio 
effect leads expansion original query vector additional terms extracted known relevant non relevant documents added original query vector appropriate weights salton buckley 
extended boolean norm model heuristic extension traditional boolean model perform document ranking regarded special case sim ilarity model fox salton 
similarity function parameter controls strictness satisfying constraint boolean query way approaches strict conjunctive disjunctive boolean model approaches infinity conjunctive disjunctive constraint behaves regular vector space similarity measure smaller 
model rely sumptions boolean structure query undesirable mathematical properties rousseau 
little large scale evaluation model 
vector space model far popular retrieval model due simplicity effectiveness 
typical effective weighting formula pivoted document length normalization taken singhal ln ln tf dl avdl qtf ln empirical parameter usually df tf term frequency document qtf term frequency query total number documents collection df number documents contain term dl document length avdl average document length 
main criticism vector space model provides formal framework representation making study representation inherently separate rele vance estimation 
separation relevance function weighting terms advantage flexible difficult study interaction rep resentation relevance measurement 
semantics similarity relevance function highly dependent actual representation term weights query document 
result study representation vector space model far largely heuristic 
central problems document query representation extraction indexing terms units weighting indexing terms 
choice different indexing units extensively studied significant improvement achieved simplest word indexing lewis evaluation shown promising improvement average lin guistic phrases evans zhai strzalkowski zhai 
heuristics proposed improve term weighting weighting method significantly better heuristic tf idf term weighting salton buckley 
address variances length documents effective weight ing formula needs incorporate document length heuristically singhal 
salton introduced idea discrimination value indexing term salton 
discrimination value indexing term increase decrease mean inter document distance caused adding indexing term term space text representation 
middle frequency terms higher discrim value 
similarity measure discrimination value provides principled way selecting terms indexing 
deficiencies 
discrimination value modeling relevance relies similarity mea sure 
second helpful selecting indexing terms weighting terms 
risk minimization framework propose suggests new formal similarity retrieval model representation query documents associated statistical language models 
statistical language models possible replace traditional ad hoc tuning parameters principled estimation parameters 
traditional vector space models regarded special cases general similarity model parameters set heuristically 
example represent query document unigram language model easily derive similarity model similar distribution model proposed wong yao 
probabilistic relevance models probabilistic relevance model interested question probability document relevant query sparck jones 
query document assumed relevant non relevant system sure true relevance status document rely probabilistic relevance model estimate 
formally random variables denote document query respectively 
binary random variable indicates relevant 
takes values denote relevant relevant 
task estimate probability relevance 
depending probability estimated special cases general probabilistic relevance model 
estimated directly discriminative regression model 
essentially relevance variable assumed dependent features characterize matching regression model probably intro duced success fox fox features term frequency au citation combined linear regression 
fuhr buckley fuhr buckley polynomial regression approximate relevance 
lo regression involving information query term frequency document term fre quency idf relative term frequency collection model shows promising performance small testing collections 
regression models provide principled way exploring heuristic features ideas 
important advan tage regression models ability learn past relevance judgments sense parameters model estimated relevance judgments including judgments different queries documents 
regression models heuristic features place lots empirical experi mentation needed order find set features 
regression model provides limited guidance extending retrieval model 
alternatively estimated indirectly generative model way lafferty zhai equivalently may log odds ratio rank documents log log different ways factor conditional probability correspond ing document generation query generation document generation ranking formula log log log essentially retrieval problem formulated category document classifica tion problem interested ranking classification likelihood assigning class labels 
operationally models estimated query modeling relevant documents modeling non relevant documents 
documents ranked posterior probability relevance 
classic probabilistic retrieval models robertson sparck jones van ri fuhr document generation 
binary independence retrieval bir model robertson sparck jones fuhr known classical probabilistic model 
bir model assumes terms inde distributed relevance models essentially uses na bayes classifier document ranking lewis 
bir retrieval formula robertson sparck jones lafferty zhai log rank log rank means equivalent terms ranking documents 
efforts improve binary representation 
van rijsbergen extended binary independence model capturing term dependency defined required underlying independence assumption final retrieval formula weaker cooper 
minimum spanning tree weighted average mutual information van 
dependency model achieved significant increases retrieval performance independence model 
evaluation done small collections estimation parameters problem practice harper van rijsbergen 
croft investigated heuristic term significance weight incorporated probabilistic models principled way croft 
effort improve document representation involves introducing term frequency directly model multiple poisson mixture representation documents robertson 
model shown empirical improvement retrieval performance directly approximation model simple tf formula turns quite effective robertson walker 
heuristic retrieval formula bm successfully city university okapi system trec systems voorhees harman 
different way introducing term frequency model directly proposed implied lot text categorization regard document generated unigram language model mccallum nigam 
query generation ranking formula log log log assumption conditioned event document inde pendent query formula log rank log log components model 
major component interpreted relevant query model conditioned document 
probability user likes document query 
second component prior encode user bias documents 
models query generation explored maron kuhns fuhr lafferty zhai 
probabilistic indexing model proposed maron kuhns probabilistic retrieval model indexing terms assigned document weighted probability user likes document term query 
weight term document 
estimation model user feedback content binary independence indexing bii model proposed fuhr special case query generation model 
allows description document weighted terms estimated arbitrary queries specific parameterization hard estimate parameters practice 
lafferty zhai shown proposed language modeling approach retrieval special probabilistic relevance model query generation decompose generative model 
provides relevance justification new family probabilistic models statistical language modeling 
language modeling approach introduced ponte croft explored hiemstra kraaij miller berger lafferty song croft 
estimation language model doc ument estimation 
key component language modeling approach 
direction differs mainly language model method language model estimation 
smoothing document language models kind collection language model popular existing 
example geometric smoothing ponte croft linear interpolation smoothing hiemstra kraaij berger lafferty viewed state hidden markov model miller 
berger lafferty ex semantic smoothing estimating translation model mapping document term query term reported significant improvements baseline language modeling approach translation models berger lafferty 
language modeling approach important contributions 
introduces new effective probabilistic ranking function query generation 
earlier query generation models estimating parameters difficult model pro posed ponte croft explicitly addresses estimation problem statistical language models 
second reveals connection difficult problem text representation ir language modeling techniques studied application areas statistical machine translation speech recognition making possible exploit various kinds language modeling techniques address representation problem 
multinomial model documents introduced wong yao exploited language model 
notion relevance probabilistically equivalent clas sic document generation probabilistic models language modeling approach important differences estimation perspective involve different pa rameters estimation 
relevance judgments available easier estimate language modeling approach estimate clas sic probabilistic models 
intuitively easier estimate model relevant queries document estimate model relevant documents query 
bir model encountered difficulties estimating explicit relevance information available 
typically set constant estimated assumption collection documents non relevant croft harper robertson walker 
lavrenko croft progress estimating relevance model relevance judgments exploiting language modeling techniques lavrenko croft 
explicit rel judgments available classic models document generation advantage able improve estimation component probabilistic models naturally exploiting explicit relevance information 
relevance judgments user provide direct training data estimating applied new documents 
relevance judgments provide direct training data improving estimate lan guage modeling approach judged relevant documents 
directly improved models expected improve ranking un judged docu ments 
interestingly improved models potentially beneficial new queries feature unavailable document generation models 
imposing strict document generation query generation decomposition generate document query pair simultaneously 
mittendorf schauble explored passage generative model hidden markov model hmm regarded case mittendorf schauble 
document query pair represented sequence symbols corresponding term particular position document 
term tokens clustered terms similarity token query 
way term token particular position document mapped symbol represents cluster token belongs 
symbol sequences modeled output hmm states corresponding relevant passage background noise 
relevance value computed likelihood ratio sequence passage hmm model background model 
empirically probabilistic relevance models shown performance 
simple approximation poisson probabilistic model led bm retrieval formula okapi system effective robertson walker robertson 
language modeling approaches shown perform ponte croft hiemstra kraaij miller 
bm formula shown notations singhal ln df df tf dl avdl tf qtf qtf usually parameters vari ables meaning vector space retrieval formula described pre vious section 
probabilistic relevance models shown special case risk tion framework constant cost loss function 
risk minimization framework maintain separate generative model queries documents re spectively 
slightly different loss function derive stage language modeling approach text retrieval propose methods automatically estimating parame ters stage smoothing strategy 
extensive evaluation stage smoothing method gives excellent retrieval performance completely automatic pa rameter settings 
probabilistic inference models probabilistic inference model relevance uncertainty document respect query modeled uncertainty associated inferring proving query document 
depending defines means proving query document different inference models possible 
van rijsbergen introduced logic probabilistic inference model text retrieval van rijsbergen document relevant query query proved document 
boolean retrieval model regarded simple case model 
cope inherent uncertainty relevance van rijsbergen introduced logic probabilistic inference probability conditional estimated notion possible worlds 
wong yao wong yao extended probabilistic inference model developed general probabilistic inference model subsumes tr models boolean vector space classic probabilistic models 
fuhr shows particular form language modeling approach derived special case general probabilistic inference model fuhr 
theoretically interesting probabilistic inference models rely fur ther assumptions representation documents queries order obtain operational retrieval formula 
choice representations way outside model little guidance choose improve representation 
inference network model probabilistic inference turtle croft 
essentially bayesian belief network models dependency satisfaction query observation documents 
estimation relevance computation conditional probability query satisfied document observed 
similar uses bayesian belief network re trieval fung ribeiro muntz ribeiro neto 
inference network model general formalism models discussed 
different ways realize probabilistic relationship observation documents satisfaction user infor mation need obtain different existing specific tr models boolean extended boolean vector space conventional probabilistic models 
importantly inference network model potentially go traditional notion topical relevance goal inference general highest level framework general accommodate probabilistic model 
gen possible combine multiple evidence including different formulations query 
query language directly model important practical contribution ir technology 
despite generality inference network framework says little decompose general probabilistic model 
result operationally usually set probabilities heuristics done inquery system callan 
kwok network model may considered performing probabilistic inference kwok spread activation 
general probabilistic inference models address issue relevance general way 
sense lack commitment specific assumptions general models helped maintain generality retrieval models 
predictive power theory 
result generally provide little guidance refine general notion relevance 
risk minimization framework quite general 
able show existing models special cases risk minimization 
furthermore framework goes traditional notion topical relevance just inference network framework allows incorporating multiple user factors retrieval ria 
risk minimization framework different probabilistic inference models bayesian belief network models provides explicit direct connection query document language models 
techniques language modeling brought operational retrieval model easily 
sense refined operational framework probabilistic inference models 
thesis explore possibilities 
summary large number different retrieval approaches proposed studied tremendous amount effort devoted evaluation various kinds ap proaches especially context trec evaluation voorhees harman 
lot progress developing retrieval theory improving em performance 
existing research limitations 
integration theory practice text retrieval far quite weak 
theoretical guidance formal principles rarely led performance directly lot heuristic parameter tuning order achieve performance 
parameter tuning generally difficult due fact optimal setting parameters collection query dependent parameters may interact complicated way 
seen excerpt parameter tuning known okapi system best performing tr systems today weighting formula described section parameters depend nature queries possibly database default respectively smaller values advantageous long queries set effectively infinite robertson walker 
significant scientific challenge develop principled retrieval approaches perform empirically 
thesis new text retrieval framework facilitates development new principled approaches text retrieval statistical language models 
statistical language models provide principled way model text documents queries making possible set retrieval parameters statistical estimation methods 
par ticular special case risk minimization framework stage language model shown achieve excellent retrieval performance ad hoc parameter tuning 
existing language modeling approach promising tered difficulty incorporating feedback mechanism important com ponent retrieval system 
specifically feedback generally dealt ad hoc way 
typically set terms selected relevant documents documents assumed relevant situation blind pseudo feedback query aug mented set terms weight ponte miller ng :10.1.1.54.6410
creates conceptual inconsistency query original query normally piece text expanded query text plus weighted terms 
difficulty largely due lack query model existing 
instance risk minimization framework derive kl divergence retrieval model covers language modeling approach special case 
kl divergence model explicitly deals query model perform feedback naturally treating query model updating 
fundamental limitation traditional retrieval models strong sumptions relevance independent relevance assumption topical relevance assumption assumptions usually hold reality 
real appli cations retrieval criteria may involve factors redundancy 
traditional models inadequate modeling realistic retrieval criteria 
risk minimization framework retrieval problem formalized statistical decision problem general way 
generality allows unify different traditional retrieval models single general probabilistic framework possible go traditional notion independent topical relevance capture realistic retrieval criteria 
explore language models capture redundancy sub topics documents study loss functions rank documents relevance sub topic diversity 
risk minimization framework opens new possibilities developing prin approaches text retrieval possible explore different retrieval mod els systematically considering different loss functions different language models framework 
thesis explores special cases 
chapter risk minimization framework text retrieval chapter risk minimization framework 
risk minimization formulation bayesian decision theory statistical language modeling give brief 
bayesian decision theory bayesian decision theory provides solid theoretical foundation thinking prob lems action inference uncertainty berger 
basic idea ex considering formulation decision problem 
assume observation random variable distribution depends parameter interpreted representing true state nature 
possible actions 
assume loss function ai associated action value specifies decision preferences 
task decision action take 
order evaluate action consider bayesian expected loss risk asso ciated action ai observed ai ai bayesian decision theory states optimal decision choose bayes action action minimizes conditional expected risk berger arg min statistical language models statistical language model probabilistic mechanism generating sequence words text jelinek rosenfeld 
defines distribution possible word sequences 
simplest language model unigram language model essentially word distribution 
unigram language model text gen erated generating word independently 
example probability generating piece text wn unigram language model 
wn wi complex language models may capture word orders structure text jelinek rosenfeld 
example trigram language models gener ate word previously generated words capturing local ordering words 
maximum entropy language models capture long distance dependency words 
probabilistic context free grammars structure generative models text allowing incorporation structural constraints 
general statistical language models provide principled way capture quantitatively uncertainty associated natural language applications variety language technology tasks especially speech recognition 
just applied text retrieval 
ultimately need explore sophisticated models thesis study simplest unigram language model reasons text re trieval generally involves large amount text information puts constraints efficiency algorithm evaluated 
sophisticated language models significantly increase computational complexity retrieval making large scale evalu ation practically infeasible 
cases estimating document language model query language model working extremely limited amount data estimation complex models may reliable 
words sparseness data puts constraint complexity model estimate accurately 
simplest language models existing able demonstrate promising retrieval performance 
understanding simple models understand better kind sophisticated models may expected improve performance 
retrieval decision problem general retrieval system regarded interactive information service system answers user query presenting list documents 
seeing documents user may reformulate query executed system produce list documents 
cycle continues 
cycle retrieval system needs choose subset documents user way information available system cludes current user user query sources documents specific document collection 
terms bayesian decision theory observations user query document sources sn collection documents regarded observations random variables 
specifically view query output probabilistic process associated user similarly view document output probabilistic process associ ated author document source si 
query document result choosing model generating query document model 
set documents result generating document independently possibly different model 
independence assumption essential simplify pre sentation 
query model principle encode detailed knowledge user information need context query 
similarly document model encode complex information document source author 
formally denote parameters query model denote pa rameters document model 
user generates query selecting distribution 
model query generated probability 
note user potentially text query mean different information needs strictly speaking variable regarded corresponding user current context 
affect presentation frame simply refer user 
similarly source selects document model distribution uses model generate document 
markov chains illustrated model selection model selection query generation document generation generative model query document 
dn collection documents obtained sources sn 
denote model generates document di 
observations actions 
action corresponds possible response system query 
example imagine system return unordered subset documents user 
alternatively system may decide ranking documents ranked list documents 
possibility cluster relevant documents structured view documents 
generally think retrieval action compound decision involving selecting subset documents presenting user issued query presentation strategy 
set possible presentation strategies 
represent actions di di subset results presentation strategy 
general framework bayesian decision theory action ai di associated loss ai general depends parameters model relevant user factors document source factors 
framework expected risk action ai di di posterior distribution di bayes decision rule choose action expected risk arg min select strategy note gives general formulation retrieval decision problem involves searching simultaneously 
presentation strategy fairly arbitrary principle presenting documents certain order presenting summary documents presenting clustering view documents 
practically need able quantify loss associated presentation strategy 
sections consider special cases 
set retrieval consider case loss function depend presentation strat egy means care select optimal subset documents presentation 
case risk minimization framework leads general set retrieval method 
arg min arg min loss function encode user preferences selected subset 
generally loss function relevance status documents selected optimal subset contain documents relevant 
preferences desired diversity desired size subset captured appropriate loss function 
traditional boolean retrieval model viewed special case general set retrieval framework uncertainty query models document models di loss function document satisfies boolean query 
loss function quite general sense allow deterministic retrieval rule applied query document relevant loss function result retrieval strategy involves making independent binary retrieval decision document 
particular function defined structured query 
ways specialize set retrieval method exploring main focus thesis 
major disadvantage set retrieval may hard user control number results 
zero return query constrained overwhelming number results query constrained 
hard user locate relevant ones reading non relevant documents 
may useful rank documents making hard retrieval decision document 
rank retrieval consider different special case risk minimization framework selected documents user ranked list documents possible presentation strategy corresponds possible ranking documents 
ranking strategy assumed modern retrieval systems models 
formally may denote action ai di complete ordering di 
action ai mean selected documents order means denote action sequence documents 
write ai index document ranked th rank permutation mapping assume actions essentially involve different rankings docu ments collection permutation complete ordering documents simplify notations denote action ai 
allow partial ordering principle consider complete ordering 
case optimal bayes decision general ranking rule ments 
arg min arg min 
see loss function discriminating different possible rankings docu characterize loss associated ranking documents 
presenting documents ranking implies user apply stopping criterion user read documents order appropriate 
actual loss equivalently utility ranking depend user stops 
utility affected user browsing behavior model probability distribution ranks user 
setup define loss ranking expected loss assumed stopping distribution formally si denote probability user reading seeing top documents 
si 
treat sn user factors 
sil actual loss incurred user views documents 
note different expected loss ranking user stopping probability distribution exact loss ranking user views list 
assuming user view documents order total loss viewing documents sum loss associated viewing indi vidual document reasonable decomposition loss conditional loss viewing user viewed 
putting arg min arg min si define conditional risk dk dk def dk dk interpreted expected risk user viewing document dk dk previously viewed 
write si si general framework ranking documents risk minimization framework 
basically says optimal ranking minimizes expected conditional loss stopping distribution associated sequentially viewing document 
see optimal ranking depends stopping distribution si 
user tends early optimal decision affected loss associated top ranked documents equally affected loss sociated documents 
stopping probability distribution provides way model high precision early stopping preference high recall late ping preference 
sequential decomposition loss reasonable presenting ranked list user 
clearly presentation strategies clustering decomposition appropriate 
consider different cases loss function 
independent loss consider case loss viewing document independent viewing 
means case expected risk ranking si si see risk weighted sum risk viewing individual document 
rank increases weight decreases weight rank largest si 
optimal ranking independent si ascending order individual risk equivalent situation assume possible action single document 
loss function interpreted loss associated presenting viewing document complete specification loss func tion generally force explicit assumed ranking criterion notion relevance 
show risk function covers existing retrieval models special cases lafferty zhai 
relevance independent loss functions show traditional relevance probabilistic models special cases risk minimization consider special case loss function defined psfrag replacements model selection model selection query generation doc generation generative model query document relevance binary relevance variable specifically assume document di hidden binary relevance variable ri depends ri interpreted representing true relevance status di re spect relevant non relevant see 
random variable ri observed user relevance judgment di unobserved wise 
assume ri observed 
note query model encode detailed knowledge user distribution relevance variable user specific 
introducing variable parameter space equation assume loss function depends relevance variable defined cost constants reasonable loss function 
equation means risk minimization ranking criterion equivalent ranking probability relevance decreasing order equivalent increasing order 
basis probabilistic relevance retrieval models 
shown variants probabilistic relevance models reviewed chapter section special cases risk minimization framework 
particular cover classic document generation probabilistic retrieval models language modeling approach query generation 
see lafferty zhai details derivation 
distance independent loss functions consider special case loss function proportional distance similarity measure cost constant 
intuitively models close similar small 
loss function equation means risk minimization ranking criterion equivalent ranking expected model distance 
distance easier compute approximate value posterior mode parameters 
arg max arg max note factor includes prior information document general included comparing risk different documents 
critical incorporating query independent link analysis extrinsic knowledge document 
assume affect ranking general distance equivalently similarity probabilistic model view vector space model special case general similarity model simply term vector parameters estimated heuristically distance function cosine inner product measure 
dependent loss independent loss really realistic assumption loss viewing document generally depends documents viewed 
example user seen document similar document document incur greater loss completely new user 
independence assumption hold complexity finding optimal ranking computation tractable 
practical solution greedy algorithm construct sub optimal ranking 
specifically grow target ranking choosing document rank starting rank 
suppose partially constructed ranking choosing document rank 
possible document index considered rank represent ordering dk 
increase risk picking dk rank si dk dj extend choose arg min arg min dk step just need evaluate dk choose minimizes 
gives general greedy context dependent ranking algorithm 
algorithm see optimal ranking depend stopping prob abilities si 
chapter discuss special cases algorithm including maximal marginal relevance method mmr carbonell goldstein 
discussion decision theoretic view retrieval treating retrieval decision theoretic view new 
people studying choose weight indexing terms decision theoretic perspective bookstein swanson harter cooper maron 
probability ranking principle justified optimizing statistical decision retrieve document robertson 
action decision space considered early limited binary decision regarding retrieve document regarding assign index term document gave complete decision theoretic formal model retrieval 
risk minimization framework explicitly formally treated retrieval problem decision making problem 
decision problem general action space principle consists possible actions system take response query 
scope decision space significant departure existing decision theoretic treatment retrieval 
general decision theoretic view explicitly suggests retrieval modeled interactive process involves cycles user reformulating query system presenting information 
believe time user variable document source variable explicitly formally introduced retrieval model 
strictly speaking represents user certain information need user enters query treated different robertson 
hard imagine factor real user retrieval context separate variables 
introduced separate source variable document independent 
simplify presentation framework easily put constraints source variables requiring identical 
explicit possible consider interesting user factors document source factors specifying loss function 
example high precision versus high recall preferences encoded assuming different stopping probability distribution 
interestingly shown formally chapter assume independent loss function greedy algorithm approximate optimal ranking sequentially additive loss function optimal solution depend stopping probability distribution 
redundancy documents captured dependent loss function 
factors readability documents incorporated long model readability 
major difference risk minimization framework early decision theoretic treatment indexing early cooper maron takes utility frequency sense expected utility possible uses take bayesian view consider utility respect current user 
decision theoretic view retrieval possible model interactive re trieval process sequential decision process user variable changes time 
allow system accept user response just text query input really going retrieval general interac tive information access system 
risk minimization probability ranking principle probability ranking principle prp taken foundation prob retrieval models 
stated robertson principle assumptions relevance document request independent doc uments collection usefulness relevant document requester may depend number relevant documents requester seen seen useful subsequent may assumptions prp provides justification ranking documents descending order probability relevance evaluated separately document 
risk minimization framework derived general ranking formula ranking documents ascending order expected risk document computed separately document 
assumptions independent loss function assume loss associated user viewing document depend documents user may seen 
sequential browsing assume ranked list docu ments user browse list sequentially ranking 
interesting note difference relationship assumptions assumptions robertson 
sequential browsing assumption robertson explicitly stated robertson independent loss assumption stronger independent relevance assumption possible define dependent loss function independent relevance 
second assumption robertson implies utility equivalently loss retrieving document depends number relevant documents ranked document directly depend relevance status specific document 
price weaker assumption prp longer guaranteed give ranking globally optimal optimal greedy algorithm 
assumption greedy algorithm construct optimal ranking implicit robertson decision problem involves retrieve single document choosing ranking documents 
contrast assumptions ranking expected risk shown globally optimal 
prp limitations discussed cooper 
prp assumes document usefulness binary property reality really matter degree 
independent loss ranking function derived limitation 
possible derive prp risk mini mization framework assuming loss function depends binary relevance variable 
second ranking documents probability usefulness optimal 
cooper gave example essentially shows independent relevance assumption may true 
robertson discussed informally ways extend prp address possible dependency documents robertson 
captured risk minimization framework 
go ranking probability relevance ranking expected utility achieve loss function risk minimization framework 
second essentially greedy algorithm ranking conditional loss function 
risk minimization framework provide formalized way go prp 
stated robertson estimation probability relevance document may appropriate form prediction 
main questions basis kinds information system prediction 
system utilize combine various kinds information 
questions represent central problem retrieval theory risk minimization framework provides formal answer questions 
information available system includes user document source query documents 
prediction consists selecting subset doc uments presenting way 
easily imagine possible predictions factors combined bayesian decision theoretic framework compute optimal prediction 
notion relevance risk minimization framework originally motivated need general rank ing function allows view different ranking criteria including query likelihood criterion language modeling approach unified frame 
discussed existing literature retrieval problem may decomposed basic components representation query representation document matching representations 
emphasis framework probabilistic modeling corresponding assumptions query viewed observation probabilistic query model document viewed observation probabilistic document model utility document respect query ranking criterion function query model document model 
flexibility choosing different query models document models neces sary allow different representations query document 
flexibility choosing loss function necessary order cover different notions relevance different ranking strategies 
result assumptions representation problem essentially equivalent model estimation matching problem equivalent estimation value utility function observed query document 
bayesian decision theory utility modeled loss function loss value regarded negative utility value 
say notion relevance taken risk minimization framework essentially expected utility value reflects user preferences uncertainty query document models 
notion relevance clearly general traditional notion independent topical relevance utility depend factors affect user satisfaction system action 
example factors may include user perception redundancy special characteristics documents collection 
seen formally dependency loss function variables traditional notion independent relevance obtained special case general utility notion making independent assumption loss function 
assumption optimal ranking rank documents respective expected loss risk 
expected risk essentially gives independent measure relevance document respect query 
interesting note measure explicitly captures different types uncertainties 
assumed content topic represented model underlying document query uncertain document query estimate model 
uncertainty reflects system inability completely understand underlying content topic query document called topic uncertainty second know true model query document relevance value document model respect query model uncertain vague 
uncertainty reflects incomplete knowledge user true relevance criterion called relevance uncertainty topic uncertainty handled computing expectation possible models relevance uncertainty resolved specification concrete loss function 
different approximation assumptions simplify computation risk minimization formula resolving uncertainties different ways 
general similarity model example resolve topic uncertainty pick ing model rely similarity distance function measure rel uncertainty 
probabilistic relevance model including language modeling approach assumes binary relevance relationship query docu ment addresses relevance uncertainty topic uncertainty single probabilistic model 
binary relevance relationship document relevant non relevant query different degree relevance modeled different similarity model 
statistical language models text retrieval language models risk minimization framework framework quite different general retrieval frameworks inference network particular framework operational 
operational document ranking formula derived specifying components query model document model loss function 
different specification components leads different operational model 
clear parameter involved retrieval formula derived risk minimization framework loss function language models documents queries 
parameters associated loss function generally represent user retrieval preferences set user meaningful way 
example level redundancy tolerance parameter set user different users may different preferences high recall preference may imply tolerance redundancy 
hand parameters associated language models principle estimated automatically 
example chapters see parameters control smoothing language models 
parameters involved statistical language models possible exploit statistical estimation methods estimate values parameters providing principled way setting retrieval parameters 
able estimate retrieval parameters major advantage language models information retrieval 
chapter show new retrieval formula stage language model smoothing method achieve excellent retrieval performance completely automatic setting retrieval smoothing parameters 
advantage language models expect achieve better retrieval performance accurate estimation language model reasonable language model 
guidance improve retrieval model traditional model 
demonstrated new retrieval model feedback documents exploited improve estimation query language model 
show improved query model lead improved retrieval performance general 
language models useful modeling sub topic structure doc ument redundancy documents 
explored thesis way achieve non traditional ranking documents minimize redundancy maximize sub topic coverage 
chapter smoothing language modeling approach document language models query language models building blocks risk minimization framework 
chapter study important problem language model smoothing focusing smoothing document language models 
term smoothing refers adjustment maximum likelihood estimator language model accurate 
required assign zero probability unseen words 
estimating language model limited amount text single document smoothing maximum likelihood model extremely important 
language modeling techniques centered issue smoothing 
language modeling approach retrieval smoothing accuracy directly related retrieval performance 
existing research assumed method smoothing smoothing effect tends mixed heuristic techniques 
direct evaluation different smoothing methods unclear retrieval performance affected choice smoothing method parameters 
research questions sensitive retrieval performance smoothing document language model 
smoothing method selected parameters chosen 
compare popular smoothing methods developed speech language processing study behavior method 
study leads interesting unanticipated 
find retrieval performance highly sensitive setting smoothing parameters 
sense smoothing important new family retrieval models term weighting traditional models 
interestingly sensitivity pattern query verbosity highly correlated 
performance sensitive smoothing verbose queries keyword queries 
verbose queries generally require aggressive smoothing achieve optimal performance 
suggests smoothing plays differ ent roles query likelihood ranking method 
role improve accuracy estimated document language model accommodate generation common non informative words query explain possible noise query 
rest chapter organized follows 
section discuss language modeling approach connection smoothing heuristics traditional retrieval models 
section describe smoothing methods evaluated 
major experiments results sections 
section clarification experiment results support dual role smoothing stage smoothing method 
section presents 
language modeling approach basic idea language modeling approach information retrieval described follows 
assume query generated probabilistic model document query qn document dm inter estimating conditional probability probability generates observed applying bayes formula dropping document independent constant interested ranking documents discussed berger lafferty righthand side equation interesting interpretation prior belief relevant query query likelihood document captures document fits particular query simplest case assumed uniform affect document ranking 
assumption taken existing berger lafferty ponte croft ponte hiemstra kraaij song croft :10.1.1.54.6410
cases capture non textual information length document links web page format style features document 
study assume uniform order focus effect smoothing 
see miller empirical study exploits simple alternative priors 
uniform prior retrieval model reduces calculation language modeling comes 
language model previous uni gram model 
multinomial model assigns probability qi clearly retrieval problem essentially reduced unigram language model estimation problem 
focus unigram models see miller song croft explorations bigram trigram models 
surface language models appears fundamentally different vec tor space models tf idf weighting schemes unigram language model explicitly encodes term frequency appears inverse document frequency weighting model 
interesting connection language model approach heuristics traditional models 
connection smoothing appreciation gives insight language modeling approach 
smoothing methods distributions model ps seen words occur document model pu unseen words 
probability query written terms models follows denotes count word log log qi qi qi log ps qi log ps qi pu qi qi log pu qi log pu qi ponte croft adopts similar slightly different standard unigram model 
probability unseen word typically taken proportional general frequency word computed document collection 
assume pu qi qi document dependent constant qi collection language model 
log qi log ps qi qi log log qi length query 
note term righthand side indepen dent document ignored ranking 
see retrieval function decomposed parts 
part involves weight term common query document matched terms second part involves document dependent constant related probability mass allocated unseen words particular smoothing method 
weight matched term qi identified logarithm ps qi directly proportional document term frequency qi inversely proportional collection frequency 
computation general retrieval formula carried efficiently involves sum matched terms 
qi smoothing distribution turned play role similar known idf 
component formula just product document dependent constant query length 
think playing role document length normalization important technique improve performance traditional models 
closely related document length expect longer document needs smoothing smaller long document incurs greater penalty short term 
connection just derived shows collection language model model smoothing document language models implies retrieval formula implements tf idf weighting heuristics document length normalization 
suggests smoothing plays key role language modeling approaches retrieval 
restrictive derivation connection hiemstra kraaij 
method ps parameter jelinek mercer pml dirichlet absolute discount max table summary primary smoothing methods compared 
smoothing methods described goal estimate unigram language model document simplest method maximum likelihood estimate simply relative counts ml maximum likelihood estimator generally underestimate probability word unseen document main purpose smoothing assign non zero probability unseen words improve accuracy word probability estimation general 
smoothing methods proposed context speech recog nition tasks chen goodman 
general smoothing methods try discount probabilities words seen text assign extra probability mass unseen words fallback model 
information retrieval sense common exploit collection language model fallback model 
chen goodman assume general form smoothed model ps word seen ps smoothed probability word seen document collection language model coefficient controlling probability mass assigned unseen words probabilities sum 
general may depend ps ps individual smoothing methods essentially differ choice ps 
smoothing method may simple adding extra count word called additive laplace smoothing sophisticated katz smoothing words different counts treated differently 
retrieval task typically re quires efficient computations large collection documents study constrained efficiency smoothing method 
selected representative methods popular relatively efficient implement 
excluded known methods katz smoothing katz turing estimation efficiency constraint 
methods evaluated simple issues bring light relevant advanced methods 
methods described 
jelinek mercer method 
method involves linear interpolation maxi mum likelihood model collection model coefficient control ence model 
pml simple mixture model preserve name general jelinek mercer method involves deleted interpolation estimation linearly interpolated gram models 
bayesian smoothing dirichlet priors 
language model multinomial distri bution conjugate prior bayesian analysis dirichlet distribution parameters model 
wn laplace method special case technique 
involve count words frequency document expensive compute 
absolute discounting 
idea absolute discounting method lower prob ability seen words subtracting constant counts ney 
similar jelinek mercer method differs discounts seen word prob ability subtracting constant multiplying 
model max discount constant probabilities sum 
number unique terms document total count words document 
methods summarized table terms ps general form 
easy see larger parameter value means smoothing cases 
retrieval methods implemented efficiently smoothing parameter advance 
pre computed documents index time 
weight matched term computed easily collection language model query term frequency document term frequency smoothing parameters 
scoring complexity query query length average number documents query term occurs 
efficient scoring tf idf model 
experimental setup goal study behavior individual smoothing methods compare different methods 
known performance retrieval algorithm may vary significantly testing collection 
generally desirable larger collections queries 
databases trec including largest testing collections ad hoc retrieval official trec ad hoc trec ad hoc trec web track testing collections financial times disk fbis disk los angeles times disk disk disk minus cr trec trec ad hoc tasks trec web data 
characteristics databases summarized table 
queries topics trec ad hoc task topics trec ad hoc web tasks 
order study possible collection size term doc fbis mb ft mb la mb trec gb web gb query set min term avg term max term trec title trec long trec title trec long table statistics text collections study top queries testing bottom 
smoothing query length type different versions set queries title long version title description narrative 
lengths different kinds queries summarized table 
title queries key words long queries sentences verbose 
experiments tokenization applied stemming porter stemmer 
indexed words language want biased artificial choice words believe effects word removal better achieved exploiting language modeling techniques 
table give labels possible retrieval testing collections databases queries described 
smoothing method testing collection experiment wide range parameter values 
run smoothing parameter set value queries documents 
chapter follow standard trec evaluation procedure ad hoc retrieval topic performance figures computed top documents retrieval results voorhees har document queries collection trec trec title long title long fbis fbis fbis fbis fbis ft ft ft ft ft la la la la la trec trec trec trec trec web web web table labels test collections 
man 
study behavior individual smoothing method select set representative parameter values examine sensitivity non interpolated average precision recall variation values 
compare smoothing methods optimize performance method non interpolated average preci sion optimization criterion compare best runs method 
optimal parameter determined searching entire parameter space 
behavior individual methods section study behavior smoothing method 
derive ex pected influence smoothing parameter term weighting document length normalization implied corresponding retrieval function 
examine tivity retrieval performance plotting non interpolated precision recall documents different values smoothing parameter 
jelinek mercer smoothing 
jelinek mercer smoothing method fixed see parameter ranking function see section documents length normalization term constant 
means score interpreted sum weights matched term 
term weight log pml qi qi 
small means smoothing emphasis relative term weighting 
approaches zero weight term dominated term log term independent scoring formula dominated coordination level matching simply count matched search performed iterative way iteration focused previous 
searching improvement average precision 
precision precision precision jelinek mercer small collections fbis fbis ft ft la la fbis fbis ft ft la la lambda precision jelinek mercer large collections trec trec web trec trec web lambda recall recall recall jelinek mercer small collections lambda recall jelinek mercer large collections lambda performance jelinek mercer smoothing 
terms 
means documents match query terms ranked higher match fewer terms implying conjunctive interpretation query terms 
hand approaches weight term approximately pml qi qi log small 
scoring essentially pml qi qi 
means score dominated term highest weight implying disjunctive interpretation query terms 
plots show average precision recall different settings large small collections 
evident precision recall sensitive long queries title queries 
web collection exception performance sensitive smoothing title queries 
title queries retrieval performance tends optimized small fbis fbis ft ft la la fbis fbis ft ft la la trec trec web trec trec web lambda optimal lambda range jelinek mercer trec query lambda optimal lambda range jelinek mercer trec optimal range trec left trec right jelinek mercer smoothing 
line shows optimal value bars optimal ranges 
long queries optimal point generally higher usually 
difference optimal value suggests long queries need smoothing emphasis placed relative weighting terms 
left curve close zero close performance achieved treating query conjunctive boolean query right close performance achieved treating query disjunctive query 
shape curves suggests appropriate interpret title query conjunctive boolean query long query close disjunctive query sense intuitively 
performance sensitivity seen clearly topic plot optimal range shown 
optimal range defined maximum range values deviate optimal average precision 
dirichlet priors 
dirichlet prior smoothing see retrieval formula document dependent 
smaller long documents interpreted length normalization component penalizes long documents 
weight matched term log qi qi 
note jelinek mercer method term weight document length normalization implicit ps qi term weight affected raw counts term length document 
rewriting weight log pml qi qi see playing role differs document dependent 
relative weighting terms emphasized smaller 
just jelinek mercer shown approaches zero scoring formula dominated query count matched terms 
gets large complicated jelinek mercer due length normalization term obvious terms dominate scoring formula 
precision precision precision dirichlet prior small collections fbis fbis ft ft la la fbis fbis ft ft la la prior precision dirichlet prior large collections trec trec web trec trec web prior recall recall recall dirichlet prior small collections prior recall dirichlet prior large collections prior performance dirichlet smoothing 
plots show average precision recall different settings prior sample size 
clear precision recall sensitive long queries title queries especially small 
optimal value different title queries long queries 
tends slightly larger long queries difference large jelinek mercer 
optimal prior vary collection collection cases 
tail curves generally flat 
absolute discounting 
term weighting behavior absolute discounting method little complicated 
obviously document sensitive 
larger fbis fbis ft ft la la fbis fbis ft ft la la trec trec web trec trec web document flatter distribution words count unique terms relatively large 
penalizes documents word distribution highly small number words 
weight matched term log qi qi 
influence relative term weighting depends way 
larger term weights flat ter term weight skewed count term document 
larger amplify weight difference rare words flatten difference common words rarity threshold precision precision precision absolute discounting small collections fbis fbis ft ft la la fbis fbis ft ft la la delta precision absolute discounting large collections trec trec web trec trec web delta recall recall recall absolute discounting small collections delta recall absolute discounting large collections fbis fbis ft ft la la fbis fbis ft ft la la trec trec web trec trec web delta performance absolute discounting 
plots show average precision recall different settings discount constant 
clear precision recall sensitive long queries title queries 
similar bayesian smoothing different jelinek mercer smoothing optimal value different title queries long queries 
optimal value tends 
true title queries long queries testing collections 
behavior smoothing method indicates general performance long verbose queries sensitive choice smoothing parameters concise title queries 
inadequate smoothing hurts performance severely case long verbose queries 
suggests smoothing plays important role long verbose queries concise title queries 
interesting observation web collection behaves quite differently databases jelinek mercer dirichlet smoothing absolute discounting 
particular title queries performed better long queries web collection dirichlet prior 
analysis evaluation needed understand observation 
interpolation vs backoff methods described tested far belong category interpolation methods discount counts seen words extra counts shared seen words unseen words 
problem approach high count word may actual count document fallback model gives word high probability 
alternative smoothing strategy backoff main idea trust maximum likelihood estimate high count words discount redistribute mass com mon terms 
result differs interpolation strategy extra counts primarily unseen words 
katz smoothing method known backoff method katz 
backoff strategy popular speech recognition tasks 
chen goodman implemented backoff version interpolation methods derived follows 
recall methods ps written sum parts discounted maximum likelihood estimate denote collection language model term 
term ps renormalize probabilities smoothing method follows backoff strategy 
hard show interpolation smoothing method characterized ps pu backoff version form ranking formula smoothing parame wi precision precision precision precision interpolation vs backoff jelinek mercer fbis fbis bk fbis fbis bk lambda precision interpolation vs backoff dirichlet prior fbis fbis bk fbis fbis bk prior precision interpolation vs backoff absolute discounting fbis fbis bk fbis fbis bk interpolation versus backoff jelinek mercer top dirichlet smoothing middle absolute discounting bottom 
ters remain 
easy see backoff version differs interpolation version document dependent term penalizes long doc uments 
weight matched term due backoff smoothing wider range values interpolation 
analytically backoff version tends term weighting document length normalization aggressively corresponding interpolated version 
delta backoff strategy interpolation strategy compared methods fbis database topics fbis fbis 
results shown 
find compared interpolation backoff performance sensitive smoothing parameter especially jelinek mercer dirichlet prior 
difference clearly significant absolute discounting method may due lower upper bound original restricts aggressiveness penalizing long documents 
general backoff strategy yields worse performance interpolation strategy comes close approaches zero expected analytically know approaches zero difference strategies diminish 
comparison methods compare smoothing methods select best run terms non interpolated average precision interpolation method testing collection com pare non interpolated average precision precision documents precision documents selected runs 
results shown table table titles long queries respectively 
title queries clear order methods terms precision measures dirichlet prior better absolute discounting better jelinek mercer 
dirichlet prior best average precision cases average performance significantly better methods test 
performed extremely web collection significantly better 
performance relatively insensitive choice 
non optimal dirichlet runs significantly better optimal runs jelinek mercer absolute discounting 
long queries partial order 
average jelinek mercer better dirichlet prior absolute discounting precision measures average precision identical dirichlet precision documents significantly better methods test 
jelinek mercer dirichlet prior clearly better average precision absolute discounting 
comparing method performance different types queries table see methods perform better long queries title queries collection method parameter avg 
prec 
prec prec jm fbis dir dis jm ft dir dis jm la dir dis jm fbis dir dis jm ft dir dis jm la dir dis jm trec dir dis jm trec dir dis jm web dir dis jm average dir dis table comparison smoothing methods title queries 
best performance shown bold 
cases best performance significantly better best signed rank test level marked star 
jm denotes jelinek mercer dir denotes dirichlet prior dis denotes smoothing absolute discounting 
dirichlet prior performs worse long queries title queries web collection 
improvement average precision statistically significant methods ac cording test 
performance increase significant jelinek mercer 
jelinek mercer worst title queries best long queries 
appears jelinek mercer effective queries long verbose 
trec database differs combined set ft fbis la federal register database compare performance method collection method parameter avg 
prec 
prec prec jm fbis dir dis jm ft dir dis jm la dir dis jm fbis dir dis jm ft dir dis jm la dir dis jm trec dir dis jm trec dir dis jm web dir dis jm average dir dis table comparison smoothing methods long queries 
best performance shown bold 
cases best performance significantly better best signed rank test level marked star 
jm denotes jelinek mercer dir denotes dirichlet prior dis denotes smoothing absolute discounting 
smaller databases large 
find non interpolated average precision large database generally worse smaller ones similar worst small databases 
precision documents large collections significantly better small collections 
title queries long queries relative performance method tends remain merge databases 
interestingly optimal setting smoothing parameters stay similar range databases merged 
strong correlation effect smoothing type queries smoothing query avg 
pr pr doc pr doc title jelinek mercer long improve title dirichlet long improve title absolute disc 
long improve table comparing long queries short queries 
star indicates improvement statistically significant signed rank test level 
unexpected 
purpose smoothing improve accuracy estimating unigram language model document effect smoothing affected characteristics documents collection rela tively insensitive type queries 
results suggest case 
effect smoothing clearly interacts query factors 
understand length verbosity long queries responsible interactions design experiments examine query factors length verbosity 
details reported section 
dual role smoothing section report results experiments different types queries short keyword long keyword short verbose long verbose 
compare behave respect smoothing clarify query factor caused strong interaction smoothing 
show high sensitivity retrieval perfor mance smoothing caused presence common words query independent query length 
suggests smoothing plays different roles estimated document language model accurate explain non informative words query 
accordingly propose stage smoothing strategy decouples roles smoothing facilitates setting smoothing parameters 
types queries experiments generated trec topics 
topics special concept field contains list keywords related topic 
keywords serve long keyword version queries 
shows example topic topic 
title south african sanctions description document discusses sanctions south africa 
narrative relevant document discuss aspect south african sanctions sanctions declared proposed country south african government response policy response pressure individual organization country international sanctions imposed united nations effects sanctions africa opposition sanctions compliance sanctions 
document identify sanctions considered corporate trade ban academic arms 
concepts 
sanctions international sanctions economic sanctions 
corporate exodus corporate stock ban new investment trade ban import ban south african diamonds arms defense contracts cutoff goods academic reduction cultural ties 
white domination 
black majority rule 
example topic number 
keywords long keyword version queries 
precision sensitivity precision jelinek mercer ap short keyword long keyword short verbose long verbose lambda precision sensitivity precision dirichlet ap short keyword long keyword short verbose long verbose prior mu sensitivity average precision jelinek mercer smoothing left dirichlet prior smoothing right ap 
way topics generated versions queries 
short keyword title topic description usually noun phrase occasionally function words manually excluded order queries purely keyword 
precision sensitivity precision jelinek mercer wsj short keyword long keyword short verbose long verbose lambda precision sensitivity precision dirichlet wsj short keyword long keyword short verbose long verbose prior mu sensitivity average precision jelinek mercer smoothing left dirichlet prior smoothing right wsj 
precision sensitivity precision jelinek mercer zf short keyword long keyword short verbose long verbose lambda precision sensitivity precision dirichlet zf short keyword long keyword short verbose long verbose prior mu sensitivity average precision jelinek mercer smoothing left dirichlet prior smoothing right zf 

short verbose description field usually sentence 

long keyword concept field keywords average 

long verbose title description narrative field words average 
verbose queries consist natural language sentences keyword queries consist content carrying noun phrases 
relevance judgments available topics documents trec disk disk 
order observe possible difference smoothing caused types documents partition documents disks largest subsets documents accounting majority relevant documents queries 
databases ap wsj ziff mb mb size 
queries relevance judgments particular database ignored experiments database 
queries judgments ap queries judgments ziff 
preprocessing documents minimized porter stemmer words removed 
combining types queries databases gives total different testing collections 
better understand interaction different query factors smoothing studied sensitivity retrieval performance smoothing different types queries 
jelinek mercer dirichlet smoothing testing collections vary value smoothing parameter record retrieval performance parameter value 
results plotted figures 
case plotted average precision varies different values smoothing parameter 
figures easily see types keyword queries behave similarly types verbose queries 
retrieval performance generally sensitive smoothing case keyword queries verbose queries long short 
sensitivity correlated verbosity query length query 
short verbose queries clearly sensitive long keyword queries jelinek mercer smoothing 
general insufficient smoothing harmful verbose queries keyword queries 
suggests smoothing responsible explaining common words query 
see consistent order performance types queries 
expected long keyword queries best short verbose queries worst 
long verbose queries worse long keyword queries better short keyword queries better short verbose queries 
appears suggest queries presumably keywords tend perform better verbose queries 
longer queries generally better short queries 
interaction patterns query verbosity smoothing observed experiments suggest smoothing plays different roles query likelihood retrieval method 
role improve accuracy estimated documents language model referred estimation role 
explain common non informative words query referred role query modeling 
second role explicitly implemented state hmm miller 
role supported connection smoothing idf weighting derived section 
intuitively smoothing decrease discrimination power common words query documents rely collection language model generate common words 
need query modeling may explain backoff smoothing methods worked corresponding interpolation methods allow query modeling 
particular query observed effect smoothing combination roles smoothing 
concise keyword query effect ex pected dominated estimation role query non informative common words 
hand verbose query role query modeling influence query generally high ratio non informative common words 
results reported section show dirichlet prior method performs best concise title queries suggesting estimation role jelinek mercer performs worst title queries best long verbose queries suggesting jelinek mercer role query modeling 
intuitively sense dirichlet prior adapts length documents naturally desirable estimation role jelinek mercer set fixed smoothing parameter documents necessary query modeling 
observations dual role smoothing empirically suggest stage smooth ing method decouples different roles 
stage document language model smoothed dirichlet prior implement estimation role 
sec ond stage smoothed jelinek mercer implement query modeling role 
jelinek mercer smoothing regarded simple mixture model sec ond stage essentially introduce generative mixture model queries involves mixing document language model query background language model generate common words query 
chapter formally derive stage smoothing method risk minimization framework study detail 
studied problem language model smoothing context query likelihood retrieval method 
rewriting query likelihood retrieval formula smoothed document language model derived general retrieval formula smoothing document language model interpreted terms heuristics traditional models including tf idf weighting document length tion 
examined popular interpolation smoothing methods jelinek mercer method dirichlet priors absolute discounting backoff ver sions evaluated large small trec retrieval testing collections 
retrieval performance generally sensitive smoothing parame ters suggesting understanding appropriate setting smoothing parameters important language modeling approach 
results completely conclusive smoothing method best interesting observations help understand methods better 
test collections jelinek mercer method generally performs tends perform better long queries title queries 
optimal value strong correlation query type 
concise title queries optimal value generally small long verbose queries optimal value larger 
dirichlet prior method generally performs tends perform better concise title queries long verbose queries 
optimal value appears wide range usually 
large value safer especially long verbose queries 
absolute discounting method performs concise title queries long verbose queries 
interestingly little variation optimal value generally cases 
successfully speech recognition backoff strategy retrieval evaluation 
interpolated versions perform significantly better backoff versions 
interesting observation effect smoothing strongly correlated type queries 
performance generally sensitive smoothing verbose queries keyword queries 
verbose queries generally require aggressive smoothing achieve optimal performance 
suggests smoothing plays different roles query likelihood retrieval method 
role improve accuracy estimated document language model estimation role accommodate generation non informative common words query query modeling role 
results suggest dirichlet prior may estimation role jelinek mercer may query modeling role 
motivates propose stage smoothing strategy combines dirichlet prior jelinek mercer explicitly decouples roles smoothing dirichlet prior estimation role jelinek mercer second 
stage smoothing method studied detail chapter 
interesting research directions 
evaluate sophisticated smoothing algorithms turing smoothing katz smoothing katz kneser ney smoothing kneser ney 
success dirichlet prior smoothing method interesting explore smoothing hierarchical bayesian model explored mackay peto 
second important study set smoothing parameters automat ically 
reported experiments exhaustively search space parameter values order study sensitivity 
practice impossible need guidance set 
general interesting explore possibility training estimating parameters query collection past relevance judgments available 
chapter method estimating parameters stage smoothing method step important direction 
chapter stage language models query likelihood retrieval method discussed previous chapter original language modeling approach proposed ponte croft 
involves step scoring procedure 
estimate document language model document second compute query likelihood estimated document language model directly 
chapter derive family stage language models risk minimization framework 
models generalize step procedure introducing query generative model zhai lafferty 
result second step estimated document model directly query generative model estimated document model compute query likelihood 
viewpoint smoothing regard stage language model ing approach involving stage smoothing original document model 
stage smoothing happens estimate document language model second stage implemented query generative model 
stage smooth ing method suggested previous chapter easily obtained special case stage language models bayesian approach estimate document language model mixture model query generation 
important advantage stage language models explicitly capture different influences query document collection smoothing 
known optimal setting retrieval parameters generally depends document col lection query decoupling influence query documents easier estimate smoothing parameters independently different documents different queries 
methods estimating parameters involved stage smoothing method automatically 
extensive evaluation shows stage smoothing method automatically estimated parameter settings achieve excellent retrieval performance close better ideal retrieval perfor mance single stage smoothing methods 
known optimal settings retrieval parameters generally depend document collection query 
example specialized term weighting short queries studied kwok chan 
salton buckley studied differ ent term weighting methods vector space retrieval model recommended methods strongly depend type query characteristics document collection salton buckley 
great challenge find optimal settings retrieval parameters automatically adaptively accordingly character collection queries empirical parameter tuning inevitable order achieve retrieval performance 
evident large number parameter tuning experiments reported virtually published trec pro ceedings voorhees harman 
need empirical parameter tuning due part fact traditional retrieval models vector space model salton bm re trieval model robertson retrieval parameters introduced heuristically 
lack direct modeling queries documents hard models incorporate principled way parameters adequately address special characteristics queries documents 
example vector space model assumes query document represented term vector 
mapping query document vector arbitrary 
model sees document vector representation principled way model length document 
result heuristic parameters see pivot length normalization method singhal 
similarly bm retrieval formula direct modeling queries making necessary introduce heuristic parameters incorporate query term frequencies robertson 
order able set parameters automatically necessary model queries documents directly risk minimization retrieval framework significant advantage traditional models capability modeling queries documents directly statistical language models 
query document similar sense text important differences 
example queries shorter contain just keywords 
viewpoint language modeling query document require different language models 
practically separating query model document model important advantage allowing different retrieval parameters queries documents appropriate 
general statistical language models allows introduce parameters probabilistic models possible set parameters automatically statistical estimation methods 
chapter explore stage language models special case risk minimization framework show achieve excellent retrieval performance completely automatic parameter setting 
rest chapter derive family stage language models retrieval risk minimization framework show specific stage smoothing method suggested previous chapter easily obtained special case 
methods estimating parameters involved 
specifically propose leave method estimating stage dirichlet parameter mixture model estimating second stage interpolation parameter 
experimental results different databases types queries show stage smoothing method proposed parameter estimation method consistently gives retrieval performance close better best results single smoothing method achievable exhaustive parameter search 
proposed stage smoothing method represents step goal setting database specific query specific retrieval parameters automatically need tedious experimentation 
effectiveness robustness approach fact ad hoc parameter tuning involved useful solid baseline approach evaluation retrieval models 
derivation section derive general stage language model retrieval formula risk minimization retrieval framework chapter 
start risk ranking function independent loss function consider special loss function indexed small constant model distance function constant positive cost 
loss zero query model document model close 
loss function obtain risk sphere radius centered parameter space 
assuming concentrated estimated value ap proximate value integral integrand value note constant ignored purpose ranking 
mean effect ranking rank belong parameter space small value integral approximated value function times constant volume constant ignored purpose ranking 
rank risk ranking documents posterior probability user estimated document model query model 
applying bayes formula rewrite equation basic stage language model retrieval formula 
similar model discussed berger lafferty formula tion captures estimated document model explains query encodes prior belief user query model 
prior exploited model different document sources document characteristics chapter assume uniform prior 
generic stage language model refined specifying concrete model generating documents concrete model generating queries different specifications lead different retrieval formulas 
query gener ation model simplest unigram language model scoring procedure original language modeling approach proposed ponte croft estimate document language model compute query likelihood estimated model 
section generative models lead stage smoothing method suggested previous chapter 
stage smoothing method dn denote document qm denote query denote words vocabulary 
consider case param eters unigram language models multinomial distributions words simplest generative model document just unigram language model multinomial 
document generated sampling words independently di document assumed generated potentially different model assumed general risk minimization framework 
particular document want estimate dirichlet prior parameters 
dir parameters chosen wi parameter collection language model estimated set documents source posterior distribution dirichlet parameters wi wi 
fact dirichlet mean length dirichlet prior smoothing method described zhai lafferty 
consider query generation model 
simplest model unigram language model result retrieval model dirichlet prior sin gle smoothing method 
observed zhai lafferty model able explain interactions smoothing type queries 
order capture common non discriminative words query assume query composed types words topic words general english words possible overlaps 
query assumed generated sampling words component mixture multinomials component query background language model 
qi qi parameter roughly indicating amount noise combining estimate query model retrieval scoring formula document query qi qi qi qi qi formula document language model effectively smoothed steps 
smoothed dirichlet prior second interpolated query background model 
precisely stage smoothing method suggested previous chapter goal decouple dual role smoothing 
query background model general different collection lan guage model estimated query logs current user similar users 
insufficient data estimate assume reasonable approximation 
form stage smooth ing method essentially combination dirichlet prior smoothing jelinek mercer smoothing zhai lafferty 
easy verify just dirichlet prior smoothing jelinek mercer smoothing 
combined smoothing formula follows gen eral smoothing scheme discussed zhai lafferty implemented efficiently 
section empirically explore parameter space stage smooth ing method examine method effective decoupling estimation role query modeling role smoothing 
empirical exploration stage smoothing experiments reported previous chapter observed strong interactions tween type queries sensitivity performance smoothing 
idea stage smoothing method factor influence query smoothing second stage interpolation smoothing 
see expect achieve goal empirically explore parameter space stage smoothing method examine sensitivity retrieval performance smoothing parameters 
see stage smoothing method help reveal consistent sensitivity patterns decoupling roles 
experimental setup previous chapter section largest collections 
shows stage smoothing reveals regular sensitivity pattern single stage smoothing methods studied earlier 
figures show precision varies change prior value dirichlet smoothing different testing collections respectively trec ad hoc task trec ad hoc task precision precision precision sensitivity dirichlet prior smoothing disk cr topics title long long stage lambda prior sensitivity dirichlet prior smoothing disk cr topics title long long stage lambda prior sensitivity dirichlet prior smoothing trec web topics title long long stage lambda prior stage smoothing reveals consistent sensitivity pattern dirichlet prior title queries long queries 
different collection trec top trec middle web testing collection bottom 
trec web task 
lines correspond dirichlet smoothing title queries dirichlet smoothing long queries stage smoothing exactly trec trec trec trec web web described section labeled differently order clarify effect stage smoothing 
dirichlet jelinek mercer long queries 
single smoothing method dirichlet prior third uses stage smoothing near optimal 
see 
dirichlet smoothing sensitivity pattern long queries different title queries optimal setting prior clearly different title queries long queries 

stage smoothing help jelinek mercer smoothing second role sensitivity pattern dirichlet smoothing similar title queries long queries sensitive type length queries 
factoring second role smoothing see consistent stable behavior dirichlet smoothing filling role 
comparing trec top trec middle involve different topic sets document collection see optimal value prior parameter figures generally despite difference queries 

topic set value stabilize sensitivity pattern dirichlet smoothing different collections 
trec middle web bot tom involve topic set different collections 
comparing note value cause dirichlet prior behave similarly title queries long queries collections 

optimal value prior parameter dirichlet prior method generally sensitive collection 
seen comparing trec middle web bottom noticing position optimal prior different 
noted figures help jelinek mercer method stage smoothing dirichlet smoothing achieve higher precision long queries attainable single stage smoothing 
course may jelinek mercer just better method long queries stage results better best result jelinek mercer see table 
near optimal value jelinek mercer method applied 
worth mentioning web data bottom title queries form better long queries dirichlet prior smoothing 
stage smoothing long queries perform similarly title queries slightly worse 
contrast clear improvement long queries title queries trec collection middle 
topic set exactly figures explained difference collections 
possibility ex tra words introduced long queries useful retrieval web database trec database 
example may extra words ambiguous web database right sense trec database 
analysis needed fully understand 
collection best jelinek mercer best dirichlet near optimal stage trec trec web trec trec web table comparison average precision near optimal stage smoothing best smoothing 
setting long queries title queries setting trec trec database web database stage smoothing performs best single stage smoothing method better 
surface parameters worry 
results show parameters interpreted meaningful way 
intended query related parameter smaller query verbose long 
roughly interpreted modeling expected noise query 
document related parameter controls amount probability mass assigned unseen words 
optimal value expected relatively stable fixed document collection optimal setting jelinek mercer expected correlated query 
possible optimize document collection depending queries similarly optimize primarily queries 
section methods estimating data 
parameter estimation stage smoothing estimating purpose dirichlet prior smoothing stage address estimation bias due fact document extremely small amount data estimate unigram language model 
specifically discount maximum likelihood estimate appropriately assign non zero probabilities words observed document usual role language model smoothing 
useful objective function estimating smoothing parameters leave likelihood sum log likelihoods word observed data computed terms model constructed data target word excluded left 
criterion essentially cross validation derive known smoothing methods including turing method ney 
formally dn collection documents 
dirichlet smoothing formula leave log likelihood written estimate di di log di arg max easily computed newton method 
update formula second derivatives di di di di di di di di di di collection avg 
doc length max 
doc length vocab 
size ap wsj zf table estimated values database characteristics 
long solution global maximum 
experiments starting value algorithm converges 
iteration goes terms documents complexity iteration nl total number documents collection average number distinct terms document 
big concern estimation done indexing time independent queries 
estimated values databases shown table 
clear correlation database characteristics shown table estimated value 
estimating query model hidden query likelihood qi qi order estimate approximate query model space set estimated document language models collection 
approximate integral sum possible document language models estimated collection qj di qj di di smoothed unigram language model estimated document di dirichlet prior approach 
assume query generated mixture document models unknown mixing weights setup parameters estimated em algorithm 
update formulas qj di qj qj qj qj qj di qj note leaving free important really want maximize likelihood generating query document collection 
want find maximize likelihood query relevant documents 
free estimate allocate higher weights documents predict query likelihood function presumably documents relevant 
unfortunately intend find exact maximum hood estimate assigning entire probability mass single document 
exists smoothed doc ument model gives highest likelihood query setting document gives higher likelihood 
clearly de empirically leads non optimal performance 
solve problem initialize uniform distribution allow early em algorithm iterations experiments 
strategy allows obtain relatively smooth estimate works empirically 
number em iterations carry parameter needs set performance sensitive exact number iterations long large smaller safer smaller number iterations sense performance different optimal performance 
em iteration involves computation query likelihood document complexity scoring documents 
inverted index complexity iteration total number inverted index entries query terms total number documents collec tion 
estimate different query computational complexity concern practice 
possible way improve efficiency small number documents highest estimated value mainly determined documents 
develop efficient methods estimating topic research 
effectiveness parameter estimation methods evaluate parameter estimation methods stage smoothing method tested testing collections studying query factors see section 
collections represent diversity types queries documents 
homogeneous databases relatively small 
order test robustness stage smoothing method tested bigger heterogeneous trec collections 
official ad hoc retrieval collections trec trec trec small web track experiments described section 
topics concept field types queries short keyword short verbose long verbose 
perform minimum pre processing porter stemmer words removed 
testing collection compare retrieval performance estimated stage smoothing parameters best results achievable single smoothing method 
best results single smoothing method obtained exhaustive search parameter space ideal performance smoothing method 
experiments collection language model approximate query background model 
results shown table table small collections large col respectively 
types queries abbreviated initial letters sk short keyword 
standard trec evaluation procedure ad hoc re trieval followed considered performance measures non interpolated average precision initial precision precision recall precision documents 
results see performance stage smoothing estimated parameter values consistently close better best performance single method measures 
cases difference statistically significant indicated asterisk 
quantify sensitivity retrieval performance smoothing parameter label collections differently labeling consistent table 
collection query method avg 
prec 
median init 
prec 
prec prec best jm sk best dir stage best jm lk best dir ap stage best jm sv best dir stage best jm lv best dir stage best jm sk best dir stage best jm lk best dir wsj stage best jm sv best dir stage best jm lv best dir stage best jm sk best dir stage best jm lk best dir zf stage best jm sv best dir stage best jm lv best dir stage table comparison estimated stage smoothing best single stage smoothing methods small collections 
best number measure shown boldface 
asterisk indicates difference stage smoothing performance best stage smoothing performance statistically significant signed rank test level 
single smoothing methods show parentheses median average precision parameter values tried 
see jelinek mercer sensitivity clearly higher verbose queries keyword queries median usually jelinek mercer tried values dirichlet prior tried values 
collection query method avg 
prec 
median init 
prec 
prec prec best jm trec sk best dir stage best jm trec sv best dir stage best jm trec lv best dir disk cr stage best jm trec sk best dir stage best jm trec sv best dir stage best jm trec lv best dir stage best jm trec sk best dir stage best jm web trec sv best dir stage best jm trec lv best dir stage table comparison estimated stage smoothing best single stage smoothing methods large collections 
best number measure shown boldface 
asterisk indicates difference stage smoothing performance best stage smoothing performance statistically significant signed rank test level 
lower best performance verbose queries 
means harder tune jelinek mercer verbose queries keyword queries 
interestingly dirichlet prior median just slightly best queries verbose 
worst cases significantly lower 
sensitivity curves figures previous chapter see long set relatively large value dirichlet prior performance worse best performance median large value 
immediately suggests expect perform reasonably simply set safe large value 
clear results table table simple approach perform parameter estimation methods 
stage performance better median cases short keyword queries slightly worse 
dirichlet prior smoothing dominates stage smoothing effect short keyword queries due little noise suggests leave method underestimated 
note general jelinek mercer performed dirichlet prior experiments 
cases verbose queries trec sv trec lv trec database outperform dirichlet prior 
cases stage smoothing method performs better jelinek mercer 
stage smoothing performance appears track best performing single method optimal parameter setting 
performance stage smoothing reflect performance full fledged language modeling approach involve sophisticated feedback models lafferty zhai lavrenko croft zhai lafferty 
really comparable performance trec systems 
performance figures shown competitive compared performance official trec submissions performance trec ad hoc task trec web track 
results stage smoothing method encouraging especially cause approach involves ad hoc parameter tuning retrieval process 
automatically estimated specific database query completely determined database determined database query gether 
method appears quite robust experiments different types queries different databases 
chapter derive family stage language models risk tion retrieval framework stage smoothing method special case 
stage language modeling approach generalizes original query likelihood method proposed ponte croft incorporating query generative model making possible explicitly capture different influences query document collection optimal setting smoothing parameters 
important advantage stage language models explicitly capture different influences query document collection smoothing making easier estimate smoothing parameters dependently different documents different queries 
special case stage language modeling approach formally derive stage smoothing method suggested previous chapter method ically motivated observation dual role smoothing 
stage stage smoothing method document language model smoothed prior collection language model model second stage smoothed document language model interpolated query background language model 
stage smoothing method shown reveal regular sen pattern smoothing empirically 
propose leave method estimating stage dirichlet prior param eter mixture model estimating second stage interpolation parameter 
methods allow set retrieval parameters automatically adaptively different databases queries 
evaluation different databases types queries indicates stage smoothing method proposed parameter es scheme consistently gives retrieval performance close better best results attainable stage smoothing method achievable exhaustive parameter search 
effectiveness robustness stage smoothing approach fact ad hoc parameter tuning involved solid baseline approach evaluating retrieval models 
ideally tie setting parameters directly optimization perfor mance 
unfortunately difficult impossible ad hoc text retrieval due fact performance measured subjectively user 
course relevance feedback available machine learning techniques exploited set param eters optimizing performance documents known judgments 
mainly considering ad hoc retrieval scenario parameter setting problem sense inherently empirical 
sense maximum likelihood parameter estimation may necessarily guarantee optimize retrieval performance certain guarantees optimality estimated language model 
meth ods significant advantage traditional parameter tuning methods possible see improve language models estimation methods analysis non optimality happens traditional param eter tuning rarely guidance improve model 
case consistent near optimal performance demonstrated parameter estimation meth ods extensive evaluation suggests methods automatic parameter setting robust effective 
interesting research directions 
shown automatic stage smoothing gives retrieval performance close best results attainable stage smoothing method analyzed optimality estimated parameter values stage parameter space 
example important see relative optimality estimated fixing 
second interesting explore estimation methods 
example regarded hyperparameter hierarchical bayesian approach 
estimation query model parameter interesting explore efficient methods mixture model 
interesting try different query background models 
possibility estimate background model resources past queries addition collection documents 
possible exploit query background model address issue redundancy retrieval results 
specifically biased query background model may represent explain sub topics user encountered reading previously retrieved results order focus ranking new sub topics relevant set documents 
direction explored chapter 
chapter kl divergence retrieval models chapter study special case risk minimization retrieval framework generalizes existing language modeling approach allows deal feedback natural way 
derive family unigram retrieval models kl divergence loss function risk minimization framework 
effect models score documents computing kl divergence query model document model 
kl divergence retrieval approach extends query likelihood approach incorporating query language model 
lack query model previous language modeling approach unnatural incorporate feedback 
kl divergence approach involves es query language model addition document language model making possible treat feedback naturally query model updating 
propose specific query model updating algorithms feedback documents 
evaluation indicates algorithms effective feedback 
show exploit feedback documents improve estimation query model improved query model results better retrieval performance 
derivation section derive kl divergence retrieval models formally risk min framework 
start general probabilistic similarity model derived chapter repeat special case model assume parameters unigram language models called query topic language model document topic language model respectively choose distance function kullback leibler divergence 
probability mass functions kullback leibler divergence relative entropy defined log easy show non negative zero true distance distributions symmetric satisfy triangle inequality useful think kl divergence distance distributions cover thomas 
apply kl divergence function see log log cons log ranking function essentially cross entropy query language model respect document language model 
dropped constant query model entropy different sign 
value cross entropy larger equal query model entropy 
minimum value query model entropy achieved identical sense retrieval 
kl divergence model covers popular query likelihood ranking function special case 
suppose just empirical distribution query 
qm language model qi qi indicator function 
obtain log qi precisely log likelihood criterion ponte croft introducing language modeling approach language mod eling approach date 
chapter develop new methods estimate model demonstrate new models perform significantly better empirical distribution interpretation model kl divergence retrieval model special case general probabilistic distance model 
interestingly general probabilistic distance model kl divergence model intuitive interpretation similar vector space model 
recall vector space model basic components query term vector doc ument term vector vector similarity measure cosine 
probabilistic dis tance model similar components query language model document language model model similarity measure kl divergence 
important difference representation 
vector space model document query represented heuristically weighted term vector probabilistic distance model represented unigram language model 
heuristic term weighting vector space model model empirical unigram language model representation possible exploit principles statistical parameter estimation improve representation purpose retrieval 
kl divergence model appears similar probability distribution model proposed wong yao uses information theoretic retrieval strategy 
kl divergence model general flexible explicit modeling query documents 
wong yao multi nomial term distribution primarily proposed alternative representation docu ments query vector space model sense generative model documents query 
surprising issue model estimation considered term distribution representation naturally assumed best approximated relative frequency terms 
limitation modeling seen clearly claimed difficulty kl divergence function directly similarity measure model smoothing considered possibility wong yao 
note kl divergence distance function possibilities measuring model similarity 
thesis explore distance functions focus derived unigram kl divergence model 
model suggests documents ranked kl divergence function value estimated query unigram language model estimated document unigram language model 
sections discuss estimation query model document model 
estimation document language model query language model kl divergence retrieval model retrieval problem boils problem estimating document language model query language model depending actual language models assumed possibilities 
example document model estimation different smoothing methods lead different estimated mod els 
discussed chapter 
ranking kl divergence equivalent ranking cross entropy shown query model computation kl divergence retrieval formula efficient query likelihood formula efficient traditional tf idf retrieval formula simple smoothing methods shown chapter 
course ways estimate document models 
particular mixture models reduce noise documents resulting document distillation method achieves effect tf idf weighting document terms similar query distillation approach discussed 
focus study estimation query model related issue feedback 
lack query language model existing language modeling approach created difficulties understanding extending approach 
particular hard unnatural incorporate feedback kl divergence function form symmetric 
important retrieval technique 
query language model important step powerful retrieval models language modeling 
simplest generative model query generates query directly query topic language model 
qn query query topic language model 
qi estimate observed query maximum likelihood estimator arg max qi seen section model essentially popular query likelihood model 
sections describe different ways estimating query topic language model 
show better query language model estimated ex mixture model model queries different amounts noise 
propose different methods estimating query model feedback documents 
exper results show effective pseudo feedback updated query model perform significantly better original model 
query model distillation observed length type query may affect retrieval performance significantly 
example long verbose queries tend perform better short keyword queries special heuristics proposed improve retrieval performance short queries kwok chan 
maximum likelihood estimate query language model discussed may able effectively handle queries different amounts noise dis cussed chapter 
see problem recall query likelihood ranking formula essentially sum weight query term matched document 
weight higher query term frequent query text means document matches common term query score higher matched rare term query common word important query 
hand document match common term score significantly penalized 
know long verbose query common words short query query likelihood model emphasize common word case long verbose query 
chapter addressed problem stage language model explicitly modeling query noise 
kl divergence model natural way address problem allow verbose query generated mixture model query topic model mixed general english model collection language model 
assume query generated picking topic word word general english 
formally query topic model pc collection unigram model 
mixture model pc mixture weight parameter related verbosity query 
verbose queries expect larger short queries 
intuitively inter indicating amount noise generating query 
order exploit simple mixture model retrieval estimate query compute kl divergence estimated document language model 
estimation done applying em algorithm results updating formulas pc wi wi need go query terms iteration em algorithm quite efficient 
experiment results 
show mixture model generally performs better simple model long verbose queries 
intuitively assuming generative mixture model queries expected help deal queries different amounts noise 
hypothesis mixture model estimate distilled query topic model excluded possible background noise common words query model reflects true topic better maximum likelihood estimate 
distillation affects long verbose queries short keyword ones may expect improve performance long trec queries significantly 
test hypothesis compare performance distilled query topic model maximum likelihood model estimated original query testing collections 
collection ap topics web collection evaluation smoothing methods 
see section 
long queries constructed text available original trec description topics terms average 
natural candidate background model collection unigram model 
believe background model supposed model common words query model estimated past queries better background model 
tried ap mixture past query model collec tion model performs best 
appears model built past queries quite biased extremely sparse data smoothing collection model reasonable 
smoothing may important sample query data available 
experiments ap linear interpolation smoothing coefficient collection model 
web experiments tried past query model expect help 
tried long verbose queries results reported applicable queries 
expect improvement significant short queries 
precision effect query distillation dirichlet prior dist prec orig 
prec prior recall effect query distillation dirichlet prior dist prec orig 
prec prior average precision left recall right distilled query model original query model ap 
shows distilled query improves recall precision values smoothing prior parameter dirichlet prior smoothing method ap 
distilled query model estimated setting background noise coefficient relatively setting topics 
shows similar comparison web 
see distilled query model improves recall precision consistently 
precision effect query distillation dirichlet prior web dist prec orig 
prec prior recall effect query distillation dirichlet prior web dist prec orig 
prec prior average precision left recall right distilled query model original query model web 
time optimal topics 
experiments needed understand set noise coefficient 
presumably optimal value related query length distribution properties query terms 
compares average precision recall curve distilled query models original queries ap web 
see distilled query better original query recall points effect clearly seen high recall points 
prec effect query distillation pr curves original best distill best recall prec effect query distillation web pr curves distill best original best recall precision recall curves distilled query model original query model ap left web right 
similar distillation mixture model applied documents extract focused document language model document 
common words tend higher probabilities background model probabilities focused model significantly discounted 
result high probability words focused model content words occur frequently document 
distillation achieve similar effect tf idf weighting terms 
distillation depend query done indexing time 
model feedback feedback regarded learning component tr system system learns example relevant documents improve ranking function 
different scenarios feedback relevance feedback pseudo feed back underlying technique generally similar 
difference relevance feedback pseudo feedback example documents come 
relevance feedback documents user judged relevant pseudo feedback usually top ranked documents previously retrieved result evans buckley xu croft 
feedback especially relevance feedback improves performance quite significantly 
pseudo feedback successful heuristics traditional retrieval models improve performance automatic ad hoc retrieval 
typical feedback procedure traditional model involves extracting terms example documents adding terms query expanding query terms example documents 
surprisingly procedure feedback language modeling approach 
example ratio approach proposed ponte selects terms high distribution feedback documents low distribution collec tion language model :10.1.1.54.6410
approach performs similarly rocchio method rocchio relevant documents significantly better roc relevant documents 
pseudo relevance feedback results promising significantly better results baseline language modeling approach ponte :10.1.1.54.6410
ratio approach conceptually restricted view query set terms applied general case query considered sequence terms frequency information query term considered 
number terms needs determined heuristically 
miller treat feedback essentially expanding original query terms feedback documents miller 
terms pooled bins number general discussion learning tr fuhr 
feedback documents occur bin different transition probabil ity hmm heuristically estimated 
performance feedback technique reported quite promising robust 
interpretation query text generated hmm set terms conceptually inconsistent 
heuristic adjustment transition probabilities incorporating document frequency filter high frequency words 
ng query likelihood ranking cri motivated ratio document likelihood clear underlying generative model terms ranking essentially similar simple hmm miller 
interesting ideas feedback ng 
feedback criterion optimization scores feedback documents criterion turns similar ratio approach ponte croft 
second threshold number selected terms heuristically derived score optimization criterion 
approach reported effective ng 
shares problem inconsistency interpreting query miller 
previous feedback successful empirically essentially query expansion 
expansion feedback strategy generally compatible essence language modeling approach model estimation 
result expanded query usually interpreted different way original query contrast natural way performing feedback classical relevance probabilistic model binary independence model robertson sparck jones 
propose model approach feedback incorporated kl divergence retrieval model 
model approach feedback new essence classical probabilistic model robertson sparck jones 
unclear query likelihood rank ing function existing language modeling approach 
kl divergence retrieval model general way exploit language modeling infor mation retrieval 
covers query likelihood approach special case regarded natural extension 
involves estimation query language model document language model language modeling techniques rated retrieval model flexibly 
particular query language model compared relevance model classical probabilistic retrieval model hmm 
result smoothing longer equivalent simple linear interpolation basic feedback performed re estimating query model feedback documents 
propose different criteria re estimating query model 
generative model feedback documents assume generative model feedback documents estimate query topic model parameters generative model observed feedback documents maximum likelihood method method 
consider mixture model collection language model component query topic model 

divergence risk minimization feedback documents estimate query model minimum average kl divergence feedback documents 
worth mentioning markov chain query expansion method applied set feedback documents regarded model approach feedback meant translation model lafferty zhai 
relevance model estimation method proposed lavrenko croft estimate richer query model feedback documents 
approaches rely query words focus model different approaches proposed 
estimate feedback model solely feedback documents interpolate model existing query model 
related hiemstra feedback documents re estimate smoothing parameters query likelihood retrieval function 
effect similar query term reweighting traditional retrieval model really fully taken advantage feedback documents new terms introduced enhance query 
kl divergence model supports model feedback naturally 
specifically feedback documents available basically face problem re estimating query model feedback information plus original query text 
simple general way achieve assume feedback documents extra data help smooth original query language model 
thesis explore sim smoothing method linear interpolation 
specifically estimated original query model estimated feedback query model feedback doc uments dn documents judged relevant user case relevance feedback top documents initial retrieval case pseudo relevance feedback 
new query model controls influence feedback model 
describe different strategies estimating feedback documents 
generative model feedback documents natural way estimate feedback query model assume feedback documents generated probabilistic model parameter query model 
problem estimating query model standard problem parameter estimation observed example maximum likelihood estimator arg max bayesian estimator specify meaningful prior consider maximum likelihood estimator 
simplest genera tive model unigram language model generates word independently 
di di count word document di 
simple model rea feedback documents contain relevant information 
doc uments probably contain background information non relevant topics 
reasonable model mixture model generates feedback document mixing query topic model collection language model 
document generated picking word query topic model collection language model 
knowledge collection language model reasonable approximation model generating irrelevant content feedback document 
simple mixture model log likelihood feedback documents log di log note estimated maximum likelihood estimate zero mixture model degenerated simple unigram model 
intuitively non zero interpreted amount background noise generating document 
set constant estimate done em algorithm dempster 
em algorithm leads updating formulas dj wi dj wi intuitively estimating query model trying purify document eliminating background noise estimated query model generally concentrated words common feedback document set common collection language model 

exactly traditional feedback methods rocchio method rocchio try capture 
iteration em algorithm involves iterating distinct terms feedback documents complexity number feedback documents average number distinct terms feedback document 
traditional algorithms rocchio 
generally need iterations actual complexity higher rocchio practice difference probably matter typically small 
score document estimated query model interpolate original query model obtain updated query model compute estimated smoothed document language model 
divergence minimization feedback documents different strategy estimating query model feedback documents min empirical kl divergence model feedback documents 
strat egy feedback consistent risk minimization framework kl divergence model derived 
dn set feedback documents 
define empirical kl divergence query model de di average kl divergence respect empirical word distribution document di 
intuitively estimate query model minimizing average divergence query model score documents give best average score equivalently minimum average divergence feedback documents 
estimated query model close feedback document model possible 
feedback documents share common words due language domain characteristics query model may quite general especially truncate model sake efficiency 
solution problem add regulation condition divergence function 
postulate query model preferred incurs greater divergence respect collection model approximation language model distracting background contents 
incorporating condition empirical divergence function feedback query model de di 
log log di log weighting parameter collection language model 
easily recognize term essentially entropy different sign second term reflects desire similar feedback document models dissimilar collection model 
minimizing divergence equiva lent maximizing entropy model preference constraint encoded second term 
similar maximum entropy approach parameter estima tion 
divergence minimization criterion estimate query model arg min de easily analytically lagrange multiplier approach 
solution log log subject normalization constant 
computation solution efficient involves iteration feedback documents level complexity rocchio 
di smoothed unigram language model estimated document di 
see query model estimated divergence minimization tends assign high probability words common feedback documents common accord ing collection language model 
parameter controls weight collection language model 
similar collection mixture model set zero effect collection language model completely ignored query model strictly minimizes divergence feedback documents 
exploit kl divergence retrieval model interpolate original query model obtain updated model score document 
evaluate model feedback methods performing pseudo feedback different testing collections 
preliminary evaluation results show methods effective pseudo feedback updated query model may perform significantly better simple non feedback model 
evaluation model pseudo feedback section report preliminary results proposed model feedback methods pseudo feedback testing collections 
ap topics 
collection lavrenko croft labeled ap 

trec disk cr topics 
official trec ad hoc task col lection labeled trec 

trec small web collection topics 
official trec small web task collection labeled web 
fixed document language model order focus exploring different ways estimating query models feedback documents 
specifically prior method prior estimating document language model experiments 
appropriate way evaluating feedback method con sider relevance feedback pseudo blind feedback step consider pseudo feedback 
experiments take top documents set previously retrieved results obtained basic query likelihood ranking function dirichlet smoothing method prior 
compare query mod els estimated collection mixture model method divergence minimization method vary interpolation parameter feedback model estimation parameters 
cases titles topic description closer actual queries real applications feedback expected useful short queries 
done minimum preprocessing documents queries tokenization performed stemming porter stemmer 
stopword list applied 
believe appropriate probabilistic modeling words effec tively weighted 
effect feedback order see effect feedback compare feedback results baseline non feedback results 
general find appropriate parameter settings feedback techniques proposed effective 
example best feedback results method fixed compared baseline performance table 
notice average precision recall consistently improved performing feedback 
increase average precision larger cases 
notice initial precision feedback results slightly decreased cases 
top documents may relevant surprising initial precision sensitive ranking particular document top goal improve ranking docu ments 
note despite decrease initial precision precision documents documents consistently improved 
interesting improvement ap greater trec web 
true approaches true rocchio approach discussed may suggest feedback ap easier trec web prec prec prec effect feedback ap recall baseline mixture fb div min fb effect feedback trec recall effect feedback web baseline mixture fb div min fb recall baseline mixture fb div min fb effect feedback ap top trec middle web bottom 
picture feedback methods compared baseline simple language modeling approach feedback 
homogeneity documents higher density relevant documents 
experiments analysis needed understand better 
table compare feedback results tuned rocchio approach tf idf weighting top documents feedback 
tf formula collection simple lm mixture fb improv 
dm fb improv 
ap prec prec recall trec prec prec recall web prec prec recall table comparison basic language modeling method model feedback methods 
columns give performance mixture model divergence minimization respectively 
bm retrieval formula parameter settings robertson walker 
tuned rocchio method varying main parameters rocchio coefficient number terms reported results best results obtained 
note rocchio baseline results strong compared published official trec web results voorhees harman especially considering title queries 
see model feedback methods perform better rocchio terms precision recall slightly worse rocchio 
clear improvement precision documents suggests language model feedback methods tend better job improving ranking top documents rocchio better low level recalls 
possibility tuned number terms rocchio method tuned probability cutoff methods affects amount terms introduce feedback 
experiments truncated estimated query model ignoring terms probability 
reasonable expect recall improved lower probability cutoff 
note precision expected stay increase terms selected extra terms generally small probability collection rocchio fb mixture fb improv 
dm fb improv 
ap prec prec recall trec prec prec recall web prec prec recall table comparison rocchio feedback method model feedback methods 
columns give performance mixture model divergence minimization respectively 
great impact ranking documents high scores 
interesting test hypothesis experiments 
comparison best feedback results 
important study feedback performance may affected parameters model 
look interpolation coefficient 
influence interpolation coefficient recall interpolate estimated feedback query model original maximum likelihood model estimated query text 
interpolation controlled coefficient 
essentially original model feedback completely ignore original model estimated feedback model 
actual experiments truncated estimated feedback model ignoring terms probability lower renormalized interpolation 
shows feedback average precision varies value 
line represents specific feedback model estimated mixture model precision sensitivity feedback precision alpha value alpha ap mix ap div min web mix web div min trec mix trec div min influence value precision 
lines represent different feedback models different testing collections 
divergence minimization method particular testing collection 
note precision baseline non feedback performance precision performance feedback model 
see setting affect performance significantly 
example ap feedback model better original query model optimal setting tends close 
hand trec web feedback model worse original query model interpolated original query model appropriately effective model 
means models complement 
original query model helps focus topic feedback model supplements suggesting related words 
consistent people observed traditional method rocchio setting coefficient parameters affects performance significantly salton buckley 
optimal setting 
appears usually safe set value close smaller 
precision precision precision sensitivity precision lambda ap alpha mixture div min feedback lambda mixture model div 
minimization sensitivity precision lambda trec alpha mixture div min feedback lambda mixture model div 
minimization sensitivity precision lambda web alpha mixture div min feedback lambda mixture model div 
minimization sensitivity precision feedback model parameters ap top trec middle web bottom 
picture horizontal line non feedback performance lines correspond feedback methods respectively 
note axis means different different methods 
sensitivity performance feedback model parameter look parameter feedback method 
mixture model method parameter controls amount background noise feedback docu ments divergence minimization method parameter controls influence collection language model 
cases indicates extent estimated query model deviate collection language model 
play similar role conceptually affect feedback performance different ways 
difference seen show average preci sion changes different values fixed 
specifically see performance relatively insensitive setting mixture model method quite sensitive setting divergence minimization method 
mixture model performance generally base line matter value set 
divergence minimization performance baseline small 
big performance extremely bad significantly worse baseline performance 
set parameters auto matically important topic research 
chapter explored family kl divergence retrieval models special cases risk minimization framework 
kl divergence models extend query likelihood retrieval method incorporation query language model possible treat feedback naturally query model updating 
proposed model methods performing feedback language mod eling approach information retrieval 
contrast popular expansion feedback method existing 
advantage model approach cause conceptual inconsistency interpreting query re trieval model explicitly treats feedback process learning process 
methods proposed feedback documents estimate query model update original query model linear interpolation 
methods differ estimate query model feedback documents 
method assumes feedback documents generated mixture model component query topic model collection language model 
observed feedback documents maximum likelihood method estimate query topic model 
second method uses completely different estimation criterion 
assumes estimated query model average kl divergence empirical word distribution feedback documents 
methods relatively efficient compute second efficient second method efficient traditional rocchio method 
methods evaluated representative large retrieval collections 
results show methods effective feedback perform better roc method terms non interpolated average precision 
results show better retrieval performance achieved reasonable language models better estimation methods 
particular shown feedback documents exploited improve estimation query language model 
analysis results indicates performance sensitive settings interpolation coefficient feedback method 
relatively mixture model method sensitive divergence minimization method 
appears setting value close smaller cases 
smaller probably appropriate divergence minimization mixture model method set 
mixture model approach appears robust 
patterns observed feedback documents experiments reported feedback doc uments sensitivity pattern appears basically similar reported performance gain feedback usually greater 
obviously documents performance eventually decrease 
little control true relevant examples serious drawback experimenting pseudo feedback hard tell bad feedback performance due bad feedback technique just bad luck feedback examples 
extreme case top documents non relevant bad initial rank ing 
obviously expect feedback technique gain case 
important direction test proposed feedback techniques relevance feedback able examine effectiveness learning closely 
interesting research direction consider confidence assuming top documents relevant 
intuitively associate rele vance probability feedback document estimated query model affected documents relatively high relevance probability 
rele vance probability may come initial retrieval scores may estimated help original query text 
interesting derive feedback language models directly risk minimization framework 
possibility assume relevance variable introduced relevance loss functions observed feedback documents augment observed variables include observed relevance values 
chapter independent topical relevance chapter preliminary research results modeling aspect re trieval problem risk minimization framework demonstrates risk minimization framework go traditional notion independent topical rele vance 
study different types dependent loss functions 
reducing redundancy equivalently emphasizing novelty new documents direct way increasing aspect coverage 
direct modeling aspects language models 
experimental results types loss functions 
topical relevance important factors text retrieval real appli cations user cares factors 
example users generally avoid seeing documents seeing similar viewing retrieval results 
removing redundancy documents desirable 
example documents satisfy user information need judged individually sufficiently relevant 
interesting discussion need non traditional ranking perspective optimal search behavior varian 
address factors redundancy necessary break independent relevance assumption see chapter 
traditional retrieval models inde pendent relevance assumption inadequate address factors redundancy 
models relevance treated relationship single document query 
risk minimization framework allows encode user factors consider loss functions defined set documents general model factors may depend document 
explore different types loss functions risk minimization framework resulting different types dependent retrieval models 
type maximal marginal relevance mmr models carbonell goldstein model topical relevance redundancy documents 
essentially want retrieve rel documents time minimize chance user see redundant documents user goes ranked list documents 
second type model maximal diverse relevance mdr model model topical relevance diversity documents 
assume user goal retrieve documents cover different relevant sub topics aspects possible 
note types models related 
reduce redundancy documents expect coverage aspect minimized coverage potentially different aspects may indirectly maximized 
similarly maximize aspect coverage implicitly penalizing coverage single aspect help reduce redundancy documents 
easily imagine cases goal mmr models goal mdr models consistent 
discuss 
types loss functions explore different language models capturing rel novelty redundancy aspects 
general relevance usually captured kl divergence query model document model 
novelty redundancy captured kl divergences documents mixture models 
aspects modeled generative aspect models 
evaluation non traditional models poses challenge 
existing re trieval testing collections designed evaluate traditional retrieval tasks relevance judgments independently document 
second redundancy diversity documents extremely vague properties hard quantify tend interact relevance sense emphasizing diversity may cause decrease relevance 
optimal trade user factor highly tive hard quantify 
research exploit trec interactive track data set evaluation context types models 
interactive track run trec studies aspect retrieval problem retrieve different relevant aspects relatively general topic 
interactive track focuses studying interactive retrieval problem generated test collection including aspect judgments test automatic ranking methods 
rest chapter introduce aspect retrieval task type models experimental results trec interactive aspect retrieval data 
aspect retrieval task description regular retrieval task framed retrieving relevant documents sumption document information unit consideration 
topic usually sub topic structure involves different aspects 
example user looking documents tropical storms may interested identifying different types instances tropical storms 
real applications users looking particular aspects relevant aspects possible 
trec interac tive track designed study aspect retrieval task interactive retrieval system 
example query trec number human assessors different applications robotics mentioned relevant docu ments query 
number title robotics description applications robotics world today 
instances time please find different applications sort described 
please save document different application 
document discusses applications need save documents repeat goal identify different applications sort described possible 
sample relevant aspects clean room applications healthcare precision engineering spot welding robotics controlling inventory storage devices pipe laying robots talking robot robots loading unloading memory tapes test materials different chemical compositions robot telephone operators robot 
goal address problem automatic approaches 
clearly require non traditional ranking documents ranking solely relevance optimal 
types models propose expected perform better standard relevance ranking 
mmr models may indirectly increase aspect coverage redundancy minimized mdr models directly aiming improving aspect coverage 
relevance aspect judgments available trec interactive tracks aspect retrieval task provides interesting realistic setting evaluate non traditional ranking documents 
data set years trec trec trec interactive track document collection financial times london collection part trec adhoc collection 
collection mb documents 
average document length words voorhees harman 
year interactive track task introduces new topics 
collected topics years 
topics formed modifying original ad hoc trec topics 
modification generally minimum just involving removing narrative section adding instance section explain aspect means topic 
trec nist assessors read pool documents submitted trec par identify list instances aspects determine documents contain cover instances 
example sample topic shown identified different aspects 
judgment document represented bit vector bits indicating document covers corresponding aspect 
clearly length vectors varies different topics ranging aspects average aspects data set 
number judged rel documents available differs different topics range average documents topic 
judgments non relevant documents 
information assume document total number judgments including relevant non relevant documents range non relevant covering relevant aspect 
strong assumption true submitted human saved results judged time user spend working topics limited 
documents list certainly relevant treated non relevant evaluation 
know documents hope biased evaluation informative comparing different rankings 
evaluation traditional relevance precision recall measures applied aspect retrieval task sufficient user inter seeing relevant documents possible seeing relevant aspects instances possible 
need additional informative measures evaluate effectiveness covering different aspects avoiding redundant aspects 
intuitively user factors involved aspect retrieval task 
topical relevance 
document topically relevant query topic 
second coverage new aspects 
document cover different new aspects aspects documents ranked covered 
third redundancy 
document redundant respect documents ranked presumably user seen getting document 
ideally measure cover factors 
unclear optimal trade factors defined 
interesting measures may consider 
look aspect coverage different ranks 
count number different aspects ranks 
intuitively tell cover different aspects user goes ranked list documents 
ranking measure allow user see aspects early possible 
plot curve show aspect coverage changes consider different ranks 
hard come single summary measure 
serious problem measure sense average different topics may different number relevant aspects 
modified similar measure examine aspect coverage different recall documents average documents 
levels 
look coverage different recall point 
plot coverage recall curve just regular precision recall curve 
similar relevance average precision aspect average coverage computed averaging coverage point new aspect retrieved covered 
intuitively measures fast bring new aspects user 
call measure aspect coverage ac 
aspect coverage measure combined measure relevance aspects ranking rank relevant documents non relevant documents time ranking relevant documents cover aspects early possible 
underlying optimization problem equivalent set cover problem known np hard 
means know true number aspects know doc ument covers aspects computationally complex find optimal ranking documents measures 
deficiency aspect coverage measure consider redundancy penalize repeated covering aspects 
presumably want avoid covering aspects trying cover new aspects possible 
measure redundancy addition aspect coverage 
unfortunately measurement redundancy tricky unclear redundant relevant aspect treated better worse non relevant aspect 
information non relevant aspects know document non relevant document 
assume relevant documents 
reasonable measure redundancy look percentage relevant aspects distinct ratio number distinct relevant aspects covered set documents total number relevant aspects 
intuitively aspects unique redundancy ratio ratio 
measure relevant non relevant documents decide non relevant documents 
possibility count non relevant document redundant aspect 
basically assume user quickly judge document non relevant making effort identifying redundant relevant aspect 
essentially measuring number aspects user needs read sees certain number distinct aspects 
words measure captures uniqueness aspects user needs read call measure aspect uniqueness au 
average topics look aspect uniqueness different levels aspect recall similar aspect coverage 
underlying optimization problem aspect uniqueness equivalent volume cover problem known np hard 
know true status aspect coverage computationally complex find optimal ranking documents 
complexity finding optimal ranking aspect cover age aspect uniqueness suggests kind approximation inevitable practice 
maximal marginal relevance mmr models idea maximal marginal relevance mmr ranking proposed formal ized carbonell goldstein 
assumption need consider relevance value novelty equivalently redundancy documents ranking set documents 
informally set previously selected documents best document relevant query topic different selected documents 
risk minimization framework encode preferences conditional loss function dk dk balances relevance value redundancy value document 
dk dk loss function 
conditional risk dk dk dk dk assume parameters concentrated mode posterior distribution close delta function 
simplified case ranking conditional risk approximately equivalent ranking value loss function mode dk dk rank dk dk technically different ways specify loss function 
deriving motivated open research question 
carbonell goldstein mmr measure re ranking pre retrieved set documents documents selected document arg max sim di max di dj sim di dj parameter controlling balance relevance redundancy sim regular retrieval similarity function sim document similarity function supposed capture redundancy 
key component mmr model measure novelty candidate docu ment information contained candidate document new 
challenge come appropriate combination novelty measure regular relevance measure 
formula novelty measured indirectly redundancy maximum similarity document old doc uments novelty measure combined relevance measure linear interpolation 
section study issues language modeling framework 
ways measure novelty document kl divergence measure mixture model 
discuss possible approaches combining novelty relevance corresponding different loss functions 
approach assumes exist independent measures relevance redundancy loss function combination measures 
second approach assumes dynamic query model may depend documents picked 
pick documents query model focused covered aspects 
third approach intends estimate marginal document model focused representing novel information con tained candidate document measure relevance marginal document model respect query model 
evaluate models aspect retrieval data 
novelty redundancy measures set language models model candidate document dk goal define novelty score sn sn indicate novel information document dk contains 
intuitively novelty correlated information dk redundant respect models correlated similarity documents 
measure converted novelty measure may reflect novelty precisely document redundant cover new information 
single topic model start simplest case just single model 
old model new document model respectively 
define sn 
intuitively sn related distance novelty high different surface appears distance function sn symmetric 
really interested asymmetric distance 
specifically interested information represented similar represented vice versa 
words interested information new document new information old document duplicated new document 
discuss different possibilities sn 
working unigram language models natural distance measure kl divergence 
asymmetric discussed necessarily problem 
order measure amount new information represented intuitively sn tells inefficient compression encoding true distribution approximate kl divergence measure allow compare redundancy different documents tell percentage new document redundant novel 
introduce novelty measure simple mixture model 
basic idea assume component mixture generative model new document component old topic model background lan guage model 
observed new document estimate mixing weight background model topic model serve measure novelty redundancy 
intuitively weight indicates extent new document explained background model opposed topic model 
similar idea component mixture models explored zhang measure redundancy information filtering 
formally background language model mixing weight background model 
log likelihood new document dk wn log wi wi estimated novelty score arg max arg max arg max arg max arg min log wi wi dk log log empirical word distribution document dk mixture model equation see estimation essentially min kl divergence empirical word distribution mixture model parameterized 
standard estimation problem simple mixture model maximum likelihood estimate easily computed em algorithm 
summary basic novelty measures 
kl divergence sn 
mixture coefficient sn arg min multiple topic models topic model possibilities 
pos compute average model topic models basic measures directly 
possibility compute novelty score respect individual topic model compute single combined summarized novelty score 
method straightforward discuss second detail 
obvious possibilities combining individual novelty scores 
minimum distance sn min sn 
maximum distance sn max sn 
average distance sn sn minimum distance essentially relies closest document measure redundancy implies logical semantics 
long new document redundant respect old document judged redundant 
property ensuring distance zero redundant new document identical old 
maximum distance appear sense document judged redundant long different old document similar 
average distance implies logical semantics 
new document judged redundant similar old documents 
identical duplicate document regarded redundant document measure 
document covering set old documents judged redundant 
similar strategy computing average model 
different novelty measures shown table 
min imum distance average distance sense considering desire avoid du aspects appears minimum distance appropriate ensure exact duplicated aspect eliminated 
aggregation basic novelty measure model aggregation novelty aggregation model average novelty minimum novelty average kl mixture table novelty measures language models 
comparison novelty measures compare novelty measures aspect retrieval task 
order focus effectiveness novelty detection factor relevance consider special task re ranking relevant documents 
novelty measure expected help bring novel aspects earlier ranked list avoiding duplication old aspects 
rank set relevant documents ranking procedure 
document picked regular relevance measure 
methods 

picked documents document picked highest novelty value determined methods 

process repeated finish ranking documents 
measure ranking aspect coverage ac measure aspect uniqueness au measure 
results shown ac au respectively 
curves observations 
ranking aspect coverage aspect uniqueness method average recall recall average recall recall relevance table comparison novelty measures relevance ranking 

see measures shown different orderings 
au measure mixture model novelty measure performs significantly better kl divergence measure slightly worse kl divergence mea sure ac measure 
measure performs significantly better relevance ranking baseline au measure significantly worse aspect coverage comparison novelty measures relevance ranking ac curves aspect recall comparison ac curves novelty measures baseline relevance ranking solid line 
novelty measures worse baseline 
baseline ac measure 
au measures capability removing redundancy observations suggest removing redundancy ily result improving aspect coverage document 
possible documents cover new aspects tend overlap existing doc uments get weighted due high redundancy value 

mixture model method better novelty equivalently redundancy measure kl divergence method 
seen clearly 
different methods summarize novelty compared group doc uments minimum method average method appear difference minimum summary consistently performs slightly better average method 
seen clearly results ta ble show concrete figures different points curves 
inter au measure model average approach works better novelty average approach mixture model opposite kl divergence measure 
surprise presumably ing novelty score achieve similar effect measuring novelty aspect uniqueness comparison novelty measures relevance ranking au curves aspect recall comparison au curves novelty measures baseline relevance ranking solid line 
mixture model measures better baseline kl divergence measures worse 
average language model trying emphasize vote document 
possible explanation averaging model obtain model smoothed accurate estimated mixture model cient expected accurate individual language model estimation coefficient may higher variances uncertainty individual models 

table note kl divergence measure performs worse base line ranking measures au value low recall level slightly better baseline 
initial improvement seen clearly 
means redundancy measure effective measuring redundancy document respect documents 
set large appears ineffective 

best au measure suggesting may rea redundancy measure 
unfortunately ac measure worse individual model smoothed dirichlet prior method 
measures 
general see measures mise 
possible explanation emphasizing removing redundancy favor documents covering fewer aspects general hurts ac performance 
consider relevant docu ments regular relevance measure helping achieve better aspect cov erage 
combination relevance redundancy necessary re ranking relevant documents 
combining relevance novelty mmr loss function combination relevance measure novelty mea sure reflect desire retrieve document relevant novel 
trade relevance novelty depends user model general introduce parameter control trade 
discuss possible ways combining relevance novelty resulting types mmr loss functions 
direct combination relevance score novelty score suppose assumption relevance score novelty score com puted independently 
define loss function direct combination scores 
formally sr relevance scoring function sn novelty scoring function 
mmr loss function defined combination scoring functions follows 
dk dk sr sn relevance novelty trade parameter dk dk rank sr sn possible combination linear interpolation sr sn carbonell goldstein dk dk sr sn general loss function sense range function sr sn comparable sr sn kl divergence 
imagine combination kl divergence sr sn 
experiment results previous section shown kl divergence capture redundancy combinations expected perform 
kl divergence reasonable measure relevance sr shown relevance retrieval experiments 
previous section see reasonable measure novelty sn 
desirable combine 
unfortunately direction interpolation sense scale 
note estimate sn interpreted expected percent novel information document respect old documents probability randomly picked word document represents new information 
may consider probabilities associated document probability relevance rel probability word document carries new information new 
leads general form loss function dk dk rel new cost constants 
rel new rel new rel new non relevant document carries new information interesting user reasonably assume 
furthermore reasonably assume cost document relevant new 
assumptions dk dk rel new rel reasonable loss function positive cost usually 
general may change dk studies assume constants 
intuitively cost seeing relevant redundant document cost seeing non relevant document 
clearly user care redundancy loss function essentially probability relevance just expect 
assume allows re write loss function equivalent form purpose ranking documents dk dk rel rank rel new new see just hope higher new helps reduce loss higher rel means smaller loss 
amount loss reduction affected cost ratio ratio indicates relative importance avoiding non relevant document vs avoiding relevant redundant document 
ratio large influence new negligible 
means user tolerate non relevant document optimal ranking affected novelty documents 
general compromise retrieving documents new content avoiding retrieving non relevant documents 
technical problem remains usually rel available score documents kl divergence function 
possible solution consider ranking documents query likelihood equivalent ranking kl divergence 
sr may assume rel proportional constant 
assumption loss function rewritten dk dk rank sr sn sr sn estimated novelty coefficient mixture model method 
refer loss function cost combination relevance novelty 
common deficiency combining relevance score novelty score assumption independent measurement relevance novelty 
words direct measure relevance new information contained new document 
document formed concatenating seen redundant relevant document lot new non relevant information may ranked high useless user 
different types loss functions directly measure relevance new information 
dynamic query models basic idea type loss function assume user information need changes user browses documents ranking order 
par ticular query model assumed depend documents user seen focus new aspects covered picked viewed documents 
way implement idea old lan guage model query background model query assumed generated mixing known information language model document language model 
way documents discriminated primarily capability explain ing part query accounted known model query 
documents discriminated relevance new information contained 
approach mentioned chapter 
old model average models previ ously picked documents 
mixture model indicates weight model loss function dynamic background model dk dk method called dynamic query background method expected discriminate relevant documents new information may effective ranking relevant documents non relevant documents 
allow query background model explain query non relevant document expected get reasonably high score 
reasonable loss function explicitly estimate new query model current model assume original query model mixture new un known model qk mixture model denoted qk qk qk parameter indicates known information want consider 
qk estimate qk dynamic query model selecting th document dk minimizing kl divergence qk arg min qk qk loss function dynamic query model dk dk qk refer method marginal query model method 
marginal document language models basic idea type loss function estimate language model best rep resents new information contained document 
imagine residue marginal document may generated removing redundancy document 
novelty score directly rely novelty mea sure estimate language model corresponds imaginary marginal document 
see achieve goal language modeling approach consider simplest case single topic model suppose background language model empirical word distribution new document 
discussed section estimated novelty sn arg min note sn gives estimate fraction novel information document 
assume sn true amount novel information rest information explained old model 
goal estimate language model identified amount novel information order estimate model consider different mixture model involves unknown marginal model estimated 
mixing coefficient fixed sn 
mixture model estimate arg min em algorithm 
simply rank documents corresponding summary idea new information document dk estimate language model represents contained new information score document kl divergence marginal language model query model 
order accommodate flexible trade relevance novelty define loss function interpolation regular relevance measure marginal relevance measure dk dk mk mk estimated marginal language model document dk 
see scoring regular relevance measure score solely marginal language model 
model defined different ways depending summarize set topic models 
mention representative possibilities 
average model average models treat models single model defined effect consider redundant parts document dk 

closest model case model closest document model represent set models 
arg min effect consider redundant part document dk 
case depends dk 
evaluation evaluate effectiveness proposed methods combining novelty relevance compare tuned relevance ranking baseline 
marginal query model approach marginal document model approach expected query model rich consider relevance ranking baselines 
simple baseline best relevance ranking terms aspect coverage measure original short queries 
simple baseline ranking achieved dirichlet prior smoothing parameter set 
feedback baseline uses expanded richer query model simple baseline 
expanded query model interpolation original maximum likelihood query model pseudo feedback model coefficient model 
feedback model estimated top documents simple baseline results mixture model approach described section background noise parameter set 
dirichlet prior smoothing parameter set optimal scoring expanded query 
search best relevance ranking trying different values dirichlet prior parameter 
results different smoothing parameter values compared show relevance precision average preci sion aspect performance aspect coverage uniqueness respond different values smoothing parameter 
pictures left side show comparison average recall recall simple query baseline 
see dirichlet prior parameter set relatively large value curves relatively flat indicating sensitivity low especially aspect measures 
cases parameter value small performance drop significantly 
see correlation curves optimal setting smoothing parameter different different measures 
particular optimal setting relevance precision tends lower aspect measures 
optimal setting relevance precision generally aspect measures 
true especially average perfor mance recall recall optimal setting relatively consistent expected performance highly influenced rank relevant documents real difference rankings may re 
results ranking parameter value gives ac au ac au ac au rel prec asp cov asp uniq relevance precision vs aspect coverage aspect uniqueness average dirichlet prior log scale dirichlet prior log scale rel prec asp cov asp uniq rel prec asp cov asp uniq relevance precision vs aspect coverage aspect uniqueness recall relevance precision vs aspect coverage aspect uniqueness recall dirichlet prior log scale ac au ac au ac au feedback relevance precision vs aspect coverage aspect uniqueness average prec asp cov asp uniq dirichlet prior log scale feedback relevance precision vs aspect coverage aspect uniqueness recall prec asp cov asp uniq dirichlet prior log scale feedback relevance precision vs aspect coverage aspect uniqueness recall prec asp cov asp uniq dirichlet prior log scale correlation relevance precision aspect coverage aspect uniqueness smoothing parameter changes measured average top recall middle recall bottom 
left simple queries right expanded queries 
performance seen sensitive smoothing parameter optimal setting smoothing parameter different measure 
best aspect coverage simple relevance baseline 
right side show similar comparison feedback query 
see patterns similar observed simple baseline results 
best average aspect coverage achieved smoothing parameter set 
performance simple baseline feedback baseline compared ta ble 
feedback baseline improves simple baseline measures amount improvement relevance measures significant 
pseudo feedback primarily aims improving relevance performance improves aspect performance 
ranking mixture relevant non relevant documents improving relevance precision bring relevant doc uments top list expected improve aspect coverage aspect uniqueness aspect measures penalize having non relevant docu ments top 
general better relevance average precision means better aspect coverage performance suggesting improve aspect coverage improving relevance measurement 
limit doing best performing ranking relevance measures give best aspect performance 
show combination relevance measure novelty measure improve aspect performance may inferior relevance performance 
baseline rel 
precision aspect coverage aspect uniqueness method avg 
avg 
avg 
simple feedback improve table comparison simple baseline feedback baseline 
baselines test proposed methods combining relevance novelty 
method examine influence parameters compare method performance baselines 
sake efficiency comparison generally re ranking top ranked documents baseline ranking 
look cost combination relevance novelty 
re ranking top documents topic returned simple baseline relevance ranking re ranking relevant documents 
vary cost parameter 
unreasonable set value mean larger relevance value corresponds larger loss 
large combination relies relevance 
ranking relevance 
results shown 
average prec au ac sensitivity precision ac au cost parameter rel prec asp cov asp uniq rho cost coefficient average prec au ac sensitivity precision ac au cost parameter relevant docs asp cov asp uniq rho cost coefficient effectiveness cost combination relevance novelty re ranking mixture relevant non relevant documents left re ranking relevant documents right 
ranking rel 
precision aspect coverage aspect uniqueness method avg 
avg 
avg 
cc improve improve ranking aspect coverage aspect uniqueness method avg 
avg 
cc improve improve table effectiveness cost combination relevance novelty re ranking mixture relevant non relevant documents top re ranking relevant documents bottom 
improvement feedback baseline simple baseline shown comparison 
see cost combination relevance novelty effective improving aspect coverage aspect uniqueness working mixed data relevant non relevant documents 
feedback baseline results obtained expanded query re rank documents 
perfor mance worse retrieving documents collection 
worse retrieving top documents collection 
see feedback baseline improve simple baseline terms rele vance precision aspect measures 
appears testing collection novelty redundancy dominating factor compared relevance improvement measuring relevance expected improve aspect coverage significantly trying minimize redundancy 
ranking relevant documents see feedback improves aspect coverage hurts aspect uniqueness 
means improvement relevance helps improve aspect coverage pushing non relevant documents bringing documents tend cover aspects probably feedback clear positive effect aspect coverage re ranking relevant documents 
ac au rel prec asp cov asp uniq effectiveness dynamic background model method mixed data novelty weight ac au asp cov asp uniq effectiveness dynamic background model method rel 
docs novelty weight effectiveness query background model approach combining relevance novelty reranking mixed relevant non relevant documents left re ranking relevant documents right 
see cost combination clearly significantly improves uniqueness re ranking relevant documents suggesting help reduce redundancy documents turn helps improve aspect coverage shown table 
evaluate dynamic query modeling approaches 
look query background model approach 
results ranking mixed documents top documents re ranking relevant documents shown 
see aspect performance improves re ranking relevant documents perfor mance improved ranking mixed documents 
reason query background helps non relevant documents generate query get higher score get 
relevance pre cision clearly decreasing larger novelty weight happens higher novelty weight non relevant documents brought hurts precision measure aspect measures 
similar cost approach re ranking relevant documents query background model approach able improve aspect coverage aspect uniqueness shown table 
ranking aspect coverage aspect uniqueness method avg 
avg 
qb improve table effectiveness query background model re ranking relevant documents 
improves aspect coverage aspect uniqueness 
results marginal query model method shown table 
results mixed data re ranking top documents returned simple query baseline 
method slightly improve measures re ranking relevant documents 
appears long novelty weight high marginal query model approach change ranking order significantly novelty weight high change ordering hurts performance measures 
results suggest simple mixture model effective estimating accurate marginal query model 
ac au rel prec asp cov asp uniq effectiveness query marginal model method mixed data novelty weight ac au asp cov asp uniq effectiveness query marginal model method rel 
docs novelty weight effectiveness marginal query model approach combining relevance novelty reranking mixed relevant non relevant documents left re ranking relevant documents right 
results marginal document model re ranking mixed data top docu ments re ranking relevant documents shown table 
see approach improve measures mixed documents quite 
interesting note approach hardly improve perfor mance working relevant documents 
suggests improvement mixed data may largely due improvement relevance ranking relatively significant increase relevance measures 
mix ture novelty measure shown quite effective improving aspect uniqueness estimated marginal document model novelty measure turns effective 
ranking rel 
precision aspect coverage aspect uniqueness method avg 
avg 
avg 
mqm improve ranking aspect coverage aspect uniqueness method avg 
avg 
mqm improve table effectiveness marginal query model approach combining relevance novelty reranking mixture relevant non relevant documents top re ranking relevant documents bottom 
ac au rel prec asp cov asp uniq effectiveness adaptive marginal model method mixed data novelty weight ac au asp cov asp uniq effectiveness adaptive marginal model method rel 
docs novelty weight effectiveness marginal document model approach combining relevance novelty re ranking mixed relevant non relevant documents left re ranking relevant documents right 
table compare methods terms best results ranking rel 
precision aspect coverage aspect uniqueness method avg 
avg 
avg 
mdm improve ranking aspect coverage aspect uniqueness method avg 
avg 
mdm improve table effectiveness marginal document model approach combining relevance novelty reranking mixture relevant non relevant documents top re ranking relevant documents bottom 
mixed data relevant data 
mixed data marginal document model method marginal query model method manage improve aspect coverage aspect uniqueness slightly cost combination method query background model method improve relevance ranking baseline 
relevant data set results opposite 
cost combination method query background model method perform better marginal model approaches 
factor relevance factor re ranking relevant documents improvement aspect performance relevant data set indicator method captures redundancy novelty elimination redundancy help retrieve relevant aspects 
results show cost combination method query background model method effective removing redundancy covering aspects 
approach improve aspect performance mixed data 
means approach effective ranking relevant documents non relevant ones ap proaches tend decrease relevance precision significantly see table 
result internal ranking relevant documents may improved performance decreases non relevant documents ranked high 
clearly perform mixed data set method able model rele vance redundancy effectively 
cost method query background model method examples modeling redundancy effective modeling relevance relatively weak 
hand marginal model approaches appear better modeling relevance redundancy 
improvement rel data set quite small improve performance slightly mixed data set 
table table see approaches improve precision mixed data set 
improvement aspect performance mainly due improvement relevance ranking 
interesting observation designed improve relevance ranking 
possible explanation marginal query model method dynamic query model effectively distilled query model background noise excluded strategy shown effec tive improving precisions see chapter section 
study needed understand marginal document model method improves precision 
mixture model novelty measure shown effective measuring novelty redundancy surprising cost combination method uses mixture model novelty measure improves aspect uniqueness significantly relevant data set 
interesting mixture model novelty measure able improve aspect coverage combining relevance possible improve aspect uniqueness aspect coverage 
summary relevant data set cost combination method ef improve aspect coverage aspect uniqueness suggesting eliminating redundancy help improve aspect coverage 
mixed data set seen case relevance precision decreased aspect performance improved improvement aspect performance accompanied increase relevance performance 
appears improving aspect coverage eliminating redundancy effective achieve ensure relevance ranking relevance ranking accurate improving relevance ranking may expected impact aspect performance removing redundancy 
eliminating redundancy improve aspect coverage highly depends redundancy data observations suggest percentage redundant documents may relatively low compared percentage non relevant documents data set 
useful test methods synthetic data control level redundancy 
practice aspect retrieval task may consider cost combination method marginal document model depending accurate relevance measure cost combination method appropriate expect achieve high precision marginal ranking aspect coverage increase aspect uniqueness increase method avg 
avg 
cc qb mqm mdm ranking aspect coverage increase aspect uniqueness increase method avg 
avg 
cc qb mqm mdm table comparison mmr models re ranking mixed data top re ranking relevant documents bottom 
numbers shown increase baseline relevance ranking 
document model method may appropriate 
maximal diverse relevance mdr models section study completely different type models aspect retrieval task 
previous section hope increase aspect coverage indirectly eliminating redundancy documents intend improve coverage directly modeling possible aspects documents mixture language models 
general aspect retrieval model model aspect retrieval problem consider generative model illustrated fig ure 
assume space aspects characterized unigram language model 
formally vector aspects 
unigram language model gives probability word aspect assume user interest retrieving documents cover aspects pick probability distribution aspects query query generation model 
intuitively encodes psfrag replacements aspect selection query generation aspect selection doc generation aspect generative model query document user preferences aspect coverage general probability mass concentrated aspects interesting user non interesting aspects may zero probability 
furthermore interesting aspects distribution generally non uniform reflecting fact aspects em 
similarly assume author source document pick aspect coverage distribution generate document generation model 
example simple case mixture model mixing weights component unigram language models 
suppose dn di derivation restricted mixture model 
derive aspect retrieval model start general greedy algo rithm ranking formula dk dk def dk dk conditional risk gives way evaluate rest documents pick best dk picked dk 
generative models dk 
consider loss function dk dk dk dk dk dk dk dk dk weighted average di ki defined follows model 
dk di dk dk parameter indicating redundancy idea loss function expect give measure aspect relevant high indicates aspect relevant 
loss function encodes preferences similar aspect coverage distribution documents dk 
assigns high probabilities aspects expect cover presumably relevant aspects aspects 
best dk dk achieve coverage distribution similar desired aspect coverage query 
parameter controls rely previously picked documents dk cover aspects 
rely looking dk best covers relevant aspects 
hand part coverage explained previously picked documents best dk best covers covered relevant aspects 
essentially searching dk best supplements coverage provided previously picked documents respect desired coverage putting loss function aspect generative model conditional risk formula dk dk dk dk ck dk dk dk ck qd dk dk ck dk ck arg max ck dk 
di di di di note assumed estimated documents collection depend dk ignored purpose ranking dk 
dk dk rank dk dk rank dk dk di di di di rank dk dk dk dk rank dk dk arg max di arg max di di di obtained ranking procedure 
rank documents greedy fashion conditional risk dk dk selecting th document 

selecting document estimate arg max 

compute dk dk compute dk presumably dk computed evaluate dk dk 
dk computed formulas 
experiments re ranking pre selected working set documents estimate working set 
order general aspect retrieval model operational need specify query model document model distinct aspect word entirely concentrated single word just regular unigram language models 
case set conditional risk longer depend previously picked documents dk dk dk dk dk qd dk precisely regular ranking formula independent kl divergence loss func tion 
aspect retrieval model generalization regular kl divergence retrieval model 
choose achieve effect aspect covering ranking picking dk concentrating covered aspects 
general plug specific aspect generative models general aspect retrieval model leading potentially different retrieval formulas 
discuss specific aspect generative models 
query model qm query 
query generation model mixture model qi coverage selection model reflect prior user prefer ences aspect coverage 
simplest case non informative uniform prior interesting consider dirichlet distribution parameters 
parameters depend intuitively reflect popularity aspects 
dirichlet prior user sample desired coverage distribution dirichlet coverage selection model generate query mixture model uses mixing weights 
note assume advance 
document model dn document 
mention plain mixture model assume words document generated uncertain fixed aspect 
di model reflect goal capturing multiple aspects single document explore model 
order model multiple aspects document aspect generative mixture model di assume imaginary author document source pick desired aspect coverage distribution generate docu ment mixture model mixing weights aspects 
question define coverage selection probability 
turns different choices known aspect models probabilistic latent semantic indexing hofmann latent dirichlet allocation blei :10.1.1.110.4050
probabilistic latent semantic indexing plsi suppose defined set documents collection dn 
allow different coverage distributions di suppose impose constraints 
assumption log likelihood collection di ni ni log di dij ni length document di 
parameters model include sub topic language models potentially different mixing weight distribution di document di 
essentially probabilistic latent semantic indexing plsi proposed hofmann 
apply model problem aspect retrieval estimate di maximizing collection likelihood 
em algorithm applied 
see hofmann discussion estimation methods avoid fitting 
suppose di estimated models 
compute maximizing posterior probability arg max map optimization problem dirichlet distribution aspect selection model 
solved em algorithm 
updating equations qi qi qi qi qi component value corresponding aspect dk score documents 
dk problem plsi large number parameters 
total num ber parameters vocabulary size number aspects number documents 
serious problem especially mod eling aspects number parameters grows linearly number aspects number documents 
discuss latent dirichlet alloca tion model effectively uses dirichlet distribution regulate documents reducing number parameters significantly 
latent dirichlet allocation lda considering finite set coverage distributions consider con space possible aspect coverage distributions space multinomial distributions aspects 
dirichlet parameter 
assumption log likelihood collection log ni precisely lda model proposed blei :10.1.1.110.4050
dij lda model significantly fewer parameters including aspect language models dirichlet parameters order obtain aspect coverage distri bution document compute posterior distribution mode estimate 
principle parameters lda model estimated maximum likelihood estimator maximizing collection likelihood 
practice estimation parameters lda model significantly complicated plsi model 
variational approach blei expectation propagation algorithm proposed studied minka lafferty :10.1.1.110.4050
comparison analysis approaches minka lafferty 
obtained estimate parameters algorithms estimate query aspect coverage distribution exactly way done plsi model arg max similarly estimate aspect coverage distribution document dn arg max arg max dj map estimation problem em algorithm 
candidate documents score documents dk dk 
evaluation probabilistic lsi ac au rel prec mu asp cov mu asp uniq mu rel prec mu asp cov mu asp uniq mu different aspect numbers plsi mixed data number aspects ac au different aspect numbers plsi rel docs asp cov mu asp uniq mu asp cov mu asp uniq mu number aspects influence number aspects plsi aspect model mixed data left relevant data right 
plsi experiments re ranking top documents returned slightly different relevance ranking baseline 
baseline obtained feedback procedure slightly different inferior parameter setting 
plsi results comparable results 
want conduct controlled experiments compare different methods 
look influence choice number aspects plsi model 
number aspects determines granularity aspects consideration 
small number aspects mean relatively general aspects view point discriminating aspects presumably better consider larger number 
parameter estimation reliable consider small number aspects 
empirically trade involved determin ing optimal number aspects 
performance different number aspects shown 
plot show aspect coverage aspect uniqueness values case re ranking mixed data show average precision 
show performance 
results see performance sensitive choice number clusters 
hard see pattern 
see improves aspect uniqueness 
expected plsi experiments performed established baselines methods 
ac au ll average ac au log likelihood different local plsi rel docs log likelihood asp coverage asp uniqueness local maxima comparison average aspect performance likelihood different local 
coverage increase uniqueness increase ac increase vs log likelihood increase plsi rel docs likelihood increase au increase vs log likelihood increase plsi rel docs likelihood increase coverage increase uniqueness increase ac increase vs log likelihood increase plsi rel docs likelihood increase au increase vs log likelihood increase plsi rel docs likelihood increase comparison aspect performance likelihood best local maxima worst maxima 
top aspect coverage bottom aspect uniqueness 
left data points queries right data points log likelihood range 
indicates redundancy want consider 
working relatively large number aspects appears help improve aspect uniqueness aspect coverage consistent 
avoid trapped local maxima experiment program automatically tries different initial values em algorithm uses gives highest likelihood 
plsi model local best local maxima trials global maxima 
means sensitivity number clusters caused variances converging different local 
clarify repeat experiments times em algorithm converge potentially different local 
determine higher likelihood better local maxima leads better performance 
compare average aspect performance likelihood different local 
weak correlation average log likelihood aspect coverage 
correlation likelihood aspect uniqueness completely unclear 
query identify best performing worst performing local compute performance difference likelihood difference best performing local maxima worst performing local maxima 
plot performance difference likelihood dif ference query 
see performance extremely sensitive local maxima obvious correlation increase aspect performance increase likelihood 
local maxima higher likelihood necessarily lead better aspect performance 
course possible local close global maxima 
results suggest important find global maxima 
ac au pr ac au influence novelty coefficient performance plsi mixed data rel prec asp cov asp uniq novelty coefficient asp cov asp uniq plsi true number aspects mixed data novelty coefficient ac au ac au influence novelty coefficient performance plsi rel docs asp cov asp uniq novelty coefficient asp cov asp uniq plsi true number aspects rel docs novelty coefficient influence novelty coefficient performance aspects top true number aspects bottom mixed data left relevant data right 
data set novelty aspects true aspect count coefficient mixed data improve relevant data improve data set novelty aspects true aspect count coefficient mixed data improve relevant data improve table effectiveness aspect loss function 
non zero novelty coefficient shown improve aspect coverage top aspect uniqueness bottom decreases relevance precision 
table compare model performance zero novelty weight non zero novelty weight 
comparison provides idea effec tive loss function capturing dependency documents 
table see non zero novelty coefficient able improve aspect coverage aspect uniqueness decreases precision 
improvement aspect formance decreasing precision possible mmr style loss functions suggesting aspect modeling loss functions promising capturing aspect coverage 
kl divergence loss function effective cap turing preference maximizing aspect coverage 
table compares performance fixed number aspects true number aspects obtained aspect judgments 
see true number aspects cheating better just fixed number aspects 
example measured aspect coverage performs better fixed aspects mixed data worse relevant data set 
unclear 
complete picture performance influenced novelty weight see performance quite sensitive setting novelty weight optimal setting depends data set performance measure 
ranking rel 
precision aspect coverage aspect uniqueness method avg 
avg 
avg 
best ac improve best au improve ranking aspect coverage aspect uniqueness method avg 
avg 
best ac improve best au improve table effectiveness basic plsi aspects mixed data top relevant data bottom 
table compare best performance plsi aspects relevance ranking baselines 
see plsi improves aspect coverage aspect uniqueness relevant data significantly worse baseline mixed data indicating capture relevance weak aspects basic aspect model 
plsi model appears great potential improving performance 
example larger number aspects achieve better aspect uniqueness 
seen table show possible achieve aspect uniqueness baseline aspects non zero novelty weight 
possibility improving basic model fix aspect background model force constant weight special ranking rel 
precision aspect coverage aspect uniqueness method avg 
avg 
avg 
best ac bm improve best au asp improve table effectiveness improved plsi 
fixing aspect background model achieves best ac background weight set aspects achieves best au 
background aspect 
idea force aspects focus specific content aspect distracted common words 
shown table set background weight set improve aspect coverage baseline 
note relevance precision significantly decreased 
low precision means relatively fewer relevant documents ranked top improvement aspect coverage means relevant documents probably relevant documents cover aspects 
mmr models improve aspect coverage relevance ranking accurate plsi model able directly maximize aspect coverage relying relevance ranking 
latent dirichlet allocation experiments lda implementation variational bayesian approach minka lafferty task mixed data re rank top documents returned baseline relevance ranking 
look novelty coefficient affects performance 
shown 
see mixed data relevant data non zero novelty weight perform better zero weight terms aspect performance 
larger novelty weight aspect uniqueness tends improve 
mixed data see relevance preci sion decreases novelty weight increases means avoiding redundancy may allow non relevant documents ranked high decreasing precision 
see mixed data set novelty weight large aspect performance decreases significantly expected 
fact non zero novelty weight perform better zero weight suggests novelty parameter loss function useful improving aspect coverage 
table compare performance zero novelty weight best non zero weight 
see non zero novelty weight improves aspect coverage aspect uniqueness mixed data relevant data 
time precision mixed data decreased 
see possible improve aspect performance improving relevance precision seen mmr models 
examine influence number aspects model 
results ac au pr influence novelty weight lda mixed data rel prec asp cov asp uniq novelty weight ac au influence novelty weight lda relevant data asp cov asp uniq novelty weight influence novelty coefficient performance lda aspects mixed data left relevant data right 
data set novelty aspect coverage aspect uniqueness coefficient mixed data improve relevant data improve table effectiveness aspect loss function lda 
non zero novelty coefficient shown improve aspect coverage uniqueness mixed data relevant data 
mixed data relevance precision decreased 
shown 
precision decreases increase number aspects 
optimal number aspects aspect uniqueness measure probably larger number aspects hurt aspect uniqueness 
optimal number aspects aspect coverage appears 
limited experiments performed best results lda worse baseline results shown table improve aspect uniqueness relevant data set 
exploration lda preliminary 
example order speed experiments limited maximum number em iterations may affected accuracy estimated model parameters 
computation document query models exact 
possible bugs easy detect program 
exploration lda clearly needed fully develop potential general ac au different aspect numbers lda mixed data mu rel prec asp cov asp uniq number aspects influence number aspects performance lda mixed data 
aspect language model 
ranking rel 
precision aspect coverage aspect uniqueness method avg 
avg 
avg 
best ac improve best au improve ranking aspect coverage aspect uniqueness method avg 
avg 
best ac au improve table effectiveness lda mixed data top relevant data bottom 
number parenthesis number aspects 
chapter demonstrated risk minimization framework go traditional notion independent topical relevance study non traditional retrieval task aspect retrieval problem risk minimization framework 
goal aspect retrieval retrieve relevant documents possible retrieve distinct relevant aspects possible 
non traditional retrieval task consider measures aspect coverage aspect uniqueness 
aspect retrieval problem requires non traditional ranking methods 
derived types aspect retrieval models involving dependent loss function 
type models increase aspect coverage indirectly reducing redundancy docu ments essentially maximal marginal relevance mmr models language models 
second type models called maximal diverse relevance mdr models increase aspect coverage directly modeling hidden aspects documents 
proposed ways exploit language modeling measure redundancy nov kl divergence mixture models 
evaluation shows mixture model measure effective capturing redundancy achieve significantly better aspect uniqueness pure relevance ranking re ranking relevant documents 
basic idea mixture model measure represent known information known information language model assume new document generated mixture model involving known information model background component model 
novelty measure equivalently redundancy measure estimated mixing weight known information model background model 
novelty measure useful re ranking subset documents reduce re 
success simple mixture model worth exploring sophisticated mixture models zhang 
mmr type models proposed different ways combine relevance novelty 
experimental results single method consistently better 
observed models better mixed data set better relevant data set 
direct combination mixture model novelty measure regular kl divergence relevance score shown effective improving aspect coverage aspect uniqueness relevant data set suggesting helpful improving aspect coverage redundancy elimination 
method perform mixed data set particular perform better baseline relevance ranking suggesting redundancy elimination helps improve aspect coverage relevance ranking accurate 
interestingly marginal document model approach directly estimate language model represents novel information contained document performs relatively better mixed data set improving relevance baseline measure including relevance precision 
method perform relevant data set 
improvement mixed data set due improvement relevance ranking 
study needed understand aspect oriented model improve relevance precision 
mmr type model appear effective improving aspect performance mixed data 
may amount redundancy relevant documents relatively low compared amount non relevant documents data set 
models designed exploit redundancy removal effectiveness best demonstrated highly redundant data set 
experiments synthetic data allow test effectiveness fairly 
interesting research direction model redundancy novelty relevance passage level 
mdr models derived general aspect retrieval function aspect kl divergence studied variants aspect generative models tic latent semantic indexing plsi latent dirichlet allocation lda approach 
evaluation shows plsi lda loss function effective capturing dependency documents optimal performance obtained non zero novelty weight means goal collectively covering multiple documents effectively reflected loss function 
interesting observation plsi lda shown capacity improving aspect performance relevance precision decreases observed experiments mmr models 
means aspect models lose relevant documents top selectively keep top relevant doc uments better cover aspects 
see kl divergence function aspect space relevance precision aspect models tends worse applying kl divergence function word space result absolute performance generally strong baseline relevance ranking 
shown possible plsi model perform better relevance rank ing baseline improve basic model incorporating background aspect 
encouraging especially aspect performance increased relevance precision decreased indicates model effectiveness modeling aspects 
study aspect retrieval preliminary results clearly demonstrated generality risk minimization framework 
shown derive non traditional ranking methods loss functions go traditional notion relevance 
just exploration models standard ad hoc retrieval task framework serves map allows explore variety non traditional models systematically 
study aspect retrieval problem results far conclusive 
improvement baseline ranking relevance significant especially case ranking mixed set relevant non relevant documents 
observation data set relevance ranking appears quite strong correlation aspect coverage measure sense intuitively relevant aspects document covers get higher score reasonable relevance measure 
follow ex periments done william cohen data set show really room improve aspect retrieval performance baseline methods cohen 
important research direction examine behavior non traditional ranking methods controlled synthetic data 
low observe performance affected factors average number aspects document level redundancy relevant documents 
help better understand problem aspect retrieval appropriateness proposed evaluation measures 
relevance feedback aspect retrieval interesting direction worth exploring 
example know information aspects interesting user information exploited late aspect model 
terms specific aspect retrieval models touched basic formulation models especially case lda lot approximation simplification assumed experiments 
im plementation plsi appears suffer problem multiple local performance highly sensitive local maxima 
lda model relatively stable performed plsi model 
study models clearly needed thoroughly understand methods effectiveness performing retrieval task 
interesting study alternative loss functions aspect retrieval problem expected result completely new aspect retrieval models 
chapter chapter summarize key research results thesis discuss directions opportunities research 
summary thesis presents new general probabilistic framework text retrieval bayesian decision theory 
framework queries documents modeled statistical language models user preferences modeled loss functions re trieval cast risk minimization problem 
risk minimization framework unifies existing retrieval models general probabilistic framework facilitates development new principled approaches text retrieval statistical language models 
explored interesting special cases framework demonstrating various advantages new framework traditional retrieval methods 
fundamental difference risk minimization framework exist ing retrieval framework risk minimization framework treats entire retrieval problem decision problem incorporates statistical language models major com ponents framework 
previous treated retrieval decision theoretic view previous complete decision theoretic formal model retrieval 
risk minimization framework complete formal treatment retrieval statistical decision theory 
time user variable document source variable explicitly formally introduced retrieval model 
decision space risk minimization framework principle may consist possible actions system take response query allows treat retrieval problem general way 
general decision theoretic view explicitly suggests retrieval modeled interactive process involves cy cles user reformulating query system presenting information 
risk minimization framework condition current retrieval decision information retrieval context user interaction history perform context sensitive retrieval 
contrast traditional retrieval models quite restricted due reliance unrealistic simplification assumptions relevance independent relevance assumption 
generally inadequate handling user fac tors redundancy tolerance readability model interactive retrieval process relying heuristics 
risk minimization framework possible systematically formally study general optimal retrieval strategies 
example making different assump tions loss function ranking derived optimal ranking principle addresses limitations similar probability ranking principle 
specifi cally assuming independent loss function sequential browsing model show optimal ranking rank documents expected risk document computed independently document 
interest ing implication ranking optimal user high precision high recall retrieval preference 
general incorporation statistical language models retrieval framework important contribution thesis 
major challenge text retrieval long develop principled retrieval approaches perform empirically 
theoretically motivated models rarely led directly performance heuristic retrieval pa rameters need introduced increase flexibility model 
parameters empirically motivated heavy empirical tuning parameters necessary achieve retrieval performance 
contrast retrieval pa rameters risk minimization framework generally introduced part statistical language model 
possible exploit statistical estimation methods improve retrieval performance set retrieval parameters automatically 
special case risk minimization framework stage language modeling approach achieve excellent retrieval performance setting retrieval parameters completely automatically 
risk minimization framework thesis extends existing language modeling approach information retrieval ways 
studied smoothing language models 
show general connection language modeling approach heuristics traditional models including tf idf weighting document length normalization 
extensively evaluated popular smoothing methods jelinek mercer dirichlet priors absolute discounting retrieval performance generally sensitive smoothing parameters smoothing plays different roles role improve accuracy estimated document language model estimation role accommodate generation non informative common words query query modeling role 
provides empirical justification stage smoothing method generalizes basic language model proposed ponte croft 
second studied perform feedback language modeling approach 
feedback far dealt heuristically language modeling approach serious conceptual inconsistency 
instance risk minimization framework derive kl divergence retrieval model covers basic language modeling approach special case 
kl divergence model explicitly deals query model perform feedback naturally treating query model updating 
proposed specific query model dating algorithms feedback documents 
evaluation indicates algorithms effective feedback updated query models outperform original query models significantly 
demonstrates possibility improving retrieval performance reasonable language models better estimation methods 
contrast lack guidance improve retrieval model previous 
due generality formalizing retrieval tasks risk minimization retrieval frame allows incorporating user factors traditional notion topical relevance 
traditionally hard formally model factors redundancy sub topics retrieval model general linear combination relevance measure novelty measure carbonell goldstein 
pre sented language models formally capture redundancy sub topics documents study loss functions rank documents terms relevance sub topic diversity 
evaluation shows proposed language models effectively capture re outperform relevance ranking method aspect retrieval task 
study aspect retrieval preliminary clearly demonstrated risk minimization framework exploited model non traditional retrieval problem 
research directions risk minimization framework opens new possibilities developing princi approaches text retrieval serves general framework applying statistical language models text retrieval 
special cases explored thesis represent small step exploring full potential risk minimization framework 
interesting research directions including automatic parameter setting major scientific challenge set retrieval parameters automatically relying heavy experimentation 
major advantage language models possibility estimating retrieval parameters completely automatically 
stage smoothing method parameter estimation meth ods promising small step goal 
stage smoothing method relatively simple model take advantage feedback 
interesting study estimate parameters powerful models feedback documents 
document structure analysis common assumption text retrieval treat document information unit 
relevant information represents small part long document 
desirable go just retrieving relevant document locate real relevant information relevant document 
traditionally heuristic approaches applied retrieve passages regarded step goal 
boundary relevant information may vary different queries interesting explore dynamic approach passage segmentation integrated retrieval function 
risk mini mization framework possible incorporate segmentation loss function exploit language models hidden markov models model document structure 
aspect retrieval models aspect retrieval problem provides interesting setting studying redundancy elimination sub topic modeling text retrieval accurate formulation retrieval problem high recall preferred 
thesis preliminary exploration language models aspect retrieval problem open issues explore 
particular latent dirichlet allocation model great potential modeling hidden aspects directly certainly worth exploring 
interesting research direction develop aspect retrieval models support aspect feedback 
interactive retrieval models real retrieval situation goal satisfying user information need accomplished series interactions user retrieval system 
interactive retrieval process suggests moment retrieval decision may depend previous actions system user taken 
example documents user seen considered order avoid redundancy 
general information previous actions utilized provide context making current retrieval decision 
risk minimization framework formally incorporate variables derive personalized context sensitive interactive retrieval models 
interesting extend risk minimization framework formalize interactive retrieval process optimize global long term utility sequence retrieval interactions 
bibliography berger lafferty 

information retrieval statistical translation 
pro ceedings acm sigir conference research development infor mation retrieval pages 
berger 

statistical decision theory bayesian analysis 
springer 
blei ng jordan 

latent dirichlet allocation 
journal machine learning research 
bookstein swanson 

decision theoretic foundation indexing 
journal american society information science 
buckley 

automatic query expansion smart trec 
harman editor overview third text retrieval conference trec pages 
nist special publication 
callan croft harding 

inquery retrieval system 
proceed ings third international conference database expert system applica tions pages 
springer verlag 
carbonell goldstein 

mmr diversity reranking reordering documents producing summaries 
proceedings sigir pages 
chen goodman 

empirical study smoothing techniques language modeling 
technical report tr harvard university 
cohen 

personal communications 
cooper 

inconsistencies probabilistic ir 
proceed ings sigir pages 
cooper 

formalism probability theory ir foundation en 
proceedings th annual international acm sigir conference research development information retrieval pages 
cooper maron 

foundations probabilistic utility theoretic indexing 
journal acm 
cover thomas 

elements information theory 
wiley 
croft 

document representation probabilistic models information re trieval 
journal american society information science pages 
croft harper 

probabilistic models document retrieval relevance information 
journal documentation 
deerwester dumais landauer furnas harshman 

indexing latent semantic analysis 
journal american society information science 
dempster laird rubin 

maximum likelihood incom plete data em algorithm 
journal royal statist 
soc 

evans 

design evaluation clarit trec system 
harman editor proceedings second text retrieval conference trec pages 
evans zhai 

noun phrase analysis unrestricted text information retrieval 
proceedings acl pages 
fox 

expending boolean vector space models information retrieval norm queries multiple concept types 
phd thesis cornell university 


relevance reconsidered agenda st century special topic issue relevance research 
journal american society information science 
fuhr 

probabilistic models information retrieval 
computer journal 
fuhr 

representations models abstractions probabilistic information re trieval 
opitz lausen editors information classification 
concepts methods applications springer berlin pages 
fuhr 

language models uncertain inference information retrieval 
proceedings language modeling ir workshop pages 
fuhr buckley 

probabilistic learning approach document indexing 
acm transactions information systems 
fung 

applying bayesian networks information retrieval 
communications acm 


inferring probability relevance method logistic regression 
proceedings acm sigir pages 


population frequencies species estimation population parameters 
biometrika parts 
harper van rijsbergen 

evaluation feedback document retrieval occurrence data 
journal documentation 
harter 

probabilistic approach automatic keyword indexing part ii 
journal american society information science part part ii 
hiemstra 

language models information retrieval 
phd thesis uni versity twente 
hiemstra kraaij 

trec ad hoc cross language track 
proceedings seventh text retrieval conference trec pages 
hofmann 

probabilistic latent semantic indexing 
proceedings acm si gir pages 
jelinek 

statistical methods speech recognition 
mit press 


new probabilistic model text classification retrieval 
technical report ciir univ massachusetts 
katz 

estimation probabilities sparse data language model component speech recognizer 
ieee transactions acoustics speech sig nal processing assp 
kneser ney 

improved backing gram language modeling 
proceedings ieee international conference acoustics speech signal processing pages 
kwok chan 

improving stage ad hoc retrieval short queries 
proceedings sigir pages 
kwok 

network approach probabilistic information retrieval 
acm transactions office information system 
lafferty zhai 

document language models query models risk minimization information retrieval 
proceedings sigir pages 
lafferty zhai 

probabilistic ir models query document generation 
proceedings language modeling ir workshop pages 
lafferty zhai 

probabilistic relevance models document query generation 
croft lafferty editors language modeling information retrieval 
kluwer academic publishers 
lavrenko croft 

relevance language models 
proceedings sigir pages 
lawrence giles 

accessibility information web 
nature 
lewis 

representation learning information retrieval 
technical report univ massachusetts 
lewis 

naive bayes independence assumption information retrieval 
european conference machine learning pages 
lyman varian 

information 
retrieved www sims berkeley edu info oct 
mackay peto 

hierarchical dirichlet language model 
natural lan guage engineering 
maron kuhns 

relevance probabilistic indexing information retrieval 
journal acm 
mccallum nigam 

comparison event models nave bayes text classification 
aaai learning text categorization workshop pages 
miller leek schwartz 

hidden markov model information retrieval system 
proceedings acm sigir conference research development information retrieval pages 
minka lafferty 

expectation propagation generative aspect model 
proceedings uai pages 
mittendorf schauble 

document passage retrieval hidden markov models 
proceedings sigir pages 
ney essen kneser 

structuring probabilistic dependencies stochastic language modeling 
computer speech language 
ney essen kneser 

estimation small probabilities leaving 
ieee transactions pattern analysis machine intelligence 
ng 

maximum likelihood ratio information retrieval model 
voorhees harman editors proceedings eighth text retrieval conference trec pages 
ponte 

language modeling approach information retrieval 
phd thesis univ massachusetts amherst 
ponte croft 

language modeling approach information retrieval 
proceedings acm sigir pages 
ribeiro muntz 

belief network model ir 
proceedings sigir pages 
ribeiro neto silva muntz 

bayesian network models information retrieval 
crestani pasi editors soft computing information retrieval techniques applications pages 
springer verlag 
robertson 

personal communication 
robertson sparck jones 

relevance weighting search terms 
journal american society information science 
robertson walker 

simple effective approximations poisson model probabilistic weighted retrieval 
proceedings sigir pages 
robertson walker 

relevance weights little relevance informa tion 
proceedings sigir pages 
robertson 

probability ranking principle journal documentation 
robertson van rijsbergen porter 

probabilistic models indexing searching 
oddy editors information retrieval research pages 
butterworths 
robertson walker 

okapi trec 
voorhees harman editors eighth text retrieval conference trec 
nist special publication 
robertson walker jones hancock beaulieu 

okapi trec 
harman editor third text retrieval conference trec pages 
rocchio 

relevance feedback information retrieval 
smart retrieval system experiments automatic document processing pages 
prentice hall rosenfeld 

decades statistical language modeling go 
proceedings ieee volume 
rousseau 

extended boolean retrieval heuristic approach 
proceedings sigir pages 
salton 

automatic text processing transformation analysis retrieval information computer 
addison wesley 
salton buckley 

term weighting approaches automatic text retrieval 
information processing management 
salton buckley 

improving retrieval performance relevance feedback 
journal american society information science 
salton fox wu 

extended boolean information retrieval 
communications acm 
salton mcgill 

modern information retrieval 
mcgraw hill 
salton wong yang 

vector space model automatic index ing 
communications acm 
salton yang yu 

theory term importance automatic text analysis 
journal american society information science 
saracevic 

concept relevance information science historical review 
saracevic editor information science pages 
bowker 
sherman 

google fires new search engine size wars 

searchenginewatch com 
singhal 

modern information retrieval brief overview 
bulletin ieee computer society technical committee data engineering 
singhal buckley mitra 

pivoted document length normalization 
proceedings acm sigir conference research development information retrieval pages 
song croft 

general language model information retrieval 
proceedings acm sigir conference research development information retrieval pages 
sparck jones walker robertson 

probabilistic model formation retrieval development comparative experiments part part 
information processing management 
sparck jones willett editors 
readings information retrieval 
morgan kaufmann publishers 
strzalkowski 

nlp track trec 
harman editor proceedings fifth text retrieval conference trec pages 
turtle croft 

evaluation inference network retrieval model 
acm transactions information systems 
van 

theoretical basis occurrence data infor mation retrieval 
journal documentation pages 
van rijsbergen 

information retrieval 
butterworths 
van rijsbergen 

non classical logic information retrieval 
computer journal 
varian 

economics search invited talk sigir 
sigir forum 
voorhees harman editors 
proceedings text retrieval conference trec 
nist special publications 
trec nist gov pubs html 
wong yao 

probability distribution model information retrieval 
information processing management 
wong yao 

modeling information retrieval probabilistic inference 
acm transactions information systems 
wurman 

information anxiety 
doubleday 
xu croft 

query expansion local global document analysis 
proceedings sigir pages 
zhai 

fast statistical parsing noun phrases document indexing 
th conference applied natural language processing anlp pages 
zhai lafferty 

model feedback kl divergence retrieval model 
tenth international conference information knowledge manage ment cikm pages 
zhai lafferty 

study smoothing methods language models applied ad hoc information retrieval 
proceedings sigir pages 
zhai lafferty 

stage language models information retrieval 
proceedings sigir pages 
zhang callan minka 

redundancy detection adaptive filtering 
proceedings sigir pages 

