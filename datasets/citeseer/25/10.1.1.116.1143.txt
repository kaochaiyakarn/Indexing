efficient java rmi parallel programming jason maassen rob van ronald henri bal jacobs vrije universiteit amsterdam java offers interesting opportunities parallel computing 
particular java remote method invocation rmi provides flexible kind remote procedure call rpc supports polymorphism 
sun rmi implementation achieves kind flexibility cost major runtime overhead 
goal article show rmi implemented efficiently supporting polymorphism allowing interoperability java virtual machines jvms 
study new approach implementing rmi compiler java system called manta 
manta uses native static compiler just time compiler 
implement rmi efficiently manta exploits compile time type information generating specialized 
uses efficient rmi protocol fast low level communication protocols 
difficult problem approach support polymorphism interoperability 
consequences polymorphism rmi implementation able download remote classes application runtime 
manta solves problem dynamic bytecode compiler capable compiling linking bytecode running application 
allow interoperability jvms manta implements sun rmi protocol standard rmi protocol addition protocol 
evaluate performance manta benchmarks applications run node myrinet cluster 
time null rmi parameters return value manta times lower sun jdk slightly higher rpc protocol 
high performance accomplished pushing runtime overhead rmi compile time 
study performance differences manta sun rmi protocols detail 
poor performance sun rmi protocol part due inefficient implementation protocol 
allow fair comparison compiled applications sun rmi protocol native manta compiler 
results show manta null rmi latency times lower compiled sun rmi protocol manta efficient rmi protocol results times higher speedups applications 
categories subject descriptors programming techniques concurrent programming distributed programming parallel programming 
programming languages language classifications concurrent distributed parallel languages object oriented languages programming languages processors compilers run time environments general terms languages performance additional key words phrases communication performance remote method invocation authors address division mathematics computer science vrije universiteit de boelelaan hv amsterdam netherlands 
permission digital hard copy part material fee personal classroom provided copies distributed profit commercial advantage acm copyright server notice title publication date appear notice copying permission acm copy republish post servers redistribute lists requires prior specific permission fee 
acm acm transactions programming languages systems vol 
november pages 
maassen 
growing interest java high performance parallel applications 
java clean type safe object oriented programming model support concurrency attractive environment writing reliable large scale parallel programs 
shared memory machines java offers familiar multithreading paradigm 
distributed memory machines clusters workstations java provides remote method invocation rmi object oriented version remote procedure call rpc 
rmi model offers advantages distributed programming including seamless integration java object model heterogeneity flexibility waldo 
unfortunately existing java implementations inferior performance sequential code communication primitives serious disadvantage high performance computing 
effort invested improving sequential code performance replacing original bytecode interpretation scheme just time compilers native compilers specialized hardware burke krall muller proebsting 
communication overhead rmi implementations remains major weakness 
rmi designed client server programming distributed web systems network latencies order milliseconds typical 
tightly coupled parallel machines latencies unacceptable 
pentium pro myrinet cluster example sun jdk implementation rmi obtains null rmi latency roundtrip time rmi parameters return value compared user level remote procedure call protocol part large overhead caused inefficiencies jdk implementation rmi built hierarchy stream classes copy data call virtual methods 
serialization method arguments converting arrays bytes implemented recursively inspecting object types primitive types reached invoking primitive 
performed runtime remote invocation 
inefficiencies jdk implementation rmi second reason slowness rmi difference rpc rmi models 
java rmi model designed flexibility interoperability 
rpc allows classes unknown compile time exchanged client server downloaded running program 
java actual parameter object rmi subclass class method formal parameter 
polymorphic object oriented languages dynamic type subclass method static type formal parameter 
subclass known receiver fetched file server downloaded receiver 
high level flexibility key distinction rmi rpc waldo 
rpc systems simply static type formal parameter type converting actual parameter lack support polymorphism break object oriented model 
acm transactions programming languages systems vol 
november 
efficient java rmi key problem obtain efficiency rpc flexibility java rmi 
article discusses compiler java system called manta designed scratch efficiently implement rmi 
manta replaces sun runtime protocol processing possible compile time analysis 
manta uses native compiler generate efficient sequential code specialized serialization routines serializable argument classes 
manta sends type descriptors argument classes destination machine rmi 
way protocol overhead pushed compile time critical path 
problems approach interface java virtual machines jvms address dynamic class loading 
required support interoperability polymorphism 
interoperate jvms manta supports sun rmi serialization protocol addition protocol 
dynamic class loading supported compiling methods generating runtime 
general strategy manta frequent case fast 
manta designed parallel processing assume frequent case communication manta processes running example different nodes cluster 
manta supports infrequent case communication jvms slower approach 
manta rmi system logically consists parts fast communication protocol manta processes 
call protocol manta rmi emphasize delivers standard rmi programming model user communication manta processes 
additional software manta rmi system compatible standard rmi manta processes communicate jvms 
refer combination parts manta rmi system 
term sun rmi refer standard rmi protocol defined rmi specification sun microsystems 
note manta rmi sun rmi provide programming model wire formats incompatible 
manta rmi system combines high performance flexibility interoperability rmi 
grid computing application foster kesselman example clusters run manta software communicate internally manta rmi protocol 
machines may run jvms containing example graphical user interface program 
manta communicates machines sun rmi protocol allowing method invocations manta jvms 
manta implements functionality required rmi specification including heterogeneity multithreading synchronized methods distributed garbage collection 
manta currently implement java security model system primarily intended parallel cluster computing 
fast flexible black white tropical fish indonesian 
acm transactions programming languages systems vol 
november 
maassen main contributions article follows 
show rmi implemented efficiently obtain performance close rpc systems 
null rmi latency manta rmi myrinet slower rpc protocol 
show high performance achieved supporting polymorphism interoperability jvms dynamic bytecode compilation multiple rmi protocols 
give detailed performance comparison manta sun rmi protocols benchmarks collection parallel applications 
allow fair comparison compiled applications sun rmi protocol native manta compiler 
results show manta protocol results times higher speedups applications 
remainder article structured follows 
design implementation manta system discussed section 
section give detailed analysis communication performance system 
section discuss performance parallel applications 
section look related 
section presents 

design implementation manta section discuss design implementation manta rmi system includes manta rmi protocol software extensions manta compatible sun rmi 
manta structure manta designed high performance parallel computing uses native compiler jit 
important advantage native compiler perform time consuming optimizations potentially generate better code 
manta system illustrated 
box middle describes structure manta process contains executable code application de serialization routines generated manta native compiler 
manta processes communicate manta rmi protocol wire format 
manta process communicate jvm box right sun rmi protocol standard rmi format format defined sun rmi specification 
manta manta rmi performed manta protocol described detail section 
manta manta communication common case high performance parallel programming system optimized 
manta serialization protocols support heterogeneity machines different byte orderings alignment properties 
manta jvm rmi performed slower protocol compatible rmi specification standard rmi wire format 
manta uses acm transactions programming languages systems vol 
november 
fig 

manta jvm interoperability 
efficient java rmi generic routines de serialize objects standard format 
routines reflection similar sun implementation 
routines written manta runtime system execute efficiently sun implementation partly written java 
support polymorphism manta jvms manta application able handle bytecode processes 
manta application requests bytecode remote process manta invoke bytecode compiler generate metaclasses de serialization routines object code methods generated manta source code compiler 
dynamic bytecode compilation described detail section 
dynamically generated object code linked application operating system dynamic linking interface 
remote process requests bytecode manta application jvm bytecode loader retrieves bytecode requested class usual way shared filesystem daemon 
sun compiler generate bytecode compile time 
structure manta system complicated jvm 
complexity implementing manta efficiently due need interface system native code compiler bytecode system 
fast communication path system straightforward manta protocol just calls compiler generated serialization routines uses simple scheme communicate manta processes 
fast communication path described 
serialization communication rmi systems split major components low level communication rmi protocol stream management method dispatch serialization 
discuss manta protocol implements component 
low level communication 
rmi implementations typically built top tcp ip designed parallel processing 
manta uses panda communication library bal efficient implementations variety networks 
panda uses scatter gather interface minimize number memory copies resulting high throughput 
acm transactions programming languages systems vol 
november 
maassen fig 

structure sun manta rmi protocols shaded layers run compiled code 
myrinet panda uses lfc communication system provides reliable communication 
lfc network interface protocol myrinet efficient provides right functionality parallel programming systems 
lfc implemented partly embedded software runs myrinet network interface processor partly library runs host 
avoid overhead operating system calls myrinet network interface mapped user space lfc panda run entirely user space 
current lfc implementation offer protection myrinet network single process 
fast ethernet panda implemented top udp way sliding window protocol obtain reliable communication 
ethernet network interface managed kernel protected way panda rpc protocol runs user space 
panda rpc interface upcall model conceptually new thread control created message arrives execute handler message 
interface designed avoid thread switches simple cases 
active message handlers von eicken upcall handlers panda allowed block enter critical section handler allowed wait message arrive 
restriction allows implementation handle messages single thread handlers execute blocking need context switches 
rmi protocol 
runtime system manta rmi protocol written designed minimize serialization dispatch overhead copying buffer management fragmentation thread switching indirect method calls 
gives overview layers manta rmi protocol compares layering sun rmi system 
acm transactions programming languages systems vol 
november 
efficient java rmi shaded layers denote statically compiled code white layers mainly jit compiled java contain native calls 
manta avoids stream layers sun rmi 
rmi parameters serialized directly lfc buffer 
jdk stream layers written java overhead depends quality java implementation 
manta layers implemented compiled code compiler generated native code 
native code generated manta compiler calls rmi directly slow java native interface 
heterogeneity little big machines handled sending data native byte order sender having receiver conversion necessary 
optimization manta rmi protocol avoiding thread switching overhead receiving node 
general case invocation serviced receiving node newly allocated thread runs concurrently application threads 
approach allocation new thread context switch thread critical path rmi 
reduce allocation overhead manta runtime system maintains pool preallocated threads thread taken pool allocated 
addition manta avoids context switching overhead simple cases 
manta compiler determines remote method may block 
compiler guarantee method block receiver executes method doing context switch separate thread 
case current application thread service request continue 
compiler currently conservative estimation guarantees nonblocking property methods call methods create objects invoke garbage collector may cause method block 
analysis conservative deadlock situation occur application thread services method blocks 
manta rmi protocol cooperates garbage collector keep track machine boundaries 
manta uses local garbage collector mark sweep algorithm 
machine runs local collector dedicated thread activated runtime system user 
distributed garbage collector implemented top local collectors counting mechanism remote objects distributed cycles remain undetected 
manta process communicates jvm uses distributed garbage collection algorithm sun rmi implementation leasing 
serialization protocol 
serialization method arguments important source overhead existing rmi implementations 
serialization takes java object converts serializes array bytes making deep copy includes referenced subobjects 
sun serialization protocol written java uses reflection determine type object runtime 
sun rmi implementation uses serialization protocol converting data sent network 
process serializing arguments method called marshalling 
acm transactions programming languages systems vol 
november 
maassen manta protocol serialization code generated compiler avoiding overhead reflection 
serialization code classes generated compile time 
serialization code classes locally available generated runtime bytecode compiler 
overhead runtime code generation incurred time new class argument method invocation 
subsequent uses efficient serializer code available reuse 
manta compiler generates marshalling code methods 
compiler generates method specific marshall functions call generated routines serialize deserialize arguments method 
method method table pointers maintained dispatch right depending dynamic type object 
similar optimization serialization object pointers method table serializer object 
particular object serialized method pointer extracted method table object dynamic type serializer invoked 
procedure applied 
manta serialization protocol performs optimizations simple objects 
array elements primitive type serialized doing direct memory copy lfc buffer array need traversed done jdk 
order detect duplicate objects marshalling code uses table containing objects serialized 
method contain parameters objects table built simple methods faster 
optimization concerns type descriptors parameters rmi call 
serialized object sent network descriptor type sent 
sun rmi protocol sends complete type descriptor class remote method including name package class version number description fields class 
information sent rmi call information class reused single rmi call 
manta rmi protocol machine sends type descriptor machine 
time type sent certain machine type descriptor sent type new type id specific receiver 
objects type sent destination machine type id reused 
destination machine receives type descriptor checks knows type 
loads local disk server 
inserts type id pointer metaclass table 
scheme ensures type information sent remote node 
generated marshalling code figures illustrate generated marshalling code 
consider class 
square method called machine compiler generates marshalling unmarshalling code 
acm transactions programming languages systems vol 
november 
import java rmi import java rmi server public class extends implements int value string name efficient java rmi synchronized int square int string string throws value name system println return fig 

simple remote class 
marshall square class int class string class string opcode call create thread request message created write network 
receive reply 
opcode opcode opcode exception class exception exception throw exception exception result return result fig 

generated pseudocode square method 
square class int class string class string result call java function square exception exception opcode exception exception opcode result call result reply message created write network 
fig 

generated pseudocode square method 
acm transactions programming languages systems vol 
november 
maassen generated square method shown pseudocode 
square strings parameters objects java table built detect duplicates 
special create thread flag set header data structure square potentially blocks contains method call may block wait creates objects may trigger garbage collection may block 
calls serialize string objects buffer 
actual writing network buffer 
function initiates reading reply 
pseudocode generated shown 
header unpacked called 
create thread flag header set run separate thread obtained thread pool 
know 
note parameter unpacked valid machine run 
dynamic bytecode compilation support polymorphism manta program able handle classes exported jvm statically compiled manta program 
accomplish manta rmi system contains bytecode compiler translate classes object code runtime 
describe bytecode compiler 
manta uses standard dynamic linker link object code running application 
jdk compiler reads bytecode file server 
generates manta metaclass dummy function entries method table 
new class may subclass unknown classes bytecode compiler invoked recursively referenced unknown classes 
subsequently instruction stream bytecode method compiled function 
method stack space virtual machine stack determined compile time local stack area declared function 
operations local variables compiled straightforward way 
virtual function calls field resolved running application including newly generated metaclasses 
jumps exception blocks implemented labels gotos nonlocal gotos setjmp longjmp 
resulting file compiled system compiler linked running application system dynamic linker called dlopen unix implementations 
dummy entries created metaclass method tables resolved function pointers dynamically loaded library 
optimizations implemented large impact speed generated code keeping method stack registers 
trivial implementation method stack maintain array bit words size stack area current method 
bytecode verification requires stack offsets computed statically possible replace array series variables calls increment decrement stack pointer avoided acm transactions programming languages systems vol 
november 
fig 

example manta interoperability 
efficient java rmi compiler keep stack registers 
problem jvm bit variables spread contiguous stack locations 
solve maintaining parallel stacks bit bit words 
bytecode instructions typed need operate relevant stack 
infrequently instructions dup family copy bit words bit word operate stacks 
memory waste duplicate stack moderate compiler remove unreferenced local variables 
optimization application speed compiled bytecode generally compiled manta code 
example application manta rmi interoperability dynamic class loading useful interoperate software runs jvm uses sun rmi protocol 
example consider parallel program generates output visualized 
parallel program compiled manta uses manta rmi protocol 
software visualization system may run sun jdk sun rmi protocol 
illustrate type interoperability implemented simple example graphical version parallel applications successive overrelaxation see section 
computation performed parallel program compiled manta runs cluster computer see 
output visualized display workstation graphical user interface gui application written java 
parallel application repeatedly performs iteration sor algorithm collects data dimensional array node cluster called coordinator 
coordinator passes array sun rmi protocol remote viewer object part gui application workstation 
viewer object creates window displays data 
gui application running sun jdk communication coordinator gui uses sun rmi protocol 
manta nodes internally manta rmi protocol 
rmi coordinator gui implemented remote viewer interface rmi stub needed 
stub compiled manta executable coordinator node dynamically acm transactions programming languages systems vol 
november 
maassen retrieves bytecode stub code base gui compiles manta dynamic bytecode compiler links application 

communication performance section communication performance manta rmi compared implementations sun rmi 
experiments run homogeneous cluster pentium pro processors containing mhz pentium pro mbyte main memory 
boards connected different networks gbit sec myrinet boden fast ethernet mbit ethernet 
system runs redhat linux kernel version 
manta sun rmi run myrinet fast ethernet 
comparison systems sun rmi sun blackdown jdk jit ibm jdk jit sun rmi system jdk compiled native manta compiler 
systems built interface run myrinet 
describe systems detail section including important optimizations 
sun system compiled manta turned fastest rmi systems system sections represent sun rmi protocol 
discuss latency section throughput section obtained manta rmi sun rmi 
analyze impact optimizations protocols section 
implementation sun rmi myrinet difference manta sun jdk manta uses native compiler jdk uses jit 
sequential speed code generated manta compiler better sun jdk jit system comparable ibm jdk jit 
overhead java native interface differences sequential code speed obscures comparison manta sun rmi protocols 
allow fair comparison built third system uses sun rmi java rmi code compiled native manta compiler 
system called sun compiled 
discuss system optimizations implemented sun rmi protocol myrinet 
sun compiled system 
built sun rmi system compiling sun rmi code manta 
sun native code replaced new manta native code 
native code object serialization interfacing network layer 
new object serialization code similar sun implementation reflection convert objects bytes 
improve performance reimplemented larger part serialization code new native code exploit knowledge memory layout objects directly class information data fields object calling reflection mechanism java sun jdk 
sun jdk expensive java native interface calls required convert scalar acm transactions programming languages systems vol 
november 
efficient java rmi types long double bytes writing output stream 
new code values written directly stream buffer converting fly 
interfacing myrinet 
run sun jdk ibm jdk sun compiled system myrinet socket interface top panda myrinet 
socket interface called reimplementation berkeley rodrigues 
main virtues zero copy streams mapping socket messages panda messages performance quite close panda sun api currently allow replacement sockets alternative implementation marginal change api necessary 
sufficient declare constructor class java net public 
api problem registered sun bug database 
performance optimizations sun rmi 
describe performance problems addressed layer allow fairer comparison manta 
general tried eliminate important sources overhead sun rmi far optimizations done layer 
particular optimized interaction thread package garbage collector 
problem socket calls send receive accept connect blocking sense suspend calling process system call completely serviced 
java applications multithreaded semantics blocking calls caller thread suspended runnable thread process scheduled deadlock may occur 
virtual machine implementations handle blocking system calls thread package sockets set nonblocking mode blocking calls intercepted threads block suspended 
thread scheduler polls sockets call posted wakes suspended thread action performed socket 
functionality block thread schedule exported virtual machine implementations 
emulate interface layer 
sockets set nonblocking mode interface layer 
naive emulation blocking thread invoke thread yield socket call completed 
performance reasons important blocking mechanism involve unnecessary thread switches multiple threads usually scheduled thread server listens registry 
penalty hundreds microseconds rmi kernel involved thread switch 
implementation uses condition variables condition synchronization 
implemented java 
manta thread package exports condition variables native functions 
thread block enters wait state 
signaled poller thread notices socket ready 
role poller thread taken blocked threads separate poller thread involves thread switches 
usually thread switches incurred critical path rmi latency test 
acm transactions programming languages systems vol 
november 
maassen table null rmi latency throughput myrinet fast ethernet latency throughput system version network mbyte sun jit blackdown myrinet ibm jit sun compiled manta rmi panda rpc sun jit blackdown fast ethernet ibm jit sun compiled manta rmi panda rpc second optimization performed concerns garbage collection 
problem create objects garbage invocation 
manta compiler provides support server side determines objects argument result invocation may escape object retained outside rmi invocation 
manta allows objects immediately returned heap 
sun compiled system modified sun skeleton compiler generated skeletons compiler information 
substantially improved latency throughput objects arguments return value see section 
mechanism jdk explicitly free objects apply technique sun ibm jdk 
garbage collector responsible low throughput achieved fast ibm jdk system 
performance 
table shows null rmi latency throughput various rmi implementations myrinet fast ethernet 
myrinet manta rmi obtains null rmi latency sun jdk just time compilation enabled obtains latency times higher 
sun compiled obtains null rmi latency times slower manta rmi 
comparison ibm jit obtains latency measured redhat linux 
sun compiled system uses efficient locking sun ibm jits manta user space thread package faster native interface 
reduces garbage collection overhead objects passed rmi calls 
sequential code speed better sun jdk jit comparable ibm jit 
table gives performance conventional remote procedure call protocol panda library bal implemented seen performance manta protocol comes close panda rpc 
throughput obtained manta rmi sending large array integers better sun jdk mbyte versus mbyte myrinet 
throughput sun compiled mbyte times manta rmi better sun jdk 
table gives performance results fast ethernet 
relative differences smaller communication costs higher 
acm transactions programming languages systems vol 
november 
efficient java rmi table ii 
breakdown manta sun compiled rmi pentium pro myrinet times manta sun compiled empty object objects objects empty object objects objects serialization rmi overhead communication method call total sun compiled system far efficient implementation sun rmi protocol system sections represent sun protocol 
latency breakdown time manta sun compiled spend remote method invocations 
benchmark zero empty objects objects data fields parameters having return value 
benchmarks written way trigger garbage collection 
results shown table ii 
measurements done inserting timing calls pentium pro performance counters granularity nanoseconds 
serialization overhead includes costs serialize arguments client side deserialize server side 
rmi overhead includes time initiate rmi call client handle upcall server process reply client excludes time de serialization method invocation 
communication overhead time initiating transfer receiving reply minus time spent server side 
manta measurements include costs sending type descriptors sent 
simplest case empty method parameters null rmi 
myrinet null rmi takes manta 
added roundtrip latency panda rpc 
large difference passing zero object parameters explained follows 
runtime system build table detect possible cycles duplicates objects 
second containing object parameters serviced dedicated thread thread pool may block triggering garbage collection 
thread switching overhead case 
creation parameter object increases latency 
sun compiled system null rmi myrinet takes times slower manta optimizations applied 
manta rmi obtains major performance improvements layers compiler generated win factor rmi overhead times lower communication protocols times faster 
study latency manta rmi sun compiled protocol various combinations input parameters return values 
similar acm transactions programming languages systems vol 
november 
maassen table iii 
rmi latency myrinet manta sun compiled different parameters return values 
latencies measured mhz digital alpha slow jit 
benchmark manta sun compiled void void void int int int tree tree float float benchmarks described karlsruhe rmi system 
results shown table iii 
comparison include latency myrinet obtained taken 
measurements done mhz digital alpha obtained jdk low quality jit 
manta rmi compatible sun rmi uses compact serialization format format specified rmi standard 
benchmarks empty return value remaining benchmarks return value passed input parameter 
int benchmark sends receives object containing integers 
tree benchmarks send receive balanced trees nodes containing integers 
benchmarks transfer arrays floating point numbers 
seen table manta rmi obtains lower latencies benchmarks sun compiled system 
manta rmi obtains better performance 
throughput study rmi throughput manta sun compiled 
benchmark measures throughput remote method invocation various types arguments return value 
synchronous sender wait remote method return 
benchmark performs bytes arguments 
reply message empty 
results shown table iv 
manta achieves throughput mbyte arrays integers compared mbyte underlying panda rpc protocol see table 
comparison throughput sun compiled mbyte throughput sun compiled arrays integers substantially higher sun jit mbyte versus mbyte see table due optimizations described section 
throughput sun compiled lower manta rmi 
sun serialization protocol internally buffers messages sends large messages chunks kbyte decreases throughput 
important sun rmi sun compiled performs unnecessary byte swapping 
sender receiver format integers format differs standard rmi format 
sun compiled uses serialization convert data standard format 
manta rmi hand sends data format sender lets receiver byte swapping necessary 
acm transactions programming languages systems vol 
november 
table iv 
rmi throughput mbyte myrinet manta sun compiled different parameters manta sun compiled array bytes array integers array floats array doubles binary tree efficient java rmi throughput obtained sun compiled system array bytes byte swapping needed mbyte see table iv 
throughput high layers sun system short cuts long messages 
writing large buffer layer passes buffer directly layer copying 
similarly large read request done passed bottom layer result passed back copying 
throughput test available philippsen 
throughput array kbyte myrinet mbyte half throughput manta rmi 
low throughput attributed overhead thread scheduling interaction java threads system threads philippsen 
binary tree throughput benchmark latency benchmark described input parameters return values 
benchmark sends balanced trees nodes containing integers 
reported throughput user payload integers information sent network rebuild tree structure 
throughput benchmark low comparison throughput achieved arrays 
overhead attributed small size nodes dynamic nature data type especially de serialization expensive tree written read network buffer tree node time sun compiled byte time overhead network access incurred arrays 
impact specific performance optimizations analyze impact specific optimizations detail 
type descriptors 
explained section sun protocol sends complete type descriptor class rmi 
manta rmi sends type information class uses type id subsequent calls 
amount data manta rmi sends object array parameters depends parameter class transmitted 
table shows amount data sent cases manta rmi sun compiled rmi 
case table gives number bytes arguments element array integer argument single object containing integer double 
shows times mhz pentium pro write type descriptor sending side read receiving side 
acm transactions programming languages systems vol 
november 
maassen table amount data sent manta rmi sun rmi runtime overhead type descriptors manta rmi sun compiled rmi empty int object empty int object bytes type descriptor bytes type id writing type descriptor reading type descriptor seen type descriptor optimization saves bytes array object parameter 
runtime costs saved optimization reading writing type descriptors arrays objects 
type descriptor includes name class 
single letter class name package benchmark optimization wins classes longer names 
sun rmi protocol sends moderately data manta protocol spends considerable amount time processing communicating data 
sun protocol spends handling type descriptors arrays objects 
pays price invocation manta protocol incurs overhead 
scatter gather interface 
explained section panda library manta built uses scatter gather interface minimize number memory copies needed 
optimization increases throughput manta rmi 
assess impact optimization measured throughput obtained sender extra memory copy 
case maximum throughput decreases mbyte memory copies expensive pentium pro brown seltzer 
experiment clearly shows importance scatter gather interface 
unfortunately dereferencing scatter gather vector involves extra processing null rmi latency current manta rmi system slightly higher earlier panda version scatter gather interface versus maassen 
reducing byte swapping 
optimization increases throughput avoid byte swapping identical machines 
described section sun rmi sender converts arguments rmi call wire format defined rmi specification receiver converts format back requires 
manta hand data transmitted native byte order sender receiver conversion necessary 
sender receiver format format different standard rmi format sun rmi byte swap conversions manta byte swapping 
measured impact optimization adding byte swapping code sender side manta rmi 
code normal manta system sender byte swapping manta 
byte swapping performed sender receiver sun rmi throughput manta rmi arrays integers floats decreases acm transactions programming languages systems vol 
november 
efficient java rmi factor 
maximum throughput obtained byte swapping enabled decreased mbyte experiment clearly shows unnecessary byte swapping adds large overhead partly due extra memory copies needed 
escape analysis 
described section implemented simple form escape analysis 
analysis objects argument result rmi escape method immediately returned heap 
optimization objects subject garbage collection reduces rmi throughput 
escape analysis throughput manta reduced mbyte sun compiled throughput byte arrays reduced mbyte throughput numbers hardly affected cases suffer forms overhead particular byte swapping 

application performance low level benchmarks show manta obtains substantially better latency throughput sun rmi protocol 
parallel programming relevant metric efficiency obtained applications 
determine impact rmi protocol application performance written parallel applications different granularities 
briefly describe applications input sizes discuss performance manta sun compiled 
application program typically creates remote objects needed interprocess communication exchanges objects machines 
overhead distributed garbage collection counting occurs initialization hardly impact application performance 
sor 
red black sor successive overrelaxation iterative method solving discretized laplace equations grid 
program distributes grid rowwise processors 
processor exchanges row matrix neighbors iteration 
grid input 
asp 
asp pairs shortest paths program computes shortest path nodes node graph 
uses distance table distributed rowwise processors 
iteration processor needs send row matrix processors 
java lacks broadcasting expressed communication pattern spanning tree 
processor forwards message binary spanning tree processors threads 
radix histogram parallel sort program splash suite woo 
rewritten program java rmi 
program repeatedly performs local sort phase communication followed histogram merge phase 
merge phase uses combining tree communication transfer histogram information 
merge phase program acm transactions programming languages systems vol 
november 
maassen moves keys processors requires 
radix program performs large number 
array numbers input 
fft fast fourier transform program splash code rewrote java 
matrix partitioned rowwise different processors 
fft communication pattern personalized exchange implemented rmi pair machines 
matrix elements 
water splash application rewrote java 
simulation parallelized distributing bodies molecules processors 
communication primarily required compute interactions bodies assigned remote machines 
java program uses message combining obtain high performance processor receives bodies needs machine single rmi 
operation updates sent rmi destination machine 
water algorithm optimized communication relative communication overhead low 
bodies measurements 
barnes hut log body simulation 
wrote java program code suel 
code optimized distributed memory architectures 
finding runtime bodies needed compute interaction splash version barnes hut code bodies needed sends collective communication phase actual computation starts 
way stalls occur computation phase suel 
problem bodies 
figures show speedups applications obtained manta sun compiled 
systems programs compiled statically manta compiler 
speedups system computed relative parallel manta program single cpu 
sequential execution times manta sun compiled similar applications compiled manta compiler systems applications manta slightly faster due caching effects 
table vi gives performance data applications including total number messages sent summed cpus amount data transferred cpus 
numbers measured panda layer include header data 
manta rmi generates panda messages request reply 
figures show manta higher communication performance results substantially better application speedups 
sun compiled performs applications water asp 
water far lowest communication overhead applications 
cpus sends messages mbytes second sun compiled 
asp communicates water performs relatively second 
applications manta obtains better maximal speedups ranging factor barnes hut radix sor 
acm transactions programming languages systems vol 
november 
efficient java rmi fig 

speedup asp 
fig 

speedup sor 
fig 

speedup radix 
fig 

speedup fft 
fig 

speedup water 
fig 

speedup barnes hut 
manta obtains high efficiencies applications radix sort 
radix sends largest number volume messages second applications cpus sends messages mbytes second summed cpus 
table vi shows sun rmi protocol sends far messages applications manta sun serialization protocol buffers messages transfers large messages chunks kbytes see section 
volume data transferred manta protocol somewhat lower acm transactions programming languages systems vol 
november 
maassen table vi 
performance data manta sun compiled cpus time cpus data time cpus data program system messages mbyte messages mbyte asp manta sun compiled sor manta sun compiled radix manta sun compiled fft manta sun compiled water manta sun compiled barnes hut manta sun compiled sun protocol manta send type descriptors class call manta sends fewer messages fewer headers 

related discuss related areas optimizations rmi fast communication systems parallel programming java 
optimizations rmi 
rmi performance studied papers 
new rmi serialization package drop replacement designed improve rmi performance philippsen 
manta performance better see table iii section 
main reasons manta uses static compilation completely native runtime system implemented 
manta exploits features underlying communication layer scatter gather interface 
uses low quality jit jdk cited publications runtime system written java suffers poor jit performance 
designed portable avoids native code throughput improved certain cases designers deliberately chose require native code 
manta hand developed scratch obtain high communication performance 
manta rmi wire format different standard rmi format 
krishnaswamy improve rmi performance somewhat caching udp tcp 
rmi implementation high latencies report null rmi latencies millisecond fast ethernet 
implementation requires modifications extensions interfaces rmi framework 
javanaise java systems implement object caching 
javanaise proposes new model distributed shared objects alternative rmi 
study rmi performance interoperability 
provide performance figures rmi rmi systems fast ethernet 
acm transactions programming languages systems vol 
november 
efficient java rmi fast communication systems 
research done improving performance remote procedure call protocols hutchinson johnson zwaenepoel van renesse schroeder burrows thekkath levy 
important ideas resulted research including compiler generated un marshalling routines avoiding thread switching layering overhead need efficient low level communication mechanisms 
ideas today communication protocols including rmi implementations 
support polymorphism manta compiler generated serialization similar orca serialization bal 
optimization nonblocking methods similar single threaded upcall model langendoen 
small nonblocking procedures run interrupt handler avoid expensive thread switches 
optimistic active messages related technique rollback runtime wallach 
kernel level tcp ip manta uses panda top lfc highly efficient user level communication substrate 
lessons learned implementation languages cluster computing useful 
implementations built user level communication primitives active messages von eicken 
examples concert karamcheti chien crl johnson orca bal split culler jade rinard 
projects fast communication extensible systems spin bershad exo kernel kaashoek scout mosberger peterson 
projects currently studying protected user level network access java chang von eicken welsh culler 
systems support remote method invocation 
parallel programming java 
projects parallel programming java exist 
titanium yelick java language high performance parallel scientific computing 
extends java features immutable classes fast multidimensional array access explicitly parallel spmd model communication 
titanium compiler translates titanium built split active messages back 
system philippsen zenger designed ease parallel cluster programming java 
particular goal run multithreaded programs little change possible workstation cluster 
allows methods class invoked remotely adding remote keyword class declaration removes need elaborate exception catching remote method invocations importantly allows objects threads created remotely 
manta optionally allows similar programming model supports standard rmi programming model 
originally implemented top sun rmi suffered performance problem sun rmi 
current implementation uses 
see example web page www org 
acm transactions programming languages systems vol 
november 
maassen spar java data task parallel programming language semiautomatic parallel programming van 

project tries ease parallel programming java parallel distributed frameworks 
java system supports object migration 
java programming systems exist developing wide area metacomputing applications alexandrov christiansen 
alternative parallel programming java mpi rmi 
mpi bindings java exist carpenter judd 
approach advantage programmers familiar mpi mpi supports richer set communication styles rmi particular collective communication 
mpi message passing communication style difficult integrate cleanly java object oriented model 
mpi assumes spmd programming model quite different java multithreading model 
current mpi implementations java suffer performance problem rmi implementations high overhead java native interface 
example java mpi system described latency calling mpi java higher calling mpi versus measured sp 
icet gray sunderam uses message passing rmi 
enables users share java virtual machines network 
user upload class virtual machine pvm interface 
explicitly calling send receive statements distributed multiple jvms 
alternative rmi distributed shared memory dsm system 
dsm systems java exist providing shared memory programming model rmi executing distributed memory system 
java dsm yu cox implements jvm top treadmarks dsm keleher 
explicit communication necessary communication handled underlying dsm 
hu dsm system java treadmarks allows efficient fine grained sharing 
macbeth tries execute multithreaded shared memory java programs machine 
caches objects local working memory allowed java memory model 
cached objects flushed back original locations main memory entry exit synchronized statement 
software fine grained dsm java manta compiler 
cjvm java system tries hide distribution provides single system image 

article investigated implement java remote method invocation efficiently goal flexible communication mechanism parallel programming 
reducing overhead rmi challenging acm transactions programming languages systems vol 
november 
efficient java rmi communication primitives remote procedure call rmi implementations support interoperability polymorphism 
approach problem frequent case fast 
designed new rmi protocol supports highly efficient communication machines implement protocol 
communication java virtual machines running sun rmi protocol possible slower 
example machines parallel system communicate efficiently protocol communicate interoperate machines running java implementations visualization system 
implemented new rmi protocol called manta rmi java system called manta designed scratch highperformance parallel computing 
manta uses native java compiler support polymorphism java implementations capable dynamically compiling linking bytecode 
efficiency manta rmi due factors compile time type information generate specialized streamlined efficient rmi protocol fast communication protocols 
understand performance implications optimizations compared performance manta sun rmi protocol 
unfortunately current implementations sun protocol inefficient making fair comparison difficult task 
address problem built implementation sun rmi compiling sun protocol manta native compiler 
reduced overhead system native calls thread switching temporary objects 
system called sun compiled achieves better latency throughput sun jdk ibm jit system measurements article particular compare manta sun rmi protocols 
performance comparison myrinet pentium pro cluster shows manta rmi substantially faster compiled sun rmi protocol 
myrinet null rmi latency improved factor sun compiled slower rpc 
breakdown manta sun compiled shows manta obtains major performance improvements layers 
differences original sun jdk implementation rmi higher example null rmi latency jdk myrinet times high manta 
throughput obtained manta rmi better sun compiled 
cases sun protocol performs unnecessary byte swapping resulting times lower throughput manta low level latency throughput benchmarks give useful insight performance communication protocols relevant factor parallel programming impact application performance 
implemented collection parallel java programs rmi 
performance measurements cpus show programs obtain high efficiency manta applications perform sun compiled 
manta obtains times higher speedups applications 
shown rmi implemented efficiently remote procedure call high performance networks acm transactions programming languages systems vol 
november 
maassen myrinet keeping inherent advantages rmi polymorphism interoperability 
showed efficient rmi implementation basis writing high performance parallel applications lack broadcast support complicates programming applications 
adding support broadcast rmi replicating shared objects topic ongoing research maassen 
acknowledgments supported part vrije universiteit 
kees contributions project 
keen criticism 
reviewers valuable comments earlier version 
ronald martijn thieme developing java applications 
alexandrov schauser 
research issues java global computing 
concurrency pract 
exper 
june 
hatcher macbeth 
compiling multithreaded java bytecode distributed execution 
proceedings euro par 
lncs springer nchen germany 
factor 
cjvm single system image jvm cluster 
proceedings international conference parallel processing aizu japan 
bal jacobs langendoen hl kaashoek 
performance evaluation orca shared object system 
acm trans 
comput 
syst 
feb 
bal jacobs langendoen 
performance high level parallel language high speed network 
parallel distrib 
comput 
feb 
blumofe brewer 
atlas infrastructure global computing 
proceedings seventh acm sigops european workshop system support worldwide applications 
acm new york ny 
bershad savage pardyak sirer becker fiuczynski chambers eggers 
extensibility safety performance spin operating system 
proceedings th acm symposium operating system principles sosp 
acm new york ny 
hl bal 
evaluating design alternatives reliable communication high speed networks 
proceedings th international conference architectural support programming languages operating systems asplos cambridge ma 
suel 
highly portable efficient implementations parallel adaptive body methods 
sc 
online www org sc program tech 
boden cohen seitz su 
myrinet gigabit second local area network ieee micro jan 
diwan balasubramanian akman gannon 
java rmi performance object model interoperability experiments java hpc distributed components 
proceedings acm workshop java high performance network computing santa barbara ca acm new york ny 
acm transactions programming languages systems vol 
november 
efficient java rmi brown seltzer 
operating system benchmarking wake lmbench case study performance netbsd intel architecture 
proceedings conference measurement modeling computer systems sigmetrics seattle wa 
burke choi fink grove hind sarkar serrano sreedhar srinivasan whaley 
jalapeno dynamic optimizing compiler java 
proceedings acm java grande conference san francisco ca acm new york ny 
carpenter fox ko lim 
object serialization marshalling data java interface mpi 
proceedings acm java grande conference san francisco ca acm new york ny 
chang 
von eicken 
software architecture zero copy rpc java 
tech 
rep cornell univ sept chang 
von eicken 
interfacing java virtual interface architecture 
proceedings acm java grande conference san francisco ca acm new york ny 
christiansen schauser wu 
javelin internet parallel computing java 
concurrency pract 
exper 

culler dusseau goldstein krishnamurthy von eicken yelick 
parallel programming split 
supercomputing 
foster kesselman 
grid blueprint new computing infrastructure 
morgan kaufmann 

mpi java mpi contrasts comparisons low level communication performance 
supercomputing 
portland 
flynn hummel 
high performance parallel programming java exploiting native libraries 
proceedings acm workshop java high performance network computing 
acm new york ny 
gray sunderam 
icet distributed computing java 
concurrency pract 
exper 
nov 

javanaise distributed shared objects internet cooperative applications 
proceedings middleware conference lake district england 
igarashi 
performance evaluation popular distributed object technologies java 
proceedings acm workshop java high performance network computing 
online www cs ucsb edu conferences java 
hu yu cox wallach zwaenepoel 
runtime support distributed sharing strongly typed languages 
tech 
rep rice univ online www cs rice 
edu willy treadmarks papers html 
hutchinson peterson abbott malley 
rpc kernel evaluating new design techniques 
proceedings th acm symposium operating system principles park az 
chan 
environment parallel distributed mobile java applications 
proceedings acm java grande conference san francisco ca 
johnson zwaenepoel 
high performance rpc system 
tech 
rep tr rice univ mar johnson kaashoek wallach 
crl high performance software distributed shared memory 
th acm symposium operating systems principles copper mountain acm new york ny 
judd clement snell 
design issues efficient implementation mpi java 
proceedings acm java grande conference san francisco ca acm new york ny 
kaashoek engler ganger hunt mazi res grimm jannotti mackenzie 
application performance flexibility exokernel systems 
proceedings th acm symposium operating systems principles 
acm new york ny 
acm transactions programming languages systems vol 
november 
maassen karamcheti chien 
concert efficient runtime support concurrent objectoriented programming languages stock hardware 
supercomputing portland 
keleher cox dwarkadas zwaenepoel 
treadmarks distributed shared memory standard workstations operating systems 
proceedings winter usenix conference san francisco ca 
krall 
cacao bit just time compiler 
concurrency pract 
exper 
nov 
online www tuwien ac andi 
krishnaswamy walther riley ahamad 
efficient implementations java rmi 
proceedings th usenix conference object oriented technologies systems coots santa fe nm 
langendoen bal 
models asynchronous message handling 
ieee concurrency april june 



project distributed programming java 
proceedings uk workshop java high performance network computing southampton england 
karamcheti 
object views language support intelligent object caching parallel distributed computations 
proceedings conference object oriented programming systems languages applications 

maassen bal 
efficient replicated method invocation java 
proceedings acm java grande conference san francisco ca acm new york ny 
maassen van bal 
efficient implementation java remote method invocation 
proceedings seventh acm sigplan symposium principles practice parallel programming ppopp atlanta ga acm new york ny 
macbeth hatcher 
executing java threads parallel distributed memory environment 
proceedings cascon 
ibm canada national research council canada 
mosberger peterson 
making paths explicit scout operating system 
proceedings usenix symposium operating systems design implementation 

muller moura consel 
harissa mixed offline compiler interpreter dynamic class loading 
proceedings third usenix conference object oriented technologies coots portland 
philippsen 
efficient rmi java 
proceedings acm java grande conference san francisco ca acm new york ny 
philippsen zenger 
transparent remote objects java 
concurrency pract 
exper 
nov 
online ira uka de 
philippsen 
efficient serialization rmi java 
concurrency pract 
exper 

proebsting townsend bridges hartman 
toba java applications way ahead time wat compiler 
proceedings rd conference object oriented technologies systems portland 
rinard scales lam 
jade high level machine independent language parallel programming 
ieee computer june 
rodrigues anderson culler 
high performance local communication fast sockets 
usenix 
schroeder burrows 
performance firefly rpc 
acm trans 
comput 
syst 
feb 
sun microsystems 

java remote method invocation specification jdk fcs online java sun com products jdk rmi 
thekkath levy 
limits low latency communication high speed networks 
acm trans 
comput 
syst 
may 
acm transactions programming languages systems vol 
november 
efficient java rmi van van sips 
spar programming language semiautomatic compilation parallel programs 
concurrency pract 
exper 
aug 
van renesse van staveren tanenbaum 
performance amoeba distributed operating system softw 
pract 
exper 

bal 
runtime optimizations java dsm implementation 
proceedings acm java grande conference 
acm new york ny 
jacobs bal 
source level global optimizations fine grain distributed shared memory systems 
ppopp symposium principles practice parallel programming 
von eicken culler goldstein schauser 
active messages mechanism integrated communication computation 
proceedings th annual int 
symposium computer architecture gold coast australia 
waldo 
remote procedure calls java remote method invocation 
ieee concurrency july sept 
wallach hsieh johnson kaashoek weihl 
optimistic active messages mechanism scheduling communication computation 
proceedings th acm sigplan symposium principles practice parallel programming ppopp santa barbara ca acm new york ny 
welsh culler 
jaguar enabling efficient communication java 
concurrency pract 
exper 

woo singh gupta 
splash programs characterization methodological considerations 
proceedings nd international symposium computer architecture 
yelick pike miyamoto krishnamurthy hilfinger graham gay colella aiken 
titanium high performance java dialect 
proceedings acm workshop java high performance network computing 
online www cs ucsb edu conferences java 
yu cox 
java dsm platform heterogeneous computing 
concurrency pract 
exper 
nov 
received march revised december accepted may acm transactions programming languages systems vol 
november 
