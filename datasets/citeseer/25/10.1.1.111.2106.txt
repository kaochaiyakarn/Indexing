measurement modelling temporal dependence packet loss maya yajnik sue moon jim kurose don towsley department computer science university massachusetts amherst ma usa emails yajnik kurose towsley cs umass edu understanding modelling packet loss internet especially relevant design analysis delay sensitive multimedia applications 
analysis hours endto unicast multicast packet loss measurement 
selected hours stationary traces analysis 
consider dependence seen autocorrelation function original loss data dependence run lengths loss run lengths 
correlation timescale 
evaluate accuracy models increasing complexity bernoulli model state markov chain model th order markov chain model 
trace segments considered bernoulli model accurate segments state model accurate segments 
markov chain model order greater necessary accurately model rest segments 
case adaptive applications track loss address issues line loss estimation required memory size exponential smoothing sliding window average estimate average loss rate 
find large memory size necessary sliding window average provides accurate estimate effective memory size 
packet loss key factor determining quality seen delay sensitive multimedia applications audio video conferencing internet telephony 
applications experience degradation quality increasing loss delay network 
understanding loss seen applications important design performance analysis 
adaptive audio video applications adjust transmission rate perceived congestion level network see 
adjustment suitable loss level maintained bandwidth shared fairly connections 
adaptive applications important simple loss models parameterized line manner 
careful analysis loss hours measurements 
measurements loss seen packet probes sent regular intervals internet connections 
significant non stationary effects seen data divide traces hour segments check segment stationarity 
gradual decrease increase mean loss rate abrupt dramatic increase loss rate minutes spikes high loss rate observed 
analyze hours stationary trace segments determine extent temporal dependence data 
results show correlation timescale time sent unicast multicast supported national science foundation ncr defense advanced research projects agency agreement 
opinions findings recommendations expressed material author necessarily reflect views national science foundation 
happens packet connected happens packet approximately second 
timescale packet losses independent 
consider loss models increasing complexity estimate level complexity necessary accurately model stationary trace segments 
loss process modelled state discrete time markov chain model corresponds bernoulli model corresponds state markov chain model 
refered order markov chain 
datasets sampling intervals bernoulli model accurate segments state markov model segments markov chain models orders remaining bernoulli state markov chain models accurate traces sampling intervals estimated order markov chain model ranged adaptive multimedia applications track congestion level network order adjust rate transmission share bandwidth fairly maintain low loss level 
information loss network period time traditional packet loss information 
situations line loss estimation useful know past information necessary accurately estimate parameters loss models 
non stationarity observed data shows loss rate vary time dramatically date information important 
need adaptive applications loss rate estimates address question memory necessary line parameter estimator provide accurate estimate 
general variance estimator due limited number samples high large numbers samples required get accurate estimate 
address question exponential smoothing provides better estimate mean loss rate sliding window average 
computationally quicker requiring buffer space exponential smoothing needs twice samples provide estimate accuracy sliding window average 
earlier works measurement unicast multicast packet loss internet noted number consecutively lost packets small :10.1.1.38.3690:10.1.1.32.7807
long outages seconds minutes observed mbone multicast backbone network overlaid internet 
measurements voice traffic ana table trace descriptions date type sampling destination time duration loss seg stationary interval rate ments segments nov unicast ms sics sweden hr nov multicast ms sics sweden hr nov unicast ms sics sweden days dec multicast ms st louis days dec unicast ms seattle hr min dec multicast ms seattle hr min dec unicast ms los angeles hr dec multicast ms los angeles hr jun unicast ms atlanta hr assess effects strategies compensate varying delay loss quality voice connection 
statistical analysis temporal correlation loss data described weak correlation noted 
discrete time markov chain models particularly state markov chain model called gilbert model proposed :10.1.1.32.7807
discrete time markov chain models increasing levels complexity including state markov chain model described :10.1.1.32.7807
takes careful look temporal dependence validity various models packet loss hours stationary data 
remainder structured follows 
section ii describe data collected 
section iii describe ways representing data go discuss analysis stationarity temporal dependence data 
models evaluation accuracy section iv 
section discuss memory size required line estimation model parameters relative suitability exponential smoothing sliding window averaging ways estimating average loss rate 
section vi 
ii 
measurement study loss internet hours traces 
traces gathered sending packet probes unicast multicast connec tions periodic intervals ing sequence numbers probe packets arrived successfully receiver 
packets sequence numbers recorded assumed lost 
ms record loss data represented binary time series takes value probe packet arrived successfully value lost 
interval probe packets sent network referred sampling interval rest 
measurements summarized table source located amherst massachusetts traces 
note multicast trace shown table extremely high loss rate disregarded analysis 
rest refer datasets notation date type example nov uni 
iii 
analysis consider ways representing loss data 
discrete time binary time series values set trace divided portions consecutive called runs portions consecutive called loss runs 
second way rep data interleaving sequences observations run length expressed number packets corresponding loss run length expressed number packets 
remainder section structured follows 
discuss analysis traces stationarity section iii find approximately hours exhibit stationarity 
section iii focus temporal dependence stationary trace segments shown sample autocorrelation function binary time series representation data 
discuss analysis temporal dependence run loss run representation data section iii 
stationarity looking smoothed loss data obvious nonstationarity traces 
traces divided approximately hour segments segment checked stationarity 
rest refer trace segment notation date type segment example nov uni 
time series said stationary strict sense statistical properties remain constant entire series 
time series said stationary wide sense called weak stationarity mean covariance function remain constant time 
way rigorously test stationarity check average loss rate varied significantly trace segments 
smooth trace moving average filter window size packets judge extent variation average loss length trace 
abrupt increases greater average loss rate taken indication non stationarity 
test gradual increase decrease average loss rate fit straight line data minimizes error estimate linear trend 
total change average loss rate greater hour trace segment considered indication non stationarity 
different kinds observed non stationary effects 
example smoothed loss third segment trace nov uni shows slow linear decay loss percentage hour 
slow decays increases noticed traces 
abrupt dramatic increase loss loss lasting approximately minutes abruptly dropping lower autocorrelation observed bounds lag fig 

sample autocorrelation function binary data nov uni loss rate 
abrupt increases noticed traces trace segment shows dramatic increases longest time 
table summarizes results analysis stationarity 
traces dec multi dec multi exhibit periodic behavior period making difficult analyze model 
identify hour segments traces analysis sections 
autocorrelation binary loss data sample autocorrelation function loss data stationary segments expressed binary time series reveals extent dependence loss experienced probe packets time 
section define autocorrelation function correlation timescale describe estimation correlation timescale autocorrelation function discuss results stationary loss data 
stationary sequence random variables realization autocorrelation function defined mean lag 
sample autocovariance function assuming stationarity lag sample mean 
sample autocorrelation function lag expressed terms time 
lag terms time 
sampling interval 
correlation timescale minimum lag terms time uncorrelated lags independent stochastic process autocorrelation function zero stochastic process independent lag autocorrelation function zero autocorrelation nov uni ms jun uni ms dec uni ms lag terms time ms fig 

sample autocorrelation function trace segments lag 
case observed sample sequence realization independent stochastic process sample autocorrelation function non zero small values 
proposition gives idea constitutes significant value sample autocorrelation function number samples see 
proposition large sample autocorrelations iid sequence finite variance approximately iid normal distribution mean variance see 
realization iid sequence approximately sample autocorrelations fall confidence bounds correlation timescale smallest lag terms time value sample autocorrelation function small considered insignificant 
proposition test hypothesis hypothesis independent lag test statistic calculated sample autocorrelation function sample sequence lag follows 
hypothesis true limiting standard normal distribution 
example hypothesis rejected significance level results loss data show correlation small lags sample autocorrelation function decays rapidly 
example consider segment trace nov uni nov uni fig 
shows autocorrelation function binary loss data 
value close zero sample autocorrelation function lag indicates independence samples confidence bounds plotted dotted lines show range values close zero indicate independence 
autocorrelation lag correlation consecutive packets approximately clear lag onwards autocorrelation function small stray points 
means data dependent lag correlation timescale analyze stationary segments traces 
traces nov uni dec multi traces dec uni dec uni trace jun uni trace frequency correlation timescale ms fig 

frequency distribution correlation timescale segments sample autocorrelation functions similar described example trace segment correlation consecutive packets vary average traces autocorrelation function lag approximately higher trace segments 
trace segments show similar high autocorrelation approximately lag values autocorrelation functions traces remain significant lags traces remain significant lags 
fig 
shows sample autocorrelation function lag expressed terms time trace segments nov uni jun uni dec uni respectively 
shows correlation timescale 
correlation timescale data segment estimated smallest lag expressed terms time hypothesis rejected significance level smallest lag time series independent 
note method underestimate correlation timescale autocorrelation function show dependence higher lag ignored effect 
results stationary trace segments summarized fig 
frequency distribution correlation timescale estimated data segment 
correlation timescale cases 
run loss run lengths second way representing data alternating sequences run lengths loss run lengths check dependence runs loss runs plotting autocorrelation function run lengths loss run lengths crosscorrelation function run lengths loss run lengths 
confidence interval proposition assess values correlation functions significant 
sample correlation functions indicate independence segments trace nov uni 
de run lengths seen trace dec multi cases lags 
traces dec uni dec uni exhibit different results 
autocorrelation function loss runs crosscorrelation function runs loss runs show independence loss runs runs loss runs 
runs lengths show dependence lags 
trace jun uni displays independence correlation functions 
step look distributions run loss run lengths 
figures show distribution run lengths distribution loss run lengths nov uni 
figures show distributions predicted models comparison observed data discussed section iv 
evident distribution run lengths decays approximately linearly logscale axis suggesting run lengths distributed 
loss run lengths stationary segments traces show similar results 
distribution run lengths segments traces nov uni dec multi visual inspection appear approximately geometric 
segments excess short run lengths 
loss run lengths greater segments nov uni dec multi 
low number consecutive losses noted earlier :10.1.1.38.3690
distributions run loss run lengths traces dec uni dec uni jun uni look somewhat different 
example distribution run lengths fig 
trace dec uni shows geometric decay high probability burst lengths distribution loss run lengths trace shown fig 
shows approximately geometric decay 
traces dec uni jun uni show similar results 
run lengths nov uni dec multi appear geometrically distributed chi square goodness fit test provide systematic evidence distributions geometric 
compare empirical distribution run lengths exponential continuous valued equivalent geometric distribution gamma distribution 
shape rate parameters computed assuming gamma distribution run lengths 
shape parameter coefficient variation gamma distribution gives idea close distribution exponential distribution value corresponds exponential distribution special case gamma distribution shape parameter segments nov uni varied aver age segments dec multi varied average chi square goodness fit test check reject hypothesis run lengths iid random variables distribution 
hypothesis tested gamma exponential distributions 
hypothesis run lengths iid random variables distribution function 
traces nov uni dec multi hypothesis rejected exponential distribution segments gamma distribution rejected segments 
difficult similarly chi square goodness fit test loss run lengths lengths loss run lengths vary small range 
continuous value distributions easier determine partitions test 
probability length observed bernoulli model state model number packets burst fig 

distribution run lengths nov uni probability length observed bernoulli model state model number packets burst fig 

distribution loss run lengths nov uni iv 
modelling section discuss potential models increasing complexity bernoulli model state markov chain model th order markov chain model modelling data 
loss process characterizes binary time series described section iii consid ered tic process 
order markov process number previous values process current value depends measure complexity model 
bernoulli model order states 
state markov chain model order th order markov chain model generalization models states 
section iv describe models associated parameter estimators 
section iv assess validity models stationary trace segments 
models bernoulli loss model state stationary discrete time bernoulli loss model sequence random variables iid independent identically distributed 
probability independent values time series probabilities irrespective model characterized single parameter probability corresponds lost packet 
estimated sample trace number times value occurs observed time series number samples time series 
average loss rate 
run length distribution model loss run length distribution probability length observed bernoulli model state model number packets burst fig 

distribution run lengths dec uni probability length observed bernoulli model state model number packets burst fig 

distribution loss run lengths dec uni state markov chain model state markov chain model loss process modelled discrete time markov chain states 
current state stochastic process depends previous value bernoulli model model able capture dependence consecutive losses additional parameter 
parameters transition probabilities states 
maximum likelihood estimators page sample trace number times observed time series follows number times follows number number trace 
run length distribution model loss run length distribution markov chain model th order class random processes rich capture large variety temporal dependencies class finitestate markov processes 
bernoulli model state markov chain model special cases class models 
markov chain model current state process depends certain number previous values process order process 
frequency order markov chain fig 

frequency distribution order markov chain model process characterized order conditional probability matrix rows may inter probability mass functions ac cording random variable generated process state process markov chain order conditional probability independent see 
note bernoulli state markov chain model special cases markov chain model corresponding orders respectively 
observed sequence markov source 
th order state transition probabilities markov chain estimated follows 
number states number conditional probabil ities state chain 
number times state followed value sample sequence 
number times state seen 
estimate probability estimates state transition probability state state maximum likelihood estimators state transition probabilities th order markov chain results stationary segments autocorrelation function binary loss data discussed section iii shows correlation small lags 
bernoulli model capture correlation seen example fig 

state markov chain model able accurately model correlation lag estimated order binary loss process indicates complexity markov chain model necessary accurately model data 
estimated order bernoulli loss model accurate state markov chain model accurate greater markov chain model order required 
table ii bernoulli state markov chain model parameters data nov uni minimum maximum average dec multi minimum maximum average dec uni dec uni jun uni minimum maximum average testing hypothesis binary loss data independent lag sample autocorrelation function discussed section iii 
alternative method testing hypothesis chi square test independence 
test statistic sample sequence lag number times occurs sample sequence similarly number times occurs sample sequence 
number times number times follows lag 
distributed chi square distribution degree freedom 
order markov chain process estimated estimating minimum lag process independent 
similar estimation correlation timescale sample autocorrelation function discussed section iii 
test hypothesis lags lag hypothesis rejected 
estimated order fig 
shows frequency distri bution estimated order markov chain stationary segments datasets 
methods testing independence hypothesis give results 
shows segments bernoulli loss model accurate segments state markov chain model accurate segments rest segments markov chain models higher orders necessary accurate modelling 
estimated order datasets nov uni dec multi ranges segments traces bernoulli model accurate state markov model accurate markov chain model order greater accurate remaining datasets dec uni dec uni jun uni estimated order ranges higher estimated datasets bernoulli model state markov model accurate 
table iv summarizes estimated model parameters discussed section iv 
shows minimum maximum average stationary segments dataset 
trace segments value higher value packet loss predicted bernoulli model state markov chain model accurate 
estimated mean value mean averaging averaging averaging packet sequence number fig 

mean loss rate estimation nov uni memory size line parameter estimation adaptive applications monitor congestion level network order adjust transmission rate keep loss rate low share available bandwidth fairly connections 
address issues line estimation loss applications 
issue amount memory necessary accurate estimate bernoulli state markov chain model parameters discussed section 
second issue exponential smoothing sliding window averaging get date accurate average loss rate estimates discussed section memory bernoulli model state markov model parameters equation gives estimator bernoulli loss model parameter equivalent mean loss rate 
assume values binary loss data available estimation 
henceforth refered memory size fig 
shows estimation mean loss rate example trace segment nov uni memory sizes plotted function packet se quence number 
graphs display extent variation estimated mean loss rate varies 
confidence interval estimator accuracy estimator confidence level required example accuracy estimate loss rate loss rate state markov chain model parameters estimated 
consider required ing parameter directly consider related parameter shown shows similar extent fluctuation shown fig 
example trace segment fluctuates wildly shown fig 

confidence intervals estimators required discussed 
accuracy estimators exponential smoothing versus sliding window averaging adaptive applications need estimate average loss rate line manner order adjust congestion network 
exponential smoothing sliding window averaging ways 
sliding window average gives sample mean sliding window say size samples 
latest samples contribute current esti estimated parameter value est 
est 
packet sequence number fig 

estimating parameter nov uni memory sizes estimated mean value mean slide 
win 
average exp smoothing packet sequence number fig 

comparison exponential smoothing sliding window average nov uni mate ensuring older information 
restricting memory size important non data 
exponential smoothing computationally quicker method estimating current mean requires buffer space 
question address exponential smoothing require memory sliding window averaging providing similar quality estimates 
see sliding window average significantly better estimator 
effective memory size exponential smoothing produces estimate double variance estimate produced sliding window estimate variance requires twice memory 
analysis variance estimate assumed simplicity loss process iid 
presence correlation variance sample mean estimator higher calculated assuming independence 
order compare styles line mean estimation compute effective memory size case exponential smoothing 
binary loss data gain exponential smoothing estimator time previous samples weights old samples decay geometrically age sample relative latest sample 
weight observation estimation time number observations immediately older observation time sum weights observations old older observation time effective memory defined total weight observations old older restricted small fraction calculated 
small values gain compare quality exponential smoothing estimator sliding window average compute relative efficiency defined variance relative sliding window average equivalent sample mean estimator 
population mean sample mean estimator population variance 
variance exponential smoothing estimator variance sample mean estimator relative efficiency ratio variances calculate gain relative efficiency exponential smoothing estimator see twice variance exponential smoothing esti sliding window average effective memory 
fig 
shows difference variance estimators nov uni memory size estimator values plotted packet se quence numbers 
similar comparison exponential smoothing estimator effective memory sliding window averaging estimator memory shows variation exponential smoothing uses double memory 
vi 
measurements internet packet loss unicast multicast connections 
analyzed traces stationarity identified hours stationary trace segments analysis 
loss data represented binary time series alternating sequences runs loss runs 
checked data temporal dependence representations 
study autocorrelation function binary time series representation revealed correlation timescale traces 
distributions run lengths loss run lengths approximately geometrically distributed traces 
geometrically distributed loss run lengths geometrically distributed 
examined accuracy models bernoulli model state markov chain model th order markov chain model terms analysis temporal dependence 
traces bernoulli model accurate segments state markov model segments markov chain models orders traces run lengths remaining bernoulli state markov chain models accurate traces estimated order markov chain model ranged line loss estimation computed memory size accuracy parameter estimate average loss rate state markov chain model parameters 
sliding window average average loss rate estimation advantages exponential smoothing varies approximately half effective number past observations 
richer collection measurements different sampling intervals variety senders receivers allow better understanding temporal dependence loss data 
worthwhile apply models protocol design performance analysis 
acknowledgments bhattacharyya friedman christopher rafael sanjeev khudanpur joseph horowitz fruitful discussions mathematical insights 
grateful chuck cranor washington univ st louis stephen pink swedish institute computer science linda prime univ washington peter wan georgia institute technology lixia zhang univ california los angeles providing computer accounts allowed take measurements 
real time determination traffic conditions internet 
master thesis chalmers university technology gothenburg sweden jan 
billingsley statistical inference markov processes 
university chicago press 
billingsley statistical methods markov chains 
ann 
math 
stat 

bolot packet delay loss behavior internet 
sigcomm symposium communications architectures protocols san francisco sept pp 

bolot garcia analysis audio packet loss internet :10.1.1.38.3690
proceedings international network operating system support digital audio video nossdav durham new hampshire apr pp 

bolot garcia control packet audio internet 
proceedings conference computer communications ieee infocom san fransisco ca apr pp 

bolot garcia case fec error control packet audio internet 
proceedings acm international conference multimedia sept 
bolot turletti adaptive error control packet video internet 
icip lausanne switzerland sept 
bolot turletti experience rate control mechanisms packet video internet 
sigcomm symposium communications architectures protocols jan pp 

davis time series forecasting 
springer verlag 
handley examination mbone performance 
tech 
rep isi rr usc isi january 
maxemchuk lo measurement interpretation voice traffic 
conference record international conference communications icc montreal canada june 
yajnik kurose towsley packet loss correlation mbone multicast network experimental measurements markov chain models :10.1.1.32.7807
tech 
rep umass university massachusetts amherst ma 
yajnik kurose towsley packet loss correlation mbone multicast network 
ieee global internet part globecom london england nov pp 

yajnik moon kurose towsley measurement modelling temporal dependence packet loss 
tech 
rep umass university massachusetts amherst ma 
