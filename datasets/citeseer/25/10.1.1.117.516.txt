optimizations aimed reducing impact memory operations execution speed long concentrated improving cache performance 
efforts achieve reasonable level success 
primary limit compiler ability improve memory behavior im perfect knowledge run time behavior program 
compiler completely predict run time access patterns 
exception rule 
reg allocation phase compiler insert substantial amount spill code instructions move values registers memory back 
compiler inserts memory instructions knowledge memory operations program 
spill code operations disjoint memory manipulations required semantics program compiled interfere cache 
proposes hardware solution problem increased spill costs small compiler con memory ccm hold spilled values 
small random access memory placed distinct address space main memory hierar chy 
compiler target spill instructions ccm moving compiler inserted memory traf fic pathway main memory eliminating impact spill instructions state main memory hierarchy 
mem exist dsp microprocessors 
techniques applied directly chips 
presents compiler methods exploit memory experimental results showing speedups ccm may sizable 
shows register allocation coloring paradigm assign spilled values memory greatly reduce amount memory required program 
digital hard copies part personal classroom se granted fee distributed commercial advan tage bear notice full hurst page 
copy 
republish post servers lets 
perm fee 
asplos viii lo ca acm compiler controlled memory keith cooper timothy harvey computer science department rice university main street ms houston texas outside observer dsp market appears breeding ground architectural innovations 
machines change quite rapidly new features appear generation 
best features persist commodity microprocessors 
dsp chips small fast chip memory programmer improve access times 
chip memories caches located disjoint address space 
simpli fies implementation eliminating need relating chip memory addresses chip memory addresses associative lookup automatic re placement 
designers programmer responsible moving data main memory chip memory timely efficient way 
dsp arena strategy worked 
presents alternative small portion chip memory holding place spilled values small compiler controlled memory ccm 
scheme advantages 
ccm spills shorten spill latencies scheduler place load spilled value speeding execution shortening live range created spilled value 
spilling ccm removes spill traffic path main memory 
system cache memory spilling ccm eliminate cache pollution introduced spill operations loads stores inter directly cache behavior planned high level compiler transformations exploit local ity caused regular accesses loop nests lo 
material part supported texas advanced technology program number darpa contract 
authors current mail addresses cooper cs rice edu cs rice edu 
narrowly focused spill code tion register allocation 
similarities register promotion transformation moves pointer variables registers 
similarity call software component technique spill promotion cases transfor mation moves value primary storage faster class memory 
originally conceived scheme way automatic portion local memory dsp chip experiments suggest may worth considering small ccm commodity microprocessors 
assess reasonableness idea need understand issues hardware support software support amount ccm needed 
presents vision ccm 
section describes assumptions underlying hard ware discusses register spilling problematic suggests ccm better solution simply existing cache memory 
section describes build stand ccm allocator runs post pass compiler fit ccm scheme spill code insertion phase chaitin briggs allocator 
section presents experimental results show kind improvements expected ccm amount ccm required programs test suite 
reiterate techniques directly applicable current dsp cessors 
chips small fast chip memories caches systems expect applications programmer explicitly manage transfers small fast memories 
sys tems results suggest style programming application programmer bottom kb chip memory compiler uses im ccm style spilling 
background proposal ccm spilling combines hardware software issues 
section looks hardware requirements explores software performance issues motivate proposal 
hardware requirements primary hardware requirement small chip memory ccm 
conceptually ccm address space accessible designated st move data ccm register set 
access ccm fast results available cycle 
class registers floating point registers general purpose registers pair instructions suffice spill tv tg ccm offset restore rl ccm tv applications ccm may find uses complex addressing modes 
purposes sim ple absolute addresses sufficient desirable 
compiler assume system runs process embedded applications ccm small simple order kb multi tasked environment ccm larger slightly complex 
handle multiple processes want add system controlled base register provide process small region ccm 
allow system avoid copying ccm contents main memory context switches 
expect ccm kb kb adequate 
importance spilling modern microprocessor presents compiler complex set challenges 
achieve reasonably large fraction processor peak performance compiler keep multiple pipelined functional units busy arrange memory accesses order creates cache locality 
keep pipelines busy compiler en sure instruction ready execute functional unit cycle 
requires care ful instruction scheduling 
requires operands instruction available registers start appropriate cycle 
improve cache locality compiler re order rearrange loop iterations 
transformations improve locality intro duce new overhead computations may move memory registers 
transformations address problems crease demand registers provoke register allocator spill values memory 
perceived increase cost spilling due spills longer memory latencies led research reducing spill costs la 
register spills problematic reasons 
add loads stores address computations program scheduled fetched executed 
second perturb behavior data cost kb cache ble 
ccm simpler implementation full blown cache 
cache increase memory bandwidth requirements 
effects complicated fact allocation occurs quite late compilation transformations block cache register locality foresee spills account impact 
cache wrong place spill modern microprocessors cache memories tool bridge expanding gap speed main memory speed processor :10.1.1.31.5726
point time processor cache holds mapped subset address space includes main memory 
hardware mechanisms adjust contents cache mapping cache locations main memory locations programs execute 
cache sys tems combined compiler transformations reasonably effective bridging gap tween memory speed processor speed 
spill code inserted stages lation disrupt compiler carefully planned se quence memory accesses 
performance perspective cache impor tance lies simple fact memory element cache takes time element cache 
hits cache typically completes single cy cle misses takes cycles simple uniprocessor machine long hundreds cycles distributed memory multi processor 
difference access time strong impact performance indi vidual programs 
accordingly research compilation directed techniques im prove likelihood hitting cache 
falls major categories blocking blocking rearranges reorders iterations loop nest attempt move multiple ref erences single location closer time tempo ral locality attempt move adjacent memory locations closer time spa tial locality 
blocking introduces new loops new index variables crease demand registers cause addi tional spilling 
prefetching appropriate hardware support advisory instruction com piler hide latency associated cache third approach 
compiler load values memory registers bypassing cache write array modeled cache 
gave compiler fairly precise control con tents cache largely avoiding instructions cause replacement 
control came expense doubling amount data movement 
inserts prefetch ad vance believes cache 
response hardware pre loads location cache lo 
prefetching cre ates new copies address calculations existing live range creates new 
effects cause additional spilling 
blocking prefetching compiler analyzes program tries predict run time behavior cache 
compiler bases transforma tions predictions 
analysis prediction techniques rely implicit assumption ac cesses exposed analysis tend focus repeated arrays 
scalar ref erences conflict cache behavior planned compiler reduce impact transforma tions 
mckinley studied actual memory behavior suite scientific programs 
conclude data cache programs relatively high hit rates 
study nearly percent memory refer ences scalar values array values 
mckinley report percentage inserted register allocator know spill scalar 
papers addressed issue reducing cost programmer inserted scalar 
address issue reducing cost compiler inserted scalar 
ways compiler inserted insidious 
spills inserted final stages compilation earlier transformations see analyze plan eliminate 
proposal small fast ccm eliminate unplanned disruption caused spill code 
rest focuses software support needed utilize ccm spilling 
different ways compiler writer handle ccm spilling experimental evidence demon strate potential impact adopting tive hardware software scheme 
software implementation software support required ccm spilling take forms 
built different imple 
post pass ccm allocator operates traditional register allocation 
sec ond embeds support ccm spilling directly typ ical chaitin briggs allocator 
experiments show approaches produce different results 
post pass ccm allocator calculate call graph necessary conservatively mark subroutines call graph cycles ccm subroutine postorder walk call graph rewrite spill instructions symbolic names perform liveness analysis spill locations build ssa spill locations build live range names build interference graph calculate cost live range allocate live ranges ccm locations coloring rewrite spill instructions spill ccm record amount ccm post pass ccm allocator invoked traditional compilation 
takes allocated scheduled code input produces equivalent code loads stores inserted spilling redirected ccm 
uses basic algorithms chaitin briggs allocator operates somewhat different domain 
ccm allocator focuses spill locations data values registers 
runs deci sions live ranges stay registers 
ccm allocator tries discover subset spilled values safely profitably re located ccm 
building ssa form values typical ccm allocator builds ssa form memory locations hold spills 
uses addresses symbolic names builds analog live range names base set symbolic names 
context notion liveness changes 
spill location live point program exists execution path instruc tion loads live loaded executes 
memory location defined program stores value program loads value new definitions ccm allocator computes analog liveness information spill locations 
liveness information turn build graph shows spill locations share single memory location main memory ccm 
ccm allocator generate new spills 
stead redirects subset existing spills size limited ccm 
discovers spills particular value fit ccm sim ply leaves original spill code intact 
causes spills value remain main memory produc ing heavyweight spill ccm spill 
result conservative safe 
traditional register allocators intraprocedural nature treat individual procedures algorithm post pass spill promotion dependent entities 
traditional register alloca tor allocates memory hold spilled value typically places spilled value current activation record procedure containing spill 
allocation decisions spill locations independently different procedures 
ccm situation changes 
ccm global resource shared program ccm allocator adopt interprocedural conventions ccm 
distinct strategies sense 
allo avoid problem limiting ccm spilling values live call site 
values ccm proce dure active ccm conflict procedure 
second allocator coordinate ccm procedures avoid conflicts 
requires information ccm procedures program strategy sense post pass ccm allocator runs link time 
implemented strategies 
absence interprocedural information post pass alloca tor adopts conservative strategy uses ccm values live calls 
interpro information available performs allocation bottom walk call graph 
processes routines reachable procedure fore considering processes procedure records call amount ccm uses 
allocating allocator location value live call location higher ccm high water mark values live call handle cycles call graph corresponding recursion behaves conservatively 
marks procedure cycle full ccm 
shows sketch post pass ccm alloca tion algorithm 
building supporting data flow analyses liveness ssa spill memory positions build interference graph 
coloring algorithm quite similar register allo loop new spill code added build ssa form include ccm positions build live range names repeat coalescing possible build interference graph include ccm positions coalesce copies calculate spill costs simplify select spill try spill ccm positions modified register allocation algorithm including spill promotion cation graph contains nodes high degree simply remove cheapest graph allowing remain heavyweight spill struction proceed note chaitin briggs register allocator post pass ccm allocator needs single pass coloring subroutine 
select specific location ccm post pass allocator uses algorithm chaitin briggs allocator uses pick spill location main memory 
starts ccm tries successive locations finds location interference graph neighbor spilled value 
search space maximum ccm usage set subroutines spilled value live 
manage issue creating array corresponds spill locations pass code uses live sets subroutine calls com pute appropriate address spill location 
ccm allocation spill code insertion incorporate ccm spilling normal register allocator ccm locations visible allocation process 
allocator assigns name ccm location extends data flow analysis include ccm names 
ccm lo cations appear interference graph alongside live ranges program values 
initial pass register allocator ccm locations inter ferences 
allocation pass act inserting spill code uses ccm locations cre ate spans live 
turn forces edges ccm locations live ranges interference graph 
allocator ignores edges allocation uses spill code insertion 
goes remaining heavyweight spill instructions spill locations updated packed tightly memory necessary interference graph built compact memory 
spill value edges node ccm lo cations show allocator ccm locations hold spilled value 
simplifies search appropriate ccm location managing name spaces difficult parts building chaitin briggs allocator 
compar ison problems introduced building ssa forming live ranges coalescing live ranges col oring result small space register spill location names adding name space ccm locations relatively easy 
ccm names introduced live ranges discovered 
allocator appends set ccm names set live ranges 
occurs just construction interference graph 
interference graph construction treats ccm loca tion names way handles register val ues 
uses definition liveness cited section ccm location live stored remains live load position 
definition real change interference graph building gorithm insertion code recognizes spills ccm ccm locations treated exactly register values 
building interference graph ccm loca tions ignored spill section locator 
time value marked spilling normal register allocation allocator signs spill location usually value stack pointer 
modify check see value assigned ccm put stack 
spill insertion allocator consults interference graph determine suitable ccm location available 
govern ing rule value spilled ccm position edge graph 
ccm spills inserted update interference graph 
spilling ur allocator color spills main memory equivalent edges main memory spill locations 
allocator runs spill locations main memory simply extends activation record current procedure 
ccm fixed size resource expensive ap proach warranted 
spill name fpppp rhs supp routine total ccm location rn requires edge live range neighbor interference graph expanded spilling algorithm shown 
algorithm described briggs em step requires modification 
experimental results evaluate ccm allocation techniques imple mented distinct algorithms post pass ccm allocator intraprocedural interprocedural versions modification chaitin briggs allo directly generates ccm spills 
built memory compaction routine colors spill memory non interfering spilled values occupy memory location possible 
ran algorithms suite routines drawn sources include code forsythe ul book numerical methods ii spec benchmarks spec benchmarks 
suite routines required amount spill code routines follow ing numbers generated 
routines sub extensive scalar optimization including global value numbering global constant propagation global dead code elimination partial redundancy elimination peephole optimization 
routines allocator keep side data structure ccm spills inserted current round spilling 
rule ii spilled interference graph edge graph spilled round spilling routine name bytes spill memory 
svd tomcatv table spill memory requirements compaction nave benchmark subjected loop transfor mations enable prefetching analysis transfor mations effect greatly increasing register pressure affected routines suffix added name 
test codes suite fortran derived intermediate code compiler 
low level address intermediate representation similar assembly code 
back transla tor heavily instrumented code compile sun cc compiler 
back design allows modify parameters ab target machine instrumenting code give valuable insights execution code 
compiled codes extremely simple ma chine model 
registers general purpose reg floating point registers 
issues single instruction cycle 
assumed memory opera tions cost cycles instructions includ ing accesses ccm execute single cycle 
exception single issue rule model roughly approximates simpler dsp chips investigating 
cycle counts section come counters instrumented code 
spill memory size question wanted answer ccm necessary discover answer ran standard chaitin briggs register allocator followed coloring memory compaction scheme 
routines require spill code coloring spill mem ory reduced memory requirements aj cn running time time spent memory operations routine name decomp svd supp fpppp iv rhs program performance byte ccm ccm post pass fo oj oo oo gg oo post pass call graph ss oo oo oo gl gs go oo gs table speedups dynamic cycle counts byte ccm integrated go oo oo gl gl gg oo oo routines 
table shows results execution time improvements routines 
entry shows number bytes spill required compaction ratio 
routines com possible required bytes spill memory 
measurements spill memory require ments chose kilobyte ccm target experiments 
size accommodates quarters subroutines 
ran experiments half amount memory see key spill promotions responsible majority speedup 
gives data points 
shows rela running time time spent memory operations routine name pp fpppp jam program performance byte ccm post pass post pass integrated ccm call graph oo go oo oo gl gl gl ss ss oo table changes speedups dynamic cycle counts byte ccm compared byte ccm tive speedup cost benefit having ccm 
second shows ccm bytes significant speedups achieved 
results running codes simple machine shown tables 
column shows dynamic execution costs cy cles routine 
parenthesized number indi cates number cycles memory operations 
second column shows relative number cycles executed code running post pass allo interprocedural information number parentheses relative reduction cycles spent memory operations 
third column shows relative reduction cycles spent codes run post pass allocator ral information 
final column shows relative re duction cycles codes run register allocator ccm allocation built spill code generator 
emphasize change dynamic execution change increased ccm size bytes bytes table reports routines sped result larger ccm 
figures show total running times programs showed improvement 
program bars associated correspond ing different ccm allocation methods post pass interprocedural post pass integrated allocator 
values shown dy namic execution times relative running programs ccm 
table table shows weighted average reduction total cycles executed cycles spent memory operations 
clearly having interprocedural information offers small improvement results expect register allocator anal ysis disposal perform better algorithms 
complex execution models course simple execution model cap ture complex behavior general purpose microprocessor 
particular complex memory hierarchy produce different results 
changes memory hierarchy achieve effects similar ccm ccm attractive 
better cache bigger effective cache decrease impact spills cache havior 
spills cache faster average 
leaves spill traffic pathway main memory 
expect ccm costly simpler interface 
percentage reduction total cycles executed cycles spent memory operations algorithm byte ccm byte ccm byte ccm byte ccm post pass post pass call graph integrated table weighted average reduction cycles executed algorithm write buffer adding write buffer alleviate cache effects stores generated spilling 
little loads generated spilling 
spilled values re loaded fact detailed numbers places briggs thesis show spilling causes loads stores 
victim cache adding victim cache proba bly alleviate ill effects spill induced cache replacements 
victim cache ccm leaves spill traffic pathway main memory 
implementation victim cache expensive small ccm 
prefetching impact advisory prefetch hard predict 
ccm requires modifications compiler generate appropriate instructions 
done successfully prefetching lower average cache penalty access variables 
unfortunately spill code added compilation deleterious effects spilling pronounced prefetch ing 
ccm look attractive 
declined consider effects schedul ing simultaneously hide memory ties cause added spilling due increased register pressure 
summary proposed creation small fast chip memory compiler scalar memory operations inserted register allocator showed minor software enhancements necessary utilize memory space 
proposal offers opportunity move scalar spill operations address space containing cache main memory 
eliminates cache pollution introduced spill reduces total traffic cache 
hardware requirements ccm simple amount ccm required real programs quite modest 
small amount ccm bytes produced significant decreases run time cost register spilling 
amount memory program small worth considering implementing general purpose micro processors ccm kb kb memory adding simple mechanism context switching copying back main memory 
showed incorporate necessary com piler support ways post pass ccm allocator run compilation link time integrated part chaitin briggs allocator 
idea may find immediate application current generation dsp chips 
dsp chips small local memory reserving bottom bytes memory allow compiler apply techniques 
chips applications run single process environment context switching issue 
acknowledgments supported darpa contract texas advanced technology program number 
possible help years group people worked massively scalar compiler project 
owe particular debt kathryn mckinley john bennett preston briggs john pieper linda tor parthasarathy ranganathan anonymous reviewers help advice 
anonymous 
performance pentium pro pen ii processor cache combinations 
technical report ecg technology communications group compaq computer may 
beck david yen thomas anderson 
ar chitecture implementation 
journal su 
peter peter dahl david matthew keefe 
spill code minimization interference region spilling 
notices june 
proceedings acm sigplan conference programming lan guage design implementation 
preston briggs 
register allocation graph col oring 
phd thesis rice university april 
preston briggs 
massively scalar compiler project 
technical report rice university july 
preliminary version available anonymous hp 
callahan alan carle mary hall ken kennedy 
constructing procedure call multigraph 
ieee transactions software en april 
david callahan ken kennedy allan porter field 
software prefetching 
proceedings fourth international conference architectural support programming languages ing systems santa clara california 
steve carr kathryn mckinley chau wen tseng 
compiler optimizations improving data locality 
proceedings sixth international conference architectural support program ming languages operating systems san jose california 
fred chow sun chan robert kennedy shin ming liu raymond lo peng tu 
new algo rithm partial redundancy elimination ssa form 
sigplan notices june 
proceedings acm sigplan con ference programming language design im plementation 
lo keith cooper ken kennedy nathaniel 
cross loop reuse analysis application cache optimization 
proceedings ninth workshop languages compilers parallel computing san jose california 
ll george forsythe michael malcolm cleve moler 
computer methods cal computations 
prentice hall englewood cliffs new jersey 
lal george andrew appel 
iterated regis ter coalescing 
cm transactions programming languages systems may 
john hennessy david patterson 
computer architecture quantitative approach 
morgan kaufmann publishers second edition 
cristina daniel lenoski john keen 
measuring memory hierarchy performance cache coherent multiprocessors micro bench marks 
acm editor sc high performance networking computing proceedings acm ieee sc conference november san jose california usa pages new york ny usa spring street suite silver spring md usa 
acm press ieee computer society press 
intel 
ii processor devel oper manual 
john lu keith cooper 
register promotion programs 
sigplan notices june 
proceedings cm conference programming language design 
sally mckee 
compiling efficient mem ory utilization 
workshop interaction re tween compilers computer architectures sec ond ieee symposium high performance com puter architecture hpca san jose california january 
kathryn mckinley 
personal communication 
email message july 
kathryn mckinley olivier 
quan analysis loop nest locality 
proceed ings seventh international conference architectural support programming languages operating systems san jose california 
larry meadows steven vincent schuster 
vectorizing software pipelining com piler superscalar architecture 
pro ceedings risc san jose ca february 
todd mowry monica lam anoop gupta 
design evaluation compiler algo rithm prefetching 
proceedings fifth international conference architectural support programming languages operating sys ems boston massachusetts 
vijay pai parthasarathy ranganathan sarita adve tracy 
evaluation memory consistency models shared memory systems ilp processors 
proceedings seventh international conference architectural support programming languages ing systems san jose california 
barbara ryder 
constructing call graph program 
ieee transactions software engi neering may 
spec release september 
standards formance evaluation 
zs spec release september 
standards performance evaluation 
michael thomas huff trevor mudge richard brown 
resource allocation high clock rate microprocessor 
proceedings sixth international conference architectural support programming languages operating sys tems san jose california 
michael wolf monica lam 
data lo ca optimizing algorithm 
notices june 
proceedings acm sigplan conference programming lan guage design implementation 
michael wolfe 
iteration space tiling 
proceedings supercomputing pages reno nevada november 
wm :10.1.1.31.5726
wulf sally mckee 
hitting memory wall implications obvious 
com puter architecture news march 
