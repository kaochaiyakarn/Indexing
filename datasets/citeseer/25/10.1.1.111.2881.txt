paradise framework evaluating spoken dialogue agents marilyn walker diane litman candace kamm labs research park avenue florham park nj usa walker diane research att com presents paradise paradigm dialogue system evaluation general framework evaluating spoken dialogue agents 
framework decouples task requirements agent dialogue behaviors supports comparisons dialogue strategies enables calculation performance subdialogues dialogues specifies relative contribution various factors performance possible compare agents performing different tasks normalizing task complexity 
advances dialogue modeling speech recognition natural language processing possible build spoken dialogue agents wide variety applications 
potential benefits agents include remote hands free access ease naturalness greater efficiency interaction 
critical obstacle progress area lack general framework evaluating comparing performance different dialogue agents 
widely approach evaluation answer hirschman 
agent responses query compared predefined key minimum maximum answers performance responses match key 
approach widely acknowledged limitations hirschman pao danieli bates may potential dialogue strategies carrying task key tied particular dialogue strategy 
contrast agents different dialogue strategies compared measures inappropriate utterance ratio turn correction ratio concept accuracy implicit recovery transaction success danieli term agent emphasize fact evaluating speaking entity may personality 
readers wish may substitute word system agent 
gerbino hirschman pao polifroni simpson fraser shriberg wade price 
consider comparison train timetable information agents danieli gerbino agent dialogue uses explicit confirmation strategy agent dialogue uses implicit confirmation strategy user want go torino milano 
agent want go trento milano 

user 
user want travel torino milano 
agent time want leave milano 
user want leave torino evening 
danieli gerbino agent higher transaction success rate produced inappropriate repair utterances agent concluded agent robust agent limitation approach answer approach inability generalize results tasks environments fraser 
generalization requires identification factors affect performance cohen sparck jones galliers 
example danieli gerbino agent dialogue strategy produced dialogues approximately twice long agent way determining agent higher transaction success agent efficiency critical performance 
addition agent factors dialogue strategy task factors database size environmental factors background noise may relevant predictors performance 
approaches limited currently calculate performance dialogues correlate performance external validation criterion normalize performance task complexity 
describes paradise general framework evaluating spoken dialogue agents addresses limitations 
paradise supports comparisons dialogue strategies providing task representation decouples agent needs achieve terms maximize task success kappa maximize user satisfaction efficiency measures number utterances dialogue time minimize costs qualitative measures agent response delay inappropriate utterance ratio repair ratio paradise structure objectives spoken dialogue performance task requirements agent carries task dialogue 
paradise uses decision theoretic framework specify relative contribution various factors agent performance 
performance modeled weighted function task success measure dialogue cost measures weights computed correlating user satisfaction performance 
performance calculated subdialogues dialogues 
goal explain illustrate application paradise framework expository purposes uses simplified domains hypothetical data 
section describes paradise performance model section discusses generality concluding section 
performance model dialogue paradise uses methods decision theory keeney raiffa doyle combine disparate set performance measures user satisfaction task success dialogue cost previously noted literature single performance evaluation function 
decision theory requires specification objectives decision problem set measures known attributes decision theory operationalizing objectives 
paradise model structure objectives rectangles shown 
paradise model posits performance correlated meaningful external criterion usability goal spoken dialogue agent maximize objective related usability 
user satisfaction ratings kamm shriberg wade price polifroni frequently literature external indicator usability dialogue agent 
model posits types factors potential relevant contributors user satisfaction task success dialogue costs types factors potential relevant contributors costs walker 
addition decision theory create objective structure novel aspects paradise include kappa coefficient carletta siegel castellan operationalize task success linear regression quantify relative contribution success cost factors user satisfaction 
remainder section explains measures ovals operationalize set objectives methodology estimating quantitative performance function reflects objective structure 
section describes paradise task representation needed calculate task success measure described section 
section describes cost measures considered paradise reflect efficiency naturalness agent dialogue behaviors 
section describes linear regression user satisfaction estimate relative contribution success cost measures single performance function 
section explains performance calculated subdialogues dialogues section summarizes method 
tasks attribute value matrices general evaluation framework requires task representation decouples agent user accomplish task accomplished dialogue strategies 
propose attribute value matrix avm represent dialogue tasks 
consists information exchanged agent user dialogue represented set ordered pairs attributes possible values 
consider simplification train timetable domain dialogues timetable contains information rush hour trains cities shown table 
avm consists attributes abbreviations attribute name shown 
table attribute value pairs annotated direction information flow represent acquires information information evaluation 
dialogue agent acquire user values dc ac dr user acquire dt 
performance evaluation agent requires corpus dialogues users agent users execute set scenarios 
scenario execution infinite sets values actual values experimental data constitute required finite set 
avm serves evaluation mechanism 
claiming avms determine agent behavior serve utterance semantic representation 
attribute possible values information flow depart city dc milano roma torino trento agent arrival city ac milano roma torino trento agent depart range dr morning evening agent depart time dt am am pm pm user table attribute value matrix simplified train timetable domain hello train enquiry service 
dc ac dr dt please speak tone 
dc ac dr dt information need 
dc ac dr dt want go torino milano 
dc ac want go trento milano 
dc ac dc ac 
dc ac want leave trento 
dc dc 
dc want leave 
dc want leave torino 
dc want leave torino 
dc dc 
dc want go milano 
ac 
ac time want leave 
dr want travel evening 
dr want leave 
dr dr 
dr train leaving 
dt agent dialogue interaction danieli gerbino corresponding avm instantiation indicating task information requirements scenario attribute paired attribute value obtained dialogue 
example assume scenario requires user find train torino milano leaves evening longer versions dialogues figures 
table contains avm corresponding key scenario 
dialogues resulting execution scenario agent user correctly convey attribute values figures avm scenario key table 
avms remaining dialogues differ key value 
dialogue strategies figures radically different avm task representation dialogues identical performance system task assessed basis avm representation 
measuring task success success task dialogue measured agent user achieve information requirements task dialogues slightly modified danieli gerbino 
attribute names utterance explained 
hello train enquiry service 
dc ac dr dt please speak tone 
dc ac dr dt information need 
dc ac dr dt want travel torino milano 
dc ac time want leave milano 
dc ac dr want leave torino evening 
dc dr want leave torino dc dr please answer 
dc dr 
dc dr train leaves 
dt agent dialogue interaction danieli gerbino attribute actual value depart city torino arrival city milano depart range evening depart time pm table attribute value matrix instantiation scenario key dialogues dialogue 
section explains paradise uses kappa coefficient carletta siegel castellan operationalize success measure 
kappa coefficient calculated confusion matrix summarizes agent achieves information requirements particular task set dialogues instantiating set scenarios 
example tables show hypothetical confusion matrices generated evaluation complete dialogues train timetable agents confirmation strategies illustrated figures respectively 
values matrix cells comparisons dialogue scenario key avms 
attribute value dialogue data avm matches value scenario key number appropriate diagonal cell matrix boldface clarity incremented 
diagonal cells represent misunderstandings corrected dialogue 
note depending strategy spoken dialogue agent uses confusions attributes possible milano confused morning effect misunderstandings corrected course dialogue reflected costs associated dialogue discussed 
matrix summarizes avms representing dialogue agent compare avms representing relevant scenario keys confusion matrices constructed summarize result dialogues subset scenarios attributes users dialogues 
distributions tables roughly performance results danieli gerbino 
key depart city arrival city depart range depart time data sum table confusion matrix agent key depart city arrival city depart range depart time data sum second matrix summarizes information exchange agent labels matrix represent possible values depart city shown table arrival city columns represent key specifying information values agent user supposed communicate particular scenario 
equivalent column sums tables reflects users agents assumed performed scenarios 
rows represent data collected dialogue corpus reflecting attribute values communicated agent user 
confusion matrix success achieving information requirements task measured kappa coefficient carletta siegel castellan proportion times avms actual set dialogues agree avms scenario keys proportion times avms dialogues keys expected agree table confusion matrix agent chance 
agreement expected chance 
total agreement 
superior measures success transaction success danieli gerbino concept accuracy simpson fraser percent agreement gale church yarowsky takes account inherent complexity task correcting chance expected agreement 
provides basis comparisons agents performing different tasks 
prior distribution categories unknown expected chance agreement data key estimated distribution values keys 
calculated confusion matrix columns represent values keys 
particular nx ti measure pairwise agreement coders making category judgments carletta siegel castellan 
observed user agent interactions modeled coder ideal interactions expert coder 
ti sum frequencies column sum frequencies tn 
actual agreement data key computed confusion matrix pn confusion matrices tables agents 
agent agent suggesting agent successful achieving task goals 
measuring dialogue costs shown performance function combination cost measures 
intuitively cost measures calculated basis user agent dialogue behaviors minimized 
wide range cost measures previous include pure efficiency measures number turns elapsed time complete task brown hirschman smith gordon walker measures qualitative phenomena inappropriate repair utterances danieli gerbino hirschman pao simpson fraser 
paradise represents cost measure function ci applied sub dialogue 
consider simplest case calculating efficiency measures dialogue 
example total number utterances 
dialogue utterances 
dialogue utterances 
calculate costs subdialogues qualitative measures necessary able specify information goals utterance contributes 
paradise uses avm representation link information goals task arbitrary dialogue behavior tagging dialogue attributes task 
possible evaluate potential dialogue strategies achieving task evaluate dialogue strategies operate level dialogue subtasks subdialogues 
consider longer versions dialogues figures 
utterance figures tagged attribute abbreviations table subtask utterance contributes 
convention type tagging single confusion matrix attributes tables inflates cross attribute confusions making smaller 
cases desirable calculate identification attributes values attributes average attribute produce task 
tagging hand generated system generated hand corrected 
preliminary studies indicate reliability human tagging higher avm attribute tagging types discourse segment tagging passonneau litman hirschberg nakatani 
segment goals dc ac utterances segment segment goals dc goals ac utterances utterances segment goals dc ac dr dt utterances segment goals dr utterances segment goals dt utterances task defined discourse structure agent dialogue interaction utterances contribute success dialogue greetings tagged attributes 
structure dialogue reflects structure task carberry grosz sidner litman allen tagging dialogue avm attributes generate hierarchical discourse structure shown dialogue :10.1.1.14.9528
example segment depart city dc ac 
contains segments consists utterances 
tagging avm attributes required calculate costs subdialogues task attributes define 
attribute arrival city consists utterances 
tagging avm attributes required calculate cost qualitative measures number repair utterances 
note calculate costs utterance corpus dialogues tagged respect qualitative phenomenon question utterance repair 
example number repair utterances 
repair utterances utterances utterances 
repair utterance note avm task tagging simultaneously addresses information goals depart range 
general utterance contributes information goals different attributes attribute accounts costs derivable 
set ci necessary combine dif previous shown done high reliability hirschman pao 
ferent cost measures order determine relative contribution performance 
section explains combine set ci yield performance measure 
estimating performance function definition success costs model performance sub dialogue defined follows performance nx wi ci weight cost functions ci weighted wi score normalization function cohen 
normalization function overcome problem values ci scale cost measures ci may calculated widely varying scales response delay measured seconds example costs calculated terms number utterances 
problem easily solved normalizing factor score standard deviation user agent utt rep mean mean mean na table hypothetical performance data users agents illustrate method estimating performance function subset data tables shown table 
table represents results assume additive performance utility function appears various cost factors utility independent additive independent keeney raiffa 
possible user satisfaction data collected experiments data willingness pay indicate 
continuing additive function require transformation data reworking model shown inclusion interaction terms model cohen 
hypothetical experiment users randomly assigned communicate agent users randomly assigned communicate agent table shows user satisfaction ratings discussed number utterances utt number repair utterances rep users 
users correspond dialogues figures respectively 
normalize user determine 

similarly user 
estimate performance function weights wi solved 
recall claim implicit relative contribution task success dialogue costs performance calculated considering contribution user satisfaction 
user satisfaction typically calculated surveys ask users specify degree agree statements behavior performance system 
single user satisfaction measure calculated single question mean set ratings 
hypothetical user satisfaction ratings shown table range high low 
set dialogues user satisfaction set ci collected experimentally weights wi solved multiple linear regression 
multiple linear regression produces set coefficients weights describing relative contribution predictor factor accounting variance predicted factor 
case basis model treated predicted factor 
normalization predictor factors ci scores guarantees relative magnitude coefficients directly indicates relative contribution factor 
regression table data sets users tests factors utt rep strongly predicts 
results regression factors included shows rep significant 
order develop performance function estimate includes significant factors eliminates redundancies second regression including significant factors done 
case second regression yields predictive equation performance 
results show significant rep significant combination rep account variance external validation criterion 
factor utt significant predictor performance part utt rep highly redundant 
correlation utt rep 
predictions relative contribution different factors performance possible return problem introduced section potentially conflicting performance criteria robustness efficiency performance agent agent compared 
values wi performance calculated agents equation 
mean performance mean performance suggesting agent may perform better agent 
evaluator test performance differences statistical significance 
case test shows differences significant level indicating trend 
case evaluation larger subset user population probably show significant differences 
application subdialogues ci calculated subdialogues performance calculated level values wi solved 
assumes factors predictive global performance generalize predictors local performance subdialogues defined subtasks defined attribute tagging 
consider calculating performance dialogue strategies train timetable agents subdialogues repair value depart city 
segment example agent initial estimation performance function analysis requires experimental data set values ci application score normalization function data 
values ci calculated dialogue level 
addition data comparable strategies calculate mean standard deviation normalization 
informally comparable strategy applies state effects 
example calculate agent subdialogues repair depart city computed subpart table concerned depart city 
agent 
value normalized data comparable subdialogues agent agent data tables mean agent 
calculate agent assume average number repair utterances agent subdialogues repair depart city mean comparable repair subdialogues standard deviation 

agent repair dialogue strategy subdialogues repairing depart city ra agent repair strategy depart city rb 
performance equation predicted performance ra performance ra agent appropriate subpart table calculate assuming average number depart city repair utterances similar assumption sound basis theories dialogue structure carberry grosz sidner litman allen tested empirically :10.1.1.14.9528
calculations yields performance rb results experiments predict agent needs choose repair strategy agent uses repair strategy agent uses repairing depart city agent strategy rb performance rb predicted greater performance ra 
note ability calculate performance subdialogues allows conduct experiments simultaneously test multiple dialogue strategies 
example suppose agents different strategies presenting value depart time addition different confirmation strategies 
ability calculate performance subdialogues impossible test effect different presentation strategies independently different confirmation strategies 
summary paradise framework evaluate hypothetical dialogue agents simplified train timetable task domain 
par derive performance function task estimating relative contribution set potential predictors user satisfaction 
paradise methodology consists steps definition task set scenarios specification avm task representation experiments alternate dialogue agents task calculation user satisfaction surveys calculation task success calculation dialogue cost efficiency qualitative measures estimation performance function linear regression values user satisfaction dialogue costs comparison agents tasks determine factors generalize refinement performance model 
note steps required develop performance function 
weights performance function solved user satisfaction ratings longer need collected 
predictions user satisfaction basis predictor variables illustrated application paradise subdialogues 
current state knowledge important emphasize researchers cautious generalizing derived performance function agents tasks 
performance function estimation done iteratively different tasks dialogue strategies see factors generalize 
way field progress identifying relationship various factors move predictive models spoken dialogue agent performance 
generality previous section paradise evaluate confirmation strategies examples fairly simple information access dialogues train timetable domain 
section demonstrate paradise applicable range tasks domains dialogues presenting avms tasks involving information access showing additional dialogue phenomena tagged avm attributes 
attribute possible values information flow depart city dc milano roma torino trento agent arrival city ac milano roma torino trento agent depart range dr morning evening agent depart time dt am am pm pm user request type rt reserve purchase agent table attribute value matrix train timetable domain requests consider extension train timetable task agent handle requests reserve seat purchase ticket 
task represented avm table extension table agent acquire value attribute request type order know information acquired 
want go torino roma dc ac approximately time day travel 
dr options 
dr morning evening 
dr departure times 
dr 
dr leave morning 
dr train leaves torino porto 
dt please reserve seat train 
rt hypothetical agent dialogue interaction presents hypothetical dialogue extended task domain illustrates user utterance types agent dialogue strategy different figures 
agent uses confirmation dialogue strategy contrast explicit implicit confirmation strategies figures 
second illustrates new types user utterances directly informational goals task 
user asks agent wh question dr attribute providing information attribute value 
satisfies knowledge precondition related answering contributes dr goal tagged 
user similarly asks question addresses subgoal related answering 
illustrates user request agent action tagged rt attribute 
value rt avm instantiation dialogue reserve second consider different domain task diagnosing fault repairing circuit smith gordon 
presents dialogue domain 

circuit fix shop 
id cb rb ft fc may help 
id cb rb ft fc 
want fix circuit 
id cb rb ft fc 
id circuit 
id 
rs 
id 
am familiar circuit 
cb led supposed displaying alternately flashing 
cb 
led 
rb 
switch led 
rb 
switch 
rb 
put switch 
rb 
okay 
rb 
put knob zero 
rb 
okay 
rb 
led displaying 
rb 
led displaying flashing 
rb 
wire connector connector 
ft 

ft 
add wire connector connector 
fc 
done 
fc 
led displaying 

alternately flashing 

led displaying longer period time 



led displaying longer period time 



put knob zero 

okay 

led displaying 

alternately displaying 

led displaying longer period time 



put switch 

switch 

led displaying 



circuit working correctly 
bye 
circuit domain dialogue smith gordon avm tagging smith gordon collected dialogues task agent initiative varied different dialogue strategies tagged dialogue subtask structure establish purpose task assessment establish current behavior diagnosis establish cause errant behavior repair establish correction errant behavior test establish behavior correct task results avm shown table 
note attributes identical smith gordon list subtasks 
circuit id corresponds correct circuit behavior current circuit assessment report reliability tagging scheme 
fault type corresponds diagnosis fault correction corresponds repair test corresponds test 
attribute names emphasize information exchange subtask names emphasize function 
attribute possible values circuit id id rs rs 
correct circuit behavior cb flash flash 
current circuit behavior rb flash fault type ft 
fault correction fc test table attribute value matrix circuit domain tagged attributes table 
smith gordon tagging dialogue subtask representation follows turns turns turns turns turns note differences dialogue structures yielded tagging schemes 
scheme greetings turns tagged attributes 
second smith gordon single tag corresponds attribute tags table scheme defines extra level structure assessment subdialogues 
discussion paradise framework evaluating spoken dialogue agents 
paradise general framework evaluating spoken dialogue agents integrates enhances previous 
paradise supports comparisons dialogue strategies task representation decouples agent needs achieve terms task requirements agent carries task dialogue 
furthermore task representation supports calculation performance subdialogues dialogues 
addition paradise success measure normalizes task complexity provides basis comparing agents performing different tasks 
paradise performance measure function task success dialogue costs ci number advantages 
allows evaluate performance level dialogue ci calculated dialogue subtask 
performance measured subtask dialogue strategies range subdialogues dialogue associate performance individual dialogue strategies 
second success measure takes account complexity task comparisons dialogue tasks 
third allows measure partial success achieving task 
fourth performance combine objective subjective cost measures specifies evaluate relative contributions costs factors performance 
knowledge propose user satisfaction determine weights factors related performance 
addition approach broadly integrative incorporating aspects transaction success concept accuracy multiple cost measures user satisfaction 
framework transaction success reflected corresponding dialogues 
performance measure captures information similar concept accuracy low concept accuracy scores translate higher costs acquiring information user lower scores 
limitation paradise approach task success measure reflect solutions better 
example train timetable domain task success measure give higher ratings agents suggest express local trains provide helpful information explicitly requested especially better solutions occur dialogues higher costs 
possible address limitation interval scaled data version 
possibility simply substitute domain specific task success measure performance model evaluation model applications spoken dialogue processing 
believe framework applicable dialogue modalities human human task oriented dialogues 
addition proposals literature algorithms dialogue strategies cooperative collaborative helpful user webber joshi pollack hirschberg webber joshi webber weischedel chu carberry strategies evaluated improve measurable aspect dialogue interaction 
demonstrated dialogue strategy evaluated possible show cooperative response cooperative strategy improves task performance reducing costs increasing task success 
hope framework broadly applied dialogue research 
acknowledgments james allen jennifer chu carroll danieli wieland eckert giuseppe di don hindle julia hirschberg narayanan jay steve whittaker anonymous reviews helpful discussion comments earlier versions 
michael brown bruce 

development principles dialog interfaces 
ecai spoken dialog processing workshop budapest hungary 
bates 

proposal incremental dialogue evaluation 
proceedings darpa speech nl workshop pages 
carberry 
plan recognition understanding dialogue 
kobsa wahlster editors user models dialogue systems 
springer verlag berlin pages 
carletta jean 
assessing reliability subjective codings 
computational linguistics 
chu jennifer sandra carberry 

response generation collaborative negotiation 
proceedings conference rd annual meeting association computational linguistics pages 
cohen paul 

empirical methods artificial intelligence 
mit press boston 
danieli eckert fraser gilbert mcglashan 

dialogue manager design evaluation 
technical report project esprit sundial wp 
danieli gerbino 

metrics evaluating dialogue strategies spoken language system 
proceedings aaai spring symposium empirical methods discourse interpretation generation pages 
doyle jon 

rationality roles reasoning 
computational intelligence 
fraser norman 
quality standards spoken dialogue systems report progress eagles 
esca workshop spoken dialogue systems denmark pages 
gale william ken church david yarowsky 

estimating upper lower bounds performance word sense disambiguation programs 
proc 
th acl pages newark delaware 
grosz barbara candace sidner 

attentions intentions structure discourse 
computational linguistics 
hirschberg julia christine nakatani 

prosodic analysis discourse segments monologues 
th annual meeting association computational linguistics pages 
hirschman lynette deborah dahl donald mckay lewis norton 

class proposal automatic evaluation discourse 
proceedings speech natural language workshop pages 
hirschman lynette christine pao 

cost errors spoken language system 
proceedings third european conference speech communication technology pages 
joshi aravind bonnie webber ralph weischedel 

preventing false inferences 
coling proc 
th international conference computational linguistics pages 
kamm candace 

user interfaces voice applications 
david roe jay editors voice communication humans machines 
national academy press pages 
keeney ralph howard raiffa 

decisions multiple objectives preferences value tradeoffs 
john wiley sons 
klaus 

content analysis methodology 
sage publications beverly hills ca 
litman diane james allen 

recognizing relating discourse intentions task oriented plans 
philip cohen jerry morgan martha pollack editors intentions communication 
mit press 
passonneau rebecca diane litman 

discourse segmentation human automated means 
computational linguistics 
polifroni joseph lynette hirschman stephanie seneff victor zue 

experiments evaluating interactive spoken language systems 
proceedings darpa speech nl workshop pages 
pollack martha julia hirschberg bonnie webber 

user participation reasoning process expert systems 
proceedings national conference artificial intelligence pages pp 

shriberg elizabeth elizabeth wade patti price 

human machine problem solving spoken language systems sls factors affecting performance user satisfaction 
proceedings darpa speech nl workshop pages 
siegel sidney castellan 

nonparametric statistics behavioral sciences 
mcgraw hill 
simpson fraser 

black box glass box evaluation sundial system 
proceedings third european conference speech communication technology pages 
smith steven gordon 

effects variable initiative linguistic behavior humancomputer spoken natural language dialog 
computational linguistics 
sparck jones karen julia galliers 

evaluating natural language processing systems 
springer 
walker marilyn 
effect resource limits task complexity collaborative planning dialogue 
artificial intelligence journal 
webber bonnie aravind joshi 

initiative natural language database interaction justifying 
coling pages 
