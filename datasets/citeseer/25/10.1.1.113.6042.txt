machine learning kluwer academic publishers 
manufactured netherlands 
spade efficient algorithm mining frequent sequences mohammed zaki zaki cs rpi edu computer science department rensselaer polytechnic institute troy ny editor douglas fisher 
spade new algorithm fast discovery sequential patterns 
existing solutions problem repeated database scans complex hash structures poor locality 
spade utilizes combinatorial properties decompose original problem smaller sub problems independently solved main memory efficient lattice search techniques simple join operations 
sequences discovered database scans 
experiments show spade outperforms best previous algorithm factor order magnitude pre processed data 
linear scalability respect number input sequences number database parameters 
discuss results sequence mining applied real application domain 
keywords sequence mining sequential patterns frequent patterns data mining knowledge discovery 
sequence mining task discover set attributes shared time large number objects database 
example consider sales database bookstore objects represent customers attributes represent authors books 
say database records books bought customer period time 
discovered patterns sequences books frequently bought customers 
example people buy jane austen pride prejudice buy emma month stores patterns promotions shelf placement consider example web access database popular site object web user attribute web page 
discovered patterns sequences frequently accessed pages site 
kind information restructure web site dynamically insert relevant links web pages user access patterns 
domains sequence mining applied include identifying plan failures zaki lesh ogihara finding network alarm patterns 
task discovering frequent sequences large databases quite challenging 
search space extremely large 
example attributes potentially frequent sequences length millions objects database problem minimization paramount 
current algorithms iterative nature requiring full database scans longest frequent sequence zaki clearly expensive process 
methods especially form sampling sensitive data skew adversely affect performance 
furthermore approaches complicated internal data structures poor locality parthasarathy zaki li add additional space computation overheads 
goal overcome limitations 
new algorithm called spade sequential pattern discovery equivalence classes discovering set frequent sequences 
key features approach follows 
vertical id list database format associate sequence list objects occurs time stamps 
show frequent sequences enumerated simple temporal joins intersections id lists 

lattice theoretic approach decompose original search space lattice smaller pieces sub lattices processed independently main memory 
approach usually requires database scans single scan pre processed information minimizing costs 

decouple problem decomposition pattern search 
propose different search strategies enumerating frequent sequences sublattice breadth depth search 
spade minimizes costs reducing database scans minimizes computational costs efficient search schemes 
vertical id list approach insensitive data skew 
extensive set experiments shows spade outperforms previous approaches factor order magnitude additional line information 
furthermore spade scales linearly database size number database parameters 
briefly discuss sequence mining applied practice 
show complicated real world applications sequence mining produce overwhelming number frequent patterns 
discuss identify interesting patterns pruning strategies post processing step 
rest organized follows section describe sequence discovery problem look related section 
section develop approach problem decomposition pattern search 
section describes new algorithm 
experimental study section 
section discusses sequence mining realistic domain 
conclude section 
problem statement problem mining sequential patterns stated follows im set distinct items comprising alphabet 
event non empty unordered collection items loss generality assume items event sorted lexicographic order 
sequence ordered list events 
event denoted ik item 
sequence denoted sequence mining event 
sequence items called sequence 
example ac sequence 
sequence event occurs denote say subsequence sequence denoted exists order preserving function maps events events 
example sequence ac subsequence ab ac ab ac ac order events preserved 
hand sequence ab subsequence abe vice versa 
database sequence mining consists collection input sequences 
input sequence database unique identifier called sid event input sequence unique identifier called eid 
assume sequence event time stamp time stamp event identifier 
input sequence said contain sequence subsequence input sequence support frequency sequence denoted total number input sequences database contain 
user specified threshold called minimum support denoted min sup say sequence frequent occurs min sup times 
set frequent sequences denoted fk 
frequent sequence maximal subsequence frequent sequence 
database input sequences min sup problem mining sequential patterns find frequent sequences database 
example consider input database shown running example 
database 
original input sequence database 
zaki 
rule generation algorithm 
items input sequences events 
shows frequent sequences minimum support sequence occur input sequences 
example maximal frequent sequences abf bf comments order see generality problem formulation discover sequences subsets items just single item sequences 
example set bf bf 
discover sequences arbitrary gaps events just consecutive subsequences 
example sequence bf subsequence input sequence intervening event bf 
sequence symbol simply denotes happens relationship 
formulation general encompass categorical sequential domain 
example input sequences dna strings event consists single item 
input sequences represent text documents word attributes word noun position comprise event 
continuous domains represented suitable discretization step 

sequence rules frequent sequences known obtain rules describe relationship different sequence items 
example sequence bf occurs input sequences abf input sequences 
say bf occurs chance occurs 
words say rule bf abf confidence 
example rule bf bf 
confidence 
user specified minimum confidence min conf generate rules meet condition means simple algorithm shown 
rule generation step relatively straightforward rest mainly concentrate frequent sequence discovery phase 
return problem generating useful rules section planning domain 

related problem mining sequential patterns introduced agrawal srikant 
algorithms solving problem 
aprioriall algorithm sequence mining shown perform better approaches 
subsequent srikant agrawal authors proposed gsp algorithm outperformed aprioriall times :10.1.1.40.6428
introduced maximum gap minimum gap sliding window constraints discovered sequences 
independently mannila toivonen verkamo proposed mining frequent episodes essentially frequent sequences single long input sequence typically single items events handle set events 
formulation geared finding frequent sequences different input sequences 
extended framework mannila toivonen discover generalized episodes allows express arbitrary unary conditions individual sequence events binary conditions event pairs 
algorithms oates discover patterns multiple event sequences explore rule space directly sequence space 
sequence discovery essentially thought association discovery agrawal savasere omiecinski navathe temporal database 
association rules discover intra event patterns called itemsets discover inter event patterns sequences 
set frequent sequences superset set frequent itemsets 
due similarity sequence mining algorithms aprioriall gsp utilize ideas initially proposed discovery association rules 
new algorithm fast association mining techniques zaki 

sequence search space complex challenging itemset space warrants specific algorithms 
preliminary version appeared zaki 

gsp algorithm describe gsp algorithm srikant agrawal detail base compare spade best previous algorithms :10.1.1.40.6428
gsp multiple passes database 
pass single items sequences counted 
frequent items set candidate sequences formed 
pass gather support 
frequent sequences generate candidate sequences process repeated frequent sequences 
main steps algorithm 

candidate generation set frequent sequences fk candidates pass generated joining fk 
pruning phase eliminates sequence subsequences frequent 
fast counting candidate sequences stored hash tree 

support counting find candidates contained input sequence conceptually subsequences generated 
subsequence search hash tree 
candidate hash tree matches subsequence count incremented 
zaki 
gsp algorithm 
gsp algorithm shown 
details specific mechanisms constructing searching hash trees please refer srikant agrawal 

sequence enumeration lattice approach embarking algorithm description briefly review terminology lattice theory see davey priestley 
definition 
set 
partial order binary relation relation reflexive anti symmetric implies transitive implies set relation called ordered set 
definition 
ordered set element upper bound lower bound minimum upper bound called join denoted maximum greatest lower bound called meet denoted greatest element denoted called top element element denoted called bottom element 
definition 
ordered set 
called join meet semilattice exists minimum upper bound maximum lower bound exists 
called lattice join meet semilattice 
ordered set sublattice implies definition 
lattice say covered ifx implies element bottom element lattice called atom covers 
set atoms denoted 
sequence mining definition 
ordered set 
called hyper lattice representing unique minimum upper bound maximum lower bound represents set minimal upper bounds maximal lower bounds 
note regular lattice join meet refers unique minimum upper bound maximum lower bound 
hyper lattice join meet need produce unique element result set minimal upper bounds maximal lower bounds 
rest usually refer sequence hyper lattice lattice wish stress difference sequence context understood 
lemma 
set sequences items subsequence relation defines hyper lattice theorem 
set items ordered set possible sequences items hyper lattice join set sequences ai set minimal common meet set sequences set maximal common subsequences 
formally ai ai ai ai ai ai example database set frequent items 
shows sequence lattice spanned subsequence relation frequent items 
atoms sequence lattice cover bottom element 
see set sequences forms hyper lattice consider join ab 
see join produces minimal upper bounds minimal common super sequences 
similarly meet sequences produce set maximal lower bounds 
example ab ab ab maximal common sub sequences 
bottom element sequence lattice top element undefined sequence lattice infinite 
shows parts lattice complete set sequences sequences generated ab possible sequences generated recursive combinatorial structure subsequence lattice apparent 
example consider set sequences generated item sequence sets identical extra prefix set 
lemma 
denote number frequent items 
total number sequences length 
proof 
count number ways sequence constructed assign items arrangement 
number ways sequence constructed number ways obtain sum integers 
zaki 
sequence lattice spanned subsequence relation 

number ways obtain sequence 
example shows number ways obtain sum integers 
integers sum interpreted sizes events comprising length sequence 
assign items event 
event length wehave item assignments 
multiplying choices case adding cases obtain total number sequences ik ik ik difficult derive closed form expression exact number sequences formula closed form expression upper bound number sequences obtained follows 
positions choice sequence mining 
lattice induced maximal frequent sequences abf bf items choices put 
total number sequences bounded expression nk total number sequences length ni ni nk nk constant mentioned case lattice sequences infinite 
fortunately practical cases bounded 
number sequence elements events bounded maximum number events input sequence say 
size event bounded maximum event size say sequence items subsequence lattice bounded example database largest possible sequence items 
practical cases lattice bounded set frequent sequences sparse depending min sup value 
example consider shows sequence lattice induced maximal frequent sequences abf bf example 
set atoms frequent items 
obvious set frequent sequences forms meet semilattice closed meet operation frequent sequences meet maximal common subsequence frequent 
join semilattice closed joins frequent doesn imply minimal common supersequence frequent 
closure meet leads known observation sequence frequency lemma 
subsequences frequent sequence frequent 
lemma leads naturally bottom search procedure enumerating frequent sequences leveraged sequence mining algorithms srikant zaki 
id lists atoms 
agrawal mannila toivonen verkamo oates 
essence lemma says need focus sequences subsequences frequent 
leads powerful pruning strategy eliminate sequences subsequences infrequent 
lattice formulation apparent need restrict purely bottom search 
employ different search procedures discuss 

support counting associate atom sequence lattice id list denoted list input sequence sid event identifier eid pairs containing atom 
shows id lists atoms example database 
example consider atom original database see occurs input sequence event identifier pairs 
forms id list item lemma 

jy denotes temporal join id lists called cardinality denotes number distinct sid values id list sequence lemma states sequence obtained temporal join atoms lattice support sequence obtained joining id list atoms 
say wish compute support sequence bf 
set 
perform temporal joins atom time obtain final id list shown 
start id list atom join symbol represents temporal relationship find occurrences input sequence store corresponding time stamps eids obtain 
join id list atom time relationship non temporal call equality join occur time 
find occurrences eid store id list bf 
temporal join completes process 
sequence mining 
naive temporal joins 
lemma 
jy 
lemma tells construct id list sequence atoms lattice lemma generalizes set sequences 
lemma says join set sequences support temporal join id lists elements particular determine support sequence simply joining id lists length subsequences 
simple check cardinality unique sid values resulting id list tells new sequence frequent 

space efficient joins 
naively produce id lists shown storing eids time stamps items sequence waste space 
corollary states generate sequence joining lexicographically length subsequences possible reduce space requirements storing sid eid pairs columns sequence matter items 
corollary 
sequence denote lexicographically subsequences 
reason corollary allows space reduction length sequences sequence share length prefix 
share prefix follows eids items prefix difference eids items 
suffices discard eids prefix keep track eids item sequence 
illustrates idlist bf obtained idlist joins 
bf perform temporal join subsequences bf obtained dropping item obtained dropping second item 
recursively obtain id list bf perform equality join zaki 
computing support space efficient temporal id list joins 
id list 
perform temporal join 
sequences obtained joining atoms directly 
shows complete process starting initial vertical database id list atom 
see point sid eid pairs stored id lists eid item sequence stored 
exact details temporal joins provided section discuss implementation spade 
lemma 
sequences 
lemma says sequence subsequence cardinality id list support equal cardinality id list practical important consequence lemma cardinalities intermediate id lists shrink move lattice 
results fast joins support counting 

lattice decomposition prefix classes main memory enumerate frequent sequences traversing lattice performing temporal joins obtain sequence supports 
practice sequence mining 
equivalence classes induced classes induced 
limited amount main memory intermediate id lists fit memory 
brings natural question decompose original lattice smaller pieces piece solved independently main memory 
address question 
define function set sequences set nonnegative integers 
words returns length prefix define equivalence relation lattice follows say related denoted 
sequences class share common length prefix 
shows partition induced equivalence relation collapse sequences common item prefix equivalence class 
resulting set equivalence classes 
call level classes parent classes 
bottom shows links classes 
links carry pruning information 
words want prune sequence infrequent subsequence may need cross class information 
say section 
lemma 
equivalence class induced equivalence relation sub hyper lattice proof 
elements class share common prefix share common prefix minimal common super sequence 
implies hand share common prefix maximal zaki common sub sequence 

sub hyper lattice hyper lattice set atoms 
example atoms bottom element application corollary generate supports sequences class sub lattice temporal joins 
main memory hold temporary id lists class solve independently 
practice level decomposition induced sufficient 
cases class may large solved main memory 
scenario apply recursive class decomposition 
assume large fit main memory 
lattice decomposed relation 
shows classes induced applying applying 
resulting parent classes processed independently generate frequent sequences class 
depending amount main memory available recursively partition large classes smaller ones class small solved independently main memory 

search frequent sequences section discuss efficient search strategies enumerating frequent sequences parent class 
discuss main strategies breadth depth search 
methods recursive decomposition parent class smaller classes induced equivalence relation shows decomposition smaller smaller classes resulting lattice equivalence classes 

recursive decomposition class smaller sub classes sequence mining breadth search bfs breadth search lattice equivalence classes generated recursive application explored bottom manner 
process child classes level moving level 
example process equivalence classes moving classes bf 
depth search dfs depth search completely solve child equivalence classes path moving path 
example process classes order bf bf 
advantage bfs dfs information available pruning 
example know set sequences constructing sequences information available dfs 
hand dfs requires main memory bfs 
dfs needs keep intermediate id lists consecutive classes single path bfs keep track id lists classes consecutive levels 
consequently number frequent sequences large example dense domains cases min sup value low dfs may feasible approach bfs run virtual memory 
bfs dfs search search possibilities 
example dfs scheme determine bf frequent process classes necessarily frequent 
currently investigating schemes efficient enumeration maximal frequent sequences 

spade algorithm design implementation section describe design implementation spade 
shows high level structure algorithm 
main steps include computation frequent sequences sequences decomposition prefix parent equivalence classes enumeration frequent sequences bfs dfs search class 
describe step detail 

spade algorithm 
zaki 
computing frequent sequences sequences current sequence mining algorithms agrawal srikant srikant agrawal assume horizontal database layout shown :10.1.1.40.6428:10.1.1.40.9892
horizontal format database consists set input sequences 
input sequence set events items contained event 
contrast algorithm uses vertical database format maintain disk id list item shown 
entry id list sid eid pair item occurs 
enables check support simple id list joins 
computing vertical id list database frequent sequences computed single database scan 
database item read id list disk memory 
scan id list incrementing support new sid encountered 
computing number frequent items average id list size bytes 
naive implementation computing frequent sequences requires id list joins pairs items 
amount data read corresponds data scans 
clearly inefficient 
naive method propose alternate solutions 
preprocessing step gather counts sequences user specified lower bound 
information invariant computed cost amortized number times data mined 

perform vertical horizontal transformation fly 
done quite easily little overhead 
item scan id list memory 
sid eid pair say insert list input sequence example consider id list item shown 
scan pair insert list input sequence 
shows complete horizontal database recovered vertical item id lists 
computing recovered horizontal database straight forward 
form list sequences 
vertical horizontal database recovery 
sequence mining list sid update counts dimensional array indexed frequent items 

enumerating frequent sequences class shows pseudo code breadth depth search 
input procedure set atoms sub lattice id lists 
frequent sequences generated joining id lists pairs atoms including self join checking cardinality resulting id list min sup 
joining pruning step inserted ensure subsequences resulting sequence frequent 
true go ahead id list join avoid temporal join 
spade supports pruning practice databases looked improve running time 
hand successfully apply pruning store memory frequent sequences far 
imposes significant memory overheads experiments disabled pruning 
discuss details section 
sequences frequent current level form atoms classes level 
recursive process repeated frequent sequences enumerated 
terms memory management easy see need memory store intermediate id lists consecutive levels 
depth search requires memory classes levels 
breadth search requires memory classes levels 
frequent sequences level generated sequences current level deleted 
disk scans processing parent equivalence class initial decomposition relevant item id lists class scanned disk memory 
id lists atoms sequences initial class constructed joining 
pseudo code breadth depth search 
zaki item id lists 
frequent sequences enumerated described 
initial classes disjoint set items item id list scanned disk entire frequent sequence enumeration process sub lattices 
general case degree overlap items different sub lattices 
database portion corresponding frequent items need scanned lot smaller entire database 
furthermore sub lattices sharing common items processed batch mode minimize disk access 
claim algorithms usually require single database scan computing contrast current approaches require multiple scans 

temporal id list join describe perform id list joins sequences 
consider equivalence class atom set ab ad 
prefix rewrite class get pb pd 
observe class kinds atoms event atoms pb pd sequence atoms 
assume loss generality event atoms class precede sequence atoms 
extend class sufficient join id lists pairs atoms 
depending atom pairs joined upto possible resulting frequent sequences possible minimal common super sequences 
event atom event atom joining pb pd possible outcome new event atom pbd 

event atom sequence atom joining pb possible outcome new sequence atom pb 
sequence atom sequence atom joining possible outcomes new event atom af new sequence atoms special case arises join produce new sequence atom describe actual id list join performed 
consider shows hypothetical id lists sequence atoms compute new id list resulting event atom af simply need check equality sid eid pairs 
example matching pairs 
forms id list af 
compute id list new sequence atom need check temporal relationship pair check exists pair sid 
true means item follows item input sequence words input sequence contains pattern pair added pattern id list 
id list obtained similar manner reversing roles final id lists new sequences shown 
join sequences class prefix items eid time stamp sequence mining 
temporal id list join 
need keep track item eid determining equality temporal relationships 
optimization generate id lists possible new sequences just join 

pruning sequences pruning algorithm shown 
denote item sequence 
generating id list new sequence check subsequences length frequent 
frequent perform id list join 
dropped consideration 
note subsequences current class 
example consider sequence bf 
subsequences bf lie 
sequence pruning 
zaki class 
subsequence bf belongs class 
processed complete subsequence information pruning 
processed determine bf frequent 
partial pruning members class possible 
generally better process class lexicographically descending order case events information available pruning 
items event kept sorted increasing order 
example wanted test check class frequent processed solve classes reverse lexicographic order check bdf frequent 
practical note implement subsequence pruning step efficiently need store frequent sequences previous levels sort hash structure 
general pruning eliminate lot unnecessary candidates 
experiments section pruning help 
mainly lemma says id list join especially efficient large sequences generate longer sequences cardinality id lists decreases leads fast frequency checking 
words performing idlist join fast checking subsequences frequent hashing 
furthermore storing frequent sequences memory imposes significant memory overheads causes virtual memory exceeded large number frequent sequences 
experiments reported disabled subsequence pruning feature 
may databases pruning crucial performance support pruning datasets discussed 

experimental results section study performance spade varying different database parameters comparing gsp algorithm 
gsp implemented described srikant agrawal 
spade results shown bfs search 
experiments performed mhz mips processor mb main memory running irix 
data stored non local gb disk 
synthetic datasets synthetic datasets srikant agrawal albeit twice input sequences 
publicly available dataset generation code ibm quest data mining project ibm 
datasets mimic real world transactions people buy sequence sets items 
customers may buy items sequences may buy items multiple sequences 
input sequence size event size clustered mean may elements 
datasets generated process 
ni maximal events average size generated choosing items 
ns maximal sequences average size created assigning events ni sequence 
customer input sequence average transactions events created sequences ns assigned different customer elements respecting average transaction size generation stops input sequences sequence mining 
synthetic datasets 
generated 
srikant agrawal set ns ni 
shows datasets parameter settings 
refer reader agrawal srikant additional details dataset generation 
plan dataset real dataset obtained planning domain 
input consists database plans people city 
plan unique identifier sequence actions events 
event composed different attributes including event time unique event identifier action name outcome event set additional parameters specifying weather condition vehicle type origin destination city cargo type example plans shown 
plan represents input sequence sid 

example plan database 
zaki distinct attribute value pair item 
example action move action load distinct items 
set items forms event eid time 
example second row plan corresponds event load success exodus people 
data mining goal identify causes plan failures 
plan tagged failure success depending achieved goal 
mine dataset bad plans items plans input sequences events 
average plan length average event length 
details planning application section discuss sequence mining applied practice 

comparison spade gsp compares spade gsp different synthetic datasets 
graph shows results minimum support changed 
sets experiments reported value support 
bar labeled spade corresponds case computed vertical horizontal transformation method described section 
times gsp spade include cost computing 
bars labeled spade gsp correspond case computed preprocessing step times shown don include pre processing cost 
runs subsequence pruning disabled spade benefit 
figures clearly indicate performance gap algorithms increases decreasing minimum support 
spade twice fast gsp lower values support 
addition see spade outperforms gsp order magnitude cases 
reasons spade outperforms gsp 
spade uses simple temporal join operation id lists 
length frequent sequence increases size id list decreases resulting fast joins 

complicated hash tree structure overhead generating searching subsequences incurred 
structures typically poor locality parthasarathy zaki li 
hand spade excellent locality join requires linear scan lists 

minimum support lowered larger frequent sequences 
gsp complete dataset scan iteration 
spade hand restricts usually scans 
cuts costs 
drawn spade gsp comparison nearly benefit spade comes improvement running time pass algorithms spend roughly time computing 
fk spade outperforms gsp factor order magnitude 
sequence mining 
performance comparison synthetic datasets 
zaki 
performance comparison planning dataset 
compared performance algorithms plan database 
results shown 
case synthetic databases spade algorithm outperforms gsp factor 

scaleup study spade performs increasing number input sequences 
shows spade scales number input sequences increased fold number events increased respectively 
experiments performed dataset different minimum support levels ranging 
execution times normalized respect time input sequence dataset 
observed spade scales linearly 
study scale vary dataset parameters ways keeping average number items event constant increase average number events input sequence keeping average number events input sequence constant increase average number items event 
size datasets kept nearly constant ensuring product average event size average number events input sequence number input sequences remains 
aim experiments gauge scalability respect test parameters independent factors database size number frequent sequences 
shows scalability results 
ensure number frequent sequences doesn increase great amount absolute minimum support value percentages graph legends indicate value 
graphs database size kept constant graph varied varied second graph set varied varied 
sequence mining 
scale number input sequences 

scale number events input sequence event size 
easily observed algorithm scales linearly varying parameters 
scalability dependent minimum support value lower minimum support relatively frequent sequences generated increase number events event size takes time pattern discovery cases 
study scalability change size maximal elements ways keeping parameters constant increase average length maximal potential frequent sequences keeping parameters constant increase average length maximal potential frequent events 
constant parameters experiment varied 
second experiment constant parameters varied 
zaki 
scale frequent sequence length frequent event length 
shows algorithm scales test parameters 
higher values support time starts decrease increasing maximal element size 
fact average event size average number input sequence events remains fixed increasing maximal frequent sequence event size means fewer fit input sequence fewer frequent sequences discovered 
lower values support larger sequence introduce subsequences time starts increase initially decreases due reasons 
peak occurs roughly median values sequences experiment events experiment 

practical application sequence mining saw section spade efficient scalable method mining frequent sequences 
mining process rarely ends stage 
important aspect take results mining effectively target domain 
section briefly describe experiences applying sequence mining planning domain predict failures happen improve plans 
spade find frequent sequences developed system called plan mine zaki lesh ogihara integrated applications planning trips collaborative planning system ferguson james improve algorithm improving large probabilistic plans lesh martin allen :10.1.1.49.8206
trips integrated system person collaborates computer develop high quality plan evacuate people small island 
process building plan system simulates plan repeatedly probabilistic model domain including predicted weather patterns effect vehicle performance 
system returns estimate plan success 
additionally trips invokes sequence mining 
number frequent sequences effect different pruning techniques 
execution traces produced simulation order analyze plan failed 
information improve plan 
integrated improve algorithm automatically modifying plan higher probability achieving goal 
improve runs execution traces plan pinpoint defects plan lead plan failure 
applies qualitative reasoning plan adaptation algorithms modify plan correct defects detected 
applied spade planning dataset detect sequences leading plan failures 
domain complicated structure redundancy data spade generates enormous number highly frequent rules zaki lesh ogihara 
shows number mined frequent sequences different lengths various levels minimum support ran spade bad plans 
support level overwhelming number patterns 
support patterns quite useless predicting failures compute confidence relative entire database plans 
clearly potentially useful patterns sequences mined bad plans extract interesting ones set 
developed step pruning strategy selecting predictive sequences mined set 
pruning normative patterns eliminate normative rules consistent background knowledge corresponds normal operation plan eliminate patterns occur bad plans occur plans quite patterns predictive bad events 

pruning redundant patterns eliminate redundant patterns frequency proper subsequences eliminate patterns zaki obtained augmenting existing pattern frequency intuition predictive 
pruning dominated patterns eliminate dominated sequences predictive proper subsequences eliminate patterns obtained augmenting existing pattern shorter general higher confidence predicting failure shows reduction number frequent sequences applying kind pruning 
normative pruning removing patterns support plans get factor reduction sequences 
applying redundant pruning addition normative pruning reduces pattern set 
dominant pruning applied normative redundant pruning reduces rule set highly predictive patterns 
combined effect pruning techniques retain patterns highest confidence predicting failure confidence conf db db dg db dataset bad plans dg dataset plans 
steps carried automatically mining bad plans separately comparing discovered rules unsuccessful plans successful plans 
main goals improve existing plan generate plan monitor raising alarms 
case planner generates plan simulates multiple times 
produces database bad plans simulation 
information fed mining engine discovers high frequency patterns bad plans 
apply pruning techniques generate final set rules highly predictive plan failure 
mined information fixing plan prevent failures loop executed multiple times till improvement obtained 
planner generates final plan 
second goal planner generates multiple plans creates database bad plans simulation step 
high confidence patterns mined information generate plan monitor raises alarms prior failures new plans 
experiments zaki lesh ogihara showed improve improves plan success rate sophisticated methods choosing part plan repair able achieve maximum success rate 
showed output build execution monitors predict failures plan occur 
able produce monitors precision signal failures occur 

spade new algorithm fast mining sequential patterns large databases 
previous approaches multiple database scans sequence mining complex hash tree structures tend sub optimal locality spade decomposes original problem smaller sub problems equivalence classes frequent sequences 
equivalence class solved independently processed main memory 
spade usually database scans frequent sequences frequent sequences generating frequent sequences 
supports sequences available scan required 
spade uses simple temporal join operations ideally suited direct integration dbms 
extensive set experiments conducted show spade outperforms best previous algorithm gsp factor order magnitude precomputed support sequences 
excellent scaleup properties respect number parameters number input sequences number events input sequence event size size potential maximal frequent events sequences 
discussed mined sequences real application 
observed simple mining frequent sequence produces overwhelming number patterns trivial useless 
mined set contain potentially useful patterns 
form post processing necessary weed irrelevant patterns locate interesting sequences 
showed identify novel pruning strategies applied domain 
agrawal srikant 

mining sequential patterns 
th intl 
conf 
data engineering 
agrawal mannila srikant toivonen verkamo 

fast discovery association rules 
fayyad 
ed advances knowledge discovery data mining pp 

menlo park ca aaai press 
davey priestley 

lattices order 
cambridge cambridge university press 
ferguson james 

trips integrated intelligent problem solving assistant 
th nat 
conf 
artificial intelligence 
klemettinen mannila ronkainen toivonen 

knowledge discovery telecommunication network alarm databases 
th intl 
conf 
data engineering 
ibm 
www almaden ibm com cs quest html 
quest data mining project ibm almaden research center san jose ca 
lesh martin allen 

improving big plans 
th nat 
conf 
artificial intelligence 
mannila toivonen 

discovering generalized episodes minimal occurences 
nd intl 
conf 
knowledge discovery data mining 
mannila toivonen verkamo 

discovering frequent episodes sequences 
st intl 
conf 
knowledge discovery data mining 
oates schmill jensen cohen 

family algorithms finding temporal structure data 
th intl 
workshop ai statistics 
parthasarathy zaki li 

memory placement techniques parallel association mining 
th intl 
conf 
knowledge discovery data mining 
savasere omiecinski navathe 

efficient algorithm mining association rules large databases 
st intl 
conf 
large data bases 
srikant agrawal 

mining sequential patterns generalizations performance improvements 
th intl 
conf 
extending database technology 
zaki zaki parthasarathy ogihara li 

new algorithms fast discovery association rules 
rd intl 
conf 
knowledge discovery data mining 
zaki lesh ogihara 

sequence mining plan failures 
th intl 
conf 
knowledge discovery data mining 
zaki 

efficient enumeration frequent sequences 
th intl 
conf 
information knowledge management 
received february revised february accepted november final manuscript december 
