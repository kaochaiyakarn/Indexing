causal discovery mixture experimental observational data gregory cooper yoo center biomedical informatics center biomedical informatics university pittsburgh university pittsburgh pittsburgh pa pittsburgh pa edu edu describes bayesian method combining arbitrary mixture observational experimental data order learn causal bayesian networks 
observational data passively observed 
experimental data produced randomized controlled trials result experimenter manipulating variables typically randomly observing states variables 
presents bayesian method learning causal structure parameters underlying causal process generating data data contains mixture observational experimental case records causal process modeled causal bayesian network 
learning method applied input various mixtures experimental observational data generated alarm causal bayesian network 
experiments absolute relative quantities experimental observational data varied systematically 
training datasets learning method applied predict causal structure estimate causal parameters exist randomly selected pairs nodes alarm confounded 
reports structure predictions parameter estimates compare true causal structures parameters alarm network 
causal knowledge know want know science 
causal modeling discovery central science areas inquiry 
experimental studies randomized controlled trials provide trustworthy methods establishing causal relationships data 
experimental study variables manipulated typically randomly effects variables measured 
studies potentially highly informative may safe ethical feasible financially worthwhile 
observational data passively observed 
data readily available experimental data databases observational 
observational computer databases increasingly available opportunities increase causal discovery 
general exist observational experimental data set variables interest 
example clinical medicine growing abundance observational data contained routinely collected electronic medical records 
addition selected variables high clinical interest data 
need coherent way combining types data arrive assessment causal relationships clinical variables 
bayesian discovery causal networks active field research numerous advances continuing areas include causal representation model assessment scoring model search cooper 
prior bayesian discovery causal networks researchers focused primarily methods discovering causal relationships observational data 
notable exception heckerman learning influence diagrams causal models contains essential ideas learning causal bayesian networks combination experimental data deterministic manipulation observational data heckerman 
contribution current ideas investigate explicitly detail learning causal structures parameters arbitrary mixture observational experimental data 
particular current presents general bayesian analysis learning task including situation experimental manipulation deterministic 
specializes general formulation arrive closed form bayesian scoring metric learning causal structures parameters data mixture 
significantly scoring metric simple variation previous scoring metric bayesian network learning cooper herskovits heckerman 
previous implementations metric readily adapted learn causal networks combination observational experimental data 
investigates learning performance metric mixture experimental observational data generated alarm causal bayesian network 
modeling method causal bayesian network causal network short bayesian network arc interpreted direct causal influence parent node variable child node relative nodes network pearl 
illustrates structure hypothetical causal bayesian network structure contains nodes 
due limited space probabilities associated causal network structure shown 
chronic bronchitis fatigue history smoking lung cancer hypothetical causal bayesian network structure 
mass seen chest ray causal network structure indicates example history smoking causally influence lung cancer turn causally influence patient experiences fatigue 
causal markov condition gives conditional independence relationships specified causal bayesian network node independent non descendants non effects parents direct causes 
causal markov condition permits joint distribution variables causal bayesian network factored follows pearl xi denotes state variable denotes joint state parents xi denotes background knowledge discussed section 
bayesian analysis section considers posterior probability variable causes variable database measured variables denote additional set hidden latent variables 
designate union denote arbitrary causal bayesian network structure containing variables denote background knowledge may influence beliefs causal relationships variables background knowledge come scientific laws common sense expert opinion accumulated personal experience sources 
see section contain knowledge cases experimental observational 
derive posterior probability causes sum taken causal network structures contain just nodes contain arc non zero prior probability 
properties probabilities term sum equation may rewritten follows relative entire set causal structures considered probability constant equation shows posterior probability causal structure proportional view score context probability terms right side equation may expanded follows prior belief captures correctly qualitative causal relationships variables probabilities parameters relate nodes quantitatively respective parents likelihood data terms variable node interchangeably 
equation subsequent equations section substructure replaced substructure containing subset variables simplicity exposition focus section pairwise causal relationship form 
produced causal process generating data causal bayesian network expresses belief probability distributions serve model underlying causal process 
integral equation integrates parameters causal bayesian network structure derive called marginal likelihood 
combining equations obtain equation 
assumption equation assumption 
causal relationships represented causal bayesian networks 
full bayesian approach causal discovery expressed equation considers principle causal bayesian networks priori possible 
example sums equation possible causal bayesian network structures integrals possible parameters possible causal structure 
result global analysis causality derived posterior probabilities summarize comprehensive normative belief causal relationships set variables 
bayesian analysis equation presents considerable challenges assessment prior probabilities causal network structures parameters summation large set causal network structures evaluation integral 
focus task 
particular introduce set assumptions simplify evaluation integral show solution corresponds closely previous solution observational data 
assumption 
cases random sample joint probability distribution causal bayesian network structure parameters assumption implies cases independent conditioned generating model specified assumption 
assumptions express integral equation follows ch represents cases dataset equation term denotes causal bayesian network structure parameters infer probability state variables corresponds case containing observational data inference performed entire bayesian network 
generation case involved experimental manipulation model variables additional assumption assumption 
experimentally manipulated variable case probability modeled removing arcs setting value manipulated 
justification assumption follows 
manipulated deterministically forces outside causal network model longer influence variables model arcs removed 
set equal assume experimental manipulation deterministic 
see spirtes section detailed discussion assumption 
assumption consider case contains variable manipulated state case term equation inferred follows modify removing arcs remove parameters correspond removed arcs set modified causal bayesian network infer probability state variables observational variables 
generalization simultaneous manipulation multiple variables straightforward 
hidden variables missing data bayesian approach model explicitly cooper exact computation integral equation current methods usually intractable causal network contains hidden variable 
sampling approximation methods shown promise estimating integral missing data hidden variables 
modeling hidden variables missing data focus current 
consider case model variables set known states assumption 
missing data hidden variables 
assumption bayesian network inference reduces computing product conditional probabilities 
equation simplifies formally assume information xi manipulated state case contained background knowledge denoted xi variables xi denotes state variable xi case denotes states parents xi case case xi manipulated term equation replaced assumption probability variable state manipulated 
manipulated observed probability state conditioned states parents case notice parents observational variable may experimentally manipulated states case note manipulated cases manipulated cases 
order efficiently evaluate integral equation researchers introduced assumptions lead closed form solution cooper herskovits heckerman 
assumptions follow section expressed geiger heckerman integral equation computed efficiently closed form 
assumption 
variables discrete 
assumption parameter independence global parameter independence causal bayesian network structure parameters probabilities associated node probabilistically independent parameters associated nodes 
local parameter independence parameters associated node instance parents independent parameters node instances parent nodes 
assumptions permit terms equation obtain equation xi qi ri ijk number states denotes number joint states parents ijk number cases node passively observed state parents heckerman uses term mechanism independence causal version global parameter independence term component independence causal version local parameter independence heckerman 
states example manipulated cases ijk equal states addition note tally ijk indifferent parents attained states introduce additional assumptions 
assumption 
parameter modularity heckerman node parents distinct networks distribution parameters associated node identical networks 
assumption 
prior distribution parameters associated node dirichlet 
assumptions permit replacing equation dirichlet prior distribution 
solution equation assumptions follows cooper herskovits heckerman ij ij ij ijk ijk ijk gamma function ijk ij express parameters dirichlet prior distributions ri nij nijk assumptions follows results cooper herskovits heckerman observed estimate conditional distribution follows xi ijk nijk 
ij nij probabilities equation define parameters causal bayesian network structure perform probabilistic inference 
xb designate generic instance infer distribution variables conditioned state variables xb 
assume xa contains variables observed 
variable set xb may contain observed manipulated variables 
manipulated variable xb assumption implies remove arcs xb inferring conditional distribution infer distribution conditioned model averaging possible network structures follows xb term obtained substituting equation equation substituting equation equation 
example section derive marginal likelihood causal structure equal data table contains cases 
binary variables 
case state variable 
state obtained observation appears normal font 
state obtained manipulation appears outlined font 
table example dataset 
example equal causal structure apply equation derive follows ij ij nij ijk nijk ijk assumed parameters jk equal parameters jk equal 
convention represented 
parent state represented parent state 
example consider term corresponds frequency jointly state parent hypothesis considered state analysis section derive table considering cases manipulated correspond cases table 
cases occur jointly state state equation example 
note assume solve equation solving equation 
nondeterministic manipulation section considers situation experimental manipulation deterministic 
experimenter decides manipulate state variable takes state current section generalize result situation manipulation may deterministic 
classic example medicine patient volunteered participate study may randomized receive medication may decide take variable represents value experimenter wishes manipulate denote experimenter wish manipulate wants merely observe value 
augment model variables section include carry analysis section assuming observational data 
causal network hypotheses analysis include probabilities specify prior beliefs causal influence prior beliefs updated data stated experimental wishes observed variable outcomes 
general formulation described previous paragraph simplifies model section assume probability variable parent case term equation replaced mi represents state hypothesized parents section contains explanation choices ijk parameters 
variables case formulation previous paragraph general distribution xi mi deterministic 
prior belief data may instances support strongly parent xi indicating experimental intentions little effect actual values xi experimental methods evaluating causal learning ideally know real world causal relationships structure parameters set variables interest 
knowledge generate experimental observational data 
datasets input learning method predict causal structure estimate causal parameters exist modeled variables 
predictions estimates compared true causal relationships 
confident knowledge underlying causal processes relatively rare initial study causal discovery mixed data gold standard causal model constructed expert 
particular alarm causal bayesian network contains arcs nodes possible states 
beinlich constructed alarm research prototype model potential problems operating room beinlich 
constructing alarm knowledge medical literature personal experience 
remainder section describes generated data alarm data evaluating learning method described section 
data generation nodes alarm may paired unique ways 
denote arbitrary pair nodes 
directed causal path say causally related 
share common ancestor say confounded 
table summarizes types causal relationships node pairs alarm 
randomly selected node pairs 
table shows frequencies types pairs sampled 
frequencies table closely match table supporting sample biased 
experiment reported focused node pairs confounded 
simplify experimental design analysis initial experiment 
table shows possible modeled relationships exist nodes confounded causal paths particular version alarm publicly available downloading alarm dsc bayesian network repository www nt cs berkeley edu home nir public html repository alarm htm 
causal paths connecting paths pearl 
table types node pairs alarm 
causally related total confounded total table types node pairs sampled alarm 
causally related total confounded total table causal hypotheses modeled 
double headed arcs convey causal influence direct relative modeled variables indirect 
hypothesis label causal bayesian network hypothesis table see nodes percent node pairs alarm 
table indicates pairs included sample denote pairs 
pair stochastic simulation henrion generate types data alarm 
particular generated data manipulated observed manipulated observed observed 
data generated manipulation uniform prior states manipulate manipulated variable binary states manip manip 
learning method learning dataset consisted cases manipulated observed cases manipulated observed cases observed 
contains cases 
varied incrementally 
value varied incrementally 
pairs nodes method section compute posterior probability distribution causal network structures table 
assumed uniform prior probability structure 
applying equation derive marginal likelihood parameter priors ijk choice priors properties heckerman 
priors weak sense marginal likelihood influenced largely dataset second observational data structures equal posterior probabilities 
properties provide type noninformative parameter prior 
chose noninformative prior current evaluation order draw insights mainly data subject beliefs 
evaluation metrics node pair true designate structures table relationship alarm 
pair dataset derived structural error metric true true posterior probability derived method section 
method predicted true relationship alarm probability error 
computed structural error rate averaging pairwise error rates follows sum taken node pairs 
analyses corresponding causally related nodes tabulated table corresponding causally unrelated nodes 
interested learned models able accurately predict distribution variable manipulation observation variable 
remainder section define error predicting distribution observed 
define error predicting distribution manipulated 
denote arbitrary state arbitrary state denote marginal probability observed alarm bayesian network 
designate conditional probability inferred alarm observing observed pe estimate conditional probability obtained applying model averaging equation 
define follows expected error predicting observation observation outer sum taken states inner sum taken states number states 
database measures expected absolute error predicting observed state observed state expectation taken respect observational distribution states observational prediction error defined follows consider situation manipulated state observe distribution notation manip represent manipulated state particular reason assume manipulated state 
purpose deriving error metric assume equally manipulated rx possible states 
terms obtain manipulation error metrics rx pa manip pe manip 
experimental results discussion table shows results structure prediction error causally related 
prior probability structure error rate approximately data 
average experimental data contains probable prediction generating causal relationship 
experiment stopped experimental cases expect error rate continue decreasing experimental cases available 
observational data sufficient determine causing causing significantly table indicates observational data augment experimental data decreasing error increasing posterior probability assigned true data generating relationship 
observational data able helping eliminate hypothesis related 
table structural error metric pairs nodes causally related confounded different combinations observational data data resulting experimental manipulation 
experimental data cases obs 
data cases stated experimental observational data error rate table 
observational data added error rate initially increases generating structures weakly correlated samples order cases structures relatively low posterior probabilities causally related 
performed additional simulation cases observational data pairs error rate converged expected 
table shows structure prediction error causally related 
expected experimental observational data able determine equally independent 
combining types data decreases error anticipated 
table structural error metric pairs nodes confounded related 
experimental data cases obs 
data cases tables number observational cases yields lower observational prediction error rate number experimental cases 
primary reason result appears observational data relevant performing parameter estimation observational prediction general subset experimental data relevant 
notice observational cases adding experimental data relatively ineffective lowering error rate 
table observational prediction error metric pairs nodes causally related confounded 
experimental data cases obs 
data cases table observational prediction error metric pairs nodes confounded related 
experimental data cases obs 
data cases table indicates causally related sole experimental data leads lower errors predicting manipulations sole observational data 
experimental data observational data distinguish causing causing table shows small amounts experimental data observational data significantly decrease prediction error 
example experimental cases observational data error 
adding just observational cases decreases error half 
experimental cases observational cases error reduces comparable error experimental cases 
pattern interesting real world stuck relatively small amount experimental data expensive difficult acquire may abundance observational data 
noteworthy table error rate observational cases experimental predictions 
believe result occurred part causal relationships analyzed weak 
issue deserves additional investigation 
table manipulation prediction error metric pairs nodes causally related confounded 
experimental data cases obs 
data cases table shows causally related observational experimental data similar terms predicting effect manipulation effect particularly larger datasets 
table manipulation prediction error metric pairs nodes confounded related 
experimental data cases obs 
data cases bayesian analysis causal discovery mixture experimental observational data similar analysis observational data 
assumptions closed form bayesian scoring metric derived differs existing scoring metric observational data interpretation numerical counts ijk terms 
means existing implementations observational scoring metric readily adapted score causal networks experimental observational data available 
empirical evaluation learning method performed data generated alarm causal bayesian network 
general patterns observed support combining observational experimental data useful learning causal structure performing predictions observations manipulations 
tasks results quantify data type tends useful lowering error rates data type relatively scarce 
emphasize patterns investigated seen far data generated alarm network 
additional studies needed see patterns appear data generated causal networks 
current includes expanding set hypotheses model confounding variables increase number causal hypotheses 
begun investigating causal learning confounding possible results preliminary 
addition evaluation reported current uses simple pairwise causal relationships 
observational data potentially informative measured variables 
plan alarm investigate causal discovery causal hypotheses allowed contain variables 
important evaluate causal learning variety different causal bayesian networks generating models 
interesting apply learning methods real observational experimental data 
real data require able model missing data may missing random 
acknowledgments stefano monti comments earlier draft 
research reported supported nsf iis 
beinlich suermondt chavez cooper 
alarm monitoring system case study probabilistic inference techniques belief networks proceedings second european conference artificial intelligence medicine 
cooper 
method learning belief networks contain hidden variables proceedings workshop knowledge discovery databases 
cooper 
overview representation discovery causal relationships bayesian networks 
glymour cooper 
eds computation causation discovery aaai press mit press menlo park ca 
cooper herskovits 
bayesian method induction probabilistic networks data machine learning 
geiger heckerman 
characterization dirichlet distribution application learning bayesian networks proceedings conference uncertainty artificial intelligence 
heckerman 
bayesian approach learning causal networks proceedings conference uncertainty artificial intelligence 
heckerman geiger chickering 
learning bayesian networks combination knowledge statistical data machine learning 
henrion 
propagating uncertainty bayesian networks logic sampling 
lemmer kanal 
eds uncertainty artificial intelligence north holland amsterdam 
pearl 
probabilistic reasoning intelligent systems morgan kaufmann san mateo ca 
spirtes glymour scheines 
causation prediction search available hss cmu edu html departments philosophy tetra book book html 
