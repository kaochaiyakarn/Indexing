darpa communicator dialog travel planning systems june data collection walker aberdeen boland bratt garofolo hirschman le lee narayanan papineni polifroni potamianos prabhu rudnicky sanders seneff stallard whittaker labs mitre university louisiana sri international nist mitre nist labs labs ibm university colorado mit lucent bell labs labs carnegie mellon university nist mit bbn technologies labs describes results experiment different darpa communicator systems participated june data collection 
systems supported travel planning utilized form mixed initiative interaction 
varied critical dimensions targeted different back databases travel information different modules asr nlu tts dialog management 
describe experimental design approach data collection metrics collected results comparing systems 

objective darpa communicator project support rapid cost effective development multi modal speech enabled dialog systems advanced conversational capabilities 
order reality important able evaluate contribution various techniques users willingness ability spoken dialog system 
june conducted exploratory experiment participating communicator systems 
systems supported travel planning utilized form mixed initiative interaction 
systems varied critical dimensions targeted different backend databases travel information system modules asr nlu tts dialog management typically different systems 
experiment designed evaluation subcommittee composed representatives communicator site nist 
logfile standard developed mitre systems collect set core metrics making cross site comparisons 
described evaluation committees webpage 
collected user satisfaction metrics web survey 
results discussed detail show user satisfaction differed considerably systems 
subsequent modeling user satisfaction applying paradise framework gave insight system satisfactory :10.1.1.43.3525
metrics significant predictors user satisfaction metrics task completion task duration recognition accuracy mean system turn duration accounted variance user satisfaction 
section explains walker research att com experimental design section presents results 
section discusses plans 

experimental design setup different communicator travel planning systems participated data collection labs bbn technologies carnegie mellon university university colorado ibm lucent bell labs mitre sri international 
report results anonymously random number assigned site 
ran controlled experiment set realistic subjects target population frequent travelers interacted communicator spoken dialog systems 
recruited native english speakers call systems periods days plan travel tasks set realistic scenarios 
subjects carried scenarios fixed order 
goal dialogs task system subjects called systems resulting corpus consists dialogs 
task scenarios consisted fixed open scenarios 
fixed scenarios designed vary task complexity task complexity purpose defined simply number constraints user communicate system 
user tabular format 
open scenarios defined user 
completing pre defined tasks systems users asked remaining systems plan intended business trip plan vacation 
asking users define tasks open scenarios intended approximate conditions systems field discuss intention achieved 
dialogs recorded full nist connecting call central call router 
site provided standard logfile transcriptions recordings user utterances 
call users gave subjective feedback web survey 
communicator data collection designed possible apply paradise evaluation framework integrates unifies previous approaches evaluation :10.1.1.43.3525
framework posits maximizing user satisfaction system objective task success various interaction costs calculated metrics predictors user satisfaction 
metrics collected call consisted objective metrics extracted logging subjective metrics collected survey 
survey calculate user satisfaction asking user specify degree agreed set statements point likert scale 
conversation easy get information wanted 
task ease system easy understand conversation 
tts performance conversation knew say point dialogue 
user expertise system worked way expected conversation 
expected behavior experience conversation system get travel information system regularly 
values responses summed giving dialog measure ranging 
addition ternary definition task completion annotated hand call 
distinguish exact scenario completion esc scenario completion scenario completion 
metric arose callers completed itinerary assigned 
may resulted caller didn correct system misunderstood 
case system viewed having done best information provided 
argues defining task completion esc 
examination dialogs suggests category arose rational reaction repeated recognition error 
fact surveys included comments supports users generally attempting complete described scenarios 
decided distinguish cases users completed assigned task completed task call ended itinerary completion 
analysis results exact scenario completion esc scenario completion esc 
concerned user behavior experimental setup separately hand tagged dialog user behavior 
descriptions provided 
set metrics dialog efficiency metrics total elapsed time time task system turns user turns turns task time turn system module dialog quality metrics word accuracy sentence accuracy mean response latency response latency variance task success metrics perceived task completion exact scenario completion scenario completion user satisfaction sum tts performance task ease user expertise expected behavior 

experimental results experiment resulted dialogs dialogs system numbering 
variation number dialogs system task resulted problems system stability stability load central call router 
design subjects design subjects called systems 
report analysis data 
user behavior labeled dialog types user behavior 
percentages behavior 
goal directed user completely focused task exhibits behaviors 
initially user took seconds respond system responding answering wrongly 
false acceptance users failed correct system misunderstanding 
wrong information users provided information inconsistent fixed scenario 
scenario switch category open tasks user changed plans dialog response repeated recognition error 
unknown case covers dialogs logfile generated system crashed prematurely ended call 
user satisfaction initially examined differences user satisfaction systems shown box plot 
box plot indicates full range values user satisfaction interquartile range box 
median distribution shown horizontal line box 
way anova user satisfaction site modified bonferroni statistic shows user satisfaction metric distinguishes groups performers sites top group sites second group sites defining third fourth group 
examined relationship individual components user satisfaction task ease tts performance user expertise expected behavior cumulative user satisfaction measure 
contrast previous components contributed similarly measure 
correlation user satisfaction task ease tts performance user expertise expected behavior 
suggests question asked question stand rest 
examined significant differences systems components 
expect significant differences components pattern component tended main mirror pattern shown user satisfaction user satisfaction site id user satisfaction site id applied paradise develop models user satisfaction examined differences sites metrics significant predictors user satisfaction 
order provide baseline performance model initially derived model set core metrics typically available dialog corpus task completion task duration sentence accuracy 
models user satisfaction core metrics account variance user satisfaction 
tailed test shows predictors significant level 
finding task completion recognition performance significant predictors duplicates previous results :10.1.1.43.3525
fact task duration significant predictor may simply indicate larger differences task duration corpus 
metrics available communicator logfile standard utilized best model fits obtained addition metric system turn duration 
model accounts variance user satisfaction learned model user sat sum esc sacc esc ternary task completion metric time task sacc sentence accuracy average time system turn 
examined metrics significant predicting user satisfaction distinguished sites task completion examined task completion scenario site 
examined task completion scenario order determine experimental manipulation task complexity tasks difficult differences completion open tasks scenarios fixed tasks scenarios 
way anova esc session showed significant differences sessions esc metric metric 
reasons contrary expectations users readily modified travel plans open tasks system couldn understand airport bali thought user wanted fly st petersburg russia users changed vacation plans 
fact differences completion session suggests experience systems improve users ability complete tasks 
may users called system 
see discussion 
value sess completion metric esc completion session id user tasks sequence order systems varied 
way esc site indicate significant differences task completion 
way anova esc site modified tree models full set metrics account variance user satisfaction bonferroni statistic multiple comparisons defines groups performers sites top group sites second group sites lowest group 
way anova scenario completion site modified bonferroni statistic defines groups 
shows task completion performance task duration 
way anova task duration site modified bonferroni statistic multiple comparisons indicates significant differences task duration distinguishes groups performers site top group shortest durations sites second group sites third group 
interesting case task duration calls itinerary completed failed tasks due system crashes early dialog 
box plot indicates performance site task duration task completion subset 
oneway anova task duration site subset indicates significant differences value completion site id task duration completed tasks site id completion metric esc sentence accuracy way anova sentence accuracy site modified bonferroni statistic showed significant differences sites groups performers 
systems support voice barge correlated higher accuracy 
strong interaction gender sentence accuracy site recognition performance sites better female speakers better males difference 
see box plot 
furthermore experimental design attempted balance gender subjects added users failed call 
user population female male causing problems sites poor recognition performance female speakers 
system turn duration paradise model indicates system turn duration positively correlated satisfaction 
flight presentation utterances longer system turns may simply indicate presentation potential itineraries 
acc acc sentence accuracy females vs males site id user words turn user words turn significant predictor user satisfaction examined metric indicator user initiative 
way anova site revealed significant differences sites amount initiative users took 
particular site site half dialogs average user words turn greater 
examination dialogs site suggests may due open prompts dialog tell travel plans phases dialog 
example system having trouble understanding user open ended suggestions try asking flights major cities directive prompts please tell destination 
discussion analysis identified issues data collection 
issue subjects design 
thought allow learn comparisons systems believe design may result behavior reflecting common denominator users called system accommodated behavior flexible system 
second issue tabular presentation fixed scenarios users took little initiative presentation format may lead believe conversation simply filling slots table 
third issue users doing open scenarios change task vs scenarios approximate users planning real trips 
expect address problems ways 
second data collection scheduled april longitudinal experiment months users repeatedly system 
better approximate real conditions users able learn systems providing system designers opportunity explore algorithms system adaptation users 
second users frequent travelers call system plan real trips 
short long users 
long users perform fixed learning scenarios data collection provide data adaptation algorithms create expert population 
third hope audio presentation learning tasks address problems tabular presentation avoiding problem putting words user mouth 
experimental design described detail evaluation committee web page 
related developed additional qualitative metrics dialog act tags comparing communicator systems dialog act metrics improve models user satisfaction 
plan utilize metrics data collection 
acknowledgments supported darpa mda 
danieli 
field trials italian arise train timetable system 

maynard 
devillers rosset 
predictive performance dialog systems 
int 
conf 
language resources evaluation lrec 
hirschman bates dahl fisher garofolo pallett smith price rudnicky 
multi site data collection evaluation spoken language understanding 
proc 
human language technology workshop 
hirschman lynette 
evaluating spoken language interaction experiences darpa spoken language program 
ed spoken language discourse cambridge mass mit press 
jack foster 
intelligent dialogs automated telephone services 
int 
conf 
spoken language processing larsen 
combining objective subjective data evaluation spoken dialogs 
esca workshop interactive dialog multi modal systems love foster jack 
identifying salient usability attributes automated telephone services 
int 
conf 
spoken language processing polifroni seneff 
galaxy ii architecture spoken dialog evaluation 
nd international conference language resources evaluation lrec darpa communicator evaluation committee website 
www research att com walker eval eval html aberdeen mitre org 
rudnicky 
factors affecting choice speech keyboard mouse simple data retrieval task 
eurospeech 
sturm den os cremers 
evaluation dutch train timetable information system developed arise project 

shriberg wade price 
problem solving spoken language systems sls factors affecting performance user satisfaction 
proc 
darpa speech nl workshop sparck jones galliers 
evaluating natural language processing systems springer 
stallard 
talk travel conversational system air travel planning 
proceedings applied natural language processing conference seattle washington 
walker kamm litman :10.1.1.43.3525
developing general models usability paradise 
natural language engineering special issue best practice spoken dialog systems walker passonneau 
date dialog act tagging scheme evaluation spoken dialog systems 
human language technology conference 
san diego march 
