modular scheduling approach grid application development environments holly henri casanova fran berman san diego supercomputer center university california san diego casanova berman sdsc edu version april propose adaptive scheduling approach designed improve performance parallel applications computational grid environments 
primary contribution design modular provides separation scheduler application specific components needed scheduling process 
part scheduler developed search procedure effectively efficiently identifies desirable schedules 
test cases approach selected applications class iterative mesh applications 
test applications developed data mappers performance models 
prototype approach conjunction application specific components perform validation experiments production grid environments 
results show scheduler provides significantly better application performance conventional scheduling strategies 
show scheduler gracefully handles degraded levels availability application grid resource information 
demonstrate overheads introduced methodology reasonable 
evolved context grid application development software project grads 
scheduling approach designed easily integrated grads program development tools 
key words scheduling grid computing programming environments parallel computing 
vast improvements wide area network performance pervasiveness commodity resources distributed parallel computing benefit increasingly rich computational platform 
focused development efforts shown advantage computational grid environ ments scientific computing requires extensive labor support distributed computing experts 
grid infrastructure projects provided services needed grid computing middleware services help reduce programmer effort improve application performance platforms 
middleware generally account specific needs applications 
example application unique resource requirements considered scheduling material supported national science foundation 
application grid resources 
generally programmer wants take advantage computational grids responsible transactions require knowledge application hand examples include discovering resources selecting application appropriate subset resources staging binaries selected machines long running applications monitoring application progress 
sci benefit extensive resources offered computational grids application development remains daunting proposition 
solution develop software frees user responsibilities 
grid application development software grads project seeks provide solution developing comprehensive programming environment explicitly incorporates application characteristics requirements ap plication development decisions 
goal project provide integrated grid application development solution incorporates activities compilation scheduling staging binaries data application launch monitoring application progress execution 
interested specifically scheduling process required system 
grads design assigns scheduler responsibility discovery available resources selection application appropriate subset resources mapping data tasks selected resources 
application schedulers long considered important tool usage computational grids 
fact projects developed successful scheduling strategies grid :10.1.1.42.8707:10.1.1.47.2751:10.1.1.21.1251:10.1.1.15.9060
schedulers incorporate specific needs applications scheduling decisions fulfill design requirements scheduler grads 
grads solution easy apply variety application development scenarios scheduler easily applied variety applications 
unfortunately schedulers mentioned previously developed application specific class applications designs generally easily re targeted applications classes 
difficulty re targeting designs arises fact application specific details components generally embedded scheduling software 
design difficult determine components need replaced incorporate needs new application 
propose modular scheduling approach explicitly separates general purpose schedul ing components application specific components needed scheduling process 
specifically application requirements characteristics encapsulated performance model analytical metric performance expected application set resources data mapper direc tives mapping logical application data tasks physical resources 
core scheduler general purpose schedule search procedure effectively efficiently identifies desirable schedules 
scheduler provides framework schedule search procedure conjunction application specific performance model mapper provide scheduling decisions appropriate needs application 
test cases approach selected applications class iterative mesh ap plications 
test applications developed data mappers performance models 
prototype approach conjunction application specific components perform tion experiments production grid environments 
results demonstrate scheduler provides significantly better application performance conventional scheduling strategies 
show scheduler gracefully handles degraded levels availability application grid information 
demonstrate overheads introduced methodology reasonable 
expect general purpose software achieve performance highly tuned application specific scheduler goal provide consistently improved performance relative conventional scheduling strategies 
primary contributions follows 
approach modular easily instantiated applications 
ii 
scheduler gracefully handles degraded levels availability application grid information iii 
scheduler simplifies usage grid automating scheduling process 
furthermore compared conventional approaches user directed scheduling approach provides improved application performance reduced failure rates production grid environments 
iv 
scheduler function stand fashion validated exper iments fact integrated component grads system 
scheduler described prototype scheduling component developed grads usage multiple applications 
organized follows 
section describe scheduler design 
section details test applications presents performance model mapper designs 
section results obtained applying methodology computational grid environments 
section describe related conclude 

scheduling section describes scheduler design 
provide context rest section describe scheduling scenario address 
scheduling scenario begins user application wishes schedule application computational grid resources 
application parallel may involve significant inter process communication 
target computational grid consists heterogeneous workstations connected local area networks lans wide area networks wans 
user may directly contact scheduler submit scheduling request intermediary component grads system contact scheduler submit user request 
case assume goal scheduling process find schedule minimizes total turnaround time scheduling time application run time 
selected schedule modification application execution consider rescheduling 

architecture presents primary components scheduler interactions components 
provide rest expect components interactions completely clear point 
prob info perf model mapper user mach list final schedule mds search procedure fig 
scheduler design 
search procedure core scheduler 
procedure responsible searching schedules appropriate target application 
schedule consists ordered list machines mapping data tasks machines 
search procedure responsible finding best schedule final schedule 
submitting application scheduler user obtain develop application specific components 
performance model procedure call provides prediction application performance set resources 
variety performance metrics scheduling grid info nws section assume performance model predict application execution time 
mapper procedure call maps logical application data tasks physical resources 
machine schedule mapper define piece application data assigned processor 
components application specific run generic 
application run user defines prob lem parameters problem size 
performance model mapper instantiated information appropriate current problem run 
describe application specific performance models mappers section section simply assume components available 
user submit machine list containing machine names user access forgo discussion list section 
machine machine list collect resource information cpu speed available physical memory bandwidth hosts 
information retrieved resource information providers network weather system nws metacomputing directory service mds discuss services section 

search procedure schedule search procedure core scheduling methodology 
goal searching process find groups machines prove performance efficient platforms application call groups candidate machine groups 
find corresponding candidate schedules search procedure identifies generates data map 
performance model select best candidate schedule 
straightforward approach search process exhaustive search possible groups machines ignoring permutations ordering defined mapper 
larger resource set sizes moderately complex performance models mappers search feasible 
practical search procedure extensive careful pruning search space 
pseudo code schedule search procedure 
loop list target refined different resource set characteristic connectivity outer loop com putational memory capacity individual machines second loop selection appropriate resource set size inner loop 
goal generate moderate number ensuring exclude performance efficient 
step search procedure call method method takes list machines organizes disjoint subsets sites network delays subset lower network delays subsets 
implementation group machines site share domain name plan consider sophisticated approaches 
method computes power set set sites exclude algorithm mapper sites sites collection computation memory dual size collection cmg collection mapper cmg map cmg return fig 
schedule search procedure 
null set 
example set sites site collections 
machine collections identified outer loop search procedure examines turn 
middle loop search procedure seek identify machines exhibit high local memory computational capacities 
generally know priori machine characteristics greatest impact application performance define metrics sort machine list computation metric emphasizes computational capacity machines memory metric emphasizes local memory capacity machines dual metric places equal weight factor 
inner loop exhaustively searches appropriately sized resource group 
resource set size selection complex depends problem parameters application characteristics detailed resource characteristics 
potentially resource set sizes poor predictions include resource set sizes search 
described momentarily application performance model select different schedules 
note exhaustive search level procedure feasible due extensive pruning performed loops 
method sorts input machine list collection machine type metric returns best number machines 
mapper called obtain data map current cmg mapping process typically dependent characteristics target resource group included parameter mapper 
mapper unable find feasible mapping due constraints local machine memory capacities current cmg skipped search process continues 
returned map valid combines map cmg form schedule 
method called compare current schedule best schedule discovered search far 
exact comparison mechanism depends type performance model available 
default assume performance model provides execution time predictions default returns schedule lowest predicted execution time 

search complexity straightforward schedule search method exhaustive search search guaranteed identify optimal cmg 
resource pool size search examine number equal 


example schedule search machine resource group require evaluation 
reasonably sized resource set performance model evaluation mapping process time intensive exhaustive search simply costly 
vast majority cases search procedure provides impressive reduction search space 
demonstrate develop loose upper bound number considered search heuristic 
assuming sites resource set consideration obtain site collections fact exclude null set leaving collections 
consider resource orderings collection computation memory dual 
ordered collections exhaustively search possible subset sizes 
number resources site topology collection dependent characteristics grid environment predict priori number resources ordered collections 
upper bound assume collection size size entire resource pool 
third loop search procedure distinct subsets generated ordered collection 
upper bound total number identified search procedure recall earlier example machine set exhaustive search required evaluation case 
supposing resource set included sites search procedure require evaluation 
fact assume machines sites search procedure requires evaluation 
improvement gained methodology greatest number sites consid eration significantly number machines case vast majority modern grids 

grid information computational grids highly dynamic environments compute network resource availability varies grid information sources periodically unstable 
strive provide best effort service supporting multiple information sources possible type information required scheduler 
currently support information collection widely grid resource information systems metacomputing directory service mds network weather service nws 
mds grid information management system collect publish system configuration capability status information 
examples information typically retrieved mds server include operating system processor type speed number cpus available software availability installation locations 
nws distributed monitoring system designed track forecast resource conditions 
examples information typically retrieved nws server include fraction cpu available newly started process amount memory currently unused bandwidth data sent remote host 
scheduling methodology utilize types resource information list machines available run local computational memory capacities machine network bandwidth latency information 
list machines currently obtained directly user secure mds publishing mechanisms available user account information published directly mds retrieved automatically scheduler 
local machine computational memory capacity data sort machines search procedure needed input performance model mapper implementations 
network bandwidth latency data similarly required input performance model mapper implementations 
important characteristic approach scheduler gracefully copes degraded grid information availability 
possible support source type resource information required scheduler 
furthermore particular type information available specific machines machine list required scheduler scheduler gracefully excludes machines search process 
experience application schedulers gracefully handle situations leading scenarios scheduler fails 

application case studies section describe specific applications demonstrate scheduling methodology validation experiments 
required scheduling methodology develop performance models mapping strategies application 
application develop performance model predicts execution time memory usage 
strategy comparing candidate schedules absence execution time model strategy demonstrates scheduling framework adjusted accommodate alternative performance metrics types performance model 
implement mappers applied test applications time balance mapper execution time model available equal allocation mapper applied application information limited memory usage model 

case study applications chosen applications class regular iterative mesh applications important domains science engineering :10.1.1.109.2076
specifically focus game life jacobi 
selected applications initial test cases known straightforward describe share performance characteristics applications 
conway game life known binary cellular automaton fixed set rules determine generation cells state current generation 
dimensional mesh pixels represent environment pixel mesh represents cell 
iteration state cell updated point stencil 
strip data partitioning strategy strategy typically exhibits lower communication costs partitioning schemes important consideration grid computing 
processor manages data strip defines pixel wide set ghost cells data grid edges 
iteration consists computational phase processors update portion data array communication phase processors swap ghost cell data neighbors 
jacobi method simple algorithm context laplace equation 
describe general linear system solver version involves communication broadcasts 
method attempts solve square linear system ax iteration formula ajj bj value jth unknown th iteration 
method guaranteed converge matrix diagonally dominant 
popular parallel data decomposition jacobi method assign portion unknown vector processor processors need store rectangular sub matrices processor computes new results portion broadcasts updated portion processor 
final phase iteration termination detection phase 
method stationary meaning matrix fixed application 
implemented test application spmd style computation message passing interface mpi 
allow load balancing implemented support irregular data partitions applications 
globus enabled version mpich mpich order run computational grid testbed 

application performance modeling scheduling framework dependent availability performance model 
method described previous section assumes performance model predicts application execution time 
ultimately performance models may automatically generated compiler grads framework 
moment develop performance model jacobi game life 
develop memory usage model required mapper discussion section 
applications support rectangular data grids assume full data mesh dimensional square 
definitions rest section 
refer size dimension data mesh note number data elements amount grows refer processors chosen execution pp size data partitions allocated processor np 

memory usage model magnitude performance degradation due paging memory disk ensure application fits available memory processors selected execution 
compute amount memory bytes required data strip size ni ni number bytes storage allocated element data domain 
game life allocates matrices integers jacobi allocates matrix doubles 
architectures targeted bytes allocated integer bytes allocated double 
applications 
recall local processor available memory availability supplied total physical memory values mds free memory values nws 
practice close match provides overly tight fit due additional memory needed application memory contention system small user processes 
early experimental results memory usage benchmarks increasing provides reasonable tradeoff grads computational grid environment 

execution time model target regular synchronous iteration applications application execution time assumed proportional iteration time slowest processor 
iteration time processor pi naturally modeled sum computation time communication time itt compt 
computation phase test applications primarily consists data update process iteration may include termination detection operation jacobi 
model computation time processor pi compt ni number processor cycles performed application element data domain 
computational capacity processor pi represented raw cpu speed mds currently available cpu nws combination thereof 
fully instantiate model need determine appropriate value case study application 
methods source code assembly code analysis opted empirical approach ran applications dedicated resources known cpu speed iterations computed average values 
game life communication phase consists swapping ghost cells neighboring machines 
non blocking sends receives theory messages iteration overlapped 
practice processors simultaneously participate message transfers reduction performance message importantly processors reach communication phase iteration moment 
initial approximation assume messages particular neighbor overlapped communication different neighbors occurs distinct phases serialized 
jacobi communication phase involves series broadcasts iteration machine computation root broadcasts 
mpi implementation broadcast implemented binomial tree 
approximation modeling communication structure calculate average message time calculate communication time processor pi log 
game life jacobi communication models depend model cost sending message machines 
initially opted simple popular latency bandwidth model message sent pi pj latency bandwidth measurements forecasts provided nws 
observed model significantly estimates message transfer times applications 
bandwidth model latency led better predictions possibly nws measurement techniques mpi implementation network topologies 
rest accurate bandwidth model 

alternative performance models metrics section scheduling methodology assumption application specific performance model available 
wanted different performance metric different performance model 
due modularity scheduling approach component needs modified method implementation see 
example suppose memory usage model available execution time model 
memory usage information mapper see section ensure candidate schedules fulfill application memory requirements 
alternative performance model purpose schedule comparisons series heuristics evaluate candidate schedules satisfy set broad resource requirements bandwidth computational capacity 
presents decision tree employed implement series simple heuristics 
decision tree appropriate jacobi game life validation experiments section 

application data mappers function mapper determine appropriate mapping strip widths np processors pp 
mapping process involves distinct subproblems 
problem determine topological arrangement machines physical processor assigned logical processor position application communication costs minimized 
second problem find allocation processors rows data mesh assigned process application resource requirements met possible application execution time minimized 
sections mappers equal allocation mapper time balance mapper 

equal allocation mapper mapper simply allocated uniformly processors assigned equally sized data strip size number pixels assigned processor returning data map mapper verifies processor sufficient local memory support application memory requirements 
processor sufficient memory mapper returns error 
scheduling context section current machine group removed list search process continues 
mapper requires memory usage model full execution time model 
production grid scheduling systems expect applications full performance model return better complete resource info schedules 
equivalent return second better effective bandwidth higher schedules 
bw min bw link schedule equivalent schedule require fewer resources 
effective computational capacity higher schedules 
power min comp 
capacity resource schedule equivalent equivalent fig 
alternative schedule comparison design 
design employs series comparison heuristics place execution time model 
available 
case scheduling methodology applied pairing equal allocation mapper alternative performance model preceding section 
explore scenario section 

time balance mapper regular synchronous iteration applications application execution time limited progress slowest processor 
total execution time minimized finding data map processors complete iteration time minimizing synchronization times 
goal time balance mapper find data map ensuring application memory requirements met 
approach formalize machine resource availabilities application memory requirements execution time considerations series constraints 
allocation framed constrained optimization problem solution map data strip widths processors 
describe general operation mapper describe formalization problem 
called time balance mapper verifies aggregate memory cmg sufficient aggregate requirements current application problem 
mapper attempt find data map returns error 
cmg sufficient aggregate memory mapper searches perfectly time balanced data map map returned 
machines sufficient local memory satisfy memory requirements perfectly time balanced map 
case mapper relaxes time balance constraints seek alternative map satisfies memory requirements 
mapper uses binary search find map provides best time balance satisfying application memory requirements 
parameters binary search configurable default values provided follows 
default maximum relax factor meaning acceptable map predicted iteration time slowest processor times predicted iteration time fastest processor 
default search tolerance meaning search refinement ends relax factor changes search steps 
briefly describe specification problem constrained optimization problem see thorough explanation previous applied similar solution data mapping problem 
unknowns strip widths assigned processor np 
strip widths constrained integer values problem framed integer programming problem 
unfortunately integer programming problem np complete rendering solution computationally expensive compute unacceptable scheduling methodology 
efficient alternative real valued linear programming solvers specifically lp solve package simplex method 
real valued solver integer problem introduces error provides sufficient accuracy needs 
problem formulation begins specification objective function 
impossible express true objective linear formulation minimize computation time see section computation time model specify constraints ensure processors time balanced 
specify bounds unknown variables processor assigned non negative number mesh rows exceed total number rows ni rest specification form constraints 
total number data mesh rows allocated equal ni data allocated processor fit processor local memory ni refer section memory usage model 
specify processor predicted iteration time equal predicted iteration time itt itt ime 
add support relaxation time balancing requirements relax factor constraint itt itt ime itt ime 
incorporating details execution time model see section re arranging inequalities specify absolute value sets constraints compt ime compt ime compt ime compt ime 
validation results described section scheduler typically utilizes performance model compare candidate schedules 
ability scheduler select best schedule directly tied prediction accuracy performance model 
performed suite validation experiments execution time model described section 
goal experiments compare predicted application performance ime actual application performance ime 
calculate prediction error ime ime 
ime space fully describe experimental design full explanation available 
tested model accuracy jacobi game life applications single site testbed site testbed see section details 
total obtained comparisons actual predicted times 
histogram prediction errors measured experiments shown 
samples percent prediction error fig 
histogram prediction errors measured total experiments 
results aggregated experiments conducted jacobi game life single site testbed site testbed 
prediction accuracy execution time model moderate 
objective provide performance models applications demonstrate models utilized part scheduling strategy 
sophisticated precise models developed 
evaluation results show approach behaves reasonably accurate models 
models hope obtain automatically grads compiler available 

results section describe experimental results obtained jacobi game life applications realistic grid usage scenarios 
designed experiments investigate questions 
scheduler provide reduced application execution times relative conventional scheduling ap proaches 
ii 
scheduler effectively utilize dynamic resource information improve application performance 
reasonable schedules developed absence dynamic resource information 
iii 
scheduler behavior affected degraded application information 
specifically reasonable schedules developed absence application execution time model 

testbeds 
experimental design experiments performed subset grads testbed composed workstations university tennessee knoxville utk university illinois urbana champaign uiuc university california san diego ucsd 
depicts testbed provides snapshot available bandwidths networks links 
table summarizes testbed resource characteristics 
collection resources typical computational grids users array purposes everyday basis resources fall variety administrative domains testbed distributed heterogeneous 
utk lan mbps mbps mbps mbps wan mbps mbps ucsd lan mbps uiuc lan mbps mbps fig 
heterogeneous distributed network workstations 
network links labeled available bandwidth megabits second values collected network weather service network monitoring sensors november pm 
experiments performed full site tested site testbed ucsd resources 
ran experiments site testbed problem sizes site testbed problem sizes 

scheduling strategies help answer questions iii developed scheduling strategies dynamic static basic user realistic grid scheduling scenario 
dynamic strategy uses scheduler design represents case full information available application testbed 
strategy scheduler coupled full execution time performance model see section time balance circus machines machines opus machines major machines domain ucsd edu cs utk edu cs uiuc edu cs uiuc edu nodes names opus opus opus opus processor mhz piii mhz piii mhz pii pii mhz pii cpus node memory node mb mb mb mb os debian linux red hat linux red hat linux red hat linux kernel smp network mbps mbps mbps mbps shared ethernet switched ethernet switched ethernet shared ethernet table summary testbed resource characteristics 
mapper see section 
scheduling decisions run time near real time cpu availability free memory available bandwidth information nws cpu speed data mds 
static strategy models scheduler behavior full application information available resource information degraded 
specifically strategy uses performance model mapper dynamic strategy assumes dynamic resource information available run time nws server unavailable 
scheduling decisions line static information mds available physical memory total cpu speed 
estimates available bandwidth nws collected run time 
basic strategy models scheduler behavior resource information fully available complete execution time model 
strategy uses memory usage model described section alternative method defined section 
mapping done equal allocation mapper defined section 
mapper require execution time information 
user strategy designed emulate scheduling process typical grid user employ provides comparison conventional approach 
assume users generally invest time scheduling application configuration scenario static resource information sufficient scheduling occurs line 
assume user preferred ordering resources example users utilize home resources resources guest 
site testbed assume resource ordering ucsd utk uiuc 
assume typical user detailed performance model may able estimate application memory usage 
strategy uses memory usage model selects minimum number resources satisfy application memory requirements 
summarizes application grid information usage scheduling strategies 
sophistication resource information basic memory usage model dynamic resource info user memory usage model static resource info static sophistication application information dynamic full performance model dynamic resource info full performance model static resource info fig 
summary user basic static dynamic scheduling strategies 
strategy note availability sophisticated application resource information 
bars correspond colors strategy scheduling results graphs 
comparison scheduler performance achieved automated run time scheduler clearly desirable addition strategy comparison defined 
unfortunately currently comparable grid scheduler effective applications environments target 
listed grid scheduler efforts section plan investigate applications environments reasonable scheduler comparison 

experimental procedure scheduling strategy comparison experiment consists back back runs application config scheduling strategy 
application execution iterations performed average standard deviation iterations times taken warmup iterations 
characteristics iterative mesh applications compare application performance worst average iteration time reported processor computation 
avoid undesirable interactions application execution dynamic information scheduler test included minute sleep phase tests 
obtain broad survey relative strategy performance ran scheduling strategy comparison experiments combinations applications testbeds problem sizes testing scenarios 
performed repetitions testing scenario total schedule comparison experiments scheduler application executions 

strategy comparison metric common comparison metric percent degradation best 
experiment find lowest average iteration time achieved strategies itt compute itt ime itt itt strategy 
strategy achieved minimum iteration time assigned 
note optimal scheduler consistently achieve degradation best 

aggregate results presents average percent degradation best achieved scheduling strategy scheduling strategy comparison experiments 
bar graph represents average approximately values 
table presents additional statistics data set 
application testbed combinations user strategy outperformed average strategies 
user strategy variations scheduling methodology results provide sufficient evidence answer question affirmative approach provide reduced application execution times relative conventional approaches 
improvement average performance user static strategy partially answers question ii reasonable schedules developed absence dynamic resource information 
additionally recall primary difference user basic strategy pair static dynamic strategy pair usage dynamic information 
basic strategy outperforms user strategy dynamic strategy outperforms static strategy answer rest question ii affirmative scheduler effectively utilize dynamic resource information improve application performance 
question iii posed query scheduler behavior affected availability accurate performance model 
expected scheduling strategies utilize accurate application performance model static dynamic outperform user basic 
scheduling strategies show clear ordering average performance examination individual experimental results shows relative scheduler performance heavily influenced run time condi tions application characteristics factors 
sections detailed analysis small subset experiment results 
case studies provide insight behavior scheduling strategy highlight conditions specific strategy particularly effective ineffective 
percent degradation best user basic static dynamic game life game life jacobi jacobi site site site site fig 
average percent degradation best scheduling strategy application testbed combination 
app testbed statistic user basic static dynamic game life avg std site min max game life avg std site min max jacobi avg std site min max jacobi avg std site min max table summary statistics percent degradation best scheduling strategy application testbed scenarios 

case study variability time detail experimental results jacobi application site testbed problem size 
performed experiment repetitions period oct nov 
specifically collected repetitions october november november 
section resource selection decisions scheduling strategy describe application performance results obtained schedules 
reports schedules selected scheduling strategy experiment repetition 
number machines selected shown grayed rectangles 
machine selection reported site testbed uiuc machines differentiated opus cluster labeled uiuc major cluster labeled uiuc 
schedules shown schedule includes machines single site 
user strategy constrained select machines particular order strategies evaluated performance tradeoffs automatically selected subset total resource pool 
shows user static strategies schedule repetitions basic dynamic strategies employed different schedules repetition repetition 
user static strategies perform scheduling line static information basic dynamic strategies utilize dynamic information run time scheduling decisions 
notice static dynamic strategies typically select machines user basic strategies 
dynamic static strategies select resource set size minimizes predicted application execution time user basic strategies model situations execution time model available strategies try reduce communication costs selecting minimum number resources satisfy application memory requirements 
interesting characteristic utk resources frequently chosen particularly static dynamic strategies 
testbed utk site includes substantial number machines powerful terms memory computation machine provided sites see table 
utk machines clearly choice machines sufficient current problem run 
note dynamic strategy selected machines repetition include utk machines schedule 
fact time running experiments wan performance utk ucsd uiuc significantly worse wan performance ucsd uiuc 
example repetition current series jacobi application site testbed problem size dynamic scheduler obtained bandwidth predictions nws utk uiuc mbps utk ucsd mbps uiuc ucsd mbps 
accordingly scheduler represented basic static dynamic strategies automatically avoids schedules utk machines multi site schedule 
reports results obtained application executed schedules 
bar height indicates average iteration times error bars indicate standard deviation iteration repetitions ucsd uiuc user basic static dynamic uiuc utk ucsd uiuc uiuc utk fig 
processor selections scheduling strategy jacobi application site testbed problem size 
experiment repetition processors selected strategy highlighted gray boxes 
iteration times sec failed repetition ucsd uiuc uiuc utk ucsd uiuc uiuc utk user basic static dyn 
fig 
average standard deviation iteration times jacobi application site testbed problem size 
times 
relative performance schedulers match results shown 
times reported user strategy third repetition application failed complete 
closer examination size data allocated machines exceeded available physical memory leading serious interference users jobs 
application killed allow normal progress jobs 
experiment highlights importance run time scheduling dynamic resource information 
results shown repetition striking 
repetition dynamic strategy performed particularly poorly average standard deviation iteration times surprisingly high sec 
shows time measured iteration application scheduler application runs 
iteration times scheduler plotted graph comparison purposes application runs performed different times possibly different conditions 
selected case study usefulness demonstrating points behavior scheduling strategies seen fact anomalous refer 
iteration time sec outlier time sec user basic static dyn 
iteration number fig 
time application iteration function iteration number 
run performed different time possibly different conditions plotted comparison purposes 
results jacobi application site testbed repetition 
dramatic drop performance dynamic strategy iteration responsible strategy poor average performance repetition 
dynamic strategy worst performer average repetition shows dynamic strategy best performer majority iterations dramatic iteration time jumps responsible poor average performance 
investigated system behavior dramatic jump seconds nws cpu availability measurements cs uiuc edu machines schedule completely missing seconds second iteration 
believe long iteration period cs uiuc edu completely line disrupted lightweight nws sensors application run 
identified correlation dramatic increase cs uiuc edu computation times iterations broad shift upward application iteration times iterations 
case demonstrates sensitive performance loosely synchronous applications performance individual machines 
case reveals limitations reporting average iteration times average iteration times representative total execution time application metric experienced users 

case study ii variability problem size preceding case study examined variations scheduler behavior performance different repetitions experiment 
section focus experiments jacobi application site testbed detail experiments performed shorter time period hours november variety problem sizes 
reports machine selections scheduling strategy experiments reports measured application performance schedule 
iteration times reported extend seconds iteration range orders magnitude 
notice strategies successful finding schedule see user dynamic strategies failed launch execution application see 
dynamic strategy experiment failed application launch due unidentified problem launching machine 
user strategy experiment failed application heavily interfered user killed application 
application interferes users extent suggests best estimates available memory run time ensure machine memory availability avoid thrashing memory usage model may conservative estimate memory available application machine 
consider benefits additional memory application communication costs associated utilizing machines 
schedules shown include utk machines machines site user strategy basic strategy 
cases correspond exactly worst iteration time results shown schedules performed poorly poor network performance utk sites refer preceding section ucsd uiuc user basic static dynamic uiuc utk ucsd uiuc uiuc utk fig 
processor selections scheduling strategy jacobi application site testbed problem sizes 
experiment repetition processors selected strategy highlighted gray boxes 
iteration time sec user basic static dynamic problem size ucsd uiuc uiuc utk ucsd fig 
average standard deviation iteration times jacobi application site testbed problem sizes 
uiuc uiuc failed utk failed details 
ordering machine selection predefined user strategy ucsd utk uiuc surprising user strategy selected schedules 
surprising basic strategy selected schedule 
investigate behavior detail 
problem size demanding testbed aggregate mb ram required 
equal allocation translates machine available memory requirements example mb machine machines mb machine machines mb machine machines 
unloaded conditions equal allocation schedule utilize machines major machines uiuc mb machines utilized major machines excluded machine utilized machines utk 
notice basic strategy selected machines 
basic strategy selects smallest resource set satisfies application memory requirements may surprising strategy selected just machines 
recall basic strategy collects uses dynamic resource information schedule time run time 
experiment basic strategy utk machines partially loaded longer provide minimum mb machine needed run application just utk machines 
strategy selected machines reducing minimum memory required machine levels supported utk machines 
looking may strange static dynamic strategies determined utk machine acceptable choice 
static strategy uses static information assumes resources unloaded unloaded conditions utk machines appropriate choice 
looking results shown appears choice reasonable conditions experienced static strategy strategy performed reasonably 
cases blindly assuming unloaded conditions drastic affects 
dynamic strategy ran retrieved run time resource information utk machines partially loaded 
usage time balance mapper provided strategy added flexibility unequal allocations 
time balance mapper map allowed usage utk machines shifting partially loaded machines unloaded machines 
general time balance mapper generally successful reducing application iteration times useful increasing number scheduling choices available 

scheduler application failures experiments reported encountered number application scheduler failures 
detailed analysis types failures occur frequency summarize results completeness 
scheduler failure occurs scheduler find feasible schedule application 
scheduling methodology reduces frequency scheduling failures effective search heuristic ensure feasible machine groups identified exist time balancing mapper adapts data allocations match available memory capacities individual machines 
measures succeed computation memory capacity information available targeted machines methodology occasionally fails due lack resource information 
identified variety failures label application failures application launch process occasionally failed due unexplained script failures memory allocation application fail sufficient available memory application communication processes failed occasionally due globus socket communication bugs machines involved computation fail participate communication machine went line application resource usage interfere users time kill application 
frequency launch run time failures provides useful insight stability program execution grid 

scheduling overhead scheduler design practical overhead scheduling process reasonable compared application execution times 
results preceding sections included overheads introduced scheduler 
section quantify overheads 
consider total overhead scheduling overhead activities performed scheduling methodology collection resource information mds nws ii search candidate schedules 
measured scheduling overheads jacobi application site testbed scheduler configuration dynamic scheduling strategy 
case study provides reasonable overview overheads methodology note cost scheduling dependent problem run configuration selected testbed target application complexity chosen performance model mapper variable load grads nws nameserver mds server 
important differentiate costs data retrieval mds nws servers cost transferring request data response wans 
set nws nameserver mds cache ucsd performed tests machine ucsd sources information referred local nws local mds cache 
include test scenarios nws information retrieved local nws grads nws located utk knoxville tennessee 
include scenarios mds information retrieved local mds cache grads mds located isi los angeles california 
specifically test retrieval modes 
mode grads nws nameserver grads mds server 
mode grads nws nameserver local mds cache 
experiments local mds cache contained needed information fully 
mode local nws nameserver fully local mds cache 
ran scheduler retrieval modes back back manner completed triplets 
run measured time required entire scheduling execution ime time required grid information collection ime consider cost schedule search ime scheduling time spent information collection ime ime ime 
table presents summary results repetitions mean standard deviation ime ime ime 
ran scheduling experiments similar experimental configuration scheduling strategies typically achieved application iteration times seconds 
ran roughly iterations experiments application iterative phase occupied seconds 
mode mode mode collect time avg std search time avg std total time avg std table scheduling overheads seconds schedule jacobi site testbed dynamic scheduling strategy 
cost grid information collection dominates scheduling overhead modes mode seconds average required collect information machines testbed 
overhead reasonable compared application run times conclude procedure collecting resource information efficient cost data retrieval nws server reasonable 
mode nws data retrieved remote nws server increased information collection times approximately seconds 
conclude collection information remote nws server efficient uses scheduler 
overhead problematic larger testbed case scheduler run time resource information done static strategy 
mode utilized remote nws nameserver remote mds server increasing collection times seconds approximately minutes 
overhead prohibitive practice prevent usage scheduling approach 
conclude retrieval times reduced mds local caching mds information necessary 
mds information retrieved methodology changes order weeks months local caching acceptable solution 
note ongoing development mds nws seeking reduce information retrieval latencies 
cost schedule search process seconds collection modes acceptable overhead scheduling scenarios 
low search time overhead due low computational complexity execution time model mapping strategy extensive search pruning performed search process 
notice average search time mode search time modes mode retrieves resource information grads mds experiments server unable provide required information 
scheduling methodology consider machines data available leading pruning schedule search space reduction search time 

discussion section describe related section describe possible extensions sec tion conclude section 

related application level scheduling project apples developed successful scheduling strategies grid including :10.1.1.15.9060
efforts provided important foundations core components scheduling approach schedule search procedure mappers performance models 
efforts particularly related 
focused scheduling jacobi solver finite difference approximation poisson equation 
second effort focused scheduling parallel simulation classified iterative mesh application 
efforts demonstrated significant improvements application performance compared conventional scheduling efforts 
performance models mappers section part models mapping strategies previous jacobi 
efforts examples development search procedure believe search procedure developed thorough discover desirable machine groups 
search procedure developed lans wans thoroughly tested environments jacobi schedulers tested lan environments 
apples efforts targeted specific applications important contribution separated application specific components application generic 
due formal separation believe scheduling approach easily re targeted new applications previous apples efforts 
apples efforts successfully targeted classes applications 
efforts target master slave applications target applications may involve significant inter processor communications 
number scheduling projects notable targeting variety applications entire application class examples include condor matchmaker prophet nimrod 
nimrod effort focuses embarrassingly parallel applications comparable apples efforts current effort 
prophet run time scheduling system designed parallel applications written mentat pro gramming language 
related effort prophet run time scheduling system designed parallel applications written mentat programming language 
scheduling system similar exploits application structure system resource information promote application performance 
prophet demonstrated spmd applications applications task parallel pipelines scheduler design tested heterogeneous local area environments 
possible compare performance strategies prophet may difficult find suitable scenario comparison satisfies requirements scheduling strategy 
example prophet requires target application written mentat mentat efforts 
project interest condor matchmaker 
matchmaking system users specify resource requirements application system resource providers similarly specify capabilities resources centralized matchmaker match application resource requirements appropriate resources 
design quite general applied different types applications 
matchmaking strategy general scheduler differs primarily resource discovery mechanism able provide detailed schedule development 

initial prototype scheduler obtain experiments 
currently refining prototype integrating software main grads software base 
interesting extension incorporate search procedure distinct searches different types machines example master slave application want find best machine master process search machines slave processes excluding machine selected master 
plan extend validation scheduler testing applications application classes testbeds 
schedulers developed grads project specific applications 
plan test approach applications compare performance achieved scheduler 
collaborating developers schedulers define fundamental characteristics successful scheduling approach grads environment 
purposes designed built application performance models mapping strategies 
grid application development accessible larger number users expect users provide detailed performance models mapping strategies 
recognizing members grads research community investigating feasibility compiler generation application information performance models inclusion models grid enabled libraries 
matures plan experiment usage models application scheduling 

proposed adaptive scheduling approach designed improve performance parallel applications computational grid environments 
section architecture scheduler detailed search procedure lies heart scheduler 
section described jacobi game life iterative mesh applications selected test cases scheduler 
application data mappers performance models appropriate scheduler 
validation approach prototype scheduler conjunction mappers performance models developed section 
section results experiments applied scheduling approach realistic usage scenarios production grid environments 
experiments demonstrate scheduler pro vides significantly better application performance conventional scheduling strategies 
experiments included scheduling strategies application resource information limited experiments demonstrated scheduler gracefully handles degraded levels availability appli cation grid resource information 
showed overheads introduced approach reasonable 
acknowledgments benefited greatly collaborations grads team 
especially innovative computing laboratory utk pablo group uiuc allowing run experiments resources 
adam birnbaum insightful review manuscript 
abramson giddy high performance parametric modeling nimrod killer application global grid 
international parallel distributed processing symposium may 
prasanna raghavendra unified resource scheduling framework heterogeneous computing environments 
proceedings th heterogeneous computing workshop april 
allen foster liu seidel cactus worm experiments dynamic resource discovery allocation grid environment 
international journal high performance computing applications 
appear 
prabhu panda sadayappan communication modeling heterogeneous networks workstations performance characterization collective operations 
proceedings th heterogeneous computing workshop april 
barrett berry chan demmel donato dongarra van der vorst templates solution linear systems building blocks iterative methods nd edition 
siam philadelphia pa 
berman grid blueprint new computing infrastructure 
morgan kaufmann publishers ch 
high performance schedulers pp 

berman chien cooper dongarra foster gannon johnsson kennedy kesselman mellor crummey reed torczon wolski grads project software support high level grid application development 
international journal supercomputer applications 
appear 
berman wolski schopf shao application level scheduling distributed heterogeneous networks 
proceedings supercomputing november 
casanova berman wolski apples parameter sweep template user level middleware grid 
proceedings supercomputing november 
czajkowski fitzgerald foster kesselman grid information services distributed resource sharing 
proceedings th ieee symposium high performance distributed computing august 
modular framework adaptive scheduling grid application development environments 
master thesis university california san diego march 
available ucsd tech 
report cs 
casanova berman modular scheduling framework grads 
submitted th ieee symposium high performance distributed computing 
berman wolski grimshaw application aware scheduling application legion 
proceedings th heterogenous computing workshop may 
flake computational beauty nature computer explorations fractals chaos complex systems adaptation 
mit press cambridge ma 
foster designing building parallel programs 
addison wesley ch 

available www unix mcs anl gov 
foster geisler gropp karonis lusk tuecke wide area implementation message passing interface 
parallel computing 
foster karonis grid enabled mpi message passing heterogeneous computing systems 
proceedings supercomputing conference november 
foster kesselman globus project status report 
proceedings th heterogeneous computing workshop 
foster kesselman eds 
grid blueprint new computing infrastructure 
morgan kaufmann publishers 
fox williams messina parallel computing works 
morgan kaufmann san francisco ca 
available www npac syr edu pcw 
grimshaw ferrari humphrey wide area computing resource sharing large scale 
ieee computer may 
gropp lusk skjellum high performance portable implementation mpi message passing interface standard 
parallel computing 
gropp lusk user guide mpich portable implementation mpi 
mathematics computer science division argonne national laboratory 
anl 
kennedy broom cooper dongarra fowler gannon johnsson mellor crummey torczon telescoping languages strategy automatic generation scientific problem solving systems annotated libraries 
journal parallel distributed computing 
kennedy mendes application manager execution mechanism grid applications 
grads project working document available cs rice edu grads publications reports htm oct 
kwok ahmad benchmarking comparison task graph scheduling algorithms 
journal parallel distributed computing 
litzkow livny mutka condor hunter idle workstations 
proceedings th international conference distributed computing systems june 
miller steenkiste collecting network status information network aware applications 
infocom march 
johnsson adaptive software library fast fourier transforms 
proceedings international conference supercomputing 
mpi forum webpage www mpi forum org 
parallel programming mpi second ed 
morgan kaufmann publishers san francisco ca ch 
pp 

dongarra ellis fagg roche numerical libraries grid 
international journal high performance computing applications 
appear 
raman livny solomon matchmaking distributed resource management high throughput computing 
proceedings th ieee symposium high performance distributed computing july 
shao berman wolski effective network views promote distributed application performance 
proceedings international conference parallel distributed processing techniques applications 
shao wolski berman master slave computing grid 
proceedings th heterogenous computing workshop may 
casanova berman applying scheduling tuning line parallel tomography 
proceedings supercomputing conference november 
cirne frey berman wolski su kesselman young combining workstations supercomputers support grid applications parallel tomography experience 
proceedings th heterogenous computing workshop may 
su berman wolski apples schedule simple sara computational grid 
international journal high performance computing applications 
wolski building performance topologies computational grids 
proc 
th ieee symp 
high performance distributed computing 
submitted 
weissman prophet automated scheduling spmd programs workstation networks 
concurrency practice experience 
weissman zhao scheduling parallel applications distributed networks 
journal cluster computing 
williams model building mathematical programming second ed 
wiley chichester new york 
wolski spring hayes network weather service distributed resource performance forecasting service metacomputing 
journal generation computing systems 

