anatomy large scale hypertextual web search engine sergey brin lawrence page pagel cs stanford edu computer science department stanford university stanford ca google prototype large scale search engine heavy structure hypertext 
google designed crawl index web efficiently produce satisfying search results existing systems 
prototype full text hyperlink database pages available stanford edu engineer search engine challenging task 
search engines index tens hundreds millions web pages involving comparable number distinct terms 
answer tens queries day 
despite importance large scale search engines web little academic research done 
furthermore due rapid advance technology web proliferation creating web search engine today different years ago 
provides depth description large scale web search engine detailed public description know date 
apart problems scaling traditional search techniques data magnitude new technical challenges involved additional information hypertext produce better search results 
addresses question build practical large scale system exploit additional infon nation hypertext 
look problem effectively deal uncontrolled hypertext collections publish want 
keywords world wide web search engines information retrieval pagerank google 
note versions version shorter printed version 
full version available web conference cd rom 
web creates new challenges information retrieval 
amount information web growing rapidly number new users inexperienced art web research 
people surf web link graph starting high quality human maintained indices yahoo 
search engines 
human maintained lists cover popular topics effectively subjective expensive build maintain slow improve cover esoteric topics 
automated search engines rely keyword matching usually return low quality matches 
matters worse advertisers attempt gain people attention measures meant mislead automated search engines 
built large scale search engine addresses problems existing systems 
especially heavy additional structure hypertext provide higher quality search results 
chose system name google common spelling fits goal building largescale search engines 
web search engines scaling search engine technology scale dramatically keep growth web 
web search engines world wide web won mcbryan index web pages web accessible documents 
november top search engines claim index webcrawler web documents search watch 
foreseeable year comprehensive index web contain documents 
time number queries search engines handle grown incredibly 
march april world wide web worm received average queries day 
november altavista claimed handled roughly queries day 
increasing number users web automated systems query search engines top search engines handle hundreds millions queries day year 
goal system address problems quality scalability introduced scaling search engine technology extraordinary numbers 

google scaling web creating search engine scales today web presents challenges 
fast crawling technology needed gather web documents keep date 
storage space efficiently store indices optionally documents 
indexing system process hundreds gigabytes data efficiently 
queries handled quickly rate hundreds thousands second 
tasks increasingly difficult web grows 
hardware performance cost improved dramatically partially offset difficulty 
notable exceptions progress disk seek time operating system robustness 
designing google considered rate growth web technological changes 
google designed scale extremely large data sets 
efficient storage space store index 
data structures optimized fast efficient access see section 
expect cost index store text html eventually decline relative amount available see 
result favorable scaling properties centralized systems google 
design goals improved search quality main goal improve quality web search engines 
people believed complete search index possible find easily 
best web navigators best navigation service easy find web data entered 
web quite different 
search engine readily testify completeness index factor quality search results 
junk results wash results user interested 
fact november top commercial search engines finds returns search page response name top results 
main causes problem number documents indices increasing orders magnitude user ability look documents 
people willing look tens results 
collection size grows need tools high precision number relevant documents returned say top tens results 
want notion relevant include best documents may tens thousands slightly relevant documents 
high precision important expense recall total number relevant documents system able return 
quite bit optimism hypertextual information help improve search applications marchiori sl weiss 
particular link structure page link text provide lot information making relevance judgments quality filtering 
google link structure anchor text see sections 
academic search engine research aside tremendous growth web increasingly commercial time 
web servers com domains 
number grew 
time search engines migrated academic domain commercial 
search engine development gone companies little publication technical details 
causes search engine technology remain largely black art advertising oriented see appendix 
google strong goal push development understanding academic realm 
important design goal build systems reasonable numbers people 
usage important think interesting research involve leveraging vast amount usage data available modem web systems 
example tens millions searches performed day 
difficult get data mainly considered commercially valuable 
final design goal build architecture support novel research activities large scale web data 
support novel research uses google stores actual documents crawls compressed form 
main goals designing google set environment researchers come quickly process large chunks web produce interesting results difficult produce 
short time system papers databases generated google underway 
goal set environment researchers students propose interesting experiments large scale web data 

system features google search engine important features help produce high precision results 
link structure web calculate quality ranking web page 
ranking called pagerank described detail page 
second google utilizes link improve search results 
pagerank bringing order web citation link graph web important resource largely gone unused existing web search engines 
created maps containing hyperlinks significant sample total 
maps allow rapid calculation web page pagerank objective measure citation importance corresponds people subjective idea importance 
correspondence pagerank excellent way prioritize results web keyword searches 
popular subjects simple text matching search restricted web page titles performs pagerank prioritizes results demo available google stanford edu 
type full text searches main google system pagerank helps great deal 
description pagerank calculation academic citation literature applied web largely counting citations backlinks page 
gives approximation page importance quality 
pagerank extends idea counting links pages equally normalizing number links page 
pagerank defined follows assume page pages ti 
tn point citations 
parameter damping factor set 
usually set 
details section 
defined number links going pagerank page asfollows pr pr ti ic ti 
pr tn ic tn note probability distribution web pages sum web pages pageranks 
pagerank pr calculated simple iterative algorithm corresponds principal eigenvector normalized link matrix web 
pagerank web pages computed hours medium size workstation 
details scope 
intuitive justification pagerank thought model user behavior 
assume random surfer web page random keeps clicking links hitting back eventually gets bored starts random page 
probability random surfer visits page pagerank 
damping factor probability page random surfer get bored request random page 
important variation add damping factor single page group pages 
allows personalization nearly impossible deliberately mislead system order get higher ranking 
extensions pagerank see 
intuitive justification page high pagerank pages point pages point high pagerank 
intuitively pages cited places web worth looking 
pages citation yahoo 
homepage generally worth looking 
page high quality broken link quite yahoo homepage link 
pagerank handles cases recursively propagating weights link structure web 
anchor text text links treated special way search engine 
search engines associate text link page link 
addition associate page link points 
advantages 
anchors provide accurate descriptions web pages pages 
second anchors may exist documents indexed text search engine images programs databases 
possible return web pages crawled 
note pages crawled cause problems checked validity returned user 
case search engine return page existed hyperlinks pointing 
possible sort results particular problem rarely happens 
idea propagating anchor text page refers implemented world wide web worm mcb yan especially helps search non text infon nation expands search coverage fewer downloaded documents 
anchor propagation anchor text help provide better quality results 
anchor text efficiently technically difficult large amounts data processed 
current crawl pages anchors indexed 
features aside pagerank anchor text google features 
location information hits extensive proximity search 
second google keeps track visual presentation details font size words 
words larger font weighted higher words 
third full raw html pages available repository 
related search research web short concise history 
world wide web worm mcbryan web search engines 
subsequently followed academic search engines public companies 
compared growth web importance search engines precious documents search engines pinkerton 
michael mauldin chief scientist lycos various services including lycos closely guard details databases 
fair amount specific features search engines 
especially represented get results post processing results existing commercial search engines produce small scale individualized search engines 
lot research information retrieval systems especially controlled collections 
sections discuss areas research needs extended better web 
information retrieval infon nation retrieval systems goes back years developed witten 
research information retrieval systems small controlled homogeneous collections collections scientific papers news stories related topic 
primary benchmark information retrieval text retrieval conference trec uses fairly small controlled collection benchmarks 
large corpus benchmark compared gb crawl web pages 
things trec produce results web 
example standard vector space model tries return document closely approximates query query document vectors defined word occurrence 
web strategy returns short documents query plus words 
example seen major search engine return page containing bill clinton picture bill clinton query 
argue web users specify accurately want add words query 
disagree position 
user issues query bill clinton get reasonable results enormous amount high quality information available topic 
examples believe standard information retrieval needs extended deal effectively web 
differences web controlled collections web vast collection completely uncontrolled heterogeneous documents 
documents web extreme variation internal documents external meta infon nation available 
example documents differ language human programming vocabulary email addresses links zip codes phone numbers product numbers type format text html pdf images sounds may machine generated log files output database 
hand define external meta information infon nation inferred document contained 
examples external meta information include things reputation source update frequency quality popularity usage citations 
possible sources external meta information varied things measured vary orders magnitude 
example compare usage information major homepage yahoo currently receives millions page views day obscure historical article receive view years 
clearly items treated differently search engine 
big difference web traditional controlled collections virtually control people put web 
couple flexibility publish nous influence search engines route traffic companies deliberately manipulating search engines profit serious problem 
problem addressed traditional closed information retrieval systems 
interesting note metadata efforts largely failed web search engines text page directly represented user abused manipulate search engines 
numerous companies specialize manipulating search engines profit 
system anatomy provide high level discussion architecture 
depth descriptions important data structures 
major applications crawling indexing searching examined depth 
google architecture overview section give high level overview system works pictured 
sections discuss applications data structures mentioned section 
google implemented efficiency run solaris linux 
google web crawling downloading web pages done distributed crawlers 
sends lists urls fetched crawlers 
web pages fetched sent 
compresses stores web pages repository 
web page associated id number called docid assigned new url parsed web page 
indexing function performed indexer sorter 
indexer performs number functions 
reads repository documents parses 
document converted set word occurrences called hits 
hits record word position document approximation font size capitalization 
indexer distributes hits set barrels creating partially sorted forward index 
indexer performs important function 
parses links web page stores important infon nation anchors file 
file contains information determine link points text link 
hits set barrels creating partially sorted forward index 
indexer performs important function 
parses links web page stores important information anchors file 
file contains information determine link points text link 
reads anchors file converts relative urls absolute urls turn 
puts anchor text forward index associated docid anchor points 
generates database links pairs 
links database compute pageranks documents 
sorter takes barrels sorted docid simplification see section resorts generate inverted index 
done place little temporary space needed operation 
sorter produces list offsets inverted index 
program called takes list lexicon produced indexer generates new lexicon searcher 
searcher run web server uses lexicon built inverted index pageranks answer queries 
major data structures google data structures optimized large document collection crawled indexed searched little cost 
cpus bulk input output rates improved dramatically years disk seek requires io ms complete 
google designed avoid disk seeks possible considerable influence design data structures 
virtual files spanning multiple file systems addressable bit integers 
allocation multiple file systems handled automatically 
package handles allocation deallocation file descriptors operating systems provide needs 
support rudimentary compression options 
repository repository contains full html web page 
page compressed zlib see fc choice compression technique tradeoff speed compression ratio 
chose zlib speed significant improvement compression offered bzip 
compression rate bzip approximately repository compared zlib compression 
repository documents stored prefixed docid length url seen 
repository requires data structures order access 
helps data consistency development easier rebuild data structures repository file lists crawler errors 
document index document index keeps information document 
fixed width index sequential bulk input output rates improved dramatically years disk seek requires ms complete 
google designed avoid disk seeks possible considerable influence design data structures 
virtual files spanning multiple file systems addressable bit integers 
allocation multiple file systems handled automatically 
package handles allocation deallocation file descriptors operating systems provide needs 
support rudimentary compression options 
repository repository contains full html web page 
page compressed zlib see rfc 
choice compression technique tradeoff speed compression ratio 
chose zlib speed significant improvement compression offered bz compression rate bzip approximately repository compared zlib compression 
repository documents stored prefixed length url seen 
repository requires data structures order access 
helps data consistency development easier rebuild data structures repository file lists crawler errors 
document index document index keeps information document 
fixed width index sequential access mode index ordered docid 
information stored entry includes current document status pointer repository document checksum various statistics 
document crawled contains pointer variable width file called contains url title 
pointer points contains just url 
design decision driven desire reasonably compact data structure ability fetch record disk seek search additionally file convert urls 
list url checksums corresponding sorted checksum 
order find docid particular url url checksum computed binary search performed checksums file find docid 
urls may converted batch doing merge file 
technique uses turn urls 
batch mode update crucial perform seek link assuming disk take month link dataset 
lexicon lexicon different forms 
important change earlier systems lexicon fit memory reasonable price 
current implementation keep lexicon memory machine mb main memory 
current lexicon contains words rare words added lexicon 
implemented parts list words concatenated separated nulls hash table pointers 
various functions list words auxiliary information scope explain fully 
hit lists hit list corresponds list occurrences particular word particular document including position font capitalization infon nation 
hit lists account space forward inverted indices 
important represent efficiently possible 
considered alternatives encoding position font capitalization simple encoding triple integers compact encoding hand optimized allocation bits huffman coding 
chose hand optimized compact encoding required far space simple encoding far bit manipulation huffman coding 
details hits shown 
compact encoding uses bytes hit 
types hits fancy hits plain hits 
fancy hits include hits occurring url title anchor text meta tag 
plain hits include 
plain hit consists capitalization bit font size bits word position document positions higher labeled 
font size represented relative rest document bits values flag signals fancy hit 
fancy hit consists capitalization bit font size set indicate fancy hit bits encode type fancy hit bits position 
anchor hits bits position split bits position anchor bits hash docid anchor occurs 
gives lin phrase searching long anchors particular word 
expect update way anchor hits stored allow greater resolution position doc dhash fields 
font size relative rest document searching want rank identical documents differently just documents larger font 
length hit list stored hits 
save space length hit list combined forward index docid inverted index 
limits bits respectively tricks allow bits borrowed 
length longer fit bits escape code bits bytes contain actual length 
forward index forward index partially sorted 
stored number barrels 
barrel holds range 
document contains words fall particular barrel docid recorded barrel followed list correspond words 
scheme requires slightly storage duplicated difference small reasonable number buckets saves considerable time coding complexity final indexing phase done sorter 
furthermore storing actual store relative difference minimum falls barrel 
way just bits unsorted barrels leaving bits hit list length 
running web crawler challenging task 
tricky performance reliability issues importantly social issues 
crawling fragile application involves interacting hundreds thousands web servers various name servers control system 
order scale hundreds millions web pages google fast distributed crawling system 
single serves lists urls number crawlers typically ran 
crawlers implemented python 
crawler keeps roughly connections open 
necessary retrieve web pages fast pace 
peak speeds system crawl web pages second crawlers 
amounts roughly second data 
major performance stress dns lookup 
crawler maintains dns cache need dns lookup crawling document 
hundreds connections number different states looking dns connecting host sending request receiving response 
factors crawler complex component system 
uses asynchronous manage events number queues move page fetches state state 
turns running crawler connects half servers generates tens millions log entries generates fair amount email phone calls 
vast number people coming line know crawler seen 
daily receive email wow looked lot pages web site 

people know robots exclusion protocol think page protected indexing statement page copyrighted indexed needless say difficult web crawlers understand 
huge amount data involved unexpected things happen 
example system tried crawl online game 
resulted lots garbage messages middle game 
turns easy problem fix 
problem come downloaded tens millions pages 
immense variation web pages servers virtually impossible test crawler running large part internet 
invariably hundreds obscure problems may occur page web cause crawler crash worse cause unpredictable incorrect behavior 
systems access large parts internet need designed robust carefully tested 
large complex systems crawlers invariably cause problems needs significant resources devoted reading email solving problems come 
indexing web parsing parser designed run entire web handle huge array possible errors 
range typos html tags kilobytes zeros middle tag non ascii characters html tags nested hundreds deep great variety errors challenge imagination come equally creative ones 
maximum speed yacc generate cfg parser flex lexical analyzer stack 
developing parser runs reasonable speed robust involved fair amount 
indexing documents barrels document parsed encoded number barrels 
word converted memory hash table lexicon 
new additions lexicon hash table logged file 
words converted occurrences current document translated hit lists written forward barrels 
main difficulty parallelization indexing phase lexicon needs shared 
sharing lexicon took approach writing log extra words base lexicon fixed words 
way multiple indexers run parallel small log file extra words processed final indexer 
sorting order generate inverted index sorter takes forward barrels sorts produce inverted barrel title anchor hits full text inverted barrel 
process happens barrel time requiring little temporary storage 
parallelize sorting phase machines simply running multiple process different buckets time 
barrels don fit main memory sorter subdivides baskets fit memory docid 
sorter loads basket memory sorts writes contents short inverted barrel full inverted barrel 
searching goal searching provide quality search results efficiently 
large commercial search engines great progress terms efficiency 
focused quality search research believe solutions scalable commercial volumes bit effort 
google query evaluation process show 
put limit response time certain number currently matching documents searcher automatically goes step 
means possible sub optimal results returned 
currently investigating ways solve problem 
past sorted hits pagerank improve situation 
ranking system google maintains information web documents typical search engines 
hitlist includes position font capitalization information 
additionally factor hits anchor text pagerank document 
combining infon nation rank difficult 
designed ranking function particular factor influence 
consider simplest case single word query 
order rank document single word query google looks document hit list word 
google considers hit different types title anchor url plain text large font plain text small font type weight 
type weights vector indexed type 
google counts number hits type hit list 
count converted count weight 
count weights increase linearly counts quickly taper certain count help 
take dot product vector vector type weights compute ir score document 
ir score combined pagerank give final rank document 
multi word search situation complicated 
multiple hit lists scanned hits occurring close document weighted higher hits 
parse query 

convert words 

seek start short barrel word 

scan document matches search terms 

compute rank document query 

short barrels seek start full barrel word go step 
go step 
sort documents matched rank return top 
google query evaluation occurring far apart 
hits multiple hit lists matched nearby hits matched 
matched set hits proximity computed 
proximity far apart hits document anchor classified different value bins ranging phrase match close 
counts computed type hit type proximity 
type proximity pair type prox weight 
counts converted count weights take dot product count weights type compute ir score 
numbers matrices displayed search results special debug mode 
displays helpful developing ranking system 
feedback ranking function parameters type weights type prox weights 
figuring right values parameters black art 
order user feedback mechanism search engine 
trusted user may optionally evaluate results returned 
feedback saved 
modify ranking function see impact change previous searches ranked 
far perfect gives idea change ranking function affects search results 
results performance important measure search engine quality search results 
complete user evaluation scope experience google shown produce better results major commercial search engines searches 
example illustrates pagerank anchor text proximity shows google results search bill clinton 
results demonstrates google features 
results clustered server 
helps considerably sifting result sets 
number results gov domain may reasonably expect search 
currently engine may fit gb drive new pc 
system performance important search engine crawl index efficiently 
way infon nation kept date major changes system tested relatively quickly 
google major operations crawling indexing sorting 
difficult measure long crawling took disks filled name servers crashed number problems stopped system 
total took roughly days download pages including errors 
system running smoothly ran faster downloading pages just hours averaging just pages day pages second 
ran indexer crawler simultaneously 
indexer ran just faster crawlers 
largely spent just time optimizing indexer bottleneck 
optimizations included bulk updates document index placement critical data structures local disk 
indexer runs roughly pages second 
run completely parallel machines process sorting takes hours 
search performance improving performance search major focus research point 
current version google answers queries seconds 
time dominated disk nfs disks spread number machines 
furthermore google optimizations query caching common ns common optimizations 
intend speed google considerably distribution hardware software algorithmic improvements 
target able handle queries second 
table sample query times current version google 
repeated show speedups resulting cached 
google designed scalable search engine 
primary goal provide high quality search results rapidly growing world wide web 
google employs number techniques improve search quality including page rank anchor text proximity information 
furthermore google complete architecture gathering web pages indexing performing search queries 
large scale web search engine complex system remains done 
immediate goals improve search efficiency scale approximately web pages 
simple improvements efficiency include query caching smart disk allocation 
area requires research updates 
smart algorithms decide old web pages new ones crawled 
goal done cho 
promising area research proxy caches build search databases demand driven 
planning add simple features supported commercial search engines boolean operators negation stemming 
features just starting explored relevance feedback clustering google currently supports simple hostname clustering 
plan support user context user location result summarization 
working extend link structure link text 
simple experiments indicate pagerank personalized increasing weight user home page bookmarks 
link text experimenting text surrounding links addition link text 
web search engine rich environment research ideas 
far list expect section shorter near 
high quality search biggest problem facing users web search engines today quality results get back 
results amusing expand users horizons frustrating consume precious time 
example top result search bill clinton popular commercial search engines bill clinton joke day april 
google designed provide higher quality search web continues grow rapidly information easily 
order accomplish google heavy aside quality search google designed scale 
efficient space time constant factors important dealing entire web 
implementing google seen bottlenecks cpu memory access memory capacity disk seeks disk throughput disk capacity network 
google evolved overcome number bottlenecks various operations 
google major data structures efficient available storage space 
furthermore crawling indexing sorting operations efficient able build index substantial portion web pages week 
expect able build index pages month 
research tool addition high quality search engine google research tool 
data google collected resulted papers submitted conferences way 
research abiteboul shown number limitations queries web may answered having web available locally 
means google similar system valuable research tool necessary wide range applications 
hope google resource searchers researchers world spark generation search engine technology 
acknowledgments scott hassan alan critical development google 
talented contributions authors owe gratitude 
hector garcia molina rajeev motwani jeff ullman terry winograd webbase group support insightful discussions 
recognize generous support equipment donors ibm intel sun 
research described conducted part stanford integrated digital library project supported national science foundation cooperative agreement iri 
funding cooperative agreement provided darpa nasa interval research industrial partners stanford digital libraries project 
best web navigators ora awards html bill clinton joke day april 
io com clinton html 
bzip homepage demon uk google search engine fl oo le stanford edu harvest harvest transarc com mauldin michael lycos design choices internet search service ieee expert interview ht www computer ubs exl ert trends mauldin htm effect cellular phone driver attention www com aaa text cell cell toc htm search engine watch www searchenginewatch com rfc zlib ftl ftp uu net documents zlib index html robots exclusion protocol webcrawler com robots exclusion htm web growth summary mit edu people net web summary html yahoo 
yahoo com abiteboul serge abiteboul victor vianu queries computation web proceedings international conference database theory 
delphi greece 
ben 
media monopoly 
th edition 
publisher beacon isbn chakrabarti chakrabarti dom gibson kleinberg raghavan rajagopalan 
automatic resource compilation analyzing hyperlink structure associated text 
seventh international web conference 
brisbane australia april 
cho junghoo cho hector garcia molina lawrence page 
efficient crawling url ordering 
seventh international web conference www 
brisbane australia april 
gravano luis gravano hector garcia molina tomasic 
effectiveness text database discovery problem 
proc 
acm sigmod international conference management data 
kleinberg jon kleinberg authoritative sources hyperlinked environment proc 
acm siam symposium discrete algorithms 
marchiori massimo marchiori 
correct information web hyper search engines 
sixth international conference ww 
santa clara usa april 
mcbryan oliver mcbryan 
taming web 
international conference world wide web 
cern geneva switzerland may 
cs colorado edu home mcbryan www page lawrence page sergey brin rajeev motwani terry winograd 
pagerank citation ranking bringing order web 
manuscript progress 
stanford edu pinkerton brian pinkerton finding people want experiences webcrawler 
second international conference chicago usa october 
webcrawler com htm spertus ellen spertus 
parasite mining structural information web 
sixth international conference 
santa clara usa april 
trec proceedings fifth text retrieval conference trec 
gaithersburg maryland november 
publisher department commerce national institute standards technology 
editors harman voorhees 
full text trec nist ov witten ian witten alistair moffat timothy bell 
managing gigabytes compressing indexing documents images 
new york van nostrand reinhold 
weiss ron weiss velez mark sheldon peter andrzej duda david gifford 
hierarchical network search engine exploits content link hypertext clustering 
proceedings th acm conference hypertext 
new york 
sergey brin received degree mathematics computer science university maryland college park 
currently ph candidate computer science stanford university received 
recipient national science foundation graduate fellowship 
research interests include search engines information extraction unstructured sources data mining large text collections scientific data 
lawrence page bom east lansing michigan received computer engineering university michigan ann arbor 
currently ph candidate computer science stanford university 
research interests include link structure web human computer interaction search engines scalability information access interfaces personal data mining 
appendix advertising mixed motives currently predominant business model commercial search engines advertising 
goals advertising business model correspond providing quality search users 
example prototype search engine top results cellular phone effect cellular phone driver attention study explains great detail distractions risk associated conversing cell phone driving 
search result came high importance judged pagerank algorithm approximation citation importance web page 
clear search engine money showing cellular phone ads difficulty justifying page system returned paying advertisers 
type reason historical experience media ba expect advertising funded search engines inherently biased advertisers away needs consumers 
difficult experts evaluate search engines search engine bias particularly insidious 
example reported selling companies right listed top search results particular queries marchiori 
type bias insidious advertising clear deserves willing pay money listed 
business model resulted ceased viable search engine 
bias tolerated market 
example search engine add small factor search results friendly companies subtract factor results competitors 
type bias difficult detect significant effect market 
furthermore advertising income provides incentive provide poor quality search results 
example noticed ma search engine return large airline advertising causes mixed incentives crucial competitive search engine transparent academic realm 
appendix scalability 
scalability google designed google scalable near term goal web pages 
just received disk machines handle roughly amount 
time consuming parts system parallelize roughly linear time 
include things crawlers indexers 
think data structures deal gracefully expansion 
web pages close sorts operating system limits common operating systems currently run solaris linux 
include things addressable memory number open file descriptors network sockets bandwidth 
believe expanding lot pages greatly increase complexity system 
scalability centralized indexing architectures capabilities computers increase possible index large amount text reasonable cost 
course bandwidth intensive media video pervasive 
cost production text low compared media video text remain pervasive 
soon speech recognition reasonable job converting speech text expanding amount text available 
provides amazing possibilities centralized indexing 
illustrative example 
assume want index written year 
assume people write average day 
works terabytes 
assume indexing terabyte done reasonable cost 
assume indexing methods text linear nearly linear complexity 
assumptions compute long take index terabytes reasonable cost assuming certain growth factors 
moore law defined doubling months processor power 
held remarkably true just processors important system parameters disk 
assume moore law holds need years reach goal indexing written year price small afford 
course hardware experts somewhat concerned moore law may continue hold years certainly lot interesting centralized applications get part way hypothetical example 
course distributed systems gloss gravano harvest efficient elegant technical solution indexing difficult convince world systems high administration costs setting large numbers installations 
course quite reducing administration cost drastically possible 
happens starts running distributed indexing system searching certainly improve drastically 
humans type speak finite amount computers continue improving text indexing scale better 
course infinite amount machine generated content just indexing huge amounts human generated content tremendously useful 
centralized web search engine architecture improve ability cover pertinent text infon nation time bright search 
