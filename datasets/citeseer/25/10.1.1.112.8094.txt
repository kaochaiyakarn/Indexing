active learning adaptive resampling vijay iyengar ibm research division watson research center box yorktown heights ny usa vsi ibm com classi cation modeling supervised learning extremely useful analytical technique developing predictive forecasting applications 
explosive growth data warehousing internet usage large amounts data potentially available developing classi cation models 
example natural language text widely available forms electronic mail news articles reports web page contents 
categorization data common activity automated large extent supervised learning methods 
examples include routing electronic mail satellite image classi cation character recognition 
tasks require labeled data sets su ciently high quality adequate instances training predictive models 
line data particularly unstructured variety text unlabeled 
labeling usually expensive manual process done domain experts 
active learning approach solving problem works identifying subset data needs labeled uses subset generate classi cation models 
active learning method uses adaptive resampling natural way signi cantly reduce size required labeled set generates classi cation model achieves high accuracies possible current adaptive resampling methods 
categories subject descriptors arti cial intelligence learning pattern recognition models database management database applications data mining general terms data mining machine learning classi cation active learning adaptive resampling apte ibm research division watson research center box yorktown heights ny usa apte ibm com tong zhang ibm research division watson research center box yorktown heights ny usa watson ibm com 
supervised learning methods build classication models various domains nance marketing healthcare 
classi cation techniques scienti disciplines including statistics pattern recognition machine learning neural nets expert systems 
quality quantity training data supervised methods important factor prediction accuracy derived models 
applications getting data class labels expensive labeling done manually experts 
frequently cited example electronic mail routing categories 
training data usually obtained manually labeling number instances mail 
example categorizing web pages content 
approach solving problem select data need labeled small amount training data su ces build classi er su cient accuracy 
random sampling clearly ine ective various classes skewed distributions data instances infrequent classes get omitted random samples 
strati ed sampling method developed address problem random samples 
unlabeled data partitioned attributes instance data 
sampling done separately partition biased expected di culty classifying data partition 
di cult generate partitions high dimensional data clear ectively apply approach seen real life applications 
active learning term coined represent methods learning algorithm assumes control subset input space modeling 
active learning mean learning unlabeled data oracle queried labels speci instances goal minimizing number oracle queries required 
active learning proposed various forms :10.1.1.13.8629:10.1.1.30.3233
discuss detail earlier works active learning related approach 
approach active learning uncertainty sampling instances data need labeled iteratively identi ed measure suggests predicted labels instances uncertain 
vari ous methods measuring uncertainty proposed 
single classi er produces estimate degree uncertainty prediction 
iterative process selects xed number instances maximum estimated uncertainty labeling 
newly labeled instances added training set generated larger training set 
iterative process continues training set reaches speci ed size 
method generalized classi ers rst determine degree uncertainty second classi cation 
probabilistic classi er chosen rst task ciency considerations rule induction chosen second task 
related approach committee 
version query committee approach classi ers consistent labeled training data randomly chosen 
instances data chosen classi ers disagree candidates labeling 
emphasis prove theoretical results approach 
adaptive resampling methods increasingly solve classi cation problem various domains high accuracies :10.1.1.133.1040
adaptive resampling refer methods boosting adaptively resample data biased misclassi ed points training set combine predictions classi ers 
various explanations forth classi cation accuracies achieved techniques :10.1.1.30.3515
adaptive resampling methods boosting useful selecting relevant examples original goal improve performance weak learning algorithms 
application boosting selective labeling suggested algorithmic details experimental results 
related application boosting select subset labeled instances nearest neighbor classi ers explored :10.1.1.133.1040
closest related combines query committee approach bagging boosting techniques 
general formulation separates roles classi er approaches 
allows plug different classi ers including oracle roles gain additional insight factors uencing results achieved 
di erences method relate practical aspects application impact computational requirements discussed 
applies adaptive resampling active learning task direct way described section 
goal retain advantages adaptive resampling methods accuracy robustness generated models combine reduction required size labeled training set 
comparisons classi ers adaptive resampling framework 
experimental results benchmarks various domains illustrate sizes labeled training sets needed get adequate classi cation accuracy 

description method adaptive resampling selects instances labeled training set goal improving classi cation accuracy 
selection process adapts biasing favor instances misclassi ed ensemble classi ers generated 
explore direct application framework choose unlabeled instances labeled active learning task 
actual labels unknown instances active learning task guessed labels generated classi er 
method alar input unlabeled data output labeled training set output classi er choose initial subset start process select initial subset label instances 
remove add subset instances selected labeling phase phase guess labels instance classi cation method 
multiple rounds adaptive resampling adaptive resampling training set classi cation method generate ensemble classi cation models 
select subset instances add training set adaptive resampling phase phase select subset sp weights calculated instance remove sp add build combined classi er voting combine ensemble classi cation models form resultant classi er alar description active learning adaptive resampling comments italicized consider detailed description method alar 
assumed apart unlabeled data provided method expert available label selected instance method produces output classi er selectively labeled training set uses classi er 
instances selected unlabeled data labeling iterative process 
initial subset typically chosen random 
instances labeled expert moved labeled training set statement 
additional instances labeled added phases 
phase labeled training set classi cation method guess labels unlabeled instances statement 
set instances labeled far adaptive resampling framework classi cation method generate ensemble classi cation models statement 
variations adaptive resampling proposed di er details weighting function resampling classi cation method 
experimental results generated decision trees classi cation method 
resampling done normalized version weighting function instance error error cumulative error instance classi cation models ensemble ensemble classi cation models guessed classes unlabeled data select instances labeling phase statement 
intuitively weights selecting instance labeling biased ensemble assuming validity guessed class labels experiments equation compute weights cumulative error calculated guessed class labels 
set instances sp selected sampling normalized version weights typically iterative addition instances labeled set continue speci ed size reached model quality improvements taper nal classi er generated combining classi cation models ensemble statement explore couple variations generation rst case classi cation models combined 
second case labeled training set complete new set classi cation models generated adaptive resampling complete set earlier models discarded 
second case corresponds method generate labeled training set adaptive resampling method experiments unweighted voting set classi cation models combined produce nal classi er 
variations alar method considered experiments discussed section 
rst approach refered alar vote combine unweighted voting ensemble classi cation models available phase classi cation model 
approach takes advantage reported ectiveness voting methods providing guessed labels :10.1.1.133.1040
second approach refered alar nn distinct classi cation methods utilized 
nearest neighbor method nn classi cation method 
approaches decision trees classi cation method 
comparison performance approaches interesting earlier comparisons classi er methods 
important parameters varied method number phases number points selected labeling phase number rounds adaptive resampling training set phase 
values parameters experiments section experimental details 

experiments section presents results applying method benchmarks various domains 
rst benchmark internet ads consider application identify images internet advertisements 
application remove advertisements identi cation evaluated benchmark donor 
features encode geometry image 
remaining binary features capture occurrences phrases url anchor text text near anchor text 
records benchmark missing data 
original data reported results accuracy measure 
skewed distribution classes ad leads usual information retrieval measures recall precision infrequent class ad 
experiments benchmark done fold cross validation 
rst experiment random sampling create training sets various sizes 
training set created types classi cation models constructed evaluated test set 
rst type model decision tree constructed tree package 
second type model created adaptive resampling training set trees 
shows results averaged experiments partition fold cross validation 
arithmetic mean precision recall metric displayed 
results obtained single tree comparable results 
quality precision recall degrades substantially single tree randomly chosen training set size reduced factor 
hand adaptive resampling randomly chosen subsets ar random robust 
precision recall metric ar random entire training data better 
training set cut size randomly factor metric ar random degrades 
earlier works active learning give comparisons classi ers single tree case shown 
prevalence success adaptive resampling methods interesting compare accuracy active learning methods ar random baseline 
improvement prediction accuracy alar method ar random shown 
performance curve repeated comparison 
curves marked alar achieved alar method set parameters 
total phases initial addition equal number instances labeled phase 
phase rounds adaptive resampling done labeled training set available point 
phase additions labeled training set increased rounds adaptive resampling 
combined classi er obtained voting trees ensemble 
set parameters experiments noted 
curves alar vote alar nn depict results achieved variations alar method 
average recall precision percentage ar random single tree size training set results random sampling benchmark internet ads alar vote curve achieved unweighted majority vote ensemble models classi cation method 
alar nn curve achieved nn classi cation method 
results indicate slight loss accuracy alar vote alar nn training set size reduced factor 
reductions size labeled training set accuracy methods alar vote alar nn degrades continues remain better ar random 
benchmark alar vote performs slightly better alar nn training set size range 
interesting curve plotted called 
curve oracle classication method 
obviously practical solution labels instances known 
alar oracle curve assess impact accuracy classi cation methods nn vote alar method 
gap alar oracle alar vote alar nn widens allowed size labeled set reduced 
caused part quality guesses alar vote alar nn getting worse size labeled set available decreases 
alar results impacted changing parameters alar method number phases number instances added labeling phase 
experimented parameters extent set parameter values benchmarks 
benchmark consider satimage uci repository 
benchmark contains spectral values pixels satellite image attributes goal predict soil type classes 
training set points test set points 
alar method applied set parameters described earlier results averaged experiments test set plotted 
ar random curve baseline goal accuracy achieved ar random average error entire training set size 
alar vote alar nn achieve comparable accuracy labeled instances 
labeled instances alar nn achieves average error alar vote achieves average error 
interestingly alar nn alar vote accuracy similar alar oracle ofthe training set size range 
alar method refer produces labeled training set speci ed size addition classi er explored labeled training set benchmark 
di erent classi ers compare training sets alar nn generated labeled set size random subset size entire training set size 
classi ers nn adaptive resampling trees single tree 
table presents average percentage errors standard deviation parenthesis experiments 
benchmark smaller labeled set produced alar nn classi ers produce fairly accurate models compared results entire training set 
investigations needed determine general labeled sets useful classi ers 
benchmark letter recognition uci repository 
attributes capture statistical moments edge counts english alphabets various fonts goal determining displayed alphabet classes 
benchmark speci es training set instances test set instances 
results applying alar method shown 
alar nn alar vote achieve accuracy goal labeled instances 
benchmark mod apte split reuters data set available 
top categories considered 
solve binary classi cation problem category 
notion information gain select set attributes binary classi cation problems :10.1.1.32.9956
average recall precision percentage alar oracle alar vote alar nn ar random size training set results alar methods benchmark internet ads error percentage ar random alar vote alar nn alar oracle size training set results alar methods benchmark satimage feature selection method requires labels applicable truly unlabeled data 
reduction size labeled set experimental framework translate corresponding reduction labeled set needed reuters classi cation problem 
experimental framework earlier works 
internally available decision tree package customized text applications benchmark 
customary benchmark micro average measure confusion matrices categories added precision recall computed 
random runs performed micro average arithmetic mean recall precision 
slight degradation accuracy just labeled instances alar vote alar nn method 

discussions experimental results previous section indicate alar nn alar vote methods perform similarly benchmarks 
clearly ev experiments justify added computational cost separate classi cation method nn 
alar vote natural direct way apply adaptive resampling task active learning compared alar nn 
benchmarks internet ads reuters alar method oracle signi cantly better alar vote especially smaller sizes training set 
part explanation quality guesses get worse size labeled training set decreases 
variations behavior various benchmarks require investigation 
hard directly compare results obtained alar methods obtained earlier approaches active learning 
clearly performance active learning method depends heavily benchmark usage 
earlier works active learning report signi cant reduction required size labeled training set 
baseline target accuracy chosen di erently case 
example baseline target classi er random alar nn entire subset generated training subset set size size size nn adaptive resampling trees single tree table alar nn generated subset classi ers comparisons error percentage ar random alar vote alar nn alar oracle size training set results alar methods benchmark letter recognition set accuracy achieved rules full labeled set 
seen adaptive resampling classi cation methods signi cantly improve baseline target single tree classi ers 
pointed includes boosted results baseline 
adaptive resampling trees computationally intensive process alar method inherits computational complexity decision trees chosen classication method 
values parameters alar method chosen experiments computational complexity accuracy considerations 
instances chosen labeling added training set phases 
phase needs rounds adaptive resampling train ensemble classi ers adequately training set phase 
adding instance phase lead phases rounds adaptive resampling 
experiments total number rounds adaptive resampling impacts computational cost chosen comparable earlier usage :10.1.1.133.1040
having chosen number phases determined trading having rounds phase adaptive resampling versus having phases ne grain control adding instances labeling 
mentioned computational considerations lead select multiple instances labeling phase 
opens issue instances chosen 
approach extend greedy method picking instance picking multiple instances largest weights 
randomized method creating probability function selection weights equation pick multiple instances replacement 
comparison benchmark satimage 
benchmark probabilistic method alar vote performs better greedy method greedy smaller training set sizes 
plausible explanation picking multiple instances greedy fashion may including instances redundant modeling 
combining methods improve selection process needs explored 
practice active learning process stopped detecting diminishing improvement quality models built 
convergence detection studied case random sampling estimating slope learning curve 
learning curve behaved active learning case making task complicated 
general problem determining schedule adding labeled points harder random sampling case 
variations method ex micro average recall precision percentage alar oracle alar nn alar vote ar random size training set results alar methods top categories benchmark reuters error percentage greedy alar vote size training set comparing greedy probabilistic selection methods benchmark satimage 
simpler classi cation methods explored 
related problem decision trees addressed attribute selection unlabeled data 
variation explored function equation adaptive resampling relating importance selecting instance measure error 
adaptive resampling literature explored related subject tting noisy labels training set 
concern tting noise labels directly applicable active learning context error measure computed guessed labels 

dealing vast amounts unlabeled data growing problem domains 
direct way adaptive resampling methods selecting subset instances labeling 
experiments various benchmarks indicate method successful signi cantly reducing size labeled training set needed sacri cing classi cation accuracy compared state art method adaptive resampling trees 
anonymous referees helpful comments 

abe 
query learning strategies boosting bagging 
proceedings international conference machine learning pages 
angluin 
queries concept learning 
machine learning 
apte damerau weiss 
automated learning decision rules text categorization 
acm transactions information systems july 
bauer kohavi 
empirical comparison voting classi cation algorithms bagging boosting variants 
machine learning 
berry data mining techniques marketing sales customer support 
john wiley sons 
blake keogh merz 
uci repository machine learning databases 
university california irvine dept information computer science url www ics uci edu mlearn html 
breiman 
arcing classi ers 
annals statistics 
cochran 
sampling techniques 
john wiley sons 
cohn atlas ladner 
training connectionist networks queries selective sampling 
advances neural information processing systems 
morgan kaufmann 
cohn atlas ladner 
improved generalization active learning 
machine learning 
cohn ghahramani jordan 
active learning statistical models 
journal arti cial intelligence research 
cohn ghahramani jordan 
active learning mixture models 
multiple model approaches modeling control 
taylor francis 
dietterich 
experimental comparison methods constructing ensembles decision trees bagging boosting randomization 
machine learning august 
freund 
sifting informative examples random source 
advances neural information processing pages 
freund schapire :10.1.1.133.1040
experiments new boosting algorithm 
proceedings international conference machine learning pages 
morgan kaufmann 
freund seung shamir tishby 
information prediction query committee 
advances neural information processing systems pages 
morgan kaufmann 
freund seung shamir tishby 
selective sampling query committee algorithm 
machine learning 
friedman hastie tibshirani 
additive logistic regression statistical view boosting 
technical report technical report stanford university dept statistics july 
kushmerick 
learning remove internet advertisements 
proceedings third international conference agents pages 
lewis 
reuters data set 
url www research att com lewis reuters html 
lewis catlett 
heterogeneous uncertainty sampling supervised learning 
proceedings eleventh international conference learning pages 
lewis gale 
sequential algorithm training text classi ers 
proceedings seventeenth annual acm conference research development information retrieval pages 
liere tadepalli 
active learning committees text categorization 
proceedings fourteenth national conference onarti cial intelligence pages 
mccallum nigam 
employing em pool active learning text classi cation 
proceedings fifteenth international conference machine learning pages 
provost jensen oates 
cient progressive sampling 
proceedings fifth acm sigkdd international conference knowledge discovery data mining pages 
schapire freund bartlett lee 
boosting margin new explanation ectiveness voting methods 
annals statistics 
seung opper sompolinsky 
query committee 
proceedings fifth acm workshop computational learning theory pages 
weiss apte damerau johnson oles goetz 
maximizing text mining performance 
ieee intelligent systems applications july august 
weiss indurkhya 
data miner software kit 
url www data miner com 
weiss kulikowski 
computer systems learn 
morgan kaufmann 
yang pedersen :10.1.1.32.9956
comparitive study feature selection text categorization 
icml proceedings fourteenth international conference machine learning pages 
