unsupervised learning models recognition weber welling perona dept computation neural systems dept electrical engineering california institute technology mc pasadena ca universit di padova italy welling perona vision caltech edu 
method learn object class models unlabeled unsegmented cluttered scenes purpose visual object recognition 
focus particular type model objects represented flexible constellations rigid parts features 
variability class represented joint probability density function pdf shape constellation output part detectors 
stage method automatically identifies distinctive parts training set applying clustering algorithm patterns selected interest operator 
learns statistical shape model expectation maximization 
method achieves classification results human faces rear views cars 
related interested problem recognizing members object classes define object class collection objects share characteristic features parts visually similar occur similar spatial configurations 
building models object classes type faced problems see fig 

segmentation registration training images objects recognized appear training images 
part selection object parts distinctive stable 
estimation model parameters parameters global geometry shape appearance individual parts best describe training data 
solutions model learning problem proposed typically require questions answered human supervisor 
example features training images need hand labeled 
oftentimes training images showing objects front uniform background required 
objects need positioned way training images common frame established 
amit geman developed method visual selection learns hierarchical model simple type feature detector edge elements front 
method assumes training images registered respect grid 
exhaustive search local feature detectors global model built shape variability encoded form small regions local features move freely 
vernon ed eccv lncs pp 

springer verlag berlin heidelberg unsupervised learning models recognition fig 

objects appear consistently left images right side 
machine learn recognize instances object classes faces cars information provided 
burl proposed statistical model shape variability modeled probabilistic setting mardia shape space densities :10.1.1.44.4529
method requires labeled part positions training images 
similar approaches object recognition include active appearance models taylor model global deformations eigenspace methods dynamic link architecture der malsburg colleagues consider deformation energy grid links landmark points surface objects 
yuille proposed recognition method gradient descent deformation energy function 
obvious methods trained supervision 
problem automatic part selection important generally established parts appear distinctive human observer lend successful detection machine 
walker address problem albeit outside realm statistical shape models 
emphasize distinctiveness part selection 
argue believe part selection done context model formation 
completely unsupervised solution problems introduced particular may reach 
intuition suggests deal knowledge objects question required order know look cluttered training images 
solution provided expectation maximization framework allows simultaneous estimation unknown weber welling perona data probability densities unknown data 
framework problems solved simultaneously 
compelling reason treat problems jointly existing trade distinctiveness parts 
distinctive part strong cue appears arbitrary location surface object think manufacturer logo car 
hand distinctive part contribute information occurs stable spatial relationship relative parts 
approach model object classes burl :10.1.1.44.4529
object composed parts shape parts image patches may detected characterized appropriate detectors shape describes geometry mutual position parts way invariant respect rigid possibly affine transformations 
joint probability density part appearance shape models object class 
object detection performed running part detectors image obtaining set candidate part locations 
second stage consists forming object hypotheses constellations appropriate parts eyes nose mouth ears complete partial constellations considered order allow partial occlusion 
third stage consists object joint probability density calculating likelihood hypothesis arises object object detection likelihood specific hypothesis arises object object localization 
order train model need decide key parts object select corresponding parts eyes nose number training images lastly need estimate joint probability density function part appearance shape 
burl perform second act hand estimating joint probability density function automatically 
propose methods automating second steps 
technique selecting potentially informative parts composed steps see fig 

small highly textured regions detected training images means standard interest operator keypoint detector 
training images segmented step select regions interest image areas corresponding training objects clutter background 
objects training set similar appearance textured regions corresponding objects frequently similar opposed textured regions corresponding background uncorrelated 
unsupervised clustering step favoring large clusters tend select parts correspond objects interest background 
appropriate part detectors may trained clusters 
second step proposed model learning algorithm chooses promising parts informative ones simultaneously estimates remaining model parameters 
done iteratively trying different combinations small number parts 
iteration parameters underlying probabilistic model estimated 
depending performance model validation data set unsupervised learning models recognition choice parts modified 
process iterated final model obtained improvements possible 
foreground training images background training images part selection interest operator parts vq parts model learning select update model structure parts parameter estimation validation model final model parts foreground test images test model background test images fig 

block diagram method 
foreground images images containing target objects cluttered background 
background images contain background 
outline section statistical object model 
section discusses automatic part selection 
section dedicated second step model formation training 
section demonstrates method experiments datasets cars faces 
modeling objects images model burl 
important differences model positions background parts uniform density gaussian large covariance 
probability distribution number background parts burl ignored modeled case poisson distribution 
generative object model model objects collections rigid parts detected corresponding detector recognition 
part detection stage transforms entire image collection parts 
parts correspond instance target object class foreground stem background clutter simply false detections background 
information associated object part position image identity part type 
assume different types parts 
positions parts extracted image summarized matrix form xt xt superscript indicates positions observable image opposed unobservable missing denoted weber welling perona tth row contains locations detections part type entry xij isa dimensional vector 
assume object composed different parts need able indicate parts xo correspond foreground object interest 
vector set indices hi indicating point xij foreground point 
object part contained xo occluded undetected corresponding entry zero 
unsegmented unlabeled image know parts correspond 
observable treat hidden missing data 
call hypothesis hypothesize certain parts xo belong foreground object 
convenient represent positions unobserved object parts separate vector xm course hidden 
dimension xm vary depending number missed parts 
define generative probabilistic model joint probability density 
note entries xo xm random variables dimensions 
model details order provide detailed parametrization introduce auxiliary variables binary vector encodes information parts detected missed occluded 
bf hf bf 
variable vector nt shall denote number background candidates included th row variables completely determined size 
assume independence foreground background decompose way 
probability density number background detections modeled poisson distribution nt 
mt nt mt mt average number background detections type image 
conveys assumption independence part types background idea background detections arise location image equal probability independently locations 
discrete grid pixels modeled binomial distribution 
model foreground simplify notation consider case extension general case straightforward 
unsupervised learning models recognition detections continuous range positions chose poisson distribution continuous limit binomial distribution 
admitting different mf part type allows model different detector statistics 
depending number parts model probability explicit table length joint probabilities large independent probabilities governing presence absence individual model part 
joint treatment lead powerful model certain parts occluded simultaneously 
density modeled bf denotes set hypotheses consistent nf denotes total number detections type part expresses fact consistent hypotheses number bf nf equally absence information part locations 
pfg defined ot mt coordinates foreground detections observed missing coordinates background detections 
important assumption foreground detections independent background 
experiments pfg modeled joint gaussian mean covariance 
note far modeled absolute part positions image 
little foreground object position image 
obtain translation invariant formulation algorithm experiments describing part positions relative position part 
modification pfg remain gaussian density introduce fundamental difficulties 
formulation somewhat intricate especially considering missing parts 
discussion invariance reader referred 
positions background detections modeled uniform density total image area 
classification nt experiments objective classify images classes object class object absent class 
observed data optimal decision minimizing expected total classification weber welling perona error choosing class maximum posteriori probability map approach see 
convenient consider ratio xo xo denotes null hypothesis explains parts background noise 
notice ratio omitted absorbed decision threshold 
sum numerator includes hypotheses null hypothesis object remain undetected part detector 
denominator consistent hypothesis explain object absent null hypothesis 
concerned classification framework means restricted problem 
instance object localization possible identifying foreground parts image highest probability corresponding occurrence target object 
automatic part selection problem selecting distinctive object parts intimately related method detect parts recognition system put 
need evaluate large number potential parts detectors settled normalized correlation efficient part detection method 
furthermore extensive experiments lead believe method offers comparable performance elaborate detection methods 
correlation detection pattern small neighborhood training images template prospective part detector 
purpose procedure described reduce potentially huge set parts reasonable number model learning algorithm described section select useful parts 
step procedure accomplish 
step identify points interest training images see fig 

done interest operator proposed capable detecting corner points intersections lines center points circular patterns 
step produces part candidates training image 
significant reduction number parts achieved second step selection process consists performing vector quantization patterns similar procedure leung malik 
standard means clustering algorithm tuned produce set patterns 
patterns represents center cluster obtained average patterns cluster 
retain clusters patterns 
impose limit clusters composed examples tend represent patterns appear significant number training images 
obtain parts averaged entire set training images 
order eliminate redundancies remove patterns small shift pixels arbitrary direction 
due restriction points interest set remaining patterns exhibits interesting structure seen 
parts human eyes unsupervised learning models recognition fig 
points interest left identified image face cluttered type patterns 
patterns obtained means clustering small image patches shown faces center cars right 
car images high pass filtered part selection process 
total number patterns selected faces cars 
readily identified 
parts simple corners result averages larger clusters containing thousands patterns 
procedure dramatically reduces number candidate parts 
point parts corresponding background portions training images 
model learning order train object model set images need solve problems 
firstly need decide small subset selected part candidates model define model configuration 
secondly need learn parameters underlying probability densities 
solve problem iterative greedy strategy try different configurations 
iteration pdfs estimated expectation maximization em 
greedy model configuration search important question answer parts endow model 
number parts increases models gain complexity discriminatory power 
strategy start models comprised parts add parts monitoring generalization error possibly criterion penalizing complexity 
start learning process parts say facing problem selecting best possible sets parts number part candidates produced described sec 

iteratively starting random selection 
iteration test replacing model part randomly selected improves model 
estimate remaining model parameters training images explained section assess classification performance validation set positive negatives examples 
performance improves replacement part kept 
process stopped improvements possible 
start increasing total number parts model 
weber welling perona possible render process efficient particular models parts prioritizing parts previously shown validation performance smaller models 
estimating model parameters expectation maximization address problem estimating model pdfs set model parts set training images 
detection method relies maximum posteriori probability map principle goal model class conditional densities accurately possible 
employ expectation maximization em algorithm produce maximum likelihood estimates model parameters 
em suited problem variables xm missing inferred observed data xo 
standard em fashion proceed maximizing likelihood observed data log hi dx hi respect model parameters 
difficult achieve practice em iteratively maximizes sequence functions log hi 
refers expectation respect posterior hi xo 
section tilde denotes parameters optimizing tilde implies values previous iteration substituted 
em theory guarantees subsequent maximization converges local maximum derive update rules step em algorithm 
parameters need consider gaussian governing distribution foreground parts table representing parameter governing background densities 
helpful decompose parts factorization equation 
log ni log bi log hi ni bi log hi ni terms depend parameters updated em 
unsupervised learning models recognition update rule depends derivative expected likelihood yields zi zt definition 
setting derivative zero yields update rule zi 
update rule similarly obtain derivative respect inverse covariance matrix zi zi equating zero leads zi zi update rule find update rule probability masses need consider term depending parameters 
derivative respect probability observing specific vector obtain shall denote kronecker delta 
imposing constraint instance adding lagrange multiplier term find update rule 
update rule notice term containing information mean number background points part type mf differentiating respect find ni equating zero leads intuitively appealing result ni 
weber welling perona computing sufficient statistics update rules derived expressed terms sufficient statistics zz calculated step em algorithm 
consider posterior density hi hi hb hi xm xo hi xm xo denominator expression equal xo calculated explicitly generating summing hypotheses integrating missing data hypothesis 
expectations calculated similar fashion calculated summing hypotheses consistent dividing xo 
similarly ni calculated averaging hypotheses 
case slightly complicated 
hypothesis regroup zt note xo xo fore xm needs calculate defined dx mo oo oo om mo mm summing hypothesis dividing xo establishes result 
need calculate zz ot oe xm xm part mt considered 
integrating missing dimensions involves mt dx mm mo oo mot looping possible hypotheses dividing xo provides desired result 
concludes step em algorithm 
experiments order validate method tested performance classification task described sect 
data sets images rear views cars images human faces 
mentioned sec 
experiments described performed translation invariant extension learning method 
parameters learning algorithm set values experiments 
integrating dimensions gaussian simply done deleting means covariances dimensions multiplying suitable normalization constant 
unsupervised learning models recognition roc percent cars train model performance cars test faces train faces test number parts fig 

results learning experiments 
left show best performing car model parts 
selected parts shown top 
ellipses indicating std deviation distance mean part positions foreground pdf superimposed typical test image 
aligned hand illustrative purposes models translation invariant 
center show best part face model 
plot right shows average training testing errors measured area corresponding roc curve 
models observes moderate overfitting 
faces smallest test error occurs parts 
amount training data optimal number parts 
cars parts 
training test images object classes took images showing target object arbitrary location cluttered background fig 
left 
took images background scenes environment excluding target object fig 
right 
images discarded hand prior experiments 
face images taken indoors outdoors contained different people male female 
car images public streets parking lots photographed vehicles different sizes colors types sport utility vehicles pick trucks 
car images high pass filtered order promote invariance respect different car colors lighting conditions 
images taken digital camera converted grayscale representation downsampled resolution pixels 
image set randomly split disjoint sets training test images 
face experiment single person sets 
fig 

multiple parts part model left correctly classified images right 
part labels 
note middle part exhibits high variance vertical direction 
matches locations images bumper license plate roof 
probabilistic framework decision correct match 
evidence accumulated possible matches 
weber welling perona automatically selected parts parts automatically selected procedure described sec 

interest operator applied unlabeled unsegmented training images containing instances target object class 
performed vector quantization grayscale patches size pixels extracted points interest 
different set patterns produced object class shown 
model learning learned models parts data sets 
greedy configuration search em algorithm potentially converge local extrema learned model times recording average classification error 
models learned entire set selected parts 
knowledge training small models usefulness parts applied training larger models 
done order investigate extent parts chosen model sizes 
em algorithm converge iterations corresponds model parts min part model 
matlab implementation subroutines written pc mhz pentium ii processor 
number different part configurations evaluated varied parts parts 
results classifying image applying fixed decision threshold computed receiver operating characteristics ratio posterior probabilities 
order reduce sensitivity noise due limited number training images average possible values decision threshold area roc curve measure classification performance driving optimization model configuration 
show learned models error measure function number parts 
examples successfully wrongly classified images test sets shown fig 

inspecting models produced able interesting observations 
example case faces confirmation eye corners parts 
intuition correct 
features turned stable parts containing models 
introduced high pass filter preprocessing step car models concentrated dark shadow underneath cars stable feature 
researchers familiar problem tracking cars freeways confirmed shadow easiest way detect car 
oftentimes learning algorithm took advantage fact part detectors respond multiple locations target objects fig 

effect pronounced models parts 
difficult predict exploit behavior building model hand ran learning process times able assess likelihood converging local extrema 
size models different part choices produced 
choice produced times 
regarding em unsupervised learning models recognition correct incorrect incorrect incorrect incorrect correct correct incorrect incorrect incorrect fig 

examples correctly incorrectly classified images test sets models fig 

part labels 
foreground background images classified case 
decision threshold set yield equal error rate foreground background images 
case faces images classified correctly compared difficult car experiment 
algorithm observed instance choice parts resulted different classification performances 
leads conclude em algorithm extremely get stuck local maximum 
inspection different part types selected model sizes noticed half parts chosen particular model size smaller models 
suggests initializing choice parts parts performing smaller models strategy 
allow algorithm choose parts smaller models 
discussion ideas learning object models unsupervised setting 
set unsegmented unlabeled images containing examples objects clutter supplied algorithm automatically selects distinctive parts object class learns joint probability density function encoding object appearance 
allows automatic construction efficient object detector robust clutter occlusion 
demonstrated model learning algorithm works successfully different data sets frontal views faces rear views motor cars 
case faces discrimination images containing desired object vs background images exceeds correct simple models composed parts 
performance cars correct training computationally expensive detection efficient requiring second matlab implementation 
suggests training seen line process detection may implemented real time 
main goal demonstrate feasible learn object models directly unsegmented cluttered images provide ideas may 
aspects implementation suboptimal susceptible improvement 
list implemented part detectors normalized correlation 
sophisticated detection algorithms involving multiscale image processing filters neural networks considered tested 
weber welling perona current implementation part information supplied detectors candidate part location scale orientation image patch parameters describing appearance patch likelihood incorporated 
interest operator unsupervised clustering parts optimized respect choice algorithms deserves scrutiny 
important aspect implementation falls short generality invariance models learned tested translation invariant rotation scale affine invariant 
conceptual limit generalization straightforward implementation em algorithm rotation scale invariant case slow impractical extensive experimentation 
funded nsf engineering research center systems engineering caltech nsf nsf national young investigator award 
nsf 
welling supported sloan foundation 
grateful rob fergus helping collecting databases thomas leung mike burl jitendra malik david forsyth helpful comments 

amit geman 
computational model visual selection 
neural computation 

burl leung perona 
face localization shape statistics 
int workshop automatic face gesture recognition 

burl leung perona 
recognition planar object classes 
proc 
ieee comput 
soc 
conf 
comput 
vision pattern recogn 

burl weber perona 
probabilistic approach object recognition local photometry global geometry 
proc 
eccv pages 

cootes taylor 
locating objects varying shape statistical feature detectors 
european conf 
computer vision pages 

dempster laird rubin 
maximum likelihood incomplete data em algorithm 
journal royal statistical society 

duda hart 
pattern classification scene analysis 
john wiley sons 

edwards cootes taylor 
face recognition active appearance models 
proc 
th europ 
conf 
comput 
vision burkhardt neumann eds lncs series vol 
springer verlag pages 

haralick shapiro 
computer robot vision ii 
addison wesley 

lades buhmann lange malsburg wurtz andw 

distortion invariant object recognition dynamic link architecture 
ieee trans 
comput mar 

leung burl perona 
finding faces cluttered scenes random labeled graph matching 
proc 
th int 
conf 
computer vision pages june 

leung burl perona 
probabilistic affine invariants recognition 
proc 
ieee comput 
soc 
conf 
comput 
vision pattern recogn pages 

leung malik 
surfaces dimensional textons 
proc 
th int 
conf 
computer vision pages 

walker cootes taylor 
locating salient facial features 
int 
conf 
automatic face gesture recognition nara japan 

yuille 
deformable templates face recognition 
cognitive neurosci 
