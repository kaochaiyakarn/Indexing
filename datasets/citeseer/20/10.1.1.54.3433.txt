function optimization connectionist reinforcement learning algorithms ronald williams jing peng college computer science northeastern university appears connection science pp 

nonassociative reinforcement learning algorithm viewed method performing function optimization possibly noise corrupted sampling function values 
describe results simulations optima deterministic functions studied ackley sought variants reinforce algorithms williams 
algorithms incorporated additional heuristic features resembling certain aspects algorithms ackley studies 
differing levels performance achieved various algorithms investigated number performed level comparable best ackley studies number tasks spite simplicity 
variants called reinforce ment represents novel principled approach reinforcement learning nontrivial networks incorporates entropy maximization strategy 
perform especially hierarchically organized tasks 
background thesis ackley explored interesting general approach function optimization differing somewhat common approaches emphasize limiting behaviors terminating conditions 
studied behavior variety generalpurpose optimization algorithms existing design number optimization problems involving functions defined binary tuples measured performance criterion require convergence 
algorithms investigated forms simple hillclimbing algorithm combined random restarts convergence simulated annealing gelatt vecchi combined random restarts convergence preparation partially supported iri national science foundation 
fixed temperature thermally hillclimber essentially simulated annealing annealing variations genetic algorithms goldberg holland holland combined random restarts convergence combination hillclimbing genetic search random restarts convergence connectionist network algorithm called stochastic iterated genetic hillclimbing contains elements drawn number sources interesting description terms election metaphor 
studied number existing reinforcement learning algorithms appropriate candidates various algorithms stochastic learning automata literature narendra various connectionist reinforcement learning algorithms associative reward penalty algorithm barto colleagues barto barto anandan barto anderson reinforce algorithms williams 
describe results experiments performed variants reinforce tasks studied ackley 
preliminary report appeared williams peng 
problem formulation problem formulation proposed ackley adopted loosely described follows 
consider generate test scenario particular stopping criterion 
job generator generate trial points tester determines value function optimized trial point 
stopping criterion process generate test repeated indefinitely 
interesting generator adaptive tends generate better points gains information function optimized 
adopt convention better point having higher function value 
systems interest ones perform endless repetition simple generate test adapt loop 
view system carrying optimization algorithm add stopping criterion sort way reporting answer step process 
ways issues handled 
way suitable process eventually converges eventually trial point generated test condition report point output algorithm 
way retain memory best point far report point output algorithm terminated 
real value approach attempt isolate possible useful features generate test adapt loop issues involving choice termination criterion 
particular approach require global optimum recognized explicitly process terminates global optimum generated implicitly eventual convergence global optimum 
generator may continue generating inferior points having generated global optimum 
approach stresses ackley called sustained exploration 
believe sustained exploration may turn important feature procedures designed perform sort optimization process particularly large finite search spaces having points involved function optimized varies time expect characteristic realistic optimization problems 
course study various approaches adaptive generation process simulation necessary incorporate adaptive generators studied terminating algorithms 
follow ackley adopt strategy problems optimum point known simply run algorithm point generated maximum computational effort expended 
measure computational effort number function evaluations performed 
measure determine terminate run declare failure measure performance various adaptive generation techniques studied 
reinforcement learning networks adaptive trial generators connectionist network generator trial points optimization problem long domain function optimized represented set output patterns network 
furthermore reinforcement learning algorithm adjusting weights network barto barto anandan barto anderson munro sutton williams provide means adapting behavior trial point generator simply regarding function value reinforcement signal delivered network response output pattern 
particular reinforcement learning algorithm represents extreme specialization general formulation reinforcement learning problem reinforcement may stochastic deterministic function network output network may required perform mapping input output associative reinforcement learning reinforcement signal input provided network may depend past input output patterns environment memory 
general formulation encompasses features characteristic realistic learning situations 
reason number sophisticated directions study reinforcement learning systems taken including temporal difference learning methods adaptive prediction reinforcement barto sutton anderson sutton sutton internal models environment type munro sutton relevant purposes 
treat problem maximizing deterministic function extremely pared form reinforcement learning task nonassociative involves memoryless environment noise free reinforcement term optimization process meant cover variety possibilities including processes terminate global maximum processes simply continue discover better better points possible terminate 
signal 
important feature type problem seek attack techniques large space optimization performed 
differs markedly emphasis armed bandit similar problems heavily studied learning automata literature narendra 
reinforcement learning tasks issue problems sample entire space determine statistical confidence action gives best average result converging selecting action exclusively 
consider search spaces large infeasible consider sampling subset possible points 
emphasize connectionist approach optimization study quite different initiated hopfield tank 
approach knowledge function optimized approach taken 
approach requires devising function having global optimum actual function optimized 
new function incorporated network weights network settles local optima function 
contrast technique studied general information concerning function optimized 
information available function arises sampling function values various points 
paradigm studied exploring genetic algorithms goldberg holland holland function optimization function optimized usually called fitness function accord approach inspired process biological evolution natural selection 
approaches reinforcement learning networks study stochastic units allow sampling variety output patterns 
setting weights network particular distribution output patterns generated 
broad goal adaptive sampling scheme try reshape sampling distribution ways sample better points 
applying reinforcement learning algorithm weights viewed means doing just sample points generated network 
formal notation terminology discussing specific algorithms optimization problems investigated introduce general notational framework mathematical assumptions description reinforcement learning networks 
network quantities consider network having external input lines environment output units affect environment nh hidden units 
denote tuple external input signals network particular time denote tuple network output produced result 
convenient collect unit output values nh tuple typical element output th unit network 
addition define nh tuple obtained concatenating denote set indices designate units networks disjoint set indices designate input lines 
typical element output th unit network value received th input line note consequence notational convention different names quantity general philosophy notation variables symbolized represent input variables symbolized represent output level individual units level entire network 
output unit may serve input units consistently role input emphasized role output emphasized 
similarly input network output denote weight matrix network exactly weight may zero pair units input line unit 
element ij theta nh matrix represents weight connection th unit th unit th input line 
accommodate bias weight unit simply include input lines input value 
adopt convention bias input index represents bias weight th unit 
introduced notation appropriate general case network may provided external environmental input 
includes associative case 
specific function optimization application considered assume external input need bias input 
time network computes output vector assumed represent single trial point function optimized 
bernoulli logistic units assume units network bernoulli logistic units terminology williams 
appropriate purposes functions optimized defined binary tuples 
output unit determined stochastically bernoulli distribution parameter logistic function gammas ij usual weighted summation input values unit 
unit represents probability choosing output value 
reinforce algorithms main objective research reported study reinforce class algorithms perform function optimization tasks 
give brief overview particular form algorithms take applied networks bernoulli logistic units 
extensive discussion algorithms see williams 
general reinforcement learning paradigm network generates output pattern environment responds providing reinforcement evaluation output pattern drive weight changes particular reinforcement learning algorithm network 
bernoulli logistic units general reinforce algorithm prescribes weight increments equal deltaw ij ff ij gamma ij gamma ff ij positive learning rate possibly different weight ij serves reinforcement baseline different weight 
consider algorithms having form deltaw ij ff gamma gamma ff ij ff ij shown williams regardless computed depend immediately received reinforcement value algorithm satisfies ffr denotes expectation operator 
reinforcement learning algorithm satisfying loosely described having property statistically climbs gradient expected reinforcement 
optimization problems optimization problems simulation results report particular maximization problems originally studied ackley 
problems detail contrived problems designed isolate specific features various optimization problems may possess specific combinatorial optimization problems 
claim suite problems represents definitive benchmark optimization algorithms simply wished able compare results ackley 
generally denote function maximized representing point domain 
problems studied mapping dimensional hypercube real numbers point domain dimensional bit vector 
notation description problems follows number gamma number tuple tuple problems max function point global maximum false maxima 
max function gamma nj global maximum false maximum 
function value global maximum problems false maximum 
number points space uphill moves lead global maximum somewhat larger number false maximum look attractive hillclimber 
porcupine function gamma mod essentially max high frequency component added confound myopic hillclimber 
global maximum point hamming distance local maximum 
plateaus function defined follows assumed divisible kn words function computed follows divide bits equal sized groups 
group compute score bits group 
sum scores 
previous ones function global maximum 
large plateaus function constant 
optimization problems report results simulation studies case 
graph partitioning problems type problem investigated type combinatorial optimization problem known np complete minimum cut graph partitioning problem garey johnson 
usual form problem graph number nodes assign node groups way groups contain equal numbers nodes number edges connecting nodes lying groups minimized 
nodes graph assignment nodes groups represented giving groups names considering binary tuple represent assignment th node assigned group order treat optimization problem set binary tuples hard constraint groups contain equal numbers nodes replaced imbalance penalty 
ackley treated graph partitioning problem problem maximizing function gammac gamma gamma number edges cross partition particular assignment ackley studied randomly generated graphs graphs having particular hierarchical structure 
belief problems having type higher order structure hope develop useful general purpose optimization algorithms restricted attention hierarchically structured graphs studied 
graph nodes depicted nodes depicted 
ackley called multilevel hypercube graphs gave names mlc mlc respectively 
insert 
insert 
note function optimized problems symmetric bitwise complementation argument graph 
particular graph partitioning problems exactly global maxima number local maxima 
furthermore minimum hamming distance false peak global maximum mlc mlc 
note network generate trial points number output units network obviously equal identify network output pattern experiments team networks team networks report results set studies simple form trial generating network units output units interconnections 
discuss experiments networks interconnections play important role 
degenerate class network corresponds called team automata literature stochastic learning automata narendra 
call networks teams bernoulli logistic units 
units output units interchangeably network 
shows example team network 
insert 
bernoulli logistic unit receiving input sources external unit constant bias input probability unit produces particular trial value bias weight fy jw gammaw units pick outputs independently follows team bernoulli logistic units probability particular output vector conditioned current value weight matrix jw gamma gammay bias weights adjusted particular learning algorithm details algorithms discussed 
note unit equally pick increasing 
adjusting bias weights team bernoulli logistic units tantamount adjusting probabilities individual components 
team algorithms total different algorithms team architecture general form th time step generating output receiving reinforcement increment bias weight deltaw gamma ff learning rate ffi weight decay rate parameters algorithm 
call ae reinforcement factor eligibility weight reinforcement factor exponentially weighted average trace prior reinforcement values flr gamma gamma fl computed ae gamma gamma gamma fi fi parameter algorithm 
trace parameter fl set equal experiments reported 
considered different forms eligibility gamma gamma gamma average past values computed exponential weighting scheme fly gamma gamma fl forms eligibility considered varied algorithms studied feature dimensions size decay rate ffi size fi 
particular different settings ffi zero appropriate nonzero value chosen experiments 
similarly different settings fi zero appropriate nonzero value ackley chose 
values nonzero decay value trace parameter chosen solely commonly values parameters play corresponding roles wide variety similar algorithms attempt tune parameters explore possible variations performance 
experimental results report combinations variations fi ffi nonzero 
algorithms reinforce algorithms described earlier viewed slight variants 
reinforce algorithms gamma ffi seen comparing equation result combining equations 
fi uses standard reinforcement comparison technique advocated sutton reinforcement baseline equation set equal essentially tries reinforcement factor zero mean 
version fi corresponds setting reinforcement baseline equation equal fi 
gives reinforcement factor negative bias expect destabilize algorithm fails change 
ackley technique component algorithm curious see prevent convergence force sustained exploration 
gamma form eligibility motivated simulation results sutton personal communication suggesting faster learning achieved form analytic results suggesting proving 
omit details analysis algorithm results combining standard reinforcement comparison reinforcement factor eligibility factor close relationship linear regression analysis bernoulli logistic units 
weight decay chosen simple heuristic method force sustained exploration discovered algorithms converge 
having decay bias particular member team bernoulli units closely related having nonzero mutation rate particular allele genetic algorithm goldberg holland holland 
see suppose represents probability particular bit position randomly generated bit vector mutation operator 
suppose probability mutation operator complements bit generated mutation 
probability entire process fu jp gamma gamma gamma gamma effect applying mutation operator way just applying proportional decay probability generating 
difference proportional bias decay nonlinearity squashing function 
squashing function linear approaches identical 
results team algorithms summary results experiments performed optimization problems including team networks table 
parameters fixed problems particular algorithm learning rate ff 
extensive amount fine tuning performed ff combination algorithm problem 
table shows combination particular value learning rate runs combination rounded mean run length number function evaluations reach global optimum set runs 
case mean runs algorithm problem combination 
result reported infinite indicates algorithm failed find global maximum runs 
discussed case happened reason algorithm trapped local maximum 
comparison give best average result reported ackley optimization problems 
results reported rounded means runs problems median runs graph partitioning problems 
discussion team results experiments convinced team algorithms having weight decay eventually converge true generally reinforce algorithms arbitrary networks 
expected algorithms having negative bias reinforcement factor turned true negatively biased reinforcement factor 
convergence generally false maximum reason algorithms usually successful graph partitioning problems 
conclude negative bias mechanism providing sustained exploration believed 
consequence tendency converge problem choice learning rate algorithms weight decay critical disregarding problems typically failed plateaus function 
large learning rate guarantees search converge plateaus 
particularly interesting result algorithms maximum porcupine virtually fast maximum max 
certainly reinforcement learning algorithms able handle noisy reinforcement signals treat porcupine merely noise added underlying function happens max quickly discover climb 
general draw results functions functions property simple bitwise correlation reinforcement function sufficient discover maximum assuming statistics collected 
clearly plateaus function requires waiting longest right statistical pattern emerge bit group sample case reason algorithms take longer 
results table suggest part speedup provided choosing gamma form eligibility reinforce 
situations difference pronounced maximum rapidly 
conjecture due fact learning algorithms form eligibility different estimators underlying quantity gamma better small sample properties 
result noted table combination straight reinforcement comparison gamma form eligibility weight decay gave lowest average time find maximum team algorithms 
gamma form eligibility gave better average result node graph problem difference performance statistically significant standard deviation sets runs 
graph partitioning problems obviously provide real challenge algorithms strong tendency statistically avoid failing times getting stuck local maxima 
approach adopted try algorithms problems ackley algorithm converges detect convergence perform random restart 
speculate reason combining weight decay algorithms allows global maximum refusal allow weights grow certain point amounts continuing tendency engage random restarts coupled tendency climb hills statistically 
analysis runs involving weight decay reveal behavior loosely described exploration local maximum followed may amount jump neighborhood local maximum exploration peak eventually jump leads neighborhood global maximum 
experiments networks having nontrivial connectivity importance interconnections real value learning network generate trial points function optimized interconnections network enforce coordination choices output units order concentrate search suspected high payoff regions space 
occur output units direct influence hidden units serve command cells 
form coordination presence randomness certain parts network insures exploration occur interconnections insure randomness appropriate directions 
support process learning algorithm allow network retain information gained exploration process control desired coordination trials 
team approach information represented result correlations behaviors individual units reinforcement signal 
problems order correlations carry little information correct direction move higher order correlations helpful 
example graph partitioning problems investigated 
bit vector representing partition reinforcement value componentwise complement 
order correlations individual components outcome zero sample uniformly 
bits strongly committed value discover correlation choice value outcome 
network coordinate choices output units able generate certain combinations bits greater probability individual components selected independently 
particular graph partitioning hope units corresponding highly interconnected group nodes graph operation coordinated point come select high probability assignment subset nodes 
network operates way expect find solution hierarchical graphs type studied quickly coordination 
challenge course able represent higher order statistics points learning algorithm allows parameters controlling search distribution adjusted distribution comes capture regularities set points 
describe algorithm shows promise regard 
reinforce ment algorithms performed extensive simulations reinforce algorithms networks having nontrivial connectivity experiments demonstrated algorithms successful capturing regularities set output patterns leading high reinforcement network potentially capable representing regularities 
indication inability capture regularities converge single choice output output patterns lead maximum reinforcement value demonstrate 
result having nontrivial connectivity network diminish susceptibility convergence false optima reinforce 
led devise novel variant call reinforce ment algorithm 
combines reinforce approach entropy maximization 
entropy maximization designed help keep search alive preventing convergence single choice output especially choices lead roughly reinforcement value 
observations apply general situation reinforce algorithms may derived specialize case appropriate application network bernoulli logistic units having nonconstant external input 
denote number output units network 
tuple gamma ln jw jw gamma jw ln jw entropy output network particular input pattern weights run net input weights obtain output quantity unbiased estimate entropy 
establish key result 
th unit network denote vector weights incoming lines denote pattern input particular unit 
bernoulli logistic units inner product notation applies generally form internal computation unit 
random output value drawn discrete distribution having probability mass function jw suffix ment stands maximization entropy 
special case bernoulli logistic unit gamma result passing inner product logistic function equations 
lemma nu tuple th coordinate feedforward network stochastic units jw proof 
prove induction 
assume vector indexed integers way unit outputs correspond indices range way ij nonzero network feedforward necessarily exists indexing 
indexing value depends values denote vector denote vector 
clearly jw jw establish induction step assume jw 
jw jy jw induction step established 
lemma proved 
note result obvious team output values selected independently lemma shows holds generally 
follows immediately lemma gamma ln jw gamma ln network having hidden units quantity gamma ln easily computed unbiased estimate entropy output network function input 
example network consists bernoulli logistic units equation shows needed compute unit send central summation location ln output ln gamma output 
hidden units define similarly unbiased estimate entropy state network input turns useful 
stochastic hidden units serve command cells example unbiased estimate output entropy easy obtain involves summation possible states units computed readily quantities currently network 
purposes consider nonassociative case constant 
may suppress define function gamma ln jw network having hidden stochastic units gamma ln serves unbiased estimate output entropy particular trial actual output obtained trial 
restrict attention feedforward networks random unit output unit 
define simplex network maximally connected feedforward network having nonconstant input hidden units 
example simplex network 
network ordering units unit connection higher numbered units lower numbered units 
addition unit bias input 
insert 
term simplex describe network fact topological simplex defined combinatorially related fashion ordering property 
see relationship note example node simplex network laid form triangle node simplex network laid form tetrahedron 
reinforce ment algorithm optimizing function defined output patterns network having stochastic hidden units obtained reinforce algorithm reinforcement signal parameter algorithm computed equation 
bernoulli logistic units reinforcement comparison version algorithm 
trial weight ij incremented deltaw ij ff gamma gamma ff learning rate computed equation computed equation 
reinforce ment algorithm just reinforce algorithm reinforcement signal combines external reinforcement internal reinforcement intended reward variety 
internal contribution reinforcement expected value proportional entropy distribution output vectors produced reinforcement learning network 
effect network willing sacrifice performance achieve higher entropy enjoyed continuing explore 
importantly experiments demonstrate effect exploration network discovers number output patterns lead high reinforcement network weights attempt capture regularities points 
biases searching new points share regularities 
cases appropriate search hierarchical modular fashion network discover exploit organization search space assuming particular network architecture capable representing 
gain better understanding behavior algorithm consider case constant assume reinforcement comparison 
relatively point sampled weights adjusted point point high likelihood sampled weights adjusted point 
effect constant algorithm trades performance measured order entropy higher 
actual algorithm experiments results reported table slight modification equation units output values 
uniformity presentation discuss results units 
weight update algorithm version deltaw ij ff gamma gamma quantities equation 
led faster learning units 
order check speedup due simply fortuitous match representation particular problems studied ran experiments units alternative algorithms 
algorithm tried updates weights deltaw ij ff gamma gamma gamma algorithm seeks weights appropriate units weight changes input unit comes units 
algorithm tried updates bias equation updates weights deltaw ij ff gamma gamma gamma exponentially weighted trace past values conforms approach recommended sutton accelerate learning decorrelating learning biases learning weights 
algorithms pure reinforce ment units modifications just described units performed essentially faster pure reinforce ment applied units 
preliminary demonstrations explore effect adding entropy term ran reinforce reinforce ment problems involving unit simplex architecture 
experiment function optimized defined illustrated 
treating network reward disregarding added entropy term corresponds rewarding network units produce output 
reinforce network go deterministic converging single optimal choice output particular training run 
hand reinforce ment ff leads weights shown trials 
weights effect high payoff points generated probability close probability generating remaining points close zero 
insert 
second experiment function optimized defined illustrated 
network receives optimal reward output pattern having 
reinforce causes network converge optimal choices output particular training run 
hand reinforce ment ff leads weights shown trials 
weights effect high payoff points generated probability close probability generating close zero 
way works follows bias unit causes generate time time remaining weight bias cause second unit generate unit produces generate roughly equal probability unit produces 
insert 
appreciate significance results consider high dimensional optimization problem early search pair bit positions payoff viewed noisy function bit positions say problem 
early search approximately equally high payoff received match lower payoff received don 
algorithm reinforce essentially rule bits reason 
fact may reason may happen may turn better conjunction choices discovered search 
reinforce ment hand tries keep options open search 
point nicely illustrated weights obtained second experiment 
note team bias decay amounts alternative way incorporate force increased entropy learning algorithm 
essential difference bias decay reinforce ment applied team weight changes prescribed reinforce ment particular trial depend actual behavior network trial weight decay 
average effect 
imagine weight decay reasonable alternative reinforce ment algorithm interconnected network just team network 
clear bias unit network decay zero unit produce roughly equal probability allow points generated equal probability 
results optimization problems insert table 
summary results experiments performed reinforce ment simplex architecture optimization problems included table 
parameter fixed problems variation learning rate ff explored 
team algorithms table shows problem particular value learning rate runs algorithm problem rounded mean run length number function evaluations reach global optimum set runs 
case mean runs algorithm problem combination 
problems interesting note reinforce ment perform team algorithms problems easily outperformed best hierarchical graph partitioning problems 
team algorithms performed essentially porcupine max 
team algorithms performed better max max 
believe reason result may related strengths problems hierarchical graph partitioning problems 
fact local optima max problem may give algorithm better chance finding global maximum learns exploring false peak generalizes readily global peak particular may learning making bits identical 
observations regarded purely speculative analyzed detail performance simplex network reinforce ment problems chosen concentrate performance hierarchical graph partitioning problems provided main motivation devising place 
reason may inferior team algorithms simpler problems simplex network having units weights team network having number units weights 
team tries fit parameter distribution current view high payoff parts space problems corresponding simplex network tries fit parameter distribution data 
network having weights sense rule hypotheses high payoff points seen far common 
hierarchical graph partitioning problems shown table reinforce ment simplex architecture able find global maxima mlc problem average just function evaluations able find global maxima mlc problem average just function evaluations 
gain insight performance reinforce ment multilevel hypercube graph problems performed detailed analysis behavior course seeking solution 
follows illustrate aspects behavior analyzed reinforce ment simplex network contrasting corresponding behavior reinforce bias decay team network algorithm architecture combination successfully solved problems experiments 
intent simply demonstrate combination appear conduct search manner appropriate type problem contrast techniques able eventually find solution 
way determine algorithm exploring space truly finding regularities shared points giving relatively high payoff see generates finding global maximum broader context finding point sense 
particular equally solutions problems terminate run network continue generate trial points see long take solution 
result mlc runs average additional function evaluations required second optimal point generated 
average solutions function evaluations 
mlc took average additional function evaluations find second optimal solution solutions function evaluations average 
try team algorithms incorporating weight decay doubt take long certainly longer takes find optimal solution 
team obviously represent necessary regularities problems 
shows plot value function trial number typical run reinforce ment mlc problem 
note value global optimum mlc graph partitioned edge cuts 
plot shows global optimum near trial number 
shows subsequent trials led generation global optima points generated increasing frequency 
furthermore plot show points generated trial turns optimal points generated numerous times run 
insert 
comparison shows corresponding plot behavior run team reinforce bias decay problem 
particular run atypical sense global optimum sooner average note architectures algorithms comparisons combined ways 
combinations may capable solving graph partitioning problems experiment clear properties describe 
representational limitation team architecture obviously affected algorithm noted earlier bias decay weight decay reinforce necessarily help identify appropriate regularities 
case trial number trial number illustrate behavior comparable time interval 
results reinforce ment simplex network algorithm architecture combination lead frequent generation high payoff points 
furthermore optimum points generated 
insert 
order examine simplex network reinforce ment learns represent regularities high payoff points explores studied distribution points generated weight matrix evolved single runs mlc problem 
essence solving problem discovering highly connected node clumps graph concentrated examining represent exploit information 
examination weights evolved shows network generates optimal point clump weights take positive values weights stay closer zero general 
allows exploration proceed way clumps freely placed side partition represents appropriate strategy dealing graphs effectively reducing size search space dimensions dimensions mlc 
believe success reinforce ment problems rests roughly characterized ability find experiment placement clumps corresponding strategy known graph partitioning algorithm kernighan lin 
detailed understanding search behavior weights easy 
weights tend relatively small magnitudes unit simplex network experiments unit simplex network th unit receives input sources 
examined distribution output values selected network clump individual runs 
particular plotted histograms clump showing number generated clump periods consisting consecutive function evaluations 
shows subset histograms generated run reinforce ment 
histograms trials show approximately bell shape appropriate sum bernoulli random variables case weights initialized 
histograms trials begun flatten indicating preference cases 
remaining histograms show tendency continues sampling done final trials run terminated trials network evolved strong preference having values clump preference 
run search evolves way clump coordination 
short network discovers significance clumps allows exploration proceed clump level manipulations 
insert 
comparison shows corresponding histograms run team reinforce bias decay depicted 
histograms approximately bell shape appropriate sum bernoulli random variables regardless far run proceeded team network coordinate behaviors individual units 
histograms final function evaluations show network fairly strong preference having units corresponding nodes clumps side output having units output 
network captured regularities characteristic wide range high payoff points 
insert 
note omitted mention precise mapping nodes graph units simplex network discussion 
obvious symmetry members team network definite ordering computation performed simplex network 
leads possibility assigning different problem representation roles individual units network lead different results performing search optimum 
investigated graph partitioning problems running number trials mapping graph nodes network units mediated randomly generated permutations 
virtually difference results 
interesting result observed reinforce ment simplex network find solutions graph partitioning problems rapidly average algorithm tried consistent ability find solutions relatively quickly 
algorithm standard deviation length time find global maximum runs mlc mlc 
contrast standard deviations team reinforce weight decay mlc mlc version gamma eligibility standard deviations mlc mlc 
longest time run simplex network reinforce ment mlc mlc longest times successful team algorithms range tasks 
discussion described results applying number variants reinforce algorithms optimization problems studied ackley 
algorithms include team algorithms novel network algorithm derived incorporates entropy maximization strategy 
relatively performance simple single bit correlation team algorithms problems surprising may indication particular problems challenging hoped 
point function studied ackley called trap function algorithms discussed successful finding global maximum 
function essentially version max larger proportion space leads uphill false peak 
ackley studies algorithm successful solving type problem simple hillclimber restarted reaching peak 
useful exploration performed iterated hillclimber really restarts begins right region succeed 
algorithms studied algorithms investigated involve amount global sampling prevents necessarily myopic point view necessary succeed tasks 
interesting note difficult function created adding porcupine entire space just vicinity global peak leading function iterated hillclimber find essentially impossible optimize 
aspect relation ackley point careful uniform parameter settings algorithm experiments 
obviously fair way optimize black box function 
contrast parameters algorithms results reported fixed problems 
particular parameter learning rate varied problems cases results reported involve relatively little variation parameter problems fixed algorithm 
able claim algorithms truly useful black box optimization algorithms need conduct studies fixed value learning rate alternatively imagine adding meta level adaptation designed determine useful settings usually experimenter controlled parameter settings 
interesting potential application lemma take advantage studies avoid extensive monte carlo simulations directly computing probability network having random units output units produce particular output 
pattern generated network ackley algorithm find global peak special case global false peak bitwise complementary points distribution trial points biased favor symmetry general placement peaks failed non 
produces global optimum function useful know happened fluke destined happen soon anyway test network pattern having wait generated 
simply loading pattern actual output generated performing computation values determine lemma probability network generated pattern 
described part interested investigating dealing reinforce ment algorithm 
aspects reinforce ment explored 
helpful limited cases random units output units interesting version devised allows symmetrical interactions units involving asynchronous update strategy type settling behavior 
investigated detail appears reinforcement learning algorithm boltzmann machine described hinton way symmetrical interactions interesting find require complete annealing process just generate single trial point 
generally worthwhile understand relation reinforce ment approach approaches incorporate entropy formulation simulated annealing 
clearly essentially temperature parameter 
initial investigation question led suspect important similarities useful exploit appear differences 
differences significant merely superficial await analysis 
interesting extension reinforce ment approach begun explore possible applicability associative reinforcement learning input network constant 
case adding external reinforcement entropy entire state network function input computed equation intuitively reasonable 
idea entropy best optimized finding set internal representations viewed patterns activity hidden units potentially job required particular input committing prematurely particular 
studied algorithm hidden unit xor task bernoulli logistic units succeeds 
external reinforcement task output correct 
form reinforcement leads failure statistically gradient pure reinforce algorithm presence attractive local maxima sophisticated reinforcement functions devised allow pure reinforce solve xor problem 
algorithm succeeds tasks success failure reinforcement signal associative reward penalty ar gammap algorithm barto anderson 
preliminary studies comparing behavior reinforce ment ar gammap task show reinforce ment may somewhat slower probably incorporate absolute standard reinforcement ar gammap 
ackley 

stochastic iterated genetic hillclimbing 
ph dissertation dept computer science carnegie mellon university pittsburgh pa available connectionist machine genetic hillclimbing 
norwell ma kluwer 
barto 

learning statistical cooperation self interested neuron computing elements 
human neurobiology 
barto anandan 

pattern recognizing stochastic learning automata 
ieee transactions systems man cybernetics 
barto anderson 

structural learning connectionist systems 
proceedings seventh annual conference cognitive science society 
barto sutton anderson 

neuronlike elements solve difficult learning control problems 
ieee transactions systems man cybernetics 
garey johnson 

computers intractability guide theory np completeness 
san francisco freeman 
goldberg holland 
eds 

special issue genetic algorithms machine learning nos 

hinton 

connectionist learning procedures 
artificial intelligence 
holland 

adaptation natural artificial systems 
ann arbor university michigan press 
hopfield tank 

neural computation decisions optimization problems 
biological cybernetics 
kernighan lin 

efficient heuristic technique partitioning graphs 
bell systems technical journal 
kirkpatrick gelatt vecchi 

optimization simulated annealing 
science 
munro 

dual back propagation scheme scalar reward learning 
proceedings ninth annual conference cognitive science society 
narendra 

learning automata 
englewood cliffs nj prentice hall 
sutton 

temporal credit assignment reinforcement learning 
ph dissertation university massachusetts amherst coins technical report 
sutton 

learning predict methods temporal differences 
machine learning 
sutton 

normalized adaptive linear element learns efficiently technical report 
gte laboratories waltham ma 
sutton 

learning world models connectionist networks 
proceedings seventh annual conference cognitive science society 
williams 

reinforcement learning connectionist networks mathematical analysis technical report 
university california san diego institute cognitive science 
williams 

class gradient estimating algorithms reinforcement learning neural networks 
proceedings annual international conference neural networks ii pp 

williams 

theory reinforcement learning connectionist systems technical report nu ccs 
northeastern university boston ma 
williams peng 

reinforcement learning algorithms function optimizers 
proceedings international joint conference neural networks washington dc vol 
ii 
algorithm architecture reinforcement weight factor eligibility decay team gamma gamma team gamma gamma fi gamma team gamma gamma team gamma gamma team gamma gamma fi gamma team gamma gamma simplex reinforce ment best ackley task optimization task max max porcupine plateaus mlc mlc ff time ff time ff time ff time ff time ff time table summary simulation results optimization problems 
hierarchically structured graph mlc 
hierarchically structured graph mlc 
unit team network 
unit output unit adjustable weights biases treated weights connections indicated arrows 
presynaptic signal connections constant 
unit simplex network 
unit output unit 
adjustable weights biases treated weights connections indicated arrows 
presynaptic signal connections constant 
unit simplex network optimization problem learned solve reinforce ment algorithm 
ideally bias unit bias second unit half magnitude weight units 
unit simplex network optimization problem learned solve reinforce ment algorithm 
ideally bias unit ln remaining weights equal magnitude 
plot function trial number typical run reinforce ment simplex architecture facing mlc graph partitioning problem 
plot function trial number run reinforce bias decay team architecture facing mlc graph partitioning problem 
histograms showing number generated mlc clumps specific trial periods typical run reinforce ment simplex architecture 
clumps ordered placed optimal partition 
histograms showing number generated mlc clumps specific trial periods run reinforce plus weight decay team architecture 
clumps ordered placed optimal partition 
solution experiment clearly assigns node clumps side partition remaining nodes side 
