learning bottlenecks evolution recursive syntax simon kirby december human language unique natural communication system reasons 
firstly mapping meanings signals language structural properties animal communication systems 
particular syntax gives ability produce infinite range expressions dual tools compositionality recursion 
compositionality defined property meaning expression monotonic function meaning parts way put 
recursion phenomenon constituent sentence dominates instance syntactic category 
recursion principle reason number sentences natural language normally taken infinite 
recursion compositionality reason infinite set sentences express different meanings 
secondly content mapping learned children observation language 
true animal communication see review oliphant volume 
chapter formally investigate interaction unique properties human language way learned syntactic structure 
evolution natural selection evolutionary linguistics currently growing field research tackling origins human language pinker bloom hurford 
particular interest researchers origins syntactic structure 
dominant approach evolution structure pinker bloom suggest best way view human language biological adaptation evolved response need communicate propositional structures serial interface 
linguists view syntax fully specified innate genetically determined language acquisition device lad research chapter carried language evolution computation research unit department linguistics university edinburgh funded 
jim hurford mike oliphant ted briscoe robert worden useful discussions relating material necessarily agree content 
author email home page simon ling ed ac uk www ling ed ac uk simon 
significantly constrains language learner prior knowledge nature language 
evolutionary theory offers clear criteria trait attributed natural selection complex design function absence alternative processes capable explaining complexity 
human language meets criteria 
pinker bloom chapter agree structure human learning mechanism bring particular prior biases bear acquisition task 
theoretical reasons case learner generalise mitchell 
language unique biological terms search carefully alternative processes turning natural selection explanation 
fact chapter continuation batali kirby kirby hurford batali volume hurford volume suggested complex structure language may result quite different process biological evolution 
shows learning influences dynamic process language transmission historically generation 
ways approach mirrored linguists quite different research perspectives niyogi berwick niyogi berwick christiansen devlin briscoe 
chapter aims demonstrate reasonable learning bias basic structural properties language recursion compositionality inevitably emerge time complex dynamical process social transmission words built highly constraining innate language acquisition device 
computational approach understand ways learned socially transmitted system language evolve need sophisticated models learners embedded dynamic context 
verbal behaviour complex dynamical systems 
niyogi berwick point intuitions evolution simple dynamical systems wrong 
researchers responded problem computational perspective hurford hurford batali oliphant cangelosi parisi steels kirby hurford briscoe 
methodology provides third way verbal hand analytical mathematical approaches tend prove difficult formulate types system 
chapter follows line research developing working computational simulation individuals capable learning communicate observing behaviour tracking development artificial languages emerge population 
rest chapter divided main sections 
firstly computational model described detail particular attention paid process learning details left appendix 
section deals representative experiments model dealing emergence compositionality simple semantics emergence recursive subordinate clauses complex semantic space 
explanation behaviour simulation theoretical terms discussion impact results linguistic theory 
production production acquisition language language time language language transmission language time 
working model linguistic transmission language exists different domains chomsky hurford kirby language internal language represented brains population 
language user knowledge language 
language external language exists utterances arena hurford 
domains language influence profound ways process linguistic transmission diagrammed 
language product language speakers 
language language learners product language access 
model constraints domains transformations map sufficient determine dynamical properties linguistic transmission 
computational simulation linguistic transmission works framework shown elaboration model 
simulation implements processes 
individual simulation set meanings expressed 
meanings thought provided external world simulation simply chosen randomly predefined set 

individual attempts express meaning internalised knowledge language random process invention 

new learner takes set utterances uses input learning 

learner new speaker old speaker discarded new individual added new learner cycle repeats 
utterances individuals produce learn simulations pairs strings letters thought basic phonemic segments predefined space possible meanings set utterance grammar zero learner adult learner infant learner adult grammar grammar meaning set meaning set production acquisition production utterance set computational implementation linguistic transmission 
meaning representations 
simulations world set predefined atomic concepts 
include john tiger eats fears knows concepts combined simple predicate argument propositions may hierarchical structure 
example fears john tiger knows john eats tiger john example utterance individual simulation happened know english pair eats tiger john obviously biggest component simulation part takes sets pairs able learn useful way words part simulation takes instances language maps language 
subject section 
learning simulations chapter model generations speakers design learning algorithm crucial 
important criteria learning algorithm efficiency simulations need model thousands learners time ease analysis interested language evolves time important able easily inspect internal states learners 
algorithm designed specifically simulation tasks mind extremely simple efficient enables internal states learners easily analysed 
claims efficacy practical grammar induction tool model simple way dual processes rote learning examples induction generalisations core model language acquisition 
grammatical representation simulations hypothesis space learning algorithm searches consists context free grammars enriched kind simple semantics described 
important realise internal knowledge individuals type context free grammar mean compositionality recursion built 
consider learner produce string meaning eats tiger john 
possible grammars learner internalised eats tiger john eats eats tiger tiger john john symbol grammars start symbol arbitrarily named non terminals 
lower case letters shorthand expand atomic phonemic segments 
material slashes attached non terminals semantic representation non terminal 
grammar left simplest grammar produce utterance 
basically states valid sentence meaning eats tiger john 
notice entirely non compositional way meaning function meanings parts 
fact string broken analysed simply treated holistic chunk 
grammar right compositional 
sub parts string assigned meanings 
example tiger corresponds meaning tiger 
string composed piecing substrings combining meanings variables clear example grammatical formalism obviously allows represent languages structured syntactically constrain languages form 
words space languages learners access includes considered possible human languages respects algorithm simplification development described kirby kirby 
formally semantic structures take forms 
fully specified form semantic structure variables 
partially specified form semantic structure variables 
variables may occur top level 
variable left hand side semantics take forms grammar right hand side semantics variables formalism 
example non compositional 
choice formalism build result looking 
rule subsumption stage learning grammar contains rules 
data inducer pairing string terminals semantic structure 
single pair incorporated grammar trivially 
say pair eats tiger incorporated 
simplest rule covers fact language induced eats tiger trivial learning algorithm involve gathering language facts string meaning pair storing big grammar 
give grammar generate exactly sentences input 
add simple refinement technique deleting duplicate rules grammar 
fact basic operations incorporation duplicate deletion core final induction algorithm simulation 
problem just operations inducer power generalise 
poor model learning 
basic strategy extracting generalisations rules overly specific similar ways general method inductive logic programming see discussion citations mitchell take pairs rules look general generalisation subsumes prespecified constraints 
example imagine grammar rules eats tiger eats john general rule subsume 
firstly need replace tiger john semantics variable 
left hand side eats 
means need nonterminal attached right hand side rule 
replace tiger john right hand sides single new category call new rule eats delete original rules subsumes 
problem 
introduced new nonterminal rule saying stage induction generalisation ensure new grammar parse sentences parse previously 
add new rules tiger tiger john john commonly applied subsumption method induction algorithm 
example rules mary mary mary mary rule subsumes simply choose non terminal category symbols say chooses replace keep induction rewrite occurrences grammar induction algorithm proceeds utterance incorporating simplest possible rule generates utterance directly searches pairs rules grammar possible subsumptions ones described generalisations deletes duplicate rules left 
details algorithms rule subsumption constraints application appendix chapter 
invention particular meanings sentences speakers produce controlled experimenter 
space possible meanings thought population world model words want talk 
way think world speaker try produce string certain meaning 
means guarantee speaker way generating string meaning compelled produce 
especially true early stages simulation run initial population initialised grammatical knowledge 
way speakers produce strings absence grammar generate language get ground 
important model individual enriched allow invention 
invention process essentially mechanism introducing random new words chunks meaning build new syntactic structure 
words assume individuals able invent strings sounds able spontaneously invent hierarchical structure observed 
invention algorithm meaning speaker way producing tries find closest meaning speaker way producing 
new meaning string parse tree string generated 
parse tree show parts string correspond wrong parts meaning words parts near meaning different meaning produced 
parts string excised replaced random sequence symbols 
speaker induction algorithm hears invented string meaning pair ensures speaker output consistent 
example clearer 
imagine speaker grammar loves john mary mary jane jane general chooses matter case start category start category changed 
simulation runs sequence varies letters randomly chosen alphabet 
speaker asked produce string meaning loves john anna 
nearest meanings speaker produce strings loves john mary loves john jane 
ll pick produces tree structure loves john mary mary mary wrong part tree material dominated node introduces meaning mary 
delete string mary replace random sequence characters 
invented string meaning loves john anna 
second example demonstrates important property algorithm avoids novel structure 
ll grammar try invent string meaning loves fred mary 
nearest meaning grammar loves john mary generates tree 
time wrong bit meaning john dominates string 
invented string loves fred mary 
summary simulation cycle general simulation contain population number individuals keep things simple experiments described individuals time adult speaker new learner 
start simulation run speaker learner grammar words knowledge language 
means language observed simulation purely emergent interactions individuals simulation 
generation simulation goes steps 
speaker tries produce set utterances form input learner 
involves repeating sequence actions number times set experimenter speaker meaning chosen random predefined set 
speaker able generate string meaning grammar invents string 
speaker invented string speaker uses string meaning pair input induction 
means individual invents new way saying learn invention need arises 
learner string tries parse grammar 
unable parse string takes string meaning pair uses input induction 
generation deterministic 
grammar allows way producing certain string way 
random 

speaker grammar logged deleted simulation 

learner new speaker new learner blank grammar added simulation 
main parameters experimenter vary model number utterances speaker called produce lifetime structure size meaning space 
discussion section chapter see parameters bear interesting way 
example experiments section describes detail experiments demonstrate interesting linguistic structure emerges time cycle acquisition 
experiment run times differing initial random number seeds 
case similar results achieved specific details languages emerged differ trivial ways 
degree compositionality simulation run experiment properties languages emerge individuals communicate simple meanings 
meaning space simple degree place predicates predicates embedding world possible objects possible actions 
example meanings likes gavin mary loves mary john hates heather pete 
ease coding arguments predicates distinct words loves john john allowed 
speaker produces utterances lifetime chosen random space place predicates 
means meanings carefully chosen picked random learners exposed entire range possible meanings 
typical generation grammar nonterminals start nonterminal arbitrarily chosen capital letters generation john gavin hates heather mary loves mary pete admires john mary pete john likes heather gavin loves john mary loves pete john vcs likes john pete os loves heather gavin likes mary gavin ke admires john gavin hy admires pete heather dx admires gavin pete likes heather mary heather john john pete fu mary gavin hates gavin john likes gavin john admires gavin mary hates heather gavin hates pete mary likes gavin pete qi admires gavin john john mary heather pete pete mary sm loves heather john hates john heather xf loves mary gavin admires gavin heather yn hates heather pete admires john mary lg pete nv grammar speaker life 
reason speaker grammar fact utterance invents uses induction 
grammar essentially idiosyncratic vocabulary random subset meaning space 
example speaker sentence corresponding english gavin hates john sentence gavin likes john completely unrelated non compositional non syntactically structured communication system 
notice chance similarity sentences flg meaning admires mary john meaning admires pete john lead creation category mary pete 
simulation grammars generation hates pete john john likes gavin pete lw hates heather john mary pete gavin dx admires heather mary hhi likes mary pete heather hates gavin mary rw gavin john hates heather gavin hates mary rs hates heather pete kw likes heather gavin loves likes admires gavin mary ni john heather pete loves hates likes pete gavin yo heather john heather kr gavin hates rp hates admires productive generalisations 
example words category different contexts 
category fact covers objects semantic space objects exclusively expressed way 
example different contexts heather expressed kr turning time forward get highly regular grammars generation gavin mary ni pete re john loves hates admires srw likes heather pete mary ns gavin yo john category clearly thought verb 
nominal categories giving types expression objects semantic space shown table meaning type category type category mary ns ni pete re gavin yo john heather sentence rules 
sentence rule gives language object nouns type subject nouns type 
sentence rule word order 
interestingly types noun switched roles object nouns type subject nouns type 
form language fairly stable losing type form gavin remaining thousands generations 
eventually language goes rapid complex series changes form type noun generation gavin gw john gbb pete heather mary pd hates loves admires srw likes result fairly typical simulation run started different random number seeds 
language population evolves idiosyncratic vocabulary complex meanings completely compositional syntax nominal verbal categories 
main variation runs quickly coverage basic categories complete 
idiosyncratic sentence rule particular action particular object survives long time occasionally optionality word order emerges appears stable 
infinite language finite means simulation previous section finite meaning space actions objects 
translates possible meanings predicates possible st arguments possible nd arguments 
step expand meaning space infinite range meanings may expressed 
include predicates may take predicates arguments 
simulation run embedding predicates know say speaker tries produce degree meanings tries produce degree meanings degree meanings 
generation grammars simulation starting parameters large rules times utterances produced 
small subset typical generation grammar new set conditions generation pete heather hits john mary admires heather pete hates gavin mary qv says gavin hates john mary ira says mary admires gavin mary believes heather gavin mary uic decides heather hits heather gavin says mary pete gavin te decides heather hits gavin john says john hits mary pete says gavin admires mary heather zv knows gavin loves pete heather believes john heather mary ei says mary loves heather gavin recall arguments predicate 
notice presentation scheme simulates starting small learning paradigm elman kirby hurford 
thinks gavin loves gavin mary decides heather hates heather pete vi believes gavin hates heather john lay decides john admires heather john jj says heather hits gavin john decides john mary pete decides heather hits john mary heather pete knows gavin admires mary gavin ws says mary thinks mary john gavin bx thinks pete thinks john admires pete heather gv believes pete thinks john hates john heather bc believes gavin thinks gavin hates heather pete im believes pete decides gavin hates pete heather lsq decides heather believes heather admires mary pete admires mary heather knows pete knows john loves john mary 
firstly notice vocabulary obviously includes complex meanings says mary thinks mary john gavin english mary says thinks john gavin 
simulation runs inducer done 
similarity sentences meaning knows pete admires mary heather mmd meaning knows pete knows john loves john mary lead creation category admires mary heather knows john loves john mary 
grammars simulation rapidly increase size complexity peaking mid terms number rules quickly able express full range degree meanings regular sentence rules emerged simulation runs previous section 
time grammars typically reduce dramatically size generation gp loves admires hates likes btl pete heather gavin eks mary john says decides believes knows thinks sentence rules grammar categories 
second sentence rule similar ones saw previous section allowing language express full range degree sentences 
category verbal category nominal category 
language vos order main clauses 
sentence rule allows language express meanings greater degree 
introduces category verbs subordinating function meaning says crucially category right hand side 
means language recursive allowing build infinite range meanings 
tree shows particular language copes complex meanings 
displays parse sentence translated english means pete knows john loves mary 
language simulation evolved simply learned repeatedly individuals population 
initially random idiosyncratic non compositional gp knows pete loves mary john loves john mary knows pete loves mary john meaning pete knows john loves mary 
relatively communication system compact compositional language nominal verbal categories word order encoding meaning distinctions recursive subordinate clauses allowing speakers express infinite range meanings 
obvious question 
bottlenecks universal grammar individuals simulation simply observe behaviour learn occasionally inventing random new behaviours 
apparent randomness organisation emerges 
little built simulation compositional recursive syntax inevitable 
answer question need look back languages persist time population 
divide language units replicators may may persist time 
persistence language view related success replicators language 
words languages easily transmitted generation generation persist 
population certain replicators compete survival 
success measured relative success population time 
competing replicators rules potentially express meaning 
ways saying john loves mary particular exposure meaning learner obviously hear 
exposure rules properly set rules express john loves mary chance induced learner 
face value competing rules rule sets equal chance chosen producing meaning success rules language equal 
true rule expressed meaning 
rule express meanings things equal rule greater chance expressed language language language bottleneck language domain acts bottleneck transmission language 
language input learner 
case general rule better replicator 
concrete example consider situation population languages competing rules 
rule expresses john loves mary unanalysed string symbols essentially word 
rule expresses john loves mary string symbols express meaning loves mary 
rule express gavin loves mary 
imagine rules equal chance express john loves mary 
general rule better replicator randomly chosen set meanings expect idiosyncratic rule 
chances survival generation far secure idiosyncratic rule 
course general rule learned easily idiosyncratic rule 
simulations described idiosyncratic pairing meaning form takes exposure learn general rule takes 
idiosyncratic rule covers meaning general rule covers infinite number 
clear probability acquiring particular rule random sample meanings increases generality rule 
success contain general rules secure 
picture emerges language population acting adaptive system right 
initially rules minimally general pairing string meaning 
point chance invention lead learner go data making generalisation previous generation 
generalisation compete idiosyncratic rule meaning 
generalisations better replicators idiosyncratic rules pushed time 
competition replayed generalisations general rules surviving 
notice picture move holistic emergent syntactic system similar proposed wray 
inevitable state process language syntax supports compositionally derived semantics highly regular fashion 
grammar language appears shortest terms numbers rules express entire meaning space 
shorter grammar higher generality rules shortest grammar job expressing meanings optimal replicators 
lld lad venn diagrams showing different approaches explaining observed constraints cross linguistic variation 
set logically possible languages gray area signifies set occurring human languages 
top diagram language acquisition device constrains learner directly required explain limits variation 
bottom diagram language learning device constraining particular characteristics human languages result historical evolution languages populations represented arrows 
think transformations language bottleneck transmission language time see 
number meanings learners exposed lower total number meanings totally idiosyncratic language survive 
compositional recursive languages logically possible languages pass bottleneck unchanged 
start chapter approach taken contrasted dominant approach evolutionary linguistics structure language taken match closely structure language faculty turn shaped natural selection 
precisely unpack differences perspectives origins syntax 
particular relationship model constraints cross linguistic variation quite different 
traditionally language acquisition device lad directly constrains possible human language limiting directly acquired 
limit said closely map observed constraints variation 
part generative research program involves accounting variation languages explicitly model language 
fact universal grammar ug lad treated synonymous tradition 
generally considered dynamics language acquisition impose constraints boundaries imposed structure lad see niyogi berwick clark interesting exceptions 
contrasts view proposed 
language learning device clearly impose constraints directly similar fashion certain types language learner simply acquire constraints far severe imposed lad 
seen initial stages simulation un language systems acquired learner 
constraints variation built learner emergent properties social dynamics learned communication systems structure semantic space individuals wish express 
theory gives neat explanation human languages syntactic structure compositionally derive semantics recursive subordination express infinite distinctions digital way words major syntactic categories noun verb structural relations word order encode meaning distinctions 
allow understand specific universals 
example particular constituent orders far frequent languages world hawkins dryer 
best explanation types universal look effect parsing generation transmission replicators see kirby kirby details 
hand word order constraints may eventually explained terms linguistic adaptation appealing processing see christiansen christiansen devlin suggestions lines 
bar theory sub part ug constrains structure syntactic trees cross jackendoff implicated various word order universals 
daniel suggests bar just sort generalisation theory put forward chapter predicts 
characterised pair phrase structure rules xp spec xp spec rules standard context free rules variables range lexical categories language 
variables phrase structure rules possible formalism adopted result possible simulation 
language learning device able generalisation expressed bar expect thrive replicator 
generally expect languages behave way word orders expressed compact way reflect behaviour optimal general replicator 
dryer shows large scale cross linguistic survey case languages tend order non branching nodes side branching nodes phrasal categories language 
compositionality recursion arguably basic features syntax language 
structural properties way transmitted human language unique natural communication system 
language survive generation generation learned individuals observing behaviour individuals 
sample observations finite range meanings individuals may wish communicate large infinite 
simulations shown things 
languages transmitted time observational learning evolve 

language survive syntactic 
internal structure 
complex meanings structure compositional recursive 

compositional recursive languages achievable states cultural evolution language start state language 
set requirements syntactically communicating organism drawn 
expect model described syntax emerge population organisms ffl hierarchical internal representations ffl need communicate representations ffl ability time able guess representations speaker ffl ability generalisations observed instances 
remains topic research extent humans fulfill list requirements animals 
conclude order explain origins syntax need appeal ffl single mutation gradual biological change selective fitness due giving syntax ffl mechanism specifically communicative function language directly impacts evolution 
batali john 

innate biases critical periods combining evolution learning acquisition syntax 
artificial life iv ed 
rodney brooks pattie maes 
mit press 

computational simulations emergence grammar 
approaches evolution language social cognitive bases ed 
james hurford chris knight michael kennedy cambridge 
cambridge university press 
derek 

language species 
university chicago press 
briscoe ted 
language acquisition hypothesis baldwin effect 
ms computer laboratory university cambridge 
cangelosi angelo domenico parisi 

emergence language evolving population neural networks 
technical report national research council rome 


formal semantics 
cambridge cambridge university press 
chomsky noam 

knowledge language 
praeger 
christiansen morten 
infinite languages finite minds connectionism learning linguistic structure 
university edinburgh dissertation 
joseph devlin 

recursive inconsistencies hard learn connectionist perspective universal word order correlations 
proceedings th annual cognitive science society conference 
mahwah nj lawrence erlbaum associates 
clark robert 
internal external factors affecting language change computational model 
master thesis university edinburgh 
dryer matthew 

word order correlations 
language 
elman jeffrey 
learning development neural networks importance starting small 
cognition 
hawkins john 
word order universals 
academic press 
jan 

hypothesis 
explaining language universals ed 
john hawkins 
blackwell 
hurford james 

language number emergence cognitive system 
cambridge ma basil blackwell 

biological evolution sign component language acquisition device 
lingua 

evolution critical period language acquisition 
cognition 

social transmission favours linguistic generalisation 
evolution language volume arising second international conference evolution language ed 
chris knight james hurford michael kennedy 
appear 
chris knight michael kennedy eds 

approaches evolution language social cognitive bases cambridge 
cambridge university press 
jackendoff 
syntax study phrase structure 
mit press 
kirby simon 

competing motivations emergence explaining implicational hierarchies 
language typology 

function selection emergence language universals 
oxford oxford university press 
press 

language evolution natural selection vocabulary syntax population learners 
technical report department linguistics university edinburgh 

syntax natural selection compositionality emerges vocabulary population learners 
evolution language volume arising second international conference evolution language ed 
chris knight james hurford michael kennedy 
appear 
james hurford 

evolution incremental learning language development critical periods 
occasional department linguistics university edinburgh edinburgh 
james hurford 

learning culture evolution origin linguistic constraints 
fourth european conference artificial life 
mit press 
bruce 

synthetic ethology approach study communication 
artificial life ii ed 
langton taylor farmer 
addison wesley 
mitchell tom 
machine learning 
new york mc hill 
frederick 
functional explanation linguistics origins language 
language communication 
niyogi robert berwick 

logical problem language change 
technical report ai memo cbcl mit ai laboratory center biological computational learning department brain cognitive sciences 

populations learners case 
unpublished manuscript mit 
oliphant michael 

dilemma communication 
biosystems 
pinker steven paul bloom 

natural language natural selection 
behavioral brain sciences 
steels luc 

emergent adaptive lexicons 
proceedings simulation adaptive behavior conference ed 
maes 
cambridge ma mit press 

dictionary grammatical terms linguistics 
london routledge 
wray alison 

holistic system social interaction 
language communication 
details rule subsumption appendix gives thorough treatment rule subsumption approach introduced section 
algorithm uses methods subsumption merge rules category symbols merged merge categories 
words pick categories rewrite grammar 
chunk rules chunked sequence terminals chunk terminals 
chunking involves creating new rule substring nonterminals right hand side old rule adjusting old rule refer new 
whilst rule subsumption merging straightforward chunking difficult implement 
best describe procedure step step 
take pair rules grammar left hand side category symbol 
chunking applied rules 
left hand side semantics rules differ position 
call differences difference difference 
strings terminals removed right hand sides rules 
call string difference isn string difference go step 
create new category 
create new rules replace old rules rule 
rule identical replaced right hand side replaced variable left hand side 


chunking applied just rules 
left hand side semantics rules unified 

string terminals rules corresponds nonterminal label rule 
words difference rules right hand sides 

delete rule containing substring 
create new rule 

chunking procedure example section 
start rules eats tiger eats john left hand side category symbol 
check see chunking applied rules 
left hand side semantics differ position tiger john 
shortest pair strings terminals removed rules tiger john tiger john 
new category name convenience ll call 
new rules tiger tiger john john old rules replaced single general eats 
merging chunking inducer successfully discover new rules subsume pairs rules learnt simple incorporation 
practice useful add procedure induction algorithm rules general 
possible inducer tries simplify rules utilising rules grammar 
example pair rules loves john mary mary mary inducer simplify loves john 
