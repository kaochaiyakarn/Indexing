appears proceedings th international conference inductive logic programming springer verlag 
combining statistical relational methods learning hypertext domains se slattery mark craven school computer science carnegie mellon university pittsburgh pa usa mail cs cmu edu 
new approach learning hypertext classifiers combines statistical text learning method relational rule learner 
approach suited learning hypertext domains statistical component allows characterize text terms word frequencies relational component able describe neighboring documents related hyperlinks connect 
evaluate approach applying tasks involve learning definitions classes pages ii particular relations exist pairs pages iii locating particular class information internal structure pages 
experiments demonstrate new approach able learn accurate classifiers constituent methods 
years great deal interest applying machinelearning methods variety problems classifying extracting information text 
large part trend sparked explosive growth world wide web 
interesting aspect web thought graph pages nodes graph hyperlinks edges 
graph structure web interesting domain relational learning 
previous demonstrated web learning tasks relational learning algorithm learn accurate classifiers competing propositional approaches 
new approach learning hypertext classifiers combines statistical text learning method relational rule learner 
experiments evaluate particular instantiation general approach foil learner augmented ability invent predicates naive bayes text classifier 
experiments indicate approach able learn classifiers accurate purely statistical purely relational alternatives 
previous research web provided fertile domain variety machine learning tasks including learning assist users searches learning information extractors learning user interests 
research field involved propositional learners ii representing documents words occur 
approach motivated key properties hypertext documents pages related hyperlinks 
important sources evidence web learning tasks neighboring pages hyperlinks 
large feature sets needed represent content documents natural language involves large vocabularies 
typically text classifiers feature spaces hundreds thousands words 
uses relational learner approach able represent document relationships arbitrary parts hypertext graph learned definitions 
uses statistical learner feature selection method able learn accurate definitions domains large vocabularies 
algorithm designed hypertext mind believe applicable domains involve relational structure large feature sets 
section describe commonly bag words representation learning text classifiers 
describe representation naive bayes algorithm applied text learning problems 
describe relational learner foil bag words representation background relations describing connectivity pages hypertext learning tasks 
section describe new approach learning hypertext domains 
method naive bayes foil algorithms section 
section empirically evaluate algorithm types tasks learning definitions page classes learning definitions relations pages learning locate particular type information pages investigated part effort aimed developing methods automatically constructing knowledge bases extracting information web 
section provides discusses 
approaches hypertext learning section describe approaches learning text domains 
discuss naive bayes algorithm commonly text classification describe approach involves relational learning method foil tasks 
algorithms constituents hybrid algorithm section 
naive bayes text classification learning text classifiers involves representing documents bag words representation 
representation document described feature vector consisting feature word document 
features boolean indicating presence absence word continuous indicating measure frequency word 
key assumption bag words representation position word document matter encountering word machine document encountering 
common approach text classification naive bayes classifier bag words representation 
method classify document words wn set classes simply calculate arg max pr pr jc order word probability estimates pr jc robust respect infrequently encountered words common smoothing method calculate 
smoothing technique laplace estimates pr jc number times word appears training set examples class total number words training set class total number unique words corpus 
addition position independence assumption implicit bag representation naive bayes assumption occurrence word document independent words document 
clearly assumption hold real text documents 
practice naive bayes classifiers perform quite 
document corpora typically vocabularies thousands words common text learning type feature selection method 
frequently methods include dropping un informative words occur list ii dropping words occur fewer specified number times training set iii ranking words measure mutual information class variable dropping low ranked words iv stemming 
stemming refers process heuristically reducing words root form 
example words compute computers computing stemmed root comput 
employing feature selection methods common feature sets consisting hundreds thousands words 
relational text learning propositional relational symbolic rule learners text learning tasks 
argue relational learners especially appealing learning hypertext domains enable learned classifiers represent relationships documents information occurrence words documents 
previous demonstrated ability enables relational methods learn accurate classifiers propositional methods cases 
section experiments apply foil hypertext learning tasks 
problem representation relational learning tasks consists background relations link hyperlink page page relation represents web hyperlinks 
hyperlink argument specifies identifier hyperlink second argument specifies page hyperlink located third argument indicates page hyperlink points 
word page set relations indicates words occur page 
predicate word vocabulary instance indicates occurrence word specified page 
anchor word hyperlink set relations indicates words anchor underlined text hyperlink 
neighborhood word hyperlink set relations indicates words neighborhood hyperlink 
neighborhood hyperlink includes words single paragraph list item table entry title heading hyperlink contained 
words capitalized hyperlink instances relation hyperlinks words anchor text start capital letter 
alphanumeric word hyperlink instances relation hyperlinks contain word alphabetic numeric characters teach cs 
representation hypertext enables learner construct definitions describe graph structure web link relation word occurrences pages hyperlinks 
word anchor word neighborhood word predicates provide bag words representation pages hyperlinks 
note theory constants represent words doing require relational learner foil add literals clause word test representation 
combining statistical relational approaches section approach combines statistical text learner relational learner 
argue algorithm suited hypertext learning tasks 
conventional bag words text classifier algorithm able learn predicates characterize pages hyperlinks word statistics 
relational learning method able represent graph structure web represent word statistics neighboring pages hyperlinks 
described previous section conventional relational learning algorithm foil employ bag words representation learning hypertext domains 
hypothesize algorithm properties better suited tasks ordinary relational method input uncovered positive examples negative examples gamma target relation background relations 
initialize clause xk true 

gamma 
contains negative tuples complex 
call predicate invention method get new candidate literals 
select literal background invented predicates add 
update tuple set represent variable bindings updated 
invented predicate 
selected retain background relation return learned clause fig 

inner loop foil pilfs 
essentially inner loop foil augmented predicate invention procedure 
characterizes pages hyperlinks statistical method learned rules dependent presence absence specific key words conventional relational method 
statistical classifiers learned rules consider weighted evidence words 
learns statistical predicates characterize specific set pages hyperlinks perform feature selection directed manner 
vocabulary learning predicate selected specifically particular classification task hand 
contrast selecting vocabulary relational learner represents words background relations vocabulary pruned regard particular subsets pages hyperlinks described clauses priori know constants subsets include 
consider approach quite general involves relational learner represent graph structure statistical learner method characterize edges nodes graph 
algorithm refer foil pilfs foil predicate invention large feature spaces represents particular instantiation approach 
algorithm basically foil augmented method spirit 
shows inner loop foil pilfs learns single clause relation predicate invention method shown predicates foil pilfs invents statistical classifiers applied textual description pages hyperlinks components thereof 
currently invented predicates unary boolean predicates 
assume constant problem domain type type may associated document collections 
constant type maps unique document associated collection 
example type page input partial clause document collection type parameter ffl 
variable 
document collection associated type 
documents representing constants bound pos tuples 
gamma documents representing constants bound neg tuples 
rank word gamma mut 
info 
class variable 
js gamma theta ffl 
top ranked words 
call naive bayes learn feature set training set gamma return learned predicates fig 

foil pilfs predicate invention method 
associated collection documents represent words pages type hyperlink associated collections documents represents words anchor text hyperlinks represents neighboring words hyperlinks 
considers inventing new predicate basic relational algorithm fails find clause method considers inventing new predicates step search clause 
specifically point search partial clause includes variables xn method considers inventing predicates characterize variable type associated collection documents 
document collection associated type consider learning predicate collection 
example type hyperlink document collections associated hyperlink anchor text neighboring text consider learning predicate characterize constants bound anchor text predicate characterize constants neighboring text 
method decided construct predicate variable document collection step assemble training set naive bayes learner 
think tuple set currently covered table row tuple column corresponds variable clause training set consists constants appearing column associated row corresponds extension positive training example extension negative example 
constants appear positive tuples positive instances predicate learning task appear negative tuples negative instances 
issue crops constant appear multiple times column appear positive negative tuples 
enforce constraint constant may appear predicate training set 
example constant bound multiple positive tuples appears single instance training set predicate 
motivation choice want learn naive bayes classifiers generalize new documents 
want learner focus characteristics common documents training set focusing characteristics instances occur times training set 
learning predicate training set method determines vocabulary naive bayes 
cases predicate training set may consist small number documents quite large 
necessarily want allow naive bayes words occur training set features 
method involves steps 
rank word occurs predicate training set mutual information target class predicate 
second ranking take vocabulary naive bayes classifier top ranked words determined follows ffl theta number instances predicate training set ffl parameter set experiments 
motivation heuristic 
want dimensionality feature set size predicate learning task small find predicate fits training set reasonably confident generalize new instances target class 
lower bound number examples required pac learn target function omega vc dimension ffl ffl usual pac error parameter 
bound get rough answer question training examples large feature space consider find promising predicate learner feature space assurance generalize 
class naive bayes learner number features 
ignoring constant factors solving get equation 
note method heuristic 
provide theoretical guarantees accuracy learned clauses assumptions target function predicate consider broader issue accuracy clause literal 
issue set class priors naive bayes classifier 
typically estimated class frequencies training data 
estimates biased positive class context 
consider estimating accuracy partially grown clause fraction positive training set tuples covers usually result biased estimate 
compensate bias simply set class priors uniform distribution 
document contain words vocabulary learned classifiers assign document negative class priors enforce default class 
candidate naive bayes predicates constructed evaluated candidate literal 
naive bayes predicates included clauses retained new background relations may incorporated subsequent clauses 
selected discarded 
naive bayes classifiers produce probabilities instance probabilities constructed predicates evaluation learned clauses 
naive bayes probability estimates usually poor independence assumption violated predictive accuracy quite situations 
experimental evaluation section stated foil pilfs algorithm desirable properties characterizes pages hyperlinks statistical method naive bayes learned rules dependent presence absence specific key words 
statistical classifiers learned rules consider weighted evidence words 
learns statistical predicates characterize specific set pages hyperlinks perform feature selection directed manner 
vocabulary learning predicate selected specifically particular classification task hand 
section test hypothesis approach learn definitions higher accuracy comparable relational method ability statistical predicates 
specifically compare foil pilfs method ordinary foil hypertext learning tasks 
university data set primary data set experiments assembled research project aimed extracting knowledge bases web 
project encompasses learning problems study 
recognize instances knowledge base classes students faculty courses web 
cases framed page classification task 
want recognize relations objects knowledge base 
approach task learn prototypical patterns hyperlink connectivity pages 
example course home page containing hyperlink text instructor tom mitchell pointing home page faculty member positive instance instructors course relation 
data set consists pages hyperlinks drawn web sites computer science departments 
data set includes pages hyperlinks interconnecting 
pages labeled home page classes course faculty student project staff department catch class 
data set includes instances relations entities 
relation instance consists pair pages corresponding class instances involved relation 
example instance instructors course relation consists course home page person home page 
data set relation instances comprises instructors course instances members project instances department person instances 
complete data set available www cs cmu edu webkb 
experiments data set leave university cross validation allowing study learning method performs data unseen university 
important evaluate knowledge base extractor previously unseen web sites 
representations experiments sections give foil background predicates described section 
issue arises predicates represent words pages hyperlinks selecting vocabulary 
experiments remove words apply stemming algorithm remaining words refer back section descriptions processes 
frequency vocabulary pruning follows word page chose words occur times training set 
procedure results predicates training set 
anchor word hyperlink vocabulary set relations includes words occur times hyperlinks training set 
results predicates depending training set 
neighborhood word hyperlink vocabulary set relations includes words occur times hyperlinks training set 
set includes predicates depending training set 
foil pilfs algorithm background knowledge relations listed section predicates 
ability invent predicates describe words pages anchor neighboring text hyperlinks 
effectively learners access information input 
key difference ordinary foil information form background predicates allow foil pilfs page hyperlink words invented naive bayes predicates 
experiments learning page classes study page classification pick largest classes university data set student course faculty project 
classes turn positive class binary page classification problems 
example learn classifier distinguish student home pages pages 
run foil foil pilfs tasks naive bayes classifier applied directly pages 
table 
recall precision scores classification tasks naive bayes foil foil pilfs student course faculty project method naive bayes foil foil pilfs table 
pairwise comparison classifiers 
pairing number times classifier performed better recall precision shown 
wins wins wins wins wins wins naive bayes naive bayes foil foil foil pilfs foil pilfs table shows recall precision results classification tasks 
recall precision defined follows correct positive examples positive examples correct positive examples positive predictions shown score algorithm task 
score commonly information retrieval community weights precision recall equally nice measurement properties 
defined pr comparing scores see foil foil pilfs outperform naive bayes tasks student foil lags slightly 
importantly observe new combined algorithm outperforms foil classification tasks 
comparing precision recall results foil foil pilfs see case foil pilfs outperforms foil 
increased recall performance surprising statistical nature predicates produced 
test aggregate distribution words test document hyperlink depending presence distinct keywords 
apart faculty task see increase precision 
suggests statistical predicates generally applicable better able describe concept learned 
foil pilfs potentially words training set foil reduced set words provided increase precision may pronounced foil larger vocabulary 
pairwise comparisons algorithms shown table 
see pair learning methods outperformed course page page naive bayes link anchor naive bayes page naive bayes 
page naive bayes homework handout assign exam class hour 
anchor naive bayes assign homework project solution note 
page naive bayes upson postscript textbook 
fig 

clause learned foil pilfs covers positive negative training examples 
unseen test set covers course pages non course pages 
shown words greatest log odds ratios invented predicate 
cross validation runs 
example cross validation runs performed foil better recall naive bayes times better precision times 
confirming results score see foil pilfs outperform foil turn outperforms naive bayes problems 
shows accurate clauses learned foil pilfs 
clause uses invented predicates test distribution words page classified tests distribution words hyperlink page 
highly weighted words predicates intuitively reasonable testing page home page course 
note page naive bayes predicate uses words positive log odds ratios 
experiments learning page relations section consider learning target concepts represent specific relations pairs pages 
learn definitions relations described section 
addition positive instances relations data set includes approximately negative examples 
experiments involve additional set background relations class page 
class previous section corresponding relation lists pages represent instances class 
instances determined actual classes pages training set predicted classes pages test set 
previous section learn target concepts relational learner background predicates provide bag words representation pages hyperlinks ii version foil pilfs algorithm 
base algorithm slightly different foil 
previous foil hill climbing search suited learning relations cases pages instance directly connected 
experiments section augment algorithms deterministic variant richards mooney relational pathfinding method 
basic idea underlying method relational problem domain thought graph nodes domain constants edges correspond relations hold constants 
algorithm tries find small number prototypical paths table 
recall precision results relation learning tasks 
department person instructors course members project method path foil path foil pilfs table 
recall precision results relation learning tasks 
department person instructors course members project method wins wins wins wins wins wins path foil path foil pilfs graph connect arguments target relation 
path initial clause formed relations constitute path clause refined hill climbing search 
dzeroski bratko foil algorithms considered estimates clause error guide construction 
evaluation function results fewer general clauses tasks foil information gain measure 
previous experiment difference algorithms compare way predicates describe word occurrences 
consider directly applying naive bayes method experiments target relations arity necessarily require relational learner 
table shows recall precision results target relations 
department person path foil pilfs provides significantly better recall precision path foil 
target concepts path foil edge measures 
table shows number cross validation folds algorithm outperformed 
table shows path foil pilfs decisively better department person algorithm clearly superior relations 
relational learning internal page structure far considered relational learning applied tasks involve representing relationships hypertext documents 
hypertext documents internal structure 
section apply learning method task involves representing internal layout web pages 
specifically task address country name web page determine operations country 
table 
recall precision results node classification task 
method wins wins foil foil pilfs approach algorithm parses web pages tree structures representing layout pages 
example node tree represent html table ancestors html headings come page 
general node tree text associated 
frame task classifying nodes contain country name associated text 
experiments apply foil foil pilfs task background relations heading node page li node page list node page list table node page paragraph node page table node page td node page title node page tr node page predicates list nodes type page node contained 
types correspond html elements 
ancestor node node parent node node sibling node node ancestor heading node node parent heading node node predicates represent relations hold nodes tree 
target relation location node page binary relation learner easily relate nodes common page relationship tree 
setup similar previous experiments give foil set node word node predicates allow foil pilfs invent predicates characterize words nodes 
data set task consists pages parsed nodes 
positive instances target relation negative ones 
compare foil foil pilfs task fold cross validation run 
table shows recall precision results task 
additionally table shows number folds algorithm outperformed terms precision recall 
foil pilfs provides significantly better recall slightly better precision ordinary foil task 
measures foil pilfs outperformed foil folds 
varying vocabulary parameter foil pilfs described section foil pilfs algorithm employs parameter ffl controls words naive bayes constructing new predicate 
contrast experiments ordinary foil vocabulary size decisions separately page anchor neighborhood predicates ffl provides single parameter set foil pilfs 
table 
recall precision scores foil pilfs page classification tasks vary ffl 
student course faculty project ffl experiments far set ffl 
order assess foil pilfs performance affected varying ffl rerun page classification experiment section ffl set 
forces naive bayes fewer words allows twice original experiments 
precision recall scores experiment shown table 
referring back table see general results change values ffl considered 
indicate performance overly sensitive value ffl 
hybrid relational statistical approach learning hypertext domains 
relational component able describe graph structure hyperlinked pages internal structure html pages statistical component adept learning predicates characterize distribution words pages hyperlinks interest 
described particular instantiation approach algorithm foil invents predicates demand represented naive bayes models 
evaluated approach comparing baseline method represents words directly background relations 
experiments indicate method generally learns accurate definitions 
explored particular instantiation approach believe worthwhile investigating search strategies learning clauses ii statistical methods constructing predicates 
additionally plan investigate probabilities estimated statistical classifiers evaluating learned clauses 
believe approach applicable learning tasks involve hypertext 
hypothesize suited domains involve relational structure potentially large feature spaces 
plan apply method domains 
acknowledgments dan dipasquo assistance experiments reported section 
research supported part darpa hpkb program contract 

cohen 
fast effective rule induction 
proc 
th international conference machine learning 
morgan kaufmann 

cohen 
learning classify english text ilp methods 
de raedt editor advances inductive logic programming 
ios press 

craven dipasquo freitag mccallum mitchell nigam slattery 
learning extract symbolic knowledge world wide web 
proc 
th national conference artificial intelligence madison wi 
aaai press 

craven slattery nigam 
order learning web mining 
proc 
th european conference machine learning pages chemnitz germany 
springer verlag 

dipasquo 
html formatting aid natural language processing world wide web 
senior thesis computer science department carnegie mellon university 

domingos pazzani 
optimality simple bayesian classifier zero loss 
machine learning 

dzeroski bratko 
handling noise inductive logic programming 
proc 
nd international workshop inductive logic programming pages tokyo japan 

ehrenfeucht haussler kearns valiant 
general lower bound number examples needed learning 
information computation 


discrimination constructive induction logic programs 
proc 
th national conference artificial intelligence pages san jose ca 
aaai press 

lewis ringuette 
comparison learning algorithms text categorization 
proc 
rd annual symposium document analysis information retrieval pages 

lewis schapire callan papka 
training algorithms linear classifiers 
proc 
th annual international acm sigir conference research development information retrieval pages 
verlag 

mitchell 
machine learning 
mcgraw hill 

moulinier 
ganascia 
text categorization symbolic approach 
proc 
th annual symposium document analysis information retrieval 

quinlan cameron jones 
foil midterm report 
proc 
th european conference machine learning pages vienna austria 
springer verlag 

richards mooney 
learning relations pathfinding 
proc 
th national conference artificial intelligence pages san jose ca 
aaai press 

van rijsbergen 
information retrieval chapter 
butterworths 

yang pedersen 
comparative study feature set selection text categorization 
proc 
th international conference machine learning pages nashville tn 
morgan kaufmann 
