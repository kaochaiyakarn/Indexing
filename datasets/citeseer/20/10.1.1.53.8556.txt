variational probabilistic inference qmr dt database tommi jaakkola university california santa cruz ca tommi cse ucsc edu michael jordan university california berkeley ca jordan cs berkeley edu october describe variational approximation method efficient inference large scale probabilistic models 
variational methods deterministic procedures provide approximations marginal conditional probabilities interest 
provide alternatives approximate inference methods stochastic sampling search 
describe variational approach problem diagnostic inference quick medical qmr database 
qmr database large scale probabilistic graphical model built statistical expert knowledge 
exact probabilistic inference infeasible model small set cases 
evaluate variational inference algorithm large set diagnostic test cases comparing algorithm state art stochastic sampling method 
probabilistic models increasingly prevalent ai years 
significant representational advantages probability theory including guarantees consistency naturalness combining diverse sources knowledge pearl discovery general exact inference algorithms principally responsible rapid growth probabilistic ai see lauritzen spiegelhalter pearl shenoy 
exact inference methods greatly expand range models treated probabilistic framework provide unifying perspective general problem probabilistic computation graphical models 
probability theory viewed combinatorial calculus instructs merge probabilities sets events probabilities composites 
key operation marginalization involves summing integrating values variables 
exact inference algorithms essentially find ways perform sums possible marginalization operations 
terms graphical representation probability distributions random variables correspond nodes conditional independencies expressed missing edges nodes exact inference algorithms define notion locality example cliques appropriately defined graph attempt restrict summation operators locally defined sets nodes 
approach manages exponential explosion exact probabilistic computation exponential explosion inevitable calculus explicitly performs summations sets nodes 
models interest local overly large see jordan 
point view surprising exact inference np hard cooper 
discuss inference problem particular large scale graphical model quick medical qmr model 
qmr model consists combination statistical expert knowledge approximately significant diseases approximately findings 
probabilistic formulation model qmr dt diseases findings arranged bi partite graph diagnosis problem infer probability distribution diseases subset findings 
finding generally relevant wide variety diseases graph underlying qmr dt dense reflecting high order stochastic dependencies 
computational complexity treating dependencies exactly characterized terms size maximal clique moralized graph see dechter lauritzen spiegelhalter 
particular running time exponential measure size 
qmr dt considering standardized conference cpc cases discuss find median size maximal clique moralized graph nodes 
rules general exact algorithms qmr dt 
general algorithms take advantage particular parametric form probability distributions nodes graph conceivable additional acronym qmr dt refers decision theoretic reformulation qmr shwe 

shwe replaced heuristic representation employed original qmr model miller myers probabilistic representation 
factorizations take advantage particular choice qmr dt 
factorization fact heckerman algorithm provides exact inference algorithm tailored qmr dt 
unfortunately run time algorithm exponential number positive findings 
cpc cases estimate algorithm require average years solve inference problem current computers 
faced apparent infeasibility exact inference large scale models qmr dt researchers investigated approximation methods 
general approach developing approximate algorithms perform exact inference partially 
consider partial sets node instantiations partial sets hypotheses partial sets nodes 
point view led development algorithms approximate inference heuristic search 
approach developing approximation algorithms exploit averaging phenomena dense graphs 
particular laws large numbers tell sums random variables behave simply converging predictable numerical results 
may need perform sums explicitly exactly partially 
point view leads variational approach approximate inference 
approach approximate inference stochastic sampling 
sample simplified distributions doing obtain information complex distribution interest 
discuss methods turn 
horvitz suermondt cooper developed partial evaluation algorithm known bounded conditioning works considering partial sets node instantiations 
algorithm notion cutset subset nodes removal renders remaining graph singly connected 
efficient exact algorithms exist singly connected graphs pearl 
summing instantiations cutset calculate posterior probabilities general graphs efficient algorithm subroutine 
unfortunately exponentially cutset instantiations 
bounded conditioning algorithm aims exponential growth considering partial sets instantiations 
algorithm promise graphs nearly singly connected provide solution dense graphs qmr dt 
particular median cutset size qmr dt cpc cases yielding large number cutset instantiations 
approach approximate inference provided search methods consider node instantiations entire graph cooper henrion peng reggia 
general hope methods relatively small fraction exponentially node instantiations contains majority probability mass exploring high probability instantiations bounding unexplored probability mass obtain reasonable bounds posterior probabilities 
search space huge containing approximately disease hypotheses 
considers cases small number diseases hypotheses involving small number diseases contain high probability posteriors may possible search significant fraction relevant portions hypothesis space 
henrion fact able run search algorithm qmr dt inference problem set cases characterized small number diseases 
cases exact algorithm efficient 
general corpus cpc cases characterized small number diseases case realistically expect patients hospital setting limited set diseases 
generally true hypotheses small numbers diseases contain probability mass high dimensional search problems necessary allow paths limited target hypothesis subspace particular able arrive hypothesis containing diseases pruning hypotheses containing additional diseases peng reggia 
imposing limitation lead failure search 
partial evaluation methods include localized partial evaluation method draper hanks incremental spi algorithm ambrosio probabilistic partial evaluation method poole mini buckets algorithm dechter 
algorithm considers partial sets nodes consider partial evaluations sums emerge exact inference run 
promising methods partial evaluation methods clear restrict exponential growth complexity ways yield realistic accuracy time tradeoffs large scale models qmr dt 
variational methods provide alternative approach approximate inference 
similar spirit partial evaluation methods particular incremental spi mini buckets algorithms aim avoid performing sums exponentially summands come problem different point view 
variational point view sum avoided contains sufficient number terms law large numbers invoked 
variational approach inference replaces quantities expected beneficiary averaging process surrogates known variational parameters 
inference algorithm manipulates parameters directly order find approximation marginal probability interest 
qmr dt model turns particularly appealing architecture development variational methods 
show variational methods simple graphical interpretation case qmr dt 
final class methods performing approximate inference stochastic sampling methods 
stochastic sampling large family including techniques rejection sampling importance sampling markov chain monte carlo methods mackay 
methods applied problem approximate probabilistic inference graphical models analytic results available dagum horvitz 
particular shwe cooper proposed stochastic sampling method known likelihood weighted sampling qmr dt model 
results promising results date inference qmr dt able produce reasonably accurate approximations reasonable time difficult cpc cases 
consider shwe cooper algorithm particular compare algorithm empirically variational algorithm entire corpus cpc cases 
ambrosio reports mixed results incremental spi qmr dt somewhat difficult set cases heckerman henrion restricted number positive findings 
important compare approximation methods emphasized outset think goal identify single champion approximate inference technique 
different methods exploit different structural features large scale probability models expect optimal solutions involve combination methods 
return point discussion section consider various promising hybrids approximate exact inference algorithms 
general problem approximate inference np hard dagum luby provides additional reason doubt existence single champion approximate inference technique 
think important stress hardness result cooper hardness result exact inference cited taken suggest exact inference approximate inference equally hard 
take example related field exist large domains solid fluid mechanics exact solutions infeasible approximate techniques finite element methods 
similarly statistical physics models exactly solvable exist approximate methods mean field methods renormalization group methods cases 
feel goal research probabilistic inference similarly identifying effective approximate techniques large classes problems 
qmr dt model qmr dt database shwe level bi partite graphical model see 
top level graph contains nodes diseases bottom level contains nodes findings 
number conditional independence assumptions reflected bi partite graphical structure 
particular diseases assumed marginally independent 
independent absence findings 
note diseases assumed mutually exclusive patient multiple diseases 
states disease nodes findings assumed conditionally independent 
discussion regarding medical validity diagnostic consequences assumptions embedded qmr dt belief network see shwe 
state precisely probability model implied qmr dt model write joint probability diseases findings jd jd binary vectors referring presence absence states diseases positive negative states outcomes findings respectively 
conditional probabilities jd represented noisy model pearl jd jl jd 
diseases findings qmr belief network level graph dependencies diseases associated findings modeled noisy gates 
gamma gamma ij gamma gamma ij set diseases parents finding qmr graph ij jd probability disease cause finding positive outcome jl leak probability probability finding caused means diseases included qmr model 
final line noisy probability model exponentiated notation 
notation model parameters ij gamma log gamma ij 
inference carrying diagnostic inference qmr model involves computing posterior marginal probabilities diseases set observed positive negative findings 
note set observed findings considerably smaller set possible findings note bi partite structure qmr dt graph unobserved findings effect posterior probabilities diseases 
brevity adopt notation corresponds event gamma refers positive negative findings respectively 
posterior probabilities interest jf gamma gamma vectors positive negative findings 
negative findings gamma benign respect inference problem incorporated posterior probability linear time number associated diseases number negative findings 
discuss seen fact probability negative finding eq 
exponential expression linear positive findings hand problematic 
worst case exact calculation posterior probabilities exponentially costly number positive findings heckerman ambrosio 
practical diagnostic situations number positive findings exceeds feasible limit exact calculations 
consider inference calculations detail 
find posterior probability gamma absorb evidence negative findings compute gamma 
just gamma jd normalization 
gamma jd factorize diseases see eq 
eq 
posterior gamma factorize 
normalization gamma jd reduces independent normalizations disease carried time linear number diseases negative findings 
remainder concentrate solely positive findings pose real computational challenge 
stated assume prior distribution diseases contains evidence negative findings 
words presume updates jf gamma 
turn question computing jf posterior marginal probability positive findings 
formally obtaining posterior involves marginalizing jd remaining diseases jf jd summation possible configurations disease variables shorthand summation index 
qmr model jd form jd jd gamma gamma gamma ij follows eq 
fact jd gamma gamma jd 
perform summation eq 
diseases multiply terms gamma deltag corresponding conditional probabilities positive finding 
number terms exponential number positive findings 
algorithms exist attempt find exploit factorizations expression particular pattern observed evidence cf 
heckerman ambrosio algorithms limited roughly positive findings current computers 
sufficient latent factorization qmr dt model able handle full cpc corpus median number positive findings case maximum number positive findings 
variational methods brief exact inference algorithms perform millions arithmetic operations applied complex graphical models qmr dt 
proliferation terms expresses symbolic structure model necessarily express numeric structure model 
particular sums qmr dt inference problem sums large numbers random variables 
laws large numbers suggest sums may yield predictable numerical results ensemble summands fact enable avoid performing sums explicitly 
exploit possibility numerical regularity dense graphical models develop variational approach approximate probabilistic inference 
variational methods general class approximation techniques wide application applied mathematics 
variational methods particularly useful applied highly coupled systems 
introducing additional parameters known variational parameters essentially serve low dimensional surrogates high dimensional couplings system methods achieve decoupling system 
mathematical machinery variational approach provides algorithms finding values variational parameters decoupled system approximation original coupled system 
case probabilistic graphical models variational methods allow simplify complicated joint distribution eq 

achieved parameterized transformations individual node probabilities 
see node transformations interpreted graphically nodes graph 
find appropriate transformations 
variational methods consider come convex analysis see appendix 
considering methods obtaining upper bounds probabilities 
known fact convex analysis concave function represented solution minimization problem min gamma conjugate function 
function obtained solution minimization problem min gamma formal identity pair minimization problems expresses duality conjugate representation eq 
known variational transformation 
parameter known variational parameter 
relax minimization fix variational parameter arbitrary value obtain upper bound gamma bound better values variational parameter particular value bound exact 
want obtain lower bounds conditional probabilities 
straightforward way obtain lower bounds appeal conjugate duality express functions terms maximization principle 
representation applies convex functions current require lower bounds concave functions 
concave functions special form allows exploit conjugate duality different way 
particular require bounds functions form concave function ng non negative variables constant 
variables expression effectively coupled impact changing variable contingent settings remaining variables 
jensen inequality obtain lower bound variables decoupled 
particular viewed defining probability distribution variables variational parameter case probability distribution optimal setting parameter easily verified substitution eq 
demonstrates lower bound tight 
variational upper lower bounds noisy return problem computing posterior probabilities qmr model 
recall conditional probabilities corresponding positive findings need simplified 
write jd gamma gamma gamma ij log gammae gammax ij consider exponent log gamma gammax 
noisy conditional models involving compact representations logistic regression exponent concave function discussion previous section know exist variational upper bound function linear gamma eq 
evaluate conjugate function noisy obtain gamma log log desired bound obtained substituting eq 
recalling definition ij jd ij ij gammaf jd jensen inequality states concave simple consequence eq 
taken note variational evidence jd exponential term linear disease vector just negative findings implies variational evidence incorporated posterior time linear number diseases associated finding 
graphical way understand effect transformation 
rewrite variational evidence follows jd ij gammaf gammaf ij note term constant note product factorized diseases 
factors multiplied pre existing prior corresponding disease possibly modulated factors negative evidence 
constant term viewed associated finding node effect variational transformation finding node graph altering priors disease nodes connected finding node 
graphical perspective important presentation variational algorithm able view variational transformations simplifying graph point exact methods run 
turn lower bounds conditional probabilities jd 
exponent ij exponential representation form applied jensen inequality previous section 
concave need identify non negative variables case ij constant applying bound eq 
jd ij jji io ij jji jji io ij jji gammad io jji io ij jji gammaf io io jd allowed different variational distribution finding 
note bound linear disease variables 
case upper bound implies variational evidence incorporated posterior distribution time linear number diseases 
view variational transformation terms finding node graph 
approximate inference qmr previous section described variational transformations derived individual findings qmr model discuss utilize transformations context inference algorithm 
conceptually approach straightforward 
transformation involves replacing exact conditional probability finding lower bound upper bound jd jd jd transformations viewed ith finding node graph see transformations yield bounds yield simplified graphical structure 
imagine introducing transformations sequentially graph sparse exact methods feasible 
point introducing transformations run exact algorithm 
problem approach 
need decide step node transform requires assessment effect accuracy transforming node 
imagine calculating change probability interest transformation choosing transform node yields change target probability 
unfortunately unable calculate probabilities original untransformed graph unable assess effect transforming node 
unable get algorithm started 
suppose backwards 
introduce transformations findings reducing graph entirely decoupled set nodes 
optimize variational parameters fully transformed graph optimization variational parameters 
graph inference trivial 
easy calculate effect single exact conditional node choose reinstate node yields change 
consider particular case upper bounds lower bounds analogous 
transformation introduces upper bound conditional probability jd 
likelihood observing positive findings upper bounded variational counterpart jd jd assess accuracy variational transformation introducing optimizing variational transformations positive findings 
separately positive finding replace transformed conditional probability jd corresponding exact conditional jd compute difference resulting bounds likelihood observations ffi gamma computed transforming th positive finding 
larger difference ffi worse th variational transformation introduce transformations ascending order ffi put way treat exactly transform conditional probabilities ffi measure large 
practice intelligent method ordering transformations critical 
compares calculation likelihoods ffi measure opposed method chooses ordering transformations random 
plot corresponds representative diagnostic case shows upper bounds log likelihoods observed findings function number conditional probabilities left intact transformed 
note upper bound improve decrease fewer transformations 
results striking choice ordering large effect accuracy note plot log scale 
exactly treated findings log likelihood upper bound log likelihood delta method removing transformations solid line method bases choice random ordering dashed line 
note curve proposed ranking convex bound improves fewer transformations left 
remove worst transformations replacing exact conditionals 
remaining transformations better indicated delta measure bound improves replacements 
claims optimality delta method simply useful heuristic allows choose ordering variational transformations computationally efficient way 
note implementation method optimizes variational parameters outset chooses ordering transformations fixed parameters 
parameters suboptimal graphs substantial numbers nodes reinstated practice simplified algorithm produces reasonable orderings 
decided nodes reinstate approximate inference algorithm run 
introduce transformations nodes left transformed ordering algorithm 
product exact conditional probabilities graph transformed conditional probabilities yields upper lower bound joint probability associated graph product bounds bound 
sums bounds bounds likelihood marginal probability findings bounded summing bounds joint probability 
particular upper bound likelihood obtained jd jd corresponding lower bound likelihood obtained similarly jd jd jq cases assume graph sufficiently simplified variational transformations sums performed efficiently 
expressions eq 
eq 
yield upper lower bounds arbitrary values variational parameters wish obtain tightest possible bounds optimize expressions respect minimize respect maximize respect appendix discusses optimization problems detail 
turns upper bound convex adjustment variational parameters upper bound reduces convex optimization problem carried efficiently reliably local minima 
lower bound turns maximization carried em algorithm 
bounds likelihood useful ultimate goal approximate marginal posterior probabilities jf 
basic approaches utilizing variational bounds eq 
eq 
purpose 
method emphasis current involves transformed probability model model upper lower bounds computationally efficient surrogate original probability model 
tune variational parameters transformed model requiring model give tightest possible bound likelihood 
tuned transformed model inference engine provide approximations probabilities interest particular marginal posterior probabilities jf 
approximations manner bounds computationally efficient approximations 
provide empirical data section show approach yields approximations marginal posteriors qmr dt database 
ambitious goal obtain interval bounds marginal posterior probabilities 
denote combined event qmr dt model generates observed findings th disease takes value bounds follow directly jd jd jd product upper bound transformed conditional probabilities exact untransformed conditionals 
analogously compute lower bound jq applying lower bound transformations jd jd jq combining bounds obtain interval bounds posterior marginal probabilities diseases cf 
draper hanks jq jq jf jq binary complement experimental evaluation diagnostic cases evaluating performance variational techniques cases abstracted conference cpc cases 
cases generally involve multiple diseases considered clinically difficult cases 
cases middleton 
find importance sampling method satisfactorily 
evaluation variational methodology consists parts 
part exploit fact subset cpc cases cases sufficiently small number positive findings calculate exact values posterior marginals algorithm 
cases able obtain gold standard comparison 
provide assessment accuracy efficiency variational methods cpc cases 
variational upper lower bounds likelihood scatterplots compare variational approximations posterior marginals exact values 
comparisons likelihood weighted sampler shwe cooper 
second section results remaining intractable cpc cases 
lengthy runs shwe cooper sampling algorithm provide surrogate gold standard cases 
third section consider problem obtaining interval bounds posterior marginals 
comparison exact marginals cpc cases fewer positive findings see table cases possible calculate exact values likelihood posterior marginals reasonable amount time 
heckerman algorithm heckerman algorithm tailored qmr dt architecture perform exact calculations 
case pos 
findings neg 
findings table description cases evaluated exact posterior marginals 
shows log likelihood tractable cpc cases 
shows variational lower upper bounds 
calculated variational bounds twice sorted cases sorted cases log likelihood exact values variational upper lower bounds log likelihood tractable cpc cases 
positive findings treated exactly positive findings treated exactly 
differing numbers positive findings treated exactly cases treated exactly simply means finding transformed 
panel positive findings treated exactly positive findings treated exactly 
expected bounds tighter positive findings treated exactly 
average running time tractable cpc cases seconds exact method seconds variational method positive findings treated exactly seconds variational method positive findings treated exactly 
results obtained mhz dec alpha computer 
likelihood important quantity approximate particularly applications parameters need estimated interest qmr dt setting posterior marginal probabilities individual diseases 
discussed previous section simplest approach obtaining variational estimates quantities define approximate variational distribution distribution upper bounds likelihood distribution jq lower bounds likelihood 
fixed values variational parameters chosen provide tight bound likelihood distributions provide partially factorized approximations joint probability distribution 
factorized forms exploited efficient approximate inference engines general posterior probabilities particular provide approximations posterior marginals individual diseases 
practice distribution yielded accurate posterior marginals distribution jq restrict presentation 
displays scatterplot approximate posterior marginals panel corresponding case positive findings treated exactly panel case positive findings treated exactly 
plots obtained extracting highest posterior marginals case computing ap significant fraction positive findings treated exactly simulations may wonder additional accuracy due variational transformations 
address concern section demonstrate variational transformations fact responsible significant portion accuracy cases 
exact marginals exact marginals variational estimates scatterplot variational posterior estimates exact marginals 
positive findings treated exactly positive findings treated exactly 
proximate posterior marginals corresponding diseases 
approximate marginals fact correct points figures align diagonals shown dotted lines 
see reasonably correspondence variational algorithm appears provide approximation largest posterior marginals 
quantify correspondence ranking measure section 
current state art algorithm qmr dt enhanced version likelihood weighted sampling proposed shwe cooper 
likelihood weighted sampling stochastic sampling method proposed fung chang shachter peot 
likelihood weighted sampling basically simple forward sampling method weights samples likelihoods 
enhanced improved utilizing self importance sampling see shachter peot version importance sampling importance sampling distribution continually updated reflect current estimated posterior distribution 
middleton 
utilized sampling self importance sampling heuristic initialization scheme known iterative tabular bayes qmr dt model satisfactorily 
subsequent shwe cooper proposed additional enhancement algorithm known markov blanket scoring see shachter peot distributes fractions samples positive negative values node proportion probability values conditioned markov blanket node 
combination markov blanket scoring self importance sampling yielded effective algorithm 
particular modifications place shwe cooper reported reasonable accuracy difficult cpc cases 
re implemented likelihood weighted sampling algorithm shwe cooper incorporating markov blanket scoring heuristic self importance sampling 
utilize iterative tabular bayes utilized related initialization scheme heuristic tabular bayes discussed shwe cooper 
section discuss results running algorithm tractable cpc cases comparing initialization method proved little effect inference results 
results variational inference 
section fuller comparative analysis algorithms cpc cases 
likelihood weighting sampling sampling algorithm realizes tradeoff additional samples requires time improves accuracy 
comparing sampling algorithm variational algorithm ran sampling algorithm different total time periods accuracy achieved sampling algorithm roughly covered range achieved variational algorithm 
results shown right hand curve corresponding sampling runs 
displays mean correlations approximate exact posterior marginals independent runs algorithm tractable cpc cases 
execution time mean correlation mean correlation approximate exact posterior marginals function execution time seconds 
solid line variational estimates dashed line likelihood weighting sampling 
lines sampling result represent standard errors mean independent runs sampler 
variational algorithms characterized time accuracy tradeoff 
particular accuracy method generally improves findings treated exactly cost additional computation 
shows results variational algorithm left hand curve 
points curve correspond positive findings treated exactly 
note variational estimates deterministic single run 
shows achieve roughly equivalent levels accuracy sampling algorithm requires significantly computation time variational method 
scatterplots correlation measures provide rough indication accuracy approximation algorithm deficient respects 
particular diagnostic practice interest ability algorithm rank diseases correctly avoid false positives diseases fact significant included set highly ranked diseases false negatives significant diseases omitted set highly ranked diseases 
defined ranking measure follows see investigated gibbs sampling pearl 
results gibbs sampling results likelihood weighted sampling report results remainder 
middleton 
consider set highest ranking disease hypotheses ranking correct posterior marginals 
corresponding set diseases find smallest set approximately ranked diseases includes significant ones 
words true positives approximate method produces gamma false positives 
plotting false positives function true positives provides meaningful useful measure accuracy approximation scheme 
extent method provides nearly correct ranking true positives plot increases slowly area curve small 
significant disease appears late approximate ordering plot increases rapidly near true rank missed disease area curve large 
plot number false negatives set top highly ranked diseases 
false negatives refer number diseases highest ranking diseases appear set approximately ranked diseases 
note previous measure measure reveal severity frequency 
improved diagnostic measure hand return evaluation inference algorithms variational algorithm 
provides plots true positives false positives approximate ranking average number false positives function true positives variational method solid lines partially exact method dashed line 
false negatives set top approximately ranked diseases 
figures positive findings treated exactly 
false positives panel false negatives panel true positives tractable cpc cases 
positive findings treated exactly simulation shown 
displays results positive finding treated exactly 
noted earlier positive findings comprise significant fraction total positive findings tractable cpc cases important verify variational transformations fact contributing accuracy posterior approximations exact calculations 
comparing variational method method call partially exact method posterior probabilities obtained findings treated exactly variational calculations findings transformed 
variational transformations contribute accuracy approximation true positives approximate ranking average number false positives function true positives variational method solid line partially exact method dashed line 
false negatives set top approximately ranked diseases 
figures positive findings treated exactly 
performance partially exact method comparable variational method 
clearly indicate case 
difference accuracy methods substantial computational load comparable seconds mhz dec alpha 
believe accuracy portrayed false positive plots provides indication potential variational algorithm providing practical solution approximate inference problem qmr dt 
figures show number false positives grows slowly number true positives 
example shown positive findings treated exactly find diseases need entertain top diseases list approximately ranked diseases compared partially exact method 
ranking plot likelihood weighted sampler shown curve variational method included comparison 
plots ran likelihood weighted sampler amount time seconds comparable time allocated slowest variational method seconds case positive findings treated exactly 
recall time required variational algorithm positive findings treated exactly seconds 
plots show tractable cpc cases variational method significantly accurate sampling comparable computational loads 
full cpc corpus consider full cpc corpus 
majority cases cases positive findings appear reach exact methods 
noted conservative comparison partially exact method fact benefits variational transformation set exactly treated positive findings selected basis accuracy variational transformations accuracies correlate diagnostic relevance findings 
true positives false positives average number false positives function true positives sampler dashed line variational method solid line positive findings treated exactly 
important attraction sampling methods mathematical guarantee accurate estimates limit sufficiently large sample size gelfand smith 
sampling methods promise providing general methodology approximate inference caveats number samples needed difficult diagnosis samples may required obtain accurate estimates 
real time applications issue rule sampling solutions 
long term runs sampler provide useful baseline evaluation accuracy faster approximation algorithms 
considering possibility context likelihood weighted sampling qmr dt 
turn comparative evaluation likelihood weighted sampling variational methods time limited setting 
explore viability likelihood weighted sampler providing surrogate gold standard carried independent runs consisting samples 
shows estimates log likelihood sampling run sorted cases sampling estimates sampling estimates upper lower bounds solid lines corresponding sampling estimates dashed line log likelihood observed findings cpc cases 
correlation plot posterior marginal estimates independent sampling runs 
cpc cases 
show variational upper lower bounds cases cases sorted lower bound 
note bounds rigorous bounds true log likelihood provide direct indication accuracy sampling estimates 
see estimates lie bounds see cases sampling estimates deviate substantially bounds 
suggests posterior marginal estimates obtained samples unreliable 
presents scatterplot estimated posterior marginals independent runs sampler 
see cases results lie diagonal indicating agreement runs see pairs posterior estimates far diagonal 
results cast doubt viability likelihood weighted sampler general approximator full set cpc cases 
appear reliable surrogate gold standard cases making difficult evaluate accuracy real time approximations variational method 
note estimates fall classes estimates lie variational bounds estimates far bounds 
suggests possibility distribution sampled multi modal estimates falling correct mode providing approximations falling spurious modes providing seriously inaccurate approximations 
situation holds accurate surrogate gold standard obtained variational bounds filter sampling results retaining estimates lie bounds variational approach 
provides evidence viability approach 
sampling estimates correlation plot selected posterior marginal estimates independent sampling runs selection variational upper lower bounds 
cpc cases independent runs sampler resulted estimates loglikelihood lying approximately variational bounds 
recomputed posterior marginal estimates selected cases plotted 
scatterplot shows high degree correspondence posterior estimates cases 
tentatively assume estimates accurate serve surrogate gold standard proceed evaluate real time approximations 
plots false positives true positives selected cpc true positives false positives average number false positives function true positives variational method solid line likelihood weighted sampler dashed line 
variational method positive findings treated exactly sampler results averages runs 
cases variational method 
twelve positive findings treated exactly simulation 
obtaining variational estimates took seconds computer time case 
curve increases rapidly tractable cpc cases variational algorithm appears provide reasonably accurate ranking posterior marginals reasonable time frame 
compare variational algorithm time limited version likelihood weighted sampler ran algorithm period time seconds case roughly comparable running time variational algorithm seconds case 
shows corresponding plot false positives true positives averaged independent runs 
see curve increases significantly steeply variational curve 
find diseases variational method need entertain top diseases list approximately ranked diseases 
sampling method need entertain top approximately ranked diseases 
interval bounds marginal probabilities far utilized variational approach produce approximations posterior marginals 
approximations discussed originate upper lower bounds likelihood bounds 
guaranteed lie true posteriors see 
discussed section possible induce upper lower bounds posterior marginals upper lower bounds likelihood cf 
eq 

section evaluate interval bounds qmr dt posterior marginals 
displays histogram interval bounds tractable cpc cases selected cpc cases previous section cpc cases 
histograms include diseases qmr dt database 
case tractable cases variational method run positive findings treated exactly 
remaining interval size frequency interval size frequency interval size histograms size interval bounds diseases database tractable cpc cases selected cpc cases previous section cpc cases 
cpc cases variational method run positive findings treated exactly 
running time algorithm seconds computer time cpc case 
tractable cpc cases interval bounds tight nearly diseases database 
positive findings treated cases need practice compute variational bounds cases 
get somewhat better picture viability variational interval bounds picture decidedly mixed 
selected cases tight bounds provided approximately half diseases 
bounds vacuous approximately quarter diseases range diseases 
consider cpc cases approximately third bounds tight nearly half vacuous 
results may indicate limitations variational approximation immediate problem appears responsible looseness bounds cases 
particular recall algorithm heckerman handle exact calculations framework variational algorithm 
unfortunately suffers vanishing numerical precision large numbers positive findings general run numerical problems resulting vacuous bounds positive findings incorporated exactly variational approximation 
clearly interest run variational algorithm longer durations improve bounds unable current implementation exact subroutine 
clearly worth studying methods treating exact findings variational algorithm interest consider combining variational methods methods search partial evaluation methods intervals 
methods may help simplifying posterior obviating need improving exact calculations 
worth emphasizing positive aspect results potential practical utility 
previous section showed variational method provide accurate approximations posterior marginals 
combined interval bounds section calculated efficiently user obtain guarantees approximately third approximations 
relatively benign rate increase false positives function true positives guarantees may suffice 
diseases bounds loose perturbation methods available jaakkola help validate approximations diseases 
discussion summarize variational inference method evaluate results obtained 
variational method begins parameterized upper lower bounds individual conditional probabilities nodes model 
qmr dt bounds exponentials linear functions introducing model corresponds nodes graph 
sums products bounds yield bounds readily obtain parameterized bounds marginal probabilities particular upper lower bounds likelihood 
exploited likelihood bounds evaluating output likelihood weighted sampling algorithm 
sampling algorithm yield reliable results corpus cpc cases utilized variational upper lower bounds select samples able obtain sampling results consistent runs 
suggests general procedure variational bounds assess convergence sampling algorithm 
imagine intimate relationship algorithms variational bounds adjust line course sampler 
fact bounds likelihood marginal probabilities critical bounding property allows find optimizing values variational parameters minimizing upper bounding variational distribution maximizing lower bounding variational distribution 
case qmr dt database bipartite noisy graph minimization problem convex optimization problem maximization problem solved em algorithm 
variational parameters optimized resulting variational distribution exploited inference engine calculating approximations posterior probabilities 
technique focus 
graphically transformed model viewed sub graph original model finding nodes 
sufficient number findings possible run exact algorithm resulting graph 
approach yields approximations posterior marginals disease nodes 
empirically approximations appeared provide approximations true posterior marginals 
case tractable set cpc cases cf 
subject assumption obtained surrogate gold standard selected output sampler case full cpc corpus cf 

compared variational algorithm state art algorithm likelihood weighted sampler shwe cooper 
variational algorithm outperformed likelihood weighted sampler tractable cases full corpus 
particular fixed accuracy requirement variational algo rithm significantly faster cf 
fixed time variational algorithm significantly accurate cf 

results satisfactory interval bounds posterior marginals 
full cpc corpus approximately third disease bounds tight half diseases bounds vacuous 
major impediment obtaining tighter bounds appears lie variational approximation se exact subroutine investigating exact methods improved numerical properties 
focused detail qmr dt model worth noting variational probabilistic inference methodology considerably general 
specifically methods described limited bi partite graphical structure qmr dt model necessary employ noisy nodes jaakkola jordan 
case type transformations exploited qmr dt setting extend larger class dependence relations generalized linear models jaakkola 
review applications variational methods variety graphical model architectures see jordan 

promising direction research appears integration various kinds approximate exact methods see dagum horvitz jensen kong kjaerulff 
particular search methods cooper peng reggia henrion variational methods yield bounds probabilities indicated exploit different aspects structure complex probability distributions 
may possible combine bounds algorithm variational bounds guide search bounds aid variational approximation 
similar comments respect localized partial evaluation methods bounded conditioning methods draper hanks horvitz 
seen variational bounds assessing estimates monte carlo sampling algorithms converged 
interesting hybrid scheme variational approximations refined treating initial conditions sampler 
extensions results appear quite promising 
algorithm runs real time large scale graphical model exact algorithms general infeasible 
results obtained appear reasonably accurate corpus difficult diagnostic cases 
needed believe results indicate promising role variational inference developing critiquing exploiting large scale probabilistic models qmr dt 
acknowledgments university pittsburgh randy miller qmr dt database 
want david heckerman suggesting attack qmr dt variational methods providing helpful counsel way 
ambrosio 

incremental probabilistic inference 
proceedings ninth conference uncertainty artificial intelligence 
san mateo ca morgan kaufmann 
ambrosio 

symbolic probabilistic inference large bn networks 
proceedings tenth conference uncertainty artificial intelligence 
san mateo ca morgan kaufmann 
cooper 

computational complexity probabilistic inference bayesian belief networks 
artificial intelligence 
cooper 

nestor computer medical diagnostic aid integrates causal probabilistic knowledge 
unpublished phd thesis computer science department stanford university stanford ca 
dagum horvitz 

reformulating inference problems selective conditioning 
proceedings eighth annual conference uncertainty artificial intelligence 
dagum horvitz 

bayesian analysis simulation algorithms inference belief networks 
networks 
dagum luby 

approximate probabilistic reasoning bayesian belief networks np hard 
artificial intelligence 
dechter 

mini buckets general scheme generating approximations automated reasoning 
proceedings fifteenth international joint conference artificial intelligence 
dechter 

bucket elimination unifying framework probabilistic inference 
jordan ed learning graphical models 
mit press cambridge ma 
dempster laird rubin 

maximum likelihood incomplete data em algorithm 
journal royal statistical society 
draper hanks 

localized partial evaluation belief networks 
proceedings tenth annual conference uncertainty artificial intelligence 
fung chang 

weighting integrating evidence stochastic simulation bayesian networks 
proceedings fifth conference uncertainty artificial intelligence pp 

elsevier science amsterdam 
gelfand smith 

sampling approaches calculating marginal densities 
journal american statistical association 
heckerman 

tractable inference algorithm diagnosing multiple diseases 
proceedings fifth conference uncertainty artificial intelligence 
henrion 

search methods bound diagnostic probabilities large belief nets 
proceedings seventh conference uncertainty artificial intelligence 
horvitz suermondt cooper 

bounded conditioning flexible inference decisions scarce resources 
proceedings fifth conference uncertainty artificial intelligence 
jaakkola 

variational methods inference learning graphical models 
unpublished phd thesis massachusetts institute technology 
jaakkola jordan 

recursive algorithms approximating probabilities graphical models 
advances neural information processing systems 
jensen kong kjaerulff 

blocking gibbs sampling large probabilistic expert systems 
international journal human computer studies 
jensen 

bayesian networks 
springer new york 
jordan jaakkola saul 

variational methods graphical models 
jordan ed learning graphical models 
mit press cambridge ma 
lauritzen spiegelhalter 

local computations probabilities graphical structures application expert systems discussion 
journal royal statistical society 
mackay 

monte carlo methods 
jordan ed learning graphical models 
mit press cambridge ma 
middleton shwe heckerman henrion horvitz lehmann cooper 

probabilistic diagnosis internist qmr knowledge base ii 
evaluation diagnostic performance 
section medical informatics technical report smi 
stanford university 
miller myers 

quick medical qmr diagnostic assistance 
medical computing 
pearl 

probabilistic reasoning intelligent systems 
san mateo ca morgan kaufmann 
peng reggia 

probabilistic causal model diagnostic problem solving part diagnostic strategy 
ieee trans 
systems man cybernetics special issue diagnosis 
poole 

probabilistic partial evaluation exploiting rule structure probabilistic inference proceedings fifteenth international joint conference artificial intelligence nagoya japan 
rockafellar 

convex analysis 
princeton univ press 
shachter peot 

simulation approaches general probabilistic inference belief networks 
proceedings fifth conference uncertainty artificial intelligence pp 

elsevier science amsterdam 
shenoy 

valuation systems bayesian decision analysis 
operations research 
shwe cooper 

empirical analysis likelihood weighting simulation large multiply connected medical belief network 
computers biomedical research 
shwe middleton heckerman henrion horvitz lehmann cooper 
probabilistic diagnosis internist qmr knowledge base probabilistic model inference algorithms 
methods information medicine 
duality upper lower bounds individual conditional probability distributions form basis variational method dual conjugate representations convex functions 
brief description convex duality appendix refer reader rockafellar extensive treatment 
real valued convex function defined convex set example 
simplicity exposition assume behaved differentiable function 
consider graph points dimensional space 
fact function convex translates convexity set called denoted epi 
elementary property convex sets represented intersection half spaces contain see 
parameterizing half spaces obtain dual representations convex functions 
define half space condition gamma gamma parameterize non vertical half spaces 
interested characterizing half spaces contain require points satisfy half space condition epi gamma gamma 
holds gamma gamma points property 
condition satisfied follows epi half spaces containing convex set epi 
conjugate function defines critical half spaces intersection epi equivalently defines tangent planes 
max gamma gamma 
equivalently max gamma right hand side equation defines function known dual conjugate function 
function convex function defines critical half spaces needed representation epi intersection half spaces 
clarify duality drop maximum rewrite inequality equation roles functions interchangeable may suspect obtained dual function optimization procedure 
fact case max xi gamma equality states dual dual gives back original function 
provides computational tool calculating dual functions 
concave convex functions results analogous replace max min lower bounds upper bounds 
optimization variational parameters variational method described involves replacing selected local conditional probabilities upper bounding lower bounding variational transformations 
product bounds bound transformed joint probability distribution bound upper lower true joint probability distribution 
sums bounds bound sum obtain bounds marginal probabilities marginalizing transformed joint probability distribution 
particular provides method obtaining bounds likelihood marginal probability evidence 
note transformed distributions bounds arbitrary values variational parameters individually transformed node conditional probability bound arbitrary values variational parameter 
obtain optimizing values variational parameters take advantage fact transformed distribution bound minimize case upper bounds maximize case lower bounds transformed distribution respect variational parameters 
optimization process provides tight bound marginal probability interest likelihood picks particular variational distribution subsequently approximate inference 
appendix discuss optimization problems solve case noisy networks 
consider upper lower bounds separately upper bound 
upper bound transformations goal compute tight upper bound likelihood observed findings jd 
discussed section obtain upper bound jd introducing upper bounds individual node conditional probabilities 
represent upper bound jd product individual variational transformations may contain contributions due findings treated exactly transformed 
marginalizing obtain bound jd quantity wish minimize respect variational parameters 
simplify notation assume positive findings transformed need optimized remaining conditional probabilities treated exactly 
notation im jd jd im jd expectation taken respect posterior distribution diseases positive findings plan treat exactly 
note proportionality constant depend variational parameters likelihood exactly treated positive findings 
insert explicit forms transformed conditional probabilities see eq 
eq 
find im ij gammaf im gammaf ae im ij oe simply converted products sums exponent pulled terms constants respect expectation 
log scale proportionality equivalence constant log im gamma log ae im ij oe observations order 
recall conjugate concave function exponent concave reason gammaf convex 
appendix prove remaining term log ae im ij oe convex function variational parameters 
sum convex functions convex conclude log convex function variational parameters 
means local minima optimization problem 
may safely employ standard newton raphson procedure solve log 
alternatively utilize fixed point iterations 
particular calculate derivatives variational form iteratively solve individual variational parameters derivatives zero 
derivatives follows log log kj log gamma var kj expectation variance respect posterior approximation derivatives computed time linear number associated diseases finding 
benign scaling variance calculations comes exploiting special properties noisy dependence marginal independence diseases 
calculating expectations eq 
exponentially costly number exactly treated positive findings 
large number positive findings recourse simplified procedure optimize variational parameters having transformed positive findings 
resulting variational parameters suboptimal practice incurred loss accuracy typically quite small 
simulations reported optimized variational parameters approximately half exactly treated findings introduced 
precise case total findings treated exactly optimized parameters findings respectively introduced 
lower bound transformations mimicking case upper bounds replace individual conditional probabilities findings lower bounding transformations resulting lower bounding expression jd 
product marginalizing yields lower bound likelihood jd jq wish maximize jq respect variational parameters obtain tightest possible bound 
problem mapped standard optimization problem statistics 
particular treating latent variable observed variable parameter vector optimization jq logarithm viewed standard maximum likelihood estimation problem latent variable model 
solved em algorithm dempster laird rubin 
algorithm yields sequence variational parameters monotonically increase objective function log jq 
em framework obtain update variational parameters maximizing expected complete log likelihood phi log jd psi log jd constant old denotes vector variational parameters update constant term independent variational parameters expectation respect posterior distribution old jd old 
variational parameters associated conditional probabilities jd independent maximize term sum separately 
recalling form variational transformation see eq 
log jd jji efd io ij jji gamma io io maximize respect jji keeping expectations efd fixed 
optimization problem solved iteratively monotonically performing synchronous updates normalization jji efd jji io ij jji gamma ij io ij jji gamma jji io denotes derivative 
update guaranteed non negative 
algorithm easily extended handle case positive findings transformed 
new feature conditional probabilities products jd old jd left intact transformed optimization respect variational parameters corresponding transformed conditionals proceeds 
convexity purpose appendix demonstrate function log ae im ij oe convex function variational parameters note affine transformations change convexity properties 
convexity im ij implies convexity variational parameters 
remains show log log convex function vector fx indicated discrete values range random variable denoted probability measure values gradient respect gives defines probability distribution 
convexity revealed positive semidefinite hessian components case kl ffi kl gamma see positive semi definite consider gamma variance discrete random variable takes values probability 
