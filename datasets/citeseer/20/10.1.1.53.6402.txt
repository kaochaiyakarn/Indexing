visual interpretation hand gestures human computer interaction review vladimir pavlovi rajeev sharma thomas huang department electrical computer engineering beckman institute advanced science technology university illinois urbana champaign mathews avenue urbana il usa hand gestures provides attractive alternative cumbersome interface devices human computer interaction hci 
particular visual interpretation hand gestures help achieving ease naturalness desired hci 
survey literature vision hand gesture recognition context role hci 
number approaches video hand gesture recognition grown years 
need analysis different aspects gestural interaction developed 
discuss complete model hand gestures possesses spatial dynamic properties human hand gestures accommodate natural types 
classes models employed interpretation hand gestures hci considered 
utilizes models human hand second relies appearance human hand image 
investigation model parameters analysis features impact interpretation hand gestures light naturalness desired hci 
hand models offer way complete modeling hand gestures 
lack simplicity computational efficiency highly preferred currently feasible appearance models 
suggest methods increase effectiveness gestural interface hci 
integration hand gestures natural modes communication provide potential answer problem 
puts advances computer vision understanding human computer interaction necessary produce effective natural hand gesture interface 
human society lives interaction entities environments 
daily lives interact people objects perform variety actions important 
computers computerized machines new element society 
increasingly influence aspects lives example way communicate way perform actions way interact environment 
new concept interaction emerged human computer interaction hci 
computers advanced tremendously common hci relies simple mechanical devices keyboards mice joysticks tremendously reduce effectiveness naturalness interaction 
limitation evident emergence new concept surrounding interaction virtual reality 
studies shown natural point virtual space index finger explore virtual objects hands 
easier understand people virtual environment see manipulate objects 
ideas virtual collaborative environments researchers jointly design test prototypes new products reality 
new means hci available perform interactions environments natural way 
early days computers attempting understand speech 
years increased interest trying introduce means human human interaction field hci 
new means include class devices spatial motion human arm hand gestures 
human hand gestures means non verbal interaction people 
range simple actions pointing objects moving complex ones express feelings allow communicate 
exploit gestures hci necessary provide means interpreted computers 
hci interpretation gestures requires dynamic static configurations human hand arm body measurable machine 
attempts solve problem resulted mechanical devices directly measure hand arm joint angles spatial position 
group best represented called glove devices 
glove devices completely fulfill important requirement hci naturalness 
glove gestural interfaces force user carry load cables connect device computer 
hinders ease naturalness user interact computer controlled environment 
overcome limitations imposed glove devices vision approach hand centered hci proposed years 
approach suggests set video cameras computer vision techniques interpret gestures 
non resulting vision interface resulted burst activity area 
vision gestural hci mainly focused recognition static hand gestures postures 
variety models taken directly general object recognition approaches utilized purpose images hands geometric moments contours silhouettes hand skeleton models examples 
dynamics hand gestures easily disregarded interpreted light object tracking 
hand gestures dynamic actions interpreted motion hands conveys meaning posture 
fusion dynamic characteristics gestures hci role deserves 
numerous approaches ranging global hand motion independent fingertip motion exploited necessary justification 
rapid growth hci brought surface need analysis aspects interaction especially light naturalness 
unfortunately task accomplished technical literature 
attempts achieve goal 
organized follows section formulate problem hand gestures means hci 
discuss modeling methods hand gestures hci 
propose definition taxonomy gestures suitable hci framework 
section section establish unified approach analysis recognition hand gestures 
consider choice various features analysis human hand arm images influence different models gestures performance gesture interpretation scheme 
stress importance hand gestures hci briefly discuss section number possible applications light modeling analysis recognition techniques previously 
conclude review discussion limitations current approaches visual interpretation hand gestures propose number possible solutions prospective research directions 
hand gestures hci hand gestures new mode hci 
visual interpretation hand arm movements carries tremendous advantage techniques require mechanical transducers non 
restrictions imposed user movements restrictions may caused weight discomfort mechanical devices 
visual interpretation carries burden complexity implementation 
numerous approaches applied problem visual interpretation gestures hci seen sections 
approaches chosen implemented focus particular aspect gestures hand tracking pose classification hand posture interpretation example 
effectively study process hand gesture interpretation global structure interpretation system needs established 
purpose propose global vision gesture interpretation system system requires mathematical model gestures established 
model pivotal successful functioning system devote section depth discussion gesture modeling issues 
model decided system gesture description mathematical model gestures model parameter space classes grammar recognition analysis parameters model input video block diagram vision gesture interpretation system 
follows classical path 
model parameters computed analysis stage section image features extracted single multiple video input streams 
selection features specific task gesture interpretation crucial effective model parameter computation overlooked note section section 
analysis stage followed recognition block section 
parameters classified interpreted light accepted model rules imposed adequate grammar 
grammar reflects internal syntax gestural commands possibility interaction gestures communication modes speech gaze facial expressions 
naturalness interpretation gestures measured point 
encompasses accuracy robustness speed variability number different classes hand arm movements covers 
requirement milestone remains fully reached 
gesture modeling quality gestural interface hci directly related proper modeling hand gestures 
model hand gestures depends primarily intended application hci context 
instances example coarse simple model may sufficient 
purpose natural interaction model established allows natural gestures interpreted computer 
discussion focuses question modeling hand gestures hci 
definition gestures outside hci framework hand gestures easily defined 
definitions exist particularly related communicational aspect human hand body movements 
webster dictionary example defines gestures motions limbs body means expression movement usually body limbs expresses emphasizes idea sentiment attitude 
psychological social studies tend narrow broad definition relate man expression social interaction 
domain hci notion gestures somewhat different 
computer controlled environment wants human hand perform tasks mimic natural hand manipulator human machine communication control computer machine functions gestures 
classical definitions gestures hand rarely concerned mentioned human hand called practical gestures 
purpose establishing hand means interaction computer controlled virtual environment propose definition hand gestures definition vector describes pose hands arms spatial position environment time parameter space hand gesture represented trajectory parameter space suitably defined interval note definition suggested allows possibility handed gestures 
spite note gestures performed natural environment single hand type exceptions including manipulations hands gestures 
questions remain 
construction gestural model parameter set define gesture interval focus attention questions 
gestural taxonomy lack clear definition gestures general raises issue taxonomy gestures 
taxonomies suggested literature deals psychological aspects gestures 
vary author author 
kendon distinguishes autonomous gestures occur independently speech gestures occur association speech 
mcneill levy recognize groups gestures iconic metaphoric gestures beats 
taxonomy appropriate hci purposes developed quek 
adopt generalize taxonomy proposition proposition taxonomy gestures applicable hci 
classify hand arm movements major classes gestures unintentional movements 
unintentional movements hand arm movements convey gestural information 
gestures modalities communicative manipulative 
manipulative gestures ones act objects environment object movement rotation communicative gestures hand inherent hand arm movements gestures unintentional movements communicative manipulative acts symbols referential deictic mimetic gestural taxonomy hci 
communicational purpose 
natural environment usually accompanied speech 
communicative gestures acts symbols 
symbols gestures linguistic role 
symbolize referential action instance circular motion index finger may referent wheel speech look wing gesture specifying wing vibrating example 
hci context gesture far commonly gestures represented different static hand postures discuss section 
acts gestures directly related interpretation movement 
movements classified mimetic imitate actions deictic pointing acts 
taxonomy gestures largely influences way parameter space gesture interval determined 
related gestural taxonomy classification gestural dynamics 
consider issue 
temporal modeling gestures human gestures dynamic process 
issue temporal dynamic characteristics gestures practical nature 
helps resolve problem temporal segmentation gestures unintentional hand arm movements 
tantamount question determine gesture interval surprisingly psychological studies gestures provide fairly consistent answer previous question 
kendon calls interval gesture phrase 
established phases gesture preparation nucleus peak stroke retraction 
preparation phase consists preparatory movement sets hand motion resting position 
nucleus gesture definite form enhanced dynamic qualities 
hand returns rest position new gesture phase 
exception rule called beats gestures related rhythmic structure speech 
discussion guide process temporal discrimination gestures 
useful set rules developed leads temporal classification 
set rules suggested quek 
formulate modified version rules form proposition proposition hci environment set rules determines temporal segmentation gestures 
gesture interval consists phases preparation stroke retraction 

hand pose stroke follows classifiable path parameter space 

gestures confined specified spatial volume workspace 

repetitive hand movements gestures 

manipulative gestures longer gesture interval lengths communicative gestures 
temporal phases distinguishable general hand arm motion preparation retraction characterized rapid change position hand stroke general exhibits relatively slower hand motion 
proposition holds case general gestures hci 
seen section complexity gestural interpretation usually imposes stringent constraints allowed temporal variability hand gestures 
vision gesture hci done far reduces gestures static equivalents hand poses 
spatial modeling gestures hand arm movements actions space 
description gestures involves characterization spatial properties 
hci domain characterization far influenced kind application gestural interface intended 
example applications require simple models static image templates human hand tv set control require sophisticated ones hand model instance 
gives rise question model hand arm movements provide complete description gestures hci 
propose answer proposition complete gesture model hci parameters belong parameter space constructed manner fx position hand arm segment joints fingertips proposition relies assumption human hand arm thought articulated object 
valid hci deformations human hand skin convey additional information needed interpret gestures hci 
model proposed provide information required correct analysis hand gestures hci 
approach 
dimensionality parameter space high theta parameters arm 
second important obtain parameters model computer vision techniques proves extremely complex 
overcome obstacle major approaches gesture modeling utilized far see 
model gestures hand arm model 
approach appearance 
examine approaches closely subsections 
appearance spatial gesture model hand model parameters parameters joint angles palm position images image geometry parameters image motion parameters fingertip position motion spatial gesture models 
hand arm model employment hand arm model purpose gesture modeling direct consequence proposition 
dealing parameters mentioned proposition reduced set equivalent joint angle parameters segment lengths usually 
reduction accomplished sets assumptions generally hold 
assumptions example introduce dependencies different joints impose bounds moving ranges joint angles 
hand arm models simplified skeletons human hand arm 
researchers concerned global body arm motion cylindrical models human arms body segments 
modeling human hands skeleton models common see 
models mimic human hand skeleton kinematics 
examples studies human hand morphology biomechanics 
briefly describe basic notions relevant discussion 
human hand skeleton consists bones divided groups wrist bones palm bones finger bones 
joints connecting bones naturally exhibit different degrees freedom dof 
joints connecting limited freedom movement 
holds metacarpal joints tm see 
finger joints show flexibility instance mcp tm joint dof extension flexion abduction pip dip joints dof extension flexion 
equally important notion dof notion dependability movements neighboring joints 
instance natural people bend flex extend fingers pip dip joints flex extend 
certain range angles hand joints naturally assume 
sets constraints placed joint angle movements static range dynamic dependencies 
set constraints dof hand model metacarpal middle phalanx distal phalanx proximal phalanx mcp distal dip proximal pip ip mcp distal phalanx proximal phalanx metacarpal tm middle ring thumb index skeleton model human hand 
static constraints fingers thumb mcp gamma mcp dynamic constraints ip dip ip mcp mcp ip tm mcp mcp mcp mcp converge gamma mcp mcp tm mcp superscripts denote extensions abduction movements local joint centered coordinate systems 
example lee kunii developed degree freedom dof hand skeleton model analogous set constraints 
similar skeleton models equal lesser complexity authors 
appearance model second group models appearance hands arms image 
means model parameters encompass parameters mentioned proposition ones directly derived 
model gestures relating appearance gesture appearance set predefined template gestures 
large variety models belong group 
deformable templates human hand arm :10.1.1.17.6274
deformable templates sets points outline object interpolation nodes object outline approximation 
simplest interpolation function piecewise linear function 
template sets corresponding variability parameters describe variability elements set obtained principal component analysis pca training sets data 
template models hand tracking purposes 
simple gesture classification multitude classes templates :10.1.1.17.6274
different group appearance models uses hand image sequences gesture templates 
gesture set allowed gestures modeled sequence representative image tuples 
furthermore element tuple corresponds view hand arm 
common case stereoscopic views 
parameters models images features derived images 
instance complete image sequences human hands motion templates se various gestures 
images fingers employed templates finger tracking application 
majority appearance models parameters derived images templates 
denote class parameters hand image property parameters 
include contours edges image moments image eigenvectors mention 
parameters features analysis gestures see section 
contours direct model parameter simple edge contours signatures contours polar coordinates possible examples 
contours employed basis eigenspace analysis 
parameters image moments :10.1.1.51.6538
easily calculated hand arm silhouettes contours 
parameters zernike moments orientation histograms example 
group models uses fingertip positions parameters 
approach assumption position fingertips human hand relative palm sufficient differentiate finite number different gestures 
assumption holds space restrictions noted lee kunii palm assumed rigid fingers limited number dofs 
models locations fingertips palm :10.1.1.32.4166
applications concerned deictic gestures usually single index fingertip point hand body 
gesture analysis previous section discussed different ways model gestures hci 
purpose analysis stage estimate parameters trajectory parameter space gesture model number low level features extracted images human operators acting hci environment 
parameters gesture models acquired multistage analysis mono multi camera video input sequences images 
steps constitute analysis hand arm localization hand arm feature extraction hand arm model parameter computation features see 
analyze steps 
hand arm image feature extraction hand arm image feature extraction hand arm localization segmentation hand arm localization segmentation hand arm model parameter computation model parameters local image features 
camera camera global image global image gesture analysis hci 
hand localization segmentation hand arm localization segmentation process hands arm extracted rest image 
general complex task 
lower burden localization segmentation analysis variety restrictions usually restrictions background restrictions user restrictions imaging 
restrictions background commonly ones uniform distinctive dark background greatly simplifies segmentation task 
additional restriction user requirement wear long dark example simplify localization problem restrictions imaging hand focused cameras instance 
extraction hands background performed thresholding image directly 
restrictive setups usually employ color histogram analysis 
color space analysis applicable characteristic histogram footprint usually hsv color space human skin see instance 
mentioned approaches may require additional processing steps exclusion false candidates instance applications resort uniquely colored gloves markers hands fingers :10.1.1.32.4166
computational point view methods easier implement tend reduce naturalness interaction 
techniques take advantage motion analysis scene moving artifacts certain restrictions produced hand arm movements segment hand static objects example 
features extraction low level image features depends model gestures 
different models different types parameters features employed calculate parameters similar 
example hand arm models models finger trajectories require fingertips extracted features 
images hands arms features 
wide scope parameters previously described section features obtained images 
hand arm silhouettes simplest features widely 
silhouettes easily extracted local hand arm images restricted background setups 
case complex backgrounds techniques employ color histogram analysis similar hand localization 
examples silhouettes features hand model analysis example appearance techniques 
furthermore higher level features parameters extracted silhouettes image moments contours fingertips 
contours represent group features 
different edge detection schemes produce contours 
simple hand arm silhouettes color grey level images 
contours model appearance model analysis 
model gesture recognition form sets finger link candidates 
appearance models different parameters associated contours instance signatures polar functions points contour size functions 
commonly feature gesture analysis fingertip 
fingertip locations obtain parameters hand models appearance models 
detection fingertip locations space trivial 
simple effective solution detection problem marked gloves color markers designate characteristic fingertips see instance 
extraction fingertip location fairly simplified performed color histogram techniques 
different way detect fingertips pattern matching techniques templates images fingertips fingers generic cylindrical models 
techniques enhanced additional image features contours 
fingertip extraction algorithms characteristic properties fingertips image 
instance curvature fingertip follows characteristic pattern low high low 
heuristics fact finger represents foremost point hand deictic gestures instance 
indirect approaches detection fingertips employed instances image analysis specially tuned gabor kernels 
discussed features reflect possible features 
fact example combine different features form robust set effective parameter computation 
parameter computation computation model parameters stage hand arm gesture analysis 
gesture recognition systems stage followed recognition block 
hand arm tracking systems parameter computation stage usually produces final output 
type computation depends model parameters features 
hand arm model gesture models employ successive approximation methods parameter computation 
basic idea vary model parameters features extracted model match ones obtained data images see 
matching procedure usually begins palm ends matching fingers 
initial model parameters usually selected ones match generic hand position open hand example ones obtained prediction analysis parameters previous images sequence 
multitude features hand parameter computation huang hand silhouettes 
varied volumetric model parameters model silhouette matched hand image 
applications rely fingertip locations calculate model parameters 
lee kunii proved locations fingertips additional characteristic points palm uniquely define hand pose assumptions similar ones discussed section 
models similar approach derived authors ahmad kang example 
approaches contours edges guide successive adjustments model parameters selecting possible candidates finger arm links palm example gavrila davis 
model parameter adjustment model feature extraction feature comparison model features image features model parameters initial model hand arm model parameter computation successive approximation technique 
deformable template models usually similar successive approximation approach model position orientation principal components adjusted successive steps satisfactory match model image achieved 
simpler models direct mappings feature parameter spaces 
mappings explicitly defined image moments image silhouettes instance employ interpolation feature parameter correspondence tables usually obtained training procedure 
gesture recognition gesture recognition phase trajectory parameter space obtained analysis stage classified member meaningful subset parameter space 
problems associated recognition process optimal partitioning parameter space implementation recognition procedure 
problem partitioning raises new questions design meaningful partition parameter space reflects natural human perception different gesture determine class membership mappings parameter space 
related implementation issue recognition process question practical nature computationally intensive recognition procedure 
discuss questions detail 
partitioning gesture parameter space influenced primarily kind application gesture hci system intended 
optimal partitioning produces single class parameter space corresponding allowed gesture minimally intersect gesture class 
provide complete description general gesture partitioning reflect taxonomy hand arm movements temporal properties gestures 
temporal properties gestures proposition suggest temporal partitioning obey phase model 
furthermore model parameter space partitioning meaningful second temporal phase stroke model parameters initial final phase contain gestural information 
follow general taxonomy gestures proposition provide main taxonomical groups differentiation different mimetic gestures 
complete gesture model proposition induces parameter space allow partitioning rules produce set distinctive classes associated natural gesture 
hand model gesture models closest complete gesture model provide possibility general gesture recognition 
complete models wider class gestures cover 
hand systems appearance models fall short general gesture recognition 
parameter space models insufficient describe general gestures different general gestures similar difficult distinguish trajectories 
models assume restrictions 
restrict particular taxonomical group deictic gestures instance particular parameter space optimally partitioned respect gestures group 
second disregard dynamic properties gestures analyze static postures 
restrictive setups simple models exhibit satisfactory recognition performance 
perform actual partitioning methods 
time partitioning requires global hand arm motion known distinguishes temporal phases see proposition 
model parameter space partitioning performed number different classification methods 
methods require representative gesture class known 
class representative ad hoc determined learning examples procedure averaging means hidden markov models neural networks 
membership mappings classes minimum distance measure class representative 
hidden markov models hmm technique particularly appropriate case 
states hmm easily associated temporal gesture phases 
gesture hmm contain usually hidden states 
hmm training procedure built learning examples classification time parameter space recognition procedure uses dynamic time warping dtw temporally invariant classification 
far gesture models hmm employed appearance recognition notable success successful recognition scheme general classification distance membership functions time space context specific gesture :10.1.1.51.6538
established introducing grammatical element recognition procedure 
grammar reflect linguistic character communicative gestures spatial character manipulative gestures 
words certain subclasses gestural actions respect current previous states hci environment naturally plausible 
example user reaches performs valid manipulative gesture coffee cup handle handle visible user point view hci system discard gesture 
small number systems far exploits fact 
grammars simple usually introduce artificial linguistic structures build languages learned user 
question computational effectiveness recognition arises 
trade classical model complexity versus recognition applicability versus recognition time 
complex model wider class gestures general applied 
computational complexity increases recognition time 
model gesture models characterized parameters 
parameter calculation gesture analysis requires computationally expensive successive approximation procedures price somewhat lowered prediction type analysis 
systems models rarely show close real time performance 
example time performance ranges minutes single frame prediction element frames second 
applicability systems general hci gesture recognition arena superior simple appearance models 
appearance models usually restricted applicability narrow subclass hci applications enhancements computer mouse concept hand posture classification instance :10.1.1.51.6538
hand lower complexity computationally affordable easier implement real time applications 
applications systems interest gestural interface hci driven vast number potential applications 
hand gestures mode hci simply enhance interaction classical desktop computer applications replacing computer mouse similar hand held devices 
replace joysticks buttons control computerized help physically impaired communicate easily 
major impulse development gestural interfaces come growth applications situated virtual environments ves 
manipulative gesture communicative gesture gestural interface manipulation communication natural applications gestural interface hci 
gestures natural environment manipulative communicative gestures hci employed direct manipulations objects convey messages 
hand gestures natural environments manipulative actions communication see section 
communicative role gestures subtle hand gestures tend supportive element speech exception deictic gestures play major role human communication 
manipulative aspect gestures prevails current hci applications hand gestures portray manipulators virtual objects vos 
depicted 
vos computer generated graphics simulated objects windows abstractions computer controlled physical objects device control panels robotic arms 
perform manipulations objects hci combination coarse tracking communicative gestures currently 
example direct computer rotate object user interface may issue step command select object 
rotate object 
action uses coarse hand tracking move pointer vicinity object 
rotate object user rotates hand back forth producing metaphor rotational manipulation 
may pose question communicative gestures manipulative actions 
communicative gestures imply finite usually small vocabulary gestures learned manipulative ones natural hand arm movements 
answer question consider complexity analysis recognition type gestural models section section 
hand model gestural models suited modeling manipulative communicative gestures appearance models gestures applicable communicative ones 
hand model gesture models computationally expensive appearance models see section 
achieve usable real time performance resort purpose desirable appearance models gestures 
brief summary characteristics systems aimed applications table 
applications hand gestures hci meant yield manipulative actions 
gestures hci convey messages purpose analysis storage transmission 
video teleconferencing vtc processing american sign language asl provide opportunities 
vtc applications reduction bandwidth major issues 
typical solution problem uses different coding techniques 
techniques model coding image sequences described states position scale orientation instance physical objects scene human participants case vtc 
updates descriptors sent receiving computer generated model physical objects driven received data 
model coding vtc requires human bodies modeled appropriately 
depending amount detail desired achieved coarse models upper body limbs finely tuned models human faces hands 
modeling hand arm gestures substantial value applications 
application gestural modeling technique gestural commands complexity speed cd player control panel hand silhouette moments tracking fps virtual squash hand silhouette moments contour signature tracking metaphors fps fingertip template tracking alive template correlation tracking combined recognition facial expressions real time tv display control template correlation tracking fps heuristic detection pointing action tracking metaphor combined speech real time window manager hand pose recognition neural networks tracking metaphors real time image moments fingertip position tracking metaphors fps fingermouse heuristic detection pointing action tracking real time digiteyes dof hand model tracking fps silhouette zernike moments metaphors fps automatic robot instruction fingertip position grasp tracking robot manipulator control fingertip positions metaphors real time hand sign recognition discriminating features mdf images signs asl recognition silhouette moments grammar words fps frames second :10.1.1.51.6538
available table systems employ hand gestures hci 
choose speed measure complexity interpretation lack accurate measure different applications may implemented different computer systems different levels optimization 
recognition asl considered application naturally employs human gestures means communication 
applications play vital role communication people communication impairment 
device automatically translate asl hand gestures speech signals undoubtedly positive impact individuals 
practical reason asl testbed hand gesture recognition systems defined structure compared natural gestures humans 
fact implies appearance modeling techniques particularly suited asl interpretation proven applications 
prospects hand gesture hci vast 
applications mentioned section steps introducing hand gestures hci 
need development quite natural 
point important developmental issues exciting new applications hand gestures hci detail section 
directions fully exploit potential gestures hci environments class recognizable gestures broad possible 
ideally gesture performed user unambiguously interpretable allowing naturalness interface 
state art vision gesture recognition provide satisfactory solution achieving goal 
gesture hci systems time address narrow group applications symbolic commands hand postures mouse type pointing see section 
reason complexity associated analysis section recognition section gestures 
simple gesture models usually result real time gestural interfaces example pointing direction quickly silhouettes human hand relatively non restrictive environments 
seen find hand posture distinguish gesture simple image appearance silhouettes quite difficult 
interface systems hand model silhouettes gray scale images different hand postures 
silhouette interpreted reflection vertical axes silhouette 
silhouettes unambiguously define hand posture 
gesture models currently non existent 
models commonly employed hand tracking hand posture analysis 
analysis parameters hand model models result wider class hand gestures identified analysis linked appearance models 
leads point naturalness hci hand model gesture models offer prospect appearance models 
prospect presently hindered lack speed restrictiveness background hand model approaches 
issue adequately solved solution problem 
problem associated complexity model feature extraction 
fingertip positions useful feature see section difficult extract 
possible solution problem may employ skin nail texture distinguish tips fingers 
additionally computational complexity model parameters section reduced choosing optimal number parameters satisfies particular level naturalness employing parallelization computations involved 
aspects pertain construction natural hci need addressed 
aspects involves handed gestures 
human gestures naturally employ actions hands 
vision gesture systems focus attention single hand gestures exception systems developed krueger 
approach inevitable time 
analysis technique requires hands extracted global images 
handed gestures allowed ambiguous situations occur single hand case may occur dealt occlusion hands distinction indexing left right hand 
second versatile gesture analysis techniques model techniques currently exhibit major drawback speed 
techniques appearance principle handle handed gestures 
applicability usually restricted simple symbolic gestures require hands 
adequately address issue handed gestures effective analysis techniques considered 
techniques rely improvements classical techniques single hand gestures exploit interdependence hands performing gesture case hands performing single gesture assume symmetrical postures 
issue related handed gestures multiple 
successful interaction hci environments consider multiple users 
example virtual modeling task benefit enormously designers simultaneously participate process 
implementation multi user interface difficult issues face foremost analysis gestures 
analysis assumes defined workspace associated see proposition 
case multiple users intersection workspaces probable event 
differentiation users pose serious problem 
active computer vision cameras adaptively focus area interest may offer solution problem 
address issue interaction multiple communication modes hci related hand gestures 
hand gesture speech body movement gaze means communication see section 
natural communication humans concurrently involves modes communication accompany 
instance come gesture usually accompanied words come 
example sentence notice control panel deictic gesture involving index finger pointing particular control panel gaze directed panel 
seen examples communicative gestures affirm complement meaning speech message 
fact literature reports psychological studies human communication interaction speech gestures means communication explored 
leads multimodal interaction rendered useful hci see 
affirmative hand gesture speech gestures speech virtual environment gaze multimodal gesture speech hci system 
photograph courtesy rich illinois state journal register springfield illinois 
reduce uncertainty speech hand gesture recognition provide robust interface 
gestures complement speech hand carry complete communicational message interpreted speech possibly gaze 
multimodal messages reduce complexity increase naturalness interface hci 
example designing complicated gestural command object selection may consist deictic gesture followed symbolic gesture symbolize object pointed hand supposed selected simple concurrent deictic gesture verbal command 
number studies explore multimodality hci steadily increasing past couple years 
time integration communication modes systems performed commands portions different modes independently recognized 
interface structure simplified way information pertaining interaction modes lower levels probably lost 
utilize multimodal interaction levels new approaches fuse multimodal input analysis recognition considered 
study interaction humans machines attracted principal interest researchers past years 
coincides burst activity surrounding applications situated abstractions natural surroundings virtual environments 
widely interaction devices time keyboards mice joysticks lower ease naturalness interaction hinder effectiveness environments 
direct natural means interaction speech hand gestures gaze proven play essential role solution problem 
focus discussion means hand gestures 
visual interpretation hand gestures yields interesting non potential solution problem interpretation hci computer controlled environments 
number different approaches video hand gesture recognition grown tremendously years 
need analysis aspects gestural interaction emerged 
addresses task presenting unified approach modeling analysis recognition hand gestures visual interpretation 
effective model hand gestures hci take account characteristics natural hand gestures 
propose complete model hand gestures reflects spatial dynamic properties human hand gestures accommodate natural types 
consider classes models employed far purpose interpretation hand gestures relies models human hand second utilizes appearance human hand image 
investigation model parameters analysis features influence recognition hand gestures light naturalness preferred hci 
hand models offer way complete modeling hand gestures stage lack simplicity computational efficiency highly desirable possible accomplish appearance models 
study motivated potential application hand gestures natural human computer interface 
applications hand gesture interaction systems today infancy 
find current systems employ hand gestures manipulation objects complexity interpretation gestures dictates achievable solution gestures convey manipulative actions today usually communicative type 
additionally hand gestures hci restricted produced single user system 
consequently effectiveness interaction 
suggest methods elevate effectiveness gestural interface hci show integration hand gestures speech gaze naturally related modes communication provide attractive potential solution problem 
substantial research effort connects advances computer vision basic study human computer interaction needed develop effective natural hand gesture interface 
acknowledgments supported part national science foundation iri part electric industries 
hauptmann gesture speech graphics manipulation international journal man machine studies vol 
pp 
feb 
tsai virtual prototyping mechanical system concurrent engineering concurrent engineering tools technologies mechanical system design vol 
pp 


lu swift system workbench integrating facilitating teams international journal intelligent cooperative information systems 
baudel lafon charade remote control objects free hand gestures communications acm vol 
pp 

fels hinton glove talk neural network interface data glove speech synthesizer ieee transactions neural networks vol 
pp 
jan 
sturman zeltzer survey glove input ieee computer graphics applications vol 
pp 
jan 
gesture recognition dataglove proceedings ieee national aerospace electronics conference vol 

wang cannon virtual effector pointing system point direct robotics inspection surface flaws neural network skeleton transform proceedings ieee international conference robotics automation vol 
pp 
may 
kendon current issues study gesture biological foundations gestures motor semiotic aspects 
eds pp 
lawrence erlbaum assoc 
mcneill levy conceptual representations language activity gesture speech action studies deixis related topics klein eds wiley 
quek eyes interface image vision computing vol 
august 
quek vision hand gesture interface virtual reality software technology conference pp 
aug 
freeman weissman television control hand gestures proc 
zurich pp 
june 
huang vision hand modeling tracking proceedings international conference computer vision cambridge ma june 
goldberg merialdo automatic face gestural recognition video indexing proc 
zurich pp 
june 
image analysis model sign language coding progress image analysis processing ii proceedings th international conference image analysis processing pp 

kishino stereo description generalized cylinder complexes occluding contours systems computers japan vol 
pp 

gavrila davis model tracking recognition human movement multi view approach proc 
zurich pp 
june 
ed hand vol 

philadelphia pa sanders 
thompson biomechanics hand perspectives computing vol 
pp 
oct 
vision hand modeling gesture recognition human computer interaction master thesis university illinois urbana champaign 
lee kunii constraint hand animation models techniques computer animation pp 
tokyo springer verlag 
lee kunii model analysis hand posture ieee computer graphics applications pp 
september 
rehg kanade digiteyes vision human hand tracking tech 
rep cmu cs school computer science carnegie mellon university 
rehg kanade visual tracking self occluding articulated objects tech 
rep cmu cs carnegie mellon university school computer science cmu pittsburgh pa december 
ahmad usable real time hand tracker ieee asilomar conference 
vision hand pose estimation proc 
zurich pp 
june 
ritter learning recognize hand postures perspective pixel images artificial neural networks alexander taylor eds north holland elsevier science publishers 
cootes taylor cooper graham active shape models training application computer vision image understanding vol 
pp 
january 
kervrann heitz learning structure deformation modes nonrigid objects long image sequences international workshop automatic face june 
lanitis taylor cootes ahmed automatic interpretation human faces hand gestures flexible models proc :10.1.1.17.6274
zurich pp 
june 
darrell pentland space time gestures proceedings computer vision pattern recognition conference 
darrell pentland attention driven expression gesture analysis interactive environment proc 
zurich pp 
june 
crowley coutaz finger input device augmented reality proc 
zurich pp 
june 
cho dunn learning shape classes ieee transactions pattern analysis machine intelligence vol 
pp 
sept 
controlling computers gestures proceedings virtual reality systems april 
fox real time interaction degrees freedom monocular image flows proc 
zurich pp 
june 
cui weng learning hand sign recognition proc 
zurich pp 
june 
moghaddam pentland maximum likelihood detection faces hands proc 
zurich pp 
june 
hunter jain recursive identification gesture inputs hidden markov models proceedings second ieee workshop applications computer vision fl pp 
december 
starner pentland visual recognition american sign language hidden markov models proc :10.1.1.51.6538
zurich pp 
june 
hunter jain vision hand gesture interpretation recursive estimation proceedings th asilomar conference signals systems computer 
freeman roth orientation histograms hand gesture recognition international workshop automatic face gesture recognition june 
ahmad tresp classification missing uncertain inputs proceedings international conference neural networks vol 
pp 

davis shah gesture recognition tech 
rep cs tr department computer science university central florida 
kuno sakamoto shirai vision human computer interface user centered frame proceedings iros pp 

fukumoto mase finger pointer pointing interface image processing computers graphics vol 
pp 

quek zhao finger mouse freehand pointing interface proc 
zurich pp 
june 
kjeldsen visual hand gesture recognition window system control proc 
zurich pp 
june 
cipolla okamoto kuno robust structure motion motion parallax proceedings international conference computer vision pp 
ieee 
novel gestural input device virtual reality ieee annual virtual reality international symposium pp 
ieee 
krueger environmental technology making real world virtual communications acm vol 
pp 
july 
uras verri hand gesture recognition edge maps proc 
zurich pp 
june 
davis shah visual gesture recognition iee proc 
vis 
image signal process vol 
pp 
april 
kishino interactive computer graphics driven verbal instructions previous current activities atr computers graphics vol 
pp 

davis shah determining hand motion proceedings th asilomar conference signals systems computer 
new ways operating computer proc 
zurich pp 
june 
kang ikeuchi automatic robot instruction perception recognizing grasp observation ieee transactions robotics automation vol 
pp 
aug 
hunter jain posture estimation reduced model gesture input systems international workshop automatic face gesture recognition june 
adam virtual reality ieee spectrum vol 
pp 

krueger artificial reality ii 
addison wesley 
ishibuchi kishino real time hand gesture recognition prediction model proceedings international conference systems man cybernetics le france pp 
october 
human interface recognition human gestures image processing 
recognition gesture specify moving directions ieee international workshop robot human communication pp 

band video communication system transmission sign language ordinary telephone lines image sequences processing dynamic scene analysis huang ed pp 
springer verlag berlin heidelberg 
kishino intelligent image coding communications realistic sensations trends ieice transactions vol 
pp 
june 
blake yuille active vision 
mit press cambridge ma 
sharma active vision visual servoing review ieee workshop visual servoing achievements applications open problems may 
levy mcneill speech gesture discourse discourse processes pp 

gesture communication coordination gaze speech communication monographs vol 
pp 
december 
sharma huang pavlovi multimodal framework interacting virtual environments proc 
symp 
human interaction complex systems north carolina september 
vo waibel multi modal human computer interface combination gesture speech recognition adjunct proceedings interchi april 
vo houghton yang bub meier waibel multimodal learning interfaces arpa spoken language technology workshop january 
sakamoto multimodal human communication ieice transactions information systems vol 
pp 
june 
