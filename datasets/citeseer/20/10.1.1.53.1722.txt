tuple classifier ignore micha richard rohwer dept computer science applied mathematics aston university birmingham uk june tuple pattern recognition method tested selection large data sets european community statlog project results compared reported algorithms project tested 
results indicate ultra fast memory method viable competitor include optimisation neural network algorithms theory memory neural computing highly developed terms statistical theory 
popular style neural computation apply optimisation techniques suitably designed neural network models 
advantages performance reasonably firm theoretical underpinnings suffers computational requirements 
alternative style randomly selected features 
theory developed methods offer overwhelming advantage computation speed 
oldest memory methods tuple classifier bledsoe browning bledsoe browning 
method tested data sets previously european community esprit statlog project michie test classification algorithms 
results add body practical experience rohwer rohwer aleksander lends weight view sophisticated methods performance advantage offer 
methods include popular neural network methods better theoretical foundations multi layer perceptron radial basis functions 
appear memory methods deserve intensive study 
tuple recognition method tuple recognition method known type neural network 
forms basis commercial product aleksander 
method classifying binary patterns regarded bit strings fixed length important restriction efficient preprocessing method tailored generalisation properties converting scalar attributes bit strings 
method defined section 
section defines tuple classification algorithm 
say sets distinct bit locations selected randomly 
tuples 
restriction pattern tuple regarded bit number identity tuple constitutes feature pattern 
standard tuple recogniser operates simply follows pattern classified belonging class features common training pattern class 
case general rule class assigned unclassified pattern argmax theta ffi ff ff set training patterns class theta theta ffi kronecker delta ffi 
ff th feature pattern ff gamma th bit th bit location th tuple 
classes distinguish system implemented network nc nodes random access memory ram term 
memory content address ff th node allocated class set theta ffi ff ff usual case bit content set pattern feature ff unset 
recognition accomplished summing contents nodes class addresses features unclassified pattern 
pattern assigned class argmax include stochastic generalisations prams tuple recognition algorithm applied 
considered 
relaxing requirement tuple different bit locations amounts introducing mixture differently sized tuples 
note restriction disallow single pattern component shared tuple 
comma unconventional extra clarity 
discussion algorithm tuple classifier memory method akin kanerva sparse distributed memory kanerva 
methods differ optimisation methods back propagation error multi layer perceptrons important ways 
firstly hidden representations features selected randomly secondly training simple task involving features 
differences give memory methods advantage training speed 
radial basis functions obtain part speed advantage selecting features randomly broomhead lowe multi layer perceptrons trained faster little loss performance fixed random weights hidden layers gallant smith sutton whitehead 
give speed simplicity training mere provides 
theoretical understanding memory models tuple method particular aleksander flanagan bledsoe bisson dodd level statistical sophistication available optimisation methods mackay 
tuple network trained optimisation luttrell rohwer statistical tools brought bear far failed comprehensively explain quantify success 
experimental results reported encourage effort area 
interesting note sheer simplicity may memory methods biologically implausible optimisation methods 
course tuple method uses features specialised digital hardware principle may apply just biologically computable features 
architectural parameters 
adjustable parameters tuple recognition method tuple size number tuples threshold 
architectural parameters neural network algorithms shortage theoretically convincing prescriptions setting 
argue basis sampling fluctuations results improve upper bound increasing practical experience shows values adequate 
optimal settings related measurable things amount training data 
small easily saturation condition recogniser fails rohwer 
having large thought correlations bits pattern relevant class discrimination size address space node large compared number training patterns performance decline due overly sparse memory usage rohwer lamb 
experience data sets patterns indicates performance best 
better theoretical tuple recognition algorithm highly desirable algorithm high speed entirely practical just run tests plausible parameter settings find suitable ones 
preprocessing scalar attributes classifies bit strings attributes patterns statlog data sets real numbers integers 
known aleksander generalisation behaviour generalised hamming distance bit strings 
generalisation numerical attributes related arithmetic differences important transform numbers bit strings way numerical proximity transformed hamming proximity 
memory efficient method tailored generalised hamming distance underlying generalisation provided ko combination cmac gray coding techniques 
prescription encoding integer concatenate bit strings th gamma rounded expressed gray code 
gray code integer obtained bitwise exclusive expressed ordinary base number rounded 
provides representation ak bits integers gamma inclusive integers differ codes differ hamming distance jx gamma yj arithmetic distance corresponding hamming distance experiments reported giving bit representations integers 
scalar attributes linearly rescaled rounded obtain integers interval 
letter data set see table attributes take values reasonable encoding strings bits cmac gray procedure anyway convenience uniformity 
selection pre processing statlog data sets european community esprit project statlog project designed carry comparative testing evaluation classification algorithms large scale applications 
data sets estimate performance procedures 
described detail michie 
larger data sets samples randomly split training testing partitions 
different methodologies cross validation bootstrap applied smaller data sets 
study large data sets summarised table 

name largest prior training patterns description classes attributes testing patterns real classify measurements simulated large scale power system leading stable unstable behaviour 
cut real measurements candidate segmentation point joined handwritten text 
classify suitable cut point 
commercially confidential data 
cut real best attributes stepwise regression cut 
technical commercially confidential 
appears generated decision tree 
attribute values 
dna boolean sequences nucleotides valued classified categories 
integer pixel regions landsat images 
intensities spectral bands 
classified land uses central pixel 
images chromosomes reduced features 
real belgian ii smaller simulation 
attributes thought informative omitted simulation 
real classify environmental attributes presence flies 
letter valued images typed capital letters described real numbers discretised integers 
shuttle real classification problem concerning position space shuttle 
noise free data 
table descriptions data sets 
experiments threshold set experiments reported set tuples 
experiment repeated selection small tuple sizes 
results reported averages different random input mappings best involves test data set architectural parameter strictly speaking experiments show generalisation performance purely directly 
subsequent re input mapping completely network connectivity completely re defining random features discrimination 
experiments demonstrate generalisation input mapping difficult argue new test data randomly drawn distribution severe effect selecting new features randomly data 
procedural expedient felt justified 
computation time requirements insignificant experiments carried program sun sparc workstation 
example tuple network trained attribute training patterns data set seconds 
sixteen seconds needed just read data cmac gray conversion floating point attributes final train 
testing patterns takes slightly longer seconds loop classes needed loop tuples 
detailed timing statistics published algorithms statlog project clear popular neural network algorithms back propagation relatively fast radial basis functions slow comparison 
algorithm highly important faster special purpose parallel hardware designed purchased aleksander 
storage requirements moderate cases 
extreme case shuttle kb ram class needed 
results classification results algorithm attempted data set 
table gives brief description algorithm symbol represent 
classification error rates increase left right scaled separately data set equal error rate trivial method guessing class highest prior probability ignoring input pattern 
remarked section results plotted tuple recognition algorithm averages randomly selected input mappings 
corresponding standard deviations plotted error bars obscured dots representing means 
best data sets gave performance broadly comparable algorithms including popular neural network methods back propagation radial 
ffl tuple recogniser 
discriminators 
back propagation hidden layer mlp 
radial basis functions 
cascade correlation 
phi smart projection 
omega pairwise linear discriminators 
psi logistic discriminant 
ff quadratic discriminant 
fi linear discriminant 
methods related density estimation 
ff castle probabilistic decision tree 
fi nn nearest neighbors 
fl lvq learning vector quantisation 
ffi kohonen topographic map 
naivebayes estimate assuming independent attributes 
alloc function density estimator decision trees 
newid decision tree ac decision tree cal decision tree cn decision tree decision tree cart decision tree cart variation decision tree decision tree table synopsis algorithms symbols 
error rate default error rate classification performance shuttle letter dna technical cut cut ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl ffl fi fi fi fi fi fi fi fi fi fi fi phi phi phi phi phi phi phi phi phi phi phi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ff ff ff ff ff ff ff ff ff ff psi psi psi psi psi psi psi psi psi psi psi omega omega omega omega omega omega omega omega omega omega omega ff ff ff ff ff ff ff ff ff ff ff fl fl fl fl fl fl fl fl fl fl fi fi fi fi fi fi fi fi fi fi fi results tuple ffl algorithms 
algorithm codes appear table 
classification error rates increase left right scaled separately data set equal error rate trivial method guessing class highest prior probability ignoring input pattern 
arrows indicate cases performance worse 
basis functions 
better worse alarming margin 
relative performance methods jumps similar extent eye judge 
sophisticated attempt find systematic performance differences statlog algorithms michie turn gathered judgements inspection 
worst data sets tell different story 
algorithms poorly data sets failed spectacularly 
scarcely better method assigning test pattern priori probable class 
news results suggest hypothesis new type data relied reasonably perform badly obvious 
research needed determine precisely sort data handle results suggest couple guesses 
possibility highly skewed distribution class priors problematic cut cut data sets probability concentrated classes technical data set concentrates quarter probability just classes 
shuttle data skewed 
possibility poorly informative attributes problem 
comparison results particularly suggests uses subset attributes selected expert opinion informativeness 
inappropriate results draw unequivocal perform better multi layer perceptrons letter data set usually scope improving method parameters implementational details 
glance justify perform compared methods 
consequently foolish embark hours long back propagation run spending minute simulation 
results suggest hypothesis considered theoretical experimental 
tuple recognition method fails completely obviously fail fails pattern attributes relatively uninformative highly skewed class priors contributing factor failures 
appear memory learning algorithms general tuple classifier particular hold great promise ultra fast systems giving competitive performance types data 
lends urgency problem strengthening theoretical foundations techniques 
authors grateful louis universite de liege useful correspondence permission report results data sets trevor booth australian csiro division forestry permission report results data set reza daimler benz ulm germany permission report technical cut cut data sets 
aleksander 
guide pattern recognition random access memories 
computers digital techniques 
aleksander thomas 
radical step forward image recognition 
sensor review 
ko 
enhanced tuple approximators 
neural network workshop 
bledsoe bisson 
improved memory matrices tuple pattern recognition method 
ieee trans 
electronic computers 
bledsoe browning 
pattern recognition reading machine 
pages proceedings eastern joint computer conference 
broomhead lowe david 

multi variable functional interpolation adaptive networks 
complex systems 
flanagan rahman 
model behaviour tuple ram classifiers noise 
journal intelligent systems 
gallant smith 
random cells idea time come gone come 
pages ii ii butler eds ieee international conference neural networks 
san diego ieee 
kanerva 
sparse distributed memory 
cambridge ma mit press 
luttrell 
gibbs distribution theory adaptive tuple networks 
pages aleksander taylor 
eds artificial neural networks 
elsevier 
mackay 
bayesian interpolation 
neural computation 
michie spiegelhalter taylor 
eds 

machine learning neural statistical classification 
prentice hall 
rohwer 
bayesian treatments tuple recognition method 
tech 
rept 
ncrg 
dept computer science aston university birmingham uk 
ftp cs aston ac uk pub docs ps unix compressed postscript 
rohwer 
phoneme classification boolean networks 
pages mariani 
eds proceedings european conference speech communication technology 
paris cep albany st edinburgh scotland 
rohwer lamb 
exploration effect super large tuples single layer 
pages 
ed proceedings neural network workshop computing logical neurons 
sutton whitehead 
online learning random representations 
tenth international conference machine learning ml 
roland rohwer richard 

efficient training data tuple recognition method 
electronics letters 
dodd 
recognition experiments typed numerals envelopes mail 
pattern recognition 

experiments tuple method pattern recognition 
ieee transactions computers 
