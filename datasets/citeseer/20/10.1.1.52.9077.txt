performance caching proxies presents performance study state art caching proxy called squid 
instrumented squid measure request network disk activities conducted series experiments large web caches 
discovered interesting consistent patterns wide variety environments 
data analysis essential understanding modeling tuning performance proxy server 
web clearly environment global information distribution exchange sharing 
caching proxies playing important role handling web traffic 
web caching key methods coping exponential growth web 
caching proxies usually installed clients accessing internet single path 
proxy keeps copy objects web documents ftp downloads passed 
client requests object network proxy may able serve local copy object fetching object original source 
serving local copy object proxy saves bandwidth outbound network connections potentially reduces response time 
local copies objects usually stored disks 
storage capacity typical proxy gigabytes 
bandwidth savings guaranteed improvement response time 
caching proxies employ special algorithms optimize retrieval objects disk storage send clients 
caching proxy bottleneck clients immediately experience network delays 
proxy handle intense traffic performance degradation 
sophisticated techniques developed improve proxy performance heavy load 
little known performance real proxies 
caching proxies developed public domain software web 
pioneers time means experimenting alternative designs performance solutions 
rely common sense extensive borrowing design performance ideas applications 
public proxy software mature shift focus adding new essential features performance enhancements 
growing number commercial caches squeezing public domain products especially enterprises handle large volumes web traffic interesting case 
commercial products claim performance superiority public software limited interest research community closed design proprietary protocols 
research contributions performance analysis essential understanding state art caching proxy 
instrumented version squid measures request network disk activities 
detailed measurements allows depth studying major proxy components 
identify quantify network disk performance degradation high load periods 
demonstrate various classes requests different impact proxy resources optimization decisions take account 
study performance caching proxies variety environments able identify common performance patterns 
show level caching hierarchy affects proxy performance 
measurements observations ffl performance modeling proxy server ffl simulating workload proxy server ffl performance tuning existing proxies ffl identifying potential bottlenecks cache administrators prefer squid leader public domain caching commercial alternatives 
performance advantages commercial products questionable public caching proxies easy customize 
commercial proxy supports internet cache protocol allows cooperation proxies cache hierarchy 
ffl evaluating current design decisions potential enhancements analysis unique cover variety hardware operating systems caching hierarchy levels workloads concentrating single proxy server 
research data collected relatively short time interval increase relevance 
terminology web caching modern invention uses special terminology name objects interest 
unfortunately terms misused misinterpreted 
give interpretation commonly web caching terms 
group terms logically alphabetically 
client originator request particular web object client request short message containing location desired object possibly attributes 
primary server just server web server keeps original copy document 
note cooperative caching server just proxy depending context 
object object cached served cache proxy reasons 
example reload request web browser client indicates document served cache 
dynamic documents may change content client request server indicates document cached 
caching policy proxy may admit certain documents caching 
example big documents 
negative caching storing indication client request particular object resulted error 
object requested short period time error reply sent client verifying current situation 
pipelining requests allowing data stage request processing stage prior completion stage 
technically pipelining request stages requests 
hit client request successfully satisfied transmitting document content primary server 
hit hit reply code 
occurs proxy reply contains document content errors detected 
common type hit 
hit ims hit hit reply code 
occurs client requested object modification date certain time 
proxy believed object modified time 
small notification message sent back client 
client request hit 
particular request satisfied due error usually treated 
see negative caching exception negative hit hit negatively cached document 
swap request swap swap request swap request internal proxy request swap load object disk memory 
swap request may result disk read requests 
swap request internal proxy request swap store object disk memory 
swap request may result disk write requests 
document hit ratio hit rate ratio number hits total number replies sent proxy specified time interval 
byte hit ratio byte hit rate bhr ratio total size hits total size replies sent proxy specified time interval 
swap ratio ratio number swap requests total number swap requests performed specified time interval 
design caching proxy designs architectures caching proxies vary 
important design decisions properties shared proxies 
properties direct impact performance proxy 
incomplete list properties common methods implementation 
concurrent processing client requests modern proxies process multiple client requests parallel 
approach implies proxy block pending request 
common methods supporting concurrency 
utilizes concurrent processes threads process request 
second relies non blocking network disk os 
approach supposed improve scaleup number concurrent requests mrg may reduce expensive context switch overhead lazy garbage collection proxies clear cache old entries lazy mode 
separate process logical thread scans cache entries free storage space new traffic 
speed scan may depend current space utilization avoid storage overflows 
alternative lazy garbage collection ondemand clean triggered incoming traffic storage space accommodate new cache entries 
demand garbage collection believed create peaks disk load large documents enter cache lot space cleaned 
experiments show variable speed lazy garbage collection may suffer problem 
lru th caching policy caching proxies purge entries clean cache 
lru algorithm augmented threshold parameter lru th avoid caching large documents 
value parameter depends proxy environment 
example proxies serve lot netscape microsoft binaries may high value threshold binaries 
larger values threshold favor byte hit ratio smaller values may increase document hit ratio 
implement lru policy maintain list entries sorted access times 
list searchable entry located pushed top list accessed 
academic approach may expensive support 
practice sorted list replaced global hash table entries sorted 
lru policy implemented purging entries bucket hash table 
actual caching policies far complex lru th 
usually special procedure verifying freshness document 
cached relatively old document requested proxy may check primary server cached version date 
verification algorithms take consideration factors recency 
example modification time document expiration time may considered 
study concentrates squid caching proxy 
squid state art proxy derived harvest object cache project cd 
squid uses single process process request implemented non blocking squid keeps metadata virtual memory maintains level disk cache 
squid proxies form caching hierarchies internet cache protocol icp 
squid runs popular unix platforms 
detailed description squid architecture available squid 
methodology patch performance data collected patched version squid caching proxy patch 
patch enabled squid log detailed request measurements network disk activities 
get request patch logged information request stages 
client connect accepting connection client reading client request 
network card queuing time prior accept system call measured 
non blocking approach may avoid request context switching completely 
example squid context switch client request perform dns lookup implemented separate process avoid blocking dns lookups 
proxy connect establishing connection primary server sending request document 
dns lookup delays included 
server reply receiving reply primary server closing connection 
proxy reply sending reply client closing connection 
swap swapping document disk memory 
includes delay opening file 
swap swapping document memory disk 
includes delay creating file 
activity patch recorded measurements 
ffl start activity timestamp activity microsecond resolution 
ffl delay example time took read page file receive block data network 
delay measured start activity microsecond resolution 
ffl total delay time took complete activity microsecond resolution 
example total time read document disk receive document primary server 
delays happened start activity included 
fields may contain null values corresponding request participate certain activity 
important note patch increase proxy load 
time measurements performed squid internal time extra system calls 
overhead adding extra bytes standard log entries considered negligible 
experiment framework instrumented version squid run proxies 
proxy collected day worth logs 
log files collected ran analyzing scripts extract useful statistics 
produce meaningful results percentiles distributions possible 
median th percentile estimate average value mean unreliable data includes large isolated peaks 
measurements grouped min slots 
slots allowed detect spikes proxy performance having entries produce meaningful median 
periods light load number requests statistically small ignored 
instances discussed unusual patterns proxy administrator isolate interesting performance phenomena anomalies caused configuration bugs network outages participating proxies squid proxies participated study 
proxy collected day worth logs 
proxies represent levels caching hierarchy starting leaf university proxies root proxy nlanr international hierarchy 
expanding collection new proxies experiments 
summarize information participating proxies tables 
results collected days worth logs 
participating proxies submitted day logs sv profiled week 
logs analyzed 
hour log performed measurements 
measurement trace distribution single performance parameter client connect delay versus time distribution network transfer size 
grouped related measurements experiments 
example file size distribution experiment contains size distributions various classes documents 
note experiments previously collected logs 
require separate run squid 
compared experiments different proxies different days proxy 
comparisons revealed consistent patterns identified performance anomalies 
number possible comparisons large 
record start client start swap activities patch re uses standard log fields millisecond resolution 
proxy country type machine total total disks disks total storage os date memory controller capacity mb gb sv usa root dec sys log dec oct alphaserver cache unix mhz rev netherlands top ibm rs scsi sys log aix sept level model ssa cache ruu netherlands leaf sun sunos sept sparcstation sun norway top sgi scsi irix oct level challenger mhz mips uit norway leaf sgi scsi irix oct challenger mhz mips mexico inter intel ide freebsd oct mediate pentium mhz australia leaf sparc sys cache sunos oct mhz cache table proxy setup proxy squid cache memory disks cache capacity average object objects bucket max object version mb low high cache gb low high kb mb sv ruu uit table squid parameters proxy documents unique documents unique clients unique servers sv ruu uit table daily traffic automate process generating graphs grouping experiments 
technically feasible experiments proxies 
selected proxies base line presentation sv ruu 
selected proxies represented levels caching hierarchy busiest proxies collection 
entire set experiments publicly available interesting comparisons stats 
section presents series experiments 
experiment include graphs selected proxy sv left middle ruu right 
essential note proxies express similar performance patterns noted 
shall see patterns shared proxies despite differences absolute numbers 
graph scale experiment possible 
graphs different scales show important details 
default graphs section hour data 
selected days load high squid running problems days 
time day measurements coordinated universal time cut local time 
related experiments grouped subsections assist readers orientation material 
traffic patterns section group experiments depend caching proxy 
experiments study environmental factors distribution files sizes traffic intensity 
transfer size distribution file size kb hits misses swap swap swap file size kb hits misses swap swap swap file size kb hits misses swap swap swap transfer sizes start experiments plotting distributions transfer sizes various categories 
show real traffic file size distribution count access document 
document accesses counted document cached twice hit document cache 
swap curve shows file distribution cached documents counting swap swap requests 
transfer sizes essential estimating network disk bandwidth requirements 
note network transfers smaller kb 
half disk transfers smaller kb 
note squid uses kb pages transfers 
misses larger hits large transfers large documents popular big unpopular files counted misses rarely counted hits access document counted small popular files counted times hits misses 
swap requests larger hits significant number ims hits small retrieved disk 
swap transfers probably larger misses number relatively small documents high 
measurements needed support statement 
file size distribution disk capacity requirements depend files cached files transferred swapped 
file sizes graph shows distribution file sizes hits misses swap requests 
show file size distribution traffic count access document 
file size kb hits misses swap swap swap file size kb hits misses swap swap swap file size kb hits misses swap swap swap file sizes distribution file sizes important estimating memory requirements squid 
number entries memory resident hash table corresponds number documents fit disk cache 
disk cache size usually determined available disk capacity 
hash size calculated dividing disk cache size average document size srn 
entries available memory disk cache size decreased avoid swapping 
common approach estimate average size document considering entries access log file calculating average transfer size 
single popular document may counted times 
non documents stored hash table counted 
transfer sizes file sizes may lead underestimation memory requirements severe degradation performance due swapping 
note median size cached file level swap curve kb 
participating proxies kb configuration 
kb average file size comes mean transfer size calculations adjusted ims hits 
cache administrators considering quite reasonably lowering number 
average proxies swap larger objects swap 
inevitable 
proxies cache large objects get decent byte hit ratio 
proxy traffic intensity hour hits misses hour hits misses hour hits misses traffic intensity number client requests received proxy determines stress proxy component network disk storage subsystem 
shall see performance patterns follow traffic intensity 
detected types proxy load 
root proxy sv experiences relatively small variations load hour period 
proxies bell shaped curves highest load day lowest load night 
possible utilize proxy idle hours improving performance peak load 
example alternative caching policy idle time refresh content cache day statistics rs 
prefetching documents cache possibility 
root proxy serves international traffic time zones 
consequently idle periods 
may speculate may tendency constantly loaded top level servers share international web traffic grows traffic uniformly distributed 
important analyze performance proxy day 
idle periods ignored cases 
peak periods correspond excessive load studied care real proxies may overloaded show extreme performance patterns happen normal conditions 
aggregate performance section measurements show aggregate proxy performance 
performance depends proxy components 
contributions individual components studied sections 
concurrent requests hour hits misses hour hits misses hour hits misses concurrent requests number concurrent requests reflect ability proxy handle traffic 
time takes process request increases load 
leads larger number concurrent requests system 
actual increase depends request type hard predict 
note ratio concurrent hits misses quite different ratio traffic intensity 
misses slower hits retrieved primary server directly proxy 
hits rarely contact primary servers read data disk ims hits 
slow speed misses major consumer proxy resources 
ratio concurrent misses hits system may high higher ratio misses hits traffic 
identifying major source resource consumption essential optimization purposes 
example increase squid page size hit requests reduce number os hit 
optimization may improve hit response time preserving total memory requirement number concurrent hits smaller misses 
hand similar increase misses may significantly increase total memory requirement 
important observation increase number concurrent request root proxy peak load 
sv works limit resources 
small increase traffic intensity may lead severe performance degradation 
behavior typical proxies studied 
ideally proxy requires upgrade share load sibling proxy 
request response time hour hits misses hour hits misses hour hits misses request response time decreasing response time major function caching proxy 
results show average response time hit may times smaller proxy decrease response time 
average improvement savings average response time compared misses case depends hit ratio 
sv proxy improved response time average request 
leaf proxies achieve improvement 
clear combination fast hits slow misses affects user perception qos 
hit response times increase sharply peak load 
experiments identify network proxy components responsible effect 
request response time vs transfer size file size kb hits misses file size kb hits misses file size kb hits misses request response time vs transfer size savings response time depend document size 
interestingly savings response time come hits smaller size tcp socket output buffer kb sv kb 
effect tcp buffer visible ruu proxy 
ruu proxy observe effect 
note response time hit increase size reaches tcp buffer size 
savings files larger tcp buffer marginal exist 
probably set tcp buffer size hits maximum kb 
note increase affect total memory requirement number concurrent hits relatively small 
misses benefit tcp buffer hits 
tcp buffer flushed periodically network full 
application responsible filling buffer fast achieve high utilization 
misses fetched primary servers data comes slowly fill buffer flushed 
large hits improve response time 
responsible higher byte hit ratio 
consequently fundamental tradeoff improving response time limiting maximum document size caching smaller objects saving bandwidth caching large objects 
hits analysis section concentrates analysis hit requests 
hits deployment proxies worthwhile 
increasing number hits optimizing hit response time significantly improve qos 
hits major impact proxy performance 
hit ratios document hit ratio affects savings request response time proportion swap swap requests 
byte hit ratio bhr characterizes savings network bandwidth determines disk bandwidth requirements 
average higher bhr 
interestingly ratios depend traffic intensity 
may expect number client requests increases number hits 
case 
apparently peak hours user population access patterns different light load hours population different 
phenomenon requires investigation 
hit ratios may depend time day implies user population access patterns vary time 
new models experiments needed study variation 
hour doc byte hour doc byte hour doc byte hit ratios hits classification hour disk hits ims hits mem hits neg hits hour disk hits ims hits mem hits neg hits hour disk hits ims hits mem hits neg hits hits classification profiling stages individual requests able identify classes hits ffl disk hits hits resolved reading content disk 
replies considered 
ffl memory hits hits resolved sending content memory 
requested document hot memory buffer disk activity necessary 
replies considered 
ffl ims hits hits resolved sending reply client 
see terminology section details ffl negative hits hits reply code 
see terminology section details hit classes original server contacted check freshness cached object 
algorithms determine freshness verified complex factors document expiration modification times specific urls 
note classes intersect rare cases covered classification 
illustrate relative importance class plot percentage hits class represents 
clearly disk ims hits responsible hits 
average share ims hits large increases caching hierarchy level leaf top level root proxy 
optimizations take account portion ims hits may require different techniques depending hierarchy level 
ims hits retrieved disk important isolate disk hits studying impact disk performance hit response time 
low percentage memory hits indicates keeping documents hot memory buffer improve performance squid 
believe hits object come bursts 
may sense keep new documents memory buffer short time case requested soon 
experiments show number hits usually memory hits studied buffer sizes new objects swapped disk soon possible free space incoming traffic 
proxy showed hits 
currently investigating reasons different performance 
negative caching considered important feature squid 
measurements show percentage negative hits small 
invalid requests results negatively cached may large response times 
additional experiments needed show response time reduction invalid requests worth caching 
outbound network misses hits request data primary servers proxies 
section studies performance outbound network crucial influence request response time proxy resources consumption 
concurrent outgoing connections hour hits misses hour hits misses hour hits misses concurrent outgoing connections total number outgoing connections follows traffic intensity pattern 
number outgoing connections requests close number concurrent misses 
happens uses outgoing connection retrieve data 
contrary number outgoing connections hits noticeably lower number concurrent hit requests 
factors affect 
hit requests require outgoing connection verify freshness document 
second primary server confirms requests small message reading document 
network server delays minimal fast response time hits decreases number outgoing hit connections 
proxy connect time hour hits misses hour hits misses hour hits misses proxy connect time proxy connect time time takes send request primary server proxy 
misses send requests retrieve documents 
client requests old cached object proxy may send modified request 
note dns lookup activity included proxy connect time 
graph ignore requests outgoing connection 
interestingly takes longer hit send ims request 
effect especially visible leaf proxies detected higher levels caching hierarchy 
speculate may reasons anomaly 
hit documents originate primary servers farther average network topology servers deliver misses 
example leaf proxy europe retrieve lot hits popular servers usa slow link 
hand hit ratio local documents may lower due higher document diversity 
second hits served popular servers 
popular servers overloaded high response time 
misses served average loaded servers 
server reply time hour hits misses hour hits misses hour hits misses server reply time server reply time time takes receive reply primary server proxy 
clearly server reply time susceptible load 
note hit replies transmitted faster small ims acknowledgment regardless file size 
average hit replies faster misses sv proxy faster ruu 
file size kb hits misses file size kb hits misses file size kb hits misses server reply time vs reply size server reply time hits change document size 
possible server reply hit positive ims reply carries content 
length ims reply message depend actual document size 
shown ims reply time reply time small documents 
indicates network congestion dominates server reply time 
reply time consists components server latency network latency 
time takes primary server construct ims reply smaller time read small document disk 
total reply times cases network latencies dominate 
hour hits misses hour hits misses hour hits misses server response time server response time hits slower misses connect phase 
opposite true reply phase 
server response time measures total network delay communication primary server proxy connect time plus server reply time 
spite slower connect time total server response time hits lower 
hits verify freshness object save time misses fetch data network 
note tcp socket buffer visible impact outgoing connections 
inbound network clients inbound network connections request document proxy receive reply 
major function proxy decrease total response time reducing number outbound network transmissions 
inbound connections congested savings total response time may marginal 
section studies performance inbound network 
client connect time hour hits misses hour hits misses hour hits misses client connect time client connect time delay accept system call proxy receiving parse able request 
note measure network card queuing time client request prior accept call 
network connection remains open client request received reused send reply 
may client connect time depend result request hit result known connect phase 
case 
participating proxies detected difference client connect time hits misses 
proxies takes longer hits connect 
root proxy opposite pattern 
longer connect time hits explained source hit request 
sources hits clients neighbor proxies siblings 
major source misses clients speculations require investigation 
unfortunately may information current log files test hypothesis 
icp siblings fetch misses icp 
clients closer cache server sibling proxies 
hit requests originated neighbors may longer connect times 
happen misses originated siblings 
effect especially noticeable leaf proxies hit connect time twice long 
additional experiments may needed verify theory 
root proxy opposite holds 
major sv siblings connected fast vbns links hit connect phase shorter misses 
client connect time load dependent 
caused outbound network congestion squid performance 
experiments may help identifying real cause 
proxy reply time hour hits misses hour hits misses hour hits misses proxy reply time proxy reply time time takes send reply client document retrieved cache primary server 
note due pipelining reply process may start prior receiving byte disk primary server 
takes squid time reply hit apparent reason large percentage hits ims hits small content 
investigate proxy reply time isolated ims hits hits transfer document content reply 
hour hits hits misses hour hits hits misses hour hits hits misses proxy reply time detailed note reply time varies time 
increase proxy reply time may affected factors ffl degradation outbound connections slows delivery large ffl proxy performance degradation affects misses hits ffl degradation inbound connections affects replies behavior hits line important 
outbound connections proxy performance affect replies 
reply time hits goes inbound connections congested 
proxy sibling parent may serve misses siblings setup rare 
hits misses depend performance proxy misses depend outbound connections 
note hits misses suffer congestion hits larger size may require network os 
proceed reply size account 
proxy reply time vs reply size file size kb hits misses file size kb hits misses file size kb hits misses proxy reply time vs reply size graphs show effect tcp socket buffer discussed request response time experiment 
note presence tcp buffer visible ruu proxy 
ruu proxy follow common pattern experiment 
disk storage subsystem hits retrieved disk 
performance disk storage subsystem direct impact request response time improvement achieved proxy 
section experiments measuring disk performance 
note measurements distinguish individual disks 
results section analyze performance disk storage subsystem 
shorter word disk 
disk traffic intensity hour swap swap hour swap swap hour swap swap disk traffic intensity rate incoming swap requests determines stress disk storage subsystem 
squid treats swap requests equally regardless direction 
swap swap requests different priorities qos factors squid memory requirements considered 
swap request contribute response time hits 
reducing response time improve qos 
better response time achieved example giving higher priority swap requests 
delaying swap requests may increase total memory requirement incoming documents swapped disk 
knowing swap request rate may help solving tradeoff 
actual number swap swap requests determined traffic intensity document hit ratio caching policy 
number swap requests usually dominate leaf proxies 
opposite true top level caches lower hit rates leaves 
root proxy swap swap requests dominate half day 
swap ratio significantly changes time participating proxies 
changes performance tuning harder static optimizations may 
concurrent disk requests hour hour hour concurrent disk requests graphs show number concurrent swap requests proxy server 
count number requests system msec intervals calculate median minute grouping 
small msec intervals assure count number concurrent requests total number requests large interval 
note disk request second graph 
plot th th percentiles 
th percentile median 
measurements distinguish individual disks 
measure total number concurrent requests disk storage subsystem 
number directly affects length queues individual disks 
number concurrent swap requests increases sharply peak load 
increase proportional incoming swap requests rate 
direct effect large queuing time swap requests 
disk utilization hour swap swap hour swap swap hour swap swap disk utilization disk utilization measured percentage times active swap request 
measurements done msec intervals 
actual disk utilization represented curve 
curves swap swap requests compare contribution class disk utilization 
measure disk utilization 
graph represents utilization disk storage subsystem 
words disk system utilization regardless number physical disks installed 
disk utilization reaches root top level proxies 
participating leaf proxies utilization incoming traffic lighter 
hour swap swap hour swap swap hour swap swap disk response time disk response time disk response time total time takes swap document disk cache 
note drastic increases response time correspond higher number concurrent swap requests 
peaks sharply increase total response time hits 
participating proxies swap requests somewhat faster swap requests spite larger average size 
may attribute os level caching disk write requests 
os may postpone scheduling write request time may completed faster 
optimization transparent squid perceived faster response time writes 
course read requests postponed 
low level disk scheduling differs operating systems 
differences may explain faster swap requests proxies 
data support claim 
disk response time anatomy file size kb st delay swap swap total swap swap file size kb st delay swap swap total swap swap file size kb st delay swap swap total swap swap disk response time anatomy understand performance disk storage subsystem plot disk response time versus file size 
squid swaps files kb pages 
swap direction plot total request response time time takes swap page 
total st delay curves files smaller kb 
various delays dominate disk transfer time size important number os 
fact explains step shape total curves times read files kb approximately 
delay file size 
ran patch discovered case 
delay dropped ruu proxies 
suspicion measurements incorrect 
hours searching bug 
squid 
squid doing extra page document 
delay multi page documents include extra smaller response times 
bug report bug bug fixed squid version 
participating proxies ruu fixed bug running experiments 
disk delay includes os overhead opening file 
consecutive os file overhead 
may compute duration os overhead simple model assuming overheads depend file size small files st delay overhead otal kb st delay otal kb st delay otal kb gamma otal kb overhead otal kb gamma model reasonable assumptions 
discovered proxies model positive solution overhead component 
main reasons model failure probably queuing delays individual os squid 
squid attempts process ready swap requests interleaved fashion page swap request time 
number ready requests large single disk request may wait completed 
number ready requests unstable large random delays causes may affect model 
currently working ways os overhead estimation 
way detecting squid queuing delays analyze second time swap requests 
note second include os overhead opening file includes squid queuing delays 
measure duration total response time 
page files kb difference gives second duration 
hour swap swap hour swap swap hour swap swap second duration duration second experiences peaks total swap response time 
observation supports hypothesis squid queuing delays dominate disk response time peak loads 
squid enqueues disk request opening file 
page documents served steps 
file opened page scheduled second actual performed 
stage may experience queuing delay 
page documents may suffer queuing delays 
usually page swap requests 
squid designed handle multi page documents fair fashion swap request split small steps steps execution interleaved 
demonstrated interleaving may lead huge extra queuing delays page documents 
measurements collected study currently investigate ways improving disk response time preserving fairness 
proxy response time components conclude study analyzing relative impact request processing stages 
analysis essential performance optimization helps identifying performance bottlenecks 
misses distinguish major stages client connect proxy connect server reply proxy reply 
graphs show relative contribution stage total delay 
total delay calculated sum stages performance optimization absolute level contribution change time important 
tells contributes total delay 
may help identifying performance problems arise peak load 
example server reply component dominates response time 
relative contribution decreases peak loads 
sv server reply time component important proxy connect stage sharply increases relative value peak loads 
takes longer send small request primary server receive potentially large reply 
median total delay may differ median response time pipelining non accounted activities dns lookups 
working precise model accounts side effects 
hour proxy reply server reply proxy connect client connect hour proxy reply server reply proxy connect client connect hour proxy reply server reply proxy connect client connect proxy response time components misses contribution client connect stage usually increases twice peak load 
interestingly proxy reply time responsible portion total delay regardless load 
analysis implies connect times susceptible traffic intensity 
persistent connections promising way reduce impact load response time 
squid team currently working persistent connections support squid version 
hour proxy reply swap client connect hour proxy reply swap client connect hour proxy reply swap client connect proxy response time components hits hits distinguish major stages client connect swap proxy reply 
purpose analysis consider hits 
ignore communication primary server majority hits verify freshness 
curves hits stable misses 
sv proxy reply time dominates swap stage takes approximately time client connect 
components equally important 
client connect time stable component proxies 
pattern consistent misses 
important observation disk delays contribute total response time 
network performance control caching proxy 
contrary disk performance isolated external factors optimized 
note account pipelining affects may change relative contributions large requests 
requests pipelined due small document sizes 
believe estimations close actual performance 
related web caching research concentrated primarily caching policies caching hierarchies 
surprisingly little attention paid performance analysis 
area currently done administrators large caching proxies study systems order detect potential problems improve performance 
efforts badly documented optimization recommendations anecdotal evidence 
pioneer works performance analysis caching proxies benchmarking harvest object cache cd 
authors simulated workload generated local clients compare harvest performance study study dec request measurements detailed request measurements network disk delays 
allows performance analysis request categories misses ims hits small swap requests 
demonstrated request classes significantly differ performance characteristics 
aggregate statistics meaningless misleading 
system state snapshots authors effectively utilized unix tools collect snapshots system activities 
snapshots contain important information low level system performance available squid 
example actual network queues raw disk delays measured 
approach lacks low level os measurements 
desirable combine squid level measurements os statistics describe certain effects precisely 
organizational reasons patch run environments control prevented performing measurements 
drawback approach connection squid actions system performance lost 
loss top rapidly changing system states hard summarize collected data meaningful form 
results may look messy inconclusive 
fixed caching software squid variety environments concentrated research state theart proxy various environments 
essential show observations hold regardless proxy hardware operating system configuration note squid software extremely popular european caching proxies surveyed running squid ect squid cern proxies fixed environment authors studied proxies fixed environment test alternative design decisions 
able show important differences performance caused proxies architecture 
clear applicable findings environments especially levels hierarchy 
cooperative caches hierarchy levels studied proxies actively involved cooperation caches 
cooperation typical modern proxies 
demonstrated cooperation affect proxy performance 
participating proxies represented levels caching hierarchy 
single isolated cache authors concentrated performance leaf proxy 
study affects hierarchical caching 
compact time range base analysis measurements collected short time interval 
weeks 
compact time range comparison different proxies realistic 
analyze trends web traffic impact proxy performance 
months time range web traffic handled studied proxy doubled time cern proxy tested experiments squid 
performance comparison questionable 
hand long time range allowed interesting observations historical trends 
cern 
contains important insights harvest architecture 
performance measurements small simulated environment 
related research publication performance study caching proxies conducted digital palo alto gateway mrg 
authors analyzed performance cern squid proxies real workloads 
measured proxy resource consumptions snapshots system activities 
study orthogonal see table 
studies performance primary web servers trs 
results obtained web server directly applied proxy 
modern web servers rely file system cache documents 
approach applicable caching proxies 
cpu network related observations single process design versus process request approach relevant proxy performance optimization 
performance study squid caching proxy 
approach measuring request network disk activities allowed depth analysis major proxy subsystems 
carefully classifying requests able identify quantify degradation network disk storage subsystems high load periods 
common performance patterns detected various proxy environments 
studying proxies different levels caching hierarchy analyzed impact cooperative caching proxies 
data analysis essential understanding modeling enhancing performance proxy server 
believe request profiling tools incorporated caching proxies provide developers essential information available means 
fact success project part lack detailed performance statistics squid vacuum important area encouraged cache administrators participate experiments 
constantly extending log collection analysis 
performance observations suggest significant improvements squid architecture 
investigating alternatives direction 
considering studying impact large number icp requests cooperative proxies icp requests ignored purpose study 
acknowledgments thankful cache managed squeeze time run experiments proxies discuss results utrecht university netherlands edwin mexico brian australia lars university norway ton netherlands duane wessels nlanr usa 
discussions helpful improving quality 
encourage administrators actively participate research experiments study 
experience shows collaboration benefits researchers practitioners 
internet better place live 
abrams abdulla williams fox 
caching proxies limitations potentials 
boston usa december 
ei cs vt edu succeed www www html cd chankhunthod danzig neerdaels schwartz 
hierarchical internet object cache proc 
usenix annual technical conference san diego usa january 
excalibur usc edu cache html cache html bug double read bug report www cs edu research cache squid profiling stats ruu bug html ect european caching task force survey results cache icm edu pl survey results icp rfc internet cache protocol icp version squid nlanr net squid rfc txt rizzo vicisano 
replacement policies proxy cache 

www iet unipi luigi caching ps gz ari luotonen henrik frystyk nielsen tim berners lee 
cern httpd 
july 
www org pub www daemon mrg carlos kathy richardson dirk grunwald 
performance issues enterprise level web proxies 
proc 
acm sigmetrics intl 
conference seattle wa june 
www cs colorado edu sigmetrics ps gz patch performance profiling patch 
documentation www cs edu research cache squid profiling rs alex 
static caching proxy servers second web cache workshop boulder colorado usa june 
ircache nlanr net cache workshop squid squid internet object cache squid nlanr net srn squid release notes squid nlanr net squid release notes txt stats squid profiling statistics www cs edu research cache squid profiling stats trs tatarinov 
static caching web servers 
proc 
sixth ieee intl 
conf 
computer communications networks ic las vegas nevada usa september 
