learning dynamic bayesian networks zoubin ghahramani department computer science university toronto toronto canada www cs utoronto ca zoubin zoubin cs toronto edu october 
bayesian networks directed acyclic graphs represent dependencies variables probabilistic model 
time series models including hidden markov models hmms speech recognition kalman filter models filtering control applications viewed examples dynamic bayesian networks 
provide brief tutorial learning bayesian networks 
dynamic bayesian networks capture richer structure hmms kalman filters including spatial temporal multiresolution structure distributed hidden state representations multiple switching linear regimes 
exact probabilistic inference intractable networks obtain tractable variational approximations call subroutines forward backward kalman filter recursions 
approximations learn model parameters maximizing lower bound likelihood 
table contents bayesian network tutorial dynamic bayesian networks example state space models example hidden markov models learning inference ml estimation complete data ml estimation hidden variables em algorithm example learning state space models kalman smoothing example learning hidden markov models modified version appear giles gori eds adaptive processing temporal information 
lecture notes artificial intelligence 
springer verlag 
forward backward algorithm tractable models example factorial hmms example tree structured hmms example switching state space models inference intractability gibbs sampling variational methods example mean field factorial hmms example structured approximation factorial hmms convex duality suppose wish build model data finite sequence ordered observations fy realistic scenarios modeling stock prices physiological data observations related deterministically 
furthermore added uncertainty resulting limited size data set mismatch model true process 
probability theory provides powerful tool expressing randomness uncertainty model 
express uncertainty prediction outcome probability density jy 
probability density point predictions define error bars decisions expected minimize loss function 
chapter presents probabilistic framework learning models temporal data 
express models bayesian network formalism probabilistic graphical models belief networks marriage probability theory graph theory dependencies variables expressed graphically 
graph allows user understand variables affect ones serves backbone efficiently computing marginal conditional probabilities may required inference learning 
section provides brief tutorial bayesian networks 
section demonstrates bayesian networks modeling time series including known examples kalman filer hidden markov model 
section focuses problem learning parameters bayesian network expectation maximization em algorithm 
section describes richer models appropriate time series nonlinear multiresolution structure 
inference models may computationally intractable 
section tractable methods approximate inference basis learning 
bayesian network tutorial bayesian network simply graphical model representing conditional independencies set random variables 
consider random variables basic probability theory know factor joint probability product conditional probabilities jw factorization tell useful joint probability distribution variable potentially depend variable 
consider factorization jw zjx factorization implies set conditional independence relations 
variable set variables conditionally independent bjc ajc bjc 
factorization show values independent jx jw zjx jw zjx dw dz jw zjx jy zjx bayesian network graphical way represent particular factorization joint distribution 
variable represented node network 
directed arc drawn node node conditioned factorization joint distribution 
example represent factorization draw arc bayesian network representing factorization shown 
basic definitions graph theory necessary point 
node parent node directed arc child descendents node children children 
directed path sequence nodes starting node sequence parent node sequence 
undirected path sequence nodes starting node sequence parent child node 
semantics bayesian network simple node conditionally independent non descendents parents 
generally correspondence nodes variables talk conditional independence relations nodes meaning conditional independence relations variables associated nodes 
fig 

directed acyclic graph dag consistent conditional independence relations 
disjoint sets nodes conditionally independent undirected path node node node converging arrows descendents converging arrow 
visual inspection graphical model easy infer independence relations explicitly grinding bayes rule 
example conditionally independent set fy zg path converging arrows 
infer graph conditionally independent notice factorization implies strict ordering variables connections obtained manner define directed acyclic graph furthermore ways factorize joint distribution consequently bayesian networks consistent particular joint 
bayesian network said independency map map distribution separation displayed corresponds valid conditional independence relation minimal map arc deleted removing map property 
absence arcs bayesian networks implies conditional independence relations exploited obtain efficient algorithms computing marginal conditional probabilities 
singly connected networks underlying undirected graph loops exists general algorithm called belief propagation 
multiply connected networks undirected path nodes exists general algorithm known junction tree algorithm 
provide essence belief propagation algorithm exact methods refer reader relevant child previous nodes path 
undirected graphical models markov networks important tool representing probability distributions different set semantics 
deal exclusively directed graphical models 
texts details 
assume observe evidence value variables network 
goal belief propagation update marginal probabilities variables network incorporate new evidence 
achieved local message passing node sends message parents children 
graph singly connected separates graph evidence mutually exclusive sets consisting parents nodes connected parents gamma consisting children nodes connected children 
message children probability fig 

separation evidence singly connected graphs 
setting evidence observed set 
message parents probability setting parent evidence observed set gamma fng 
marginal probability node proportional product messages obtained parents weighted conditional probability node parents message obtained children 
parents fp fc fp kg je gamma jn nodes undirected path goes parent summation generally integral extends settings fp example evidence fx zg jx jw dw xjy zjx message passed xjy message passed variables evidence set referred observable variables evidence set referred hidden variables 
bayesian network constructed combining priori knowledge conditional independences variables expert particular domain data set observations 
natural way priori knowledge elicited expert asking questions regarding causality variable direct causal effect variable parent network 
temporal order specifies direction causality notion plays important role design dynamic bayesian networks 
dynamic bayesian networks time series modeling observe values certain variables different points time 
assumption event cause event vice versa design bayesian networks time series directed arcs flow forward time 
assigning time index variable simplest causal models sequence data fy order markov model variable directly influenced previous variable yt jy delta delta delta jy gamma fig 

bayesian network representing order markov process 
models directly represent dependencies observables time step 
having observed fy model predict value simple way extending markov models allow higher order interactions variables 
example th order markov model allows arcs fy gamma gamma way extend markov models posit observations dependent hidden variable call state sequence states markov process 
classic model kind linear gaussian state space model known kalman filter 
fig 

bayesian network specifying conditional independence relations state space model 
example state space models state space models sequence dimensional real valued observation vectors fy yt modeled assuming time step generated dimensional real valued hidden state variable sequence define order markov process 
short hand notation fy denote sequences fx jx jx gamma jx state transition probability jx gamma decomposed deterministic stochastic components gamma deterministic transition function determining mean gamma zero mean random noise vector 
similarly observation probability jx decomposed transition output functions linear time invariant distribution states observation noise variables gaussian model linear gaussian state space model ax gamma cx state transition matrix observation matrix 
observations divided set input predictor variables output response variables 
assuming linearity gaussian noise write state transition function ax gamma bu input observation vector input matrix 
bayesian network corresponding model include sequence nodes fu parent corresponding linear gaussian state space models extensively areas control signal processing 
example hidden markov models hidden markov model hmm sequence observations fy modeled assuming observation depends discrete hidden state sequences hidden states distributed markov process 
joint probability sequences states observations factored exactly manner equation place fs js js gamma js consequently conditional independences hmm expressed graphically bayesian network shown 
state represented single multinomial variable take discrete values kg 
state transition probabilities js gamma hmm specified single theta transition matrix 
observables discrete symbols values emission probabilities js fully specified theta observation matrix 
realvalued observation vectors js modeled different forms gaussian mixture gaussians neural network 
state space models hmms augmented allow input variables :10.1.1.53.917
system models conditional distribution sequence output observations sequence input observations 
hmms applied extensively problems speech recognition computational biology fault detection 
learning inference bayesian approach learning starts priori knowledge model structure set arcs bayesian network model parameters 
initial knowledge represented form prior probability distribution model structures parameters updated data obtain posterior probability distribution models parameters 
formally assuming prior distribution models structures prior distribution parameters model structure jm data set form posterior distribution models bayes rule dj jm integrates uncertainty parameters 
model structure compute posterior distribution parameters jm dj jm djm data set sequence observations fy yt wish predict observation data models bayesian prediction yt jd yt jm dm integrates uncertainty model structure parameters 
obtain somewhat impoverished useful limiting case bayesian approach learning assume single model structure estimate parameters maximize likelihood dj model 
limit large data set uninformative uniform prior parameters posterior jm sharply peaked maxima likelihood predictions single maximum likelihood ml model similar obtained bayesian integration parameters 
focus problem estimating ml parameters model model structure 
principle approximate bayesian learning practice full fledged bayesian analysis impractical furthermore application areas strong priori knowledge model structure single estimate parameters provides parsimonious interpretable model distribution parameters 
ml estimation complete data assume data set independent identically distributed observations fy vector time series vectors likelihood data set dj approximate methods integrating posterior case neural network models described 
notational convenience henceforth drop implicit conditioning model structure ml parameters obtained likelihood equivalently log likelihood log observation vector includes variables bayesian network term log likelihood factors log log jy pa log jy pa indexes nodes bayesian network pa set parents parameters define conditional probability parents 
likelihood decouples local terms involving node parents simplifying ml estimation problem 
example variables discrete conditional probability table parents ml estimate simply normalized table containing counts setting setting parents data set 
ml estimation hidden variables em algorithm hidden variables log likelihood decomposed 
find log log xj set hidden variables sum integral required obtain marginal probability data 
dropped superscript evaluating log likelihood single observation 
distribution hidden variables obtain lower bound log xj log xj log log gamma log middle inequality known jensen inequality proven concavity log function 
define energy global configuration log readers may notice lower bound negative quantity known statistical physics free energy expected energy minus entropy 
expectation maximization em algorithm alternates maximizing respect respectively holding fixed 
starting initial parameters step arg max step arg max easy show maximum step results xjy point bound equality 
step obtained maximizing term entropy depend step arg max xjy log expression associated em algorithm obscures elegant interpretation em coordinate ascent step step change guaranteed decrease likelihood combined em step 
worthwhile point usually necessary explicitly evaluate posterior distribution xjy 
log contains hidden observed variables network factored sum log probabilities node parents 
consequently quantities required step expected values posterior distribution xjy analogous quantities required ml estimation complete data case 
example learning state space models equation log probability hidden states observations linear gaussian state space models written log fx log log jx log jx gamma probability densities gaussian expression sum 
example equation log jx gamma gamma cx gamma gamma cx gamma jrj const covariance observation noise matrix transpose delta matrix determinant 
random variables observed ml parameters solved maximizing 
derivatives obtain linear systems equations 
example ml estimate matrix gamma states fact hidden step expected values don access actual observed values 
denote expected value quantity respect posterior distribution hf hf xjy dx step hx hx gamma similar steps derived parameters derivatives expected log probability 
general require terms kind hx hx hx gamma terms computed kalman smoothing algorithm 
kalman smoothing kalman smoother solves problem estimating state time linear gaussian state space model model parameters sequence observations fy yt consists parts forward recursion uses observations known kalman filter backward recursion uses observations 
seen order compute marginal probability variable bayesian network take account evidence variable 
fact kalman smoother simply special case belief propagation algorithm encountered bayesian networks 
gaussian marginal density hidden state vector completely specified mean covariance matrix 
useful define quantities mean vector covariance matrix respectively parameters linear gaussian state space model estimated methods line recursive identification 
forward backward recursions known rauch rts smoother 
thorough treatments kalman filtering smoothing 
observations fy kalman filter consists forward recursions gamma ax gamma gamma gamma av gamma gamma gamma cv gamma gamma gamma gamma cx gamma gamma gamma cv gamma prior mean covariance state model parameters 
equations describe forward propagation state mean variance having accounted observation time mean evolves known dynamics affects variance 
addition variance increases state noise 
observation effect shifting mean amount proportional prediction error gamma cx gamma proportionality term known kalman gain matrix 
observing effect reducing variance equations derived laboriously analytically evaluating gaussian integrals result belief propagation applied bayesian network corresponding state space models 
forward recursions values need proceed backwards evaluate influence observations estimate states past gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma ax gamma gamma gamma gamma gamma gamma gamma gamma gamma gain matrix similar role kalman gain matrix 
equation shifts mean amount proportional prediction error gamma ax gamma gamma recursively compute covariance time steps gamma gamma gamma av gamma initialized gamma gamma kt av gamma gamma expectations required em readily computed hx hx hx gamma gamma gamma example learning hidden markov models log probability hidden variables observations hmm log fs log log js log js gamma represent valued discrete state dimensional unit column vectors state time value represented terms decomposed summations example transition probability js gamma ij gamma ij probability transitioning state state arranged theta matrix log js gamma gamma log ij log gamma matrix notation 
similarly assume vector initial state probabilities log log emission probabilities depend form observations 
discrete variable take values represent dimensional unit vectors obtain log js log theta emission probability matrix 
state variables hidden compute directly 
em algorithm case hmms known baum welch algorithm allows circumvent problem computing expectation posterior distribution hidden states observations 
expectation expressed function hs hs gamma 
term hs vector containing probability hmm states time current parameters entire sequence observations second term hs gamma matrix containing joint probability hmm pairs states times gamma hmm notation hs corresponds fl learning data set containing multiple sequences quantity computed separately sequence 
clarity describe single sequence case 
hs gamma corresponds expectations step straightforward take derivatives respect parameters set zero solve subject sum constraints ensure valid transition emission initial state probabilities 
example transition matrix obtain ij hs gamma hs gamma hs gamma necessary expectations computed forward backward algorithm 
forward backward algorithm forward backward algorithm simply belief propagation applied bayesian network corresponding hidden markov model see treatment 
forward pass recursively computes ff defined joint probability sequence observations ff gamma gamma gamma js gamma js gamma ff gamma js gamma js backward pass computes conditional probability observations fi js yt js js js fi js js easy compute expectations needed em hs fl ti ff fi ff fi hs gamma tij ff gamma ij js fi ff gamma js fi notice kalman smoothing algorithm forward backward algorithm conceptually identical 
occasionally useful compute single probable state sequence 
solution problem viterbi algorithm similar forward backward algorithm summations replaced see tutorial hmms especially applied speech recognition 
tractable models linear gaussian state space models hidden markov models provide interesting starting point designing dynamic bayesian networks 
suffer important limitations comes modeling real world time series 
case linear gaussian state space models limitations advertised name realistic applications state dynamics relation states observations nonlinear noise non gaussian 
hidden markov models situation subtle 
hmms dynamical extension mixture models unconstrained mixture models model distribution limit infinite number mixture components 
furthermore state transition matrix unconstrained arbitrary nonlinear dynamics modeled 
limitation lie 
consider problem modeling movement objects sequence images 
objects occupy positions orientations image possible states system underlying image 
hidden markov model require distinct states model system 
representation inefficient difficult interpret 
hmm capture underlying state space different dimensional variables 
seriously unconstrained hmm states order parameters transition matrix 
data set captures possible transitions priori knowledge constrain parameters severe fitting may result 
section describe ways hmms state space models extended overcome limitations 
represents hidden state hmm set distinct state variables 
hmm distributed state representation factorial hidden markov model :10.1.1.16.2929
example factorial hmms generalize hmm representing state collection discrete state variables take values 
state space model consists cross product state variables 
simplicity assume algorithms trivially generalized case differing state space factorial hmm consists combinations variables placing constraints state transition structure result theta transition matrix 
unconstrained system uninteresting reasons equivalent hmm states discover interesting structure state variables variables allowed interact arbitrarily time complexity sample complexity estimation algorithm exponential focus factorial hmms underlying state transitions constrained 
natural structure consider state variable evolves dynamics priori uncoupled state variables js gamma js gamma bayesian network representing model shown 
transition structure model parametrized distinct theta matrices 
shown observation time step depend state variables time step factorial hmm 
real valued observations simple form dependence linear gaussian observation gaussian random vector mean linear function state variables 
represent state variables theta vectors discrete values corresponds position 
resulting probability density theta observation vector js jrj gamma gammad exp ae gamma gamma gamma gamma oe matrix theta matrix columns contributions means settings theta covariance matrix denotes matrix transpose 
way understand observation model equations consider marginal distribution obtained summing possible states 
settings state variables possible mean vectors obtained forming sums columns column chosen matrices 
resulting marginal density gaussian mixture model gaussian mixture components having constant covariance matrix static mixture model inclusion time index markov dynamics factorial parameterization standard mixture gaussians model interest right 
model just extends allowing markov dynamics discrete state variables underlying mixture 
fig 

bayesian network representing conditional independence relations factorial hmm underlying markov chains 
example tree structured hmms factorial hmms state variables time step assumed priori independent state variables previous time step 
assumption relaxed ways introducing coupling state variables single time step 
interesting way couple variables order depends furthermore state variables output depend observable input variable obtain bayesian network shown 
fig 

tree structured hidden markov models 
architecture interpreted probabilistic decision tree markovian dynamics linking decision variables 
consider model generate data time step 
input top node take values 
stochastically partitions space decision regions 
node hierarchy subdivides regions subregions 
output generated input way decisions hidden nodes 
time step similar procedure generate data model decision tree dependent decision taken node previous time step 
model generalizes hierarchical mixture experts related decision tree models cart mars giving decisions markovian dynamics 
tree structured hmms provide useful starting point modeling time series temporal spatial structure multiple resolutions 
explored generalization factorial hmms 
example switching state space models factorial hmms tree structured hmms discrete hidden state representations 
model time series continuous nonlinear dynamics possible combine real valued hidden state linear gaussian state space models discrete state hmms 
natural way switching state space model 
switching state space models sequence observations fy modeled hidden state space comprising real valued state vectors discrete state vector discrete state multinomial variable take values mg reasons obvious refer switch variable 
joint probability observations hidden states factored fs js gamma jx gamma theta jx corresponds graphically conditional independences represented 
conditioned setting switch state observable multivariate gaussian output equation state space model probability observation vector jx gamma jrj gamma theta exp gamma gamma gammac delta gamma gamma gammac delta dimension observation vector observation noise covariance matrix output matrix state space model cf 
equation single linear gaussian state space model 
real valued state vector evolves linear gaussian dynamics state space model differing initial state transition matrix state noise equation 
switch state evolves discrete markov dynamics specified initial state probabilities theta state transition matrix js gamma 
model seen extension mixture experts architecture modular learning neural networks 
state space model linear expert gaussian output noise linear gaussian dynamics 
switch state gates outputs state space models plays role gating network markovian dynamics 
fig 

bayesian network representation switching state space models 
discrete switch variable real valued state vectors 
inference intractability problem extensions hidden markov models state space models previous section sequence observations probabilities interest intractable compute 
consider example computing likelihood factorial hmm marginal probability sequence observations parameters fy gj fy denotes fy yt sum possible hidden state sequences joint probability sequence observations fy gj fs fs gj possible states time step mt hidden state sequences length assuming transition probabilities exactly 
brute force approach evaluating sequences avoided making conditional independences represented bayesian network 
example directly applying forward pass forward backward algorithm outlined section compute likelihood summing ff time step fy gj st st ff factorial hmm ff vector size equal full state space time elements 
results recursive algorithm computes likelihood tk operations 
improved fact state transitions defined matrices size theta single theta matrix resulting recursive algorithm tmk operations see appendix :10.1.1.16.2929
unfortunately time complexity improved 
observation time valued state variables coupled th order interaction 
possible sum variable independently 
likelihood computing posterior probability single state variable observation sequence jy exponential similar exponential time complexity results hold likelihoods posterior probabilities tree structured hmms switching state space models 
gibbs sampling approach computing approximate marginal probabilities monte carlo integration 
log likelihood expressed log fy gj fs fs log fs fy gamma log fs sampling posterior distribution fs log likelihood approximated expression just negative free energy 
learn parameters model samples posterior evaluate expectations required em 
course intractable models sampling directly posterior distributions computationally prohibitive 
easy set markov chain converge samples posterior 
simplest methods achieve gibbs sampling review gibbs sampling markov chain monte carlo methods see 
observation sequence fy gibbs sampling starts random setting hidden states fs step sampling process state variable updated stochastically probability distribution conditioned setting state variables 
graphical model useful node conditionally independent nodes markov blanket defined set children parents parents children node 
example sample typical state variable factorial hmm need examine states neighboring nodes jfs mg gamma js gamma js js denotes sampled 
sampling tm hidden variables model results new sample hidden state model requires tmk operations 
sequence states resulting pass gibbs sampling defines markov chain state space model 
markov chain guaranteed converge posterior probabilities states observations long probabilities model exactly zero suitable time samples markov chain taken approximate samples posterior probabilities 
second order statistics needed estimate hs hs hs gamma collected states visited probabilities estimated sampling process approximate step em 
monte carlo methods learning dynamic bayesian networks explored 
variational methods approach approximating probability distribution define parametrized distribution vary parameters minimize distance context em algorithm seen likelihood lower bounded free energy 
difference kullback leibler divergence posterior distribution hidden variables gamma kl gamma fs kp fs delta fs fs log fs fs oe parameters distribution complexity exact inference approximation determined conditional independence relations parameters 
chose tractable structure bayesian network eliminates weaker assumption ergodicity suffice ensure convergence bayesian treatment learning problem parameters considered hidden random variables handled gibbs sampling replacing step sampling conditional distribution parameters hidden variables example see 
dependencies structure free vary parameters obtain tightest possible bound minimizing 
refer general strategy parameterized approximating distribution variational approximation refer free parameters distribution variational parameters 
example mean field factorial hmms illustrate approach simplest variational approximation posterior distribution factorial hmms state variables assumed independent means fs joe variational parameters oe oe means state variables state variable represented dimensional vector th position th markov chain state time elements vector oe define state occupation probabilities multinomial variable distribution joe oe completely factorized approximation kind statistical physics provides basis simple powerful mean field approximations statistical mechanical systems 
fig 

completely factorized variational approximation assuming state variables independent conditional observation sequence 
structured variational approximation assuming state variables retain markov structure chain independent chains 
bound tight possible vary oe separately observation sequence minimize kl divergence 
derivatives respect oe setting zero obtain set fixed point equations defined oe new ae gamma gamma delta log oe gamma log oe oe residual error predictions state variables including gamma oe delta vector diagonal elements gamma deltag softmax operator maps vector vector size elements log denotes elementwise logarithm transition matrix see appendix details derivation :10.1.1.16.2929
term projection error reconstructing observation weights state vector particular setting state vector reduce error larger associated variational mean 
second term arises fact second order correlation hs evaluated variational distribution diagonal matrix composed elements oe terms introduce dependencies forward backward time 
posterior distribution hidden variables approximated completely factorized distribution fixed point equations couple parameters associated node parameters markov blanket 
sense fixed point equations propagate information pathways defining exact algorithms probability propagation 
may provide intuitive interpretation approximation distribution 
particular observation sequence hidden state variables markov chains time step stochastically coupled 
stochastic coupling approximated system hidden variables uncorrelated coupled means 
variational mean field equations solve deterministic coupling means best approximates stochastically coupled system 
hidden state vector updated turn time complexity tmk iteration 
convergence determined monitoring term replaced log second term appear kl divergence variational distribution successive time steps practice convergence rapid iterations 
convergence global minimum kl divergence required general procedure converge local minimum 
fixed point equations converged expectations required step obtained simple function parameters :10.1.1.16.2929
example structured approximation factorial hmms approximation previous section factors posterior probability product statistically independent distributions state variables 
approximation tractable preserves probabilistic dependencies original system 
scheme posterior distribution factorial hmm approximated uncoupled hmms shown 
hmm efficient exact inference implemented forward backward algorithm 
arguments previous section hinge form approximating distribution distribution provides lower bound log likelihood obtain learning algorithm 
approach exploiting tractable substructures suggested machine learning literature saul jordan 
write structured variational approximation fs zq joe js gamma oe zq normalization constant ensuring sums 
parameters oe original priors state transition matrices factorial hmm time varying bias state variable 
parameters prior transition probabilities joe js gamma oe gamma gamma equality follows fact gamma vector position 
comparing equations equation see theta vector plays role probability observation js settings example joe joe corresponds having observation time state probability intuitively approximation markov chains attaches state variable distinct fictitious observation 
probability fictitious observation varied minimize kl divergence applying arguments obtain set fixed point equations minimize kl qkp new exp ae gamma gamma delta oe delta defined redefine residual error gamma hs parameter obtained fixed point equations observation probability associated state variable hidden markov model probabilities forward backward algorithm compute new set expectations hs fed back 
forward backward algorithm subroutine minimization kl divergence 
notice similarity equations equations completely factorized system 
completely factorized system hs oe fixed point equations written explicitly terms variational parameters 
structured approximation dependence hs computed forward backward algorithm 
fixed point equations contain terms involving prior transition matrix terms cancelled choice approximation 
intractable dynamic bayesian networks amenable structured variational approximations 
case treestructured hmms natural choices substructures retain approximation 
choice remove arc time step retain temporal dependences resulting bayesian network shown 
choice retain arcs time step eliminate arcs consecutive time steps 
approximations approximation viterbi algorithm pursued 
switching state space models natural approximation state space models ssms discrete markov process controlling switch variable 
course variational parameters models deterministically coupled purposes computing posterior probabilities possible apply kalman smoothing state space model separately forward backward algorithm switch process 
variational parameters thought real valued responsibilities state space model observation sequence 
determine best variational parameters start responsibilities compute posterior probability state ssm kalman smoothing data weighted responsibilities 
weighting corresponding applying normal kalman smoothing equations weighting corresponds assuming data observed intermediate weighting implemented dividing matrix responsibility 
recompute responsibilities running forward backward algorithm switch process predicted error ssm 
procedure iterated responsibilities converge 
details structured variational approximation switching state space models provided 
convex duality framework obtaining lower bounds log likelihoods special case general variational methods convex duality 
section provide brief tutorial methods closely jaakkola introduced methods problems bayesian network learning 
general treatment rockafellar 
delving convex duality motivate reader making remarks 
lower bounds suggested maximizing lower bounds likelihoods objective learning clearly desirable complete picture deriving upper bounds 
second dealt networks complex nonlinear interactions 
methods convex duality principle solve problems 
brief tutorial refer reader examples approach define upper bounds deal certain nonlinearities 
convex function characterized property set points convex 
set called denoted epi 
convex sets represented intersection half spaces contain 
parametrize half spaces obtain dual consider half space gamma contains epi implies gamma gamma implies max gamma gamma follows max gamma defined dual function conversely max gamma intuitive way think dual function point linear function slope intercept touches lower bound 
dual function slopes evaluates corresponding intercept point slope 
simply put shown convex function lower bounded linear function parametrized 
simple result important consequences 
show lower bound log likelihood seen special case bound 
log likelihood written log log log oe log potential hidden states 
log partition function oe log log convex function potentials oe 
dual log partition function oe negative entropy function gammah log convex function probability distributions duality verified derivatives oe respect oe remembering dual function slopes evaluates corresponding intercepts 
log oe max fq oe max log gamma log usual lower bound bayesian networks concise graphical formalism describing probabilistic models 
provided brief tutorial methods learning inference dynamic bayesian networks 
interesting models simple linear dynamical system hidden markov model calculations required inference intractable 
different approaches handling intractability monte carlo methods gibbs sampling variational methods 
especially promising variational approach exploiting tractable substructures bayesian network 
strictly convex functions 
author geoffrey hinton michael jordan lawrence saul collaborators reviewed chapter 
author supported fellowship ontario information technology research centre 

anderson moore 
optimal filtering 
prentice hall englewood cliffs nj 

baldi chauvin mcclure 
hidden markov models biological primary sequence information 
proc 
nat 
acad 
sci 
usa 

baum petrie soules weiss 
maximization technique occurring statistical analysis probabilistic functions markov chains 
annals mathematical statistics 

bengio frasconi 
input output hmm architecture 
tesauro touretzky leen editors advances neural information processing systems pages 
mit press cambridge ma 

besag 
spatial interaction statistical analysis lattice systems 
royal stat 
soc 


breiman friedman olshen stone 
classification regression trees 
wadsworth international group belmont ca 

cacciatore nowlan 
mixtures controllers jump linear non linear plants 
cowan tesauro alspector editors advances neural information processing systems pages 
morgan kaufmann publishers san francisco ca 

carter kohn 
markov chain monte carlo conditionally gaussian state space models 
australian graduate school management university new south wales 

dean kanazawa 
model reasoning causation 
computational intelligence 

dempster laird rubin 
maximum likelihood incomplete data em algorithm 
royal statistical society series 

digalakis rohlicek ostendorf 
ml estimation stochastic linear system em algorithm application speech recognition 
ieee transactions speech audio processing 

friedman 
multivariate adaptive regression splines 
annals statistics 

geman geman 
stochastic relaxation gibbs distributions bayesian restoration images 
ieee transactions pattern analysis machine intelligence 

ghahramani 
factorial learning em algorithm 
tesauro touretzky leen editors advances neural information processing systems pages 
mit press cambridge ma 

ghahramani hinton 
parameter estimation linear dynamical systems 
technical report crg tr ftp ftp cs toronto edu pub zoubin tr ps gz department computer science university toronto 

ghahramani hinton 
switching state space models 
technical report crg tr ftp ftp cs toronto edu pub zoubin switch ps gz department computer science university toronto 

ghahramani jordan 
factorial hidden markov models 
machine learning 

goodwin sin 
adaptive filtering prediction control 
prenticehall 

heckerman 
tutorial learning bayesian networks 
technical report msr tr ftp ftp research microsoft com pub tr tr ps microsoft research 

hinton zemel 
minimum description length helmholtz free energy 
cowan tesauro alspector editors advances neural information processing systems 
morgan kaufmann publishers san francisco ca 

jaakkola 
variational methods inference estimation graphical models 
technical report ph thesis department brain cognitive sciences mit cambridge ma 

jacobs jordan nowlan hinton 
adaptive mixture local experts 
neural computation 

jaynes 
probability theory logic science 


jensen 
bayesian networks 
springer verlag new york 

jensen lauritzen olesen 
bayesian updating recursive graphical models local computations 
computational statistics quarterly 

jordan ghahramani saul 
hidden markov decision trees 
mozer jordan petsche editors advances neural information processing systems 
mit press cambridge ma 

jordan jacobs 
hierarchical mixtures experts em algorithm 
neural computation 

juang rabiner 
hidden markov models speech recognition 
technometrics 

kalman bucy 
new results linear filtering prediction 
journal basic engineering asme 

kanazawa koller russell 
stochastic simulation algorithms dynamic probabilistic networks 
besnard hanks editors uncertainty artificial intelligence 
proceedings eleventh conference pages 
morgan kaufmann publishers san francisco ca 

kim 
computational model causal diagnostic reasoning inference systems 
proceedings th international joint conference artificial intelligence pages 


krogh brown mian haussler 
hidden markov models computational biology applications protein modeling 
journal molecular biology 

lauritzen spiegelhalter 
local computations probabilities graphical structures application expert systems 
royal statistical society pages 

ljung 
theory practice recursive identification 
mit press cambridge ma 

mackay 
probable networks plausible predictions review practical bayesian methods supervised neural networks 
network computation neural systems 

meila jordan 
learning fine motion markov mixtures experts 
touretzky mozer hasselmo editors advances neural information processing systems 
mit press 

neal 
probabilistic inference markov chain monte carlo methods 
technical report crg tr department computer science university toronto 

neal 
bayesian learning neural networks 
springer verlag new york 

neal hinton 
new view em algorithm justifies incremental variants 
technical report department computer science university toronto 

parisi 
statistical field theory 
addison wesley redwood city ca 

pearl 
probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann san mateo ca 

rabiner juang 
hidden markov models 
ieee acoustics speech signal processing magazine 

rauch 
solutions linear smoothing problem 
ieee transactions automatic control 

rockafellar 
convex analysis 
princeton university press 

saul jordan 
mixed memory markov models 
madigan smyth editors proceedings conference artificial intelligence statistics 
ft lauderdale fl 

saul jordan 
exploiting tractable substructures intractable networks 
touretzky mozer hasselmo editors advances neural information processing systems 
mit press 

shumway stoffer 
approach time series smoothing forecasting em algorithm 
time series analysis 

smyth 
hidden markov models fault detection dynamic systems 
pattern recognition 

smyth heckerman jordan 
probabilistic independence networks hidden markov probability models 
neural computation 

tanner wong 
calculation posterior distributions data augmentation discussion 
journal american statistical association 

viterbi 
error bounds convolutional codes asymptotically optimal decoding algorithm 
ieee trans 

theory 

zemel 
minimum description length framework unsupervised learning 
ph thesis dept computer science university toronto toronto canada 
