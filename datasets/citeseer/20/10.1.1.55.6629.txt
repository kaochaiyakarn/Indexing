unsupervised learning convex conic coding lee seung bell laboratories lucent technologies murray hill nj bell labs com unsupervised learning algorithms convex conic encoders proposed 
encoders find closest convex conic combination basis vectors input 
learning algorithms produce basis vectors minimize reconstruction error encoders 
convex algorithm develops locally linear models input conic algorithm discovers features 
algorithms model handwritten digits compared vector quantization principal component analysis 
neural network implementations involve feedback connections project reconstruction back input layer 
vector quantization vq principal component analysis pca widely unsupervised learning algorithms fundamentally different ways encoding data 
vq input encoded index closest prototype stored memory 
pca input encoded coefficients linear superposition set basis vectors 
vq capture nonlinear structure input data weak highly localized grandmother neuron representation 
prototypes typically required adequately represent input data number dimensions large 
hand pca uses distributed representation needs small number basis vectors model input 
unfortunately model linear structures 
learning algorithms convex conic encoders introduced 
encoders constrained vq constrained pca 
result affine conic convex affine convex conic hulls basis vectors 
able produce sparse distributed representations efficient compute 
resulting learning algorithms understood approximate matrix factorizations implemented neural networks feedforward feedback connections neurons 
affine convex conic point encoding set basis vectors linear combination called affine convex conic complete set affine convex conic combinations called respectively affine convex conic hulls basis 
hulls geometrically depicted 
convex hull contains interpolations basis vectors affine hull contains convex hull linear extrapolations 
conic hull contains convex hull constrained stay set 
extends nonnegative combination basis vectors forms cone vector space 
encoders considered 
convex conic encoders novel find nearest point input convex conic hull basis vectors 
encoders compared known affine point encoders 
affine encoder finds nearest point affine hull equivalent encoding pca point encoder vq finds nearest basis vector input 
encoders minimize reconstruction error min va fl fl fl fl fl gamma fl fl fl fl fl constraints convex conic affine encoders described 
point encoding thought heavily constrained optimization eq 
single equal unity rest vanish 
efficient algorithms exist computing encodings 
affine point encoders fastest 
affine encoding simply linear transformation input vector 
point encoding nonlinear operation computationally simple involves minimum distance computation 
convex conic encoders require solving quadratic programming problem 
encodings computationally demanding affine point encodings polynomial time algorithms exist 
tractability problems related fact cost function eq 
local minima convex domains question 
encodings contrasted computationally inefficient ones 
natural modification point encoder combinatorial expressiveness obtained allowing vector zeros ones 
unfortunately constraint optimization eq 
integer programming problem quite inefficient solve 
convex conic encodings input generally contain coefficients vanish due nonnegativity constraints optimization eq 

method obtaining sparse encodings distinct method simply truncating linear combination discarding small coefficients 
learning correspond learning algorithms encoders described minimize average reconstruction error ensemble inputs 
training set examples arranged columns theta matrix learning encoding minimization expressed min kx gamma wv kxk summed squares elements learning encoding described approximate factorization data matrix theta matrix basis vectors theta matrix code vectors 
assuming input vectors scaled range constraints optimizations eq 
affine ia convex ia conic ia 
nonnegativity constraints prevent cancellations occurring linear combinations importance seen shortly 
upper bound chosen basis vectors normalized range inputs noted earlier computation encoding tractable cost function eq 
quadratic function considered function cost function quartic finding global minimum learning difficult 
issue local minima discussed example 
example modeling handwritten digits applied affine convex conic vq learning usps database consists examples handwritten digits segmented actual zip codes 
training test images normalized theta grid affine pca vq conic convex basis vectors vq affine convex conic learning 
pixel intensities range 
noticeable segmentation errors resulting digits images left training test sets 
training examples segregated digit class separate basis vectors trained classes encodings 
shows results digit class basis vectors 
means algorithm find vq basis vectors shown 
encoding discontinuous highly constrained space exist local minima eq 

order deal problem algorithm restarted various initial conditions best solution chosen 
resulting basis vectors look templates blurry basis vector mean large number input images 
affine determines affine space best models input data 
seen individual basis vectors obvious interpretation 
space affine unique representation basis vectors degenerate 
set linearly independent vectors drawn affine space represent 
due fact product wv invariant transformation ws gamma convex finds basis vectors convex hull best fits input data 
optimization performed alternating projected gradient steps constraint column sums equal unity implemented affine essentially equivalent pca represent affine space different ways 
affine represents points chosen space 
pca represents affine space single point space gamma orthonormal directions 
degenerate representation pca fixes point sample mean gamma directions eigenvectors covariance matrix largest eigenvalues 
input image conic coding convex coding conic reconstructions convex reconstructions activities reconstructions conic convex coding 
adding quadratic penalty term 
contrast affine basis vectors interpretable templates blurred vq 
elements zero minimum 
eliminates invariant transformations violate nonnegativity constraints simulations appears degeneracy seen affine lifted nonnegativity constraints 
conic finds basis vectors conic hull best models input images 
learning algorithm similar convex penalty term sum activities 
conic representation allows combinations basis vectors just interpolations 
result basis vectors features templates seen 
contrast affine nonnegativity constraint leads features interpretable correlated strokes 
number basis vectors increases features decrease size individual pixels 
models classify novel test images 
recognition accomplished separately reconstructing test images different digit models associating image model having smallest reconstruction error 
illustrates example classifying conic convex encodings 
basis vectors displayed weighted sparsity representations clearly seen 
bottom part shows different reconstructions generated various digit models 
patterns digit class convex incorrectly classified digits test examples error rate 
virtually identical performance nearest neighbor errors linear pca models errors 
scaling convex models patterns results error rate errors 
improvement arises larger convex hulls better represent nonlinear nature input distributions 
performance relative methods prior knowledge invariances support vector machine 
methods prior knowledge nearest neighbor tangent distance 
hand conic coding results error rate errors 
larger basis sets conic shows worse performance features shrink small spots 
results indicate conic yield models non trivial correlations remain need taken account 
instance conic basis fit quite little reconstruction error codes distinct fits 
neural network implementation conic convex described matrix factorizations 
alternatively encoding performed neural network dynamics learning synaptic update rule 
describe implementation conic network convex network similar 
conic network layer error neurons layer encoding neurons fixed point encoding dynamics dv dt ia de dt gamma ia optimizes eq 
finding best convex encoding input rectification nonlinearity max enforces nonnegativity constraint 
error neurons subtract reconstruction input excitatory connection equal opposite inhibitory connection back hebbian synaptic weight update deltaw ia convergence encoding dynamics input respecting bound constraints ia performs stochastic gradient descent ensemble reconstruction error learning rate discussion convex coding similar locally linear models 
distance convex hull previously nearest neighbor classification learning algorithm proposed 
conic coding similar noisy models 
main difference previous models contain discrete binary variables conic uses continuous ones 
analog binary variables encoding computationally tractable allows interpolation basis vectors 
emphasized geometrical interpretation convex conic coding 
viewed probabilistic hidden variable models 
inputs visible hidden variables reconstruction error eq 
related log likelihood log jv 
explicit model hidden variables limited quality conic models particular 
feature discovery capabilities conic promising tool building hierarchical representations 
currently working extending new coding schemes learning algorithms multilayer networks 
acknowledge support bell laboratories 
burges cortes lecun providing usps database 
grateful clarkson freund kaufman saul wright helpful discussions 
hinton ge zemel rs 
minimum description length helmholtz free energy 
advances neural information processing systems 
ghahramani 
factorial learning em algorithm 
advances neural information processing systems 
olshausen ba field dj 
emergence simple cell receptive field properties learning sparse code natural images 
nature 
le cun 

backpropagation applied handwritten zip code recognition 
neural comput 

scholkopf burges vapnik 
extracting support data task 
kdd proceedings 
simard le cun denker 
efficient pattern recognition new transformation distance 
advances neural information processing systems 
tank dw hopfield jj 
simple neural optimization networks converter signal decision circuit linear programming circuit 
ieee trans 
circ 
syst 
cas 
bezdek jc watson 
detection characterization cluster substructure 
siam appl 
math 

bregler omohundro sm 
nonlinear image interpolation manifold learning 
advances neural information processing systems 
hinton ge dayan revow 
modeling manifolds images handwritten digits 
ieee trans 
neural networks submitted 
hastie simard sackinger 
learning prototype models tangent distance 
advances neural information processing systems 
haas hpa backer 
convex hull nearest neighbor rule 
fifth intl 
conf 
pattern recognition proceedings 
dayan zemel rs 
competition multiple cause models 
neural comput 

saund 
multiple cause mixture model unsupervised learning 
neural comput 

freund haussler 
unsupervised learning distributions binary vectors layer networks 
advances neural information processing systems 
