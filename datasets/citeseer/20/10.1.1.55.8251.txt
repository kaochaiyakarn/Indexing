estimators long range dependence empirical study murad taqqu boston university teverovsky boston university walter willinger bellcore various methods estimating self similarity parameter intensity long range dependence time series available 
reliable 
discover ones best apply different methods simulated sequences fractional gaussian noise fractional arima 
provide theoretical justification method residuals regression 
time series long range dependence appear contexts example analysis traffic load high speed networks see leland taqqu willinger wilson 
methods estimating self similarity parameter intensity long range dependence time series available described detail monograph beran 
typically validated appealing self similarity asymptotic analysis supposes sample size time series converges infinity 
leaving question robustness aside want find methods function applied fractional gaussian noise fractional arima 
idealized time series estimation methods perform particularly 
fairly large sample size generated different realizations values compared estimated values nominal ones simulation 
research partially supported nsf ncr dms boston university 
organized follows 
section define fractional gaussian noise fractional arima section describe briefly estimation methods 
results simulations section 
time series describe fractional gaussian noise fgn fractional arima farima types time series simulations 
simplest models display long range dependence 
best way introduce fractional gaussian noise parent fractional brownian motion 
fractional brownian motion gaussian process mean stationary increments variance eb covariance bh fs gamma js gamma tj statistically self similar sense distributions fa bh 
crucial index parameter takes values called self similarity parameter 
fractional gaussian noise fx increment fractional brownian motion bh gamma bh mean zero stationary gaussian time series autocovariance function fl ex fl gamma gamma jh gamma important point fl satisfies fl gamma gamma means asymptotic 
fl white noise case 
positively correlated say display long range dependence long memory 
index context measures intensity long range dependence 
spectral density fourier transform fl ch sin gamma kj ch jj gamma ch constant 
fractional gaussian noise consider fractional arima 
defined formally delta gammad ffl ffl independent identically distributed normal random variables mean variance delta differencing operator ffl gamma ffl gamma way interpret delta gammad ffl fractional value moving average ffl gammaj gamma gamma gamma gamma observe gamma gamma gamma autocovariance function fl ex delta gammad ffl satisfies fl gamma gamma gamma gamma sin large lags autocovariance power decay autocovariance fractional gaussian noise 
relating exponents gives gamma advantage fractional gaussian noise fractional arima asymptotic relations stated section hold finite sample sizes 
fractional gaussian noise increment self similar process fractional brownian motion 
advantage fractional arima fractional gaussian noise particularly simple spectral density sin gamma jj gamma particular case fractional arima versatile parametric family models 
fractional arima defined equations phi theta delta gammad ffl phi theta involve autoregressive moving average coefficients respectively 
going refer reader taqqu monograph details 
fractional gaussian noise series simulated durbin levinson algorithm implemented plus routines 
algorithm described example davis chapter provides autoregressive representation gaussian time series 
fractional arima series produced arima sim command built plus version plus statistical package marketed 
generation method durbin levinson algorithm described raftery 
generate gaussian time series delta delta delta mean zero autocovariance function fl durbin levinson algorithm generate sequence ffl independent identically distributed random variables 
set fl ffl suppose obtained 
oe delta delta delta oe ffl variances delta delta delta coefficients foe delta delta delta ng computed recursively 
set fl gamma gamma oe oe fl gamma gamma oe gamma fl gamma gamma gamma oe oe gamma gamma oe oe gamma gammai methods estimating aggregated variance method divide original time series fx blocks size average block consider aggregated series km gamma successive values index labels block 
take sample variance delta delta delta block 
sample variance estimator varx fractional gaussian noise fractional arima varx oe fi fi gamma obtain estimate fi proceeding follows 
divide data xn blocks size calculate sample variance var gamma repeat procedure different values plot logarithm sample variance versus log choose values fm equidistant log scale constant depends length series desired number points 
var estimate varx resulting points form straight line slope fi gamma gamma fi 
practice slope estimated fitting line points obtained plot 
assumed large length block number blocks large 
short range dependence slope obtained equal gamma slope line 
differencing variance common types non stationarity include jumps mean slowly decaying trends 
distinguish long range dependence difference variance see teverovsky taqqu details study varx gamma varx defined preceding subsection 
differencing introduces additional fluctuations provides way detecting types non stationarity mentioned 
best conjunction basic aggregated variance method 
absolute values aggregated series method similar method aggregated variance 
data split way aggregated series calculated 
computing sample variance finds sum absolute values aggregated series fi fi fix fi fi fi logarithm statistic plotted versus logarithm original series long range dependence parameter result line slope gamma 
higuchi method method suggested higuchi 
involves calculating length path principle finding fractal dimension method fact similar method absolute values aggregated series discussed 
involves partial sums original time series fx ng producing fractional brownian motion fractional gaussian noise finding normalized length curve gamma gamma gamma gammai fi fi fiy km gamma gamma fi fi fi length time series essentially block size denotes greatest integer function 
el chm gammad gamma log log plot versus produce straight line slope gamma residuals regression method peng involves steps 
series broken blocks size blocks partial sums series calculated 
call partial sums block fit squares line compute sample variance residuals 
procedure repeated blocks resulting sample variances averaged 
blocks size equivalent calculating sample variance entire series 
prove appendix large resulting number proportional fractional gaussian noise similar result holds fractional arima 
result plotted log log plot versus get straight line slope 
method better known methods 
discussed detail mandelbrot wallis mandelbrot mandelbrot taqqu 
time series fx partial sum sample variance gamma statistic rescaled adjusted range max tn gamma gamma min tn gamma fractional gaussian noise fractional arima ch positive finite constant dependent determine statistic proceed follows 
time series length subdivide series blocks size lag compute starting points values smaller gets different estimates 
values approaching gets fewer values gamma choosing logarithmically spaced values plot log versus log get points plot 
plot called pox plot statistic 
parameter estimated fitting line points pox plot 
short range dependence series typically results transient zone low plot set cut point low plot purposes estimating usually high plot points plot high reliable estimates 
values lie lower higher cut points estimate periodogram method calculates fi fi fi ij fi fi fi frequency number terms series data 
estimator spectral density series long range dependence periodogram proportional jj gamma close origin 
regression logarithm periodogram logarithm frequency give coefficient gamma 
provides approximation parameter practice lowest roughly frequencies regression proportionality holds close origin 
modified periodogram method modification periodogram method compensates fact log log plot frequencies fall far right exerting strong influence squared line fitted periodogram 
frequency axis divided logarithmically equally spaced boxes periodogram values corresponding frequencies inside box averaged 
values low frequencies left untouched 
study points left rest divided boxes 
line fit resulting points 
periodogram scattered squares splus formally trimmed squares regression minimizes sum smallest squared residuals 
whittle estimator whittle estimator periodogram 
involves function gamma periodogram see spectral density frequency denotes vector unknown parameters 
whittle estimator value minimizes function dealing fractional gaussian noise fractional arima simply parameter series assumed farima see includes unknown coefficients autoregressive moving average parts 
estimator takes time obtain obtains confidence intervals 
details see fox taqqu beran 
estimators discussed whittle estimator obtained non graphical method 
assumes parametric form spectral density known 
description results generated realization fractional gaussian noise points 
figures illustrate log log plot corresponding estimation methods naturally whittle 
drawn basis single realization 
value generated realizations long fractional gaussian noise fractional arima 
included fractional gaussian noise white noise sequence 
estimated values expressed terms 
estimation method obtained estimated values called fh delta delta delta 
computed mean standard deviation oe gamma gamma mse gamma nominal square root mse mean squared error provides information bias 
nominal value generate fractional gaussian noise fgn fractional arima farima 
estimation methods discussed 
results table 
box plots graphical representation results table 
vertical axis figures indicates deviation nominal value method box representing middle data 
box contains shaded region representing approximate confidence interval median see mcgill tukey larsen median represented unshaded line middle shaded region whiskers encompassing approximately data designated dashed lines outliers fell whiskers 
appendix provide theoretical justification residuals regression method described subsection 
simplicity suppose time series fractional gaussian noise unit variance proof fractional arima essentially 
log log variances aggregated variance method log log variances aggregated variance method differencing log log absolute absolute value method log log curve length higuchi method estimating simulated fgn 
log log variances residuals variance residuals method log log method 
log frequency log periodogram periodogram method log frequency log periodogram modified periodogram method estimating simulated fgn 
estimation nominal method fgn plus farima variance oe mse oe mse absolute oe mse higuchi oe mse var 
residuals oe mse oe mse periodogram oe mse modified periodogram oe mse whittle oe mse table estimation results independent realizations long 
estimators applied fgn deviation nominal value boxplots results independent realizations estimators applied arima deviation nominal value boxplots results independent realizations recall apply method divides time series blocks size block computes partial sums fy delta delta delta mg fits regression bt partial sums computes sample variance 
claim expectation sample variance asymptotically proportional theorem 
gamma gamma bt chm ch gamma proof data supposed fractional gaussian noise partial sums fractional brownian motion covariance 
slope intercept square line gamma gamma gamma gamma bt gamma mb equation sums gamma gamma bt ix bt gamma ay gamma abt ix gamma gamma ty ab ix gamma mb gamma ty gamma ix gamma gamma mb ix ix gamma gamma ix gamma ty gamma ix gamma ix gamma ty ix ty gamma ty gamma ix gamma ix gamma ix ty gamma ty ix ix ty gamma ix ty ix ix ty gamma ix gamma ix gamma ix ty ix ty ix gamma ix gamma ix ty ix ty gamma gamma equation represented terms respectively calculate 
gamma jj gamma kj gamma gamma gamma gamma dx gamma ty gamma jjj gamma kj jk gamma gamma gamma gamma gamma gamma dx gamma gamma dx gamma gamma gamma ty jk gamma gamma kj jk gamma jk gamma gamma gamma dx gamma gamma gamma going back gamma gamma bt gamma gamma chm ch 
dividing terms expression yields result 
beran 
statistics long memory processes 
chapman hall new york 
davis 
time series theory methods 
springer verlag new york nd edition 
fox taqqu 
large sample properties parameter estimates strongly dependent stationary gaussian time series 
annals statistics 
raftery 
space time modelling long memory dependence assessing ireland wind power resource 
applied statistics 
includes discussion 
higuchi 
approach irregular time series basis fractal theory 
physica 
leland taqqu willinger wilson 
self similar nature ethernet traffic extended version 
ieee acm transactions networking 
mandelbrot 
limit theorems self normalized range weakly strongly dependent processes 
zeitschrift fur und gebiete 
mandelbrot taqqu 
robust analysis long run serial correlation 
proceedings nd session international statistical institute 
bulletin international statistical institute 
vol book pp 

mandelbrot wallis 
computer experiments fractional gaussian noises parts water resources research 
mcgill tukey larsen 
variation box plots 
american statistician 
peng simons stanley goldberger 
mosaic organization dna nucleotides 
physical review 
taqqu 
linear models long range dependence finite infinite variance 
brillinger geweke parzen rosenblatt taqqu editors new directions time series analysis part ii pages new york 
ima volumes mathematics applications volume springer verlag 
taqqu 
stable non gaussian processes stochastic models infinite variance 
chapman hall new york london 
teverovsky taqqu 
testing long range dependence presence shifting means slowly declining trend variance type estimator 
preprint 
murad taqqu teverovsky boston university department mathematics street boston ma usa email murad math bu edu vt math bu edu walter willinger bellcore morristown nj usa email walter bellcore com 
