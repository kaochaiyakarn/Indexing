quadratic optimization floudas visweswaran department chemical engineering princeton university princeton nj usa 
quadratic optimization comprises important areas nonlinear programming 
numerous problems real world applications including problems planning scheduling economies scale engineering design control naturally expressed quadratic problems 
quadratic problem known np hard interesting challenging class optimization problems 
chapter review various properties quadratic problem discuss different techniques solving various classes quadratic problems 
successful algorithms solving special cases bound constrained large scale quadratic problems considered 
examples various applications quadratic programming 
summary available computational results algorithms solve various classes problems 
key words quadratic optimization bilinear programming concave programming indefinite quadratic quadratic test problems 

nonlinear programming problems arise mathematical modeling problems real world applications 
large number problems formulated quadratic programming problems qp quadratic objective function linear set equality inequality constraints 
primarily quadratic programming linear constraints viewed generalization linear programming problem lp quadratic objective function 
encompasses lp problems including applications scheduling planning flow computations 
quadratic programming known np hard means interesting combinatorial optimization problems posed quadratic programming framework 
addition quadratically constrained quadratic programs occur frequently engineering modeling design control 
apart indirect applications classes problems naturally expressed quadratic problems 
examples problems planning scheduling game theory problems involving economies scale facility allocation location problems quadratic assignment problems involve mixed variables quadratic formulation problems engineering design number problems microeconomics 
area chemical engineering process modeling quadratic models formulate problems pooling blending multiperiod quality problems author correspondence addressed floudas visweswaran problems involving separation sequences 
certain aspects vlsi chip design formulated linearly quadratically constrained quadratic models 
clear quadratic programming problem great importance mathematical application viewpoints 
reflected large number approaches proposed solution problems 
traditionally quadratic problems treated subclass general nonlinear programming problem methods solving problems relied local optimization techniques 
years attempts developing global optimization algorithms class problems 
noted global optimization algorithms developed general nonlinear programming problem 
comprehensive review algorithms pardalos rosen pardalos rosen horst tuy 
global optimization approaches general nonconvex nonlinear problem including approaches quadratic optimization primarily classified deterministic stochastic approaches 
review restrict deterministic approaches quadratic optimization 
approaches general nonlinear global optimization reader referred tuy floudas 
shor hansen 

developments global optimization approaches floudas pardalos 
discussions stochastic methods mockus torn 
reader referred chapters concave minimization programming stochastic optimization lipschitz optimization handbook 
rest chapter organized follows 
section definition general quadratic problem linear constraints classification structure problem 
section discusses basic properties class problems including various forms necessary conditions optimality provides known results characterize solution 
section discuss quadratic problem view point complexity show problems difficult solve 
sections discuss particular nature bilinear concave indefinite quadratic problems respectively overview existing algorithmic approaches 
section considers algorithms solving general form quadratic problem problems quadratic objective functions quadratic constraints 
section briefly outlines relations quadratic programming linear complementarity problems 
section presents examples application areas formulated quadratic programming framework 
section discusses available computational results bilinear concave indefinite quadratic programming problems quadratically constrained problems 

general quadratic programming problem general quadratic problem consists quadratic objective function set linear inequality constraints shown quadratic optimization min dx ax vector vector theta matrix theta matrix 
loss generality may assumed symmetric 
case converted symmetric form replacing change value objective function 
similarly problem variables necessarily nonnegative converted linear transformation 
matrix positive semidefinite positive definite convex programming problem 
local optimum equivalent global optimum convex problems solved number algorithms convex quadratic programming 
particular known convex quadratic problem class problems solvable polynomial time exist polynomial time algorithms applied solve problems 
example data problem integers chung murty showed ellipsoid algorithm khachiyan solve convex quadratic programming problems polynomially bounded computation time 
polynomial time algorithm problem 

polynomial algorithms including interior point approaches convex quadratic programming proposed nesterov monteiro adler ye ben shetty monteiro 
goldfarb liu 
large number algorithms convex nonlinear programming applied solve 
cases interest viewpoint global optimization positive semidefinite 
cases nonconvex problem application local optimization procedures problem longer guarantee identification global optimum 

classification quadratic programming problems main basis classification quadratic problems form comes nature quadratic matrix quadratic problems classified 
bilinear problems matrix exist subvectors distinct variables problem linear vectors fixed 
problems termed bilinear problems considered section 
concave quadratic problems matrix negative semidefinite eigenvalues nonpositive problem reduces concave minimization 
discussed detail section 
indefinite quadratic problems problems arise matrix positive negative eigenvalues 
view point solution class problems intractable subclasses consequently floudas visweswaran methods solving problems 
available approaches solving indefinite quadratic problems discussed section 
noted problems categories converted forms see konno hansen jaumard examples achieved 
algorithms address classes problems categories 

optimality conditions solution characterization starting point approaching solution review gathered general duality theory nonlinear programming problems 
lagrange function dx ax gamma gamma lagrange multipliers inequality nonnegativity constraints respectively 
order karush kuhn tucker kkt optimality conditions written follows shetty gamma ax gamma ax gamma stationarity condition complementary slackness conditions ensure feasibility resulting solution 
point satisfies called kkt stationary point 
shown optimal solution kkt point regardless positive semidefinite 
converse necessarily true 
words kkt conditions necessary quadratic problems convex sufficient convex problems 

feasible descent directions optimality conditions possible formulate necessary sufficient conditions local optimality concept feasible descent direction point 
feasible point vector feasible direction exists ffl td feasible ffl 
vector said descent direction exists ffl td ffl 
vector feasible descent direction feasible direction descent direction 
conditions equivalent kkt conditions theorem necessary sufficient conditions local optimality denotes dx gradient objective function denotes subset constraints active necessary sufficient condition local minimizer quadratic optimization ii dd 
proof 
see theorems vavasis 
easily shown condition theorem combined feasibility requirement leads kkt conditions 
condition ii simply additional second order optimality condition 
follows direct corollary conditions ii feasible descent direction local optimum theorem shows equivalence corresponding linear problem sufficient test global optimality 
theorem murty optimum solution optimum solution lp min ax 
active constraints optimality interesting results quadratic problems comes consideration active set constraints optimal solution 
theorem taken hager adaptation original theorem general nonlinear programming problem theorem point matrix negative eigenvalues counting multiplicities active constraints theorem provides direct correlation geometric structure feasible region algebraic structure matrix 
follows directly negative eigenvalues extreme point feasible region 
consequently problems objective function bounded feasible set optimal solution results follow concave quadratic problems exists optimal solution extreme point feasible set 
indefinite quadratic problems exists optimal solution boundary point feasible set 
exists optimal solution interior point facet polytope defined feasible set exactly negative eigenvalue 
results particularly useful algorithms active set strategy solving 
floudas visweswaran 
global optimality criteria large number necessary sufficient conditions local optimality applicable solutions results global optimality 
criterion specifically directed theorem theorem exist choice real numbers optimal solution minimizes dx gamma bj nonnegative orthant fl ax minimizes dx jax gamma bj optimal solution 
clear theorem implemented practice 
useful criterion checking global optimality negative definite comes considering shown theorem 
theorem bomze negative definite feasible point 
sets active constraints gamma ax slacks inactive constraints 
define gammaa qx gamma qx gamma gamma fv av ax gamma fv gamma av mg gamma fv gamma av av av mg denotes ith row global solution kkt point gamma mg 
satisfies qx gamma gamma mg 
practice involves gamma problems checking gamma 
worst case exponential complexity checking local optimality 

complexity issues nonconvex quadratic programming problem hard consequently interesting solve 
reason partly understood analyzing complexity problems 
analysis provide firm results worst case scenarios give idea possibility developing efficient algorithms solving problem 
long known general nonconvex nonlinear problem tough problem solve 
case quadratic programming result quadratic optimization direction sahni showed negative definite matrix qp np hard 
result proved vavasis showed result reduction qp satisfiability problem pardalos proved reduction knapsack feasibility problem 
authors shown qp np np complete problem 
murty showed result special cases qp 
vavasis proved decision version qp np complete 
mainly theoretical result helps determine complexity qp exactly 
results surprising 
fact shown just checking local optimality qp np hard problem murty vavasis 
pardalos schnitger showed result proving checking strict convexity requirement checking local optimality part second order necessary conditions problems np hard exception combined fact large number local minima problem intractability general qp obvious 
consider example qp min gamma gamma problem local minimum vertex feasible region sigma sigma sigma points 
general qp expected solved global minimum efficiently 
fact finding local minimum proving local optimality solution may take exponential time 
results concern general case 
cases small number concave variables 
natural expect problems easier solve 
shown pardalos vavasis matrix rank exactly negative eigenvalue problem np hard 
larger number negative eigenvalues necessarily problem harder solve 
consider example problem min dx decision version quadratic programming problem posed follows number exist dx ax concave quadratic problems local solution lie vertex feasible region 
vertex adjacent vertices computed polynomial time 
verify local optimality vertex sufficient consider optimality simplex defined adjacent vertices 
involves solving linear number objective function adjacent edges 
concave case local optimality verified polynomial time 
floudas visweswaran suppose gamma eigenvalues negative 
hager 
showed gamma active constraints optimal solution 
words find optimal solution sufficient solve gamma different problems case setting gamma constraints equalities 
general gamma negative eigenvalues need solve 
gammak 
independent problems 
shown total computational time required solve problem proportional 
gammak 
fixed constant independent computational time bounded polynomial grows example problem solution time grow exponentially 
bilinear programming problems earliest applications involving quadratic programming formulation comes class bimatrix games 
games involve fixed sets strategies available players select mixed strategy involving payoffs 
problem investigated nash introduced concept nash equilibrium point nep problems 
probability vectors mixed strategies payoff matrices players nep solution problem ay max ay max sets permissible strategies players phi psi phi psi unit vector shown finding nep bimatrix game equivalent finding global solution bilinear programming problem max gamma gamma ay gamma gamma constraints imposed set available strategies player reduces classical bilinear programming problem disjoint constraints 
problem written min dy quadratic optimization note qp reduced form keeping introducing additional set constraints addition problems dynamic markovian assignment problems multi commodity network flow problems complementarity problems written form 
set theta feasible solutions problem generally polyhedral convex set may bounded vertex theta ordered pair vertices easily shown optimal solution extreme point optimal solution 
property utilized extensively develop algorithms solving 
approaches may properly termed vertex enumeration methods 
proposed algorithm solving utilizes method maximizing linear function convex hull vertices convex polyhedral set 
order eliminate vertices linear objective increase algorithm uses method ranking vertices set proposed murty 
approach extended solving standard qp reduction bilinear formulation 
earliest methods solving utilized cutting planes 
methods inspired done concave problems tuy ritter 
methods proposed konno proposed solving ritter cuts eliminate karush kuhn tucker points generated algorithm 
konno method considered natural approach solving bilinear problems form 
method consists starting arbitrary fixed solving related linear problem min dy solution problem solve linear problem min dy turn yields new value procedure repeated pair values solves linear programs 
point shown kkt point 
linear cut constructed delete process repeated reduced feasible domain obtained 
konno theoretically guarantee convergence algorithm counterexample date show method fails 
floudas visweswaran shetty proposed specialized polar cuts solve bilinear programs showed cuts deeper proposed konno 
algorithm converges ffl approximate solution limit asymptotic convergence exact convergence global optimum guaranteed 
shetty modified algorithm tuy generate facets polytope consideration able avoid problems cycling original algorithm tuy exhibited 
number facets need generated large approach computationally feasible larger problems 
sherali shetty improved algorithm shetty simultaneously employing negative edge extension cuts disjunctive face cuts able prove finite convergence procedure 
approach probably efficient algorithm available bilinear programming problem disjoint constraint sets 
bilinear approached viewpoint linear duality theory 
shown falk problem written equivalent linear max min problem 
formulation falk proposed branch bound algorithm solve note algorithm guarantee convergence finite number steps gallo developed algorithms cutting planes second enlarging polytope approach modifications algorithms proposed tuy concave programming 
algorithms proof convergence counterexamples exist second algorithm cycles 
general formulation bilinear programming problem consider case joint constraints cases problem written min dy ax easy show general quadratic problem converted form 
class problems converted form set linear complementarity problems 
problems form received considerably attention literature compared problem 
primarily problems solution longer guaranteed lie vertex feasible region lie boundary defined linear constraint set 
algorithm solving proposed falk considered branch bound approach solving problem convex envelopes objective function 
algorithm utilizes fact minimum bilinear functional convex set minimum convex quadratic optimization envelope set 
problem converted form min ax dy bilinear term rectangle convex envelope term gamma gamma convex envelope bilinear objective term iteration algorithm current rectangular region partitioned nodes 
convex envelope objective function minimized subset feasible region current partition helps provide bound global solution 
algorithm shown converge limit 
specific instances algorithm shown finite convergence 
improvements enable direct application algorithm general problems resorting increasing number variables constraints 
sherali proposed reformulation linearization algorithm solving bilinear problem form 
approach consists generating valid quadratic constraints pairwise products linear inequalities products inequalities variables subsequently linearizing quadratic constraints defining new variables 
bilinear objective term similarly linearized 
results lower bounding linear program 
resulting linear program generates lower bound theoretically dominates bound produced algorithm falk practice provides tighter bounds 
partitioning process algorithm modified generate node subproblems 
computational results approaches provided small size problems variables 
matrix low rank problem reduces special form minimizing linear multiplicative functional subject linear constraint set 
class problems efficient approaches proposed solution konno kuno konno kuno konno konno 
approaches parametric simplex algorithms solve problem computational performances comparable similar size linear programming problems 
floudas visweswaran 
transformation quadratic problems bilinear problems importance bilinear direct applications classes quadratic problems indefinite concave quadratic problems transformed bilinear formulations 
easiest way achieve introducing new variables constraints floudas aggarwal floudas 
hansen jaumard proposed graph theoretic results algorithm efficient general quadratic problems 
algorithm provides set new variables introduced order convert problem bilinear form 
achieved objective minimizing number variables number new variables introduced order problem completely bilinear 
bilinear problem variable subsets algorithm identify changes subsets result smaller number variables 
liu floudas shown perturbation theory large class smooth mathematical programming problems converted biconvex bilinear form 

concave problems concave quadratic problems arise fixed charge problems problems involving economies scale 
certain aspects vlsi chip design formulated concave watanabe 
addition classes optimization problems reformulated concave classical quadratic assignment problem example 
example problems class integer programming problems formulated concave qp linear constraints 
certain conditions boundedness objective function continuity general nonlinear nonconvex mixed integer program reduced concave program necessarily quadratic 
general bilinear programming problem disjoint constraint set equivalent concave minimization konno 
frieze reduced dimensional assignment problem bilinear formulation special concave form 
concave quadratic problems far simplest qp necessarily easiest terms solution qp 
mentioned earlier solutions local global concave qp lie vertex feasible region considerable amount research focused utilizing property order solve concave qp 

extreme point ranking methods solution concave quadratic programming problem lies vertex polytope natural method solve problem complete enumeration extreme points 
face problems relatively easy solve easy construct concave vertex feasible set local minimum 
worst case enumeration vertices take exponential amount time 
quadratic optimization basic idea methods extreme point ranking 
words vertices polytope defining feasible region ranked order importance regarding global solution 
starting vertices polytope nearby vertices ranked extreme point approach 
provides new vertex move process continues adjacent vertices decreasing objective function value 
step usually linear programming problem solved provide bound global optimum 
francis proposed approach lp solved linear concave function objective function lp utilizing extreme point ranking approach proposed murty 
proposed nonlinear programming duality theory lexicographic ordering basic feasible solutions vertices order obtain lower bounds objective function basis finitely convergent global optimization algorithm concave problems 
techniques proposed ranking enumeration vertices polyhedral set 
surveys comparisons methods rubin dyer 
computational effectiveness extreme point ranking algorithms discussed mckeown 
general extreme point ranking methods attractive worst case approaches degenerate complete inspection vertices 
consequently approaches computationally feasible large problems 

cutting plane methods years large number approaches proposed solving concave quadratic programming problems approaches ones traced back seminal tuy 
tuy considered general case minimization arbitrary concave function necessarily quadratic linear constraints 
approach existence vertex solutions problems 
addition tuy recognized property concave functions property concave function defined convex set exists concave extension concave extension 
useful property region outside polytope values concave extension utilized restricting number vertices polytope need considered 
tuy basic approach involved starting specific vertex polytope 
edges polyhedron issuing vertex define cone contains feasible region 
tuy proposed cuts successively reduce cone 
cuts essentially eliminate parts feasible region consideration 
step auxiliary subproblem solved gives rise new vertex point possibly better candidate global solution 
advantage approach iteration auxiliary problem set constraints constraints corresponding floudas visweswaran original polytope differ objective function 
objective function step obtained previous iteration simple linear transformation column replacement 
noted method relies vertices nondegenerate 
case degeneracy suitable perturbation method needs 
similar approach cutting planes reduce feasible region proposed ritter 
shown proposed approaches 
cited examples show methods fail converge due cycling need infinite sequence cutting planes 
reason cycling behavior approaches lies fact approaches generate cones algorithm failed explicitly incorporate cones remaining steps 
essential avoid vertices considered 
difficulty approaches recognized proposed modified ffl convergent approach iteration constraints added ensure solution lp iteration contained cone vertex current local minimum perturbed set extreme rays coincident vertex 
similar algorithms proposed bali jacobsen 
shown tuy ffl algorithm essentially bali algorithm 
convergence bali algorithm open question depending separation property may hold general case 
variants tuy algorithm proposed glover 
general difficulties associated tuy cut approaches 
come fact guarantee convergence cuts feasible region need incorporated iteration 
cuts generate new vertices accounted way multiply indefinitely 
possible incorporate branch bound scheme monitor sequence subproblems generated local solutions tuy 
tuy proposed normal conical algorithm avoids exhaustive subdivision process earlier algorithm 

convex envelopes different approach solving concave quadratic problem developed convex envelope concave function 
concept developed stated theorem theorem falk hoffman convex envelope concave function taken convex domain point globally minimizes minimizes proof 
proof theorem deduced fact global minimum concave function lies vertex 
see falk hoffman details 
applicability theorem immediately obvious 
convex envelope function generally extremely hard generate quadratic optimization tough solving original problem 
case quadratic objective function linear constraint set quite easy generate convex envelope shown theorem theorem vertices bounded linear polyhedron convex envelope concave function defined expressed min ff ff ff ff ff ff ff proof 
see falk hoffman 
case concave minimization property utilized falk hoffman 
method uses linear underestimating functions developed convex envelopes original concave function different regions feasible domain involve cuts feasible region 
algorithm converges finitely 
disadvantage approach order approximate convex envelope implicitly size linear subproblems solved grows size iteration 
maximum number rows subproblems number subproblems solved limited original number constraints 
growth subproblems mainly addition new columns 

reduction bilinear programming concave quadratic program solved reduction solution associated bilinear programming problem 
shown konno proved negative definite constraints equalities problem equivalent bilinear problem min qy approach convex envelopes nonconvex function proposed authors 
originally falk proposed approach solve general nonconvex separable programming problem 
branch bound type approach solves series subproblems linear convex objective function minimized successive partitions feasible domain 
approach falk replaced original function piecewise linear convex envelope different regions employing branch bound approach minimize functions derive new underestimating functions case convergence achieved 
floudas visweswaran ax ay equivalent sense optimal solution solves 
conversely optimal optimal 
property enables application bilinear programming algorithms discussed section 
enables development specialized bilinear programming algorithms application concave quadratic problem 
konno approach propose cutting plane algorithm bilinear programming solve concave quadratic problem 
see konno konno problems methods solution similar approach 
similarly previous approach bilinear problems address nonconvex quadratic problem 
resulting bilinear problem greatly simplified problem structure verification necessary sufficient conditions existence optimal solution reduced solution lp case 

solution large concave linear terms existence large number local solutions expected concave qp solved efficiently small size problems 
computational results literature goodman rosen point indicating impractical solve problems number variables appearing quadratic terms 
approaches concave essentially treated problem assuming variables may appear nonlinearly problem formulation 
observed numerous problems practical interest large number variables appear linearly mathematical formulation 
number variables usually far exceeds number quadratic variables 
natural attempt take advantage fact small fraction variables appear nonlinearly 
cases solver minos murtagh saunders treats linear variables different way variables appearing nonlinearly efficiently 
major portion research years area consequently focused problems form dx ax new vector variables ae common approach solving obtain upper lower bounds optimal solution linear programming problems iterate bounds convergence achieved 
easy formulation upper bound quadratic optimization problem involves solving linear programming problem terms ignored problem min ax solution problem give vertex upper bound globally optimal solution 
linear terms dominate objective function global minimum approaches terminate immediately 
approaches large scale concave quadratic minimization variables linear original approach proposed rosen 
basic idea approach proposed ordinary concave global minimization take advantage ellipsoid level surfaces objective function find initial vertex eliminate rectangular domain enclosed level surface consideration 
approaches start finding global maximum point objective function feasible domain 
set orthogonal vectors vectors eigenvectors hessian obtained 
multiple cost row linear program rows solved max sigmau vertex solution corresponding minimum problems candidate global minimum gives upper bound global minimum 
rectangular domain constructed level set minimum objective value obtained multiple cost row programs 
concave quadratic case done eigenvalues eigenvectors hessian objective function way value vertices minimum objective function value 
involves level ellipsoid minimum value multiple cost row linear programs 
main effect partition exclude consideration 
remaining part feasible region partitioned subregions empty 
method approach falk hoffman solve concave problem subdomain 
case large scale concave problems form idea extended authors 
approaches step multiple cost row linear program solved order determine subdomain contains projection feasible region space nonlinear variables 
linear underestimating functions original concave function constructed minimized giving initial vertices start algorithms 
floudas visweswaran region partitioned branch bound scheme followed successively eliminates partitions obtains tighter bounds 
methods suggested partitioning proposes bisecting cut parallel faces 
rectangular subdomains linear lp solved region 
procedure repeated branch bound scheme improved bounds step 
proposes partitioning pyramids pyramid base faces predetermined vertex apex union pyramids giving original partition rosen proposed similar branch bound algorithm linear convex envelopes 
methods ffl approximate successively partition domain may close exactly vertex original feasible region 
comparison methods rosen shown time taken obtain ffl approximate solution increases linearly number linear variables number constraints 
indicates number nonlinearly appearing variables small approaches reasonably effective 

reduction separable form possible reduce concave quadratic problem separable quadratic form 
way achieve proposed rosen pardalos follows matrix compute real eigenvalues gammaq corresponding eigenvectors un un diag eigenvalues eigenvectors easily computed gammaq positive semidefinite matrix concave qp 
values computed multiple cost row linear program rows solved 
solutions programs qp reformulated separable form min gamma produced linear transformations assuming feasible region bounded concave separable function easily underestimated bounds linear functions 
usually generated meet bounds example function fl gamma fi fi upper bound region fi 
rosen pardalos utilized approach solve large scale concave programs 
step obtain bound relative error approx method converting concave qp separable form 
advantage preserves quadratic form 
useful error analysis algorithms may address original separable form 
quadratic optimization imation relative error difference approximation original objective function 
general relative error guaranteed 
approximate solution obtained satisfactory single mixed problem solved 
problem formulated single piecewise linear separable objective function 
phillips rosen proposed parallel algorithm large scale concave quadratic problems 
algorithm reduces concave objective function separable form 
iteration combines heuristic step attempts eliminate part feasible region parallel implementation multiple cost row linear programs 
algorithm guaranteed convergence finite number steps ffl approximate solution number subproblems need solved bounded ffl algorithm performs quite efficiently large problems maximum size nonlinear linear variables considered 
efficiency algorithm primarily comes effectiveness heuristic step practice parallel solution multiple cost row linear programs 

indefinite quadratic problems case matrix eigenvalues mixed sign presents problems quadratic optimization 
algorithms developed particular cases bilinear concave quadratic problems approaches proposed globally optimizing case indefinite quadratic objective 
efforts solving difficult class problems focused reducing indefinite quadratic problem bilinear concave minimization problem 
algorithms directly solving class discuss 

quadratic problems box constraints constraints variables lower upper bounds reduces form probably simplest problem global nonconvex minimization min dx may assumed loss generality necessary linear transformation convert problem form 
gives direct relationship qp box constraints fundamental problems combinatorial optimization minimizing quadratic function variables 
special case matrix zero diagonal entries shown rosenberg fractional solution exists optimal integer solution objective function value integer solution easily derived fractional 
problems form appear frequently solution partial differential equations discretized continuous time optimal control problems linear squares prob floudas visweswaran lems subproblems successive quadratic programming methods 
clear solution special importance 
due presence bound constraints problem possible develop alternate simplified set necessary conditions sufficient conditions local optimality 
ii represent th diagonal entry represent th row partial derivative respect theorem hansen holds theorem necessary conditions optimality point local minimum ii 
ii 
proof 
see propositions hansen 

point nondegenerate component lies upper lower bound gradient equal zero conditions sufficient ensure local optimality 
degenerate determining local solution np hard murty 
algorithms solving conditions theorem develop kind active set strategy approach 
method hansen 

branch bound method branching done sign order derivatives 
branching possible 
example eliminate variables necessarily 
branching done particular variable lies bound 
conditions result auxiliary subproblems solved node 
provide various optimality tests node tree 
algorithm best knowledge approach specifically aimed solving 
approaches solving concentrated similar necessary conditions sufficient conditions local minimum coleman 
quadratic optimization finding local solutions hope global 
circumstance important able check particular local minimum global problem 
fortunately possible deduce sufficient condition occur 
suppose nondegenerate local solution 
corresponding vectors multipliers lower upper bound constraints respectively 
gamma solution may assume loss generality matrix partitioned da db dc da thetam db theta gammam dc 
gammam theta gammam da gamma gamma diagonal matrix positive entries constructed positive semidefinite 
matrix constructed theorem proved theorem ii dx gamma gamma dx gamma gamma gamma ff ja gamma global minimum 
ff ja gamma unique global minimum 
proof 
see han 

various active set methods proposed solving local optimality 
efficient approach coleman problems large sparse matrices 
start algorithm matrix subject cholesky factorization 
step factorization floudas visweswaran particular diagonal entry positive variable taken matrix set zero 
diagonal entry nonpositive variable set lower upper bound depending solution trivial quadratic problem variable 
factorization free set variables variables bound submatrix corresponding free set starting point algorithm obtained 
starting point newton direction computed switch variables free bound sets constrained stationary point problem obtained 
check done see constrained point locally optimal 
event new variable currently bounds switched free set process repeated 
algorithm guaranteed converge solution convex quadratic problems 
implementation algorithm probably efficient large number indefinite quadratic problems involving big problem sizes algorithm performs 
problems active set strategies solving algorithms allow addition dropping constraint search direction computation 
large problems prohibitively slow 
overcome projection steps allow constraints dropped overhead 
projected methods usually drop constraints having solved reduced problem optimality doing significant amount restricted subspace original problem 
best method solving seek balance extremes 
method uses projected gradient directions active constraint set changes conjugate gradient directions dembo 
contains additional ellipsoid constraint variables solved polynomial time ye 
han 
develop interior point algorithm solving 
algorithm starts point strictly interior feasible domain 
construct ellipsoid center inscribed feasible domain solve quadratic problem constraint 
solution problem yields new point procedure repeated yielding sequence points 
sufficient number steps stationary point obtained 
procedure guarantee convergence global solution perform randomly generated test problems known global solutions finding global solution instances 
possible solve conversion unconstrained minimization problem 
consider problem equivalent min dx gamma gammax augmented lagrange function problem multipliers quadratic optimization sets constraints replaced approximation functions written follows ffl theta gamma gammax ffl gamma gammax bound constraints added penalty terms ffl penalty parameter barrier weighting functions constraints 
theorem establishes direct relationship minimum penalty function solution theorem ffl min ffl exists computable bound ffl penalty parameter ffl ffl point satisfying rp ffl corresponding triple karush kuhn tucker point 
ii ffl ffl global minimum point global minimum point ffl vice versa 
proof 
see propositions 
computational point view equivalent formulation permits standard unconstrained minimization algorithms differentiable functions solve 
particular newton type algorithms defined consistent approximations newton direction penalty function 
algorithm converges finite number iterations solution constrained problem 
suitable assumptions shown exists neighborhood solution algorithm converges single step 

decomposition techniques years decomposition approaches proposed solving 
approaches usually general global optimization problems nature quadratic problem quite attractive method solution 
particular decomposition approaches circumvent main difficulties associated solution problem size 
decomposition enables solution problem smaller possible tractable subproblems original problem size prohibits direct solution 
decomposition approaches called benders cuts proposed benders solution mixed integer problems 
approach subsequently generalized continuous biconvex floudas visweswaran case 
better understand approach consider special indefinite quadratic problem tackled min gamma ax natural decomposition problem derived separability objective function 
variables fixed problem variously called subsidiary problem primal problem obtained min gamma ax gamma problem provides upper bound global solution gives multipliers constraints 
solution problem projection space defined gamma obvious solution equivalent min fy ax xg solution problem nontrivial normally implicitly defined function 
solution provide benders cut approximate gamma ax gamma primal problem infeasible alternate problem artificial objective solved corresponding multipliers generate feasibility cut ax gamma types cuts leads master dual problem provides lower bound global solution min typical generalized benders approach involves iterating master primal problems convergence reached 
quadratic optimization solution master problem major hurdle approach problem considered minimization piecewise concave quadratic function linear set 
separable case proposed solving set linear subproblems involving minimization benders cuts 
resulting algorithm provides successively tighter lower bounds finite convergence ffl approximate solution 
number subproblems solved increases iterations progress progress algorithm slow iterations 
proposed method developing exact benders cuts problem representing solution primal problem terms variables 
floudas 
showed generalized benders decomposition applicable wider class problems including general quadratic problem polynomial function problems mixed integer nonlinear programming problems providing methods converting problems form generalized benders decomposition applicable 
provided global search scheme guaranteed converge global solution proved computationally effective large number problems 
approach aggarwal floudas solving quadratic mixed quadratic problems 
related approach solving quadratic problems gop algorithm proposed floudas visweswaran guarantees convergence ffl global solution large class problems includes quadratic problem special case 
algorithm handle quadratically constrained problems discussed detail section 

large scale indefinite problems concave quadratic case happens nonconvexity objective function due small number variables 
happen small number eigenvalues negative ii number variables appearing quadratic terms objective function small fraction total number variables 
problems feasible solve larger problems normally case 
consider case matrix relatively negative eigenvalues 
loss generality may assume eigenvalues gamma gamma concerned case relatively small compared case useful reduce objective function separable form pardalos 
concave case section multiple cost row linear program form min omega sigmau solved omega feasible region orthogonal eigenvectors solutions linear programs reformulated floudas visweswaran min ax gamma objective function concave part convex part 
main feature interesting real complexity algorithm solving problem depend total number variables algorithm tries take advantage feature proposed pardalos 

basic idea obtain approximations concave part solve problem efficiently 
function linear function fl gamma gamma fi delta fi upper bound provides underestimating function meets points lower upper bounds 
function fl convex underestimating function 
possible show maximum error approximation bounded theorem jq gamma fi proof 
see pardalos 

theorem indicates error linear approximation depends curvature concave functions eigenvalues geometry feasible region bounds variables 
solution approximation convex quadratic problem provides lower bound optimal solution 
solution satisfactory procedure terminated 
branch bound bisection technique continuously bisect rectangle defined bounds concave variables subregions better approximations obtained concave function procedure repeated get tighter lower bounds global solution 
possible obtain piecewise linear concave functions involves integer variables 
requires solution mixed linear program 
approach large problems quadratic optimization reported pardalos 
especially approximate solutions sufficient 
instance feasible solve large scale quadratic problems dominance linear terms objective function 
consider indefinite instance quadratic problem large number variables appearing linearly objective function 
phillips rosen proposed extension previous concave quadratic problems phillips rosen handle indefinite quadratic problems form 
approach algorithm reduces problem form separable objective function 
convex quadratic objective function developed solve auxiliary problem provides upper lower bounds global solution 
bounds tight feasible domain partitioned directions concave variables tighter bounds obtained subregions 
procedure continues till ffl approximate solution original problem 
computational results algorithm problems having upto concave linear variables indicate approach works number linear variables dominates solution 

polynomial time algorithms section mentioned polynomial time algorithms developed certain classes quadratic problems 
naturally raises question algorithms developed general indefinite quadratic problem 
obvious polynomial algorithm computing exact solution expected imply np general qp np 
open question approximation algorithm developed solves polynomial time 
results direction due vavasis stated theorem theorem suppose matrix indefinite feasible region compact 
number negative eigenvalues exists algorithm find ffl approximate solution ffl steps 
formula denotes time solve convex quadratic programming problem size 
proof 
see vavasis 
result indicates number negative eigenvalues fixed polynomial time algorithm developed general quadratic problem 
algorithm proposed vavasis 
approach involves computing john pair constraint region pair definition approximate solution due vavasis follows 
optimum feasible point ffl approximate solution exists feasible point satisfying gamma ffl gamma definition advantage insensitive translations dilations objective function 
floudas visweswaran concentric ellipsoids ae omega ae omega feasible region obtained shrinking dimension pair exists computed convex feasible region polynomial time 
assume ellipsoids defined fx gamma gamma fx gamma gamma ng positive semi definite symmetric matrix vector 
variables translated john pair centered origin affect quadratic term objective function matrix mx dx diagonal 
replacing gamma leads new problem form min dx ax diagonal constraint region omega satisfies ae omega ae fx fx matrix negative eigenvalues say split vectors corresponding entries remaining gamma entries respectively 
enables problem rewritten form concave convex part 
problem projected space concave variables resulting region partitioned repeatedly subcubes number partitions order ffl 
linear concave terms convex quadratic subproblems solved subregion 
resulting solutions provide lower bound optimal solution error analysis difference linear approximation concave terms possible show convergence ffl obtained 
algorithm takes exactly number steps theorem 
quadratic problems quadratic constraints general class quadratic problems arises inclusion quadratic constraints 
problems formulated follows min dx quadratic optimization theta matrix corresponding mth quadratic constraint th row theta matrix note constraints linear due absence corresponding matrices problem received far attention 
reasons finding feasible solution formidable task 
convex case am positive semidefinite algorithms solving 
quadratically constrained problems constitute important part mathematical programming problems arising various practical applications including facility location production planning vlsi chip design optimal design water distribution networks problems chemical engineering design 
encompasses categories quadratic problems special instances 
worth considering algorithms available solving detail 
early years introduced seminal kuhn tucker case considered single quadratic constraint problem swarup panne 
general approach solving proposed baron considered lagrange functions dx gamma gamma gamma multipliers quadratic bound constraints respectively 
baron proposed solving minimizing lagrange functions cutting plane algorithm 
algorithm solves sequence linear master problems minimize piecewise linear function constructed lagrange functions constant primal problem unconstrained quadratic function quadratic function nonnegative orthant 
cuts generated problems approximate dual forms convergence primal dual problems equal objective values guaranteed objective function convex set active constraints iteration positive semidefinite quadratic matrices 
falk proposed branch bound algorithm solving general problems objective function separable constraint set linear 
method involves solving bounding convex envelope approximating problems successive partitions feasible region 
algorithm extended handle nonconvex constraints 
algorithm applied solve generates number infeasible points solution procedure general converge finite number iterations 
branch bound method proposed reeves solve objective function constraints separable variables 
algorithm uses similar branching scheme 
iteration partition feasible region local minimum objective floudas visweswaran partition small interval surrounding minimum eliminated 
remaining region partitioned process repeated new partitions 
algorithm differs bounding convex polytope problems solved eliminate regions generate base points partition 
deriving local minima iteration algorithm obtains verifies finite number iterations exactly arbitrarily small precision global minimum problem 
proposed algorithm solution linear problems additional reverse convex constraint form min 
ax concave function noted appropriate transformations problem form converted form 
algorithm works partitioning feasible region subsets contained cones originating infeasible vertex polytope formed linear constraints ensuring interior point feasible region contained partition 
intersection rays forming cone reverse convex constraint determine particular cone smaller 
iteration cones generated number variables successively tightened convex hull obtained contains solution reverse convex problem 

proposed algorithms solution problems concave objective functions separable quadratic constraints 
problems form min 
ik ik ik algorithm branch bound algorithm works division initial rectangular domain increasingly smaller rectangles size going zero limit way achieve bisections 
rectangular subdivision lower upper bounds obtained objective function 
partitions deleted lower bound objective region greater best obtained solution far region infeasible quadratic constraints 
condition checked bounds partition 
addition speed convergence various linearizations quadratic optimization quadratic constraints added problem formulation 
authors propose second approach uses piecewise linear approximation quadratic constraints 
resulting problem solved mixed linear problem 
approach similar ones pardalos rosen concave quadratic problems pardalos 
indefinite quadratic problems 

decomposition techniques mentioned section decomposition techniques features attractive solving quadratic problems 
foremost usually subproblems solved far smaller size original problem 
decomposition approaches solving quadratic problem lagrangian dual formulation 
main problems quadratic problem nonconvex programs exist duality gap nonconvex problem lagrangian dual 
consequently algorithms iterate primal dual formulations original problem example algorithm baron fail converge special conditions problem structure 
proposed method generalized benders decomposition solve mixed integer quadratic problems 
approach converts problem form integer variables absent objective function resulting master dual problem linear integer variables 
original problem solved series relaxed integer linear master problems continuous convex quadratic primal problems 
wolsey proposed resource decomposition algorithm solving constrained problems 
decompositions algorithms proposed guarantee convergence global solution problems form 
approaches due floudas visweswaran considers solution reducing equivalent problem min dy gamma turn falls framework biconvex problem min convex linear fixed vice versa 
fixed value problem called primal problem linear floudas visweswaran provides upper bound global solution 
solution primal problem provides multipliers constraints formulate lagrange function shown relaxed dual formulation written min min scalar 
problem provides lower bound global solution 
presence inner minimization problems problem tough solve 
primal problem solved space variables relaxed dual problem essentially solved space basis iterative algorithm alternates providing bounds solutions floudas visweswaran proposed method solving relaxed dual problem involves linearizing lagrange function respect variables solution primal problem corresponding 
linearization ensures lagrange functions independently achieves minimum bound variables 
enables solution relaxed dual problem set linear problems variables replaced combination bounds problems 
basic algorithm gop summarized follows step initialize storage parameters select starting point step set 
solve primal problem generate lagrange function optimal multipliers problem 
update best upper bound original problem 
primal infeasible solve relaxed primal problem solution generate feasibility cut relaxed dual problem 
step generate set constraints previous iterations provide valid current region add relaxed dual problem 
step solve relaxed dual problem set linear subproblems storing feasible solutions 
select best stored solution lower bound corresponding solution step check convergence bounds 
set return step 
points worth mentioning algorithm 
iteration set subproblems solved step restricted subregion variables 
quadratic optimization region defined cone formed set constraints previous iterations 
constraints generated setting variables lagrange function iteration particular set bounds 
actual set bounds determined sign gradients lagrange function current selected way valid current cone 
iteration step equivalent partitioning set subregions 
algorithm functions branch bound cutting plane method 
lower bound step guaranteed nondecreasing iterations proceed 
property coupled presence constraints previous iterations prevent cycling give theoretical guarantee convergence algorithm ffl global solution finite number iterations 
visweswaran floudas discussed application gop algorithm classes problems including quadratically constrained quadratic problems provided preliminary computational experience examples class 
visweswaran floudas proved properties quadratic polynomial problems significantly improve computational performance algorithm 
floudas 
proposed solving relaxed dual subproblems iteration single mixed linear problem 
shown liu floudas gop algorithm applicable large class smooth optimization problems 
convergence algorithm problems shown liu floudas 
problem written form ben tal ben tal min 

fx mg functions fixed convex convex set 
note bilinear problem quadratic problems reduction bilinear form satisfies condition 
natural approach solving problem decomposition min ae oe min oe function oe may smooth inner problem convex availability algorithms non smooth optimization overcome drawback 
nonconvexity outer problem poses main challenge 
dual form written max min floudas visweswaran weak duality solution provides lower bound 
particular duality gap solutions identical 
presence duality gap means may provide tight lower bound 
overcome ben tal 
proposed branch bound approach reducing duality gap successive domain partitioning 
consider partition set subsets th partition corresponding primal dual problems respectively min 

max ae min oe theorem proved theorem optimal value optimal value optimal value min theorem shows set partitioned gap primal dual problems decreases 
problems form satisfy appropriate constraint qualification shown gap varies directly size partitions measured say radius smallest hypersphere containing size partitions zero duality gap strict equality holds left hand side theorem 
general dual problem solved partition involves linear objective function minimized convex set constraints 
functions bilinear problems example dual problems solved linear program 
ben tal 
applied approach solve instances pooling problem see section formulation problem 
particular quadratically constrained problem received considerable attention problem involves minimizing quadratic constraint sphere min dx problem comes subproblem general optimization algorithms 
objective function nonlinear programming approximated locally quadratic function 
cases approximation restricted small region current iterate 
norm define region 
methods referred model trust region methods 
presence sphere constraint solution irrational implies possible exactly compute solution 
exist polynomial time algorithms efficiently compute quadratic optimization approximate solution problem desired precision 
sorensen proposed general algorithm model trust regions ye ye karmarkar proposed strongly polynomial algorithms solving 

quadratic optimization linear complementarity problem closely associated quadratic problems class linear complementarity problems lcp 
real matrix thetan pair vectors gammam called complementary pair vectors denote vector pair cone defined fy ff ff na ff called complementary cone vector lcp involves finding complementary cone contains point finding complementary set vectors expressed nonnegative linear combination vectors 
equivalent solving problem find feasible solution vector set constraints mx prove feasible solution exist 
note lcp optimization problem strict sense objective function minimize 
problems close relationship important classes optimization problems including linear programming convex quadratic programming bimatrix games mixed integer programming 
quadratic problem example equivalent min mx mx lcp closely related optimality conditions solution 
consider kkt conditions quadratic problem 
easily shown kkt conditions reduce lcp gammaa note vector nonnegative problem immediately solved setting cases interest component negative 
floudas visweswaran original vectors augmented respectively 
lcp considered problem finding kkt point quadratic problem 
proved theorem murty solution lcp data kkt point 
case positive semidefinite convex quadratic programming lcp provide necessary sufficient optimality conditions 
general case indefinite nonconvex quadratic problems kkt conditions sufficient ensure optimality lcp directly obtain solution 
problems lcp indirect relevance 
consider example problem psi gamma gamma known point satisfies kkt conditions value coincides value objective function psi problem 
leads theorem theorem qp optimal solution 
point solves exist vectors solves 
noted theorem holds bounded 
case theorem indicates possible solve minimizing linear function solution set linear complementarity problem 
mitra equivalences quadratic problems related linear complementarity problems 
clear nature linear complementarity problem methods solution help provide considerable insight solution qp 
detailed treatment lcp scope chapter reader referred mitra lemke murty 


applications section describe interesting problems engineering design control formulated quadratic programming problems 
applications test problems quadratic programming general nonconvex optimization problems floudas pardalos 

economies scale problems involving economies scale production sales formulated concave quadratic programming problems 
consider case products produced number units product cost production unit product usually number units produced increases unit cost decreases 
correlated linear quadratic optimization pool max max 
fig 

pooling problem functional negative quantity 
constraints production demands availabilities product problem minimizing total production cost written min represents demand availability constraints 
concave minimization problem 
similarly profits maximized economies scale dictate profits unit rise linearly number units produced 
case problem maximization convex functional 

pooling blending problems pooling blending problems feature models chemical processes 
particular problems relating refinery processing necessary model product flows properties intermediate streams 
streams usually combined tank pool pool downstream processing blending 
presence streams model introduces nonlinearities nonconvex manner 
arise interactions qualities input streams blended products 
typical pooling problem shown 
consists feed streams combined pool form products absence pooling restriction problem formulated solved lp 
streams need pooled example tank store formulation quadratic shown floudas visweswaran min gamma gamma gamma gamma pool balance gamma gamma gamma gamma oe component balance gamma gamma pool quality gamma gamma oe product quality constraints oe upper bounds products quality pool lower upper bounds respectively 
traditionally problems solved successive linear programming techniques 
methods suffer drawback highly dependent starting point 
problem studied floudas aggarwal applied global optimum search method solve problem visweswaran floudas successfully applied gop algorithm solve problem 
similar pooling problems studied ben tal ben tal 

multiperiod quality problems lead similar formulations studied visweswaran floudas 

multicomponent separation problems pooling blending problems quadratic models arise separation multicomponent process streams chemical 
problems typically involve multicomponent feed streams need separated products may specified composition various components 
method solving problems superstructure approach 
involves constructing superstructure containing possible options splitting bypassing blending achieve desired products 
resulting model optimized give actual configuration perform separation 
typical example problem floudas aggarwal shown concerns separation component feed stream products 
resulting bilinear formulation optimization model shown min subject mass balances quadratic optimization ii bc ab fig 

multicomponent separation example floudas aggarwal gamma gamma gamma gamma gamma gamma gamma gamma gamma gamma splitter component balances gamma gamma gamma gamma inlet mixer balances gamma gamma xb xb xb xb compositions xb sharp split xb xb variables nonnegative 

quadratic knapsack problem quadratic knapsack problem min qx floudas visweswaran fl problem occurs frequently resource allocation multicommodity network flow problems problems logistics 
resource allocation example fl represents total amount resource consumption resource th activity 
presence knapsack constraint formulation problem easier solve 
various approaches proposed problem pardalos ye vavasis 
approaches interior point algorithm ye guaranteed converge global minimum polynomial time 

ic circuit layout compaction challenging error prone parts ic design low level cell layout 
logical design possible ways map layout geometrically 
desirable consider problem context compaction problem finding minimum area function subject linear nonlinear constraints 
dimensional layout variables formulation represent position particular symbol logical diagram 
consider example components circuit coordinates may 
geometric restrictions layout occur due separation rules require components certain distance apart 
constraints take form gamma gamma minimum distance requirements 
form constraints imposed due connectivity requirements take form linear inequalities 
constraints constitute feasible region set points 
area occupied cell composed components gamma sx ty gamma sy compaction problem quadratic minimization min omega omega feasible region defined set linear inequalities 
discussion problem see kedem watanabe 
similar model arises layout problem requires combination space communication costs minimized 
corresponds rectangular dualization problem 
example model quadratic constraints shown min quadratic optimization gamma gammax gamma gammax gamma gammay gammay gamma gamma gamma gamma details reader referred 


optimal design structural design typically involves minimization total weight structure 
problems large field practical applications result bilinear models 
typical problem shown sim oes min gamma gamma 
robust stability analysis feedback control systems feedback controllers widely stabilize plant operations various processes 
mismatches plant model physical system important controller designed robustness satisfy stability performance requirements range values parameters plant model 
typical example problem de gaston floudas visweswaran controller set point plant model disturbances fig 

involving analysis robust stability feedback control structures real parametric uncertainty shown 
variables measured variables plant output manipulated variables errors measured values desired set points measured variables 
refers variables laplace domain 
variables parameters plant model nominal values values vary due uncertainty 
requirement controller robust leads quadratically constrained optimization problem see floudas min gamma gamma gamma gamma gamma gamma gamma gamma gamma stability margin control problem 
detailed discussions importance real parameter uncertainty tool robustness analysis control systems ackermann 
see floudas details solution quadratic problems 
quadratic optimization problem problem size cpu times nx ny table random runs bilinear problems algorithms falk sherali 
summary computational results real test algorithm comes performs efficient implementation 
algorithms discussed preceding sections little computational results reported 
section summarize best known algorithms various classes quadratic problems terms computational effort required 
results reported consider randomly generated test problems 
solution times algorithms vary lot depending type problems generated 
results indicative general performance algorithm taken criteria evaluating algorithm vis vis algorithm 

bilinear programs quadratically constrained problems problems form computational results algorithms available 
performance algorithms due falk sherali shown table table ii performance gop algorithm described floudas 

instances pooling problem bilinear constraints studied visweswaran floudas ben tal 
results problems table iii 

concave quadratic problems concave quadratic problems branch bound algorithm phillips rosen gop algorithm visweswaran floudas floudas visweswaran problem size iterations cpu nx ny iter 
cpu 
table ii randomly generated bilinear problems solved gop algorithm floudas problem 
problem size gop ben tal nx ny iterations 
dual problems 



table iii pooling problems ben tal applied similar categories problems 
classes problems considered set small example problems large number randomly generated test problems 
cases problems considered form min omega gamma omega quadratic optimization thetan thetak number linear constraints number concave variables number linear variables 
parameters respectively relative tolerance convergence upper lower bounds ffl 
problem problem size gop algorithm cpu hp cpu cray example prob prob prob prob prob prob prob prob prob prob number constraints number concave variables number linear variables table iv concave quadratic problems phillips rosen algorithms phillips rosen visweswaran floudas table iv contains results example problems phillips rosen 
solution times randomly generated test problems reported table table times algorithm phillips rosen sequential parallel processors columns 
note cpu times reported phillips rosen algorithm cray times gop algorithm hp 

indefinite quadratic problems case indefinite quadratic problem box constraints computational results algorithms global optimization algorithm hansen floudas visweswaran run problem size cpu time gop table random runs concave quadratic problems algorithms phillips rosen visweswaran floudas density cpu problem size indicates problems solved 
table vi results runs algorithm hansen 
quadratic problems box constraints 
local optimization algorithm coleman 
results tables vi vii 
results indicate density type eigenvalues play crucial roles performance 
number negative eigenvalues increases problem behaves concave quadratic problem solution lie vertex 
consequently solution times problems 
seen due sparsity problems considered table vii consider dense problems possible solve larger problems reasonable time 
density matrix increases impossible solve smallest size problems 
quadratic optimization 
variables cpu negative eigenvalues table vii results runs algorithm coleman large sparse quadratic problems box constraints run problem size gop algorithm iter cpu number constraints number concave variables number linear variables table viii random runs indefinite quadratic problems gop algorithm visweswaran floudas table viii gives results runs gop algorithm visweswaran floudas large indefinite quadratic problems 
number linear variables increases size linear relaxed dual problems solved iteration increases 
chapter reviewed proposed global optimization approaches quadratic programming quadratically constrained problems 
starting definition general quadratic programming problem classification discussed local global optimality conditions complexity issues 
subsequently discussed theoretical algorithmic developments bilinear concave indefinite quadratic programming 
important class problems application point view quadratically constrained problems decomposition global optimization approaches problems discussed floudas visweswaran 
brief discussion relation quadratic programming linear complementarity problems examples important application areas quadratic programming quadratically constrained problems 
discussed computational results number global optimization approaches 
review clear significant progress especially decade theoretical algorithmic development global optimization approaches quadratic programming quadratically constrained problems 
time available computational studies proposed global optimization algorithms randomly generated test problems actual applications engineering design control described section indicate current limitations need 
difficulty reviewed classes global optimization problems attributed main features 
characteristic degree nonconvexity associated number balance mixed sign eigenvalues hessian general quadratic programming problem instance 
second characteristic related sparsity objective function constraints relative contribution nonconvex terms versus linear convex terms 
existing computational experience exist number efficient global optimization algorithms address medium large size sparse concave quadratic programming problems 
classes bilinear indefinite quadratic programming appear challenging existing global optimization approaches effective small medium size problems desirable sparsity characteristics 
important class quadratically constrained problems existing global optimization algorithms applied challenging encouraging computational results reported application problems mathematical structure exploited effectively 
classes bilinear indefinite quadratic programming quadratically constrained problems linear quadratic objective function deserve serious attention respect new theoretical algorithmic computational studies succeed addressing medium large size global optimization problems effectively 
furthermore expected global optimization approaches take advantage special mathematical structure exhibited number important application areas may efficient capable addressing problems expense general 
financial support national science foundation cbt cts gratefully acknowledged 
ackermann 
robust control systems uncertain physical parameters 
springer verlag berlin 
aggarwal floudas 
decomposition approach global optimum search qp nlp problems 
annals oper 
res 
quadratic optimization 
jointly constrained bilinear programs related problems overview 
computers mathematical applications 
falk 
jointly constrained biconvex programming 
math 
oper 
res 
horst pardalos 
global optimization quadratic functions subject quadratic constraints 
annals operations research 
bali 
minimization concave function bounded convex polyhedron 
phd thesis university california los angeles 

new tools robustness analysis 

baron 
quadratic programming quadratic constraints 
naval research logistics quarterly 
shetty 
nonlinear programming theory algorithms 
john wiley sons new york 
mohamed ben shetty 
polynomial barrier function algorithms convex quadratic programming 
sci 
eng 
ben tal 
global minimization reducing duality gap 
mathematical programming accepted 
ben tal 
computational methods solution pooling blending problem 
technical report technion israel institute technology haifa israel 
benders 
partitioning procedures solving mixed variables programming problems 
numer 
math 

algorithm class nonlinear nonconvex optimization problems 
phd thesis university california los angeles 

complementarity problem theory methods solution 
automation remote control 

methods concave minimization convex polyhedron applications russian 
methods optimization applications 
nauka 
pages 
francis 
solving nonconvex quadratic minimization problems ranking extreme points 
oper 
res 

relaxation minimization function convex polyhedron 
mathematical programming 
chung murty 
polynomially bounded ellipsoid algorithm convex quadratic programming pages 
nonlinear programming 
academic press new york 
coleman 
direct active set algorithm large sparse quadratic programs simple bounds 
mathematical programming 
jong shi pang richard stone 
linear complementarity problem 
academic press london 

bilinear programming 

mat 

method bilinear programming nonconvex quadratic problems 
mat 
gabriele bomze 
global optimality criteria concave quadratic programming problems 
mathematical programming 
de gaston 
exact calculation stability margin 
ieee transactions automatic control 
dembo 
minimization quadratic functions subject box constraints 
siam sci 
stat 
comp 
dyer 
complexity vertex enumeration methods 
math 
oper 
res 
falk 
algorithm locating solutions nonconvex separable problems 
technical report program logistics george washington university washington 
falk 
linear max min problem 
math 
progr 
falk hoffman 
successive underestimating method concave minimization problems 
math 
oper 
res 
falk 
algorithm separable nonconvex programming problems 
manag 
sci 
floudas jaumard visweswaran 
decomposition techniques global optimization 
preparation 
floudas visweswaran floudas pardalos 
collection test problems constrained global optimization algorithms volume lecture notes computer science 
springer verlag berlin germany 
floudas pardalos 
advances global optimization 
princeton series computer science 
princeton university press princeton new jersey 
floudas visweswaran 
primal relaxed dual global optimization approach 
journal optimization theory applications 
floudas aggarwal 
decomposition strategy global optimum search pooling problem 
orsa journal computing 
floudas aggarwal 
global optimum search problems 
computers chemical engineering 
floudas visweswaran 
global optimization algorithm gop certain classes nonconvex theory 
comp 
chem 
eng 
frieze 
bilinear programming formulation dimensional assignment problem 
mathematical programming 
gallo 
bilinear programming exact algorithm 
math 
prog 

generalized benders decomposition 
journal optimization theory applications 

nonconvex quadratic programming linear complementarity problems integer programming pages 
north holland amsterdam holland 

connections nonlinear integer programming problems pages 
academic press new york ny 
glover 
convexity cuts cut search 
oper 
res 
goldfarb liu 
primal interior point algorithm convex quadratic programming 
mathematical programming 

strongly polynomial algorithm strictly convex quadratic programs extension tardos algorithm 
math programming 

differentiable exact penalty function bound constrained quadratic programming problems 
optimization 
hager pardalos 
active constraints indefinite quadratic test problems complexity 
journal optimization theory applications 
han pardalos ye 
computational aspects interior point algorithm quadratic programming problems box constraints 
large scale numerical optimization 
siam 
han pardalos ye 
solution indefinite quadratic problems interior point algorithm 
informatica 
hansen jaumard 
reduction indefinite quadratic programs bilinear programs 
journal global optimization 
hansen jaumard lu 
analytical approach global optimization 
mathematical programming 
hansen jaumard ruiz xiong 
global minimization indefinite quadratic functions subject box constraints 
technical report ecole polytechnique universit mcgill montreal ca 

studies behaviour recursion pooling problem 
acm bulletin 

behaviour recursion model studies 
bulletin 
goodman 
survey methodology global minimization concave functions subject convex constraints 
omega intl 

mgmt 
sct 
horst tuy 
global optimization deterministic approaches 
springer verlag berlin 
jacobsen 
convergence tuy type algorithm concave minimization subject linear inequality constraints 
appl 
math 
optim 
mitra 
reformulation mathematical programming problems linear complementarity problems investigation solution methods 
journal optimization theory applications 

large scale global minimization linearly constrained concave quadratic func quadratic optimization tions related problems 
phd thesis computer science department university minnesota minneapolis mn 
rosen 
algorithm global minimization linearly constrained concave quadratic functions 
math 
oper 
res 
karmarkar 
interior point approach np complete problems 
contemporary mathematics 
kedem watanabe 
optimization techniques ic layout compaction 
proc 
ieee intern 
conf 
computer design vlsi computers pages 
khachiyan 
polynomial algorithm linear programming 
soviet math 
doklady 

zum problem der programmierung remarks nonconvex programming problem 

konno 
cutting plane algorithm solving bilinear programs 
mathematical programming 
konno 
maximization convex quadratic function subject linear constraints 
math 
progr 
konno 
maximizing convex quadratic function hypercube 
oper 
res 
soc 
japan 
konno 
algorithm solving bilinear knapsack problems 
oper 
res 
soc 
japan 
konno kuno 
generalized linear multiplicative fractional programming 
manuscript 
konno kuno 
linear multiplicative programming 
technical report report institute human social sciences tokyo institute technology 
konno 
solving rank bilinear programs algorithms 
technical report report institute human social sciences tokyo institute technology 
konno matsui 
parametric simplex algorithm solving special cases nonconvex minimization problems 
technical report report institute human social sciences tokyo institute technology 

indefinite quadratic programming problem 
oper 
res 

polynomial solvability convex quadratic programming 
soviet math 
doklady 

minimization concave function linear constraints modification tuy method 
survey mathematical programming proc 
th intl 
math 
prog 
symp 
budapest 
north holland amsterdam 
kuhn tucker 
nonlinear programming 
neyman editor proc 
second berkeley symposium math 
stat 
prob pages 
california press berkeley california 
sarkar gomez 
solving pooling problem successive linear 
acm bulletin 

mixed integer quadratic programming 
math 
prog 

improved algorithm mixed integer quadratic programs computational study 
math 
prog 
lemke 
survey complementarity theory pages 
wiley 
liu floudas 
gop algorithm global optimization 
journal global optimization 
liu floudas 
convergence gop algorithm large class smooth optimization problems 
submitted publication 
mueller heller 
finding optimal rectangular package plans 
proceeding th design automation conference pages 
rubin 
survey comparison methods finding vertices convex polyhedral sets 
mathematics operations research 
mckeown 
extreme point ranking algorithms computational survey 
computers mathematical programming government printing office washington 
mitra 
exposition linear complementarity problem 
intl 

math 
edu 
sci 
tech 
floudas visweswaran mockus 
bayesian approach global optimization 
kluwer academic publishers amsterdam holland 
renato monteiro ilan adler 
interior path primal dual algorithms 
ii convex quadratic programming 
mathematical programming 
renato monteiro ilan adler resende 
polynomial time primal dual affine scaling algorithm linear convex quadratic programming power series extension 
math 
oper 
res 
murtagh saunders 
minos users guide 
systems optimization laboratory dept operations research stanford university ca 
appendix minos technical report sol 
murty 
linear complementarity linear nonlinear programming 
verlag berlin 
murty 
solving fixed charge problem ranking extreme points 
operations research 
murty 
np complete problems quadratic nonlinear programming 
math 
progr 
nash 
noncooperative games 
ann 
math 
yu 
nesterov 
polynomial methods linear quadratic programming 
sov 
comput 
syst 
sci 
pardalos 
algorithm singly constrained class quadratic programs subject upper lower bounds 
mathematical programming 
pardalos vavasis 
quadratic programming negative eigenvalue nphard 
submitted publication 
pardalos 
global optimization algorithms linearly constrained indefinite quadratic problems 
comput 
math 
appl 
pardalos rosen 
global minimization indefinite quadratic problems 
computing 
pardalos rosen 
methods global concave minimization bibliographic survey 
siam review 
pardalos rosen 
constrained global optimization algorithms applications volume lecture notes computer science 
springer verlag berlin germany 
pardalos schnitger 
checking local optimality constrained quadratic programming np hard 
operations research letters 
phillips rosen 
parallel algorithm constrained concave quadratic global minimization 
math 
progr 
phillips rosen 
guaranteed ffl approximate solution indefinite quadratic global minimization 
naval research logistics 
floudas 
robust stability analysis linear nonlinear systems real parameter uncertainty 
submitted publication 

connections zero integer programming concave programming linear constraints 
operations research 
reeves 
global minimization non convex quadratic programming 
manag 
sci 
rinnooy kan 
stochastic methods global optimization 
computational mathematical programming 
springer verlag berlin 
rinnooy kan 
stochastic global optimization methods 
part clustering methods 
mathematical programming 
ritter 
method solving function 
geb 
rosen 
global minimization linearly constrained concave function partition feasible domain 
math 
oper 
res 
rosen 
performance approximate algorithms global minimization 
math 
progr 
study 
rosen pardalos 
global minimization large scale constrained concave quadratic problems separable programming 
math 
prog 
rosenberg 
zero nonlinear programming 
revue informatique de recherche op 
sahni 
computationally related problems 
siam comp 
quadratic optimization sherali 
reformulation linearization technique bilinear 
journal global optimization 
sherali shetty 
finitely convergent algorithm bilinear programming problems polar disjunctive face cuts 
math 
progr 
shor 
dual quadratic estimates polynomial boolean programming 
annals operations research 
sim oes 
search global optimum volume 
engineering optimization 

algorithm separable nonconvex programming problems ii nonconvex constraints 
mgmt 
sci 
sorensen 
newton method model trust region modification 
siam numer 
anal 
swarup 
indefinite quadratic programming quadratic constraint 


tuy 
convergent algorithms minimizing concave function 
math 
oper 
res 
torn 
global optimization volume lecture notes computer science 
springer verlag berlin germany 
tuy 
concave programming linear constraints 
dokl 
akad 
nauk 
sssr 
translated soviet math 
dokl pp 
tuy 
global minimization difference convex functions 
math 
prog 
study 
tuy 
normal conical algorithm concave minimization polytopes 
math 
prog 
shetty 
bilinear programming problem 
naval res 

quart 
shetty 
cutting plane algorithm bilinear programming problem 
naval res 

quart 
van de panne 
programming quadratic constraint 
management science 
vavasis 
quadratic programming np 
info 
proc 
lett 
vavasis 
nonlinear optimization complexity issues 
oxford university press new york 
vavasis 
local minima indefinite quadratic knapsack problems 
math 
program 
visweswaran floudas 
new properties computational improvement gop algorithm problems quadratic objective function constraints 
journal global 
visweswaran floudas 
global optimization algorithm gop certain classes nonconvex ii 
application theory test problems 
comp 
chem 
eng 
jack 
necessary sufficient condition constrained minimum 
siam optimization 
watanabe 
ic layout generation compaction mathematical programming 
phd thesis computer sc 
dept univ rochester 
wolsey 
resource decomposition algorithm general mathematical programs 
mathematical programming study 
ye 
interior point algorithms global optimization 
ann 
oper 
res 
ye 
affine scaling algorithms nonconvex quadratic programming 
mathematical programming 
ye 
extension karmarkar algorithm trust region method quadratic programming 
proceedings conference progress mathematical programming 
interior point related methods pacific grove california pages 

global minimization large scale linear constrained systems 
phd thesis computer sc 
dept univ minnesota 

nonlinear programming counterexamples global optimization algorithms 
oper 
res 

global maximization convex function linear inequality constraints 
oper 
res 
