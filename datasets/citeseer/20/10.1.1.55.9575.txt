parallelizing intensive applications workstation cluster case study lin zhou computer systems research institute university toronto toronto ontario canada intensive application parallel full text retrieval signature file method studied 
text retrieval system implemented cluster dec workstations connected ethernet 
experiments performed evaluate benefit cost running application workstation cluster 
results show substantial improvement speed obtained parallelism disk accesses despite high communication synchronization overhead incurred 
factors affect performance parallel application type computing environment discussed 
advantages workstation cluster large combined buffer capacity possible concurrent accesses disks local workstation 
study demonstrates advantages exploited properly lead effective performance improvement need additional hardware 
parallel processing network workstations attractive approach high performance computing 
approach existing resources utilized achieve better performance extra cost adding new hardware 
compared multiprocessor distributed memory multicomputer system bbn butterfly ncube sequent symmetry intel hypercube workstations available larger population users capable working independently cooperating execute parallel application 
workstations stable friendly programming environment 
compute intensive sequential applications run workstations parallelizing holds promise performance improvement trauma moving different friendly environment 
typical architecture workstation cluster number uni multi processor hosts interconnected serial communication network ethernet fddi 
host may local disk paging swapping file storage 
architecture quite different tightly coupled parallel systems 
example communication bandwidth available workstation cluster typically lower suggesting effective parallel computing may achievable applications relatively low communication computation ratio coarse grain parallelism 
availability local disk scalability workstation clusters possibility supporting certain types applications better workstations 
expect domain suitable parallel applications workstation clusters overlap subset multiprocessor distributed memory multicomputers 
identifying domain suitable applications important research problem 
due lack experience area believe effective approach problem concrete case studies 
number works reported exploiting cpu power group workstations achieve high performance computing numerical problems 
examine viability exploiting combined file buffer cache capacity group workstations 
intuitively group workstations offer larger buffer space individual machine local disks attached workstations accessed simultaneously 
hand parallelizable application subtasks involve intensive disk inherently relatively coarse grain rendering sensitive slow interconnection links workstation cluster 
potential applications effective utilize resources available workstation cluster exploited 
study full text retrieval application implementing network dec workstations measuring performance 
main issue investigated application benefit parallel processing group fast workstations connected relatively slow network ethernet shared users system 
study important factors affecting formance implementation 
text databases traditionally large archival nature insertions performed regularly deletions updates 
examples applications wide range areas ffl electronic office filing ffl computerized libraries ffl automated law patent offices applications require efficient full text search method 
database applications full text search bound 
example execution time devoted disk accesses running signature file text search program sequentially today workstations 
faster cpus portion time activities increase 
key issue parallelization create opportunities concurrent accesses signature file resides disks resorting redundant storage 
current frame signature files cat proposed shown able solve problem effectively 
subsequent sections describe implementation full text retrieval system cat network workstations 
performance results experiments demonstrate effectiveness running application workstation cluster 
system implemented top pvm parallel virtual machine software offers convenient means inter processor communication 
worth noting outset database applications simple query database processed seconds minutes opposed numerical programs take hours months complete 
question interesting speed process parallelism 
answer fold ffl query arbitrarily complex query may decomposable independent sub queries dictating sub queries processed serial fashion 
case way speed processing query speed processing simple sub queries ffl query may just take fraction second complete database engine stays long time serve users 
throughput database engine important performance criterion 
high throughput achieved speeding response time 
addition quest speed parallelism provides users larger combined storage space 
note size textual database easily exceed usable capacity single hard disk attached word signature free text doc 
signature word signature created setting bits word bit vector 
document signature ing word signatures 
workstation 
happens spreading data multiple disks necessary 
organized section gives background signature file method cat supporting software pvm section describes design implementation system section results experiments section concludes 
background section give background full text retrieval signature file methods 
describe pvm system support facility network communication 
signature files generally signature file method technique encodes textual documents hashing superimposed coding method 
code generated called signature 
signature identify document 
basic form query text database find documents contain certain words 
consider boolean query 
query conjunction words logic set documents contain words query returned 
query disjunction words logic documents contain query word returned 
note disjunctive query usually treated union single word queries words disjunct 
different ways create document signature 
alternatives superimposed coding method appears promising 
works follows word signature created setting bit positions bits vector design parameters hash function 
document signature ing word signatures document illustrated 
query word query translated query signature document signatures scanned eliminate non qualified ones 
document signature considered qualified bits set query signature set document signature 
documents corresponding remaining signatures oe oe frame frame frame section section example new signature format set 
examined entirety determine qualified documents 
documents satisfy query signatures qualify called false drops 
percentage false drops query determined design parameters signature file explained 
signature files time retrieve documents shortened overhead scanning signatures may covered reducing number documents read 
compared inverted file methods signature file methods usually incur substantially smaller space overhead handle insertions efficiently 
scanning entire signature file slow small database 
partitioning signature file necessary reduce amount data need processed 
describe method ffl partitions signature files effectively ffl creates opportunities concurrent disk access 
concurrent frame signature file concurrent frame signature file cat 
cat signature generated assume signature vector bits long vector divided frames bits frames signature 
frames grouped sections frames 
word signature created selecting frame section signature vector setting necessarily distinct bits frames 
design parameters 
illustrates signature bits bits sections bit 
frames section 
frequently variables meaning listed table 
shown false drop probability fd pset name meaning signature length frame size number frames number frames selected word bits set word ov space overhead fd false drop probability number documents number processors length document number distinct words document disk block size pointer size tr response time single word query response time insertion avg 
disk seek latency time trans avg 
sequential disk transfer time kb avg 
cpu time scanning kb data table variables meaning gamma gammay pset gamma gamma mx happens false drop probability cat identical frame sliced signature files signature size 
shown amount data retrieve cat query 
unified framework known superimposed coding methods including ssf ssf 
capable outperforming special cases criteria 
claim cat 
cat signature sections distributed different disks accessed parallel 
simulation studied bbn butterfly tc multiprocessor demonstrated gain speed substantial 
examine feasibility method workstation environment 
describe system detail section 
key issue appears saving time random disk access due partitioning buffering amortize overheads communication synchronization higher network workstations compared tightly coupled multiprocessor 
pvm system pvm parallel virtual machine software allows utilization heterogeneous network parallel serial computers single computational resource 
pvm provides asynchronous messagepassing primitives inter process communication coordination network workstations 
pvm convenient interface user programs appears able offer adequate performance kind computation text search system 
clarify choice pvm consideration convenience performance 
implementation system overview text retrieval system consists host group search engines query windows 
note functional components system 
mapping physical processors apparent shortly 
host program started system server 
host program initiates search engine workstation stores parts signature file local disk 
host run dedicated machine may share machine search engine 
host program search engines stay system long time servers 
query windows opened closed users 
run machine network 
query window opened establish contact host 
multiple query windows active time support multiple users 
query window parses user queries generates query signatures forwards host 
host distribute query signature portion signature search engines 
results query returned directly search engine query window issued query 
seen host program serves parallel task coordinator startup 
coordinator avoids possibility query signatures arriving different search engines sequence 
centralized coordinator potentially performance bottleneck current implementation concerned problem workstation cluster quite small workstations 
illustrates system architecture 
parallel search engines assume machines gamma disks gamma referred search engines 
storage text database text database divided fragments doc doc gamma search engine search search search engine engine engine query window query query window window host query query query signature signature signature signature messages internal internal messages internal messages internal messages system architecture 
doc doc doc doc doc doc doc doc doc doc doc doc doc doc doc doc example concurrent pipe lined execution processor processing segment row frame column marked 
fragment doc stored disk correspondent portion pointer file 
portion signature file corresponding fragment doc referred signature segment storage signature file mapping signature file disks described retrieval algorithm 
moment assume complete copy signature file available disk 
retrieval algorithm example illustrate idea retrieval algorithm 
example machines number frames selected word 
example frames selected query word 
frame divided segments rows 
frame duplicated times 
note solely sake clarity visualizing process scanning signature frames parallel 
segments frames processed 
machine begins processing th segment frame time machine begins processing th segment frame 
machine processes th segment frame time joins result machine available expected completed scanning th segment frame similarly processes th segment frame joins result steps machine list qualified signatures belonging segment doc machine list qualified signatures belonging segment doc machines similarly segments signature file 
snapshot machines stage 
grid marked id machine working correspondent segment row label selected frame column label 
second final stage 
general algorithm scheme distributing signature frames disks 
note algorithm signature frame units duplicated disks 
experiment results text databases experiment 
documents documents 
document size kb average 
response time obtained measuring time process unsuccessful queries dividing time 
experiments run dec workstations connected ethernet 
workstation local disk 
mentioned pvm library calls network communication 
sets send receive commands provided pvm snd rcv commands 
commands offer functionality implementations different calls involve pvm daemon program bypass daemon 
experiment shows commands take time snd rcv complete set message passing calls program 
results rest reflect implementation calls 
followings design parameters signature file procedure selecting optimal parameters 
expected false drop probability formula theta gamma database documents average number false drops cat synch concurrent pipelined algorithm section 
cat bulk processing segments section 
see text details 
naive processor assigned segment 
table options signature file scanning 
expected query documents number 
experiments table explains different options system experimented 
options user buffers cache entire signature frame processed processor 
measure followings experiment response time physical clock actual false drop rate time host program takes broadcast queries search engines 
obtain execution time profile search engine 
timing measures taken load workstations typical working day level specified 
disk activities cpu load factor varies cpu intensive program running 
program usually adds cpu load scale 
approximate sequentiality assumption section signature files created disk partitions near empty 
cat bulk algorithm needs explanation cat synch algorithm machines send receive messages scanning signature frames 
suspect cause machines may lead longer execution time 
tried cat bulk algorithm 
idea algorithm sending receiving partially processed bit vector processor machine processes segments signature frame sends bit vectors machines responsible scanning false drops corresponding database fragments 
bit vectors database fragment merged machine assigned fragment 
strategy communication occurs signature frames scanned 
naive method simply divides database fragments 
database fragment correspondent signature file segment assigned machine 
explained naive method reduce number random disk accesses 
parameters optimal due fact current system handle signature frames size multiple byte 
proc db db cat synch cat bulk naive table average query response time ms speed including scanning false drops 
indicates signature file cached 
naive method allows machines operate independently 
table gives response times speed factors running system different options listed table 
response time averaged single word word word conjunctive queries runs 
standard deviation response times table ms 
speed factors calculated sequential program opposed parallel version running single machine 
sequential program takes average seconds mb database seconds mb database single word query 
note unusually large speed factors experiments user buffer cache surprise actual amount parallel program sequential disk completely eliminated parallel program advantage possible parallelization 
notice difference response times mb database machines mb database machines buffers appears constant naive method needs transmit larger amount data 
suggest existence non parallelizable component system amount performed search engine cases 
elaborate presenting execution profile search engines 
cat synch method yields speed better cat bulk naive methods 
comparison cat synch naive consistent findings 
cause difference cat synch cat bulk explained mentioned previous section cat able achieve response time single word multiple word queries selecting frames query 
experimental results support expectation 
instance average query response times ms ms ms single word word word queries respectively 
words query false drop rate word gamma word gamma word gamma table false drop rate experiment 
proc broadcasting time standard deviation ms ms ms ms table cost broadcasting 
data taken processes active system 
subsection 
table lists actual false drop rate observed experiment 
mentioned expected false drop probability formula theta gamma experimental results agree expectation maximal difference 
table gives overhead broadcasting query search engines host program 
results obtained consecutive runs processes active system 
seen cost increases linearly number machines 
current pvm implementation treats broadcasting sending message machine sequentially 
broadcasting serial operation 
table execution profile search engine 
detailed timing statistics data processing cpu time parallel search engine taken unix profiling facility sequential program running database size equal database fragment mb parallel system 
amount data amount sequential program parallel search engine 
broadcasting costs taken table 
overhead communication synchronization computed subtracting data processing time disk time broadcasting time experimental response time 
listed table numbers non voluntary context switches engine engine running parallel 
number non voluntary context switches indicates interference unix scheduler fairly substantial switches period ms average query response time 
note broadcasting cost plus communication synchronization overhead amounts total execution time 
non parallelizable bottleneck broadcasting query signature serial operation shown table db size proc avg 
rep time ms ms ms broadcasting ms ms ms load sig 
frame ms ms ms scan sig 
frame ms ms ms scan false drop ms ms ms comm synch 
ms ms ms overheads non voluntary times times times context switch table execution profile search engine 

mb database percentage broadcasting cost increases number machines doubles 
discussion effect context switch context switch avoided application program unix process 
words processes performing signature scanning subject interruption unix scheduler 
cost context switch high non voluntary context switch query 
overhead hidden explained 
difference cat synch cat bulk methods cat bulk scanning signature segments done results scanning sent 
shown amount done methods number messages sent received 
environment process difference response time methods machines processes outcome different due fact cat synch method receive call evenly spread process 
waiting time receive calls hide time search process interrupted system 
example illustrates phenomenon 
example simplifying assumption receiving process fixed delay retrieve incoming message 
fixed delay considered minimum time issuing receive instruction receiving message 
recall pvm synchronous receive unix process may switched cpu system call 
assume network latency fixed delay 
explanation able measure communication synchronization overheads directly 
process process time time cat bulk cat synch message effect interference processes presence process machine effect finishing time cat bulk method effect cat synch method 
valid assumption relaxed situation complicated 
call strategy arranging communication calls evenly distributed process voluntary breaking 
voluntary breaking hides interruptions execution 
problems serial broadcasting relative cost broadcasting significant total response time experiments expect cost soon dominant factor number machines increases 
reason cost broadcasting currently implemented pvm linear number machines actual data processing time search engine inversely proportional number machines 
relative broadcasting cost percentage actual data processing time order database fixed size number machines 
words size database quadruple number machines doubles order retain constant relative cost broadcasting 
consider serious limitation rest program incurs overheads constant fraction actual data processing time see table search engine size database increases proportionally number machines cluster 
able verify machines processes ones active 
comparison architectures performance study cat done lin butterfly tc multiprocessor 
disk accesses emulated study disks attached individual processors 
tightly coupled multiprocessor butterfly tc execute program dedicated processor cluster communication synchronization overhead insignificant kind computation granule full text retrieval 
speed obtained processors 
compared mainframe machines textual databases may assume memory available mainframe significant portion signature file stored main memory 
case bottleneck alleviated 
trade cost mainframe substantially higher small workstation cluster 
advantage having memory mainframe appears diminishing modern workstations configured large amount cheaper memory choose 
workstation cluster expected able offer better performance cost ratio 
investigated intensive application parallel full text search implementing network workstations 
study shows substantial improvement speed obtained parallelism disk accesses despite high communication synchronization overhead incurred loosely coupled system 
problems pertinent parallel applications type computing environment discussed 
effect synchronization delays serial bottleneck broadcasting 
appears application parallelizable subtasks requiring intensive disk network workstations local disks effective platform achieve better performance 
major advantages workstation cluster substantially larger combined cache space possible concurrent disk accesses 
demonstrated advantages exploited achieve high performance adding extra hardware 
serial broadcasting identified sole sequential bottleneck implementation 
expect system scalable workstation clusters larger size efficient broadcasting mechanism available 
synchronization overhead substantial shown study 
believe improve term execution speed making supporting message passing software efficient 
challenging problem arises load balancing issue 
case study encounter problem application chosen decomposable subtasks nearly equal size 
plan look issue 
christodoulakis ho multimedia object presentation manager minos symmetric approach proc 
acm sigmod may 
cheung reeves high performance computing cluster workstations proceedings international symposium highperformance distributed computing syracuse new york sept 
faloutsos signature text retrieval methods survey ieee data engineering vol 
mar 
pp 

geist network concurrent computing pvm system technical report tm oak ridge national lab 
lin faloutsos frame sliced signature files ieee transaction data engineering vol june 
lin concurrent frame signature files distributed parallel databases international journal vol 

july requirement analysis high performance distributed computing lan proceedings international symposium high performance distributed computing syracuse new york sept 
price optical disk pilot project library congress video disc optical disk vol 
pp 
nov 
sacks davis kent ramamohanarao multikey access methods superimposed coding techniques 
acm transaction database systems vol 
dec 
van rijsbergen information retrieval butterworths london england 
