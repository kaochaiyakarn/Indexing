worst case prediction sequences log loss manfred opper david haussler 
consider game sequentially assigning probabilities data past observations logarithmic loss 
making probabilistic assumptions generation data consider situation player tries minimize loss relative loss hindsight best distribution target class worst sequence data 
give bounds minimax regret terms metric entropies target class respect suitable distances distributions 


assignment probabilities possible outcomes data past observations important applications prediction data compression gambling 
scenario data assumed occur random unknown probability distribution problem treated known statistical estimation problem 
optimal strategies game theoretic approach statistician called learner tries minimize certain average loss game played nature chooses unfavourable probabilities data family 
cases assumption randomness true distribution data may fulfilled may prior information specify reasonable target class distributions true belongs 
new approaches prediction sequences data avoid assumption randomness great deal interest computational learning theory see information theory 
collection see webpage www stat wharton upenn edu seq workshop prediction sequences held uc santa cruz 
considering average losses goal find strategies achieve small accumulated loss arbitrary sequences data game sequential prediction 
assuming target family predictors called experts hopefully suited data learner tries find strategy sequence guarantees total loss larger expert best hindsight 
important case logarithmic loss families experts assign probabilities independently past data give general bounds minimal relative loss regret achieved strategy 
differs area institut ur theoretische physik iii universit germany 
department computer information sciences university california santa cruz ca 
manfred opper david haussler applies finite dimensional infinite dimensional families simple experts 

notation 
notation assumptions 
complete separable metric space 
probability distributions discussed assumed defined oe algebra borel sets theta set theta probability distribution assume theta distributions associated distinct sense borel set ae 
addition assume fixed oe finite measure dominates theta borel set implies 
implicitly assumption distribution mentioned results dominated radon nikodym derivatives densities respect denoted lower case symbols dq dp 
sequential prediction game 
suppose symbols yn observed sequentially 
observation gamma learner asked value observation 
learner goal assign probability distribution gamma possible outcomes observation previous values 
time step actual new observation received learner suffers loss article logarithmic loss gamma log jy gamma 
logarithmic loss important meaning data compression assignment probabilities data values considered assignment possible data uniquely decodable code 
total log loss ignoring problems truncating continuous data values rounding integers proportional length compressed sequence data 
interpretation logarithmic loss terms wealth achieved gambling probabilities stand relative amount money bet data values see game learner suffered total loss gamma log jy gamma predictions jy gamma composed single joint distribution jy gamma hand joint distribution defines sequence predictive distributions conditionals jy gamma 
learners worst case prediction sequences log loss goal understood assignment distribution set possible sequences loss written gamma log sequences known randomly drawn distribution easy see order achieve minimal expected loss learner predict conditional distributions gamma gamma 
true distribution known fact belongs family distributions theta possible strategy minimize expected extra loss minimum worst 
means learner trying prepared worst distribution sequences minimize risk sup gamma log log see papers cited discussion average loss framework results obtained 
go average loss framework analyze strategy aims performing individual sequences 
approach probabilistic assumptions generation sequences 
target family distributions seen family experts hoped suited sequences 
goal learner find distribution loss sequence bigger best expert target class theta 
best expert achieves loss gamma sup theta log depends entire sequence known learner symbol yn observed 
worst case scenario learner choose distribution minimizes regret difference loss loss best expert gamma log sup theta log minimal regret achievable strategy rn inf sup inf sup ae log sup theta oe bounds asymptotic expressions minimax regret obtained finite dimensional parametric families distributions probability mass functions finite alphabet distributions smooth functions parameters 
follows denote fold products distributions respectively evaluated point manfred opper david haussler give general upper bound rn target families product distributions uniformly bounded away zero infinity 
bounds applied nonparametric families distributions knowledge minimax results arbitrary sequences obtained 
calculation explicit solution minimax problem shtarkov 
distribution sup theta sup theta minimizes worst case regret sup 
easily seen regret distribution depend sequence satisfies rn log sup theta proof achieves optimality simple 
sequence note distributions normalized 
sup sup 
upper bound minimax regret 
definition metric entropy called kolmogorov ffl entropy needed 
definition 
metric complete separable metric space 
partition pi collection borel subsets pairwise disjoint union diameter set diam sup 
diameter partition supremum diameters sets partition 
ffl ffl denote cardinality smallest finite partition diameter ffl finite partition exists 
metric entropy defined ffl log ffl say totally bounded ffl ffl 
definition 
ffl ffl separated subset subset distinct ffl 
packing number ffl denote cardinality largest finite ffl separated subset worst case prediction sequences log loss arbitrarily large sets exist 
lemma easily verified 
lemma 
ffl ffl ffl ffl follows metric entropy condition defining total boundedness defined packing numbers place constant factor ffl 
theorem 
theta 
set sup log gamma log theta 
exists positive universal constant ffl rn ffl theta ffl ffi theta dffi nffl proof series lemmas 
elementary steps cast problem form tools empirical process theory applied 
construct minimal partition theta diameter ffl consisting subsets theta ffl theta try control sup equation inside set 
fix probability distribution theta set partition theta 
lemma define expectation setting function 
log gamma log sup theta jz lemma 
ffl rn ffl theta log max exp manfred opper david haussler proof rn sup theta equation ffl theta sup theta ffl theta max sup theta ffl theta max sup theta ffl theta max exp sup theta log ffl theta max exp sup theta log gamma log ffl theta max exp penultimate line follows positivity kl divergence log log fix kth set partition omitting index clear context 
note sn norm collection fz theta random variables 
chosen randomly distribution fixed random variable sum zero mean random variables distribution depending 
type quantity techniques empirical process theory bound 
step relate exp sn lemma 
family functions indexed theta sup theta jx 
yn collection random variables tn sup theta iee tn exp nc lemma proved appendix lemma 
apply lemma theta theta log gamma log worst case prediction sequences log loss tn sn note sup log gamma log ffl diameter set partition ffl 
lemma lemma rn ffl theta nffl max bound need definition 
collection zero mean random variables fz thetag called sub gaussian process respect theta theta pr jz gamma gamma lemma easily follows corollary page lemma 
fz thetag sub gaussian process norm finite packing numbers ffl theta ffl 
exists positive universal constant ffl theta sup ffl jz jz ffl log ffi theta dffi apply lemma choose set partition omitting dependence convenience set density denote expectation measure 
fix theta 
log gamma log gamma 
equation clear ju 
sum bounded random variables 
may apply hoeffding inequality obtain pr ju exp theta gammat nd gamma shows sub gaussian respect nd follows lemma equation rn ffl theta nffl ffl log ffi theta dffi nd theorem follows 
manfred opper david haussler 
lower bound 
lower bound rn provided terms metric entropy theta respect called hellinger distance defined dh gamma oe bound established simple fact rn smaller minimax risk framework data generated random distribution theta equation rn inf sup gamma log log general lower bound quantity product distributions obtained 
lemma part equation get lemma 
assume theta dh totally bounded 
rn sup ffl minfk ffl theta dh nffl gamma log rn bounded terms hellinger metric entropy terms metric entropy 
entropies close resulting bounds characterize growth rate rn seen 

example nonparametric family densities 
interesting nonparametric families densities metric entropies scale ffi theta const ffi ff ffi 
assuming ff show limit ffl ffi theta dffi const ffl gammaff case rn theorem easily bounded setting ffl gamma ff ff 
large rn const ff ff ff 
common example lipschitz class theta densities real interval derivatives jp jp gamma cjy gamma fl fl 
assume densities uniformly bounded away zero result show metric entropy behaves ffl theta const gamma ffl delta fl ffl yields rn const fl worst case prediction sequences log loss large fl shown example lower bound yields exponent increase rn upper bound 
lower bound related statistical risk random sequence framework result shows example pessimistic assumption worst sequence framework lead higher extra losses random sequence framework 
similar result obtained parametric families 
true significantly general settings problem research 

appendix 
proof lemma write tn gamma iet sum martingale differences tn gamma iet tn gamma gamma tn function ak jy denotes conditional expectation proof inequality jd sup jx sup jx due proved lemma page 
completeness give sketch proof 
tn sup theta definition sup get triangular inequality sup norm jt gamma sup jx write tn gamma gamma tn gamma phi gamma gamma psi true independence terms curly brackets give zero 
get jd sup jx gamma sup jx sup jx sup jx proves 
properties conditional expectations bound iee tn iee iee gamma gamma dn iee gamma exp sup jx sup jx manfred opper david haussler exp sup jx sup jx exp nc inequality martingale property gamma dn fact bounded random variable jv iee second inequality obtained iterating 


acknowledge inspiring discussions peter auer andrew barron yoav freund nick manfred warmuth jon wellner 
kolmogorov ffl entropy ffl capacity sets functional spaces amer 
math 
soc 
translations ser 

vovk aggregating strategies proceedings conference computational learning theory morgan kaufmann 
cesa bianchi freund helmbold haussler schapire warmuth expert advice th annual acm symposium theory computing san diego ca 
freund predicting binary sequence optimal biased coin proceedings ninth annual conference computational learning theory acm press 
shtarkov coding discrete sources unknown statistics topics information theory csiszar elias editors north holland amsterdam 
barron xie asymptotic minimax loss data compression gambling prediction proceedings ninth annual conference computational learning theory acm press 
rissanen fisher information stochastic complexity ieee trans 
inf 
theory 
cover joy thomas elements information theory wiley series telecommunications new york 
cover ordentlich universal portfolios side information ieee transactions information theory 
aad van der jon wellner weak convergence empirical processes springer series statistics 
ledoux talagrand probability banach spaces processes springer verlag berlin 
haussler opper mutual information metric entropy risk estimation probability distributions annals statistics december 
clements entropy sets real valued functions pacific math 

weinberger merhav feder optimal sequential probability assignment individual sequences ieee trans 
inf 
theory 
hoeffding probability inequalities sums bounded random variables american statistical association journal 
