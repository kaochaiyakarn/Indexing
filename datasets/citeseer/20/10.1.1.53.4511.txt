fast mining sequential patterns large databases mohammed zaki zaki cs rochester edu university rochester computer science department rochester new york technical report november new algorithm fast discovery sequential patterns 
collection items set records items records belonging customer task identify commonly occurring sequences items bought customers 
example sequential pattern people buying douglas adam guide galaxy bought restaurant universe month 
existing solutions problem repeated database scans complex hash structures poor locality 
new spade algorithm uses simple join operations finds frequent sequences usually database scans 
help extensive experiments show spade outperforms best previous algorithm factor order magnitude incremental case 
excellent scale properties respect number customers number transactions customer transaction size size potential maximal frequent sequences 
keywords knowledge discovery data mining sequential patterns sequence discovery temporal association rules 
university rochester computer science department supported 
phenomenal growth data spurred growth new field called data mining knowledge discovery databases kdd 
key challenge identification new useful understandable knowledge massive databases 
term kdd refers process discovering new insight data mining refers core model pattern discovery step 
steps include data selection cleaning preprocessing transformation data mining task algorithm selection post processing 
main forms data mining identified 
verification driven data mining user postulates hypothesis system tries validate 
common verification driven operations include query reporting multidimensional analysis statistical analysis 
discovery driven mining hand automatically extracts new information 
common techniques include classification clustering association rules sequential patterns 
focuses discovery sequential patterns 
prototypical application retail sales market basket analysis domain 
collection items set records items records belonging customer task identify commonly occurring sequences items bought customers 
example sequential pattern people buying douglas adam guide galaxy bought restaurant universe month 
retail sales catalog applications patterns useful domains telecommunications alarm diagnosis medicine identifying symptoms precede diseases 
problem formulation problem mining sequential patterns proposed :10.1.1.40.9892
stated follows fi delta delta delta set distinct attributes called items 
itemset non empty unordered collection items loss generality assume items itemset sorted increasing order 
sequence ordered list itemsets 
itemset denoted delta delta delta item 
itemset items called itemset 
sequence ff denoted ff 
ff 
delta delta delta 
ff sequence element ff itemset 
sequence items jff called sequence 
item occur itemset occur multiple times different itemsets sequence 
sequence ff ff 
ff 
delta delta delta 
ff index set delta delta delta ng subsequence sequence fi fi 
fi 
delta delta delta 
fi index set delta delta delta mg denoted ff fi exists index jx example sequence 
ac 
subsequence ab 

ace 

de sequence elements ab ac acd de 
hand sequence ab 
subsequence abe vice versa 
say ff proper subsequence fi denoted ff oe fi ff fi fi ff 
transaction unique identifier contains set items customer unique identifier associated list transactions ft delta delta delta loss generality assume customer transaction time stamp transaction time transaction identifier 
assume list customer transactions sorted transaction time 
list customer transaction sequence 

delta delta delta 
called customer sequence 
database consists number customer sequences 
customer sequence said contain sequence ff ff ff subsequence customer sequence support frequency sequence ff fraction total customers contain sequence fr ff jfc contains jdj easy modify definition count sequence multiple times customer semantics problem require 
user specified threshold called minimum support denoted min sup say sequence frequent fr ff min sup 
set frequent sequences denoted set frequent sequences database customer sequences problem mining sequential patterns find frequent sequences database 
familiar association rules literature clear sequential pattern discovery essentially thought association discovery temporal database 
association rules discover intra transaction patterns itemsets discover inter transaction patterns sequences 
set frequent sequences superset set frequent itemsets 
database example consider customer database shown 
running example 
database items customers transactions 
minimum support customers obtain frequent sequences support sequence square brackets ab af :10.1.1.40.9892:10.1.1.40.5742
bf :10.1.1.40.5742
:10.1.1.40.5742
:10.1.1.40.5742
:10.1.1.40.5742
abf bf :10.1.1.40.9892:10.1.1.40.5742
:10.1.1.40.5742
bf :10.1.1.40.5742

:10.1.1.40.5742

:10.1.1.40.5742
bf 
sequence rules frequent sequences known obtain rules describe relationship different sequence items :10.1.1.40.5742
example sequence bf occurs customer id transaction time items original database min conf frequent sequences fi subsequences ff oe fi conf fr fi fr ff conf min conf output rule ff fi conf rule generation algorithm customers abf customers 
say bf occurs chance occurs 
words say rule bf bfa confidence 
example rule 
bf 
bf 

confidence 
user specified minimum confidence min conf generate rules meet condition means simple algorithm shown 
rule generation step quite straightforward rest concentrate frequent sequence discovery phase 
related problem mining sequential patterns introduced :10.1.1.40.9892
algorithms solving problem 
algorithms apriorisome generated maximal sequential patterns 
applications require frequent patterns 
aprioriall algorithm patterns shown perform equal better approaches 
subsequent authors proposed gsp algorithm outperformed aprioriall times :10.1.1.40.6428
introduced maximum gap minimum gap sliding window constraints discovered sequences 
problem finding frequent episodes sequence events 
episode consists set events associated partial order events 
definition sequence expressed episode targeted discover frequent episodes single long event sequence interested finding frequent sequences different customer sequences 
extended framework discover generalized episodes allows express arbitrary unary conditions individual episode events binary conditions event pairs 
sequential patterns essentially associations temporal data utilize ideas initially proposed discovery association rules 
new algorithm fast association mining techniques 
somewhat relevant includes discovery association rules quantity items bought considered taxonomy imposed items 
lately increasing interest developing efficient parallel algorithms problems 
contributions best existing algorithm sequential patterns gsp algorithm 
essentially performs level wise breadth search sequence lattice spanned subsequence relation 
gsp database scan level 
maximum frequent sequence length gsp database passes 
incurs high costs 
facilitate fact support gathering sequences counted stored complex hash tree structure 
structures shown suffer poor locality 
additional overhead building searching structures 
propose new algorithm called spade sequential pattern discovery equivalence classes 
decomposes problem smaller sub problems solved independently 
highly sub problem processed main memory 
spade usually database scans 
uses simple join operations compute frequent sequences 
highly attractive direct integration database management system dbms 
help extensive experiments show spade outperforms gsp factor order magnitude incremental case 
shown scales linearly number customers 
excellent scaleup properties respect number transactions customer transaction size size potential maximal frequent itemsets sequences 
rest organized follows 
brief discussion gsp algorithm section 
new spade algorithm section followed experimental comparison spade gsp scalability analysis spade section 
section conclude point directions 
frequent sequences gamma set candidate sequences customer sequences database increment count ff contained fff jff sup min set frequent sequences gsp algorithm gsp algorithm best previous algorithm mining sequential patterns called gsp generalized sequential patterns :10.1.1.40.6428
gsp multiple passes database 
pass single items sequences counted 
frequent items set candidate sequences formed 
pass gather support 
frequent sequences generate candidate sequences process repeated frequent sequences 
main steps algorithm 
candidate generation set frequent gamma sequences gamma candidates pass generated joining gamma 
pruning phase eliminates sequence subsequences frequent 
fast counting candidate sequences stored hash tree 
leaf nodes contain sequences interior nodes hash table 
non empty cell hash table depth points hash tree node depth 
candidates inserted hash tree starting root hashing th sequence item depth leaf reached inserted 

support counting find candidates contained customer sequence conceptually subsequences generated 
subsequence search hash tree 
candidate leaf matches subsequence count incremented 
gsp algorithm shown 
details specific mechanisms constructing searching hash trees please refer :10.1.1.40.6428
name suggests gsp solves sequential pattern problem formulated section generalizes considering taxonomies items including timing constraints minimum maximum gap successive sequence elements incorporating sliding windows relaxes definition transaction 
new spade algorithm designed goal speeding basic sequential pattern problem 
part plan extend handle generalized problem 
spade algorithm subsequence lattice fif 
subsequence lattice sequences sequences sequences sequences sequence lattice spanned subsequence relation running example fa fg 
shows sequence lattice spanned subsequence relation frequent items 
show lattice compact form 
frequent item set frequent sequences 
template denotes set fi bg template 
denotes set fx 
fi fi bg 
item simply acts prefix sequences block denotes set sequences prefix lexicographically equal greater item example level blocks ffg 
seen succeeding level built blocks preceding level 
example expanding sequence block get bdf 
expansion yields sequences ab ad af similarly expanding block 
get 
gives sequences 



expansion sequences complete label new blocks 
denotes entire set sequences subset starting sequences prefix 
new blocks serve input level 
inductively expanding block described generates entire subsequence lattice 
itemset length arrangements sequences gamma gamma gamma gamma 
gamma gamma 
gamma table number sequences lemma denote total number frequent items 
total number sequences min gamma delta gammai delta proof proof quite straight forward 
start sequence elements itemsets 
way obtain arrangement 
consider case sequence element itemset gamma elements itemsets 
gamma ways obtain arrangement 
general case sequence element itemset gamma sequences itemsets 
gamma ways obtain arrangement 
sequence element itemset 
table shows different cases 
assign items sequence element 
lets consider general case itemset element length item assignments 
remaining gamma itemset elements choices gammai choices 
multiplying choices case summing rows shown table obtain total number sequences shown 
point view subsequence lattice infinite 
fortunately practical cases bounded 
number sequence elements itemsets bounded maximum number transactions customer say 
size itemset bounded maximum transaction size say sequence delta items subsequence lattice bounded delta example maximum possible sequence items 
practical cases lattice bounded set frequent sequences sparse depending min sup value 
fast algorithm avoid looking entire lattice 
important technique achieving focus sequences subsequences frequent 
turn frequent guaranteed considered potentially frequent sequences process 
lemma sequence fi frequent subsequences ff fi frequent 
proof obvious definition support 
property successfully exploited data mining algorithms sequential patterns frequent episodes association rules 
described earlier gsp algorithm explores lattice bottom manner forming new candidate sets sequences frequent previous level making full database scan level 
new spade algorithm bottom search passes 
point may beneficial perform depthfirst hybrid random search quickly identify maximal frequent sequences gather supports subsequences 
exploring faster search methods part ongoing research 
database format sequence structure spade algorithm uses different database layout earlier approaches 
gsp algorithm uses horizontal data layout transaction customer identifier cid transaction identifier tid number items transaction items 
spade hand uses vertical layout item associated list pairs customer transaction identifiers cid tid item occurs 
list called ctid list 
contrasts horizontal vs vertical database layout 
shows ctid lists frequent sequences 
sequence spade ctid list array items sequence support counter integer representing sequence template 
sequence template separates different elements sequence 
example sequences 
bd 



set items different sequence templates respectively 
bit value denotes follows relation marks new element bit value denotes equality relation indicates items belong element 
horizontal vs vertical horizontal format imposes computation overhead candidate sequence support counting step 
particular customer sequence iteration check subsequences occurs candidate set stored hash structure 
format forces scan entire tid cid tid cid tid cid cid tid ctid lists frequent items horizontal database format transactions customer customer id id items items item id customer id pairs ctid list item vertical database format horizontal vs vertical database format database level 
vertical layout avoids problems enables count support simple intersections ctid lists 
size lists shrinks sequence length increases facilitates vary fast intersections 
need complicated hash structures 
vertical format limitations 
compute format see section usually occupies disk space potential benefits far outweigh limitations 
computing frequent sequences min sup database items read ctid list distinct cid sup sup sup min sup fig generate vertical database format shown frequent sequences computed single database scan 
database item read ctid list disk memory 
scan ctid list incrementing support new customer identifier encountered 
gives complete method 
frequent item sequence template 
computing frequent sequences drawbacks vertical format ctid lists increased cost computing essentially requires self join item read disk memory 
items read ctid lists intersect single intersection sufficient determine sequences xy 

frequent 
approach item scanned times disk 
jf total number ctid list scans sum gamma average number times item ctid list scanned gamma asymptotically 
vertical format compute requires database scans horizontal format done single pass 
trick recover horizontal format fly vertical format compute achieve efficiently discussed 
optimized computation invert frequent items read ctid list cid tid pairs cid gamma hd hd tid invert database main steps optimized calculation invert vertical format obtain horizontal format new format compute database inversion inversion method shown 
vertical input database denoted simplicity lets assume inverted database denoted hd fits memory 
hd denotes set transactions belonging th customer 
element set form item tid item associated cid size item tid pairs inverted database hd transaction identifier tid 
inversion process quite straight forward 
item scan ctid list disk 
element ctid list cid tid pair 
cid compute offset insert hd pair tid 
shows inverted database obtained example vertical database 
interesting contrast recovered horizontal database horizontal format shown 
difference recovered database sorted items transactions 
min sup hd hd distinct items get pairs item distinct items get pairs item contains min sup 
min sup 
min sup xy compute compute recovered horizontal database count support sequences 
jf setup array length theta counting sequences form 
array length theta gamma counting sequences form xy 
customer hd recovered database sorted item self join items sufficient find sequences contained customer 
shows method step 
simplicity assume count arrays fit memory 
item denote list tid pairs current customer 
item pair form lists call contains routine see section increment count sequences xy 


sequence templates respectively 
min sup jf get item range database blocks hd invert min sup hd generate memory management simplicity discussion assumed fits memory 
large databases entire inverted database surely fit memory 
count arrays may fit memory 
implementation solve problem performing appropriate memory management 
count arrays don fit memory database passes counting specific range items pass 
furthermore vertical database partitioned number blocks individual block fits memory 
partitioning done line pre processing step 
compute generate range items counted items set fl delta delta delta array segments single partition fit memory 
scan data block invert fly get hd count items current range 
process repeated items counted 
complete algorithm computing shown 
computing frequent sequences equivalence classes set frequent sequences say sequences belong equivalence class share common gamma length sequence prefix items template 
formally gamma ff denote gamma length sequence prefix sequence ff 
ff frequent gamma ff gamma equivalence class defined follows gamma fff jp gamma ff equivalence class kinds elements 
depending sequence pattern 
example consider example section 
shows different equivalence classes obtained 
shows sequence templates 
motivation definition leads natural partition sequences equivalence classes processed independently 
class information generating sequences prefix new candidate sequences constructed steps af ab bf candidate equivalence classes abf ab bf bf bf af ab ax bx dx fx equivalence classes sequence pattern sequence template equivalence classes 
self join theta element 
generates new equivalence class phi 

assuming 
template list phi template list phi template generate different classes simply consider pairs elements say 


intersection corresponding ctid lists determine sequences 




xy frequent insert appropriate equivalence class 

self join theta element produces new equivalence class phi 
consider pairs elements 
joining produce possible candidate xy belongs list phi template simple intersection ctid lists performed check candidate frequent 

cross join theta obtain phi phi need join elements 
produces candidate 
belongs list phi template 
step intersect ctid lists determine support 
candidate equivalence classes produced applying rules classes shown 
shows candidates generated may infrequent 
actual implementation candidate support computed intersection frequent sequences inserted new equivalence classes 
apply rules new classes obtain set candidate equivalence classes process repeated till frequent sequences 
lemma equivalence class frequent sequences 
frequent sequences prefix generated applying candidate generation rules 
proof equivalence class frequent sequences initially contains frequent sequences form 
prefix phi ffi oe ffi oe delta delta delta ffi oe frequent sequence prefix sequence items specified oe sequence template ffi oe ffi assume way contradiction phi generated class 
rules candidate generation implies gamma subsequences phi ffi oe ffi oe delta delta delta ffi gamma oe gamma phi ffi oe ffi oe delta delta delta ffi gamma oe gamma ffi oe generated 
loss generality lets assume phi generated 
mean gamma subsequences phi ffi oe ffi oe delta delta delta ffi gamma oe gamma phi ffi oe ffi oe delta delta delta ffi gamma oe gamma ffi gamma oe gamma generated 
lets assume subsequence phi generated 
inductively applying process get subsequence phi ffi oe ffi oe subsequences phi ffi oe phi ffi oe 
contradiction phi phi frequent subsets frequent sequence phi form 


implies assumption false words phi generated class 
problem decomposition equivalence classes spade algorithm begins calling 
process available frequent sequence sets elements belong single equivalence class null prefix 
class corresponds entire sequential pattern discovery problem 
equivalence classes hand provide natural partition problem classes lemma class processed independently produces frequent sequences prefix equivalence classes partition input database small chunks composed items belonging class 
class solved independently processed main memory 
general case require suitable memory management techniques 
constructing routine know elements ctid lists 
step construct ctid lists elements cx 

done scanning ctid lists items disk intersecting 
know entire stage avoid performing unnecessary ctid list intersections 
example consider element form cx 
apply rules candidate generation construct candidates form cxy cx 
check subsequences xy 
belong candidates frequent 
candidates generated cx pruned delete element cx class altogether 
remaining elements rules candidate generation recursively generate new classes increasing sequence lengths frequent sequences prefix 
delayed partitioning decomposing initial problem smaller sub problems 
average size equivalence class large intersecting ctid lists may prove expensive similar problem described computing cases optimized method inverting vertical database fly 
obtained way partition problem 
automatically decide switch equivalence class approach simply counting number times item scanned disk 
average number scans item theta theta log switch equivalence class approach continue recovered horizontal database approach 
ctid list intersection intersect ff fi oe oe oe distinct ff ff ctid list distinct fi fi ctid list ff fi ff get pairs cid ff fi get pairs cid fi contains ff fi oe oe oe ctid list intersection describe perform ctid list intersection sequences equivalence class 
depending pattern sequences may possible frequent candidates 
intersection sufficient determine frequent 

sequences ff 
fi 
check possible candidates oe 

oe 

oe 
xy 

sequences form ff fi check candidate oe xy 

sequences form ff fi 
check candidate oe 

cases correspond candidate generation rules 
intersection method takes input sequences possible candidates oe oe oe may null 
recall ctid list cid tid pairs elements see 
perform intersection scan ctid lists looking matching customer identifiers 
call contains subroutine determine candidate sequences customer increment candidate count 
shows intersection algorithm 
contains ff fi oe oe oe oe tids fi tid ff oe add ctid list cid oe tids ff tid fi oe add ctid list cid oe tids fi tid ff oe add ctid list cid containment check checking containment contains method checks sequence customer transaction 
ff fi lists cid tid pairs cid need check kinds relationships tid entries equality oe ii follows oe oe equality check simply traverse lists insert matching cid tid entries oe ctid list 
follows check oe insert oe ctid list tids fi greater tid ff oe roles ff fi reversed 
insert oe ctid list tids ff greater tid fi algorithm intersection process shown means example matching cid entries lists shown shaded region 
short circuited join speed intersection ctid lists making min sup value 
example lets say ff support distinct cid values fi support min sup 
comparing matching cid values intersection discover mismatches ff resulting candidates support gamma words xy cid tid cid tid intersecting ctid lists cid tid cid tid cid tid size size size size size ctid list intersection candidates frequent 
spade uses short circuit mechanism optimize intersections 
pruning candidates candidate sequence length subsequences length gamma 
reduce number candidates lemma check subsequences frequent 
frequent retain candidate perform ctid list intersection 
candidate possibly frequent dropped consideration 
candidate generation rules section subsequences lexicographic order produce candidate need check frequency remaining subsequences 
subsequences current class 
example consider subsequences 
bf 

subsequences 
bf 



produced current partition 
subsequence bf 
belongs partition 
class processed determine subsequence frequent 
pruning routine conservative assuming frequent 
ensure maximum possible information pruning process equivalence classes lexicographically descending order 
example classes order 
advantage descending order itemsets sequence elements information available pruning items itemsets kept sorted order 
prune fi gamma subsequences ff oe fi ff fi ff ff delete fi candidate pruning pruning algorithm shown 
processed class associated array frequent sequences produced class 
due nature candidate generation rules sequences sorted length primary key actual sequence items plus template secondary key sorting needed 
frequent candidate generated inserted frequent list 
ff denote item sequence ff 
check subsequence ff oe fi frequent simply perform binary search frequent list class ff 
complete spade algorithm spade min sup min sup min sup classes descending order gamma classes gamma process class delete spade algorithm presents complete spade algorithm 
compute sets frequent sequences set frequent sequences partition set independent equivalence classes 
classes processed descending order facilitate candidate pruning 
denote set equivalence classes frequent sequences 
initial class forms sole element enter iterative processing phase 
level process class gamma individually candidate generation rules 
current class generate set new equivalence classes 
set merged process entirely deleted 
process stops new frequent classes generated 
shows frequent equivalence classes generated example 
bf bf af ab bf abf ab ax bx dx fx bf bf bf equivalence classes frequent sequences equivalence classes frequent sequences memory management clear need mainmemory space gamma fact class gamma deleted inserting newly generated classes usually memory required set current implementation assumption main memory classes move databases giga tera bytes size assumption longer hold 
case necessary write newly generated class disk 
iteration classes individually read memory processed 
planning implement part 
assumption memory current implementation fully disk 
experimental results section compare performance spade gsp algorithm 
gsp algorithm implemented described :10.1.1.40.6428
implementation gsp uses optimized method computing frequent sequences 
method similar routine spade see section database horizontal format 
optimized calculation spade number partitions chosen database block occupy roughly mb number partitions may vary database 
experimental comparison number synthetic datasets real life dataset 
scale performance spade respect number customers number transactions customer transaction size average size maximal sequences 
experiments performed mhz mips processor mb main memory running irix 
data stored non local gb disk 
number customers average number transactions customer average number items transactions average number itemsets maximal potential frequent sequences average number items maximal potential frequent itemsets number maximal potential frequent sequence number maximal potential frequent itemsets number items table dataset generation parameters dataset size mb table synthetic datasets synthetic datasets synthetic datasets albeit twice customers :10.1.1.40.6428
publicly available dataset generation code ibm quest data mining project 
datasets mimic real world transactions people buy sequence sets items 
customers may buy items sequences may buy items multiple sequences 
customer sequence size transaction size clustered mean may elements 
different dataset generation parameters listed table 
relationship exists different parameters 
maximal itemsets average size generated choosing items 
maximal sequences average size created assigning itemsets sequence 
customer average transactions created sequences assigned different customer elements respecting average transaction size generation stops customers generated 
set :10.1.1.40.6428
number data sequences set 
table shows datasets parameter settings 
refer reader additional details dataset generation :10.1.1.40.9892
real life dataset real life dataset obtained natural language planning domain 
planner generates plans routing commodities city 
customer corresponds plan identifier transaction corresponds event plan 
event consists event identifier outcome success late failure action name move load set additional parameters specifying things origin destination vehicle type truck helicopter weather conditions 
data mining goal identify causes plan failures 
items plans customers events transactions 
average plan length average event length 
comparison spade gsp compares spade algorithm gsp different synthetic datasets 
graph shows results minimum support changed 
figures clearly indicate performance gap increases decreasing minimum support 
spade algorithm twice fast gsp lower values support 
reasons spade outperforms gsp 
spade uses simple join operation tid lists 
length frequent sequences increases size tid lists decreases resulting fast joins 
complicated hash tree structure overhead generating searching customer subsequences incurred 
structures typically poor locality 
hand spade excellent locality join requires linear scan lists 
minimum support lowered larger frequent sequences 
gsp complete dataset scan iteration 
spade hand restricts usually scans 
cuts costs 
elaborate performance gap gsp spade lets consider bars marked gsp spade 
show total time algorithms time second pass 
figures indicate nearly benefit spade comes improvement running time pass algorithms roughly optimized generation method 
spade outperforms gsp factor order magnitude 
incidentally suggests spade excellent algorithm incremental mining sequential patterns spade essentially corresponds case pre compute store disk 
minimum support time seconds gsp spade gsp spade minimum support time seconds gsp spade gsp spade minimum support time seconds gsp spade gsp spade minimum support time seconds gsp spade gsp spade minimum support time seconds gsp spade gsp spade minimum support time seconds gsp spade gsp spade performance comparison synthetic datasets minimum support time seconds gsp spade gsp spade natural language planning performance comparison planning dataset compare performance algorithms real life database 
results shown 
case synthetic databases spade algorithm outperforms gsp factor 
scaleup shows spade scales number customers increased fold 
experiments performed dataset different minimum support levels ranging 
execution times normalized respect time customer dataset 
observed spade scales quite linearly 
study scale increase dataset parameters ways keeping average number items transaction constant increase average number transactions customer keeping average number transactions customer constant increase average number items transaction 
size datasets kept nearly constant ensuring product average transaction size average number transactions customer number customers delta delta remains 
aim experiments gauge scalability respect test parameters independent factors database size number frequent sequences 
shows scalability results 
ensure number frequent sequences doesn increase great amount absolute minimum support value percentages graph legends indicate value 
graphs database size kept constant delta delta 
number customers relative time scale number customers graph varied varied second graph set varied varied 
easily observed algorithm scales linearly varying parameters 
scalability dependent minimum support value lower minimum support relatively frequent sequences generated increase number transactions transaction size takes time pattern discovery cases 
number transactions customers relative time transaction size relative time scale transactions customer transaction size study scalability change size maximal elements ways keeping parameters constant increase average length maximal potential frequent sequences ii keeping parameters constant increase average length maximal potential frequent itemsets 
constant parameters experiment varied 
second experiment constant parameters varied 
shows algorithm scales test parameters 
higher values support time starts decrease increasing maximal element size 
fact average transaction size average number customer transactions remains fixed increasing maximal frequent sequence itemset size means fewer fit customer sequence fewer frequent sequences discovered 
lower values support larger sequence introduce subsequences time starts increase initially decreases due reasons 
peak occurs roughly median values sequences experiment itemsets experiment 
frequent sequence length relative time frequent itemset length relative time scale frequent sequence length frequent itemset length spade new algorithm fast mining sequential patterns large databases 
previous approaches multiple database scans complex hash tree structures tend sub optimal locality spade decomposes original problem smaller sub problems equivalence classes frequent sequences 
equivalence class solved independently processed main memory 
spade usually database scans frequent sequences frequent sequences generating frequent sequences 
spade uses simple intersection operations ideally suited direct integration dbms 
extensive set experiments conducted show spade outperforms best previous algorithm gsp factor 
excellent scaleup properties respect number parameters number customers number transactions customer transaction size size potential maximal frequent itemsets sequences 
opens research opportunities plan address implementation spade directly top dbms parallel discovery sequences spade discovery quantitative sequences quantity items bought considered efficient solutions problem generalized sequences spade approach introducing minimum maximum time gap constraints sequence elements relaxing definition transaction encompass transaction sliding window imposing taxonomy items 
agrawal mannila srikant toivonen verkamo 
fast discovery association rules 
fayyad editors advances knowledge discovery data mining 
mit press 
agrawal shafer :10.1.1.40.5742
parallel mining association rules 
ieee trans 
knowledge data engg pages 
agrawal srikant :10.1.1.40.9892
mining sequential patterns 
intl 
conf 
data engg 
han fu 
discovery multiple level association rules large databases 
st vldb conf 
mannila toivonen 
discovering generalized episodes minimal occurences 
nd intl 
conf 
knowledge discovery data mining 
mannila toivonen verkamo 
discovering frequent episodes sequences 
st intl 
conf 
knowledge discovery data mining 
parthasarathy zaki li 
memory placement parallel data mining shared memory systems 
technical report tr university rochester november 
ibm quest data mining project 
www almaden ibm com cs quest 
html 
ibm almaden research center san jose ca 
savasere omiecinski navathe 
efficient algorithm mining association rules large databases 
st vldb conf 
simoudis 
reality check data mining 
ieee expert intelligent systems applications pages october 
srikant agrawal 
mining generalized association rules 
st vldb conf 
srikant agrawal 
mining quantitative association rules large relational tables 
acm sigmod conf 
management data june 
srikant agrawal :10.1.1.40.6428
mining sequential patterns generalizations performance improvements 
th intl 
conf 
extending database technology march 
zaki parthasarathy ogihara li 
new algorithms fast discovery association rules 
rd intl 
conf 
knowledge discovery data mining august 
zaki parthasarathy ogihara li 
new parallel algorithms fast discovery association rules 
data mining knowledge discovery international journal appear december 
