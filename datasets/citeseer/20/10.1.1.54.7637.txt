synthesis instruction sets microarchitectures ing huang advanced computer architecture laboratory tr august keywords application specific instruction set processor instruction set design resource allocation code generation design instruction set processor includes related design tasks instruction set design microarchitecture design code generation 
automatic approaches individual task investigation interaction tasks primarily relies designers experience ingenuity 
goal research develop formal models algorithms investigate interaction systematically 
dissertation presents phase synthesis approach problem 
architectural level set application benchmarks pipeline structure asia automatic synthesis instruction set architecture design automation system generates instruction set allocates hardware resources best fit applications time maps applications assembly code synthesized instruction set 
approach formulates codesign problem modified scheduling allocation problem 
simulated annealing algorithm solve problem 
asia microarchitectural level design automation system piper accepts instruction set architecture specification generates pipelined microarchitecture implements instruction set reordering table guides compiler backend reorderer 
approach relies extended taxonomy inter instruction dependencies associated hardware software resolutions 
techniques demonstrated illustrative practical experiments 
results show techniques capable synthesizing instruction set processors better manually designed instruction set architecture vlsi bam application specific environments design metric consisting instruction set size cycle count hardware resources 
addition techniques characterize architectural properties application benchmarks 
synthesis instruction sets microarchitectures ing huang dissertation faculty graduate school university southern california partial fulfillment requirements degree doctor philosophy electrical engineering systems dissertation committee members professor alvin despain professor kai hwang professor peter danzig august copyright ing huang ii acknowledgments finish dissertation 
lord mercy helps accompanied journey degree 
committee chairman professor alvin despain led world design automation microprocessors 
continuous support encouragement essential fuel study 
addition advanced computer architecture laboratory provided unique environment vision broadened 
committee members professor kai hwang warm support professor peter danzig humor comments 
members 
enjoyed fruitful discussions especially questions raised dry runs presentations conferences workshops qualification examination defense 
challenging questions 
am grateful paul linda maher kevin reading suggesting improvements dissertation draft 
endless unconditional support parents mei able come university pursue ph degree 
am high low 
constant sisters chun empowering supply study 
special go wife shu ing ph student student 
knows right time 
took care things concentrate writing 
addition lovely church life enriched life kept buried kinds burdens 
design instruction set processor includes related design tasks instruction set design microarchitecture design code generation 
automatic approaches individual task investigation interaction tasks primarily relies designers experience ingenuity 
goal research develop formal models algorithms investigate interaction systematically 
dissertation presents phase synthesis approach problem 
architectural level set application benchmarks pipeline structure asia automatic synthesis instruction set architecture design automation system generates instruction set allocates hardware resources best fit applications time maps applications assembly code synthesized instruction set 
approach formulates design problem modified scheduling allocation problem 
simulated annealing algorithm solve problem 
asia microarchitectural level design automation system piper accepts instruction set architecture specification generates pipelined microarchitecture implements instruction set reordering table guides compiler backend reorderer 
approach relies extended taxonomy inter instruction dependencies associated hardware software resolutions 
techniques demonstrated illustrative practical experiments 
results show techniques capable synthesizing instruction set processors better manually designed instruction set architecture vlsi bam application specific environments design metric consisting instruction set size cycle count hardware resources 
addition techniques characterize architectural properties application benchmarks 
chapter motivation instruction set architecture isa instruction set representation instruction set processors isp 
interface hardware software 
characterizes organization functionality hardware visible software compilers operating system kernels 
serves behavior specification hardware designers follow designing microarchitecture computer 
microarchitecture ma organization refers structural aspect computer design functional units register file memory system interconnect structure pipeline configuration 
microarchitectures instruction sets interdependent entities senses 

term microarchitecture denote class micro programmed hardware organization example example general sense employed text 
role instruction set microarchitecture computing system environment applications technology physical micro arch machine instruction set software 
hand microarchitecture provides micro operations implement instruction set hand instruction set encoding available microarchitecture 

implementation microarchitecture determines clock cycle time gives hardware cost silicon area power consumption number pins 
compiling application program written high level language machine code design instruction set determines efficiently underlying microarchitecture matches application 
clock cycle time determines performance 
microarchitecture defines hardware costs instruction set instruction set defines efficiency microarchitecture 

problem designing microarchitectures instruction sets typical chicken egg problem mutually depend 
instruction implemented depends supporting microarchitecture 
hand microarchitecture feature included depends instruction set implemented 
practice problem dealt iterative manner shown 
example designer may assume initial set instructions constructs initial microarchitecture design constraints 
possible alteration initial microarchitecture designer checks instructions added deleted design constraints 
repeats process reaches equilibrium point runs design time 
practice design approaches employed 

instruction set various microarchitectures possible include different pipeline organizations circuit modules different performance cost tradeoffs 
scheduling reordering phase compiler backend necessary ensure original sequential semantics software programs preserved 
phase optimizes assembly code program executed particular microarchitecture implementation 
hand complexities compilation techniques application environments may constrain design space microarchitecture 
example highly pipelined microarchitecture requires sophisticated scheduling techniques generated efficient assembly code may feasible embedded system design 
case software programs compiled possibly hand permanently loaded memory 
changed executed repeatedly life hardware system 
highly pipelined microarchitecture may infeasible purpose software development compilation happens frequently short compilation time major advantage 
iterative approach designs ma instruction set microarchitecture ma instruction set design benchmarks microarchitecture design decoupled constraints benchmarks constraints 
performance instruction set microarchitecture varies application domain 
characteristics expected application domain may affect equilibrium point microarchitecture instruction set 
isa designs set benchmark programs believed representative expected application domain employed evaluate design microarchitecture instruction set 
shown 
example design example 
benchmark sets spec livermore loops prolog benchmark suite proposed evaluate computer isa 
designing instruction set processor features instruction set microarchitecture compiler backend chosen cost constraints 
design options tuned representative application benchmarks intended application environment 
currently designs instruction set processors carried manually 
balance various design options relies mainly designers experience skills 
manual design process slow requiring labor smart people iterations analysis redesign occur 
computer aided design cad tools necessary facilitate design process instruction set processors improve understanding interaction software hardware components 
branches cad tool development related instruction set processor design 
high level behavioral synthesis instruction set processors corresponds microarchitecture design phase 
approach accepts instruction set architecture specification generates microarchitecture implementation register transfer level rtl 
examples approach 
design space approach constrained instruction set specification 
hand design automation systems address instruction set design phase 
systems accept set application benchmarks microarchitecture instruction format constraints produce best instruction set objective function 
microarchitecture yield best instruction set left designer microarchitecture 
kinds tools iterative approach design instruction set processors 
major limitations iterative approach 
tools designed interaction mind ineffective interfaces may iterations difficult 
second iterative approaches may computationally inefficient 
limitations raise research question best combination instruction set microarchitecture derived application benchmarks objective function 
application benchmarks intermediate form ir similar intermediate code generated compiler front ends 
objective function specifies designer desires trade competing features hardware resources cycle count static code size instruction set size 
thesis relationship application benchmark microarchitecture application benchmark viewed specification computing task performed target machine 
microarchitectural level application benchmark performed executing sequence instructions 
instruction con sists group micro operations 
micro operations instruction sequence represent scheduled instance dependency graphs micro operations 
micro operations manipulate state processor 
internal representation benchmark microarchitecture viewed sequence processor state changes 
process mapping instruction sequence state change sequence viewed compilation execution process shown 
reverse compilation process viewed instruction formation predefined hardware resource shown 
pair state change set dependency graphs micro operations accomplishes state change 
second micro operations mapped time machine code instructions micro operations benchmark move 
move 
move 
push 
adda 
opa opa opc opd opc opa opc opa opd opc inst inst inst inst benchmark assembly benchmark micro ops benchmark compilation benchmark assembly ii benchmark micro ops instruction set design benchmark machine states minimal set micro ops 

steps 
micro operations mapped time step considered instruction 
collection time steps assembly code 
instruction set design instruction formation constrained scheduling problem micro operations 
constraints predefined hardware resource dependency graph size step schedule representing instruction word length 
optimization performed competing factors including number steps schedule cycle count number unique steps schedule size instruction set 
problem generalized allowing hardware resources varied 
simultaneous instruction set microarchitecture design described simultaneous scheduling allocation problem objective function controlling trade 
set primitive operations micro operations represent possible operations microarchitectures application benchmarks mapped dependency graphs primitive operations 
dependency graphs instruction set microarchitecture simultaneously derived combined scheduling allocation process 
modelling design problem scheduling allocation problem provide advantages techniques developed high level synthesis language compilers employed second known methods scheduling allocation help understanding exploiting design instruction set processors 
research scope direction limitation design automation efforts dedicated instruction set processor design characterized categories 
detailed descriptions classification section page 
instruction set synthesis iss 
assuming model instruction sets approach generates instruction set optimizes objective function instruction set size cycle count cycle time transistor count models data path control path explicitly expressed design constraints embedded model instruction set 
instruction set mapping ism code generation cg approach addresses problem systematically mapping application assembly code instruction set 
approach usually involves design retargetable code generator mapper 
microarchitecture synthesis ms instruction set specification approach synthesizes microarchitecture register transfer level rtl usually including data path control path implements instruction set 
seen section problems interdependent ones 
goal research express problems integrated order understand principles govern interactions optimal solutions problems 
scheduling allocation problem formulation dissertation presents approach integrated problem architectural microarchitectural levels 
integrated design automation systems built address problems levels 
architectural level set application benchmarks pipeline structure asia automatic synthesis instruction set architecture design automation system generates instruction set allocates hardware resources best fit applications time maps applications assembly code synthesized instruction set 
phase addresses synergy instruction sets instruction set mapping hardware resources pipeline structure 
level microarchitectural level instruction set architecture specification synthesized asia approaches piper design automation system generates pipelined microarchitecture implements instruction set reordering table guides compiler backend reorderer 
approach addresses synergy pipeline structure code generation instruction set 
limitations dissertation summarized follows instruction set 
target instruction set assumed fixed word width designer 
furthermore bit widths instruction fields register index tag value immediate data designer 
current research attempt determine optimal widths fields important problems instruction set architecture design 
microarchitecture 
ideally desirable best combination instruction set pipeline structure allocation hardware resources determined time 
order manage complexity problems problems solved keeping fixed optimizing 
asia approach combination instruction set resource allocation code generation determined system pipeline stages designer 
hand piper approach pipeline structure resource allocation determined system semantics instruction set designer allowing system change timing property instruction set 
asia piper iterative fashion determine best combination instruction set pipeline structure resource allocation 
code generation 
asia synthesizes best instruction set application programs 
assembly code application programs automatically generated optimization process 
decides map application programs applied synthesize instruction set synthesized instruction set techniques code generation asia 
hand piper map application programs pipelined microarchitecture synthesizes 
generates interface reordering table direct compiler backend reorderer reordering sequence assembly code preserve sequential semantics code 
concerns 
dissertation automatically generate instructions hardware mechanisms operating system support interrupt trap handling control explicitly specified part application programs instruction set behavior 
handled including set synthetic benchmark programs contain operations 
research contributions dissertation provides integrated problem formulations combined problems instruction set design microarchitecture design code generation 
integrated formulations help better understanding design processes interactions 
formulation efficient algorithms developed design automation system practical synthesizing designs exploring design tradeoffs competing factors hardware software 
architectural level asia fast prototyping tool determine feasible initial designs new instruction set architecture design tool evaluation existing instruction set architectures application specific environment 
case studies asia applications section page section page section page 
piper generate register transfer level rtl implementation architecture synthesized asia providing accurate performance cost measures fed back asia guide design process 
addition piper explore tradeoffs microarchitecture complexity compiler backend 
furthermore extend service life improve performance existing instruction set architecture simultaneously reimplementing hardware pipeline structures generating interface patch original software environment take advantage pipelined microarchitecture 
examples piper applications section page including synthesis industrial processor 
dissertation outline dissertation organized follows 
chapter presents design problem motivation 
chapter reviews related automatic instruction set design code generation high level synthesis compares research dissertation related 
chapter describes global design flow asia piper 
describes framework advanced design automation system adas full range design automation system microprocessors asia piper integrated 
chapter presents models instruction sets microarchitectures compiler backends dissertation 
chapter presents problem formulation algorithm architectural problems addressed asia instruction set design resource allocation 
chapter presents extended taxonomy inter instruction dependency hardware software resolutions 
serve key techniques piper simultaneously synthesize pipelined microarchitectures interfaces compiler backends explore tradeoffs 
chapter presents algorithms taxonomy resolutions discussed chapter synthesize pipelined microarchitectures compiler backend interfaces 
chapter demonstrates techniques dissertation set experiments 
chapter draws points limitations dissertation suggests research directions 
lists dissertation 
brief descriptions exemplar input specifications programs design phase asia piper available anonymous ftp host usc edu directory pub software asp 
please read readme file directory information 
chapter background chapter research automating design instruction set processors reviewed 
discussion design objects metrics common interest architectural microarchitectural levels classify design automation instruction set processors particular design objects interested follow review related category 
design objects metrics architectural microarchitectural levels design objects hardware software components designers want produce control design process including input specifications constraints output implementation design metrics 
important design objects architectural micro architectural level discussed 
hardware architecture model specifies architectural style processor application specific integrated circuits asic digital signal processor dsp applicationspecific instruction set processor asip general purpose instruction set processor isp implementation style usually specified model constrain design space uniprocessor long instruction word processor vliw pipeline superscalar multiprocessor implementations 
data path data part microarchitecture implements architecture model 
data path consisting registers latches functional units interconnects memory provides mechanisms manipulate data 
basic design tasks data path include allocation resources assignment operations resources construction interconnects 
control path control part microarchitecture 
control path controls sequence operations data path obtain desired output 
basic design tasks control path include selection control styles finite state machine counter allocation control registers store control information generation symbolic boolean equations glue logic 
chip area cycle count clock cycle time power dissipation attributes particular data control path implementation 
serve design metrics measure quality implementation guide design tradeoffs 
design metrics usually obtained modeling cycle count obtained directly compilation simulation execution 
addition design metrics architectural microarchitectural levels represented symbolic values exact values low level implementation decisions 
example chip area usually represented number transistors logic gates power dissipation usually represented switching activities circuit 

cycle count number clock cycles taken execute application 
interface instruction semantics refers behavior instruction including mops contained instruction operational relation chaining parallel sharing operands timing relation 
instruction semantics feasible depends characteristics application architectural model data control path 
rich instruction semantics may require complex architectural model data control path support 
instruction format refers instruction word partitioned fields 
availability instruction format determines proposed instruction semantics supported complexity data path 
instruction set multiple instruction formats requires different ways interpreting bits instruction register ir 
bit ir may belong different fields different instructions 
bit wise manipulation instruction bus proper interconnects may necessary support multiple instruction formats 
instruction set size number valid instructions supported processor 
size impact control path effectiveness compiling applications assembly code 
increase instruction set size may effects control logic grows applications effectively compiled assembly code possibly powerful instructions available optimization computational burden compiler increases consider instructions 
software applications software programs selected represent typical computation tasks executed processor 
design processor usually customized application especially application specific environ ment embedded systems 
applications may high level languages fortran lisp prolog intermediate code code commonly compilers intermediate representations data control flow graph dependency graphs mops register transfers rtls 
assembly code representation application instruction set level 
binary version assembly code machine code lowest representation application processor fetches memory decodes executes 
code generator usually component compiler backend takes account detailed architectural features processor 
code generator maps machine independent intermediate code assembly code instruction set target processor 
code generators machine dependent processors instruction sets different 
processors supporting instruction set different implementation technologies various versions code generators deal instructions different performance cost due variation implementations 
order save development efforts code generator retargetable dividing generator parts machine independent mapping algorithm machine dependent mapping table specifies intermediate code mapped sequence target instructions 
construct efficient mapping table part design task designing architectures 
peephole optimizer component compiler backend takes care microarchitecture feature processor 
takes assembly code generated code generator searches patterns instruction sequences replaces instruction sequences better quality addition optimization repairing assembly code satisfy particular features tecture processor branch memory operation delays performed peephole optimizer 
similar code generator peephole optimizer machine dependent 
usually divided parts machine independent optimization algorithm machine dependent pattern pairs 
construct pattern pairs high quality part design challenges designing microarchitecture 
instruction simulators necessary measure cycle count benchmark programs executing target processor 
usually levels instruction simulators architecture level assumption sequential execution microarchitecture level instruction level parallelism pipelining exploited 
architectural level simulator measures performance terms number instructions executed 
microarchitectural level simulator measures performance terms number clock cycles executed 
equal summation number instructions executed number nop instructions executed number pipeline stall cycles due branch memory operation delays cache simulators machine dependent constructed processor designed 
classification design automation instruction set processors design instruction set processor complex task subtasks including designs hardware processors software compiler backends interface instruction sets 
design automation approaches instruction set processor design characterized categories instruction set synthesis code genera 
better quality refers measurements shorter instruction sequences fewer registers fewer memory operations fewer useless operations actual selection measurements objective optimization user 
tion high level synthesis 
difference approaches described terms design objects metrics described section 
table page lists design objects metrics relationships category design automation approach 
design object metric indicates major input specification constraint corresponding design automation approach indicates major output indicate respectively input output secondary concern indirect cause consequence corresponding approach 
unmarked cell indicates design object metrics irrelevant corresponding approach 
instruction set synthesis iss assuming model instruction sets approach generates instruction set optimizes objective function consists concrete design metrics instruction set size cycle count cycle time transistor count power dissipation 
models data path control path explicitly expressed design constraints embedded model instruction set 
instruction set mapping ism code generation cg approach addresses problem systematically mapping application assembly code instruction set 
approach usually involves design objects metrics instruction set synthesis iss code generation cg microarchitecture synthesis ms hardware architectural model dsp asip general purpose isp major input iss dsp asip general purpose isp major input cg dsp asip general purpose isp major input ms control path determined size semantics instruction set 
major output ms includes boolean equations control logic state registers interfaces data path data path architected registers functional units memory ports ports data path topology architected registers functional units memory ports ports data path topology major output ms net lists registers functional units interconnect components interfaces control path chip area mainly affected control path data path fixed iss ignores issue models measure 
major objective ms minimizes takes design constraints cycle count depends instruction set match benchmark major objective cg minimizes major objective ms minimizes takes design constraints cycle time difficult estimate measured iss major objective ms minimizes takes design constraints power dissipation depends instruction set scheduling iss consider power issue 
depends sequence instructions types computation sequence major objective ms minimizes takes design constraints interface instruction semantics iss determines behavior instructions major input cg part instruction set architecture specification behavior instructions instruction format iss determines usage instruction bits major input cg part instruction set architecture specification usage instruction bits instruction set size iss determines number instructions major input cg part instruction set architecture specification number supported instructions table categories design automation instruction set processors design objects metrics 
approaches span category dissertation listed table 
design retargetable code generator code mapper peephole optimizer post optimizer 
notations primary input specification constraint design automation system secondary input specification constraint design automation system primary output design automation system secondary output side effect primary output design automation system dsp digital signal processor asip application specific instruction set processor isp general purpose instruction set processor software application way measure effectiveness instruction set cg takes input intermediate representation application programs assembly code cg generates ouput assembly code target processor application ms estimate cycle count executing application synthesized processor code generator cgr depends instruction set iss generate cgr 
cg may generate assembly code directly indirectly generating retargetable cgr po 
peephole optimizer po depends instruction set iss generate po 
cg may generate assembly code directly indirectly generating retargetable cgr po 
ms pursues instruction level parallelism ilp means pipelining superscalar retargetable po necessary optimize code maintain intended sequential semantics take advantages ilp 
instruction simulator depends instruction set iss generate 
rtl level necessary simulate execution assembly code synthesized processor 
design objects metrics instruction set synthesis iss code generation cg microarchitecture synthesis ms table categories design automation instruction set processors design objects metrics 
approaches span category dissertation listed table 
microarchitecture synthesis ms instruction set specification microarchitecture synthesis approach synthesizes microarchitecture register transfer level rtl usually including data path control path implements instruction set 
automatic instruction set design early automatic instruction set designs view design problem design process independent hardware implementation 
instructions restricted single cycle instructions multi cycle instructions supported micro programming firmware 
knowing decode control complexity focus mainly directly supporting high level languages increasing code density 
results cisc instructions 
studies include bose bennett 
techniques suitable designing instruction sets modern pipelined processors 
sato proposed integrated design framework application specific instruction set processors 
framework generates profiling information set application benchmarks expected data 
profiles design system customizes instruction set super set supported gcc compiler decides hardware architecture derived gcc machine model 
approach targets gcc environment advantage having software development tools handy instruction simulator 
instruction set synthesis tools disadvantages lack instruction simulators instruction sets generate 
instruction design space sato approach limited priori gcc instruction set 
framework similar terms inputs outputs design system different terms machine model design method 
assume sequential non pipelined machine model assume pipelined machine data stationary control model 
hand sato generate instruction sets customizing super set synthesize instruction sets directly order find new useful instructions application domain 
previous approaches holmer focused generating instruction sets closely couple underlying micro architecture 
pipelined micro architecture proved superiority holmer adopted modern pipeline control model data stationary control simple parameterized data path underlying microarchitecture model 
parameters data path include number read write register ports memory ports number functional units cycle counts memory operation 
user specifies parameters invokes system find set instructions best utilizes hardware resources minimal cycle counts benchmarks achieved 
builds results holmer improving problem formulation synthesis algorithms 
possible conduct experiments larger applications 
microarchitecture synthesis microarchitecture synthesis approaches design problem different direction 
basic task high level synthesis pipelined instruction set processors construct pipelined micro architectures rtl level behavioral sequential specification instruction set architecture synthesized 
assumed machine synthesized repeatedly executes computation task 
pipeline hazard problem pipeline synthesis instruction set processors instruction set processors computation task operations fetch decode execution instructions 
computation task represented loop body specification repetition represented iteration loop body 
shows state transition diagram instruction isp ovals states state clock cycle thin arcs state transitions outer feedback arc represents iteration body 
simplicity show register accesses pc states 
dotted bi directional arcs inter iteration dependencies inter instruction dependencies registers pc respectively 

inter instruction dependencies instruction set processors appear inter iteration dependencies behavioral specification 
pipeline synthesis inter iteration dependencies pc decode pc brn store load minimal achievable latency mal 
notation read write simultaneously read write pc decode pc brn store load iteration pc decode pc brn store load iteration 
task pipeline synthesis find appropriate overlapping multiple iterations loop body subject inter iteration dependencies 
shown longest inter iteration dependency spans cycles pc dependency optimal degree overlapping causing pipeline hazards issue iteration cycles shown 
length longest inter iteration dependency called minimal achievable latency mal pipeline synthesis systems lower bound instruction initiation latency 
synthesis approaches instruction set processors pursuit high performance digital circuit designs high level synthesis systems focus automating design pipeline structures 
pipeline scheduling algorithms developed 
algorithms differ application scope achieved performance 
uses algorithms feasible scheduling maximal scheduling 
hal applies modified force directed scheduling algorithm achieve better quality pipeline scheduling allocation cost higher complexity 
systems applications exhibit loop carried dependencies 
pls cathedral ii capable working applications lcd means iterative folding algorithm loop folding algorithm respectively 
systems adopt iterative approach find mal 
mal serves upper bound performance synthesized designs 
major application domain synthesis systems digital signal processors dsp 
system architect workbench saw synthesizes un pipelined pipelined processors 
possible biases designer coding style instruction set specification eliminated set transformation rules selected user 
optimized specification fed architectural partitioning phase determine feasible hardware allocation 
control step scheduling phase invoked assign operations control steps 
system architect workbench consists synthesis methodologies tuned specifically microprocessor designs supports general design style 
approach pipelined designs derived interactively performing transformations system level 
attempt solve pipeline hazards automatically 
techniques available try minimize mal rearranging micro operations order increase degree overlapping 
limitation techniques subject constraint mal 
pipelined instruction set processors instruction initiation latencies mal impossible 
example mips mal 
synthesized techniques instruction initiation latency manually designed 
concluded techniques suitable synthesis pipelined instruction set processors 
uses vliw architecture hardware template applies percolation scheduling pipeline scheduling explore fine grain parallelism 
system performs design task phases specification optimization implementation optimization 
phase scheduling algorithms generate application micro code 
vliw template customized second phase 
capable synthesizing pipelined instruction set processors instruction initiation latency regardless 
resolve induced pipeline hazards synthesized machine flushes pipeline long instruction may cause hazards decoded 
take mips example synthesized pipeline flush soon delayed load branch 
delay load refers load instruction data loaded ready instruction pipeline 
jump decoded regardless succeeding instructions dependent instructions 
approach leaves room compilers utilize flushed idle cycles 
addition practicality limited difficulties microcode explosion complexity pattern merging 
code generation problem code generation handled differently researchers compiler community digital signal processing dsp community 
discussed subsections 
automatic generation compiler backends compiler writers view code generation step process code generators optimizers constructed second code generators optimizers compile applications assembly code 
code generators optimizers retargetable compiler writers usually adopt modular approaches separate machinedependent information machine independent code generating optimizing algorithms described section page 
machine dependent information usually kept tabular formats 
machine dependent information derived machine description 
cattell graham works focus generation code generators giegerich derivation machine specific optimizers 
derive machine dependent tables instruction set semantics describes instruction formats addressing modes operations 
micro architectural features pipeline configuration considered systems 
piper different works focuses construction back compiler phases related micro architecture 
currently focus restricted generating instruction set processors various pipeline configurations 
code generation dsp applications designers usually find compilers provided vendors digital signal processors able produce high performance code 
reason dsps usually exhibit irregular data paths multiple small size register files special registers multi port memory multiple pipelined functional units chaining functional units 
conventional retargetable code generators optimizers perform irregular data paths 
techniques high level synthesis scheduling allocation attractive alternatives code generation dsp cases 
combined approaches need closely examine problems ms iss ism instruction set processors noted researchers 
common way solve problems current tools iterative approaches 
shirai approach application translated intermediate representation simulated 
operation frequencies graph structure patterns reported designer selects desired patterns 
selected patterns define instruction set data path 
availability pattern may affected selected patterns 
due lack sure interactions handled approach 
holmer propose iteration instruction set design tool high level synthesis tool sands 
initial data path model timing parameters generates initial instruction set model 
generated instruction set specification taken sands synthesizes detailed data path control path considering pipelining 
hardware details obtained data path model updated design process repeats design objective satisfied 
uses similar iterative scheme interaction performed designer finer level 
approach intended dsp processors data path 
application analyzed types operations frequent common patterns 
initial data path constructed selecting modules cell library analysis results 
application mapped data path 
statistics mapped application collected 
tool called bundling invoked find possible chaining patterns application suggest interconnection patterns data path 
interconnection patterns define instructions 
tool analyse collect usage patterns data path modules 
information data path modules added deleted 
decisions new interconnection patterns may established 
new data path application mapped design process repeats design objective satisfied 
cast problem different flavor 
harvard architecture hardware model 
super set instructions generated gnu compiler defined candidate set 
set instructions divided subsets primary rtl basic rtl extended rtl 
directly supported data path 
complex ones implemented specialized hardware 
design problem expressed selecting best implementation methods performance cost optimized application 
formal definition problem branch bound solver 
related approach synthesizes instructions application customizing super set 
approach different related looking single formulation combined problem instruction set design microarchitecture design code generation iterative approach 
comparison asia piper related asia piper compared treat design objects metrics discussed section 
result summarized table page 
table related grouped categories section section 
notations table page 
marks indicate corresponding design objects metrics irrelevant cases 
comparison shows asia input output specification related combined approaches section 
difference way interaction microarchitecture design instruction set design handled asia uses automatic integrated scheme related combined approaches manually controlled iterative schemes 
hand piper similar related microarchitecture synthesis 
uniqueness piper interface reordering table compiler backend peephole optimizer reorderer generated pipeline synthesis process 
table shows design objects metrics receive little attention related approaches 
observation suggests directions 
estimating cycle time architectural microarchitectural levels difficult task due lack detailed information determined design tools lower levels 
estimation minimization power dissipation important designing portable systems 
investigation necessary incorporate power issue synthesis 
missing link construction compiler backend code generator peephole optimizer 
new instruction set processor little compiler backend 
piper generates reordering table reorderer part optimizer done pattern generation peephole optimization code generation 
construction effective code generator peephole optimizer tedious nontrivial task 
automatic generation retargetable code generators peephole optimizers desired 
similarly automatic generation instruction level simulators microarchitectural level simulators desired 

compiler frontend including lexical analysis syntax analysis semantic analysis intermediate code generation machine independent 

notations design object metrics irrelevant cases 
primary input specification constraint design automation system secondary input specification constraint design automation system primary output design automation system secondary output side effect primary output design automation system design objects metrics instruction set synthesis code generation architecture synthesis combined approaches bose bennett peas holmer cattell graham giegerich hal pls peas asia piper hardware architectural model control path data path chip area cycle count cycle time power dissipation interface instruction semantics instruction format instruction set size software application assembly code code generator peephole optimizer instruction simulator table comparison asia piper related chapter design framework section describes framework advanced design automation system adas full range design automation system microprocessor design 
asia piper part adas system 
piper serves microarchitectural behavioral domain adas takes instruction set architecture specification input generates reordering table interface compiler backend pipelined microarchitecture register transfer level rtl including data control paths 
asia top piper extends capability adas architectural level 
asia reads application benchmark programs synthesizes application specific instruction set fed piper input estimates number hardware resources allocated microarchitecture 
description adas inputs outputs major design phases performance cost estimation asia piper summarized section section respectively 
adas design automation system design levels adas adas accepts set application benchmarks architectural template input produces output vlsi layout pipelined instruction set processor 
addition adas generates application specific instruction set assembly code application benchmarks reordering table serves interface compiler backend reorderer 
new adas extension original adas improvement asp design automation system 
adas spans levels design abstraction architectural microarchitectural behavioral logic circuit physical geometric domains 
shows hierarchy new adas corresponding design tools 
dashed line shows design entry point original adas 
architectural domain asia produces application specific instruction set estimates number needed resources architectural template new advanced design automation system adas application specification functional specification circuit specification physical specification application benchmark architectural template scheduling transistor sizing vlsi layout generation piper architectural domain logic circuit domain physical domain geometric control path allocation pipeline synthesis data path synthesis layout generation behavioral specification architectural behavioral domain asia instruction set design resource estimation instruction set architecture specification prolog application benchmarks represent typical run time environment processor designed 
synthesized instruction sets architectural template allocated hardware resources annotated finite state machine passed tool piper microarchitectural domain piper takes finite state machine transforms pipelined machine 
data path control path pipelined microarchitecture generated rtl level 
data path described net list data path modules 
control path described net list control registers glue logic symbolic boolean equations control plas programmable logic arrays 
addition piper generates reordering table containing set reordering constraints instruct reorderer compiler backend properly reorder sequence instruction stream avoid pipeline hazards 
logic circuit domain translates data path description symbolic layout 
major tasks include cell allocation cell placement routing 
performs logic minimization state assignment control path specification creates symbolic layout 
performs transistor sizing symbolic layouts data path control path enhance circuit performance 
utilizes control information generated piper avoid false paths searching critical paths circuit 
geometric domain translates symbolic layout mask geometries cif format 
major tasks include compaction placement routing 
pad frame created automatically 

microarchitectural domain tool original adas new adas 
takes input instruction set architecture specification prolog transforms finite state machine scheduling allocation processes 
output fed piper pipeline synthesis 
adas simulation pass runs parallel synthesis pass 
set application benchmarks provided simulation major design domains verify correctness performance design 
architectural domain benchmarks simulated instruction level obtain frequencies individual instructions consecutive instruction pairs 
frequencies piper estimate pipeline stalls due pipeline hazards trade hardware software methods resolving pipeline hazards microarchitecture 
microarchitectural domain simulation event driven finite state machine model 
clock ticks interrupts represent events 
values registers compared obtained architectural level cycle cycle verify design correctness 
lower domains simulation tools produce traces machine state synthesized processor circuit level 
machine code translated application benchmarks test vector simulation 
produced traces compared produced higher levels ensure design correctness 
spice estimate cycle time synthesized processor 
design philosophy traditional cad tools adas adopts integrated hierarchical approach design microprocessors spans levels architectural vlsi mask level 
set tools carefully designed implemented 
traditional cad tools developed independently 
individual tool powerful applicable broad range design styles difficult integrate tools accomplish design tasks span levels 
major difficulty lack appropriate interface languages global understanding related tools functionality 
smoothly integrated 
design tasks carefully defined partitioned various tools interface languages tools defined 
page illustrates conceptual structure adas 
adas design task viewed sequence design transformations 
design stage design specification constraints successively transformed equivalent detailed representation design generator 
design generator controlled design rules 
design rules include heuristics modeling 
design paradigm design rules design generators separated roles design process design generators generate correct designs independent design rules optimize possible correct designs 
designs conceptual structure adas benchmark program generator design performance measure translator rule specification benchmark program performance measure specification simulator evaluator design constraints design level level simulation synthesis improved tuning design rules 
experience previous designs adjust design rules 
addition design specification information higher levels carried lower levels aid design process appropriate 
example register transfer patterns generated piper microarchitectural domain circuit domain eliminate false paths looking possible critical paths circuit 
application benchmarks provided verify design correctness performance estimation 
level simulator benchmarks translator map benchmarks level detail 
addition simulation results fed back higher levels improve design rules 
instruction set design resource allocation asia depicts structure asia 
input output design flow performance cost estimation asia summarized section 
details design models problem formulation algorithm chapter chapter respectively 
input output asia input consists application benchmarks objective function pipelined machine model 
application benchmarks represented terms micro operations carry semantic information programs 
micro operations necessarily target machine 
micro operations derived architectures long architectures register configuration target machine 
objective function user function cycle count representing run time benchmarks static code size instruction set size hardware cost 
pipelined machine model allows specification pipeline stage configuration data path connection patterns 
outputs consist instruction set hardware resources optimize objective function compiled code shows benchmarks optimally compiled generated instruction set 
models instruction set architectural template application benchmarks chapter 
design process asia design consists phases 

transform benchmarks sequences machine state transition asia system benchmarks objective function machine model micro architecture instruction set compiled codes state pair generation computation graph construction instruction set arch synthesis input output design phase basic block benchmarks transformed pair machine state transition 
machine state defined state architected general special register memory 
representing benchmarks sequences machine state transition able filter possible inefficiency embedded original micro operations describe benchmarks 
approach introduces new view benchmarks sequences machine states sequences specific micro operations may unnecessarily constrain design space 
shows basic block corresponding initial final states 
note readability basic block annotated sequence instructions micro operations 

generate computation graphs state pairs 
computation graphs data control flow graphs cdfg nodes micro operations machine model 
state pair graph generated searching minimal number micro operations move initial state final state 
shows computation graph state pair 
machine model asia accepts parameterized pipelined micro architecture 
model allows explore different combinations hardware features connections data path components cascades pipeline stages various computation graphs generated state transitions giving different micro architecture models second phase asia 
depicts variations micro architectures 
approach frees tied micro architecture original micro operations benchmarks derived 
able target wide range micro architectures 

synthesize instruction set micro architecture computation graphs 
machine state example environment registers heap move tv push move tv initial state benchmark tv tv tv tv final state parameterized micro architecture model data path pipeline control model control path instruction fetch id instruction decode register read arithmetic memory access register write logic operation instruction execution data path model control path model register file fu fu memory special registers bus interconnect functional unit pre defined storages designer specifies bit widths various instruction fields instruction word 
instructions formed packing micro operations computation graphs subject constraints data control dependencies instruction word width 
constructing instructions instruction fields instantiated values implicit 
example instruction increment derived general form add 
opcode implies source destination register immediate data constant 
micro architecture generated specifying appropriate numbers register read write ports alu memory ports 
computation graph example variations data paths pipeline stages register file register file alu alu alu id ex wb id ex ex wb variation variation ii data path pipeline stages data path pipeline stages problem concurrently synthesizing instruction sets micro architectures formally stated opposed empirically ad hoc stated previous approaches 
problem mapped problem simultaneous scheduling allocation studied extensively area behavioral synthesis 
idea illustrated 
nodes computation graph objects scheduled 
node consumes certain hardware resources instruction fields 
scheduled control step represents instruction 
objective schedule nodes number control steps cycles resources optimized constraints instruction word width number distinct control step patterns instruction set size satisfied 
approach problem instruction field encoding addressed 
providing clearer insight design problem formalization allows efficient exploration design space 
shows possible designs instruction sets micro architectures design ii computation graph 
design instructions store remember add compile graph cycles 
hardware resources needed design register file read port register file mapping design problem instruction sets micro architectures simultaneous scheduling allocation problem micro arch 
micro arch 
write port memory port alu 
design ii instruction add double store compiles graph cycle 
design better performance design cost hardware resources 
example illustrates possible designs different performance cost tradeoffs application benchmark 
objective function required balance tradeoff performance cost 
techniques step idea state pairs described holmer discussed dissertation 
interested readers may refer dissertation information 
techniques step major focus chapter chapter 
possible designs instruction sets micro architectures design design ii computation graph cdfg page design hardware configuration design ii hardware configuration number register read ports number register write ports number memory ports number functional units 
operator concatenates tag data saved register memory 
cycle name semantics store remember store remember add cycle name semantics add double store performance cost estimation asia cost synthesized instruction set determined size instruction set numbers register file read write ports memory ports functional units 
global cost calculated metrics 
function designer 
performance synthesized instruction set measured terms execution time application benchmarks 
execution time product cycle count cycle time 
cycle count number clock cycles taken execute application benchmarks reflects instruction set matches characteristics application benchmarks 
cycle time length clock determined complexity control path size topology data path 
difficult estimate cycle time architectural microarchitectural level 
common approach lookup table keeps records known cycle times existing microarchitectures 
cycle times new microarchitectures derived lookup table heuristics 
addition lookup table refined detailed information fed back lower design domains 
objective function designer control tradeoff performance cost 
objective function arbitrary function metrics fore mentioned 
example objective function section page 
objective function may inaccurately encapsulate designer idea 
solve problem asia output run piper lower domains adas obtain implementation details 
information fed back modified asia objective function generate instruction set resource allocation 
example suppose original objective function ln function controls tradeoff cycle count instruction set size designer tries indirectly model cost control path 
final control path synthesized lower domains adas twice expected size indicating cost control path underestimated factor original objective function 
objective function adjusted ln ln 
number variables objective function increases iterations carefully controlled experiments necessary order refine objective function 
synthesis microarchitectures compiler backend interfaces input output piper input inputs piper consist finite state machine specification benchmark statistics set selected design options 
finite state machine specification represents sequential register transfer implementation instruction set architecture 
specification consists finite state graph description architected registers 
finite state graph state consists set concurrent register transfers 
register transfers describe data movements architected registers 
data movements may pass functional units perform computation 
register transfers specify interconnect data goes functional units allocated computation assigned functional units 
design tasks completed piper 
state transition caused clock 
state may possible states 
case selection state controlled internal status instruction set architecture true false signal overflow underflow signals opcode decoding description architected registers specifies names registers visible instruction set register widths definition fields registers allow field wise access textual specification finite state graph instruction add load store brn processor sm 
states declared prolog predicates state 
state predicate specifies state argument identifier state second argument list concurrent register transfers occurred state third argument specifies state 
example state bc register gets original value program counter pc value incremented time 
clock state goes bc 
note state multiple states case state bc decode state processor 
possible states bc bc bc bc values opcode field register add store load brn respectively 
switch structure specify selection states 
argument switch statement specifies target selection 
second argument list cases corresponding states 
predicates specify architected registers sm processor 
element predicates declare architected registers 
argument specifies type register second argument specifies name register 
example ac register type reg typical master register pc register type increment master register 
third 
field wise access register refers capability accessing content register bit level 
group bits defined field accessed group referring field 
bc bc bc bc bc bc bc bc load store add brn state bc enable pc move pc bus enable load bc 
state bc enable mem mem read bc 
state bc switch field opcode case add bc case store bc case load bc case brn bc 
state bc move constant binary bus move field bus enable load bc 
state bc enable mem mem read bc 
state bc move ac bus port fu fu move bus port fu fu move constant port fu fu bus port fu fu enable fu fu add move fu fu bus ac enable ac load bc 
state bc move ac bus enable load move constant binary bus move field bus enable load bc 
state bc enable mem mem write bc 
state bc move constant binary bus move field bus enable load bc 
state bc enable mem mem read bc 
state bc move bus ac enable ac load bc 
state bc move ac bus port fu fu move constant port fu fu bus port fu fu enable fu fu switch fu fu case false bc case true bc 
state bc move constant binary pc bus pc move field bus pc enable pc load bc 

specification finite state graph element reg ac 
element reg 
element reg 
element pc 
ac 


pc 

opcode 

specification architected registers 
graphical view bc bc bc bc bc finite state machine specification instruction processor sm ac fifth arguments 
predicates specify bitwidth registers 
registers sm bit wide 
specifies fields register 
sm fields defined register opcode bit positions respectively 
shows graphical view finite state graph 
states bc bc bc represent instruction fetch decode cycles 
branches bc represent execution instructions respectively 
branch instruction brn way branch state bc checks condition ac bc fetch cycles instruction 
shows example frequencies consecutive instruction pairs obtained simulation trace benchmark 
information piper estimate run time performance synthesized pipelined microarchitecture conduct hardware software trade 
table lists available global synthesis options 
instruction firing period number cycles firing consecutive instructions 
maximally pipelined processor instruction firing period cycle 
hand processor fixed instruction firing period equal longest instruction execution latency variable instruction firing period fires instruction pair frequencies instruction pattern count load add 
instruction pattern count store add 
instruction pattern count brn load 
instruction pattern count add store 
instruction pattern count brn store 
instruction soon current instruction finishes execution 
sequencer refers sequencing style controller 
available choices include counters finite state machines 
depending characteristics instruction set architecture specification style advantages disadvantages 
designer perform trial experiments determine best style instruction set architecture 
state assignment instructs piper perform simple state assignment states symbols generate interface invoke berkeley finite state machine compiler meg perform assignment 
connection selects bus style combination multiplexors point point style multiplexors exclusively connecting data path modules 
output output piper consists hardware software components 
hardware data path control path generated 
data path net list data path modules including functional units architected registers internal registers memory ports ports pads multiplexors 
control path consists boolean equations control signals pipeline stage glue logics control signals different pipeline stages data control path interface 
software piper generates reordering table serves interface reorderer compiler backend 
reordering table contains list reordering constraints dependent instruction pairs may pipeline hazards option range instruction firing period integer longest instruction execution latency sequencer counter fsm state assignment assigned tool meg connection bus point point table piper synthesis options instructions specified pair executed pipeline stages simultaneously 
reordering constraint specifies number instructions nop operation instructions inserted instruction pair 
instructions nop inserted order maintain sufficient distance reorder distance pair avoid pipeline hazards 
table lists example reordering table stage pipeline implementation sm processor 
example data row dependent load brn pair reorder distance 
design process piper piper maps finite state machine representation instruction set architecture isa pipelined register transfer level design consisting data path control path 
piper generates interface compiler back reorderer measures time space complexities 
benchmark characteristics measured evaluate quality designs 
illustrates conceptual structure piper system 
piper takes input finite state machine specification performs tasks pipeline assignment pipeline hazard resolution resource allocation 
phase pipeline assignment assigns micro operations pipeline stages 
pipeline hazards may introduced pipeline assignment highly pipe 
dependent pair refers pair instructions succeeding depending results preceding 
preceding instruction succeeding instruction reorder distance number instructions inserted load brn add brn brn instructions table reordering table stage sm processor lined cases 
hazards resolved second phase combination hardware software resolution strategies 
accomplished conceptual steps analysis inter instruction dependencies application resolution strategies 
phase piper generates reordering table consisting reordering constraints instruct compiler back reorderer properly organize codes pipelined machine synthesized 
phase hardware resources allocated producing pipelined rtl level design 
design decisions pipeline scheduling hazard resolution affect performance cost hardware time space complexities compiler back 
addition design engine set estimators application benchmarks estimation effects 
techniques third phases similar pipeline synthesis systems focus dissertation 
distinguish piper systems second phase chapter chapter chapter 
structure piper system fsm spec 
isa piper design engine piper performance cost analysis reorder table data path control path interface compiler back sim benchmark trace analysis benchmarks pipeline assignment hazard resolution resource allocation performance cost estimation piper section overview performance cost estimation 
detailed discussion section 
cost synthesized microarchitecture estimated number transistors 
data path control path estimated separately significant difference structures 
empirical function combine estimates chip cost 
routing area considered 
hardware cost software cost 
cost software time memory reorderer compile code synthesized pipelined processor 
time space complexity reorderer usually function characteristics reordering table number constraints maximal reorder distance 
different pipeline implementations results reordering tables different characteristics impose various degree difficulty reorderer 
cost reorderer obtained substituting characteristics reordering table time space complexity functions 
hardware software design environment hardware cost software cost combined construct global system cost 
designer specifies global system cost function function hardware cost software cost 
performance pipelined processor includes metrics maximal speedup average speedup application benchmarks 
maximal speedup static measure determined soon pipeline structure defined 
performance usually degraded maximal speedup due pipeline stalls executing real programs 
average speedup represents actual speedup considering run time pipeline stalls 
designer required provide piper analytical model estimating average case 
may happen cost performance functions fore mentioned accurate 
output piper fed lowers domains adas details 
detailed information adjust cost functions 
hand assembly code benchmarks reordered simulated obtain run time performance 
information adjust analytical model estimation average speedup 
chapter models hardware software interface modelling important way understanding describing complex systems 
models major design entities asia piper chapter 
model instruction sets section 
model microarchitectures section 
model application benchmarks section 
model interfaces compiler backend section 
instruction sets instruction contains parallel micro operations mops 
mops controlled instruction fields 
fields belong field types 
example instruction add immed consists opcode field add register index fields immediate data field immed 
width instruction word field types specified designer 
table lists specification instruction field types bit widths taken bam instruction set 
instruction opcode field fields constrained total number bits needed operations instruction 
instruction field type number bits instruction word opcode register tag displacement immediate relation operator op table bit width specification instruction field types lists instruction formats instructions add immed immed table 
note bits unused format operands instructions encoded part opcode 
ways encode operands 
specific value permanently assigned operand implicit opcode 
second register specifiers unified 
example instruction obtained general instruction add 
facts unifying register specifiers register accesses refer physical register immed fixing operand specific value implicit encoded opcode encoding operands saves instruction fields cost possibly larger instruction set size additional connections hardwired constants data path 
example adding instruction instruction set increases instruction set size adds hardwired constant additional multiplexer data path shown 
furthermore encoding allows mops packed single instruction 
example find happens values independent registers increased time may devise new instruction performs mops represents concurrency instruction uses bits opposed bits generalized form immed immed meet instruction word width constraint bit instructions 
examples instruction formats add immed unused microarchitectures design style micro architectures considered linear pipelined micro architecture 
basic pipeline shown functionally partitioned stages instruction fetch instruction decode id register read arithmetic logic operation memory access register write 
functional stage may take cycle pipelined 
stages identical instructions 
stages instruction execution stages dependent semantics instructions 
pipeline stages varied 
example pipeline id case derived merging register read stage instruction decode stage cost restricting instructions single format register specification registers pre fetched instruction decode stage 
hand pipeline id case derived merging arithmetic stage memory stage cost eliminating displacement addressing mode 
variation data path different instruction sets register file alu 
data path instructions add 
register file alu 
data path instruction add 
mux constant placements computed instructions proceed instructions 
pipeline controlled data stationary fashion 
data stationary control opcode flows pipeline synchronization data processed data path 
shows relationship control path data stationary model data path 
register files top bottom register file 
duplicated ease readability 
opcodes forwarded stage synchronously 
stage opcode basic pipeline variations instruction fetch id instruction decode register read arithmetic memory access register write logic operation instruction execution 
basic pipeline instruction fetch id instruction decode arithmetic memory access register write logic operation instruction 
variation register read execution instruction fetch id instruction decode register read arithmetic register write logic memory instruction variation ii operation execution ble status bits data path decoded generate control signals necessary drive data path 
pipeline configuration supports single cycle instructions typical modern risc style processors 
multiple cycle instructions accommodated modification linear pipeline insertion internal opcodes 
order manage complexity research general multiple cycle instructions considered moment 
multiple cycle arithmetic logic operations memory access change control flow branch jump call supported specifying delay cycles design parameters 

single cycle instruction instruction latency cycle 
data stationary control model pla status bits data path instruction opcode pipeline stage register file register file memory data path control path pla status bits data path pla status bits data path pla status bits data path specification target microarchitecture target microarchitecture fully described specifying supported mops set parameters 
supported mops describe functionality supported microarchitecture connectivity modules data path 
example columns table list mops supported vlsi bam microprocessor corresponding mop type ids 
pipeline configuration id derived eliminating mops rmd mrd table 
operator appends tag value value sent destination 
refer notation table 
notation read port register file write port register file memory port functional unit value number particular hardware resource 
example means read ports register file 
type id mop instruction format cost hardware cost rr rrai ri rit rm rmd immed mem mi mem mrd mem disp mem disp immed jd pc table mop specification 
note listed table mops conditionally executed 
set parameters describes resource allocation timing 
parameters include number register file read write ports number memory ports number functional units sizes register file memory latencies operations delay cycles operations memory access functional units control flow change 
table example resource parameters vlsi bam microprocessor 
resource parameters specified table include numbers sizes resources operation latencies 
table lists delay parameters various pairs operations 
example cycle delay memory operation succeeding dependent arithmetic operation specified pair 
resource type operation latency read port register file register read write port register file register write memory read write port memory access functional unit arithmetic logic register file size memory size table example parameters target microarchitectures resource size latency operation pair delay cycles operation pair delay cycles arithmetic arithmetic memory control arithmetic memory control arithmetic arithmetic control control memory memory arithmetic control control memory memory table example parameters target microarchitectures delay cycles note existence bypassing buses data path modeled delay parameters 
example remove bypassing bus stage delay cycles pairs zero 
mop supported data path assigned costs instruction format hardware resources 
costs instruction format instruction fields required operate mops including register index function selectors immediate data 
hardware costs resources required support mop 
hardware resources include read write ports register file memory ports functional units 
third fourth columns table lists costs corresponding mops 
application benchmarks application benchmark represented group weighted basic blocks 
weight defined designers usually indicate times basic block executed benchmark 
basic blocks mapped control data flow graphs mops mop specification 
different microarchitectures result different mop specifications may map basic blocks different 
shows example basic block consists mops mop specification table 
bold labels mops ids 
dashed arrows control dependencies mop mo changes control flow basic block mo logically follows mops mo 
solid arrows data related dependencies 
data related dependencies characterized categories read write raw write war write write 
specify relation preceding mop scheduled succeeding mop micro architec tures master latches implement registers 
case war dependency indicates relation preceding mop scheduled succeeding mop 
data dependencies wars 
interface compiler backend design compilers closely related design instruction set processors 
design compilers partitioned phases levels corresponding hardware design 
shows major levels instruction set processor design 
design instruction set processor usually starts defining machine model 
instruction set architecture defined realization machine 
step microarchitecture register transfer level constructed implement instruction set architecture 
microarchitecture expanded vlsi layout shown 
microarchitectural behavioral synthesis systems deal design problems microarchitecture level 
level analysis phase including lexical syntax semantic analyses related machines 
second phase generates intermediate code may perform optimization intermediate code 
intermediate code usually derived machine model control data flow graph cdfg mops simple basic mo mo mo mo mo mo pc pc intermediate code generation machine dependent 
third phase intermediate code expanded target machine code assuming instructions sequentially executed target machine 
microarchitecture independent optimizations may performed 
rules expanding intermediate code target machine code obtained semantics instruction set defined instruction set architecture defined 
phase compilation architecture dependent 
major compilation tool phase code generator performs intermediate code target machine code mapping 
phase compilation target machine code modified take advantage microarchitecture implementation satisfy constraints imposed 
pipelining superscalar considered phase 
phases hardware compiler design instruction set processors isa architecture dep 
micro architecture dep 
application programs high level language intermediate code 
code optimization intermediate code code generation 
code optimization sequential target code repair post optimization optimized target code machine architecture microarchitecture analysis high level language specification execution model machine data path model control model performance cost metrics rules translations instruction set architecture instruction set design scheduling allocation data control path construction high level synthesis micro architecture instruction set processor design 

implementation 
typical considerations phase insertion nop instruction reordering optimization techniques rely micro architecture implementation 
term phase microarchitecture dependent 
typical compilation tools phase reorderer peephole optimizer 
dissertation adopts concurrent engineering approach synthesis hardware compilation tools architectural microarchitectural levels 
hardware software components corresponding levels generated time 
assumed related compilation tools retargetable tool consists modules algorithm body machine independent machine information table machine dependent 
retargetability achieved constructing machine information table target machine 
assumption concurrent engineering approach simultaneously generates hardware components machine information tables corresponding levels 
due time constraint dissertation generates machine information table reordering table reorderer moment 
generation machine information tables compilation tools dealt 
reordering table consists reordering constraints instruction pairs 
constraint specifies far dependent instruction pair may cause pipeline hazards pipeline separated 
distance reorder distance maintained instruction pair measured number independent instructions nop instructions inserted pair 
table page reordering table stage pipeline implementation instruction processor sm shown page 
table repeated table easy 
row table reordering constraint 
second columns specify pre 
dependence includes data anti data output control dependency succeeding instructions dependent instruction pair respectively 
third column gives corresponding reorder distance 
note instruction column preceding succeeding instruction single instruction class instructions 
example reordering constraints table 
constraint specifies dependent instruction pair load brn load instruction followed dependent brn branch instruction reorder distance 
hand third constraint succeeding instruction instructions means brn instruction followed dependent instruction reorder distance 
constraint effectively brn instruction delay branch instruction delay slots 

instruction branch instruction depends value program counter generated branch instruction 
exist control dependencies destination instructions branch instruction 
preceding instruction succeeding instruction reorder distance number instructions inserted load brn add brn brn instructions table reordering table stage sm processor chapter synthesis instruction sets microarchitectures chapter presents problem formulation algorithms synthesis instruction sets microarchitectures 
instruction set design formulated modified scheduling problem section 
simulated annealing algorithm scheduling problem section 
problem formulation algorithm extended cover simultaneous synthesis instruction sets allocation hardware resources microarchitectures section 
materials discussed chapter correspond third synthesis phase design process described section page 
instruction set design modified scheduling problem instruction set design problem formulated modified scheduling problem 
inputs problem application represented constraints instruction word field widths hardware resources objective function microarchitecture specification 
mops scheduled time steps subject various constraints discussed 
scheduling mops time steps instructions formed time 
outputs problem formulation synthesized instruction set compiled code 
schedules mops shown table table respectively 
column table time steps second column ids mops scheduled corresponding time step 
example assumed cycle delay jump mo mop zero cycle delay memory operations 
schedule table serialized cycles 
mop time step 
note nop seventh cycle mo scheduled mop 
schedule table compact cycles 
note delay slot mo filled mo need nop 
integrated scheduling instruction formation process scheduling arch 
spec 
application instruction formation instruction set compiled code objective function design constraints control data flow graph cdfg mops simple basic mo mo mo mo mo mo pc pc instruction formation binary tuple 
notation read port register file write port register file memory port functional unit value number particular hardware resource 
example means read ports register file 
schedule instruction semantics instruction fields costs time step mop ids rtls mop type ids encoded fields inst 
id format field values cost inst 
word width mo inst mo rrai inst mo inst mo rrai inst mo rrai inst mo pc inst nop nop inst cycle count instruction set size hardware cost max 
instruction width table schedule mops resulted instructions schedule instruction semantics instruction fields costs time step mop ids rtls mop type ids encoded fields inst 
id format field values cost inst 
word width mo mo rrai inst mo mo rrai inst mo pc inst mo rrai inst cycle count instruction set size hardware cost max 
instruction width table schedule ii mops resulted instructions semantics instruction represented binary tuple list type ids shown column table page mops contained instruction list fields encoded opcode 
example binary tuple instruction add immed instruction contains mop immed type id rrai represented list argument tuple 
fields encoded second argument tuple empty list 
hand binary tuple instruction encoded version instruction add immed discussed section page immed 
list second argument tuple specifies fields encoded element unifies register specifiers register element immed fixes immediate value permanently constant 
instructions generated time steps schedule 
time step corresponds instruction 
type ids mops scheduled time step assigned argument binary tuple instruction 
operand encoding specification generated encoding process integrated scheduling process described section assigned second argument binary tuple 
table table columns header instruction semantics instruction fields describe semantics field information instructions formed schedules respectively 
columns mop type ids encoded fields specify binary tuples instructions 
rtls corresponding mop types listed rtls column 
note denotes concurrency 
inst name column assigns names generated instructions 
column format describes instruction format required instruction fields 
column field values lists instantiated field values corresponding time step 
note order demonstrate variation instruction formation instruction set table chosen non optimal 
example table mops scheduled time step binary tuple mapped instruction inst field values instantiated respectively 
note capitalized letters denote instruction fields non capitalized letters denote instantiated values fields 
hand mop time step mapped different instruction inst contains type mop rrai time steps 
reason field immediate data permanently assigned constant zero implicit opcode indicated specification encoded field column 
implicit field generated instruction behave move instruction add 
compiled code obtained easily instruction names instantiated field values 
example compiled code scheduled basic block table represented sequence inst inst inst inst 
instruction set formed union instructions generated time steps 
example instruction set derived schedule table contains instructions inst inst instruction set schedule table contains instructions inst inst inst 
performance cycle count costs weighted sum lengths number time steps scheduled basic blocks execution cycles benchmarks 
length basic block includes nop slots inserted design process preserve constraints due multi cycle operations 
design process try eliminate nop slots reordering independent operations nop slots 
instruction costs associated 
total number bits required represent instruction 
number summation opcode explicit field widths required operate mops contained instruction 
implicit fields consume instruction bits 
example table instruction inst requires bits bit width specification table page inst requires bits immediate data field implicit saving bits 
maximal bit widths instruction sets table table bits respectively 
second cost hardware 
collection resources required mops contained instruction minus shared resources 
sharing resources related field encoding 
register reads different mops unified reading register read port register file sufficient 
hand destination register receives results arithmetic logic expression functional unit computation result shared 
example inst needs read port unified 
needs functional unit destinations memory data register memory address register register file receive value 
global hardware resources obtained choosing maximal number resource type instructions 
example global hardware resources schedule ii table table respectively 
example table shows compact powerful instructions synthesized packing mops single instruction making fields implicit register ports unified satisfy cost constraints 
particularly useful application specific environment instruction sets customized produce compact efficient codes intended applications 
constraints mops scheduled time steps subject constraints 
data control dependencies timing constraints multi cycle mops satisfied 
data dependent mops scheduled different time steps subject precedent relationship timing constraints single cycle mops war dependencies scheduled time step registers read written simultaneously 
control dependency timing constraint delayed jump dealt differently 
mops data independent jump branch mops scheduled time steps jump branch mops delay slots jump branch mops 
length delay slots determined timing constraint 
example table independent mop mo scheduled time step delay slot jump mo 
second constraint instruction word width hardware resources consumed instructions larger specified designer 
third size instruction set opcode field afford 
objective function generally speaking richer instruction set may result compact efficient compiled code 
hand larger instruction set size complex decoding circuitry time hardware designers spend design verification 
trend holds true respect compiler 
objective function necessary control performance cost tradeoff 
goal design system minimize objective function 
objective function function cycle count instruction set size represents performance metrics cycles benchmarks execute target machine represents cost metrics 
interesting objective function suitable purpose equation 
objective ln eq integral form derived holmer statement new instruction accepted provides performance improvement tries balance instruction set size performance gain 
types objective functions design system 
note formulation design constraints checked separately captured objective function 
simulated annealing algorithm formulated instruction set design problem scheduling problem difficult regular scheduling problem 
required control number unique patterns instruction set time steps scheduling addition dependency performance cost constraints 
problem size usually larger regular scheduling problems application benchmarks may easily contain thousands mops scheduled 
propose efficient solution problem simulated annealing scheme 
initial design state consisting schedule derived instruction set generated pre processor design system simulated annealing process invoked modify design state order optimize objective function 
simulated annealing process run design state achieves equilibrium state 
lists basic structure simulated annealing algorithm 
outer loop operations performed temperature point temperature updated operations 
temperature movements changes design state generated 
number movements generated specified designer 
movement carried performed inner loop 
basic simulated annealing algorithm basic simulated annealing process design state current temperature max 
movement achieving equilibrium state violate constraints resolve constraint violation generate state accept state cost cost update subsection move operators section heuristics section procedures resolve constraint violation generate state cooling schedule section update move acceptance rules section accept state 
move operators move operators change design state 
provide methods manipulating mops time steps 
move operators characterized groups 
manipulation instruction semantics format group manipulates instruction semantics format selected time step 
move operators group 
generalization current instruction format selected time step contains encoded operands operands general explicit instruction fields 
effects operator increased instruction word width hardware resources 
unification unify register accesses mops access register 
example specification previous example increment instruction result unification operator 
effects operator decreases instruction word width register read write ports 
split cancel effect unification operator 
register accesses previously unified register independent 
effects operator increases instruction word width register read write ports 
implicit value bind register specifier specific register immediate data field specific value 
specific values instantiated values mops selected time step 
example specification immed instruction result operator 
effect operator decrease instruction word width 
explicit value cancel effect implicit value operator 
instruction fields previously bound specific values explicit values assigned compiler specified regular instruction fields 
effect operator increase instruction word width 
manipulation mop location second group move operators involves movement mops 
move operators group subject data control dependencies delay constraints moving mops 
target mops time steps selected randomly guidance heuristics 
interchange interchange locations mops different time steps 
operator changes semantics formats instructions corresponding time steps 
displacement displace mop time step 
operator simplifies semantics format instruction original time step enriches semantics format instruction destination time step 
insertion insert empty time step selected time step move mop new time slot 
operator simplifies semantics formats instructions selected new time steps increases cycle count 
deletion delete selected time step empty 
operator decreases cycle count 
current implementation selected mops contain unified implicit fields fields restored original forms generalized explicit move operators group applied mops 
addition mentioned effects move operators may change resource usage selected time steps 
microarchitecture dependent operators third group move operators includes methods explore special properties target microarchitecture 
move operators provided designer part microarchitecture specification 
example target microarchitecture provides register file functional unit register file register file register file data paths designer specify mops rrai rr functionally equivalent transformed rrai immed immed rr mops different costs hardware instruction format 
rrai uses functional unit consumes additional instruction field immediate data rr uses direct bus read write ports register file 
discovering rrai mop immediate data zero design system map mop equivalent rr mop vice versa 
example changing design state move operators demonstrate move operators change design states 
show sequence move operators transforms schedule instruction set design state table ones better design state table 
sequence 
displacement displace mo time step shown table 

unification unify fields time step 
unification unify fields time step 
unification unify fields time step 
unification unify fields time step shown 

deletion delete empty time step 
displacement displace mo time step shown table 

deletion delete empty time step 
unification unify fields time step 
unification unify fields time step 
displacement displace mo time step shown table deletion delete empty time step 
table table show resulting schedule instruction set design state fifth seventh eleventh move operators applied respectively 
twelfth move operator applied design state table obtained 
row tables show cycle count instruction set size hardware cost instruction word width corresponding design states 
deleted time steps shown shaded rows 
time steps move operators applied emphasized heavy rectangles time step indices 
ele schedule instruction semantics instruction fields costs time step mop ids rtls mop type ids encoded fields inst 
id format field values cost inst 
word width mo mo rrai inst mo inst mo rrai inst mo rrai inst mo pc inst nop nop inst cycle count instruction set size hardware cost max 
instruction width table design state application move operator schedule instruction semantics instruction fields costs time step mop ids rtls mop type ids encoded fields inst 
id format field values cost inst 
word width mo mo rrai inst mo inst mo rrai inst mo rrai inst mo pc inst nop nop inst cycle count instruction set size hardware cost max 
instruction width table design state application fifth move operator schedule instruction semantics instruction fields costs time step mop ids rtls mop type ids encoded fields inst 
id format field values cost inst 
word width mo mo rrai inst mo mo rrai inst mo rrai inst mo pc inst nop nop inst cycle count instruction set size hardware cost max 
instruction width table design state application seventh move operator schedule instruction semantics instruction fields costs time step mop ids rtls mop type ids encoded fields inst 
id format field values cost inst 
word width mo mo rrai inst mo mo rrai inst mo pc inst mo rrai inst cycle count instruction set size hardware cost max 
instruction width table design state application eleventh move operator ments design state modified move operators listed bold characters 
note ease illustration original time step indices table sequence referring selected time steps 
implementation indices time steps adjusted time steps inserted deleted delay constraints mops correctly maintained 
note sequence accomplish design state transition 
sequences formed depends design algorithm 
simulated annealing scheme move operators selected mix random heuristics strategies described section 
heuristics target selection iteration design space examined determine violates design constraints 
time step randomly selected pool time steps violating constraints 
constraint violated resource constraint gets higher priority instruction word width constraint movement resolves may resolve 
depending type constraints rules applied 

instruction word width constraint violated apply randomly move operators unification implicit value interchange displacement insertion 
resource constraint violated apply randomly move operators unification register port constraint violated implicit value displacement insertion 
current design space violate constraint move operators eligible changing design state 
case basic block selected probability selection selection weight basic block defined equation shown 
execution frequency basic block benchmark number mops basic block summation denominator total number mops executed benchmark 
selection weight intended denote degree importance basic block benchmark 
time step randomly chosen selected basic block move operator randomly selected applied time step 
temperature cooling schedule proper initial temperature accept virtually transition see page 
trial runs may required set initial temperature 
simple heuristic select initial temperature start temperature see transitions accepted temperature 
double value initial temperature repeat trial transitions accepted 
number movements tried temperature proportional total number mops benchmarks typically times controlled designer 
temperature current temperature 
low temperature point defined special handling routines applied stabilize design state 
annealing process terminates design state stays unchanged certain consecutive temperature points 
move acceptance high temperatures movement satisfies conditions definitely accepted 
selection 
movement reduces value objective function 
movement result constraint resolution necessary movement order resolve constraint violations 
movement accepted probability exp increased value objective function current temperature 
low temperatures different strategy adopted stabilize design state 
movement accepted conditions true 

movement generates new state violate design constraint lower objective value 
movement result constraint resolution 
condition high temperatures 
movements generate new states violate design constraint accepted probability exp addition current best design state kept algorithm decides accept inferior design states 
design state reached accepted movement temperature point inferior current best state design state falls back current best state probability initial temperature 
action adopted observed early experiments prototype algorithm simulated annealing process able reach equivalent better state jumped local best state 
extension microarchitecture design previous formulation extended synthesize microarchitecture time architecture template specification language resource allocation proper objective function design constraints discussed section 
resource allocation hardware resources allocated mops scheduled time steps 
similar problem formulation 
time step required hardware resources total resources consumed mop scheduled time step minus resources shared 
sharing resources time step due operand encoding 
register reads belonging different mops unified reading register register read port sufficient 
destination register receive results arithmetic logic expression functional unit computation result shared 
example instruction add store immed immed represents parallelism requires register read ports register read specifiers register write port functional unit addition memory port store operation 
hand instruction push immed immed requires register read port opposed requirements types resources remaining unchanged 
saving due unification register read specifiers global resources allocated union resources instruction 
design constraints objective function design constraints section page remain intact resource ones eliminated problem formulation 
algorithm responsible finding best resource allocation objective function 
goal algorithm minimize objective function arbitrary function execution time static code size instruction set size hardware cost example objective function eq sub functions calculates contributions corresponding parameters 
sub functions eq eq eq eq constants defined designer 
objective eq ln eq eq register file read port register file write ports memory ports functional units eq ln eq natural logarithmic form eq eq suggested holmer way balance tradeoff instruction set size execution time static code size 
objective function eq indicates design changes favorable 
increasing size instruction set results decrease cycle count decrease static code size assuming parameters constant 
increasing number register file read ports results decrease cycle count decrease static code size assuming parameters constant 
increasing number register file write ports results decrease cycle count decrease static code size assuming parameters constant 
increasing number memory ports results decrease cycle count decrease static code size assuming parameters constant 
increasing number functional units alu results decrease cycle count decrease static code size assuming parameters constant 
forms sophisticated objective functions 
design process design process synthesis instruction sets microarchitectures consists phases 

application translated dependency graphs mops supported architecture template 
translation performed steps 
application written high level language translated intermediate representation compiler high level language current environment prolog compiler 
second retargetable mop mapper consulting architectural template specified language described section page transforms intermediate representation dependency graphs mops 

preprocessor generates simple minded schedule mops 
instruction set derived schedule 
done directly mapping time steps schedule instructions encoding operand 
obtained schedule instruction set constitute initial design state 

simulated annealing algorithm modifications discussed section section invoked optimize design state 
note initial temperature annealing process higher problem section 
simple heuristic set initial temperature adjust initial temperature rejection states high costs initial temperature 
number movements tried temperature larger 
modifications due larger design space instruction sets microarchitectures designed 
experiments may necessary order set proper values parameters 
best instruction set microarchitecture assembly code minimize objective function obtained design state reaches equilibrium state 
chapter taxonomy resolution inter instruction dependency piper constructs pipelined microarchitectures reordering tables microarchitectural domain synthesis tool adas 
described section page major synthesis phases piper pipeline assignment pipeline hazard resolution resource allocation 
piper unique approaches hardware software concurrent engineering approach second phase 
second phase divided tasks analysis inter instruction dependencies application hardware software resolutions section section respectively 
techniques developed sections pipelined processors fire instruction cycle 
section discusses extension techniques previous sections synthesis pipelined processors instruction firing period cycle 
extended taxonomy inter instruction dependencies data dependent pipeline hazards caused inter instruction dependencies 
resolve hazard determine type dependency involves choose appropriate resolution strategy 
provide classification inter instruction dependencies consists classes derived cross products backward stationary general model pipeline structures consider single pipeline linearly cascaded stages constant stage latency model similar 
stage latency number clock cycles instruction spends pipeline stage advances stage 
pipelined machine model defined extension execution phase instructions allows multiple register accesses alu operations 
operations may span multiple pipeline stages 
simplicity assume pipelined machine cycle stage latency section 
assumption micro operation instruction executed th cycle belongs th stage pipeline 
generalized case stage latency multiple cycles discussed section 
definitions discussion valid assume pair dependent instructions travelling pipeline closely pipeline structure interfere dependencies pair 
inter instruction dependency pipeline structure described terms triple 
register access patterns read write preceding succeeding instruction respectively 
conventional classification dependencies encapsulated pair parameters data write read read write anti read write write read output write write write write dependencies 
hand describes relative position register accesses dependent instruction pair pipeline structure 
possible values forward backward stationary 
provides classification dependencies pipeline structure point view shows relative positions register accesses preceding succeeding instructions 
suppose instruction insta accesses register th cycle th stage instruction instb accesses register th cycle th stage define classes dependencies respect pair precedence relationship instruction pairs forward backward dependency 
forward dependency happens preceding instruction accesses register earlier stage succeeding instruction accesses register stage insta instb pair insta followed instb backward dependency happens preceding instruction accesses register stage succeeding instruction accesses register earlier stage instb insta pair instb followed insta 
note forward backward dependencies potentially exist hardware pair instructions access register different stages read read case 
actual direction dependency forward backward application program determined relative precedence relationship instruction pair example insta instb pair forward dependency instb insta pair backward dependency 
forward backward stationary dependencies pipeline stages pipeline stage access reg 
instruction instb forward dependency insta followed instb backward dependency instb followed insta pipeline stage access reg 
instruction insta instb stationary dependency pipeline stage access reg 
instruction insta 

third class dependency stationary dependency happens preceding succeeding instructions access register stage shown 
please note definition inter instruction dependency different definition dependency defined access single register opposed set registers 
instruction domain range defined set registers instruction reads writes respectively 
pair instructions exhibits inter instruction dependency long domains ranges overlap 
definition insufficient single instruction may access register resulting different types pipeline hazards requires different resolution 
pair dependent instructions may involved class dependency 
classification hazards differentiated dependency separately resolved 
forward backward stationary dependencies refined types 
applying conventional classification class dependency forward data forward anti forward output backward data backward anti backward output stationary data stationary anti stationary output dependency 
table summarizes types dependencies 
preceding instruction accesses register cycle succeeding instruction accesses register cycle types register accesses read write write read write read read write write write write write forward forward data dependency forward anti dependency forward output dependency backward backward data dependency backward anti dependency backward output dependency stationary stationary data dependency stationary anti dependency stationary output dependency table inter instruction dependencies pipelined instruction set processors pipeline hazards inter instruction dependencies pair instructions exhibiting backward dependency travelling closely pipeline cause pipeline hazard succeeding instruction reaches stage accesses register preceding instruction hasn arrived stage stage accesses register instb insta pair 
example delayed load instruction immediately followed instruction uses loaded data earlier stage results pipeline hazard involving backward dependency 
forward dependency cause pipeline hazard 
insta instb pair example forward dependency 
instruction insta accesses register stage leaving time cycles succeeding instruction instb reach stage access forward dependency cause pipeline hazard properly handling may eliminate associated backward dependency example instb insta pair 
explain issue section 
stationary dependency cause pipeline hazard interfere classes dependencies 
succeeding instruction access register cycle right preceding instruction access 
instructions exhibiting stationary dependencies access register simultaneously 
delay slot required instruction pairs stationary dependencies 
stationary dependency desired way handling inter instruction dependency pipeline design 
translates design goal requires accesses register different instructions scheduled pipeline stage 
goal achievable due design constraints 
example aligning register accesses pipeline stage may effectively lengthen critical path 
stationary dependency preserved forward backward dependencies occur necessitate forms resolution ensure proper behavior 
section hardware software resolutions pipeline hazards caused forward backward dependencies 
hardware software resolutions pipeline hazards powerful practical way resolving data dependent pipeline hazards data flow approach approach 
data assigned tags data flow engine reservation station supporting circuitry approach track relationships data 
consider alternative approach employing relatively simple hardware software techniques 
advantage approach takes advantages classification dependencies previous section 
summarize resolution techniques section relate pipeline hazards section 
general hardware software resolution strategies hardware resolution straightforward way resolve hazards hardware additional registers 
types additional registers employed forwarding duplicate registers 
forwarding registers carry data instruction stream pipeline 
example datum written register instruction insta stage time forwarded pipeline forwarding registers arrives stage time 
datum moves pipeline synchronously insta 
advantage forwarding soon current datum register forwarded stage free data 
analogous adding extra latches delays pipeline order improve system throughput 
duplicate registers release burden temporary registers 
temporary register connects sources destinations possible connection patterns 
connections mutually exclusive bottleneck data traffic 
suppose actual connections established better performance achieved connections concurrently 
adding duplicate register create additional data path ease traffic improve performance shown 
software resolution instruction reordering major technique compiler back ends resolve pipeline hazards 
desired behavior instruction stream may distorted hardware resolution forwarding registers data path instruction stream instruction stream insta insta pipeline stages hardware resolution duplicate registers register 
register register 
pipelining 
instruction reordering restores desired sequential semantics instruction stream reordering sequence instructions 
directions reordering reordering 
sequential code instruction instb follows depends insta 
cases reordered codes different pipeline structures 
case instruction instb moved ahead insta case instb moved apart insta 
usually constraints windows movements maximal numbers slots instb moved ahead insta minimal number slots instb moved insta 
example respectively 
define reorder distance reordering respectively 
inter instruction dependencies applicable resolution subsection provide applicable hardware software resolution strategies pipeline hazards caused forward backward dependencies 
pointed section stationary dependencies cause hazard 
require resolution 
ease discussion pipeline archi software resolution instruction reordering instb depends insta sequential code insta instb reordering insta instb reordering instb insta 


tecture instruction pairs example assuming stage latency cycle 
generalized case pipeline stage takes multiple cycles provided section 
forward dependencies forward dependency case insta instb pair insta followed instb 
mentioned section forward dependency cause pipeline hazards resolutions optionally applied improve system performance 
forward data dependency ways resolve type dependency forwarding registers reordering 
forward register stage allocated stages totally forward registers 
side effect approach associated backward anti dependency instb insta pair automatically resolved 
approach preferable case insta instb instb insta pairs happen frequently application programs 
secondly hardware resolution choose optionally move instruction instb ahead insta reordering slots cycles 
advantage hiding possible delay slots associated instruction instb example instb delayed operation register cost longer compilation time compiler back 
forward anti dependency applicable resolution reordering compiler back described previously assuming register master 
forward output dependency ways resolving type dependency duplicate registers reordering 
duplicate registers eliminate forward output dependency insta instb independent instructions 
side effect backward output dependency instb insta pair eliminated 
forward output dependencies resolved optional reordering compiler back described previously 
backward dependencies backward dependency case instb insta pair instb followed insta 
software resolution reordering available backward dependencies 
dependent instruction insta moved away downward predecessor instb slots ensure insta access target register instb access 
compiler back fill slots nops reorder independent instructions slots 
backward output dependency resolved hardware technique duplicate registers case forward output dependency 
side effect hardware resolution associated forward output dependency automatically resolved 
circular dependency check performed duplicate register inserted 
unfortunately hardware resolution backward data anti dependencies 
summary extension summarize resolution strategies inter instruction dependencies table 
table extend resolution strategies pipeline machines multi cycle stage latency instruction spends cycles stage advances stage 
micro operation executed th cycle execution path executed mod th cycle th stage 
table assumed insta instb access register th th cycles execution paths respectively 
please note constant adjust case master slave registers 
column contains classes inter instruction dependencies require resolution 
remember stationary dependencies cause pipeline hazards 
class dependency dependent instruction pair taken listed example 
applicable hardware software resolution strategies listed second third columns class dependency 
second column list side effects hardware resolutions 
note forward data forward backward output dependencies hardware software resolution candidates available allow tradeoff hardware software 
tradeoff characteristics application domain frequency dependency applications time space complexities compiler backend 
way perform tradeoff analysis section show examples section 

master slave registers 
inter instruction dependency hardware resolution software resolution forward data insta instb forward registers total number forward registers side effect resolution backward anti dependency instb insta resolved optional reordering forward anti insta instb optional reordering forward output insta instb duplicate register side effect resolution backward output dependency instb insta resolved optional reordering backward data instb insta reordering backward anti instb insta reordering backward output instb insta duplicate register side effect resolution forward output dependency insta instb resolved reordering table hardware software resolution strategies inter instruction dependencies hazard free chapter pipeline hazard resolution chapter describes section design procedure third phase pipeline hazard resolution piper utilizes extended taxonomy dependencies hardware software resolutions section 
section models performance cost developed tradeoff hardware software 
procedure pipeline hazard resolution pipeline synthesis process piper consists phases pipeline assignment pipeline hazard resolution resource allocation 
phase pipeline scheduling assigns micro operations pipeline stages 
pipeline hazards may introduced pipeline scheduler highly pipelined cases 
hazards resolved second phase 
phase application benchmarks evaluate design choices 
phase hardware resources data path allocated producing pipelined rtl level design 
pipeline hazard resolution phase takes input pipelined schedule outputs set hardware software resolutions 
accomplished steps 
steps described subsections 
analysis inter instruction dependencies step inter instruction dependencies pipelined schedule identified 
inter instruction dependencies appear inter iteration dependencies pipelined schedule pipelined loop body 
types inter iteration dependencies interested trace cross trace 
trace dependencies dependencies lie execution trace single iteration dependencies detected unrolling loop 
hand cross trace dependencies lie different execution traces single iteration detected loops unrolled 
example shows schedule consisting basic blocks 
root block conditionally branches block 
blocks exclusive blocks loop back 
write register block 
dark bi directional arcs connecting register accesses block respectively trace dependencies grey bi directional arc connecting register accesses block cross trace dependency 
algorithm identify trace cross trace dependencies unrolling loop 
step global data flow analysis performed loop body identify trace dependencies 
traversing basic blocks analyzer records earliest latest read write register exclusive block 
second step register set exclusive blocks cross trace dependencies 
trace cross trace dependencies 
algorithm cross trace dependency analysis 
pipelined schedule output trace cross trace dependencies perform global data flow analysis loop body schedule 
identify trace dependency 
basic block belonging branch exclusive blocks record earliest latest read write register perform pairing earliest latest register accesses basic blocks set exclusive blocks 
number exclusive blocks 
label exclusive blocks 
register exclusive block pair earliest read earliest latest write blocks pair earliest write earliest latest read write blocks pair latest read earliest latest write blocks pair latest write earliest latest read write blocks report pairs cross trace dependencies trace dependency cross trace dependency 
ated 
formed pairing earliest latest register read write block earliest latest register read write block pair exclusive blocks set 
generation weight assignment resolution candidates inter instruction dependency identified step possible hardware software resolutions generated second step table page 
inter instruction dependencies may hardware software resolutions available 
cases assign weights hardware resolution candidates help designer select appropriate resolutions 
current implementation weight derived frequency application benchmarks reorder distance dependency hardware resolve 
equation defines weights 
weight assigned hardware resolution instruction pair contains dependency hardware resolve 
freq frequency instruction pair benchmark 
dist reorder distance instruction pair due dependency resolved hardware 
hardware resolution may resolve multiple dependencies instruction pairs weight calculated summation product freq dist related instruction pairs 
application benchmarks available equal frequency assumed 
equation intends measure hardware utilization effectiveness eliminating instruction reordering 
limitation simple model consider interaction 
may set exclusive blocks 
set exclusive blocks consists blocks exclusive 
freq dist resolutions different dependencies 
examine limitation example section 
generation final resolutions designer selected desired hardware resolutions software resolutions obtained 
presents algorithm generation software resolutions candidates 
step side effects selected hardware resolutions examined 
described table page addition resolving forward backward dependency involves hardware resolution side effect automatically resolving associated backward forward dependency 
reordering constraints introduced dependencies deleted software resolutions 
second step merge process performed remaining software resolutions 
purpose merge process remove software resolutions covered 
example reordering suppose ro add load delay slots add followed load ro add load exist deleted resolutions covered constraint 
second step shown algorithm generation software resolutions selected hardware resolutions software resolution candidates reordering constraints dependencies output software resolutions hardware resolution 
delete dependencies related hardware resolution 
delete software resolutions belong dependencies 
hardware resolution side effect related dependency delete dependency software resolutions remaining dependencies perform merge process software resolutions reordering constraints 
reordering constraint record format ro instruction instruction displacement repeat change 
ro ro exist delete ro 
ro exists delete ro ix dx dx 
ro exists delete ro ix dx dx reordering case 
reordering constraints obtained interchanging performance cost modelling characterize synthesized design performance cost hardware supporting software reorderer 
important metrics peak runtime performance cost hardware time space complexities compilers 
metrics able provide designers broader finer design space spans hardware software 
capability modeling software hardware components complete systems essential extending application scope design automation systems embedded systems design 
performance estimation hardware performance metrics evaluate designs maximal run time performances 
maximal performance obtained instruction latency clock rate known 
vary applications 
runtime performance depends characteristics applications 
instruction trace expansion due inter instruction dependencies pipeline hazards degrades run time performance deeply pipelined processor maximal performance 
consider fragment instructions compiled non pipelined machine case 
suppose synthesized pipelined machine requires delay slots branch brn successive instruction type 
case nop inserted brn successive sub 
instruction trace expanded nop slots degrade pipeline performance pipeline cycles 
case size nop slots compressed reordering independent instruction add nop slots 
piper uses set benchmarks instruction set programs estimate run time performance 
repeating phase compiling simulating benchmarks pipeline implementation piper applies characteristics simulation traces benchmarks compiled processors characteristics reorder table predict run time performance 
approach run time performance different synthesized pipelined processors quickly obtained 
instruction set simulator adas provides set instruction benchmark characteristics 
characteristics piper pattern frequency instruction pairs frequency consecutive instruction pairs instruction trace 
shown pattern frequency small instruction benchmark instruction set 
example entry represents instruction reordering reorder delay constraint reorder brn 
add brn sub add brn nop nop brn add nop original code reordered code sub sub pattern frequency instruction pairs instruction pattern count load add 
instruction pattern count store add 
instruction pattern count load 
instruction pattern count add brn 
instruction pattern count store jump 
instruction pattern count brn load 
instruction pattern count jump load 
instruction pattern count nop load 
instruction pattern count shr 
instruction pattern count add store 
instruction pattern count brn store 
load immediately followed add load add pair happens twelve times trace frequency 
pipelined processor run time performance metrics respect benchmark approximated equations xp trace expansion due insertion nop speedup pipelined processor respect non pipelined processor throughput pipelined processor dist pj number nop worst case inserted consecutive instruction pattern pipelined processor frequency consecutive instruction pattern instruction latency pipelined processor instruction cycle time non pipelined processor total number instructions simulation trace compression factor consecutive instruction pattern means empirically percentage number nop slots filled reordering instructions slots 
set zero worst case analysis 
product am total number cycles benchmark executed non pipelined processor product xp total number cycles executed pipelined processor exp dist exp exp cost estimation hardware represent cost hardware sizes data path control path 
size data path obtained estimating number transistors data path 
wiring cost considered current version piper 
control model adopted piper data stationary model 
stage controller 
implement controllers plas 
derive control path cost summing estimated pla size stage 
time space complexities instruction set compilers comparing time space complexities instruction set compilers different pipeline implementations instruction set architecture focus reorder phase compiler phases compiler remain constant 
apply characteristics reorder table equations time space complexities derived relative performance cost reorderer respectively 
possible characteristics reorder table include number reorder entries consecutive instruction patterns maximal safe instruction distance max minimal safe instruction distance min average safe instruction distance avg time space complexities reorderer considered constraint imposed synthesis system software reorderer 
example reorderer time complexity max implies feasible synthesis system synthesize design produces larger reorder table design large safe instruction distance smaller reorder table may acceptable design 
demonstrate idea consider simple reorderer reads reorder table size sweeps window size max instructions look target patterns searches window independent instructions inserted nop slots 
assume table kept array 
iteration reorderer takes max max time 
memory size max necessary 
time space complexities may expressed benchmark length 
substituting variables values obtain relative complexities 
similarly derive time space complexities terms reorder table parameters reordering algorithms 
set equations kept system configuration file piper modified reordering technique compiler changed 
exploration hardware software tradeoff design decisions pipeline scheduling hazard resolution affect performance cost hardware time space complexities compiler back 
addition design engine set estimators application benchmarks estimation effects 
shown table pipeline hazards caused inter instruction dependencies may hardware software resolution strategies available 
deciding strategy pick requires tradeoff analysis 
hardware resolution advantage resolving forward backward dependencies time cost additional registers connections data path 
hand software resolution advantage complicating hardware 
places burden compiler back reorder constraints longer time compile code 
time complexity max max space complexity max tradeoff analysis performed piper follows 
hardware side cost hardware represented estimated size processor including data path forwarding duplicate registers adopted control path 
set application benchmarks measure performance hardware 
performance estimated analytical approach described section 
software side time space complexities compiler back expressed functions parameters related characteristics reorder constraints size reorder table maximal minimal average reorder distances table example straightforward implementation reorderer compiler back described time space complexities proportional size reorder table number reorder constraints 
comparing software cost possible designs evaluate design time space complexity functions substituting characteristics reorder constraints functions 
practice space complexity concern space static code size reorderer varies just slightly hardware designs different sizes reorder tables 
space taken table varies usually small compared space algorithm 
performance cost hardware software taken evaluate global goodness designs 
objective function piper goodness goodness total eq total eq size hardware time complexity reorderer representing compilation difficulty constant adjusts scales parameter designer assign relative importance hardware respect software reorderer 
total conceptual cost entire system including hardware software 
estimated performance term speedup respect non pipelined design 
goodness defined performance cost ratio entire system 
concurrent hardware software approach tradeoff model piper providers designers capability customizing designs different application domains selecting appropriate benchmarks weight constant chapter experiments chapter demonstrates techniques developed dissertation 
experiments instruction set design techniques section section section 
second experiments simultaneous instruction set design resource allocation section 
third experiments instruction set design resource allocation prolog section 
experiments synthesizing microarchitectures compiler backend interfaces section 
experiments performed show strength limitation techniques 
features conducted experiments include 
illustrative practical examples experiments 
experiments assumed different microarchitectures clock cycle time 
accurate estimation clock cycle time simple assumption adopted experiment reduce programming effort 
objective estimating functions guide design process compare different designs 
goal experiments demonstrate techniques synthesize designs explore design space assuming objective estimating functions correct 
objective functions capture faithfully designer intention estimating functions accurate concerns experiments 
feature feedback mechanism described section page implemented improve objective estimating functions design heuristics 
instruction set design resources allocated section demonstrates synthesis application specific instruction sets architecture templates resources designer 
instruction sets synthesized assumption application benchmarks software executed target processors 
instructions support required functionality benchmarks synthesized 
assumption reflect design requirement embedded systems limited number application benchmarks run repeatedly 
experiments application specific instruction sets generated individual application 
purpose explore variation architectural properties different application benchmarks comparing performance cost corresponding instruction sets 
source level prolog application benchmarks experiments 
compiled assembly code prolog compiler 
preprocessor maps files assembly code dependency graphs micro operations input synthesis algorithm described section page 
files machine level code assuming sequential execution described chapter synthesis algorithm produces synthesized instruction set assembly code application benchmark 
due lack simulators synthesized instruction sets difficult obtain run time performance assembly code 
moment run time performance approxi 
phase backend prolog compiler transforms files ro files machine code ready executed pipeline stage vlsi bam microprocessor 
operations performed phase includes insertion nop instruction reordering peephole optimization 
mated assuming instruction assembly code get executed 
simulators automatically generated synthesized instruction sets 
small example example assumed target architecture table page instruction field specification table resource delay specification table page table page respectively 
example subsection small application sets list elements prolog 
consists mops 
table lists mops dependencies 
bf clauses row specify dependencies mops 
example bf constrains mop scheduled time step earlier mop 
ctl clause specifies mop changes control flow 
note control flow change cycle delay 
synthesized bit bit instruction sets resource constraints respectively 
objective function eq 
objective ln eq instruction field type number bits instruction word opcode register tag displacement immediate relation operator op table bit width specification instruction field types synthesized bit instruction set listed table consisting instructions 
note instructions inst inst contain encoded fields order satisfy required bit word constraint 
instruction set compiles application cycles shown table 
note time step delay slot inst changes control flow 
independent instruction inst scheduled time step delay slot 
bit width tag immed mop id type id rtls mop id type id rtls rit rrai rrai rit dependency bf ctl control table mops dependencies list creating application bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
bf 
ctl 
table lists bit instruction sets consisting instructions 
instructions concurrent mops 
bits wide accommodate instruction fields encoded field required instruction set 
compiled code table consists cycles cycles bit 
note instruction inst scheduled delay slot instruction inst changes control flow 
right columns specify binary tuples corresponding instructions 
instruction name instruction fields rtls mop type id encoded fields inst pc jd rrai inst rrai inst inst table bit instruction set time step compiled code time step compiled code time step compiled code inst atm inst inst inst lst inst atm inst var inst inst inst inst lst inst atm delay slot inst table compiled code bit instruction set prolog application benchmarks subsection experiments show versatility practicality tools synthesizing instruction sets application benchmarks various design constraints objective functions 
benchmarks selected prolog benchmark suite 
benchmarks con programs list manipulation 
benchmark query program database query 
benchmark circuit maps boolean equations logic gates 
second column table lists characteristics benchmarks including numbers mops data related dependencies control dependencies benchmarks 
number instruction name instruction fields rtls mop type id encoded fields inst pc jd rrai inst rrai inst rit rrai inst rit inst table bit instruction set time step compiled code time step compiled code inst atm lst inst inst inst atm var inst lst inst inst delay slot inst inst atm table compiled code bit instruction set mops represents size benchmark number data related dependencies related degree parallelism available benchmark number control dependencies indicates degree impact branch jump delays benchmark 
assumed basic block executes 
assumed target architecture table page instruction field specification table page 
delay constraints control memory operations zero respectively 
experiment conducted hp workstation memory 
benchmark synthesized bit bit bit instruction sets respectively 
interested instruction sets vary bit widths 
table lists results synthesized objective function eq page 
benchmarks expected cycle decreases instruction word width increases 
observed smaller gain circuit 
explained larger ratios number data dependencies number mops 
mops depend parallelism available packing mops instructions 
general size instruction set increases instruction word width increases 
due fact wider words accommodate mops resulting richer powerful instructions 
bit instruction sets embarrassing designs con 
instruction set sizes larger performance worse bit alternatives compiling benchmarks 
bits wide benchmarks accommodate frequent mop patterns bits sufficient 
design process specialize general forms powerful instructions dis instructions making fields implicit unifying register ports order satisfy bit width constraint 
instruction set space column examined number instruction candidates explored design process 
numbers larger final instruction sets show design process able explore rich design space best candidates keeping size design space manageable 
right columns list run time memory usage algorithm show tools able synthesize instructions application benchmarks reasonable time consume modest amount memory 
table compared synthesized bit instruction sets benchmarks bam instruction set designed vlsi bam micro pro 
number control dependencies counted total number branch jump mops 
hardware constraints bit instructions bit instructions bit instructions benchmark mops data dep control dep 
instruction word width design results performance algorithm cycle instruction set size instruction set space time minutes memory mb con query circuit table results objective function ln cessor project university california berkeley 
micro processor risc style instructions plus powerful instructions support efficient logic computation prolog 
benchmarks compiled bam instruction set measured number distinct instructions instruction set size column number cycles execute compiled code cycle column 
programs compiled prolog compiler post phase optimization phase turned experiments show synthesized instruction sets produced compact codes benchmarks reduction code size respectively 
achieved cost small number additional instructions con query respectively circuit additional instructions required 
objective function evaluate global performance cost tradeoffs instruction sets cases con query synthesized ones yield better results indicated objective value column smaller values better 
possible improve result circuit adjusting initial temperature cooling schedule experiment 
compared hardware resources instruction sets 
amount resources case synthesized instruction set uses register read port memory port bam 
experiment shows asia capable competing manually designed instruction sets collection benchmarks 
studies needed investigate competence general cases 

post phase optimization prolog compiler alters classic definition basic block 
due time limit able modify tools accommodate change 
table shows interesting instructions synthesized benchmark query 
selected bit bit bit instruction sets respectively 
ease illustration list binary tuples instructions describe rtls instructions directly 
rtls register sharing indicated register index 
note bit version instructions bam instruction set 
fact provides bam designers confidence instruction set instructions considered powerful retain existence instruction set designed independent designers case asia design automation system 
observation suggests asia addition original purpose automatic design tool verification tool designers verify manually designed instruction sets 
resource constraints asia vlsi bam processor 
bam refers instruction set manually designed vlsi bam processor 
asia refers instruction set synthesized tools asia reported 
benchmark instruction set hardware resources cycle instruction set size objective value smaller better con bam asia bam asia query bam asia circuit bam asia table performance comparison manually designed instruction set table shows synthesized instruction sets vary objective functions 
experiment synthesized bit instruction sets benchmark query versions objective function eq page 
assigns importance cycle count 
tools focused reducing instruction set size resulting instructions cycles case 
notations 
rtls instruction executed simultaneously 
tf bit latch holds truth value logic computation 
operator appends tag value value sent destination 
instructions bam instruction set 
instruction word width rtls meaning push tf conditional push tag pc pc tag pc pc switch tag tf op 
pc compute condition jump tf store conditional push shared register store add tf store conditional push store add tag data add table synthesized instructions objective function cycle instruction set size ln eq ln eq table instruction variation benchmark query due different objective functions instruction set design resource allocation experiments conducted section setting section number hardware resources constrained left design system allocate 
experiments application specific instruction sets synthesized assembly code generated resources allocated individual application 
purpose explore variation architectural properties different application benchmarks comparing resulting instruction sets resource usage 
mop specification timing parameters section architecture template 
bit width constraints instruction fields table 
objective function arbitrary complex function 
simplify experiment eq objective function experiment section 
equation dynamic cycle count instruction set size number register file read ports number register file write ports number memory ports number alus 
objective ln eq assumed basic block executes application 
assumption parameter objective function represents static code size execution time number movements tried temperature point mops 
temperature current temperature 
experiments conducted hp workstation memory 
symbolic applications selected prolog benchmark suite 
hanoi hanoi problem solver 
con concatenates strings string 

assumption due fact profile analyzer available moment able obtain run time behavior execution counts basic blocks 
reverses order string 
note predicate concat defined con subroutine 
qsort classic qsort algorithm 
lists source code prolog 
main clauses user represent typical execution programs 
note due built unification backtracking support prolog gives compact representation language 
representation usually times larger prolog representation 
compiled intermediate representation hidden details prolog explicit 
results table 
second column characteristics applications 
number mops represents size application 
numbers data control dependencies limit available parallelism mops 
ratio mop dep tries measure average parallelism 
columns header design results outputs algorithm resource allocation application programs prolog main concat 
concat 
concat concat 
main qsort 
qsort partition qsort qsort 
qsort 
partition partition 
partition partition 
partition 
main hanoi 
hanoi move 
move 
move move move 

con 
qsort 
hanoi main 
concat 

concat 
concat concat 

cycle counts application instruction set size 
header list number candidate instructions inst 
set space column number microarchitecture configurations space column explored algorithm 
right columns list cpu run time memory usage algorithm 
interesting architectural properties revealed experiment 
hanoi largest average parallelism applications indicated mop dep ratio implies allocating resources instructions may sense hanoi 
results experiment contradict expectation hanoi gets amount resources instructions 
examining mop graphs applications detail seemingly abnormal design results due irregularity basic block structures 
variation basic block sizes hanoi smaller variations 
words basic block structure hanoi regular 
number instructions mop patterns required map hanoi 
number control dependencies counted total number branch jump mops 
notation read port register file write port register file memory port functional unit value number particular hardware resource 
example means read ports register file 
benchmark mops data dep control dep mop dep 
design results performance algorithm resource allocation cycle inst 
set size inst 
set space space time min 
memory mb hanoi con qsort table synthesis results required 
explains smaller size hanoi instruction set 
hand lots dependencies applications hanoi located tiny basic blocks leaving large basic blocks dependencies 
experiment objective minimize compiled code size dynamic code size run time advantage large amount parallelism existing large basic blocks taken algorithm larger amount resources allocated applications 
explains applications get resources hanoi 
observation suggests addition simple measurement average parallelism mop dep ratio type locality indicator measuring distribution dependencies necessary help characterization applications 
second observed program listing major subroutine concat application con application 
viewed part 
words general 
suggests may exist similarities covering properties synthesized microarchitectures instruction sets applications 
results show applications allocated amount resources 
instruction set size con larger 
existence specialized powerful instructions con justified frequencies special patterns decrease larger general environment 
table compare specialized powerful instructions con corresponding ones 
instructions remain existence ones case 
disappear ones case 
lose specialization case 
hand instructions remain existence con original forms specialized forms ones case 
instruction case 
delete instruction set map mops contains simple instructions exist instruction set objective value reduced resulting better solution 
done algorithm 
reason chance mops selected displaced algorithm low pattern occurred application 
fix problem increase number movements tried temperature point cost increased cpu time 
hand introduce powerful move operators delete instruction delete resource algorithm cost complicating design heuristics modification data structure objects moved longer just mops simple local ones instructions resources complex global ones 
illustrates objective value resource allocation instruction set size cycle count varied annealing process application hanoi 
data points sampled temperature point temperature 
operands explicitly specified instruction fields printed bold face 
case instruction con instruction set corresponding instruction instruction set tag pc pc tag pc pc tf op 
available pc available tf tf available pc pc available table comparison instruction sets con points computed application movements tried temperature point 
comparison synthesized best microarchitecture instruction set hanoi iterative approach range possible resource allocation 
simulated annealing process application hanoi objective value temperature point temperature point temperature point resource allocation instruction set size static code size distinct combinations explored iteration asia configured generate instruction sets assembly code resource allocation 
difficult task decide combinations resource allocation tried believe sufficient design space explored 
resource configurations explored guide experiments 
results shown table 
iterative approach obtained instruction set hardware allocation integrated approach table times longer cpu time 
iterative approach conduct complete runs various resource configurations order find best solution integrated approach finds best solution faster dynamically switching different resource configurations shown infeasible design space pruned early search process 
results show integrated approach addition clarity problem formulation significant performance improvement times iterative approach solving combined problem instruction set design microarchitecture design code generation 
resource allocation design results performance algorithm cycle inst 
set size inst 
set space objective value time min 
memory mb total experiment time table iterative approach instruction set design resource allocation benchmark hanoi instruction set design resource allocation prolog experiments section section conducted instruction set processors embedded systems 
embedded environment size instruction set reduced eliminating instructions functionality required applications substituted instructions 
hand experiments conducted section synthesize complete instruction set prolog customized particular application 
application benchmark con listed page customized instruction set 
complete segments prolog ensure completeness synthesized instruction set special code segments holmer table dissertation purpose included application 
special code segments contain subset vlsi bam instruction set known complete prolog execution 
complete segments segment separated predicate label 
segments include basic operations required prolog compare branch jump load immediate read program counter register register move register arithmetic prolog specific operations unification maximal 
experiments conducted microarchitecture specification instruction bit width specification section objective function eq page 
synthesize instruction set prolog complete segments asia 
result shown table 
table column identifiers synthesized instructions second column lists binary tuples corresponding instructions third column shows register transfers corresponding binary tuples fourth column shows equivalent vlsi bam instructions 
instruction set generated asia identical vlsi bam instructions complete segments 
obvious coincidence result non trivial design process 
note inst swt inst uni complex instructions containing multiple conditional micro operations cond cond respectively 
instructions operands necessary control operations fit bit instruction word 
design process tries split micro operations time steps resulting instructions 
increased numbers instructions time steps favored objective function 
design process tries encode operands order reduce required instruction bits 
takes encoding transformations satisfy instruction word complete segments prolog table label prolog 
cmp eq 
bt fail 
label prolog 
cmp ne 
bt fail 
label prolog 
cmp lts 
bt fail 
label prolog 
cmp ges 
bt fail 
label prolog 
cmp ltu 
bt fail 
label prolog 
cmp 
bt fail 
label prolog 
cmp 
bt fail 
label prolog 
cmp 
bt fail 
label prolog 
fail 
label prolog 
fail 
label prolog 
ldi 
label prolog 

label prolog 
rd pc 
label prolog 
ld 
label prolog 
st 
label prolog 
lea tvar 
label prolog 
addi 
label prolog 
add 
label prolog 
sub 
label prolog 

label prolog 

label prolog 
xor 
label prolog 
sra 
label prolog 
srl 
label prolog 
sll 
label prolog 

label prolog 
mov 
umax 
label prolog 
swt true tvar fail 
label prolog 
uni 
bt fail 
id binary tuple register transfers equivalent bam instruction inst tag pc pc immed inst tag pc pc immed inst tf pc immed bt inst pc immed inst regr regr tag pc pc immed tag pc pc immed swt inst immed ldi inst immed ld inst mov inst pc rd inst add inst immed addi inst immed lea inst 
inst xor 
xor inst 
inst sub inst sll inst arithmetic right shift sra inst logic right shift srl inst tf op 
cmp inst dereference inst max umax inst immed st inst imp tvar imp cond tvar immed cond immed regr regr cond regr cond regr tag cond tag tag tvar immed tf immed tag tvar tf uni table instruction set prolog complete segments width constraints respectively 
shown second arguments binary tuples inst inst 
asia synthesis step complete segments added application con 
application major inner loop body 
number iteration loop body equal length string 
order investigate run time behavior loop body affects instruction set design versions application con con con created running application string length respectively 
execution counts basic blocks versions manually derived 
instruction sets synthesized asia modified application 
synthesized instruction sets complete instruction sets prolog customized application different input lengths 
synthesis results shown page 
comparison application compiled code prolog compiler 
resource allocation vlsi bam architecture results compiled code listed figures known design point 
note results vlsi bam architecture listed figures bam sake simplicity 
compared results results asia listed asia 
shows resource allocation 
application con gets minimal allocation 
number iteration inner loop increases resources allocated utilize available mop parallelism loop body 
increased 
run time behavior depends input patterns load 
resources justified performance improvement objective function discussed 
note resource allocation cases equivalent resource allocation vlsi bam 
shows sizes synthesized instruction sets vlsi bam instruction set 
synthesized instruction sets contain base prolog instructions prolog see page indicated base result included complete segments 
addition sizes synthesized instruction sets smaller vlsi bam maintaining general support prolog compilation 
note instruction sets con con size instructions different 
con instructions powerful consume hardware resources con 
similarly con instructions powerful consume hardware resources con 
dynamic cycle counts cycle counts executing assembly code shown 
synthesized instruction sets produce dynamic cycle counts vlsi bam con con 
dynamic cycle count synthesized instructions con worse vlsi bam benefit hardware resources instruction set size 
static code sizes shown table 
synthesized instruction sets produce larger static code larger vlsi bam 
due fact static code size part objective function asia attempt minimize 
interesting conduct experiments incorporating static code size objective function 
synthesis results applications con con con 




goodness indicated value objective function synthesized designs vlsi bam design 
results show synthesized designs better vlsi bam application objective function 
conclude synthesized designs better vlsi bam general synthesized designs customized application input patterns vlsi bam designed general purpose balanced objective function eq 
asia design exploration experiments conducted far demonstrate straightforward asia synthesis 
experiments demonstrate asia design space exploration 
application objective functions eq eq eq asia synthesize instruction sets allocate resources 
objective cost eq objective cycle count eq objective instruction set size eq objective function eq guides asia minimize total hardware resources assuming costs design metrics instruction set size static code size cycle count free 
objective function find minimal machine design space 
similarly eq find powerful machine cycle count costs hardware resources instruction set size eq find machine minimal instruction set costs hardware resources cycle counts 
objective functions explore boundaries multidimensional design space 

smaller value indicates better design 
experiments results con con con table table table respectively 
table row lists result experiment objective function column 
results designs synthesized section global objective function eq page provided 
global comparison results experiments evaluated objective function eq obtained values column 
objective function rf read port rf write port mem port alu inst 
set size static code size cycle count obj 
value eq cost eq cycle count eq inst 
set size eq obj 
function eq vlsi bam table design space exploration con objective function rf read port rf write port mem port alu inst 
set size static code size cycle count obj 
value eq cost eq cycle count eq inst 
set size eq obj 
function eq vlsi bam table design space exploration con interesting observations derived results 
design boundaries 
design space applications bounded register file read ports register file write ports memory ports alus instruction set size static code size cycle counts con con con 
designs synthesized global objective function eq page fall reasonably design space 
performance cost 
performance cost bounded performance eq hardware cost eq objective functions 
performance objective function results design called maximal machine cycle counts maximal hardware resources static code size instruction set size 
hand hardware cost objective function results design called minimal machine minimal hardware resources largest static code size cycle count 
input pattern invariant objective functions 
designs produced objective functions hardware resource eq instruction set size eq sensitive input patterns load application 
objective function eq produces design input patterns 
true eq 
correlation instruction set size hardware resources 
interesting note objective function rf read port rf write port mem port alu inst 
set size static code size cycle count obj 
value eq cost eq cycle count eq inst 
set size eq obj 
function eq vlsi bam table design space exploration con minimizing instruction set size objective function eq necessarily minimize hardware resources 
cases design minimal instruction set size consumes modest amount hardware resources modest performance cycle count static code size 
minimal instruction set obtained enforcing parallel mop pattern happens frequently single instruction splitting pattern instructions increase instruction set size 
packing frequent mop pattern single instruction requires hardware resources minimal machine 
addition powerful instructions help reducing cycle count static code size 
design synthesized objective function eq smaller cycle count static code size minimal machine 
summary experiments conducted section section suggest architectural properties vary applications typical input patterns 
application specific environments general purpose instruction set processors provide best performance cost tradeoff 
instruction sets hardware resources customized dedicated applications may achieve better performance cost tradeoff 
tools asia necessary design application specific instruction set processors 
comparison approaches difficult fairly compare different approaches automatic instruction set design 
approaches evolve different research disciplines computer architecture compiler high level synthesis 
different concerns machine models problem formulations 
addition publish detailed data experiments 
determining set objective metrics comparing approaches easy task 
qualitative comparison input behavior problem formulation machine model section page section page section page 
section quantitative comparison performed asia holmer closest approaches related 
algorithm speed 
holmer approach generates instructions executing simulator microarchitecture 
execution simulator major overhead approach 
asia improves overhead representing machine microarchitecture specification language section page 
declarative nature specification language helps reducing overhead combining mops instructions 
algorithm run time holmer algorithm published 
informal experiments shown asia speedup times holmer problems similar size hardware resource constraints hardware resources designer 
synthesis domain 
major motivation developing asia extend synthesis domain cover instruction set design hardware resource allocation 
experiments table page shows synthesis times performance improvement iterative approach asia instruction set design hardware resource constraints equivalent holmer approach run times feasible resource configurations 
previous paragraph iteration asia running hardware resource constraints times faster 
synthesis approach 
largest experiment conducted holmer segments page 
average size segments 
algorithm processed cycles instructions week computation private conversation holmer 
asia configured run hardware constraints holmer shown section 
configuration asia processed benchmarks similar size hour workstation hp refer benchmark circuit table page 
asia estimated times faster holmer approach 
addition asia generates complete assembly code benchmarks 
approach advantage validating utilization synthesized instruction set 
holmer approach generate complete assembly code 
relies manual modification compiler backend utilize new instruction set 
approach creates gap design tool assembly code optimality achieved design tool may unnecessarily reproduced final assembly code 
design results 
asia holmer approach synthesize similar instructions 
final instruction sets may vary instructions utilization rates low due difference search methods deciding instructions lower utilization included excluded 
addition asia may generate instruction sets different combination hardware resources suitable characteristics corresponding applications input patterns 
terms cycle counts approaches limitations obtaining precise measures 
discussed previous paragraph holmer approach relies manual estimation 
prolog compiler compiles benchmarks subset synthesized instruction set common vlsi bam instructions 
second performance improvement due synthesized instructions common subset estimated manually browsed execution profiles 
synthesized instruction set results cycles vlsi bam 
asia due lack profiling tools precise cycle counts obtained small benchmarks profiles manually derived 

see paragraph page 

data path vlsi bam support double word memory access branch page cycle counts normalized instruction sets synthesized asia string concatenation program range resources resources 
larger benchmarks cycle counts estimated assuming cycle count proportional static code size 
assumption normalized cycle counts larger benchmarks consists results 
expected actual cycle counts better estimated static code size asia spends efforts optimizing compilation frequently executed basic blocks 
cycle count comparison summarized table 
synthesis microarchitectures compiler backend interfaces small processor instructions small processor minimal achievable latency effort pipeline instruction initiation interval experience pipeline hazards 
show pipeline processor efficiently instruction 
actual cycle counts obtained manually annotated execution profiles see 
different cycle counts results various hardware resource allocation see 
number estimated assumption cycle count proportional static code size 
instruction set normalized cycle count vlsi bam holmer asia table comparison cycle counts vlsi bam holmer approach asia initiation interval pipeline synthesis techniques provide limited synthesis power 
shows pipeline schedule small processor simplified finite state representation loop body pipeline stages 
bubbles represent states state stage sets instruction address mar state stage fetches instruction 
state stage decode state 
opcode forwarded stages 
states stage active clock cycle 

pipeline stages state transitions instructions load store add brn 
instruction pair frequency mar decode mdr stage stage stage stage stage stage mar ac mar ac pc load store add brn pc mdr mar mar mar ac ac inter instruction dependency state transition notations retired state instruction pattern count load add 
instruction pattern count store add 
instruction pattern count brn load 
instruction pattern count add store 
instruction pattern count brn store 


clock cycle active state stage respectively 
states stage conditionally executed opcodes instruction stream 
contents bubbles register accesses interested discussion 
empty bubbles contain rtls interest 
thick bi directional arcs forward backward inter instruction dependencies associated register accesses 
arcs labelled pc mar mar fourteen dependencies forward anti data dependency pc backward data dependency pc shown bi directional arc pc shows instruction pair analysis synthetic benchmark evaluate various resolution strategies 
field instruction pair preceding instruction succeeding instruction 
second field frequency associated instruction pair exists dynamic execution trace 
average instruction level parallelism benchmark instructions access register ac 
observation implies hardware resolutions may preferable software resolutions independent instructions reordered op slots 
hardware software resolution candidates generated dependency 
candidates listed table 
note reordering constraints covered 
example reordering constraints derived instruction pair brn dependency mdr covered ones derived pc 
hardware resolution candidates available duplicate register mar resolving mar mdr forward registers mdr resolving mdr 
weights assigned hardware resolution candidates benchmark analysis respectively implying hardware resolution candidate effective 
column design table lists design software resolutions 
piper reordering constraints 
maximal minimal average reorder distances respectively 
design estimated speedup non pipelined design 
add duplicate register mar resolve output dependencies stage involves instructions add load store 
patterns exist benchmark total frequency 
hardware resolution removes reordering constraint improves performance speedup reduces reordering complexity relative time complexity 
shown column design table 
speedup improvement significant add load store execution trace nop inserted avoid output conflict mar duplicated 
mar special register 
duplicate requires port memory support dependent pair forward backward software resolution reorder constraint succeeding inst reorder distance hardware resolution number weight duplicate register forward register pc pc ac ac mar mar mdr mdr table hardware software resolution candidates column design shows design hardware resolution forward registers 
hardware resolution resolves forward data dependency mdr 
reordering constraints dependency mdr require nop inserted brn 
forwarding register chain consisting registers allocated stage brn carry copy mdr pipeline reaches stage accesses mdr leaving stage immediately available instruction 
strategy introduce anticipated performance improvement 
reordering constraint eliminated 
reason reorder distance brn pairs dominated dependency pc mdr forward registers resolve 
column design design hardware resolutions 
result shows design performance reordering constraints design 
forward registers wasted resources 
situations design design illustrate interaction resolutions different dependencies associated instruction pair expose limitation simple weighting model described section page effective sorting importance hardware candidates insufficient estimating exact performance impacts hardware candidates especially designs combination hardware resolutions 
observation reordering constraints various designs small processor maximal reorder distance remains number constraints decreases slightly hardware resource invested 
maximal reorder distance example derived backward data dependency pc stage applicable hardware resolution 
pipeline synthesis techniques described section page suitable synthesizing circuits pipeline hazards 
small processor synthesis goal keeping instruction initiation interval produce pipelined design flushes pipe cycles soon instruction load store add brn decoded respectively 
design decision slows pipeline significantly speedup non pipelined case case speedup design table 
generate compilation information compiler back simplifies hardware software complication 
sm processor sm processor instruction micro processor general special purpose registers 
advanced computer architecture laboratory university southern california studies prolog compilation design automation 
minimal achievable latency processor effort synthesize processor instruction initiation latency introduce pipeline hazards 
design design design design registers resolution dg duplicate register fg forward register reordering constraint resolution distance minimal reorder distance avg 
reorder dist estimated speedup benchmark non pipelined relative time complexity reorderer compiler back table designs various combinations hardware software resolutions results pipeline hazard resolutions heavily pipelined sm latency table 
designs mal techniques listed table comparison 
able get access tools data produced tools manually derived best knowledge algorithms 
third row latency 
fourth row lists number dependencies dealt instruction initiation latency considered 
number implies difficulty problem 
fifth row lists number hardware resolution candidates duplicate registers forward registers respectively 
sixth row lists hardware resolutions selected designer 
example design designer selected duplicate register forward register resolution possible hardware candidates 
entry means hardware selected 
seventh tenth rows summarize software resolutions respect design decision sixth row 
eleventh row estimated speedup respect non pipelined case 
row relative time complexity reorderer 
experiment took seconds hp workstation 
instruction initiation latency inter instruction dependencies possible hardware resolutions duplicate register forward register selected hardware resolutions reordering max 
reorder distance min 
reorder distance average reorder distance design id table results pipeline hazard resolution sm processor comments drawn results 
techniques outperform techniques 
maximal speedup application benchmark pipelined sm synthesized mal oriented pipeline techniques design instruction initiation latency 
design synthesized execute latency large portion execution time design flushes pipeline necessary unnecessary cases 
achieved speedup 
hand able increase speedup benchmark benchmarks dependency design instruction initiation duplicate forward register hardware resolution 
improvement achieved cost instruction reordering 
compiler backend examine pairs reorder constraints 
second able generate design alternatives consisting different hardware software combinations 
designs provide choices instruction initiation latencies speedups relative compiler backend reorderer time complexities 
designer select appropriate design application environment 
example embedded applications cruise control vehicles software compiled loaded system 
designs higher reorderer time complexity justifiable 
hand designs programming tools compilation happen designs lower reorderer time complexity feasible 
third number dependencies resolved grows fast instruction initiation latency decreased 
higher degree 
synthesized ing larger number pipeline stages larger number pipeline stages interactions stages 
fourth adopting hardware resolutions necessarily reduce number reordering constraints 
reasons adopted hardware may deleted constraint general cases ro load originally covers ro load add ro load sub 
deleting general case special cases get exposed final software resolutions 
fifth set hardware resolution candidates exists minimal subset provides maximal performance gain subset candidate set latency 
currently subset empirically identified estimation experiment 
appears systematic search subset interesting research direction 
shows performance cost metrics candidate designs 
average speedup benchmark non pipelined performance cost tradeoff analysis sm 



design 
designs largest speedup 
shows hardware sizes candidate designs 
hardware size including data control paths estimated rtl level 
able obtain actual size design directly 
roughly data path size design hardware resolution 
control path design may complicated design flush pipeline 
cost software time complexities design smaller due smaller number reorder constraints shown 
note design require reordering zero time complexity 
performance cost hardware software global hardware software tradeoff analysis conducted cases eq page shown 
case assigns emphasis hardware cost tolerates software cost 
design best performance cost ratio case design instruction initiation latency duplicate register reorder constraints 
hand case assigns importance hardware cost sensitive software cost 
case best design design instruction initiation latency duplicate register reorder constraints 
summary shown method able improve throughput pipelined sm 
performance better pipeline synthesis techniques currently available 
method provides better flexibility producing designs different application domains 
designers customize designs embedded systems applications compiled making software cost compilation time affordable shown case application development systems lots applications constantly compiled life time machines making software cost affordable shown case 
processor processor designed years ago aviation control helicopters 
instructions supporting fix point fractional complement operations registers wide variety addressing modes external controls 
built boards 
widely service parts obsolete raise difficult maintenance problem 
customized single chip re implementation desirable 
adas design automation system generate gate array implementation instruction set specification 
piper high level synthesis tool adas explore possible pipeline implementations 
table shows results 
design latency completed piper finish reasonable time weeks 
application benchmark available time experiment 
instruction initiation latency inter instruction dependencies possible hardware resolutions duplicate register forward register selected hardware resolutions reordering max 
reorder distance min 
reorder distance average reorder distance table results pipeline hazard resolution processor show estimated performance respect benchmark 
experiment pipelined latency reorder constraints 
large number reorder constraints primarily due complex instructions normalization fractional numbers multiplication division shifting arbitrary amount bits 
latency reordering constraints required 
latency simple instructions completed single stage 
hardware software resolutions mainly resolving hazards instruction pairs involving complex instructions 
judging experiment fact designed difficulty re compiling applications concluded pipelining software support reordering feasible design style sequential implementation recommended 
chapter summary design instruction set processors includes interdependent subtasks instruction set design microarchitecture design code generation 
design subtasks treated independent ones 
interdependency dealt iteration subtasks 
iteration usually conducted informal ways depending experience ingenuity designer 
order control tradeoffs competing design options application benchmarks represent typical computation executed target processor designer performance cost analysis 
dissertation presents approaches design instruction set processors architectural microarchitectural levels 
subtasks solved integrated way 
architectural level set techniques developed solve combined problem instruction set design hardware resource estimation code generation 
approach takes input application benchmarks architectural template objective function design constraints generates output application specific instruction set resource allocation instantiates architecture template assembly code application benchmarks 
approach integrated problem formulation simultaneous scheduling allocation problem integrated instruction formation process 
specification language architecture template proposed 
preprocessor maps application dependency graphs consisting mops supported architecture template 
mops scheduled time steps subject constraints 
scheduling process instructions formed resources allocated time 
binary tuple describe semantics instructions 
binary tuple key idea links instruction formation scheduling process 
efficient simulated annealing algorithm set move operators manipulate design state solve schedule 
method implemented design automation system asia automatic synthesis instruction set architecture architectural domain tool adas advanced design automation system full range design automation system instruction set processors 
microarchitectural level set techniques developed solve combined problem pipelined microarchitecture design code optimization 
approach takes input instruction set architecture specification application benchmarks generates output rtl implementation pipelined microarchitecture reordering table serves interface reorderer compiler backend target processor 
unique feature differentiates approach microarchitectural behavioral synthesis approaches pipelined instruction set processors problem formulation hardware software concurrent engineering 
key approach capability systematically analyzing potential pipeline hazards applying appropriate resolutions 
extended taxonomy inter instruction dependencies proposed analysis register related pipeline hazards instruction set processors 
hardware software solution resolution pipeline hazards developed 
solutions include forwarding duplicate registers hardware instruction reordering software compiler back 
register related pipeline hazards resolved types inter instruction dependencies involve 
application specific environment combination hardware software solutions tuned characteristics application benchmarks 
design procedure pipeline hazard resolution related algorithms described 
set techniques implemented piper design automation system microarchitectural behavioral domain adas system 
piper ways 
serves post processor asia generating reordering table reorderer rtl implementation microarchitecture instruction set synthesized asia 
detailed information microarchitecture implementation fed back asia refine design process adjusting performance cost estimation 
second piper asia hardware software design tool explore design space pipeline structure software reorderer complexity 
contributions dissertation provides integrated problem formulations problems instruction set design microarchitecture design code generation help better understanding design processes interactions 
formulations efficient algorithms developed design automation systems practical synthesizing designs exploring design tradeoffs competing factors hardware software 
architectural level asia fast prototyping tool determine feasible initial designs new instruction set architecture design tool evaluation existing instruction set architectures application specific environment 
case studies asia applications section page section page 
piper generate register transfer level rtl implementation architecture synthesized asia providing accurate performance cost measures fed back asia guide design process 
addition piper explore tradeoffs microarchitecture complexity compiler backend 
furthermore extend service life improve performance existing instruction set architecture simultaneously re implementing hardware pipeline structures generating interface patch original software environment take advantage pipelined microarchitecture 
examples piper applications section page including synthesis industrial processor 
directions techniques dissertation serve basic framework investigating hardware software interface problems instruction set processor design 
improvements enhancements expand applicability practicality techniques 
implementation limits 
current implementation techniques subject certain limits improved 
interesting architectural properties considered asia 
example multiple word memory access single address way increase memory data bandwidth consuming limited addressing bandwidth 
feature proved effective way increase performance prolog applications 
complication data control dependencies considered 
example value program counter may stored general purpose register data manipulation addition 
operation converts control data computational data turns control related dependency data related dependency 
move related micro operations value data derived program counter may adjusted 
approach asia inefficient locating pruning inferior instructions happens rarely application 
post phase simulated annealing process helpful refine results 
proposed techniques microarchitecture synthesis general support register files multi cycle non pipelined operations data path implementation piper ready features 
part due original assumption adas system registers individually named part due tight schedule developing piper 
lack support register files causes problems integrating piper asia instruction sets synthesized asia may contain register files 
algorithmic limits 
simulated annealing approach asia convenient flexible way fast prototyping 
offers opportunity incremental design improvement works applying operators improve known solution 
difficult control quality may subject convergence problem 
lessons learned current approach possible develop algorithmic approaches maintain fore mentioned advantages providing faster speed solving disadvantages 
solution develop post phase simulated annealing process perform local transformations order improve design quality 
solution provide speed design time 
innovative approaches necessary provide significant speed design time 
realistic application benchmarks 
current approach asia achieved significant speed improvement holmer approach improvements necessary deal realistic application benchmarks operating system kernels compilers simulators cad dsp applications 
straight forward solution select representative portion benchmarks apply cur rent approach synthesize application specific instruction set generate assembly code estimate resource allocation 
code generation process compile unselected portion 
problem caused solution select representative portion investigated 
addition solution relies heavily availability effective retargetable code generator 
global optimization 
current approach asia uses basic blocks boundaries micro operation movement subject limited parallelism available basic blocks 
global optimization performed application benchmarks extract parallelism asia 
forms global optimization branch prediction speculative execution may require dedicated architectural microarchitectural features incorporated machine model complicates performance cost tradeoffs hardware software 
architectural microarchitectural enhancement 
architectural microarchitectural properties considered current implementation register allocation size register file size immediate data 
practical design issues ignored 
issues lot impact performance cost hardware software difficult handle issues properly 
cache interrupt trap important activities modern processors 
activities explicit design system describing application benchmarks instruction set architecture specification implicit design system treating built modules automatically included target processor design system 
implicit case analytical models necessary predict performance influence built modules 
extensions expand uniprocessors 
interesting features include internal opcode control model vliw long instruction word architecture superscalar architecture exploit architectural microarchitectural properties 
demonstrated experiments chapter architectural microarchitectural properties exploited techniques including instruction word width instruction set size instruction set variation performance cost variation compilation complexity classification application benchmarks 
experiments properties manually analyzed synthesis results 
manual approach limits scopes exploitation 
analysis tools required automate analysis processes 
software development environment 
instruction set processor developed set software required test verify run processor simulators compilers 
software related architecture microarchitecture design processors includes instruction level simulators microarchitecture simulators code generators peephole optimizers desirable generate software tools automatically designing new processors software development usually takes equal time hardware development 
redesign feedback information 
advantages integrated design automation systems design information generated tool easily tools improve design quality 
style specifically suitable adas framework design information feedback oriented design redesign 
design details obtained lower level design tools fed back higher levels modify design heuristics estimation 
modification 
reorderer embedded peephole optimizer 
redesign design better quality closer designer intention obtained 
contrary design paradigm complicated algorithms order generate design single design iteration feedback oriented design paradigm relies iterations simple easy control algorithms obtain design 
believed feedback oriented design paradigm suitable architectural level microarchitectural level design 
difficult estimate performance cost accurately levels lower level information feedback oriented approach practical design problems 
construct feedback oriented design paradigm requires information flow user interfaces tools clearly defined 
addition tools separate design engines design rules design sensitive facilitate performance results exploitation feedback concrete design levels 
peas hardware software design system asips proc 
euro dac asip instruction set optimization algorithm functional module sharing constraint proc 
international conference computer aided designs nov alfred aho ravi sethi jeffrey ullman compilers principles techniques tools wesley bose edward davidson design instruction set architectures support high level languages proc 
th annual international symposium computer architecture bennett automated design instruction set bcpl technical report university cambridge computer laboratory bennett methodology automated design computer instruction sets ph thesis university cambridge computer laboratory 
available technical report mauricio jr john paul shen architecture synthesis high performance application specific processors proceedings design automation conference bill bush berkeley machine instruction manual internal technical report advanced computer architecture laboratory university southern california william bush advanced silicon compiler prolog proceedings international conference computer aided design cattell automatic derivation code generators machine description acm transactions programming languages systems vol 
april mike carlton source codes prolog compiler back university california berkeley albert mist design aid programmable pipelined processors proc 
st design automation conference june wei kai cheng long lin code generation dsp processor appear proc 
int symposium high level synthesis may cheng advanced design automation system microprocessors richard donald thomas synthesis pipelined instruction set processors proc 
th design automation conference instruction set mapping performance optimization proc 
iccad nov synthetic benchmark computer dasgupta computer architecture modern synthesis volume john wiley sons dasgupta computer architecture modern synthesis volume john wiley sons dasgupta design theory computer science cambridge university press alvin despain computer architecture news march alvin despain design system asp project proceedings second international workshop vlsi design december srinivas devadas richard newton algorithms hardware allocation data path synthesis ieee trans 
computer aided design vol 
july fisher trace scheduling technique global microcode compaction ieee trans 
computers vol 
gifford spector case study imb system architecture communications acm april robert giegerich formal framework derivation machine specific optimizers acm transactions programming languages systems vol 
july gert goossens jan rabaey vandewalle hugo de man efficient microcode compiler application specific dsp processors ieee trans 
computer aided design vol 
september graham table driven code generation ieee computer august isds program designs computer instruction sets fall joint computer conference prolog benchmark suite technical report ucb csd university california berkeley john hennessy thomas gross postpass code optimization pipeline constraints acm tran 
programming languages systems july pp 
john hennessy david patterson computer architecture quantitative approach morgan kaufmann publishers pp 
john hennessy norman jouppi steven christopher thomas gross design high performance vlsi processor third caltech conference vlsi page john hennessy david patterson computer architecture quantitative approach morgan kaufmann publishers bruce holmer fast prolog extended general purpose architecture proc 
th international symposium computer architecture bruce holmer automatic design computer instruction sets ph thesis univ california berkeley bruce holmer alvin despain viewing instruction set design optimization problem proc 
micro bruce holmer barry hardware software codesign automated instruction set design processor synthesis proc 
hardware software codesign workshop ing huang alvin despain high level synthesis pipelined instruction set processors back compilers proc 
th dac ing huang alvin despain extended classification inter instruction dependency application automatic synthesis pipelined processors proc 
th international symposium microarchitectures nov ing huang alvin despain hardware software resolution pipeline hazards instruction set processors proc 
international conference computer aided design nov ing huang bruce holmer alvin despain asia automatic synthesis instruction set architectures proc 
workshop nara japan oct ing huang alvin despain synthesis application specific instruction sets accepted ieee trans 
cad ing huang alvin despain synthesis instruction sets pipelined microprocessors proc 
st design automation conference june ing huang alvin despain generating instruction sets microarchitectures applications accepted international conference computer aided design april cheng hwang scheduling functional pipelining loop winding proc 
th dac imai integer programming approach instruction implementation method selection problem proc 
euro dac mike johnson superscalar microprocessor design prentice hall gerry kane mips risc architecture prentice hall shirai functional design special purpose processor high level specification description ieice trans 
fundamentals vol 
oct peter architecture pipelined computers mcgraw hill book vipin kumar algorithms constraint satisfaction problems survey ai magazine spring kumar kumar automatic synthesis control units behavior descriptions proc 
th dac fa lee effective methodology functional pipelining proc 
iccad thomas lengauer combinatorial algorithms integrated circuit layout john wiley sons england clifford trevor may pierre paulin instruction set matching selection dsp asip code generation proc 
shi zheng lin cheng hwang yu chin hsu efficient microcode arrangement controller synthesis application specific integrated circuits proc 
iccad mcmahon livermore fortran kernels computer test numerical performance range tech 
rep lawrence livermore national laboratory univ california livermore december michael mcfarland alice parker high level synthesis digital systems proc 
ieee vol 
february myers advances computer architecture john wiley sons pierre paulin john knight force directed scheduling behavioral synthesis asic ieee trans 
computer aided design vol 
june park alice parker software package synthesis pipelines behavioral specifications trans 
cad vol 
march christos papadimitriou kenneth steiglitz combinatorial optimization algorithms complexity prentice hall park rajiv jain alice parker data path synthesis pipelined designs theoretical foundations progress computer aided vlsi design vol 
pages ablex publishing patel davidson improving throughput pipeline insertion delay ieee acm rd ann 
symp 
computer arch ieee ch pierre paulin clifford trevor may dsp design tool requirements embedded systems telecommunications industrial perspective appear journal vlsi signal processing bit microprocessor smalltalk ieee journal solid state circuits sc october johan van gert goossens dirk hugo de man instruction set definition instruction selection asips appear proc 
int symposium high level synthesis may application driven design automation microprocessor design proc 
th dac peter van roy alvin despain high performance logic programming prolog compiler computer january thomas system architect workbench proc 
th design automation conference jun sato integrated design environment application specific integrated processor proc 
iccd spec benchmark suite release october ching long su alvin despain instruction scheduler register allocator prolog parallel microprocessors proc 
international computer symposium ching long su chi ying tsui alvin despain low power architecture design compilation techniques high performance processors procedings ieee compcon efficient algorithm exploiting multiple arithmetic units ibm res 
dev january pp 

jean paul tremblay paul sorenson theory practice compiler writing mcgraw hill book programming manual computer systems peter van roy logic programming execute fast imperative programming ph thesis technical report ucb csd univ california berkeley wong leong liu simulated annealing vlsi design kluwer academic publishers 
