nonlinear modeling forecasting casdagli eubank editors santa fe institute studies sciences complexity xii addison wesley reading massachusetts 
sfi semantics thermodynamics james crutchfield physics department university california berkeley california usa inferring models data leads different changes representation 
subtle profitably ignored 
change affects semantic content resulting model ultimately utility 
model semantic structure determines elements mean observer built uses 
search understanding large scale thermodynamic systems take task modeling evolve semantics syntax lays constructive approach modeling nonlinear processes computation theory 
progresses microscopic level instrument individual measurements scale models built concludes macroscopic view thermodynamic properties 
computational structure model brought analysis clear thermodynamic system support semantic information processing 
internet chaos berkeley edu 
crutchfield nonlinear modeling fact fiction 
ambiguities deficiencies recall attributed dr franz kuhn certain chinese encyclopedia entitled celestial benevolent knowledge 
remote pages written animals divided belong emperor ones trained pigs ones stray dogs included classification mad innumerable ones drawn fine camel brush hair just broken flower vase resemble flies distance 
borges analytical language john wilkins page 
intends model colors nature structure captured determines effort build 
unfortunately intentions directly stated implicit choice representation 
model time series fourier power spectra laplace transforms hidden markov models neural networks radial basis functions 
problems arise 
choice lead models structure 
solution take representation complete sufficiently large model captures data properties error vanishes increased model size 
second problem limitations imposed choices understood vis vis underlying mechanisms 
concerns appropriateness representation 
basis fourier functions complete 
fourier model square wave contains infinite number parameters infinite size 
appropriate representation data simply described state automaton 
completeness necessary property simply address appropriateness conflated 
nonlinear modeling take endeavor distinguished geometric analysis processes represented state space offers hope describing concisely appropriately range phenomena hitherto considered random 
enlarges range representations forces appreciation stages modeling nonlinearity effect behavior 
due nonlinear modeling necessarily effective 
viewpoint appropriateness nonlinear modeling ill defined science discovered nonlinearity product largely assumptions resources available implementor necessarily property process modeled 
question scientific principle transcends operational success nonlinearity allow process perform different classes computation exhibit complex behavior 
think nonlinear modeling contribution appropriate representation response free space carrying weak electromagnetic pulses 
electromagnetic theory different context modeling data 
defines different semantics 
semantics thermodynamics engineering concerns 
contention incorporating computation theory go distance basing modeling principles 
computational mechanics discussion reviews approach questions seeks discover quantify intrinsic computation process 
rules inference game demand ignorance governing equations motion 
model reconstructed data 
follows spirit research program chaotic dynamics introduced rubric geometry times series relies ideas techniques computation learning theories 
set problem modeling nonlinear processes general context continually find convenient consider task 
includes delineating effect measurement apparatus quality quantity data 
appreciation manner data build model requires understanding larger context modeling fixed amount data best explanation 
acceptable model hand number properties derive 
possible estimate entropy complexity underlying process importantly infer nature intrinsic computation 
just statistical mechanics explains macroscopic phenomena aggregation microscopic states procedure modeling viewed going collection microscopic measurements discovery macroscopic observables noted jaynes 
resulting model summarizes relation observables 
surprisingly properties thermodynamic interpretation captures combinatorial constraints explosive diversity microscopic reality 
mind power thermodynamics revealed statistical mechanics 
sections organized address issues just order 
embarking words necessary concerning biases brought development 
framework discrete discrete 
assume modeler starts time series quantized data stay limits quantized representations 
benefit adhering framework appeal computation theory chomsky hierarchy particular giving complete spectrum model classes 
complete refer procedure starting simplest finite memory models moving universal turing machine finite representation powerful computational model class 
words states inference methodology 
addresses principle ambiguity alluded selecting wrong modeling class 
chomsky hierarchy optimal representation finitely expressed language powerful class 
note framework preclude observer employing finite precision approximations real valued probabilities 
mind arithmetic codes represent transmit approximate real numbers 
real numbers algorithms 
mistake confuse real numbers consequence inference methodology need point time solve bayesian maximum crutchfield entropy estimation problem done section 
fact observer constrained build models predictions finite time infinite time access finite resources infinitely precise information 
symbolic problems posed inference methodology serve guide learning process occasionally give insight finite manipulations finite symbolic representations lead finite symbolic answers 
fuzzy fi instruments universe discourse nonlinear modeling consists process measuring apparatus modeler 
relationships components shown schematically 
goal modeler advantage available resources best representation nonlinear process 
section concentrate measuring apparatus 
modeler subject section 
process object modeler ultimate attention unknown hopefully variable picture 
little say viewed governed stochastic evolution equations configuration time noise process governing equations motion 
discussion occasion refer process measure configuration space entropy rate produces information 
measuring apparatus transducer maps accessible states instrument instrument number characteristics modeler control 
primary interaction instrument process measurement space projection say euclidean space dimension number experimental probes 
instrument resolution ffl distinguishing projected states partitions measurement space set ffl ae 
ffl cells 
cell equivalence class projected states indistinguishable instrument 
instrument represents event finding cell label loss generality information indices encoded time serial binary code 
measurement code output data stream 
way time series measurements instrument binary string data stream available modeler 
discretized set symbols 

single measurement modeler instrument returns symbol alphabet time index take binary alphabet 
gives idea fact gross simplification 
discuss important elements left instrument temperature cell dwell time 
explicitly leave specifying embedding dimension process 
secondary statistic estimated topological property model intrinsic view process 
measuring phases example associated topology semantics thermodynamics 
fuzzy instrument binary encoder probes modeler experiment model big channel 
flow information measurements shortest time scales left underlying process right modeler 
task build best representation available data set computational resources 
longer time scales modeler may modify measuring apparatus vary experimental controls process 
actions represented left going arrows 
notice modeler perspective region ambiguity model experiment 
model includes measuring apparatus instantiates modeler biases worth observing 
experiment includes measuring apparatus couples process 
additionally apparatus physical device internal dynamics modeler may unaware incapable controlling 
described measurement partition ffl crisp 
partition cell associated indicator function maps state symbolic label element depending state domain indicator function 
real instrument implements crisp measurement partition 
errors assignment state cell error resulting symbol 
kinds errors consider 
classification error cell misidentified projected state independent location measurement cell 
error rate probability taken instrument effective temperature inst boltzmann fi inst simply fi inst log realistic view classification error 
physical devices analog digital converters fail correct classification near cell boundaries implement exact decision thresholds 
case error uniform partition cells 
solution follows spirit fuzzy logic suggests cell indicator function generalized membership function decays outside cell 
example fuzzy instrument accounts somewhat realistically convolve boundaries cells crisp partition ffl fermi dirac density 
membership function crutchfield fi inst ffl fi inst kp ffl fi inst fuzzy partition inverse temperature cell center measurement space 
zero temperature crisp partition recovered fi ffl fi ffl sufficiently high temperatures instrument outputs random sequences uncorrelated process cell 
algebra fuzzy measurements carried 
simply leave point knowledge fuzzy partition 
particular consequences doing correctly reported 
main result done generality ensuing inference process precluded inferring precise structure source 
second element excluded big channel concerns time spends partition cell 
account additional time series gives cell dwell time state measurement 
special circumstances dwell time constant partition uniform coarse graining 
ergodicity appealed average dwell time 
case important parameter readily available unused 
dwell time suggests instrument parameter frequency response properly dropping fourier modeling bias instrument dynamic response 
short time scales instrument preceding internal states affect resolution determining state dwell time 
simplest case shortest time instrument respond 
passages cell brief detected 
detailed instrumental properties usefully summarized information acquisition rate general form information gain fuzzy partition fi ffl respect process asymptotic distribution projected measurement space 
fi ffl fi ffl jp jjj jq information gain distribution respect assuming ignorance process distribution allows simplification gives measurement channel capacity fi ffl fi ffl ffl fi ffl ffl log ffl log ffl fi ffl entropy cell membership function ffl number cells crisp partition 
high temperature fi ffl fi log fl fl fl fi ffl fl fl fl semantics thermodynamics information acquisition rate vanishes cell membership function widens cover measurement space 
modeler instrument consider done information data stream 
acquisition processing inferring measurement sequence functions modeler 
modeler essentially defined terms available inference resources 
dominated storage capacity computational power certainly include inference method efficacy example 
delineating resources constitutes outline observer builds models 
discussion require development level useful keep mind particular choices elements 
modeler bit string properties just 
modeler concern go useful representation 
modeler needs notion process effective state effective equations motion 
having built model representing components residual error deviation behavior described model estimate effective noise level process 
clear said way noise level sophistication model depend directly data modeler resources 
modeler may access experimental control parameters 
aid obtaining different data streams useful improving model say concentrating behavior effective noise level highest 
central problem nonlinear modeling stated 
instrument number measurements fixed finite inference resources computational structure underlying process extracted 
limits modeling pursuing goal directly helpful point limitations imposed data interpretation 
describing data stream character emphasized individual measurements indirect representations process state 
modeler interprets measurements process state unwittingly forced class computationally powerful representation 
consists finite markov chains states arbitrarily selected state alphabet 
clearer examples 
important early stage interpret measurements content limit quality resulting models 
instrument obviously constrains observer ability extract regularity data stream directly affects model utility 
basic constraints shannon coding theorems 
instrument described transducer considered communication channel process modeler 
capacity channel fi ffl fi process deterministic done hidden markov models 
crutchfield entropy theorem kolmogorov says rate maximized process crisp partition ffl generating 
property requires infinite sequences cell indices finite correspondence process states 
similar result shown hold classes process interest deterministic coupled extrinsic noise source 
note generating partition requirement necessarily determines number probes required instrument 
instrument crisp generating partition shannon noiseless coding theorem says measurement channel capacity higher process entropy case modeler data stream reconstruct model process example estimate entropy complexity 
obtained error levels determined process extrinsic noise level 
shannon theorem channel noise says modeler able reconstruct model effective noise level equivocation induced instrument 
portion dynamics represented signal 
results assume done implicitly shannon existence proofs codes modeler access arbitrary inference resources 
limited corresponding loss quality model increase apparent noise level 
interesting note adopt laplace philosophical stance classical reality deterministic update modern view chaotic instrumental limitations discussed general case 
apparent randomness consequence 
explanatory channel clear statement observer goal needed just estimating best model 
surely simple model desired viewpoint understandability process mechanism far implementation model say control system concerned 
simple model important structure rendering process apparently stochastic highly unpredictable deterministic nonlinear 
trade model simplicity large unpredictability explained terms larger goal modeler explain observer process behavior concise manner detail 
discussion interplay couched terms explanatory channel 
describing view best start simple principles 
contact existing approaches brevity sake best model taken 
access complete probabilistic description modeling universe goal maximize conditional probability model data stream mythical complete probabilistic description available semantics thermodynamics 
observer observer explanation encoder simulator observer 
model error signal encoder simulator explanatory channel 
upper portion illustrates bare channel observer communicates explanation observer lower portion shows detail subchannels making explanatory channel model channel transmits model error channel transmits error signal built observer loaded simulator 
transmitted loads simulator 
develops error signal deviation measurements data stream predicted simulating model 
deviations transmitted precision original individual measurements 
data stream simulating model predictive information error signal 
explains approximation developed factoring bayes rule sjm sjm comments 
foremost probabilities conditioned choice model class second terms right hand side refer single data stream third sjm probability model produces data 
candidate models considered generators data 
sufficient effort sjm estimated 
normalization sjm depends data dropped constant maximizing model class 
shannon coding theorem established event probability optimally represented code length log bits 
search explanation tantamount constructing shortest code data length optimal code fl fl fl fl fl fl log 
bayesian decomposition likelihood follows fl fl fl fl fl fl log sjm log crutchfield resulting optimization procedure described terms explanatory channel 
observers communicate explanation channel 
input explanatory channel modeler sees data stream output explanation denoted shown transmitted subchannels 
modeling channel model communicated 
second error channel error signal transmitted 
portion unexplained model criteria explanation 
explain able original data 
explanation short possible 
length kxk kmk kek bits minimized 
efficiency explanation equivalently model measured compression ratio kxk ksk kmk kek ksk quantifies efficacy explanation employing model cost function space possible models 
optimal model minimizes cost inf illustrates basic behavior cost function model space noteworthy extremes 
model trivial predicts data stream 
case entire data stream sent error channel 
kek ksk large model small kmk 
second complementary extreme occurs data stream taken model information needs sent error channel model explains data stream 
case kmk ksk kek 
overfitting regime model parameters come fit measurement 
view provided explanatory channel turns existence optimal code information source 
semantics decidedly different interprets code consisting parts model error 
main innovation shannon theory 
apparently modern articulation kemeny implementation ockham dictum diversity multiplied necessity 
put rigorous foundation rissanen adapted solomonoff algorithmic theory inductive inference needs universal coding theory wallace domain statistical classification 
notion explanatory channel bit abstraction far modeling nonlinear processes concerned 
implemented effect software system reconstructing equations motion dynamical system time series 
system contained symbolic dynamical system interpreter simulation portion channel 
error signal determined deviation input trajectory deterministic dynamic 
initially averaged assuming deviations iid gaussian variables 
optimal models selected minimizing model entropy consisted variant akaike boltzmann information criterion model order selection 
semantics thermodynamics model optimality 
schematic illustration features cost function model class topology extremely important means dimensional 
right portion graph region overfitting parameters model directly reflect individual measurements 
left portion graph region high apparent randomness model captures little data large prediction error 
model complexity term prediction error term 
view precision error signal different directions tangent space dynamic modulated spectrum associated local lyapunov characteristic exponents 
optimal instruments quantitative search optimal model extends criteria building optimal instruments 
view instrument part model 
basic principles easily summarized 
data 
data 
formally translate criteria instruments 

maximize conditional entropy sji ffl fi data space instruments 
seen readily estimated reconstructed model sji ffl fi 

minimize complexity reconstructed machine inf km sji ffl fi sufficiently large data sets prediction errors dominate model size optimization need performed 
regime early results demonstrated accordance kolmogorov theorem maxima attained generating partitions 
going somewhat theorem showed dependence near maxima smooth 
results showed order conditional entropy maximum determined indication smoothness equations motion 
finite especially small data sets model size plays significant role 
regime criteria optimized crutchfield simultaneously space instruments 
exactly done select optimal instrument left discussion 
picture formalism implementing scientific algorithm experimentation refinement 
drive understand predict process modeler updates instrument 
improved model allows instrument modified remove discovered regularity measurements information put data stream 
way long times instrument transducer provides increasingly informative data stream principle narrows behavior modeled 
consequence coding theoretic view instrument takes account regularity resulting data stream looks noise 
residual regularity requires larger inference resources extract 
high level view inductive inference especially light large number parameters appear 
problem goes heart coding theoretic premises 
complete lack attention functional properties reconstructed models 
exactly properties scientific value 
furthermore value independent amount data find model 
problem reflected formalism ignorance topological metric properties model class range classes 
claim accounted directly measure complexity investigation computational properties individual models 
address section begins focus particular class models 
inference algorithm outlined basic properties described discussion examines utility semantic content 
computation time series sort structure data stream models 
goal prediction preceding assumed natural object reconstruct data series representation instantaneous state process 
unfortunately noted individual measurements indirect representations process state 
instrument simply may supply data adequate quality order discover true states independent amount data 
process effective states accessed 
answer turns generalization reconstructed states introduced assumption process continuous state dynamical system packard contention single time series necessarily contained information dynamics time series 
notion reconstructed state poincare view intrinsic dimension object 
defined largest number successive cuts object resulting isolated points 
sphere dimensions method dimensional cut typically results circle second cut circle isolates points 
packard implemented probability distributions conditioned values time series derivatives 
fact implementation differential geometric view derivatives locally spanning graph dynamic 
reconstruction procedure state underlying process identified conditional probability distribution peaked 
noted shortly presence semantics thermodynamics extrinsic noise number conditions reached conditional distribution longer sharpened 
result process state identified 
width resulting distribution gives estimate effective extrinsic noise level minimum number conditions leading situation estimate effective dimension 
method time derivative reconstruction gives key discovering states discrete times series 
discrete time series state defined set subsequences render conditionally independent past 
observer identifies state different times data stream identical conditions ignorance 
set subsequences state called morph 
definition state reconstruction procedures developed 
brief simplest method consists steps 
length subsequences data stream represented paths depth binary parse tree 
second morphs discovered associating distinct depth subtrees parse tree depth 
number morphs number effective states 
final step state state transitions looking state associated subtrees map parse tree 
procedure reconstructs data stream topological machine skeleton states allowed transitions 
number issues concerning statistical estimation including error analysis probabilistic structure need addressed 
outline suffices purposes 
estimated models referred ffl machines order indicate dependence measurement resolution indirectly instrumental inferential parameters discussed far 
ffl machines product machine reconstruction set states associated set fvg vertices set transitions associated set labeled edges 
formally reconstruction procedure puts limit number machine states inferred 
important cases number infinite phase transitions 
finite set machines finitary 
depiction reconstructed machine labeled directed graph fv 
examples seen shortly 
full probabilistic structure described set transition matrices ae vv 
oe 
denotes conditional probability transition state state observing symbol time delay method appears generalize 
notion state widespread appearing various guises early symbolic dynamics ergodic automata theories 
basic notion state markov chain theory 
crutchfield stochastic machine compact way describing probabilities possibly infinite number measurement sequences 
probability sequence 
recovered machine telescoping product conditional transition probabilities 


vl vn unique start state 
state total ignorance time step take 
sequence 
consists states sequence drives machine 
summarize machine set fv important statistical properties captured stochastic connection matrix vv state state transition probability unconditioned measurement symbols 
construction state outgoing transition 
reflected fact stochastic matrix vv 
clear dropping input alphabet transition labels machine detailed call computational structure input data stream lost 
retained state transition structure markov chain 
interesting fact markov chains proper subset stochastic finitary machines 
examples support contention 
exactly step machine appears 
stationary state probabilities ae oe left eigenvector entropy rate markov chain log measures information production rate bits time step markov chain 
mapping input strings chain transition sequences general finite 
markov chain entropy rate entropy rate original data source 
log 
complexity quantifies information state alphabet sequences log reconstruction hierarchy finitary complexity context discussion implies considering processes finite amount memory 
introduced restriction unnecessary places discussion 
finitary complexity considered context generating partitions known equations motion 
semantics thermodynamics measures amount memory process 
completeness note edge complexity information contained asymptotic edge distribution ae 
oe log quantities independent 
conservation information state leads relation independent quantities modeling process stochastic finitary machine 
entropy measure diversity patterns complexity measure memory taken elementary coordinates analyze range sources 
set quantities derive skeletal structure machine 
dropping probabilistic structure growth rate number sequences produces topological entropy log principle eigenvalue connection matrix formed labeled matrices ae vv ae 
oe state transition topological complexities log kvk log kek computation theory object complexity generally taken size bits representation 
quantities just defined measure complexity reconstructed machine 
seen penultimate section entropies complexities topological metric integrated single parametrized framework thermodynamics machines emerges 
complexity useful stage reflect properties models just described reconstruct 
consider extreme data sources 
highly predictable produces streams second highly unpredictable ideal random source binary symbols 
parse tree predictable source single path 
single subtree depth 
result machine single state single transition simple model simple source 
ideal random source parse tree crutchfield depth full binary tree 
paths appear parse tree binary subsequences produced source 
single subtree morph depth parse tree depths full binary subtree 
machine single state transitions 
simple machine source produces widest diversity binary sequences 
simple experiment serves illustrate complexity measure machine memory capacity 
consider observers model process 
allowed start machine state uses generate binary strings determined edge labels transitions taken 
strings passed observer traces effect copy average information state communicate binary strings 
machine describes say period process outputs strings kvk states 
starts different states learn information process phase period cycle 
log kvk 
bits information process state chooses initial states equal probability 
machine describes idea random binary process definition communicate information structure sequences purpose 
reflected fact noted corresponding machine single state complexity log 
way process complexity amount information controlling start state communicate 
examples serve highlight basic properties complexity term 
predictable random sources simple sense models small 
complex processes view large models 
computational terms complex processes minimum requirement large amount memory revealed internal states reconstructed machine 
importantly memory structured particular ways support different types computation 
sections knowledge meaning show consequences computational structure 
general setting word complexity refer amount information contained observer resolvable equivalence classes 
finitary machines complexity measured quantities labeled notion referred statistical complexity order distinguish chaitin kolmogorov complexity complexity rissanen stochastic complexity equivalent limit long data streams process kolmogorov sinai entropy instrument generating absolutely continuous quantities entropy rate reconstructed machine eq 

accordingly word entropy refer quantities 
measure diversity sequences process produces 
implicit definitions restriction modeler pay computationally random bit 
simply stated overarching goal exact description data stream 
modeling approach advocated modeler allowed flip coin sample heat bath may coupled 
complexity reserved vocabulary refer process structural properties memory types computational capacity 
semantics thermodynamics place review wide range alternative notions complexity discussed physics dynamics literature 
reader referred comments especially citations 
important point notion defined require knowledge equations motion prior existence exact conditional probabilities markov generating partitions state space continuity differentiability state variables existence periodic orbits 
furthermore approach taken differs construction universal codes emphasis model structure 
emphasis brings direct contact disciplines stochastic automata formal language theory thermodynamics 
statistical complexity highly relative concept depends directly assumed model class 
larger setting hierarchical reconstruction finitary complexity measures number states finite state machine representation 
versions appropriate example finitary complexity diverges 
causality points brought concerning reconstructed machines represent 
definition equivalent states machines give minimal information dependency morphs 
respect represent causality morphs considered events 
machines capture information flow data stream 
state follows state cause effect second machine reconstruction produces minimal models prediction error level 
minimality guarantees events morphs intervene error level render independent 
case say information flows amount information flows negative logarithm connecting edge probability 
time natural ordering captured machines 
ffl machine process minimal causal representation reconstructed powerful computational model class yields finite complexity 
knowledge relaxation sections investigate models observer 
observer knowledge process consists data stream current model information build model obtained 
measuring instrument fi ffl facilitate interpretation calculations assume simple data acquisition discipline uniform sampling interval zero temperature measurement partition ffl simplification comes ignoring external factors observer intends needs model assuming observer goal solely optimal prediction respect model class finitary machines 
principle observer knowledge consists reconstruction method various assumptions 
best elaborate 
variables assumed fixed 
crutchfield totality knowledge available observer development moment history 
assumption agency observer moment history optimally encoded available current past measurements model totality knowledge consists parts time series measurements instrument obtained current model current state 
stating points explicitly helps clear upper bound observer know environment 
observer allowed arbitrary computational resources finite information process finite time finite amount structure inferred 
ffl machine representations observer model process 
see role change consider situation model structure kept fixed 
starting state total ignorance process state successive steps machine lead refinement observer knowledge determined sequence measurements 
average increase diffusion information model 
machine transition probabilities especially connected transient states govern observer gains information process longer measurement sequences 
measure information relaxation finitary machines time dependent finitary complexity log shannon entropy distribution fp probability distribution time initial distribution 
concentrated start state 
distribution represents observer state total ignorance process state measurements correspondingly 
simply negative boltzmann function setting 
analogous result theorem stochastic ffl machines converges monotonically sufficiently close time dependent complexity limits finitary complexity 
furthermore observer maximal amount information process observer knowledge equilibrium process vanishes lock lock fixed time characteristic process 
finitary machines convergence behaviors 
illustrated processes period generates isolated zeros allowed generates blocks length bounded 
behavior type illustrated monotonic convergence 
fact asymptotic approach occurs finite time 
case periodic recurrent markov chains refers finite state stochastic processes support subshift finite type 
convergence damped 
second convergence type illustrated asymptotic convergence asymptotic state distribution infinite time 
subcases 
semantics thermodynamics temporal convergence complexity period process triangles markovian process support subshift finite type circles process generates blocks numbers surrounded squares 
monotonic increasing convergence conventional picture stochastic process convergence 
second subcase nonmonotonic convergence 
case starting condition total ignorance leads critically damped convergence single overshoot finitary complexity 
initial distributions oscillations convergence seen 
exact convergence infinite time 
convergence type associated machines having cycles transient states classification symbolic dynamics machines support strictly system sss 
point time initial distribution spreads just recurrent states 
larger time converges 
detailed convergence behavior determined course full eigenvalue spectrum 
interpretation just directly deduced examining reconstructed machine graph aspect immediate initial distribution relaxes infinite number cantor sets sequence space 
finite number cantor sets 
sss shall refer context stochastic systems 
crutchfield structural analysis indicates ratio largely determined amount information transient states 
quantity asymptotically vanishes transient cycles information persists time probability decreases asymptotically 
leads general definition chaotic periodic phase phase locking 
phase machine point time current state 
types phase interest 
process phase second observer phase refers state observer model having read data stream time 
observer fi locked process lock fi 
occurs locking time lock longest time fi 
process periodic notion locking standard engineering 
applies chaotic processes corresponds observer knowing state process measurement predicted exactly 
classes knowledge relaxation lead quite different consequences observer processes considered small number states share single symbol statistics damped case observer knows state underlying process certainty finite time 
critically damped situation observer approximate knowledge times 
example setting fi leads locking times shown table 
ability observer infer state depends crucially process computational structure viz 
topological machine sss 
presence extrinsic noise observational noise modify systematically 
worthwhile contrast machine model model histograms look tables process 
models sufficient storage exactly represent length sequence probability distribution 
predictions length sequences 
histogram model store probabilities length sequence 
requires bins containing bit approximation rational number bits numerator denominator 
total bits includes indicator length sequence 
machine model see store current state approximate rational numbers transition probabilities bits numerator denominator 
gives model size bits 
observers model sequence 
predict event fourth symbol 
histogram model predicts machine model predicts histogram model gives wrong prediction 
says fourth symbol uncertain completely predictable 
similar analysis prediction measuring semantics thermodynamics locking times level process locked time period isolated blocks table fi locking times periodic isolated processes 
note locking time substantially longer depends fi 
locking times indicate times asymptotic convergence achieved 
observer knows state underlying process certainty locking times 
observer partially phase locked knowledge process state information 
system generates sequences 


length parity 
states fa cg 
state inscribed circle start state edges labeled measurement symbol conditional transition probability 
having observed shows opposite 
histogram model predicts fact predictable 
example illustrative superiority stochastic machine models histogram similar look table models time dependent processes 
fact processes finite memory finite size sequence histogram give correct predictions 
order physical relevance slow convergence plausible example taken logistic map parameter value 
logistic map iterated mapping unit interval rx control parameter governs degree nonlinearity 
parameter value chaotic behavior governed absolutely continuous invariant measure 
consequence statistical properties particularly behaved 
parameter values determined condition iterates map maximum asymptotically periodic 
parameter value interest root 
solving numerically yields 
symbolic dynamics produced measurement partition partition generating resulting binary sequences completely capture statistical crutchfield machine reconstructed parsing forward presentation order binary sequence produced generating partition logistic map parameter value 
machine reconstructed parsing reverse presentation order binary sequence produced generating partition logistic map parameter value 
properties map 
words mapping infinite binary sequences points attractor 
reconstructing machine long binary sequence direction symbols produced gives state machine shown 
stochastic connection matrix reconstructing machine binary sequence opposite direction gives reverse time machine shown 
connection matrix semantics thermodynamics observer sees average forward reverse lag time terms complexity convergence data plotted negative lag time axis 
note convergence characteristics differ time directions asymptotic complexity values equal 
notice transient state recurrent states compared recurrent states suggests likelihood difference complexity convergence 
shows case plotting positive negative times respectively 
convergence behaviors differ type asymptotic values complexities bits bits 
occurs despite fact entropies machines bits time unit bits time unit 
data stream equally unpredictable time directions observer learns process state different ways obtains different amounts state information 
difference bits measure computational irreversibility process 
indicates process symmetric time observer viewpoint 
example serves distinguish machine reconstruction derived quantifiers complexity subsequence measures point mutual information excess entropy 
crutchfield measurement semantics chaos shannon communication theory tells information measurement gives 
meaning particular measurement 
sufficient structure developed point introduce quantitative definition observation meaning 
meaning seen intimately connected hierarchical representation 
concerns meaning arises crossing single change representation entire hierarchy 
universe consisting observer thing observed natural semantics 
semantics describes coupling occurs measurement 
attendant meaning derives dual interpretation information transferred time 
emphasized measurement indirect representation underlying process state second information updates observer knowledge 
semantic information processing occurs measurement turns relationship levels representation event 
meaning message course depends context information available 
context inappropriate observation basis understood 
meaning 
appropriate observation understood 
understood content message largely unanticipated observation significant highly obvious message 
framework context set model held observer time measurement 
take example assume observer capable modeling class stochastic finite automata 
particular assume observer estimated stochastic finite automaton process sufficiently long know current state certainty 
time observer measures symbol measurement forces disallowed transition meaning lies outside contexts morphs captured current model 
observer clearly know process doing 
formally response observer reset machine initial state total ignorance 
measurement associated allowed transition anticipated amount meaning log denotes machine state measurement brings observer knowledge process state 
corresponding morph probability associated state asymptotic probability 
meaning content observation particular morph model updated state corresponds 
view assume estimated machine deterministic sense automata theory transitions state uniquely labeled 
simplifies discussion avoiding need define graph indeterminacy quantitative measure ambiguity 
ambiguity observer arises model stochastic nondeterministic automata 
semantics thermodynamics measurement selects particular pattern palette morphs 
measurement meaning selected morph amount meaning determined probability 
clarify notions consider example source produces infinite binary sequences regular language described expression assume choice implied uniform probability 
observer infinite sequence type reconstructs stochastic finite machine shown 
observer discovered morphs states fa cg 
meaning morph 
consider recurrent states state associated having seen number having seen odd number 
meaning odd 
pair fb cg recognize parity data stream machine accepts strings substrings form 
parity 
meaning state 
long observer knowledge process state remains state number parity unknown seen force transition parity state state transient serves synchronize recurrent states data stream 
indicates meaning content individual measurement terms state predecessors bring machine 
giving quantitative analysis time dependence state probabilities calculated 
recall state probabilities updated stochastic connection matrix initial distribution 
timedependent state probabilities transforms 

ae 
time disallowed transition forced current state reset start state reset distribution representing total ignorance 
quantitative degree meaning particular measurements 
consider possibilities possible contexts current states possible measurements 
steps reset observer 
sync state measures sync log log simplify 
best formal representation meaning uses set theoretic structure machine induces set observed subsequences 
turn formulated lattice theory machines 
crutchfield observer semantic analysis parity source observer state measures symbol interprets meaning degree meaning bits amount information bits unsynchronized infinity synchronize odd number number number confusion lose sync reset start state infinity table observer semantics measuring parity process 
sync state measures sync log log sync log bits 
state measures log log log bits 
state measures log log log log bits 
odd state measures odd log log odd log log bits 
odd state measures disallowed transition 
observer resets machine odd log log 
scheme states visited time state time 
assuming disallowed transitions observed infinite time degrees meaning observer 
sync state measures sync log 
sync state measures sync log log bits 
state measures log log bits 
state measures log log bits 
odd state measures odd log log bits 
odd state measures disallowed transition 
observer resets machine odd log log 
table summarizes analysis infinite time 
includes amount information gained making specified measurement 
simply negative binary logarithm associated transition probability 
semantics thermodynamics similar definitions meaning developed levels reconstruction hierarchy 
example just concerns semantics measurement symbol level stochastic finite automaton level 
meaning appears change representation events 
change measurement considered respect population measurements important special case arises 
view shannon information concerns degenerate meaning obtained representation class 
consider information events set possibilities occurrence governed arbitrary probability distributions fp assume structural qualifications representation class 
shannon self information log gives degree meaning log observed event respect total ignorance 
similarly information gain log pe qe gives average degree meaning distributions 
representation levels degenerate events 
shannon information gives degree meaning event respect set events respect observer internal model course model taken collection events histogram lookup table 
vacuous re interpretation essential general meaning degenerate case 
main components meaning defined emphasized 
information quantified 
second conventional uses shannon information natural special case 
third derives fundamentally relationship levels abstraction 
message different connotations depending observer model general constraint model level reconstruction hierarchy 
model reconstruction considered time dependent process moves hierarchy discussion suggests concrete approach investigating adaptive meaning evolutionary systems emergent semantics 
parity example explicitly said state measurement meant 
parity human linguistic mathematical convention compelling naturalness due largely simplicity 
low level organism need literary interpretation stimuli 
meaning say model states state sequence seen output preprocessor derives functionality organism part environment evolutionary developmental history 
said way absolute meaning nature quite complicated contingent concept 
absolute meaning derives global structure developed space time 
analysis captures representation level level origin local meaning 
tension global local entities bit new nonlinear dynamics 
subtlety consequence 
analogous insights sure follow semantic analysis large hierarchical processes 
preprocessor transducer version model takes input symbols outputs strings state alphabet crutchfield machine thermodynamics atomistic view nature ancient times largely unsuccessful raw combinatorial complication entailed connected macroscopic phenomena 
founding thermodynamics principles statistical mechanics major influence eventual acceptance 
laws thermodynamics give coarsest constraints microscopic diversity large particle systems 
view moving microscopic dynamics macroscopic laws applied task statistical inference nonlinear models 
appropriate discussing microscopic data measurement sequences reconstruction machines discussion largest scale description machine thermodynamics 
gives concise description structure infinite set infinite sequences generated machine probabilities 
analogy conventional thermodynamic treatment microstates focusing different subsets allowed sequences 
step basic identification microstates 
consistent machine reconstruction goal approximate process internal states microstates modeling individual measurement subsequences 
consider set sub length subsequences occurring length data stream probability subsequence sub estimated number occurrences data stream 
connection physical interpretation thermodynamics follows identifying microstate energy self information log 
improbable microstates high energy 
energy macrostates grouping subsequences energy subsets 
sub point distributions microstate distribution induced distribution energy macrostates 
thermodynamic structure captured parametrized microstate distribution 
fi fiu 
fi fi attenuates microstate weight solely energy 
role inverse temperature plays classical thermodynamics 
partition function fi subl fiu 
subl fi 
gives total signal space volume distribution fi fp 
fi sub way statistical mechanics explains thermodynamic properties constraints volume changes various conditions 
going individual measurements data stream subsequences change representation raw data parse tree hierarchical data structure 
semantics thermodynamics definitions extensive system size dependent thermodynamics follows directly 
example infinitely long data stream average total energy length sequences subl 
fi fi subl 
fiu 
fi subl 
fi log 
thermodynamic entropy fi subl 
fi log 
fi fi shannon information microstate distribution 
definitions extensive dependent thermodynamic parameters closed system thermally coupled environment 
total energy exists forms 
important thermal energy ts thermodynamic entropy temperature 
remaining free energy stored reversible process retrievable 
closed system helmholtz free energy fundamental equation expressing energy conservation ts modeling observer put contact process attempts collecting measurements estimating models come inferential equilibrium finding optimal model 
thermodynamics describes situation information data stream exists forms 
randomized second responsible deviation equilibrium 
thermodynamic analog helmholtz free energy fi log fi measures amount nonrandom information ensemble described fi temperature fi temperature limits interest preceding thermodynamics simply described 

equilibrium fi original subsequence distribution recovered 

information fi helmholtz free energy vanishes fi 
infinite temperature fi microstates excited equally probable 
partition function equal total number microstates effective signal space volume largest limit 
average energy just sum microstate energies 
entropy simply depends multiplicity microstates log free energy diverges 

zero temperature fi energetic probable microstate dominates 
ffi signal space volume smallest entropy vanishes 
crutchfield goal observer build model reproduces observed data stream including probability structure 
thermodynamic terms model minimize helmholtz free energy 
machine reconstruction produces stochastic automaton inferential equilibrium data 
described 
cover basic methods investigate thermodynamic structure machine invariant subsequences distributions 
dividing extensive quantities volume yields thermodynamic densities 
thermodynamic limit densities asymptotic growth rates extensive parameters obtained 
growth rates intensive 
directly computed reconstructed machine 
sense machine intensive thermodynamic object effective computational equations motion 
obtain intensive thermodynamics stochastic machine new set fi parametrized transition matrices defined fi vv fii 

log 
information obtained making transition state state symbol note parameter fi varied transition probabilities original machine different weights shape transitions maintained 
intensive analog effect fi extensive distribution fi 
thermodynamic properties determined parametrized connection matrix fi fi quantities required matrix 
principal eigenvalue fi sup kvk fi associated right eigenvector fi fi note fi stochastic matrix 
fact fi vv fi fi fi directly describe example probabilities subset sequences associated relative transition weightings fi course fi 
equilibrium machine stochastic connection matrix denoted fi produces sequences relative weights fi recall state macroscopic equilibrium determined variational principles 
total entropy equilibrium state minimizes energy 
total energy maximizes thermodynamic entropy 
semantics thermodynamics entropy representation equilibrium machine maximal thermodynamic entropy subject constraints imposed fi nonzero edge probabilities allowed vary 
fi describes process allowed subsequences thermodynamic equilibrium temperature 
shannon entropy maximization formula fi fi fi diagonal matrix components diagonal 
stochastic matrix principal eigenvalue unity 
associated left eigenvector vs fi normalized probability gives asymptotic state distribution 
entropy rate seen previous section fi log fi vv fi complexities fi log fi log metric fi topological fi quantities directly recovered 
relation fi fi fi constrains entropy rate complexities 
physically speaking log plays role interaction energy states fi related inverse temperature 
support set sequences topological machine exists temperatures varying fi measure process fi different paths machine equivalently different subsets sequences 
subset weight changes relative dictated fi elements 
crutchfield limit long sequences partition function growth rate governed maximal eigenvalue fi machine matrix fi fi fi machine helmholtz free energy density lim fi log fi fi log fi thermodynamic entropy fi boltzmann constant 
basic thermodynamic relation total energy density readily computed noting ts fi fi log fi identification fi entropy representation function computed eq 
eq 
determines thermodynamic potential arc fi model space consistent stochastic machines 
consistent machines having set allowed sequences observed data stream 
fixed fi equilibrium machine estimated eq 

equilibrium refers closed isolated system specified fixed temperature fixed average energy contrast graph concerns closed system contact energy reservoir temperature fi gives entropies energies family machines fi equilibrium machine occurs fi free energy vanishes unconstrained information thermal randomized 
thermodynamic analog cost function model space shown 
computed thermodynamic limits long data stream long sequence length ii represents different optimizations temperature temperatures 
view statistical estimation developed large deviation theory 
suggests different appreciation sinai ruelle bowen thermodynamic formalism invariant measures dynamical systems foundation nonlinear modeling 
independent modeling interpretation eq 
eq 
give direct way study macroscopic properties sequences produced stochastic machine 
particular shape determines variation entropy energy subsets sequences semantics thermodynamics fluctuation spectrum thermodynamic entropy density versus internal energy density machine invariant process 
indicates directly range fluctuations observed sequences 
examples serve illustrate points 
figures show fluctuation spectra thermodynamic entropy density versus energy density machines notice large difference character spectra 
indication computational irreversibility underlying process 
topological entropies spectra maxima fi metric entropies unity slope point curves fi despite 
energy extremes umin umax thermodynamic entropies min umax differ significantly due irreversibility 
way section final thermodynamic analogy mentioned 
experimentally accessible measures complexity excess entropy 
total excess entropy fi coarse measure average amount memory measurement sequence randomized information 
defined follows fi fi fi fi fi log fi crutchfield fluctuation spectrum thermodynamic entropy density versus internal energy density machine total renyi entropy fi fi log fi renyi entropy rate 
referred free information easily seen analogous free energy 
free information legendre transform renyi entropy fi replaces length dependence intensive parameter fi subsequence length associated volume thermodynamic pressure associated fi free information approximation finitary complexity seen type free energy 
detailed development machine thermodynamics 
preceding outline hopefully serves indicate bit utility interest 
summarize thermodynamic analysis suggests total information data stream extracted machine reconstruction interpreted observer model exists forms thermal associated information processing 
randomness data measured thermodynamic entropy 
second structure data causes deviate simple thermal equilibrium available mathematical 
consist communicating process observer information transmission space 
available static memory semantics thermodynamics information transmission time 
usefully available genuine computation support semantic information processing 
science data compression 
thinking back explanatory channel considerations lead disagree philosophical premise implicit universal coding theory approach nonlinear modeling 
accept mathematics optimization criteria semantics appears wanting 
science data compression 
structure models ultimately important encoders decoders efficient encapsulation experience 
limit large data streams positive entropy processes realm universal coding theory model essentially ignored prediction error dominates 
day models independent amount data originally infer 
point emphasized preceding analysis effects computational structure knowledge relaxation semantic structure 
naked mathematical objects typically associate meaning imply semantic structure act measurement 
semantics gives models scientific value 
preceding discussion outline attempted put issues sufficiently large arena stand 
dynamical systems diverse complicated phenomenology rapidly better understood 
enrich view natural phenomena necessarily deepen 
contrast simple specification creation apparent complexity leads computational mechanics 
computation theory development appears theory par excellence structure 
gave foundation theory randomness 
success blind pressing need constructive measures complexity physical chemical biological economic systems go randomness 
descriptions complexity need pay randomness 
true statistical inference applied nonlinear modeling thermodynamic evolutionary systems 
primary lessons nonlinear dynamics effective randomness cheap easily regenerated 
shows ideal randomness just ideal expensive principle impossible objectively obtain 
fortunately nature need 
randomness effective task hand required 
tension randomness order result complexity part problem domain thermodynamics 
phase transitions especially critical phenomena primary evidence nature delicate balance 
observation question presents nonlinear modeling types computation supported physical systems phase transitions interface order chaos 
away critical processes classical thermodynamics forms solid basis build nonlinear modeling 
extent statistical mechanics successful describe behavior thermodynamic system suffices communicate equations state approximate macroscopic parameters possibly force laws governing microscopic constituents 
exact description undesirable impossible 
constructive answer 
crutchfield optimal modeling 
just mentioned question framework 
having described analogy thermodynamics optimal modeling deeper problem suggests 
classical thermodynamics description critical phenomena due confusion observable average value order parameter value 
universal coding theoretic association optimal model eq 
fail processes low entropy near phase transitions 
especially exaggerated critical processes exhibit fluctuations scales 
cases fluctuations dominate behavior averages need centered value observable 
occurs high complexity processes described stochastic context free context sensitive grammars requisite internal computational capacity cause convergence observable statistics deviate law large numbers 
having told modeling story somewhat briefly hope little clearer view microscopic processes offered statistical mechanics needs augmented 
examples analyzed demonstrate computational structure semantic content processes entirely masked articulated conventional framework 
exactly properties form functional substrate learning evolutionary systems 
claim investigation intrinsic computation performed dynamical systems prerequisite understanding physical systems spontaneously take task modeling nonlinear environments 
believe engineering products program forecasting design control follow naturally 
greatest writes point autonomous 
true 
borges avatars page 
express appreciation discussions karl young jim hanson 
due santa fe institute author supported robert maxwell foundation visiting warm hospitality writing review 
funds onr contract nasa ames university interchange nca afosr contributed 
semantics thermodynamics 
akaike 
objective bayesian models 
ann 
inst 
statist 
math 

angluin smith 
inductive inference theory methods 
comp 
surveys 

birkhoff 
lattice theory 
american mathematical society providence third edition 

blahut 
principles practice information theory 
wesley 

borges 

simon schuster new york 

bowen 
equilibrium states ergodic theory volume lecture notes mathematics 
springer verlag berlin 


entropy complexity trajectories dynamical system 
trans 
moscow math 
soc 


large deviation techniques decision simulation estimation 
new york 

chaitin 
length programs computing finite binary sequences 
acm 

crutchfield 
noisy chaos 
phd thesis university california santa cruz 
published university microfilms intl minnesota 

crutchfield 
reconstructing language hierarchies 
editor information dynamics new york 
plenum 

crutchfield mcnamara 
equations motion data series 
complex systems 

crutchfield packard 
symbolic dynamics noisy chaos 
physica 

crutchfield young 
inferring statistical complexity 
phys 
rev 

crutchfield young 
computation onset chaos 
zurek editor entropy complexity physics information volume viii sfi studies sciences complexity page 
addison wesley 

crutchfield young 
ffl machine spectroscopy 
preprint 

ellis 
entropy large deviations statistical mechanics volume der mathematischen wissenschaften 
springer verlag new york 

fraser 
chaotic data model building 
preprint 

grassberger 
quantitative theory self generated complexity 
intl 
theo 
phys 

hartmanis stearns 
algebraic structure theory sequential machines 
prenticehall englewood cliffs new jersey 

hopcroft ullman 
automata theory languages computation 
addison wesley reading ma 


scientific reasoning bayesian approach 
open court la illinois 
crutchfield 
jaynes 
stand maximum entropy 
delaware symposium foundations physics volume berlin 
springer verlag 

kemeny 
simplicity induction 
phil 
rev 


finitary measures finite type systems 
msri journal page 

kolmogorov 
new metric invariant transient dynamical systems automorphisms lebesgue spaces 
dokl 
akad 
nauk 
sssr 
russian math 
rev vol 


kolmogorov 
approaches concept amount information 
prob 
info 
trans 

lempel ziv 
complexity individual sequences 
ieee trans 
info 
th 

li vitanyi 
kolmogorov complexity applications 
technical report cs voor wiskunde en informatica universiteit van amsterdam 

li 
generating non trivial long range correlations spectra replication mutation 
preprint 

lindgren 
complexity measures cellular automata 
complex systems 

marcus 
systems encoding data 
ieee transactions information theory 


large deviation statistical physics 
prog 
theo 
phys 

packard crutchfield farmer shaw 
geometry time series 
phys 
rev 

parry 
classification problems ergodic theory volume london mathematical society lecture notes series 
cambridge university press london 

poincare 
science hypothesis 
dover publications new york 

rabiner 
tutorial hidden markov models selected applications 
ieee proc 

rissanen 
stochastic complexity modeling 
ann 
statistics 

ruelle 
thermodynamic formalism 
wesley reading ma 

shannon weaver 
mathematical theory communication 
university illinois press champaign urbana 

wallace freeman 
estimation inference compact coding 
statist 
soc 


wolfram 
computation theory cellular automata 
comm 
math 
phys 

zadeh 
fuzzy sets applications selected papers 
wiley new york 

ziv 
complexity coherence sequences 
editor impact processing techniques communications page dordrecht 
nijhoff 

zurek 
thermodynamic cost computation algorithmic complexity information metric 
preprint 
