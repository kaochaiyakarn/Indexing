advances kernel methods support vector learning edited bernhard scholkopf christopher burges alexander smola mit press cambridge massachusetts london england contents preface ix support vector learning roadmap theory remarks support vector method function estimation vladimir vapnik generalization performance support vector machines pattern classifiers peter bartlett john shawe taylor bayesian voting schemes large margin classifiers nello cristianini john shawe taylor support vector machines reproducing kernel hilbert spaces randomized grace wahba geometry invariance kernel methods christopher burges annealed vc entropy margin classifiers statistical mechanics study manfred opper entropy numbers operators support vector kernels robert williamson alex smola bernhard scholkopf vi ii implementations solving quadratic programming problem arising support vector classification linda kaufman making large scale support vector machine learning practical thorsten joachims fast training support vector machines sequential minimal optimization john platt iii applications support vector machines dynamic reconstruction chaotic system davide simon haykin support vector machines time series prediction klaus robert muller alex smola gunnar ratsch bernhard scholkopf jens kohlmorgen vladimir vapnik pairwise classification support vector machines ulrich kre el iv extensions algorithm reducing run time complexity support vector machines edgar osuna federico girosi support vector regression anova decomposition kernels mark stitson alex gammerman vladimir vapnik vovk chris watkins jason weston support vector density estimation jason weston alex gammerman mark stitson vladimir vapnik vovk chris watkins combining support vector mathematical programming methods classification kristin bennett kernel principal component analysis bernhard scholkopf alex smola klaus robert muller vii index combining support vector mathematical programming methods classification kristin bennett mathematical sciences department rensselaer polytechnic institute troy ny usa rpi edu www math rpi edu examine relationship support vector machines svm classification family mathematical programming methods mpm primarily stemming mangasarian method pattern recognition 
mpm svm share canonical form allowing approaches easily combined 
show dissimilarities mpm svm approaches generate new methods nonlinear discrimination support vector decision trees multicategory learning 
support vector decision trees decision trees decision support vector machine 
multicategory learning approach handing classification problems classes 
computational studies altering original mpm include principles statistical learning theory improved generalization 
show mathematical programming models tools allowed develop rapidly practical approach solving transduction problem theoretical principles risk minimization 
basic idea transduction predict class set unlabeled testing points estimating classification function labeled training set 
semi supervised svm includes labeled training data unlabeled test data formulated mixed integer program 
commercial optimization packages solve moderately sized problems 
computational results indicate semi supervised approach improve generalization problems performed significantly worse baseline supervised svm 
combining support vector mathematical programming methods classification chapter investigate relationship support vector machines svm classification family mathematical programming methods primarily stemming mangasarian method pattern recognition msm mangasarian 
focus family mathematical programming methods referred mpm existing optimization classification methods literature closely related svm 
mpm svm developed independently share canonical form 
great potential exists interaction approaches 
combining statistical learning theory concepts svm ideas kernels mpm potentially new svm methods derived 
model formulation ideas mpm develop rapidly new algorithms statistical learning theory 
overview optimization methods classification msm robust linear programming rlp method bennett mangasarian 
prior reviews cover mpm classification clustering function approximation mangasarian bradley 
potential integration svm mpm exists areas 
chapter concentrate classification problem 
starting linear classification case see common roots mpm svm methodologies branched different directions 
examining dissimilarities new opportunities integrated approaches apparent 
specifically chapter examine mpm svm combined problems nonlinear discrimination decision trees multicategory classification 
illustrate idea statistical learning theory transduction risk minimization vapnik quickly converted practical algorithm ideas mpm 
results drawn primarily existing bennett bredensteiner bennett bennett demiriz 
primary goal chapter illustrate current potential integration mpm svm making mpm accessible common format pointing possibilities 
possible notation chapter exceptions 
original svm separating plane defined delta 
notation consistent mpm literature delta gamma fl 
forms exactly equivalent fl gammab 
clarity problem formulations divide training points respective classes 
psi classes denote classes psi example class case sets defined fx fx fx fx gamma cardinality set denoted ja mpm methods classification mpm methods classification mangasarian method pattern recognition mangasarian similar derivation generalized portrait method vapnik chervonenkis 
mangasarian proposed finding linear discriminant linearly separable problems solving optimization problem max ff fi ff gamma fi subject delta ff delta fi kwk method problem constructs parallel supporting planes supporting class maximizes separation margin planes 
final optimal plane delta ff fi generalized portrait method 
problem difficult solve formulated constraint kwk nonconvex 
svm formulation viewed transformation ff gamma fi kwk minimized 
msm mangasarian proposed infinity norm kwk max jw norm 
solving linear programs lps optimal solution polynomial time 
lp component weight vector fixed gamma forcing constraint kwk satisfied 
linear programs max ff fi ff gamma fi subject delta ff delta fi gamma second set lps consists problem gamma replacing constraint 
solution lp maximal objective value optimal solution problem kwk mangasarian 
generalized portrait method msm works linearly inseparable case 
training half space delta fi contain training points half space delta ff contain training points remaining margin may contain mixture points classes 
problem recursively points falling margin msm constructs piecewise linear discriminant function 
interest msm primarily historical similarities svm msm set pattern mpm address nonlinearly separable problems 
msm successfully initial automated breast cancer diagnosis system university wisconsin madison wolberg combining support vector mathematical programming methods classification psfrag replacements piecewise linear separator nd pair planes st pair planes piecewise linear discriminant constructed msm mangasarian mangasarian method performs poorly noisy data sets minimizes largest error class 
idea maximizing margin separation generalized portrait method msm different norms 
nonlinear case msm applied recursively yield piecewise linear discriminant function 
mangasarian observe nonlinear discriminants constructed mapping input attributes higher dimensional space mention kernel methods 
msm tolerant noise bennett mangasarian proposed robust linear programming method rlp bennett mangasarian linear program min fl ffi subject delta gamma fl robust linear programming method ffi fixed misclassification cost associated point original rlp method ffi ja points ffi ja points choices ffi ensure meaningless null solution unique minimum problem 
smith proposed problem ffi may unique optimal solution smith formulation 
course rlp identical soft margin hyperplane formulation absence capacity control term kwk maximizes margin separation 
norm objective term kwk added rlp result original quadratic program svm 
mangasarian meyer know exists constant optimal solution svm optimal solution rlp ffi 
solution rlp unique svm solution mpm methods classification sufficiently large optimal solution rlp norm norm objective term kwk added rlp generalized construct svm variation norm capacity control min fl kwk gamma ffi subject delta gamma fl gamma ffi fixed misclassification cost associated point relative weight margin maximization term 
close emphasis placed obtaining large margin 
close emphasis reducing misclassification error 
problem equivalent parametric linear program primal rlp capacity control min fl gamma ffi subject delta gamma fl gamma gammas commercial linear programming package cplex cpl simplex interior point algorithms solve efficiently dual rlp problem murthy dual rlp capacity control min ff ff subject gamma gamma ff gamma ff ff ffi dimensional vector ones 
optimal fl lagrangian multipliers constraints problem 
linear programming packages provide optimal primal dual solutions 
rlp norm capacity control investigated papers bennett bredensteiner bredensteiner bradley mangasarian bennett 
adding capacity control rlp improve generalization 
empirical evidence norm norm formulation produces superior generalization 
open question theoretical generalization differences 
chapter refer norm form rlp norm form svm 
names combining support vector mathematical programming methods classification linear programming support vector machine bradley mangasarian 
benefit svm rlp kernels easily introduced dual problem order nonlinear discriminants discussed chapter 
new approaches incorporating kernels linear programming methods developed chapter 
major benefit rlp svm dimensionality reduction 
rlp svm minimize magnitude weights rlp forces weights 
sparsity characteristic norm compared norm basis pursuit chen 
second benefit rlp svm solved linear programming quadratic programming 
state art general purpose linear program solvers efficient robust capable solving larger problems quadratic program solvers 
original training data sparse resulting lp formulation sparse typical linear program solvers constructed exploit sparsity 
sparse training data hessian svm quadratic program dense 
dense quadratic programs difficult 
greater effectiveness linear versus quadratic programming algorithms definitely true general purpose solvers optimization methods adapted svm problem structure ones discussed book bradley mangasarian may help alleviate difference 
linear programming formulations glover popularly 
extensions basic msm rlp methods 
papers mangasarian bradley bredensteiner contain interesting reviews 
example related problems feature selection constructing best linear discriminant minimum number attributes misclassification minimization explicitly minimizing number points misclassified bradley mangasarian bradley bredensteiner bennett bennett bredensteiner 
problems require minimization metric counts number nonzero components vector 
np hard problems kann approximate answers may nonconvex optimization techniques 
maximum feasible subsystems linear relations applied problems kann 
techniques potentially applicable svm related problems 
mpm svm significantly differed approach nonlinear discrimination multicategory discrimination 
nonlinear discrimination svm perform linear discrimination higher dimensional space kernels problem tractable 
starting msm primary mpm approach linear discriminants construct piecewise linear discriminants decision tree 
section investigate svm combined mpm decision tree algorithms 
note mpm perform nonlinear mappings higher dimensional space notably polynomial neural network approaches roy 
roy mukhopadhyay 
section examine svm mpm approaches multi nonlinear separation decision trees category discrimination 
multicategory discrimination problem classifying points classes 
approaches combined yield new methods 
nonlinear separation decision trees primary mpm approach nonlinear separation construct piecewise linear discriminant functions 
functions decision trees 
approach svm 
original msm viewed producing decision tree specialized structure 
rlp successfully decision tree algorithms bennett 
consider decision trees decision support vector machine 
results applying learning theory decision trees show tradeoff structural complexity tree depth number nodes complexity decisions shawe taylor cristianini 
know tree structure empirical risk decisions larger margins produce better generalization shawe taylor cristianini 
statistical learning theory suggests svm decision trees idea generalization 
benefit decision tree structure provides valuable information problem class membership 
decision tree produces potentially interpretable rules attributes selected decisions indicate attributes important leaf nodes cluster data potentially meaningful ways 
large data sets trees simple decisions attribute enormous 
powerful decisions construct trees simpler structure 
svm regarded decision trees decision single decision largely black box 
linear svm norm capacity control rlp construct decision linear rule necessary attributes produced 
norm svm usually function attributes 
attribute reduction essential practical applications 
want large univariate decision tree single nonlinear support vector machine 
ideal decision tree generalize select relevant attributes provide information properties underlying data relevant application 
section examine support vector decision tree algorithm successful application database marketing problem 
full details support vector decision trees bennett 
uses dual rlp construct simple decision trees excellent dimensionality reduction 
performs top induction decision trees tdidt decision tree algorithms including cart oc breiman bennett quinlan murthy 
primary distinguishing factors tdidt algorithms type decisions linear svm method constructing decisions rlp 
basic tdidt algorithm works follows combining support vector mathematical programming methods classification algorithm basic tdidt start root node 
node remains split construct decision splitting criterion 
partition node child nodes decision 
prune tree necessary 
case splitting criterion method rlp solved commercial linear programming package cplex cpl 
applied problems database marketing 
database marketing problems primary goal testing set accuracy 
primary goal produce rank ordering customers 
decision tree algorithms attribute decision frequently database marketing 
problem univariate decision tree algorithms produce large trees hundreds decisions large marketing data sets 
powerful decisions produce compact trees typically decisions 
rlp norm capacity control construct decisions performs extensive dimensionality reduction 
property norm formulation 
primal objective term kwk tends force weights zero 
decision original attributes included rlp model optimality constraints inactive equivalently bound 
lagrangian multipliers constraints primal variables 
corresponding inactive constraints zero due complementarity karush kuhn tucker optimality conditions 
linear program solver automatically determine weights attributes eliminated problem decision 
constructed part customer scoring process 
tradeoffs training accuracy dimensionality reduction capacity control controlled parameter tune prune tree validation set 
tuning takes account desired goals models database marketing 
customers ranked response rate decision tree nodes minimum distance points decision 
results reported 
compare models validation identify potential customers determine expected utility profit 
bennett results business problems 
produced simple accurate trees perform excellent scoring small number attributes 
trees provide information structure problem 
data set business produced tree 
training data consisted points attributes testing set consisted points 
cplex produced root decision cpu seconds sun ultra megabytes memory 
testing set accuracy tree linear decisions 
comparison quinlan produced tree consisting univariate decisions testing set accuracy 
took nonlinear separation decision trees psfrag replacements attr margin attr margin attr margin class resp rate targ class total pop class resp rate targ class total pop class resp rate targ class total pop class resp rate targ class total pop decision tree business test data target class minutes construct decision tree platform 
accurate trees exist corresponding significantly different 
recall goal identify customers customers target class structure tree interesting 
tree internal nodes 
value root node value subsequent decision nodes 
leaf node labeled response rate target class jclass points percentage target class reached node jclass jclass percentage total population reaching node points points 
optimal number attributes margin separation kwk decision 
optimal number attributes number attributes decision nonzero optimal weights 
notice decision nonzero weight requires attribute 
simple decision attribute produces leaf reaches target class response rate 
decision uses attributes produce leaf predominately contains points response rate target class total population reaches node 
sense decision identifies easy points decision separates points easily identified points reaching decision difficult classify 
margin separation decision smaller accuracy decision low 
decision produces useful information scoring 
rank customers leaf tree reach 
customer preference 
combining support vector mathematical programming methods classification cumulative class cumulative decile class class response response lift population population rate rate table business test data 
points ranked sorted results displayed 
line contains decile population 
appear order response rate 
decile report percentage total target class population included decile cumulative percentage total target class population response rate target class decile cumulative target class response rate 
column represents lift measure better doing choosing customers random 
lift defined response rate jclass jclass 
class shown bold 
business test data table 
final model construct test data 
testing set response rate decile estimate expected business response rate 
example market top customers expect response rate reach approximately possible target customers population 
rule thumb database marketing fifth decile target class reached model successful 
fifth decile underlined 
reached class population fifth decile 
testing combined model expected profitability determine thresholds scoring 
scoring process potential customers selected model selected threshold thomas hughes 
tested database marketing problems similar results 
largest data set attempted contained megabytes training data 
largest root decision solved minutes cplex sun ultra megabytes memory 
interested reader consult bennett full details experiments 
versions possible 
original svm quadratic program multicategory classification approach tdidt algorithm 
catch approach frequently results decision tree 
alternative svm algorithms consider optimize decisions tree simultaneously proposed blue bennett blue 
trees database marketing problem look classifiers produced original msm algorithm 
possibility trees way splits decision region left margin region margin region right margin 
popular decision tree algorithms cart attributes symbolic 
margin mean context symbolic attributes 
statistical learning theory help algorithms problems symbolic attributes 
open research topics 
multicategory classification section focus different approaches mpm svm solve problems psi classes 
original svm method multiclass problems find psi separate class discriminants cortes vapnik vapnik 
discriminant constructed separating single class 
process requires solution psi quadratic programs 
denote method psi svm 
applying psi classifiers original multicategory data set multiply classified points unclassified points may occur 
ambiguity avoided choosing class point corresponding classification function maximized point 
lp approach construct directly psi classification functions point corresponding class function maximized bennett mangasarian 
multicategory discrimination method bennett mangasarian constructs piecewise linear discriminant psi class problem single linear program 
call method rlp direction extension rlp approach 
psi svm rlp approaches combined yield new methods psi rlp svm 
provide brief description 
full details results section bredensteiner bennett bredensteiner 
simplify equations introduce notation 
wish construct discriminant function elements sets psi dimensional real space theta matrix rows points th point th row denoted denote vector ones appropriate dimension 
express set constraints delta fl fl linear case original mpm svm methods construct piecewise linear separator discriminate psi classes psi points 
psi svm vapnik cortes vapnik quadratic program solved construct discriminant function separate class remaining psi gamma classes 
process repeated psi times 
separable case combining support vector mathematical programming methods classification psfrag replacements delta gamma fl delta gamma fl delta gamma fl max delta gamma fl piecewise linear separation sets convex piecewise linear function linear discriminant class satisfy set inequalities find psi svm fl psi fl psi gamma fl gammae gamma fl psi separable case solving psi class rest svm yield fl psi fl psi solution exists 
classify new point compute delta gamma fl clearly point belongs class psi class ambiguous 
general rule class point determined fl psi finding delta gamma fl maximized 
shows piecewise linear function max separates sets 
note fl psi constructed psi separate optimization problems final classification function problem separable psi separate functions 
note svm rlp construct psi class discriminants depending norm desired capacity control 
clarity call method svm psi svm 
denote method rlp psi rlp 
psi svm psi rlp attain perfect training set accuracy function inequalities feasible exist fl psi fl psi satisfying gamma fl gamma fl psi multicategory classification equivalently gamma gamma fl gamma fl psi rlp method proposed investigated bennett mangasarian find fl psi satisfying inequalities 
class case rlp simplifies original rlp method rlp min fl ij psi psi ij fi fi fi fi fi ij gammaa gamma fl gamma fl ij psi ij theta rlp optimal objective value zero data set piecewise linearly separable 
data set piecewise linearly separable positive values variables ij proportional magnitude misclassified points plane gamma delta fl gamma fl 
rlp linear program 
original rlp rlp include terms maximizing margin 
show rlp svm combined including margin maximization generalized inner products rlp 
intuitively optimal fl provide largest margin separation possible 
approach analogous class svm approach add margin maximization terms control capacity 
dashed lines represent margins piece gamma fl gamma fl piecewise linear separating function 
margin separation classes distance gamma fl gamma fl gamma fl gamma fl gamma kw gammaw minimize fl fl gamma fl fl psi add regularization term psi fl fl fl fl objective 
piecewise linearly inseparable problem get min fl ij gamma psi psi delta ij psi gamma fl fl gamma fl fl psi fl fl fl fl subject ij gamma gamma fl gamma fl gamma psi 
note misclassification costs positive constant 
weston watkins psi class formulation similar problem proposed margin maximization term minimizes kw gamma omitted 

method originally called multicategory discrimination 
combining support vector mathematical programming methods classification psfrag replacements gamma fl gamma fl gamma fl gamma fl gamma fl gamma fl gamma delta fl gamma fl gamma gamma delta fl gamma fl piecewise linear separator margins classes class case dual problem formulated see bredensteiner bennett 
kernels easily incorporated dual formulation allow piecewise nonlinear discriminants 
notion support vector exists formulation 
psi gamma lagrangian multipliers point 
final svm produces piecewise nonlinear classification computes class point finding psi classification function psi sv ij gamma sv ji gamma fl maximized 
illustrates results svm class problem dimensions 
summarize computational results comparing svm rlp psi svm svm psi rlp rlp 
see bredensteiner bennett bredensteiner full details problem formulation results 
quadratic programming problems svm psi svm solved nonlinear solver implemented minos murtagh saunders 
solver uses reduced gradient algorithm conjunction quasi newton method 
svm psi svm rlp values respectively 
better solutions may result different choices additionally necessary value methods 
kernel function piecewise nonlinear svm psi svm methods gamma deltax delta degree desired polynomial 
multicategory classification piecewise polynomial separation classes dimensions 
support vectors indicated large ovals 
experimented united states postal service usps database lecun containing zipcode samples actual mail 
database comprised separate training testing sets 
samples training set samples testing set 
sample belongs classes integers 
samples represented features 
experiment conducted subsets usps 
subsets selected svm complete formulation large solver decomposition techniques 
data contain handwriting samples integers 
objective data set interpret quickly effectively 
data set separate training testing sets consists integer classes 
compiled individual training subsets usps training data 
subset contains examples belonging classes 
call set usps training data 
second subset contains examples belonging classes 
call set usps training data 
similarly subsets created testing data 
data sets data values scaled testing set accuracies reported methods 
total numbers unique support vectors resulting classification functions svm psi svm methods 
svm accuracies full class usps benchmark polynomial kernel incorporating prior knowledge local kernel virtual svs scholkopf 
combining support vector mathematical programming methods classification data method degree usps rlp psi rlp svm psi svm usps rlp psi rlp svm psi svm table percent testing set accuracies total number support vectors multicategory discrimination methods table contains results methods usps data subsets 
data sets piecewise linearly separable 
solution data sets tests significantly worse methods 
shows importance margin maximization rlp method lacking capacity control 
psi svm method generalizes slightly better svm computationally efficient 
psi rlp method reports accuracies similar psi svm method 
additionally psi rlp solving small linear program big linear program quadratic programs computational training time significantly smaller methods 
changing parameter may improve generalization 
svm method consistently finds classification functions fewer support vectors psi svm 
fewer support vectors sample classified quickly dot product sample support vector computed 
svm method choose classification time critical 
results illustrate value combining svm mpm approaches 
incorporating margin maximization rlp method greatly improved new methods psi rlp svm constructed 
rest approaches psi rlp psi svm best terms generalization computational time problems tested 
computational experiments limited capacity solver minos 
decomposition methods ones discussed book svm method tractable larger problems classes 
norm capacity control kernels added rlp formulation 
risk minimization mpm best multicategory formulation open question practically theoretically 
risk minimization mpm section show modeling techniques mathematical programming help translate concepts statistical learning theory practical algorithms 
concrete example examine problem risk minimization transduction 
vapnik briefly problem nips support vector machine workshop see chapter chapter vapnik briefly vapnik 
roughly transduction problem training set labeled points estimate value function unlabeled working set xm vapnik distinguishes problem transduction induction problem 
induction goal estimate function possible points 
testing points classified deduction 
transduction goal estimate function value particular set testing working points 
induction structural risk minimized 
transduction risk minimized 
risk minimization explicitly including working set data problem formulation expect better generalization problems insufficient data 
define semi supervised support vector machine problem training set points known class working set data points unknown class construct svm label working set 
formulate start norm rlp norm svm formulation add constraints point working set 
constraint calculates misclassification error point class constraint calculates misclassification error point class objective function calculates minimum possible misclassification errors 
final class points corresponds results smallest error 
specifically define semi supervised support vector machine min fl gamma ffi ffi ffi min subject delta gamma fl gammaw delta fl delta gamma fl working set gammaw delta fl ffi fixed misclassification costs 
experiments reported ffi 

set refered testing set vapnik 
combining support vector mathematical programming methods classification integer programming solve problem 
basic idea add decision variable point working set 
variable indicates class point 
point class point class results mixed integer program mip integer program min fl gamma ffi ffi ffi subject delta gamma fl gammaw delta fl delta gamma fl gamma working set gammaw delta fl md constant chosen sufficiently large feasible optimal fl 
likewise 
norm problem exactly solved cplex commercial integer programming codes cpl 
cplex uses combination branch bound branch cut techniques produce enumeration tree 
node tree continuous relaxation integer program solved low cost linear algebra 
problem effectiveness algorithm dependent number integer variables size working set effectiveness algorithm pruning search space 
mathematical programming modeling language ampl able express problem approximately lines code plus data file solve cplex 
norm margin maximization problem quadratic integer program 
methods exists solving problems access solver 
mip solve transduction problem risk minimization 
consider simple problem vapnik 
results rlp svm mip problem shown 
training set points shown transparent triangles hexagons 
working set points shown filled circles 
left picture shows solution rlp 
note working set points added resulting separation small margin 
right picture shows mip solution constructed unlabeled working set 
note larger clearer separation margin 
computational solutions virtually solution vapnik 
tested mip real world data sets murphy aha 
mip tested better data sets significantly 
data set mip perform significantly worse 

ampl code available request author www math rpi edu 
risk minimization mpm left solution rlp right solution mip data set dim points cv size rlp mip value bright cancer cancer prognostic dim heart housing ionosphere musk pima sonar table rlp vs mip average testing error results table 
data set performed fold crossvalidation 
starred data sets integer programming solver failed due excessive branching required cplex algorithm 
data sets randomly extracted point working sets trial 
parameters data set rlp mip problems 
values paired test testing set accuracies small surprise 
algorithms applied successfully problems incorporating working set information 
clear priori improve generalization data sets 
data sets improvement possible mip degrade performance rlp 
results statistical learning theory results incorporating working data improves generalization insufficient training information available 
case mip combining support vector mathematical programming methods classification improved showed significant difference generalization compared baseline empirical risk minimization approach rlp 
additional constraints svm mip adapted clustering 
problem formulations incorporate kernels investigated 
shown past problem formulations mpm mangasarian share canonical form svm 
similarities allow mpm svm methods easily combined 
examined dissimilarities mpm svm approaches generate new methods nonlinear discrimination support vector decision trees multicategory learning 
case incorporating margin maximization mpm resulted better generalization 
showed mpm models tools allowed develop rapidly practical approach solving transduction problem risk minimization 
integer programming approach able solve moderately sized problem commercial software 
preliminary empirical results support risk minimization theory indicate transduction promising practical research direction svm mpm 
review solely limited examples single family mpm 
extensions methods covered bradley mangasarian potentially combined svm 
addition wide classes totally unrelated mpm approaches glover 
potentially synthesized svm 
omission method indication quality method 
primary weakness mpm approaches guided statistical learning theory 
problems investigated chapter altering mpm methods include principles statistical learning theory improved generalization 
optimization methods potentially improved similar transformations 
acknowledgments collaborators leonardo erin bredensteiner demiriz wu scott editorial comments 
supported nsf iri iri 

analysis observed chaotic data 
springer verlag new york 
aizerman braverman 
theoretical foundations potential function method pattern recognition learning 
automation remote control 
alon ben david cesa bianchi haussler 
scale sensitive dimensions uniform convergence learnability 
journal acm 
kann 
complexity approximability finding maximum feasible subsystems linear relations 
theoretical computer science 
kann 
approximability minimizing nonzero variables unsatisfied relations linear systems 
theoretical computer science 
appear 
anthony 
probabilistic analysis learning artificial neural networks pac model variants 
neural computing surveys 
www icsi berkeley edu jagota ncs 
anthony biggs 
computational learning theory volume cambridge tracts theoretical computer science 
cambridge university press 

theory reproducing kernels 
transactions american mathematical society 
ash 
information theory 
interscience publishers new york 
bartlett 
pattern classification neural networks 
ieee transactions information theory 
bartlett 
sample complexity pattern classification neural networks size weights important size network 
ieee transactions information theory 
bartlett long williamson 
fat shattering learnability real valued functions 
journal computer system sciences 
bengio lecun henderson 
globally trained handwritten word recognizer spatial representation convolutional neural networks hidden markov models 
cowan tesauro alspector editors advances neural information processing systems volume pages 
bennett 
decision tree construction linear programming 
evans editor proceedings th midwest artificial intelligence cognitive science society conference pages illinois 
bennett blue 
support vector machine approach decision trees 
proceedings ijcnn pages anchorage alaska 
bennett bredensteiner 
parametric optimization method machine learning 
informs journal computing 
bennett bredensteiner 
geometry learning 
hart meyer phillips editors geometry washington 
mathematical association america 
available www math rpi edu geometry ps 
bennett demiriz 
semi supervised support vector machines 
unpublished manuscript talk machines learn conference snowbird 
bennett mangasarian 
robust linear programming discrimination linearly inseparable sets 
optimization methods software 
bennett mangasarian 
multicategory separation linear programming 
optimization methods software 
bennett mangasarian 
serial parallel multicategory discrimination 
siam journal optimization 
bennett wu 
support vector decision trees database marketing 
math report rensselaer polytechnic institute troy ny 

zur mit 
editor 
dagm symposium pages berlin 
vde verlag 
bertsekas 
nonlinear programming 
athena scientific belmont ma 
ph 
toint 
iterative algorithms linear squares problems bound constraints 
linear appl pages 
bishop 
neural networks pattern recognition 
clarendon press oxford 
blanz scholkopf bulthoff burges vapnik vetter 
comparison view object recognition algorithms realistic models 
von der malsburg von seelen sendhoff editors artificial neural networks icann pages berlin 
springer lecture notes computer science vol 

blue 
hybrid tabu search local descent algorithms applications artificial intelligence 
phd thesis rensselaer polytechnic institute 
blumer ehrenfeucht haussler warmuth 
learnability vapnik chervonenkis dimension 
journal acm 

differentiable manifolds riemannian geometry 
academic press nd edition 
boser guyon vapnik 
training algorithm optimal margin classifiers 
haussler editor proceedings th annual acm workshop computational learning theory pages pittsburgh pa 
acm press 
bottou cortes denker drucker guyon jackel lecun muller sackinger simard vapnik 
comparison classifier methods case study handwritten digit recognition 
proceedings th international conference pattern recognition neural networks jerusalem pages 
ieee computer society press 
bottou vapnik 
local learning algorithms 
neural computation 
bradley fayyad mangasarian 
data mining overview optimization opportunities 
technical report mathematical programming technical report university wisconsin madison 
submitted publication 
bradley mangasarian 
feature selection concave minimization support vector machines 
technical report mathematical programming technical report university wisconsin madison 
appear icml 
bradley mangasarian 
massive data discrimination linear support vector machines 
technical report mathematical programming technical report university wisconsin madison 
submitted publication 
bradley mangasarian street 
feature selection mathematical programming 
technical report computer sciences department university wisconsin madison wisconsin 
appear informs journal computing 
bredensteiner 
optimization methods data mining machine learning 
phd thesis rensselaer polytechnic institute 
bredensteiner bennett 
feature minimization decision trees 
computational optimization applications 
bredensteiner bennett 
multicategory classification support vector machines 
computational optimization applications 
appear 
bregman 
relaxation method finding common point convex sets application solution problems convex programming 
ussr computational mathematics mathematical physics 
breiman 
bagging predictors 
technical report department statistics uc berkeley 
ftp ftp stat berkeley edu pub tech reports ps breiman friedman olshen stone 
classification regression trees 
wadsworth international california 
brown bryant 
computing lyapunov spectrum dynamical system observed time series 
phys 
rev lett 
bunch kaufman 
stable methods calculating inertia solving symmetric linear systems 
mathematics computation 
burges 
simplified support vector decision rules 
saitta editor proceedings th intl 
conf 
machine learning pages san mateo ca 
morgan kaufmann 
burges 
tutorial support vector machines pattern recognition 
data mining knowledge discovery 
burges scholkopf 
improving accuracy speed support vector learning machines 
mozer jordan petsche editors advances neural information processing systems pages cambridge ma 
mit press 
burges vapnik 
new method constructing artificial neural networks interim technical report onr contract 
technical report bell laboratories 
carl 
inequalities bernstein jackson type degree compactness operators banach spaces 
annales de institut fourier 
carl 
entropy compactness approximation operators 
cambridge university press cambridge uk 
censor 
row action methods huge sparse systems applications 
siam review 
censor lent 
iterative row action method interval convex programming 
optimization theory applications 
chen 
basis pursuit 
phd thesis department statistics stanford university 
chen donoho saunders 
atomic decomposition basis pursuit 
technical report department statistics stanford university 

techniques partial differential equations 
mcgraw hill 

metric spaces 
cambridge university press 
cortes vapnik 
support vector networks 
machine learning 
courant hilbert 
methods mathematical physics volume 
interscience publishers new york 
cover 
geometrical statistical properties systems linear inequalities applications pattern recognition 
ieee trans 
elect 
comp 
cox sullivan 
asymptotic analysis penalized likelihood related estimators 
ann 
statist 
cplex optimization incorporated incline village nevada 
cplex callable library 
craven wahba 
smoothing noisy data spline functions estimating correct degree smoothing method generalized cross validation 
numer 
math 
cristianini shawe taylor 
bayesian classifiers large margin hyperplanes hilbert space 
shavlik editor machine learning proceedings fifteenth international conference san francisco ca 
morgan kaufmann 
kung 
principal component neural networks 
wiley new york 
poston 
tensor geometry 
springer verlag nd edition 
drucker burges kaufman smola vapnik 
support vector regression machines 
mozer jordan petsche editors advances neural information processing systems cambridge ma 
mit press 
duda hart 
pattern classification scene analysis 
john wiley sons 
dumais 
svms text categorization 
ieee intelligent systems 
hearst scholkopf dumais osuna platt trends controversies support vector machines 
schwartz 
linear operators part ii spectral theory self adjoint operators hilbert space 
number vii pure applied mathematics 
john wiley sons new york 
eckmann ruelle 
ergodic theory chaos strange attractors 
rev modern phys 

disorder chaos 
cambridge university press cambridge 
ehrenfeucht haussler kearns valiant 
general lower bound number examples needed learning 
information computation 
elden koch 
numerical analysis 
academic press 
gay kernighan 
ampl modeling language mathematical programming 
boyd massachusetts 
friedman 
approach classification 
technical re port department statistics stanford linear accelerator center stanford university 
gardner 
space interactions neural networks 
journal physics 
gill murray saunders 
snopt sqp algorithm large scale constrained optimization 
technical report na dept mathematics san diego 
gill murray wright 
practical optimization 
academic press 
girard 
asymptotic optimality fast randomized versions gcv cl ridge regression regularization 
ann 
statist 
girard 
asymptotic comparison partial cross validation gcv randomized gcv nonparametric regression 
ann 
statist 
girosi 
equivalence sparse approximation support vector machines 
neural computation 
girosi jones poggio 
priors stabilizers basis functions regularization radial tensor additive splines 
memo mit 
girosi jones poggio 
regularization theory neural networks architectures 
neural computation 
glover 
improved linear programming models discriminant analysis 
decision sciences 
stam srinivasan chen 
discriminant analysis linear programming 
operations research 
goldstein 
classical mechanics 
addison wesley reading ma 
bartlett lee mason 
generalization decision trees dnf size matter 
advances neural information processing systems 
golub von matt 
generalized cross validation large scale problems 
comput 
graph 
statist 
gong wahba johnson 
adaptive tuning numerical weather prediction models simultaneous estimation weighting smoothing physical parameters 
monthly weather review 
gordon konig 
geometric probabilistic estimates entropy approximation numbers operators 
journal approximation theory 
graepel obermayer 
fuzzy topographic kernel clustering 
brauer editor proceedings th gi workshop fuzzy neuro systems pages 
greene 
isometric embeddings riemannian pseudo riemannian manifolds 
american mathematical society 
gu wahba 
semiparametric analysis variance tensor product thin plate splines 
royal statistical soc 
ser 


note scale sensitive dimension linear bounded functionals banach spaces 
proceedings algorithm learning theory alt 
neci technical report 
guyon boser vapnik 
automatic capacity tuning large classifiers 
hanson cowan giles editors advances neural information processing systems volume pages 
morgan kaufmann san mateo ca 

group theory applications physical problems 
addison wesley reading ma edition 
reprint dover new york ny 
harrison rubinfeld 
hedonic prices demand clean air 
environ 
economics management volume pages 
original source boston housing data ftp ftp ics uci com pub machine learning databases housing 
hastie stuetzle 
principal curves 
jasa 
hastie tibshirani 
generalized additive models volume monographs statistics applied probability 
chapman hall london 
haykin 
neural networks comprehensive foundation 
macmillan new york 
haykin yee 
reconstruction underlying dynamics observed chaotic process 
technical report comm 
res 
lab mcmaster university 
hildreth 
quadratic programming procedure 
naval research logistics quarterly 
ho kleinberg 
building classifiers arbitrary complexity 
proceedings th international conference pattern recognition vienna pages 
hotelling 
analysis complex statistical variables principal components 
journal educational psychology 
huber 
robust statistics review 
ann 
statist 
huber 
robust statistics 
john wiley sons new york 
hughes 
complete database marketer 
irwin prof publishing chicago 
hutchinson 
stochastic estimator trace influence matrix laplacian smoothing splines 
commun 
statist simula 
joachims 
text categorization support vector machines learning relevant features 
technical report ls viii university dortmund 
joachims 
text categorization support vector machines 
european conference machine learning ecml 
jolliffe 
principal component analysis 
springer verlag new york 
karhunen 
generalizations principal component analysis optimization problems neural networks 
neural networks 
karhunen 
zur prozesse 
ann 
acad 
sci 

karush 
minima functions variables inequalities side constraints 
master thesis dept mathematics univ chicago 
kearns schapire sellie 
efficient agnostic learning 
machine learning 
brown 
determining embedding dimension phase space reconstruction geometrical construction 
phys 
rev 
kimeldorf wahba 
correspondence bayesian estimation stochastic processes smoothing splines 
ann 
math 
statist 
kimeldorf wahba 
results spline functions 
math 
anal 
applic 
kirby sirovich 
application karhunen lo eve procedure characterization human faces 
ieee transactions pattern analysis machine intelligence 
kohlmorgen 
muller pawelzik 
analysis drifting dynamics neural network hidden markov models 
jordan kearns solla editors advances neural information processing systems cambridge ma 
mit press 
kohonen 
self organized formation topologically correct feature maps 
biological cybernetics 
kolmogorov 
introductory real analysis 
prentice hall 
konig 
eigenvalue distribution compact operators 
birkhauser basel 
kre el 
impact learning set size handwritten digit recognition 
kohonen editor artificial neural networks icann pages amsterdam 
north holland 
kre el 
polynomial classifiers support vector machines 
gerstner editor artificial neural networks icann pages berlin 
springer lecture notes computer science vol 

kre el 
pattern classification techniques function approximation 
bunke wang editors handbook optical character recognition document analysis pages 
world scientific publishing singapore 
kuhn tucker 
nonlinear programming 
proc 
nd berkeley symposium mathematical statistics pages berkeley 
university california press 
lecun boser denker henderson howard hubbard jackel 
backpropagation applied handwritten zip code recognition 
neural computation 
lecun jackel bottou cortes denker drucker guyon muller sackinger simard vapnik 
comparison learning algorithms handwritten digit recognition 
fogelman gallinari editors proceedings icann international conference artificial neural networks volume ii pages france 
ec 
mnist benchmark data available www research att com yann ocr mnist 
lee bartlett williamson 
importance convexity learning squared loss 
ieee transactions information theory 
appear 
li 
asymptotic optimality cl generalized cross validation ridge regression application spline smoothing 
ann 
statist 
pawelzik schuster 
optimal embeddings chaotic attractors topological considerations 
europhys 
lett 

chaotic time series part ii 
system identification prediction 
modeling identification control 
littlestone warmuth 
relating data compression learnability 
technical report university california santa cruz 
lorenz 
deterministic flow 
atmos 
sci 
loy bartlett 
generalization size weights experimental study 
proceedings eighth australian conference neural networks pages 
mackay 
evidence framework applied classification networks 
neural computation 
mackay 
practical bayesian framework backprop networks 
neural computation 
mackey glass 
oscillation chaos physiological control systems 
science 
mallat 
wavelet tour signal processing 
academic press 
mangasarian 
multi surface method pattern separation 
ieee transactions information theory 
mangasarian 
misclassification minimization 
global optimization 
mangasarian 
mathematical programming data mining 
data mining knowledge discovery 
mangasarian meyer 
nonlinear perturbations linear programs 
siam journal control optimization 
mangasarian setiono wolberg 
pattern recognition linear programming theory application medical diagnosis 
proceedings workshop large scale numerical optimization pages philadelphia pennsylvania 
siam 

linear nonlinear separation patterns linear programming 
operations research 
mercer 
functions positive negative type connection theory integral equations 
philos 
trans 
roy 
soc 
london 
merz murphy 
uci repository machine learning databases 
www ics uci edu mlearn mlrepository html 
irvine ca university california department information computer science 
micchelli 
interpolation scattered data distance matrices conditionally positive definite functions 
constructive approximation 
moody darken 
fast learning networks locally tuned processing units 
neural computation 
mukherjee osuna girosi 
nonlinear prediction chaotic time series support vector machine 
principe morgan wilson editors neural networks signal processing vii proceedings ieee workshop pages new york 
ieee 
muller reinhardt 
neural networks 
springer verlag 

muller kohlmorgen pawelzik 
analysis switching dynamics competing neural networks 
ieice transactions fundamentals electronics communications computer sciences 

muller smola ratsch scholkopf kohlmorgen vapnik 
predicting time series support vector machines 
gerstner 
nicoud editors artificial neural networks icann pages berlin 
springer lecture notes computer science vol 

murphy aha 
uci repository machine learning databases 
department information computer science university california irvine california 
murtagh saunders 
minos user guide 
technical report sol stanford university 
murthy 
linear programming 
john wiley sons new york new york 
murthy kasif salzberg 
system induction oblique decision trees 
journal artificial intelligence research 
akamatsu 
approximation chaotic behavior neural network 
ieice trans 
inf 
syst 
nash 
embedding problem riemannian manifolds 
annals mathematics 
neal 
priors infinite networks 
technical report crg tr dept computer science university toronto 
neal 
bayesian learning neural networks 
springer verlag 
nilsson 
learning machines foundations trainable pattern classifying systems 
mcgraw hill 
oja 
simplified neuron model principal component analyzer 
math 
biology 
olver 
applications lie groups differential equations 
springer verlag 
opper 
learning neural networks solvable dynamics 
letters 
opper 
physics generalization 
domany van hemmen schulten editors physics neural networks iii 
springer verlag new york 
opper 
convexity internal representations statistical mechanics neural networks 
letters 
oren papageorgiou sinha osuna poggio 
pedestrian detection wavelet templates 
proc 
computer vision pattern recognition pages puerto rico 
osuna freund girosi 
improved training algorithm support vector machines 
principe morgan wilson editors neural networks signal processing vii proceedings ieee workshop pages new york 
ieee 
osuna freund girosi 
support vector machines training applications 
ai memo massachusetts institute technology 
osuna freund girosi 
training support vector machines application face detection 
proc 
computer vision pattern recognition pages 
packard crutchfield farmer shaw 
geometry time series 
phys 
rev lett 
parzen 
approach time series analysis 
ann 
math 
statist 
parzen 
statistical inference time series rkhs methods 
editor proceedings th biennial seminar montreal 
canadian mathematical congress 

pawelzik kohlmorgen 
muller 
annealed competition experts segmentation classification switching dynamics 
neural computation 
pawelzik 
muller kohlmorgen 
prediction mixtures 
von der malsburg von seelen sendhoff editors artificial neural networks icann pages berlin 
springer lecture notes computer science vol 

pearson 
lines planes closest fit points space 
philosophical magazine sixth series 
platt 
resource allocating network function interpolation 
neural computation 
platt 
sequential minimal optimization fast algorithm training support vector machines 
technical report msr tr microsoft research 
poggio 
optimal nonlinear associative recall 
biological cybernetics 
poggio girosi 
networks approximation learning 
proceedings ieee 
poggio girosi 
regularization algorithms learning equivalent multilayer networks 
science 
pontil verri 
properties support vector machines 
neural computation 
powell 
radial basis functions multivariable interpolation review 
algorithms approximation mason cox eds pages 
oxford clarendon press 
press teukolsky vetterling flannery 
numerical recipes art scientific computing nd ed 
cambridge university press cambridge 
principe kuo 
dynamic modeling chaotic time series neural networks 
cowan tesauro alspector editors advances neural information systems san mateo ca 
morgan kaufmann publishers 
prosser 
entropy capacity certain time varying channels 
journal mathematical analysis applications 
quinlan 
programs machine learning 
morgan kaufmann 
rasmussen 
evaluation gaussian processes methods nonlinear regression 
phd thesis department computer science university toronto 
ftp ftp cs toronto edu pub carl thesis ps gz 
ritter martinetz schulten 
eine die neuroinformatik 
addisonwesley munich germany 
roy miranda 
algorithm generate radial basis function rbf nets classification problems 
neural networks 
roy kim mukhopadhyay 
polynomial time algorithm construction training class multilayer perceptrons 
neural networks 
roy mukhopadhyay 
iterative generation higher order nets polynomial time linear programming 
ieee transactions neural networks 
saunders chen donoho 
atomic decomposition basis pursuit 
technical report dept statistics technical report stanford university 
saitoh 
theory reproducing kernels applications 
longman scientific technical harlow england 
sanger 
optimal unsupervised learning single layer linear feedforward network 
neural networks 
sauer casdagli 

stat 
phys 
saunders stitson weston bottou scholkopf smola 
support vector machine manual 
technical report csd tr department computer science royal holloway university london egham tw ex uk 
tr available www dcs rhbnc ac uk research areas comp learn sv pub report ps svm available svm dcs rhbnc ac uk 

digital image processing computer vision 
john wiley sons 
schapire freund bartlett sun lee 
boosting margin new explanation effectiveness voting methods 
annals statistics 
appear 
earlier version appeared fisher jr 
ed proceedings icml morgan kaufmann 
schmidt gish 
speaker identification support vector classifiers 
proc 
icassp pages atlanta ga 
schoenberg 
positive definite functions spheres 
duke math 

scholkopf burges vapnik 
extracting support data task 
fayyad uthurusamy editors proceedings international conference knowledge discovery data mining 
aaai press menlo park ca 
scholkopf 
support vector learning 
oldenbourg verlag munich 
scholkopf bartlett smola williamson 
support vector regression automatic accuracy control 
niklasson bod en ziemke editors proceedings th international conference artificial neural networks perspectives neural computing berlin 
springer verlag 
press 
scholkopf burges vapnik 
incorporating invariances support vector learning machines 
von der malsburg von seelen sendhoff editors artificial neural networks icann pages berlin 
springer lecture notes computer science vol 

scholkopf smola burges 
fast approximation support vector kernel expansions interpretation clustering approximation feature spaces 

dagm symposium lecture notes computer science berlin 
springer 
appear 
scholkopf mika smola ratsch 
muller 
kernel pca pattern reconstruction approximate pre images 
niklasson bod en ziemke editors proceedings th international conference artificial neural networks perspectives neural computing berlin 
springer verlag 
press 
scholkopf simard smola vapnik 
prior knowledge support vector kernels 
jordan kearns solla editors advances neural information processing systems cambridge ma 
mit press 
scholkopf smola 
muller 
nonlinear component analysis kernel eigenvalue problem 
technical report max planck institut fur kybernetik 
scholkopf smola 
muller 
kernel principal component analysis 
gerstner 
nicoud editors artificial neural networks icann pages berlin 
springer lecture notes computer science vol 

scholkopf smola 
muller 
nonlinear component analysis kernel eigenvalue problem 
neural computation 
scholkopf smola 
muller burges vapnik 
support vector methods learning feature extraction 
downs frean gallagher editors proceedings ninth australian conference neural networks pages brisbane australia 
university queensland 
scholkopf sung burges girosi niyogi poggio vapnik 
comparing support vector machines gaussian kernels radial basis function classifiers 
ieee trans 
sign 
processing 
takens van den 
estimation dimension noisy attractor 
physical review 

pattern classification unified view statistical neural approaches 
wiley new york 
scott 
multivariate density estimation 
wiley interscience new york 
seung sompolinsky tishby 
statistical mechanics learning examples 
physical review 
shawe taylor bartlett williamson anthony 
framework structural risk minimization 
colt 
shawe taylor bartlett williamson anthony 
structural risk minimization data dependent hierarchies 
ieee transactions information theory 
appear 
neurocolt technical report nc tr ftp ftp dcs rhbnc ac uk pub neurocolt tech reports 
shawe taylor cristianini 
data dependent structural risk minimisation perceptron decision trees 
advances neural information processing systems 
simard lecun denker 
efficient pattern recognition new transformation distance 
hanson cowan giles editors advances neural information processing systems pages san mateo ca 
morgan kaufmann 

absolute continuity measures corresponding homogeneous gaussian fields 
theory probability applications xviii 
smith 
pattern classifier design linear programming 
ieee transactions computers 
smola scholkopf 
regularization operators support vector kernels 
jordan kearns solla editors advances neural information processing systems cambridge ma 
mit press 
smola scholkopf 
kernel method pattern recognition regression approximation operator inversion 
algorithmica 
press 
smola scholkopf 
muller 
connection regularization operators support vector kernels 
neural networks 
smola scholkopf 
muller 
convex cost functions support vector regression 
niklasson bod en ziemke editors proceedings th international conference artificial neural networks perspectives neural computing berlin 
springer verlag 
press 
smola scholkopf 
muller 
general cost functions support vector regression 
downs frean gallagher editors proc 
ninth australian conf 
neural networks pages brisbane australia 
university queensland 
stewart 
positive definite generalizations historical survey 
rocky mountain journal mathematics 
stitson gammerman vapnik vovk watkins weston 
support vector regression anova decomposition kernels 
technical report csd tr royal holloway university london 
takens 
detecting strange attractors fluid turbulence 
rand young editors dynamical systems turbulence pages 
springerverlag berlin 
talagrand 
glivenko cantelli problem years 
journal theoretical probability 
thomas 
database marketing dual approach response modeling 
database marketing news page 
vanderbei 
loqo interior point code quadratic programming 
technical report sor princeton university 
vanderbei 
loqo user manual version 
technical report sor princeton university statistics operations research 
code available www princeton edu 
vapnik 
estimation dependences empirical data russian 
nauka moscow 
english translation springer verlag new york 
vapnik 
nature statistical learning theory 
springer verlag new york 
vapnik 
structure statistical learning theory 
gammerman editor computational reasoning chapter 
wiley chichester 
vapnik 
statistical learning theory 
wiley new york 
forthcoming 
vapnik chervonenkis 
note class perceptrons 
automation remote control 
vapnik chervonenkis 
uniform convergence frequencies occurence events probabilities 
dokl 
akad 
nauk sssr 
vapnik chervonenkis 
uniform convergence relative frequencies events probabilities 
theory probability applications 
vapnik chervonenkis 
theory pattern recognition russian 
nauka moscow 
german translation theorie der akademie verlag berlin 
vapnik chervonenkis 
necessary sufficient conditions uniform convergence means expectations 
theory probability applications 
vapnik smola 
support vector method function approximation regression estimation signal processing 
mozer jordan petsche editors advances neural information processing systems pages cambridge ma 
mit press 
vapnik lerner 
pattern recognition generalized portrait method 
automation remote control 
vapnik levin le cun 
measuring vc dimension learning machine 
neural computation 
ya 

special functions theory group representations volume translations mathematical monographs 
american mathematical society press providence ny 
wahba 
inequality constrained multivariate smoothing splines application estimation posterior probabilities 
am 
statist 
assoc 
wahba 
convergence rates certain approximate solutions integral equations kind 
journal approximation theory 
wahba 
improper priors spline smoothing problem guarding model errors regression 
roy 
stat 
soc 
ser 

wahba 
spline interpolation smoothing sphere 
siam sci 
stat 
comput 
wahba 
constrained regularization ill posed linear operator equations applications meteorology medicine 
gupta berger editors statistical decision theory related topics iii vol pages 
academic press 
wahba 
erratum spline interpolation smoothing sphere 
siam sci 
stat 
comput 
wahba 
comparison gcv gml choosing smoothing parameter generalized spline smoothing problem 
ann 
statist 
wahba 
multivariate thin plate spline smoothing positivity linear inequality constraints 
wegman editors statistical image processing graphics pages 
marcel dekker 
wahba 
spline models observational data volume cbms nsf regional conference series applied mathematics 
siam philadelphia 
wahba 
multivariate function operator estimation smoothing splines reproducing kernels 
casdagli eubank editors nonlinear modeling forecasting sfi studies sciences complexity proc 
vol xii pages 
addison wesley 
wahba johnson gao gong 
adaptive tuning numerical weather prediction models randomized gcv dimensional data assimilation 
mon 

rev 
wahba wang gu klein klein 
structured machine learning soft classification smoothing spline anova stacked tuning testing evaluation 
cowan tesauro alspector editors advances neural information processing systems pages 
morgan kauffman 
wahba wang gu klein klein 
smoothing spline anova exponential families application wisconsin epidemiological study 
ann 
statist 
rau 
statistical mechanics learning rule 
reviews modern physics 
weigend gershenfeld eds 
time series prediction forecasting understanding past 
addison wesley 
santa fe institute studies sciences complexity 
werbos 
regression new tools prediction analysis behavioral sciences 
phd thesis harvard 
werner 
optimization theory applications 
vieweg 
weston watkins 
multi class support vector machines 
technical report csd tr department computer science royal holloway university london egham tw ex uk 
widom 
asymptotic behaviour eigenvalues certain integral operators 
archive rational mechanics analysis 
wilkinson geist janet burges hammond hull larsen wilson 
census optical character recognition system conference 
technical report nistir national institute standards technology nist gaithersburg 
williams 
computation infinite networks 
mozer jordan petsche editors advances neural information processing systems cambridge ma 
mit press 
williams 
prediction gaussian processes linear regression linear prediction 
jordan editor learning inference graphical models 
kluwer 
appear 
technical report ncrg aston university 
williamson smola scholkopf 
generalization performance regularization networks support vector machines entropy numbers compact operators 
technical report nc tr royal holloway college university london uk 
williamson smola scholkopf 
maximum margin 

wolberg mangasarian 
method pattern separation medical diagnosis applied breast 
proceedings national academy sciences 
wolf swift 
determining lyapunov exponents time series 
physica 
xiang 
model fitting testing non gaussian data large data set 
phd thesis technical report university wisconsin madison madison wi 
xiang wahba 
generalized approximate cross validation smoothing splines non gaussian data 
statistica sinica 
xiang wahba 
approximate smoothing spline methods large data sets binary case 
technical report department statistics university wisconsin madison wi 
appear proceedings asa joint statistical meetings biometrics section pp 
yee 
regularized radial basis function theory applications probability estimation classification time series prediction 
phd thesis dept ece mcmaster university hamilton canada 
dale 
partial differential equations applications 
dover 
zhang hutchinson 
simple architectures fast machines practical issues nonlinear time series prediction 
weigend gershenfeld editors time series prediction forecasting understanding past 
santa fe institute addison wesley 

methods feasible directions study linear non line ar programming 
elsevier 
