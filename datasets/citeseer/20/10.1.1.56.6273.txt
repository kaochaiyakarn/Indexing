mapping arbitrary non uniform task graphs arbitrary non uniform system graphs song chen mary ying wu generic technique clustering mapping arbitrary task graphs arbitrary system graphs 
task system graphs studied non uniform computation communication weights associated nodes edges 
task graphs directed graphs system graphs undirected 
clustering algorithms multi level clustered graph called spec graph obtained task graph multi level clustered graph called rep graph obtained system graph 
mapping algorithm produces sub optimal matching spec graph containing task modules rep graph processors mp time max 
algorithm technique map arbitrary task graphs non uniform nodes edges arbitrary system graphs non uniform nodes edges 
number algorithms exist map arbitrary non uniform task graph specific uniform system graph 
algorithm generic compare specialized techniques show technique produces similar results lower time complexity 
mapping problem challenging problems parallel distributed computing 
known np complete general form restricted forms 
mapping problem studied number different ways literature 
mapping static dynamic 
static mapping assignments nodes revision possible publication ieee transactions parallel distributed systems 
preliminary version appear international conference parallel processing 
supported national science foundation ccr 
authors department computer information science new jersey institute technology newark nj 
task graphs system graphs determined prior execution changed execution 
static task graph system graph uniform non uniform 
graph called non uniform weights nodes weights edges 
uniform 
mapping directed task graphs precedence relation task modules called task scheduling studied :10.1.1.105.9185
task graphs mapped undirected called task allocation studied 
graphs directed undirected uniform non uniform basically types static mappings topological structures task system graphs mapping arbitrary tasks specialized systems mapping specialized tasks arbitrary systems mapping specialized tasks specialized systems mapping arbitrary tasks arbitrary systems 
concentrate static mapping arbitrary non uniform directed task graphs arbitrary non uniform system graphs 
mapping arbitrary directed task graphs arbitrary systems studied number scientists various sub optimal heuristics introduced 
mapping techniques assume system graphs uniform 
techniques information speeds processors communication links incorporated task graphs prior mapping computation time task module communication delay edge task modules known 
known algorithms designed mapping arbitrary non uniform tasks uniform specialized systems fully connected system :10.1.1.105.9185
information system graphs incorporated task graphs 
information speeds processors communication links kept independent task graphs 
results directly designing portable programs representable form machine independent task graphs 
generic technique mapping machine independent arbitrary nonuniform task graphs arbitrary non uniform system graphs 
proposed technique consists clustering algorithms mapping algorithm extensions 
algorithms map arbitrary uniform task graphs arbitrary uniform system graphs 
algorithms generic earlier versions treated special case 
algorithms serve part mapping component nsf funded portable programming tool called cluster 
clustering algorithms time complexities log non uniform task system graphs respectively number nodes task modules task graph number nodes processors system graph 
clustering done task graph system graph independent system graphs task graphs 
machine independent application independent clustering repeated different mappings 
mapping algorithm produces sub optimal matching non uniform clustered directed task graph spec graph non uniform clustered undirected system graph rep graph mp time max 
performance algorithms compared leading techniques 
show mapping technique works system configurations 
specific system configurations known methods applicable technique produces similar results lower time complexity 
rest organized follows 
section clustering algorithms 
mapping algorithm detailed section 
show experimental results comparing algorithm existing mapping algorithms section 
brief section 
clustering arbitrary task system graphs section algorithms clustering non uniform directed task graphs clustering non uniform undirected system graphs 
algorithm clustering task graph generate multi level clustered graph called spec graph algorithm clustering system graph generate multi level clustered graph called rep graph 
clustering done task graph system graph independent system graphs task graphs 
machine independent application independent clustering repeated different mappings 
spec graph rep graph obtained suboptimal mapping generated fast recursive mapping algorithm section 
clustering directed task graphs task represented directed graph ft set task modules executed set edges representing partial orders communication directions task modules 
directed edge represents data communication exists module completed start 
furthermore task module associated amount computation edge associated ij amount data required transmitted module module note ij exists edge directed edge exists call parent node module child node module node child called broadcast node 
node parent called merge node 
clustering algorithm called clustering non uniform directed graphs shown detail 
briefly describe 
start quadruple parameters oe ffi pi 
parameters described follows 
size cluster denoted oe represents maximum number nodes cluster computed clustering non uniform directed graphs algorithm group nodes task graph corresponding steps group edges task graph corresponding phases nodes step cluster calculate parameters cluster phases edges merge node sort incoming edges descending order communication amount embed child node parent nodes cluster merge cluster calculate parameters new cluster phases edges broadcast node sort outgoing edges descending order communication amount embed child node child nodes cluster merge cluster calculate parameters new cluster clustering non uniform directed graphs algorithm 
clustering embedding sequential computations represented node weight equivalent uniform graph having unit computation nodes 
clustering merging communications represented edge weight equivalent uniform graph having unit communication edges 
types clustering 
parallel 
number levels cluster represents computation length node cluster denoted ffi total amount communication clustering levels denoted pi average communication amount current top level denoted furthermore types operations performed clusters embedding merging 
embedding sequential clusters combined cluster shown 
shown dash line 
merging number concurrently executable sub clusters grouped form new cluster 
shown solid line 
embedded cluster oe ffi pi 
merged cluster oe ffi pi gamma 
figures value quadruple obtained identical uniform non uniform equivalent representations 
clustering done step step 
clustering step corresponds computation step 
step cluster nodes clusters follows 
node merge node embed parent nodes merge parent nodes larger cluster similar 
simple case merge node parent nodes shown 
similarly general case shown merge node parent nodes edges sorted descending order edge weight communication amount 
node broadcast node embed child nodes broadcast node merge rest child nodes broadcast node larger cluster 
simple case broadcast node child nodes shown 
similarly general case shown broadcast node child nodes edges sorted descending order weights 
note task graphs independent system graphs contain information computation time communication delay :10.1.1.105.9185
embed child node parent node merge broadcast cases shown 
embedding multiple child nodes done part mapping explained section 
cluster cluster suppose merge clusters 
embed node left parent cluster cluster max clustering merge node 
cluster cluster cluster cluster max 
clustering merge node general case 
cluster max cluster suppose clustering broadcast node 
cluster cluster max 
clustering broadcast node general case 
non uniform task graph constructing spec graph task graph obtained spec graph 
time complexity clustering non uniform directed graphs algorithm bounded number edges task graph number nodes 
illustrate algorithm consider task graph modules spec graph shown 
module labeled computation amount edge labeled amount data communication 
spec graph constructed merging clusters communication needs 
final spec graph multi level clustered graph 
clustering undirected system graphs parallel system modeled undirected system graph 
fp pn set processors forming underlying architecture set edges representing interconnection topology parallel system 
assume connections adjacent processors bi directional 
edge represents direct connection processor computation speed processor denoted communication bandwidth processors denoted ij computation speeds different processors transmission rates different communication links may non uniform 
system discussed truly heterogeneous system 
similar spec cluster rep cluster associated quadruple oe ffi pi represents number processors contained cluster average computation speed processors cluster total communication bandwidth average communication bandwidth current top clustering level 
construct clustered graph rep graph undirected system graph initially node computation speed forms cluster parameters 
clusters completely connected merged form new cluster parameters new cluster calculated correspondingly 
continued merging possible 
clusters connected contains node contains node node connected direct clustering non uniform undirected graphs algorithm nodes cluster clustering level set parameters cluster set cluster level edge linking clusters sort edges linking clusters sorted edge list empty take edge sorted edge list delete edge list merge cluster level calculate parameters delete clusters current level edge cx cy sorted edge list cx sub cluster cy sub cluster cluster cy connected sub clusters merge cy recalculate parameters delete cx cy edge list cx cy sub clusters different clusters level add weight cx cy edge super clusters delete cx cy edge list increment clustering level clustering non uniform undirected graphs algorithm 
communication link 
algorithm clustering undirected graphs shown 
example shown 
analyze running time implementation 
level sort edges clusters takes je log je je number edges system graph 
keep merging clusters levels 
suppose certain level clusters delta delta delta time comparisons number processors system graph 
number levels gamma 
total time complexity algorithm je log je 
consider worst case system graph completely connected je upper bound algorithm log 
non uniform system graph clustering 
mapping algorithm spec graph rep graph generated directly task graph system graph clustering algorithms previous section 
spec graph rep graph section efficient mapping algorithm produces suboptimal matching graphs mp time max 
set preliminaries give high level description mapping algorithm 
section examples illustrate mapping algorithm 
preliminaries define mapping function gamma 
precedence constraints computation communication requirements original task graph schedule obtained places task module processor fm proper time earliest possible starting time 
assume communication time task graph edge equal path fm rx path shortest path processor assume takes time communicate data processor 
schedule illustrated gantt chart consists list processors processor list task modules allocated processor ordered execution time 
define total execution time schedule tm latest finishing computation time scheduled task module processor 
obviously tm equals total execution time task system 
consider shortest execution time task system ultimate goal scheduling take tm measure quality scale mapping mapping algorithm detailed description mapping algorithm 
give overview algorithm 
starting mapping need compute reduction factor denoted essential mapping task graphs having nodes system graphs 
reduction factor ratio total sizes rep clusters total sizes spec clusters 
estimate computation nodes share processor 
mapping done recursively clustering level find best matching spec clusters rep clusters 
matching spec clusters rep clusters spec rep clusters sorted descending order respect parameters oe ffi pi 
example spec clusters larger sizes sorted smaller sizes spec clusters size larger number levels sorted 
second map spec clusters denoted follows 
search rep cluster denoted best matched size closest theta oe try minimize function equation 
multiple rep clusters matching size select minimum estimated execution time 
estimated execution time mapping spec cluster si rep cluster rj si rj equal number clustering levels si times average computation communication time level formulated equation 
rep cluster matching size spec cluster merge split rep clusters matching rep cluster 
jf jf theta oe gamma oe fm si rj ffi si ffi rj theta pi si theta ffi rj pi rj theta ffi si thirdly matched pair spec rep clusters embed communication intensive nodes 
similar clustering process :10.1.1.105.9185
mapping step clustering task graph kept independent system graph described previous section 
spec cluster multiple sub clusters average communication time sub clusters greater possible computation time sub cluster formulated condition embed sub clusters sub cluster having largest size calculate parameter quadruple new cluster 
insert proper position sorted list spec clusters mapping repeat matching described equation remaining spec clusters list 
embedding necessary mapping spec cluster rep cluster done level spec cluster removed list 
si rj min oe sub theta ffi sub ffi rj theta mapping algorithm worst case mapping level happens case spec cluster remaining rep clusters matching size equation select best rep cluster case spec cluster rep cluster matching size rep clusters merged split recursively rep cluster matching size obtained 
suppose number spec clusters level cases described combination cases takes time find best matches spec clusters total number clusters rep graph number processors 
pair matching spec rep clusters condition satisfied extra time taken embedding 
total number spec clusters number nodes original task graph 
total time complexity mapping algorithm mn mp max 
mapping algorithm sort spec clusters top level descending order oe ffi pi sort rep clusters top level descending order oe ffi pi calculate 
calculate required size rep cluster matching theta oe spec cluster top level sorted list cluster sub cluster go lower level multiple sub clusters rep cluster required size select rep cluster required size minimum estimated execution time equation match spec cluster rep cluster delete spec rep cluster spec rep list unmatched spec cluster size rep cluster required size split rep cluster parts part required size match spec cluster part insert part proper position sorted rep cluster list merge rep clusters sum sizes required size match spec cluster merged rep cluster split merged rep cluster parts required size match spec cluster part insert part sorted rep list matching pair spec cluster rep cluster rep cluster contains processor map modules spec cluster processor condition satisfied select sub cluster spec cluster largest size embed nodes sub clusters connected nodes selected sub cluster embed sub clusters selected calculate parameters new cluster insert sorted spec cluster list delete spec cluster spec cluster list delete rep cluster rep cluster list go sub clusters spec rep cluster pushed top level call mapping algorithm clusters mapping algorithm 
condition satisfied embed result mapping example 
mapping examples section constructed spec graph rep graph original task graph system graph shown 
shows snapshot mapping process 
shows final schedule obtained mapping data operational precedence task graph 
shown gantt chart tm 
show task graph mapped various system graphs choose different system graphs shown 
shows uniform fully connected system graph clustering 
computation speed processor communication bandwidth communication link equal 
result mapping graph gantt chart obtained schedule 
different systems topology 
shown 
system fully connected unit computation speed processor having higher communication bandwidths edges 
case algorithm distributes task modules shown processors utilize relatively high communication bandwidth available 
hand system fully connected unit communication bandwidth having higher computation speeds processors algorithm maps task modules processor highest speed avoid relatively expensive communication cost 
shown 
give example mapping real application task heterogeneous system 
choose gaussian elimination algorithm linpack 
fortran code 
suppose takes unit time addition subtraction takes units time multiplication division real numbers 
assume communication amount sending receiving real number 
task graph computing gaussian elimination theta matrix shown 
task mappings different system graphs 
mapping result task graph 
mapping result task graph 
mapping result task graph 
subroutine kji lda saxpy form kji saxpy real lda continue continue continue continue return gaussian elimination algorithm 
processors task graph mapping result gaussian elimination theta matrix 
module column modified column suppose system running task contains workstations speed respectively connected link bandwidth 
mapping result technique illustrated 
comparison results section set experimental results obtained comparing algorithm leading techniques 
examples selected designed studied authors papers reporting leading techniques 
criteria evaluating performance algorithms examined total time complexity executing mapping algorithm total execution time generated mappings tm number processors nm obtain speedup sm ts tm efficiency sm nm sequential execution time task 
existing mapping technique maps machine independent arbitrary non uniform task arbitrary non uniform system easy choose candidates comparison study 
focus comparing leading mapping techniques designed arbitrary non uniform tasks specialized systems 
mapping techniques category include gill clan sarkar edge zeroing clustering mcp yang dsc 
algorithms proven effective efficient mapping arbitrary non uniform directed tasks 
similar algorithm algorithms cluster task graphs mapping 
assume target systems fully connected unbounded number uniform processors communication links 
number processors bounded smaller number obtained clusters task modules clusters merged number clusters number processors 
comparison gill clan compare gill clan algorithm finds suitable sized grain cluster task modules assigned processor scheduling tasks 
clan set nodes directed task graph iff gamma parent node iff parent node child node iff child node informally clan subset nodes element outside set related way member set 
parsing algorithm proposed decomposes task graph 
gill algorithm assumed underlying system fully connected processors communication links uniform ij 
gill algorithm task modules task graph shown clustered assigned processors fully connected processor system comparison example clan 
task graph mapped uniform fully connected system 
mapping result tm nm 
clan mapping result tm nm 
task module receives data assigned similarly assigned assigned schedule resulting assignment appears 
clustering mapping algorithms different generic clan obtain similar results shown 
comparison wu gajski mcp modified critical path mcp algorithm critical path introduced hu 
critical path dag path greatest weight source node sink node including weights nodes edges path 
critical paths shortened removing communication weights zeroing edges embedding nodes path 
mcp assumes weights task nodes edges actual computation communication comparison example 
original task graph 
transformed task graph original mapped system graph 
mapping result tm nm 
mcp mapping result tm nm 
sarkar mapping result tm nm 
dsc mapping result tm nm 
times 
task graph shown system graph shown transformed task graph incorporating information system graph generated shown 
mapping results technique mcp shown respectively 
obtained mapping tm tm 
time complexity mcp log 
comparison sarkar edge zeroing algorithm basic idea sarkar edge zeroing algorithm repetitively zero highest weighted edge increase estimated tm edges examined 
time complexity je je je number edges task graph 
shows mapping result obtained edge zeroing algorithm example mcp section 
result 
comparison yang dsc yang dominant sequence clustering dsc algorithm critical path edge zeroing incorporates heuristics better clustering 
dsc find optimal schedules special dag fork join 
task graphs considered dsc machine independent similar techniques map non uniform systems shown 
time complexity dsc je log je number edges task graph 
shows mapping result obtained dsc example studied comparison mcp sarkar algorithms 
results example dsc best optimal close optimal 
show comparison examples dsc 
examples taken 
show mapping task graphs unbounded number identical processors fully connected identical communication links 
task graph comparison example dsc 
task mapped uniform system unit computation speed communication bandwidth 
mapping result tm nm 
dsc mapping result tm nm 
taken example studied el lewis mh algorithm 
mapped processor hypercube unit computation speed communication bandwidth 
mapping mh tm nm 
optimal mapping processors having tm 
graphs uniform edges considered 
mapping results technique dsc illustrated 
processor hypercube mappings task graph dsc shown 
generic algorithm mapping non uniform arbitrary task graphs non uniform arbitrary system graphs 
task graph system graph showed efficient techniques producing clustered graphs called spec graph rep graph input mapping algorithm 
clustering done task graph system graph independent system graphs task graphs 
machine comparison example dsc 
task mapped uniform system computation speed communication bandwidth 
transformed task graph 
mapping result tm nm 
dsc mapping result tm nm 
independent application independent clustering repeated different mappings 
complexity mapping algorithm mp number task modules number processors max 
experimental results comparing performance generic algorithm leading restricted ones 
showed obtain similar results amount time 
furthermore machine independent task graphs 
mapping algorithm part portable parallel programming tools 
processors processors processors processors comparison example dsc 
task graph mapped uniform hypercube 
mapping result processors tm nm 
dsc mapping result processors tm nm 
mapping result processors tm nm 
dsc mapping result processors tm nm 
ali el 
graph theoretic approach task allocation 
hicss 
anger hwang chow 
scheduling sufficient loosely coupled processors 
journal parallel distributed computing 
berman 
experience automatic solution mapping problem 
characteristics parallel algorithms pages 
berman snyder 
mapping parallel algorithms parallel architectures 
journal parallel distributed computing pages 
berman 
prep evolution overview 
technical report cs dept computer science university california san diego 

mapping problem 
ieee trans 
computers march 

shortest tree algorithm optimal assignments space time distributed processor system 
ieee trans 
software engineering se november 

partitioning problem parallel pipelined distributed computing 
ieee trans 
computers january 

taxonomy scheduling general purpose distributed computing systems 
ieee trans 
software engineering february 
chen 
fast recursive mapping algorithm 
concurrency practice experience 
coffman graham 
optimal scheduling processor systems 
acta informatica 
dongarra bunch moler stewart 
linpack user guide 
siam philadelphia pa 
dongarra karp 
implementing linear algebra algorithms dense matrices vector pipeline machine 
siam review 
efe 
heuristic models task assignment scheduling distributed systems 
ieee computer 
el lewis 
scheduling parallel program tasks arbitrary target machines 
journal parallel distributed computing pages 
el lewis ali 
task scheduling parallel distributed systems 
prentice hall 
ramanujam sadayappan 
task allocation hypercube recursive mincut bipartitioning 
journal parallel distributed computing pages 

cluster parallel programming paradigm 
international journal high speed computing june 
fernandez 
allocating modules processors distributed systems 
ieee trans 
software engineering november 
yang 
comparison clustering heuristics scheduling directed directed acyclic graphs multiprocessors 
journal parallel distributed computing 
gill smith warren 
spatial temporal analysis program dependence graphs useful parallelism 
journal parallel distributed computing october 
hu 
parallel sequencing assembly line problems 
operations research 
hwang chow anger lee 
scheduling precedence graphs systems interprocessor communication times 
siam computing 
khan jones 
comparison multiprocessor scheduling heuristics 
proc 
international conference parallel processing pages ii 
kim browne 
general approach mapping parallel computation multiprocessor architectures 
proc 
international conference parallel processing volume pages 
lee aggarwal 
mapping strategy parallel processing 
ieee trans 
computers april 
leland hendrickson 
empirical study static load balancing algorithms 
proc 
scalable high performance computing conference pages 
lo 
heuristic algorithms task assignment distributed systems 
ieee trans 
computers november 
lo gupta mohamed 
software tools mapping parallel computations parallel architectures 
proc 
international conference parallel processing 
gill 
automatic determination grain size efficient parallel processing 
communications acm september 
francois pellegrini 
static mapping dual recursive bipartitioning process architecture graphs 
proc 
scalable high performance computing conference pages 
mansour choudhary fox 
mapping realistic data sets parallel computers 
proc 
th international parallel processing symposium pages april 
sarkar 
partitioning scheduling parallel programs execution multiprocessors 
mit press 
shen tsai 
graph matching approach optimal task assignment distributed computing systems minmax criterion 
ieee trans 
computers march 
lee 
compile time scheduling heuristic interconnection constrained heterogeneous processor architectures 
ieee trans 
parallel distributed systems february 
stone 
multiprocessor scheduling aid network flow algorithms 
ieee trans 
software engineering se january 
ullman 
np complete scheduling problems 
journal computer systems science june 
demillo 
computational complexity generalized scheduling problem 
ieee trans 
computers november 
wu gajski 
programming aid message passing systems 
ieee trans 
parallel distributed systems 
yang 
list scheduling communication delays 
technical report department computer science rutgers university 
yang 
dsc scheduling parallel tasks unbounded number processors 
ieee trans 
parallel distributed systems september 
index terms mapping task scheduling task allocation clustering portable parallel programming 
list footnotes affiliation authors authors department computer information science new jersey institute technology newark nj 

revision possible publication ieee transactions parallel distributed systems 
preliminary version appear international conference parallel processing 
supported national science foundation ccr 
list figures clustering non uniform directed graphs algorithm 
types clustering 
clustering merge node 
clustering merge node general case 
clustering broadcast node 
clustering broadcast node general case 
task graph obtained spec graph 
clustering non uniform undirected graphs algorithm 
non uniform system graph clustering 
mapping algorithm 
mapping example 
gantt chart obtained schedule 
different systems topology 
mappings different system graphs 
mapping result task graph 
mapping result task graph 
mapping result task graph 
gaussian elimination algorithm 
task graph mapping result gaussian elimination theta matrix 
comparison example clan 
task graph mapped uniform fully connected system 
mapping result tm nm 
clan mapping result tm nm 
comparison example 
original task graph 
transformed task graph original mapped system graph 
mapping result tm nm 
mcp mapping result tm nm 
sarkar mapping result tm nm 
dsc mapping result tm nm 
comparison example dsc 
task mapped uniform system unit computation speed communication bandwidth 
mapping result tm nm 
dsc mapping result tm nm 
comparison example dsc 
task mapped uniform system computation speed communication bandwidth 
transformed task graph 
mapping result tm nm 
dsc mapping result tm nm 
comparison example dsc 
task graph mapped uniform hypercube 
mapping result processors tm nm 
dsc mapping result processors tm nm 
mapping result processors tm nm 
dsc mapping result processors tm nm 
preferred address correspondence mary dept computer information science new jersey institute technology newark nj tel email mary vienna njit edu 
