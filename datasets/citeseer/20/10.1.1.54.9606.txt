implementing efficient part speech tagger johan kann jfc nada kth se nada kth se nada numerical analysis computing science royal institute technology se stockholm sweden th march efficient implementation part speech tagger swedish described 
stochastic tagger uses established markov model language 
tagger tags unknown words correctly words 
implementation optimization considerations discussed 
main contribution thorough description tagging algorithm addition number improvements 
contains detail reader construct tagger language 
keywords part speech tagging word tagging optimization hidden markov models 
part speech pos tagging text word punctuation mark text assigned morphosyntactic tag 
different tagging systems different sets tags typically tag describes word class word class specific features number gender 
number different tags varies dozen 
constructing automatic part speech tagger involves problems 
find possible tags word 
easy word lexicon word unknown possible tags guessed 

choose possible tags 
called syntactic disambiguation solved word ambiguous part speech 
ambiguous words common languages example english word set noun adjective verb 
level analysis needed correct disambiguation varies sentence sentence 
correctly disambiguate word turn noun turn verb turn requires syntactic analyses sentences 
appear software practice experience 
second sentence particle preposition depends name road device 
correct automatic tagging impossible goal requires full understanding text 
tagging accuracy different systems described literature varies 
important language technology applications may include part speech tagging step example machine translation information retrieval grammar checking 
applications require tagger efficient tag fast especially important information retrieval accurate tag correctly especially important translation 
applications text syntactically disambiguated word sense disambiguation needed harder problem 
part speech taggers constructed various ways different types taggers different advantages 
taggers stochastic models example rules neural networks samuelsson voutilainen claim rule taggers give higher tagging accuracy plain stochastic taggers correct texts :10.1.1.14.6472
hybrids rule taggers stochastic taggers better 
different stochastic models tagging unknown words exist 
survey automatic stochastic part speech tagging 
describe implementation part speech tagger swedish 
wanted tagger easy implement fast language independent tag set independent give high accuracy tagging 
wanted tagger able cope unknown words grammatically erroneous sentences 
ability needed various applications grammar spell checking 
requirements chose construct stochastic tagger markov model 
goal achieve tagging accuracy known words accuracy unknown words reached surpassed goal 
tagger grammar checking program swedish named designed language independent possible think inflectional languages tag set application needing part speech tagging 
turned incorporated tagger hybrid stochastic tagger rule tagger 
certain complicated cases stochastic tagger wrong rules find correct tagging 
tagging model markov model section briefly describe markov model stochastic model language 
complete excellent description equations standard markov model part speech tagging 
text words seen sequence random variables corresponding tagging sequence random variables 
particular sequence values denoted 
definition tagging problem argmax operator arg max computes tagging maximizing probability model word sequence tagged second order markov model assumptions word depends tag tag depends preceding tags text 
tagging problem formulated argmax 
unattractive feature formulation quantities small difficult estimate 
reversed conditional probabilities attractive respect plausible alternative argmax 
equations particular corresponding order markov model equations different stochastic taggers equations compared equation significantly better tagging texts quite large training text probabilities known optimal solution tagging problem equation efficiently computed dynamic programming called viterbi algorithm 
algorithm avoids polynomial expansion breadth search trimming search tree level see implementation 
time complexity algorithm linear number words tagged 
type statistics rest mean word token specific occurrence word text opposed word type means lexically unique word 
misunderstanding possible write just word 
viterbi algorithm give estimates probabilities markov model 
obtain estimates collecting statistics large tagged corpus large text typically consisting words word token tagged supposedly correct morphosyntactic tag 
corpus collect statistics table compute estimates probabilities described table 
designing tagging algorithm modifying markov model equations problem probability distributions equations training text small give accurate estimates sparse data problem 
theoretical justification known 
note equivalent including factor 
gives preference common tags cases unusual tags probable 
sense conservative 
table statistics collected 
notation counting number word tokens occurrences word occurrences word tagged occurrences tag occurrences tag bigram tag followed tag occurrences tag trigram tag followed followed occurrences tag bigram word tagged followed tag cm different word types tagged tag occurrences capitalized words tagged cm different word types letters tagged table estimates probabilities 
section investigate previously reported ways smoothing modifying probabilities devise equation tagger 
reported equation gives significantly better results equation case compared 
heuristic attempt interpolate equation investigated 
interpolation accomplished extra cost terms efficiency lexical probability corresponding variant word computed just constructing lexicon time described section implementation considerations 
significant improvement decided base model just equation 
str claims modification lexical probability enhance tagging accuracy stochastic tagger corpus new optimum value parameter 
effect modification probabilities tags reduced making easier tagger choose lexically probable tags 
tests tagger gave optimum close significant improvement modification discarded 
tag trigram probability estimate presents problem large training text tag trigram bigram counts low case corpus see implementation considerations 
common way improve model interpolate tag trigram bigram unigram probabilities 
redefine trigram probability estimate follows int cn optimization parameters satisfy 
modification improves model tag trigram probabilities unreliable bigram counts small 
effect reduced making function number bigrams trigram contribution stronger bigram count high 
experiments showed optimization parameter gave slight improvement 
problem equation trigram count bigram counts zero 
experimented small numbers zero smooth equation 
turned single trigram term zero worked fine max improvement equation condition tag previous word previous tags 
pointed extension may idea tag bigrams sparse 
manual inspection tagging errors suggested including tag bigrams enhance performance 
surprisingly improvement tagging accuracy obtained tag bigrams term added equation effort reduce bad influence sparse data extra term tag bigrams frequency higher certain limit 
improvement 
resorted inspect impact word type occurring performance tag bigram formula 
experiment revealed word types worsened performance word types improved performance 
modified equation condition previous word previous tags previous word proved improve performance optimization text word words improved model termed 
tag bigrams modification equation gave improvement tagging accuracy optimization text significant improvement test text 
larger corpus required confident improvement model words occur times test optimization texts 
despite failure introducing word bigrams believe possible select tag bigrams improve model example verb particles verb prepositions 
attempt 
capitalization improve tagging swedish proper nouns spelled initial capital words commencing sentence spelled initial 
model modified select proper noun tags capitalized words capitalization convention fully observed case corpus introduced factor equation proper noun tag capitalized proper noun tag capitalized 
best performance obtained 
case unknown words 
modification effect initial capital necessarily lead word tagged proper noun tag words may tagged proper nouns 
tagging accuracy improved equation language model argmax int int max cn markov model parameter optimization standard way train hidden markov model maximum likelihood training forward backward algorithm known baum welch algorithm 
algorithm uses word type tag information iteratively improve probabilities training corpus 
advantage approach require training corpus tagged 
tagged training corpus available probabilities markov model estimated relative frequencies tagged text 
method reliable tagger 
untagged corpus tagged corpus try improve probabilities computed relative frequencies maximum likelihood training 
merialdo shown improvement occur tagged corpus large 
tagging unknown words described section heuristic modifications introduced add parameters original model standard optimization algorithms forward backward algorithm harder 
variant simulated annealing 
initial parameter values set arbitrarily optimum values give highest tagging accuracy optimization text determined simple linear searches 
values slightly altered optimum optimization repeated 
operation avoids parameters getting stuck local maxima 
naive method turned quite practical especially new parameters introduced evaluated development 
method put restrictions equation optimized 
naive linear search optimum parameter values golden section search 
algorithm implemented optimization text proved small give high variation tagging accuracy algorithm properly 
implementation markov model text tagged tokenized word punctuation mark identified 
tokenization trivial task mainly periods abbreviations numbers full stops 
flex implemented simple tokenizer tagger 
text tagged checked error rules text may re tokenized 
corpus tokenized evaluated performance tagger degraded poor tokenization 
tokenization text divided sentences sentence tagged separately 
little sense cross sentence boundaries correlation words tags adjacent sentences weak 
scope algorithm words little information traverses sentence boundaries anyway 
dynamic programming implementation viterbi algorithm need data structure object named position sentence tagged 
keeps track possible tags specific position probabilities calculated far combinations tags positions best tag position 
tagging new sentence initialize array gadget setting tags sentence delimiter tag seen 
sentence delimiter tag introduced algorithm properly 
training corpus tags inserted sentence order get proper statistics 
gadget max sentence length gadget gadget initialization gadget dynamic programming 
initialization walk word sentence compute probability equation possible combination tags trigram current word 
best probability possible tagging words stored gadget 
sentence reached sentence delimiter tags inserted algorithm works backwards positions gadget retrieve best tagging sequence 
algorithm 
tagging unknown words simple approach tagger encounters unknown word text obviously equation straight away statistical information gathered particular word 
way estimate lexical probability unknown words lexical probabilities substituted equation unknown 
simple approach estimate count number word types sentence word period int gadget gadget gadget contains current word token subsequently chosen tag word word assigns possible tags lexical probabilities 
int const tag tag tag int const tag tag tag best int const tag tag tag prob prob tags pt tag tag tag prob best best prob prev index position giving best probability prob best tag walk backwards gadgets extract best tag sequence rewind gadget heart tagging algorithm 
cm tagged tag training text cm tag set cm estimate 
estimate results unknown words tagged correctly 
better performing statistical morphological analysis unknown words 
intuitively just looking letters word fair guess syntactic functionality word 
true swedish english inflectional languages 
analyzing word endings ideally morphological analysis unknown words done program finds roots suffixes words example described 
devoid program examined method require additional information morphology words 
simply count number word types common endings length tag tag set 
endings just occurring word endings length ranging estimate tag set optimization parameters 
tagging accuracy increased increasing significant improvement detected greater 
estimate encouraging unknown words correctly tagged 
analyzing compound words contrary english language large portion swedish words compounds 
compounds frequent unknown words deserve special attention 
successful decomposition unknown compound word strong evidence correct possible tags word word form compound determines part speech 
algorithm decomposing compounds word form parts implemented 
awaiting incorporation program simplified algorithm works way possible compound divided parts optional letter suffix word happens word lexicon lexical probabilities improve estimate part possible compound word lexicon compound part word lexicon 
contrary compound method verify compound correct consider possible ways compound construction 
defined suffix 
introducing improved tagging accuracy unknown words 
initially compounds categorized prefix word different weights reflect assumption prefix indicates correctly identified compound incorrect analyses categorization improve performance 
resulting lexical probability final defined 
approach tag unknown words morphology context taken account 
experiment str exponent see modifying markov model equations order monitor relative impact morphology versus context carried improvement performance reached 
optimization set tags considered reduced half tags tag set tags function words prepositions determiners 
classes words considered closed lexicon contain words 
consequently tags content words nouns verbs need considered 
computed content tags best tags equation 
varied optimization tagging accuracy increased increasing significant improvement detected greater 
equation takes time proportional word compute 
implementation considerations section discuss problems corpus modifications 
describe number implementation details concerning speed memory usage 
efficiency portability reasons chose implement program 
selecting corpus currently available tagged swedish corpus stockholm ume corpus suc choice corpus easy 
suc consists words divided texts words 
tag set consists different tags 
easily observed corpus small give reliable tag trigram counts model 
average count occurring tag trigrams merely occurring tag trigrams occur just 
furthermore tags tag set occurrences corpus tags occur times tags occur times clearly statistical observations unreliable 
corpus divided training part optimization part evaluation part 
optimization evaluation parts consist words 
statistics extracted corpus unix utilities flex tr sort uniq cut wc comm sed 
modifying tag set suc tag set better suit purposes decided remap tag set ways 
firstly removed common tags uniting tags single tag removing unreliable data 
reducing number tags reduced amount information retrieved stored lexicon 
secondly introduced new tags thought original classification coarse 
example suc distinction auxiliary verbs verbs run eat 
types verbs clearly different syntactic behavior motivates new tag auxiliary verbs 
suc uses tag cardinals singular en plural tv 
introduced number feature cardinal tag 
restricted extend tag set remapping corpus automatically 
remapping requiring manual inspection mean 
task evaluating impact modifications tags time consuming involves building new lexicon optimizing tagger 
confined evaluate impact total remapping tag set leaving unaware quality single modification 
evaluation showed removing tags adding new tags improved tagging accuracy modest 
adding extra words lexicon matter large training corpus considerable amount unknown words texts tagged 
fortunately access word list containing words cases word class classified 
modifying existing word form generator possible word forms generated word base form 
generated word forms including base form assigned possible suc tags order words included existing suc lexicon 
extension increased number known word tags 
problem 
statistical information available estimate lexical probabilities generated words means estimate probabilities 
problem concerned unknown words encountered tagging text 
simple solution chose morphological analysis unknown words described section tagging unknown words 
analysis gives probability distribution tag set morphology word 
probabilities way reflect common different word forms sense estimate 
probabilities straight away words unknown suc 
word tags consisting known suc word unknown tag word problem 
existing lexical probabilities extended extra probabilities new tags way 
word count high existing lexical probabilities probably word count low 
heuristics showed increase tagging accuracy words suc suc suc optimization parameters 
effect tagging word greater influence common suc words 
adding words word tags reduced number unknown word tokens test text reduced number unknown word tags 
tagging accuracy increased 
tagging accuracy unknown words compared known words quite dramatic improvement tagging accuracy expected lexicon expansion 
economic way word forms add known suc words 
approach combination generating word tags known suc words derived reduced number words tagged correct tag training text tagging accuracy increased 
fast loading lexicons design requirements tagger fast means program load lexicon fast 
ideal situation lexicon structures pointers memory locations 
lexicon loaded big chunks data files directly memory 
avoiding pointers completely impeding quality code avoiding dynamic structures appropriate fast loading possible 
tagging model data collected training text considered static need dynamic structures main lexicon 
information word main lexicon equal size string word number different tags associated word 
allocating memory word strings word tags time obvious way save space time 
furthermore word strings drag drag share letters stored location 
sharing memory locations reduced total size word strings 
lexicon structure storing statistics word endings described section tagging total size word strings reduced 
main lexicon stored file word strings word tags stored big chunks data 
actual memory location pointer stored 
word strings word tags loaded probably different memory location 
case word structures word strings changed appropriately 
method effectively combines pointers high speed storing loading course requires careful implementation avoid erroneous pointers 
initially main lexicon data stored number files created extraction statistics training corpus 
lexicon loaded time hash tables structures constructed lexicon stored file fast format 
format basically memory contents information sizes memory locations 
time lexicon loaded program automatically uses fast format files 
slow fast loading modes allow original lexicon files convenient format requirement speed initial slow loading 
subsequent loadings lexicon hand fast 
speed optimizations main lexicon words stored static hash table slots table word structures pointers word structures 
design saves indirection look saves pointer word 
size table number words means memory loss 
collisions hash table resolved link slot link index place table 
design pointers hash table responsible fast storing loading provided hash table objects relocated memory 
hash tables require hash function objects simple hash function word strings turned satisfactory 
hash function average number collisions table maximum number collisions 
static hash table main lexicon words tag bigrams word endings tags tag trigrams 
unknown words detected tagging stored standard dynamic self resizing hash table 
int key string int val val val xor scatter return val hash function program 
array scatter function random number maxint 
experimented storing key hash table object object avoid multiple computations hash function words tag trigrams increase tagging speed 
order optimize speed optimization parameters declared constants release version program 
pre computing mathematical expressions possible example trigram probabilities lexical probabilities equation speeds tagging 
problem equation long sentences tagged probability approach zero 
problem avoided log probabilities transforming equation sum terms normalizing probabilities half way sentence probabilities grow small 
chose approach bytes storing probabilities sentences required normalization bytes 
require equations unknown words transformed easily done 
alternatively require resulting probability distribution run time quite time consuming 
applications tagger probabilistic tagger different applications 
discuss applications grammar checking spell checking 
grammar checking constructed tagger order apply swedish grammar checking program called 
conclude section syntactic disambiguation dramatically improved quality grammar checking respect possibility finding errors false alarm rate 
grammar checking algorithm discovers grammatical errors error rules 
rule describes erroneous construction notation uses part speech tagging text 
shows example error rule 
application demands tagger somewhat different applications 
firstly incorrectly tagged word problem occurs correct sentence incorrect tagging triggers error rule happen 
secondly tagger able tag text containing errors reasonable consistent way possible express different types errors error rules 
conjecture general stochastic taggers tag texts errors better rule taggers 
dt spec def definite article jj gen gen num num spec ind indefinite adjective nn gen gen num num spec def definite noun adjective agree noun error rule discovering indefinite adjective definite noun 
interestingly possible error rule matching improve tagging 
cases stochastic tagger errors systematic way example tags word write error rule recognizes erroneous tagging re tags sentence forcing tagger tag re applies error rules 
correction rule instance capture simple feature agreements captured markov model due short scope 
example second order markov model decide noun singular plural sentence gra bra tables number word revealed number word 
cases simple matter construct correction rule help tagger select correct tag 
type correction rules sort rewriting rule similar ones rule tagging algorithms tagger called hybrid tagger stochastic rule methods recommended best technique construct high quality taggers 
interesting difference hybrid tagging approaches tagger uses rule methods stochastic methods tagger uses stochastic methods rule methods new rounds stochastic rule methods 
unfortunately able evaluate tagging obtained correction rules think substantial improvement 
probabilistic spell checking working probabilistic tagger hand started develop probabilistic spell checker 
spell checker identifies suspicious sentence measure related probability obtained equation changes sentence order suspicious alternative suggests alternative original suspicious sentence 
method captures errors traditional spell checkers errors misspelled word happens word word list adjacent words interchanged omitted extra word slipped sentence mistake 
application successful correct types text errors normally taken care grammar checkers incorporated rule grammar checker 
spell checker constructed successfully identified corrected incorrect versions sentence jag har en bil car table tagging results 
sentences words including punctuation marks unknown words hard words correctly tagged sentences correctly tagged words unknown word errors errors hard word errors errors known word tag errors errors accuracy unknown words accuracy known words accuracy words jag har en bik 
unknown word bik jag har en bi 
noun bi causes jag en har bil 
swapped words jag har en har bil 
superfluous word har jag en bil 
missing verb spell checker successfully correct complicated sentences remains investigated toy examples show method promising 
evaluation performance speed memory requirements main lexicon constructed statistics derived suc uses mb memory 
extended suc lexicon occupies mb 
suc lexicon containing word tag pairs tagger loads seconds tags words second sun sparcstation ultra 
suc lexicons word tag pairs tagger loads seconds tags words second 
speed degradation tagging large lexicons 
quality tagging suc consists words divided texts words 
separated randomly selected word texts corpus optimization evaluation 
tagging results quite encouraging 
equation obtained tagging accuracy 
text word tokens unknown tagger words tagged correctly far better initial goal 
results test text tagging table 
analysis incorrectly tagged words revealed unknown words tagger bad choice 
hard words known words tagged wanted tag training text 
words named hard current model tag correctly 
remaining errors tagger wrong tag selection word tagged correct tag training text 
analysis indicates primarily concentrated improving tagger choice known word tag combinations 
course improvement tagging particular group words means possible improvement tagging groups choice word dependent choices surrounding words text 
tagging errors due previously unseen word tags motivated allow known tags particular word selected tagging known words including tags seen particular word training text 
allowing tags selected slow tagging probably introduce errors cure 
assumption true remains investigated 
extending suc lexicon words described implementation considerations unknown words reduced 
tagging accuracy improved 
modest improvement respect cost lexicon size grows factor 
interesting see language model allows tagger select highly lexically improbable tags ambiguous words 
sentence vad sm min vad 
causes pain calf 
tagger correctly tags occurrence vad pronoun second occurrence noun 
tagging despite fact vad tagged pronoun times noun times training text 
apparently contextual information strong impact model tagger guess case 
comparisons taggers able relevant comparisons different taggers language tag set training test texts 
reported tagging results complete suc know estimate capability tagger compared 
ume tagger uses subset words suc tag set tags reports tagging accuracy 
algorithm derived algorithm uses type statistical information algorithm unknown words treated way 
unknown words ume tagger cheats chooses tags tag unknown word test text 
new word types tagged tag test text way treating unknown words corresponds having correct tagging words 
presumably hard words eliminated ume tagger way 
discrepancy approach means tagging accuracy taggers compared 
tagging speed compared 
ume tagger tags words second compared tagger tags words second sun sparcstation 
investigation tagging errors manual inspection tagging errors optimization text words indicated errors hard tag correctly language model 
long scope understanding text means disambiguation needed 
errors caused incorrect tagging supposedly correct suc text 
fact indicates complete suc contains incorrect error rate 
errors ascribed inconsistent tagging suc tagging errors training text 
words constructions tagged different ways obvious reasons 
observation gives hand tagging error rate reduced just revised version suc 
correcting errors test training texts improved tagging accuracy 
remaining errors considered reach tagging correctly 
errors different types require different approaches solving small expected improvement 
example inclusion tag bigrams equation gave modest improvement model 
tagger grammar checker performance texts grammatical errors interest 
order test performance test text sentences agreement errors compiled authentic texts 
example den small house determiner den det determined sentences tagged way error rules match faulty construction 
error rules hand old version detected faults 
rules doing syntactic disambiguation done old faults detected 
syntactic disambiguation false alarms generated text disambiguated 
test words suc error rules gave false alarms disambiguation disambiguation 
apparently syntactic disambiguation important grammar checking swedish text increases possibility discover errors reduces false alarms 
discussion major inherent limitation markov model short scope 
second order model capture dependencies span words 
example determine singular plural hans violin known piece require fifth order markov model depends number word sentence 
required size training text grows exponentially order markov model large training text avoid sparse data problem 
methods correction rules required 
decision employ stochastic language model resulted versatile tagger mentioned earlier languages tag sets applications needing pos tagging 
seen reports taggers greater tagging speed believe state art tagger terms speed 
improve tagger error correction rules see section applications tagger hope construct state art tagger terms accuracy 
exists www version tagger test 
url www nada kth se theory projects acknowledgments funded swedish research councils tfr 
spr teborg university swedish academy source words 
prof eva ume university prof stockholm university suc 
ola knutsson carried manual inspection tagging errors evaluated grammar checking performance 
ide ronis 
special issue word sense disambiguation state art 
comp 
linguistics 
charniak hendrickson jacobson perkowitz 
equations partof speech tagging 
th national conf 
artificial intelligence pages 
cutting kupiec pedersen sibun 
practical part speech tagger 
rd conf 
applied natural lang 
process pages 
acl 
kokkinakis 
automatic stochastic tagging natural language texts 
comp 
linguistics 
derose 
grammatical category disambiguation statistical optimization 
comp 
linguistics 
kupiec 
robust part speech tagging hidden markov model 
comput 
speech lang 
merialdo 
tagging english text probabilistic model 
comp 
linguistics 
brill 
simple rule part speech tagger 
rd ann 
conf 
appl 
natural lang 
processing pages 
acl 
voutilainen 
syntax part speech analyzer 
th conf 
european chapter assoc 
comp 
linguistics pages 
acl 
mackie anderson 
syntactic category disambiguation neural networks 
comput 
speech lang 
samuelsson voutilainen 
comparing linguistic stochastic tagger 
th ann 
meeting assoc 
comp 
linguistics pages 
acl 
tapanainen voutilainen 
tagging accurately don guess know 
th conf 
applied natural lang 
process pages 
acl 
charniak 
statistical language learning 
mit press cambridge massachusetts 
viterbi 
error bounds convolutional codes asymptotically optimal decoding algorithm 
ieee trans 
inf 
theory pages 
str probabilistic tagger swedish suc tagset 
technical report department linguistics university ume ume 
press flannery teukolsky vetterling 
numerical recipes 
cambridge university press cambridge 
grefenstette tapanainen 
word sentence 
problems tokenization 
rd int 
conf 
comp 
lexicography pages 
kann 
detection spelling errors swedish word list en 
quantitative linguistics 
kann 
home page 
www nada kth se 
kann 
implementation aspects applications spelling correction algorithm 
koehler editors text linguistic paradigm levels constituents constructs 
festschrift honour 
universitat verlag trier germany 
appear 
available www www nada kth se theory projects swedish html 
str linguistic annotation system stockholm ume corpus project 
technical report department general linguistics university ume ume 
web page suc www ling su se dali projects suc 
swedish academy 
ver spr ket 
stockholm th edition 
knutsson larsson eklundh 
rex 

technical report department numerical analysis computing science royal institute technology stockholm 
