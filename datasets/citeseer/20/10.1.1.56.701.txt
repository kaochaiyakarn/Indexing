dataflow query execution parallel main memory environment wilschut peter apers university twente box ae enschede netherlands performance characteristics execution various join trees parallel dbms studied 
results study step direction design query optimization strategy fit parallel execution complex queries 
synchronization issues identified limit performance gain parallelism 
new algorithm called pipelining hash join introduced fewer synchronization constraints known hash join algorithms 
behavior individual join operations join tree studied simulation experiment 
results show pipelining hash join algorithm yields better performance multi join queries 
format optimal join tree appears depend size operands join multi join small operands performs best bushy schedule larger operands better linear schedule 
results simulation study confirmed analytic model dataflow query execution 
years attention paid development parallel dbmss 
specialpurpose hardware shown successful parallel dbms running general purpose hardware appears right choice deg 
various query processing strategies implemented dataflow query processing appears superior control flow scheduling dgs 
studies query processing general purpose shared dataflow architecture 
teradata ter gamma dgs bubba bac hc brg prisma ame examples parallel dbmss implemented 
systems exploits sort parallelism speed query execution 
query inter operator parallelism discriminated scd 
orthogonal distinction pipelining contrasted pure horizontal parallelism 
type called parallelism papers 
parallelism primary source parallelism projects mentioned 
type parallelism understood efficient execution strategies simple queries wisconsin benchmark bdt consists simple queries large volumes data describe performance system brg dgs 
dataflow architecture offers possibility exploit inter operator parallelism pipelining allocating different relational operations different sets processors 
potential different types parallelism query turns query optimization difficult problem solved conventional query optimization techniques 
far little done research area identified important development parallel dbmss bac deg 
query optimizers parallel dbmss theory developed sac theory particularly fit parallel dataflow query processing 
example linear query trees considered class trees necessarily include optimal parallel environment 
attempt understand effect various query tree formats scd studies behavior left deep linear query trees multi join queries 
concluded right deep scheduling performance advantages context gamma 
gra shown arbitrarily shaped query trees parallelized exchange operator splits part query tree number subtrees executed parallel 
clear certain query trees parallelized solve problem type query tree performs best 
study execution multi operation queries 
ultimate goal study design query optimizer parallel dbms 
relational queries example join important expensive relational operation 
outline path want follow research follows query optimization comes selecting execution strategy low costs 
searching entire space possible strategies feasible query optimizers heuristic bor jak 
heuristics insight essentials query execution 
design heuristic query optimizer parallel dbms essential understand behavior execution strategies query parallel dbms 
modeling way gain insight essentials parallel query execution 
approaches modeling study simulation analytical modeling 
resulting knowledge eventually lead formulation query optimization heuristics 
emphasized aim detailed quantitative model parallel dbms simple understandable framework nature yields insight modeled phenomenon 
intuition sort model validate heuristics yield heuristics validated real dataflow dbms detailed simulation available 
methodology described paragraph similar methodology common science scientists try understand natural phenomena modeling 
subsequently hypotheses formulated model hypotheses validated reality experimentation 
describes step path outlined 
results simulation study described 
resulted proposal new fit dataflow query execution 
execution characteristics multi join queries studied 
attempt fully understand results simulation study led derivation analytical model 
results analytical model confirm results simulation study 
near want follow path extending analytical model 
step lead formulation query optimization heuristics 
research reported carried context prisma db ame kah 
prisma db parallel main memory relational dbms runs node shared architecture 
fact prisma main memory system plays important role research 
price primary memory fallen sharply years 
trend expected continue interesting question arises huge amounts memory 
study question specialized large primary memory yield performance gain dbms 
willing accept large amounts memory performance gain expected return 
remainder organized follows section describes dataflow query execution main memory environment 
section presents simulation results 
section introduces analytical model elaboration join operations join trees 
section summarizes concludes 
dataflow query execution main memory parallel dbms running hardware features hardware consists number processors communicate message passing network 
processor hosts part base data 
processor access part base data directly 
processor wants access data stored processor sent network 
query relational database represented dataflow graph 
nodes graph represent extended relational algebra operations wig 
processor run operations processes 
want study inter operator parallelism operation process assumed private processor 
operation processes evaluate local data tuple streams sent message passing network 
result evaluation xra operation consists multi set tuples 
result stored locally case accessed local processor sent operation processes 
case sending receiving operation processes run concurrently forming pipeline 
network transport tuples modeled follows transport tuple process remote process wrapped put network hardware sending operating system sent network retrieved network unwrapped receiving operating system 
sending tuple network implies cpu costs sending receiving processor actual transmission implies delay 
general cpu costs involved appear limiting factor rate tuples transported network determined capacity cpus send receive tuples capacity network hardware 
tuple transport modeled terms cpu costs processors deg constant transmission delay 
simulation dataflow query execution section describes results simulation study 
simulation program described study join algorithms describe simulation multi join queries 
simulator study execution characteristics query simulator parallel query execution developed 
input simulator schedule query 
output consists diagram operation process schedule 
diagrams plot processor utilization behalf operation process time 
horizontal time axis scaled 
shows example diagram 
sample output simulator simulator models local processing network transport tuples 
local processing model uses simple cost formulas relational operations 
network transport tuples modeled cpu costs sending receiving processor description 
simulator parameterized costs simple operations tuples 
parameter values measured prisma db 
join algorithms choice join algorithm influences execution characteristics join query different ways 
firstly processing communication costs influenced 
schneider dewitt scd give overview known join algorithms evaluate performance simple join queries experimentation 
hash join algorithms shown efficient ones equi joins 
algorithms considered 
secondly synchronization joins participate complex join query determined join algorithm 
section synchronization requirements known hash join algorithm studied 
requirements tight allow considerable performance gain pipelining new main memory hash join algorithm proposed fewer synchronization requirements 
known hash join algorithms grace hash join simple hash join hybrid hash join disk differ way disks 
main memory version algorithms dealt 
algorithm called simple hash join 
hash table hash table hash table matching matching simple hash join pipelining hash join simple hash join pipelining hash join algorithm simple hash join simple hash join algorithm consists phases see 
phase entire operand read memory hash table 
second phase tuples operand read tuple hashed compared tuples corresponding bucket hash table operand 
match output tuple produced 
algorithm asymmetric operands join operation conceptually symmetric 
result formed second phase algorithm 
pipelining hash join pipelining hash join algorithm see aims producing output tuples early possible process calculating join decreasing performance join operation 
join process hash table operands built 
join process consists phase 
tuple comes hashed probe part hash table operand constructed 
match result tuples formed 
tuple inserted hash table operand 
tuple operands processed join process building hash table operand hash table 
keeping feature mind easy see pipelining hash join degenerates simple hash join operand available join process entirely tuple operand arrives 
pipelining hash join algorithm symmetric operands 
evaluation simple hash join pipelining hash join shows execution characteristics simple hash join processes pipelining hash join processes way multi join oea oec oed visualized simulator 
shows join tree query join symbols tree replaced diagrams corresponding join processes 
time axis diagrams scaled way 
hash join pipelining hash join join processes read input selection processes produce output limiting rate 
pipelining hash join faster start simple tuples belonging operands processed right 
pipelining hash join starts producing output earlier simple hash join 
consumer result pipelining hash join start earlier consumer simple hash join 
result response time evaluation pipelining hash join better 
cpu utilization pipelining hash join increasing time 
caused increasing probability find matching tuples hash tables filled 
join operations higher join tree effect enlarged fact operand tuples arrive join process increasing rate 
difference synchronization requirements described shows pipelining hash join allows inter operator pipelining simple hash join fits naturally dataflow execution model 
asymmetry simple hash join algorithm explains difference performance right deep scheduling reported scd 
symmetric algorithm pipelining hash join yields performance linear join tree 
section behavior linear join trees jointree formats studied 
multi join queries section trade offs differently structured query trees execution multi join queries discussed 
performance simple pipelining hash join multi join queries compared 
shows join query linear bushy join tree query 
bushy join tree linear join tree bushy linear join tree trade offs join tree formats terminology introduced 
term hop transmission join operation parent operation consuming output operand 
termination delay hops difference termination time adjacent join operations 
term delay short hand termination delay 
various types nodes join tree identified 
ffl leaf nodes tree base relations operands 
base relations available join process immediately 
ffl intermediate nodes linear tree intermediate nodes bushy trees base relation intermediate result operands 
available join process immediately join process wait operand available previous join operation 
ffl bushy join trees contain join processes intermediate results operands 
join process wait operands join process start immediately 
having choose join tree join query faced trade join processes linear join tree start immediately hashing operand way fill time waiting operand 
hand linear join tree contains longest possible pipeline causing large number delays top 
pipelines bushy join tree shorter ones linear intermediate join processes wait operands may lead large delays 
section experiment described shows optimal format join tree multi join depends size operands 
experiment study execution characteristics various join trees join relations equal numbers tuples matching tuple operand exactly tuple operand studied 
possible join trees query yield amount joining data communication costs 
individual joins query equal 
differences response time caused sort join tree 
sub experiments way join described evaluated operands resp tuples 
response times queries measured simulator linear completely bushy tree 
response times shown table 
pipelining bushy hash join linear simple bushy hash join linear table response times firstly want pipelining algorithm outperforms simple hash join cases 
difference performance larger bushy scheduling linear scheduling 
caused fact pipelining hash join degenerates simple join operations relatively close root linear tree 
remainder section schedules pipelining hash join considered 
apparently bushy scheduling performs better small operands linear scheduling better large operands 
figures show execution characteristics linear bushy query trees small large operands 
figures show join trees 
join symbols replaced diagrams corresponding join processes 
join tree time axis scaled response time corresponding query 
linear tuples linear tuples execution characteristics linear join trees diagrams see linear tree constant delay pipeline adjacent joins 
delay depend size operands 
diagrams show distinct phases processing join 
phase construction hash table base relation operand 
phase joining operand hash table 
lower join operation phases mixed described pipelining algorithm 
join tree longer join operation wait second operand 
certain point complete hash table base relation operand ready tuple second operand arrives 
point pipelining hash join behaves similar simple 
point operands join processed completely separately reached earlier small operands larger ones 
diagrams bushy tree lead observations 
leaf nodes show characteristics leaf node linear tree 
delay hop larger case linear tree operand directly available 
query hop yields approximately delay 
closer look characteristics shows delay hop proportional size operands operands tuples 
proportionality surprising bushy tuples bushy tuples execution characteristics bushy join trees result accounted intuitively 
difference termination delay linear bushy trees explain fact bushy trees better small operands linear trees larger operands 
size operands grows termination delay response time bushy tree grows proportionally 
linear trees hand termination delay grow contribution total response time decreases increasing operands 
certain operand size linear trees outperform bushy ones 
parameter setting simulation experiment break point lies tuples 
section introduces mathematical model dataflow query section explain simulation results bushy join trees 
analytical model dataflow query execution input relational operation output dataflow query execution section analytical model dataflow execution developed 
general model specialized model specific relational operations 
analytical model explain surprising proportional termination delay bushy query trees previous section 
preliminaries resources model model describes rates tuples transported processed dataflow system 
utilization processors participating dataflow system modeled 
described bandwidth message passing network assumed exceed requirements application utilization hardware modeled 
deals retrieval main memory context retrieval need disk accesses 
need model secondary storage 
resource taken account cpu 
resulting model simple consequently powerful complete analysis possible classes queries 
modeling discrete phenomena tuples discrete entities 
model continuous 
continuous model discrete phenomenon possible large numbers events described 
transition discrete continuous model eliminates need probability theory discrete model probability tuple generated continuous model generate half tuple 
way modeling generally accepted physics biology problems 
entities dimensions rate tuples transported processed utilization processors modeled 
costs certain operations expressed 
tuple transport expressed number tuples time unit 
processor utilization dimensionless maximum 
costs operations expressed time units tuple 
consider example operation processes tuples rate tuples time unit 
processor spends time units processing tuple 
resulting processor utilization ax dimensionless 
definition dataflow model summarizes essentials dataflow operation 
large box represents processor small box represents operation process 
data sent operation process bottom box result sent away top box 
terminology operation process operands 
join binary operation considered operands 
input stream contains arrows arrow indicates rate tuples available operations process second represents rate tuples processed operation process 
arrow output stream indicates rate result tuples produced 
left column shows formalism rate tuples particular operand available operation process time rate tuples particular operand processed operation process time processor utilization time rate tuples produced time functions labeled subscript indicate operand meant 
query execution consists number communicating operation processes 
time indicate starting point entire query 
operation processes query may idle time 
time operation process ready 
relationships description dataflow execution relationships deduced operation process process tuples operand arrived input stream 
modeled processor utilization function rate operand tuples processed rate tuples produced function rate operand tuples processed cpu works full capacity utilization 
larger 
model discriminates rate operand tuples available rate processed 
done rates may differ operation process keep rate tuples sent 
observation leads definition different modes operation process 
input limited mode tuples sent operation process low rate operation process keep rate 
operands 
cpu limited mode tuples sent operation process high rate receiving processor keep rate operand 
discrimination leads central equation process input limited meets process cpu limited equation evaluate behavior operation process 
outline evaluation follows equation expresses cpu utilization function rates operand streams processed 
input limited mode operation process evaluation comparing result maximal cpu utilization reveal operation process input limited cpu limited time operation process rate operand streams processed clear 
hand process appears cpu limited solving equation shows rate operand tuple stream processed 
knowing functions mapping rate tuples produced operation process calculated 
result operation process sent input operation process 
tuples assumed arrive receiving operation process delay rate produced producing operation process 
function consumer known position evaluate behavior consumer process 
summarizing model maps rate operand tuples available rate result tuples produced 
describe query tree result evaluation operations input 
remainder section model developed specialized describe pipelining 
results evaluation study bushy join trees 
cases goal full characterization participating operations terms rate operand tuples available 
pipelining hash join section assumed operand tuples operands available non limiting rate operation process processes cpu limited mode 
general case join process works input limited cpu limited dealt 
operands equal size contain tuples 
selectivity join operation assumed result contains tuples 
description pipelining join algorithm clear join algorithm processes tuples operands rate 
goal section finding deriving 
join operation operand tuple available join process hash value calculated inserted hash table compared tuples corresponding bucket operands hash table 
costs assumed constant join process match result tuple generated 
costs associated producing tuple assumed constant 
distinction dedicated processing operand tuples generating result tuples essential 
distinction insight gained operation process maps input streams output stream 
model tuples operands processed rate 
amount processor spends processing input tuples equal ax transmission delays easily handled model influence results simple 
formalism complicated transmission delay assumed small compared time needed evaluate relational operation 
choose incorporate model 
costs increasing slightly join process due fact hash buckets filled 
hash table minimizes increase 
factor expression tuples operands processed 
amount spent generating result calculated follows probability tuple arriving time produces match proportional number tuples arrived operand 
number tuples arrived operation process certain time equal integral rate tuples arrive number result tuples formed arrival tuple time equal expression amount spent generating result formulated sx cpu utilization equal sum amount spent processing input amount spent generating output 
ax sx join operation processes cpu limited mode equation specialized meets ax sx finding rate operand tuples processed ready find equation 
integral equation solved elementary calculus wil st bottom row shows diagrams plot expected decreases time join processes advances effort spent generating result tuples hashtables filled 
termination join process join operation ready time time tuples operand processed substitution equation solving equation yields sn result reasonable operand tuples result tuples processed 
processing costs sn units time 
cpu utilization equal entire join process join process sn output stream rate result tuples produced derived equation gamma ax substitution yields gamma st top row shows diagrams plot time 
increasing time probability finding match join process increases time 
join processes different selectivity shows diagrams characterization pipelining joins different selectivities different join processes join operations illustrated selectivity join chosen result contains tuples selectivity join result contains tuples 
join operation column diagram second join operation second 
topmost diagrams show rate result tuples generated function time 
rate increasing time due increasing probability finding match 
join operation equal zero due fact tuples form match arrived 
expected second join operation produces tuples higher rate 
middle diagrams show processor utilization function time 
join operations entire operation processor utilization equal 
diagrams additional curve part symbolic manipulation generation plots results manipulation carried symbolic manipulator maple cgg 
shows portion cpu effort spent processing input tuples area curve portion spent generating output area 
see selective join operation spends larger portion effort generating output cases amount related generating output increases expense processing input 
bottom diagrams show rate input tuples processed 
expected rate decreasing effect stronger second join operation 
model developed section yields analytical expression rate output tuples produced equation 
section output stream single join operation input way join trees studied 
symmetric bushy join trees behavior symmetric bushy join trees analyzed 
shows symmetric tree way join 
assumed operands equal size operand contains tuples join operations match tuple left operand exactly tuple right operand selectivity join operations equal join operation private processor 
bushy join tree simulation experiment described section corresponds sort join trees modeled 
clear join operations base relations operands execution characteristics 
join operations called level joins 
join operations join results level joins characteristics 
called level joins 
way level level higher levels defined 
model assumed base operands available level joins non limiting rates 
characteristics joins described section 
describe levels notation conventions needed 
section subscripts indicate level join operation 
due symmetry problem need discriminate input join operation 
denotes rate tuples level join operand processed 
level joins operate cpu limited mode 
higher level joins expected show increase cpu utilization start input limited time switch 
symbols describe time cpu executing join saturated 
time join process switches input limited cpu limited mode 
equal 
number tuples collected hash table operand join time equal result tuples level sent input level 
derive model join operation bushy join tree 
equation characterize input rate central equation model operation process 
furthermore expression cpu utilization pipelining join derived previous section 
combination equations definition yields model level bushy join tree gamma meets ax equations solved explicitly wil gamma gamma ffi gamma ax iffi ffi proportional gamma ffi proportional solution looks complex interpreted way 
ffl phases discriminated join process startup phase join process saturate processor main phase join process cpu limited 
level join startup phase length startup phase 
ffl main phases subsequent join levels similar apart translation ffi time 
implies main phase subsequent level starts ends ffi time units predecessor 
important thing note fact subsequent level terminates ffi time units 
ffi proportional number tuples operand fact confirms observation termination delay bushy join tree proportional number tuples operands 
ffl startup phase join operation takes longer higher levels number tuples processed consequently amount done startup equal level 
examples shows diagrams plot time level level 
similar diagrams additional plot diagrams shows portion cpu time spent processing input 
columns diagrams column way join operands tuples second shows join operands tuples 
level level level join processing bushy tree time axis diagrams scaled way 
comparison diagrams column shows delay subsequent levels constant 
comparison diagrams shows termination delay proportional number tuples operand 
optimization scheduling multi join queries model join trees extended cover general join trees indicated sort results model yields results symmetric bushy trees example query optimization query scheduling 
apparently results indicate amount done behalf relational operation give indication done busy processor 
examples illustrate scheduling information 
ffl query optimizer having select execution strategy query amount done timing information 
possible expensive schedule terms total processing costs timing characteristics response time 
response time important system schedule selected 
ffl knowledge processors busy scheduler processor assigned relational operation purposes possibly relational operation time idle 
ffl model bushy query trees shows execution join startup main phase discriminated 
scheduling join postponed time iffi main phase join left startup phase uses processor full capacity shorter period time 
postponing scheduling join time iffi affect response time entire query 
characteristics level join shown 
left diagram shows characteristics join scheduled immediately query startup right shows characteristics join scheduled time ffi 
scheduling join processes limited type join trees modeled section feel model increased insight working pipelining join algorithm cooperation producers consumers 
specifically fact model predict higher level join operation need cpu capacity encouraging 
fact postponing scheduling certain extent influence response time entire query easily scheduler different relation operations scheduled subsequently processor 
reported part research query optimization strategies parallel dataflow dbms 
methodology research outlined 
illustrated gaining understanding parallel dataflow query processing essential step 
understanding design heuristic query optimizer parallel dataflow dbms 
reported introduced step direction understanding parallel dataflow query execution 
looking back faced questions insight gained study knowledge knowledge validated 
questions answered turn 
learn study 
ffl simulation study showed different aspects algorithms relational operations query tree important 
apart course cpu costs algorithm synchronization processes produce consume input output important yield performance 
shown known simple hash join algorithm synchronization requirements tight allow performance gain pipelining 
new hash join algorithm pipelining hash join proposed expected give performance dataflow system 
algorithms relational operations studied way 
pipelining algorithms possible relational operations 
ffl simulation study various join tree formats gave insight behavior individual join processes relationship position join tree 
shown time join operation start processing depends position join operation join tree sizes operands 
regular linear bushy trees studied extensively 
join tree formats need additional study 
ffl mathematical model developed confirms simulation results 
model predict effect changes scheduling join processes indicated previous section knowledge 
gained insight ways 
firstly pipelining algorithms dataflow systems 
secondly query optimization design ideas developed feasible 
knowing cpu costs delays incurred join tree response time join query calculated 
cost evaluation combination known query optimization techniques search part space possible execution strategies find cheapest 
insight timing requirements scheduler illustrated 
validate knowledge 
currently planning experiments latest version prisma db 
path research requires study general join trees 
preliminary direction done results encouraging 
plan incorporate relational operations model want study effect distributing individual relational operations 
model evaluated limited class queries statements scheduling operations query trees 
emphasized explained statements validated 
parallel query execution 
concrete results study worthwhile probably eventually design new query execution strategies 
feel apart concrete results approach obtaining contribution database research 
experimental approach adopted science combined mathematical modeling observed phenomena opinion viable methodology tackle certain problems computer science 
ame america ed proc 
prisma workshop parallel database systems springer verlag new york heidelberg berlin 
bdt bitton dewitt benchmarking database systems systematic approach proc 
th vldb conference florence italy october november 
bor heuristic algorithms distributed query processing proc 
int 
symp 
databases parallel distributed systems austin texas usa december 
bac boral alexander clay copeland franklin hart smith valduriez prototyping bubba highly parallel database system ieee transactions knowledge data engineering 
brg development cross hc database computers proc 
th france june 
cgg char gonnet watt maple manual publications limited waterloo canada 
dgs dewitt ghandeharizadeh schneider hsiao rasmussen gamma database machine project ieee transactions knowledge data engineering march 
deg dewitt gray parallel database systems database processing passing fad sigmod record 
gra graefe encapsulation parallelism volcano query processing system proc 
acm sigmod atlantic city nj may 
jak jarke koch query optimization database systems computing surveys june 
kah kersten apers van weg prisma distributed main memory database machine proc 
th japan october 
van semantic query optimization distributed database systems phd thesis university twente 
diffusion ecological problems mathematical models springer verlag new york heidelberg berlin 
scd schneider dewitt tradeoffs processing complex join queries hashing multiprocessor database machines proc 
th vldb conference brisbane australia august 
scd schneider dewitt performance evaluation parallel join algorithms multiprocessor environment proc 
portland may june sac selinger astrahan chamberlin lorie price access path selection relational database management system proc 
boston usa 
control versus data flow distributed database machines memorandum inf universiteit twente enschede netherlands 
ter teradata teradata dbc database computer concepts facilities 
wil wilschut model pipelining hash join algorithm memorandum inf universiteit twente enschede netherlands 
wilschut apers pipelining query execution proc 
int 
conference databases parallel architectures applications miami usa march wilschut apers parallel query execution prisma db proc 
prisma workshop parallel database systems netherlands september america ed springerverlag new york heidelberg berlin 
wig wilschut grefen prisma db xra definition prisma document philips research laboratories eindhoven netherlands 
wilschut grefen apers kersten implementing prisma db proc 
th france june 
