emergence structure function evolutionary modular neural networks sung bae cho dept computer science university dong ku seoul korea mail ac kr atr human information processing research laboratories seika cho soraku gun kyoto japan mail hip atr jp concept emergence takes important role study artificial life exploit concept design neural networks 
evolutionary neural networks paid little attention fact evolve modules 
investigates emergence structure functionality modular neural networks evolution 
model develop new functionality spontaneously grow evolve structure autonomously 
show potential model applying visual categorization task handwritten digits 
sophisticated network architectures functional subsystems emerge initial set networks 
evolved neural network reproduced characteristics natural visual system organization coarse fine processing stimuli separate pathways 
evolutionary design optimal neural networks shown great possibility develop adaptive systems change architectures learning rules environments 
publications report new evolutionary design method neural networks :10.1.1.13.957
important advantages evolutionary neural networks adaptability dynamic environment supported part korea science engineering foundation ministry science technology korea 
adaptive process achieved evolution connection weights architectures learning rules 
designing optimal architecture neural networks formulated searching space point represents architecture 
performance level architectures forms surface space 
characteristics surface evolutionary algorithms promising candidate conventional ones 
previous evolutionary neural networks show little structural constraints 
networks assume total connectivity nodes 
assume hierarchical multi layered structure node layer connected nodes neighboring layers 
large body neuropsychological evidence showing human information processing system consists modules subdivisions identifiable parts purpose function 
question may raised design neural networks various modules 
extensive works design efficient architectures engineering point view produced success problems 
know comprehensive analytical solution problem relating architecture function 
architecture brain results long evolutionary process large set specialized subsystems emerged interactively carrying tasks necessary survival reproduction appears learning large scale task scratch networks may take long time 
takes module building block designing neural networks originally proposed investigates emergent properties structure function evolutionary algorithm similar genetic programming 
module offspring decoded strings reproduction parents new generation manipulation population evaluation selection genetic operators typical procedure evolutionary algorithm 
ability autonomously categorize input activation patterns discrete categories representations distributed modules individual nodes 
general principles modularity locality self induced noise self induced learning 
proposed model evolutionary neural networks able develop new functionality spontaneously grow evolve structure autonomously 
evolutionary neural networks overview order give autonomy creativity neural processing system vital system mechanism spontaneously generate change function structure 
basic idea consider module building block resulting local representations competition develop complex intermodule connections evolutionary mechanism 
computing terms evolutionary algorithm maps problem set strings string representing potential solution 
problem hand string encodes network architecture learning parameters tree structure 
evolutionary algorithm manipulates promising strings search improved solutions 
process operates simple cycle stages 
creation population tree structured strings 
evaluation string 
selection strings 
genetic manipulation create new population strings 
shows stages biologically inspired terminology 
date evolutionary algorithm similar genetic programming rank selection scheme 
interconnection nodes 
modular neural networks activation value node calculated follows see ij ij denotes weight connection node node effective input node weighted sum individual activations nodes connected input side node 
input may positive excitatory negative inhibitory 
module nodes designed model neocortical proposed 
constraints embodied model include 
dale principle individual neurons emit type transmitter 
learning local phenomenon require knowledge correct response 
capacity differentiate novel familiar input behave differently basis 
internal structure module fixed weights connections learning process see 
module node represents particular pattern input activations module node inhibits nodes module node activates positive function amount competition module node activation measure level competition going module 
important feature module autonomously categorize input activation patterns discrete categories facilitated association input pattern unique node 
process goes resolution winner competition nodes activated input 
presentation pattern module nodes activated equally results state maximal competition 
resolved inhibitory vnodes state dependent noise mechanism 
noise proportional amount competition measured number active nodes excitatory inhibitory communication control schematic diagram internal structure module simplified diagram module 
node node 
evolutionary mechanism gives possibility change phenotype module genetic operators 
interconnection modules means nodes module connected nodes module 
intermodule connections modifiable hebb rule equation deltaw ij gamma ij gamma lw ij ae activations corresponding nodes respectively ij nodes indicates neighboring node node deltaw ij change weight time 
note determines maximum value positive constants constant small value ae activation node 
mechanism generating change integrating changes system evolutionary algorithm determine parameters learning rule structure intermodule connections 
gene representation kinds information encoded genotype representation structure intermodule connection number nodes module parameters learning activation rules 
intermodule weights determined hebb rule mentioned previous section 
order represent genetic code encoded tree structure modular neural network architecture developed gene diagram 
information appropriately tree structure adopted 
arc tree expresses intermodule connection node represents specific module number nodes 
example genotype shown 
node number representing specific module 
information number nodes parameters learning activation rules omitted 
root tree input module replaces start symbol 
child node module number applied symbols represent modules connected mother module 
course decoding connections module ones input module ignored 
representation redundant connections meaningless ones define module path input output modules 
performing number genetic operators gene pool interconnection modules number changed 
designing gene represent interconnectivity possible generate variety offsprings evolve 
genetic operators genetic operators approach 
ffl selection rank selection 
selection scheme individual survives generation proportion rank performance 
elite preserving strategy applied selection 
best individuals population remain generation 
prevents best individuals eliminated stochastic genetic drifts 
ffl crossover crossover exchanges subtrees genes 
similar operator genetic programming 
performing crossover useful interconnection parts gathered intermodule connectivity evolves 
example crossover shown 
ffl deletion deletion deletes subtree gene 
operator expected cause deletion useless parts gene 
result compact individual functions generated see 
ffl mutation mutation changes tree node new node proportion mutation rate 
operator plays role changing internal parameters selected node number nodes module 
important role mutation enforce local search slight modifications connectivity parts obtained crossover duplication 
example mutation shown 
ffl insertion insertion similar duplication inserts subtrees nodes gene selected node see 
ffl duplication duplication imitates gene duplication living creatures possible evolve gene simple structure complex 
increases complexity functions expands network scale 
duplication inserts copy subtree gene 
subtree part gene nodes category appear list 
duplication leads functionally correct interconnection 
just duplication performed inserted subtree affect individual behavior neutral 
duplication change functionality crossover deletion mutation insertion duplication graphical explanation genetic operators 
sample data 
individual 
inserted subtree may modified mutations new function emerge 
parts gene change inserted subtree incorporated behavior 
shows example duplication 
simulation results environments order confirm possibility proposed model handwritten digit database concordia university canada consists unconstrained digits originally collected dead letter envelopes postal services different locations digits database digitized bilevel theta grid mm square elements giving resolution approximately ppi 
data digits training digits testing 
shows representative samples taken database 
see different writing styles apparent digits different sizes stroke widths 
size pattern normalized fitting coarse theta grid digit 
proportion square grid provided continuous activation values pattern 
network architectures generated evolutionary mechanism trained patterns rounds subsequent presentations 
single presentation lasted cycles iterative updates activations learning weights 
fitness value assigned solution testing performance trained network training digits recognition performance tested digits 
initial population consisted neural networks having random connections 
network contains input module size output module size different number hidden modules 
module connected module 
best average fitness changes generation goes 
table result generalization rates relevant information 
gen correct module node link evolution networks shows best average fitness changes course evolution 
depicts clear performance increases generation goes initial radical improvements fitness settles soon 
nearly best solutions population number generations scored correct recognition training data set 
generalization rates gradually improved generation goes 
table picks best results obtained evolution shows corresponding networks evolved 
seen evolution led increase complexity new structures new functionality emerged course evolution general early networks simple structures 
early stages evolution complicated architectures emerged disappeared search optimal solution matured 
earlier specific solutions probably overfitted peculiar training set lack generality 
network final architecture producing modular neural networks evolved st generation th generation rd generation final network 
table basic subsystems final network 
subsystem pathways table performance subsystems final network 
index performance index performance best result 
contains hidden modules size implementing different subsystems cooperatively process input different resolutions 
direct connection input module output module forms fine grained processing stream 
supplemented sophisticated modular structure modules globally connected input 
sort hierarchical structure feedback connections emerged coarser processing streams local feedback projections support main processing stream 
emergent properties order observe cooperative subsystems emerged evolution thorough analysis final network conducted 
network consists basic subsystems shown table 
lead combinations subsystems may redundant 
table shows performance subsystems 
table indicates subsystems combining play important role support subsystems 
furthermore subnetwork final network 
deeper analysis results implies subsystem emerged functionality 
example subsystem mainly works classifying classes subsystem class subsystem classes 
network gets sophisticated combining subsystems act behaviors cooperation competition separation 
instance separation combination subsystem behaves independently leads total performance close sum subsystems 
quite difficult fully analyze neural behaviors concern oscillatory activation dynamics 
analysis simpler sample class subnetworks respectively obtained series snapshots internal activations 
network subsystem shown 
system produced answer class wrong 






numbers represent activated nodes means node activated module 
mentioned subsystem acts important role fundamental network perform needs support subsystem 
second network subsystem shown 
system turned produce correct result respect input subnetwork final network 
follows 







network coupled oscillatory circuit modules resolves competition induces correct classification 
shows oscillatory dynamics finds category structure 



test generalization capability patterns similar trained network produced direct activation specific pathway 
contrary network pathways consensus strange patterns 
basic processing pathways case complemented result improved categorization 
furthermore recurrent connections utilized bottomup top information interactively influenced categorization directions 
table reports confusion matrix recognition final network test data digits 
practical pattern recognizer table confusion matrix final network 
assure proposed evolutionary neural network works 
appreciate power evolution design complex structures sophisticated network architectures autonomously 
inherently proposed evolutionary neural networks learn incrementally new data sets demonstrates relative superiority compared conventional neural networks backpropagation neural network 
concluding remarks described preliminary design modular neural networks developed evolutionary algorithm investigated emergent properties structure function evolution 
modular structure competition excitatory connections 
sort network potential take important part engineering tasks exhibiting adaptive behaviors 
attempting evolutionary mechanism sophisticated incorporating concept evolution developmental process system evolutionary process 
authors dr atr hip laboratories continuous encouragement 
lee university supporting experiments 
harp genetic synthesis neural networks proc 
genetic algorithms pp 

whitley hanson optimizing neural networks faster accurate genetic search proc 
genetic algorithms pp 

kitano designing neural networks genetic algorithms graph generation system complex systems vol 
pp 

cliff harvey husbands incremental evolution neural network architectures adaptive behavior technical report csrp university sussex school cognitive computing science 
yao evolutionary artificial neural networks int 
journal neural systems vol 
pp 

nolfi miglino parisi phenotypic plasticity evolving neural networks evolving control system autonomous agent technical report institute psychology rome 

cho evolutionary synthesis autonomous agents modular neural networks proc 
int 
workshop artificial life vol 
poster presentations pp 
nara may 
miller todd hedge designing neural networks genetic algorithms proc 
third int 
conf 
genetic algorithms applications pp 
morgan kaufmann san mateo ca 
calm categorizing learning module neural networks vol 
pp 

koza genetic programming programming computers means natural selection mit press 
evolutionary systems brain communications artificial brain artificial life iv edited brooks maes mit press 
whitley genitor algorithm selective pressure rank allocation reproductive trials best proc 
third int 
conf 
genetic algorithms applications pp 
morgan kaufmann san mateo ca 
goldberg genetic algorithms search optimization machine learning addison wesley 
wada tanaka gas survive journal society instrument control engineers vol 
pp 

