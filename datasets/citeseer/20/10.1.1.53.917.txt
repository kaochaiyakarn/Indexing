mixtures controllers jump linear non linear plants timothy cacciatore department neurosciences university california san diego la jolla ca steven nowlan orchard parkway san jose ca describe extension mixture experts architecture modelling controlling dynamical systems exhibit multiple modes behavior 
extension markov process model suggests recurrent network gating set linear non linear controllers 
new architecture demonstrated capable learning effective control strategies jump linear non linear plants multiple modes behavior 
stationary dynamic systems exhibit significantly different behaviors different operating conditions 
control complex systems computationally efficient decompose problem smaller subtasks different control strategies different operating points 
detailed information plant available gain scheduling proven successful method designing global control athans 
system partitioned choosing operating points linear model operating point 
controller designed linear model method interpolating scheduling gains controllers chosen 
control problem challenging system controlled non stationary mode system explicitly observable 
important studied class non stationary systems jump linear systems form dx dt represents system state input stochastic parameter determines mode system explicitly observable 
control system estimate mode system input output behavior plant choose appropriate control strategy 
complex plants appropriate decomposition known priori 
approach learn decomposition piecewise solutions parallel 
mixture experts architecture nowlan jacobs proposed approach simultaneously learning task decomposition piecewise solutions neural network context 
architecture applied control simple stationary plants operating mode plant explicitly available input gating network jacobs jordan 
problem extending architecture deal non stationary systems jump linear systems 
original formulation architecture assumption statistical independence training pairs appropriate classification tasks 
assumption inappropriate modelling causal dependencies control tasks 
derive extension original mixture experts architecture call mixture controllers 
extension nth order markov model implemented control nonstationary plants 
new derivation suggests importance recurrence gating network learns estimate conditional state occupancy sequences outputs 
power architecture illustrated learning control switching strategies simple jump linear non stationary nonlinear plants 
modified recurrent architecture capable learning control switching plants non recurrent architecture fails learn adequate control 
mixtures controllers architecture system shown 
denotes vector inputs controller time corresponding control output 
architecture identical mixture experts architecture gating network recurrent receiving outputs previous time step part input 
underlying statistical model corresponding training procedure mixture controllers quite different originally proposed mixture experts 
assume system interested controlling different modes states distinct control mode 
general interested likelihood producing sequence control outputs yt sequence inputs xt likelihood computed yt jx js gamma fl idealization unknown safest overestimate 
sel 
mixture controllers architecture 
feedforward networks implementing controls appropriate different modes system controlled 
gating network sel 
recurrent uses softmax non linearity compute weight assigned control outputs 
weighted sum controls control plant 
represents probability producing desired control input system state fl represents conditional probability state sequence inputs outputs seen far 
order problem tractable assume conditional probability completely determined current input system previous state system fl fw fl ffl gamma assuming control approximated markov process assuming mode system explicitly available hidden markov model 
markov assumption leads particular recurrent gating architecture mixture controllers 
gaussian assumptions original mixture experts model define gradient descent procedure maximizing log likelihood equation 
assume oe gamma gammay oe define fi js xt fi fl fi fl derivative likelihood respect output controllers log kr gamma derivative likelihood respect weight control networks computed accumulating partial derivatives sequence control outputs log log gating network softmax non linearity fl exp exp log gamma fl fl gamma derivatives weights gating network computed accumulating partial derivatives output sequences log log equations turn quite similar derived original mixture experts architecture 
primary difference appearance fi expression appearance fi direct result recurrence introduced gating network 
fi computed part modified back propagation time algorithm gating network recurrence fi kj fi kj fl fl equation analog backward pass forward backward algorithm standard hidden markov models 
simulations reported section online gradient descent procedure employs approximation fi uses step back propagation time 
approximation appear significantly affect final performance recurrent architecture 
results performances recurrent mixture controllers non recurrent mixture experts compared control tasks order jump linear system second order jump linear system tracking task required nonlinear controllers 
object jump linear tasks control plant switched randomly linear systems 
resulting systems highly non linear 
second order cases epochs error order model training error non recurrent recurrent time output order model trajectory ideal controller network controller left training convergence mixtures experts mixtures controllers order jump linear system 
vertical axis average squared error training sequences horizontal axis number training sequences seen 
right sample test trajectory order jump linear system control mixture controllers 
system switches states times 
desired drive plant outputs zero zero forcing control 
second order systems successfully controlled single linear controller 
jump linear tasks architecture mixture controllers mixture experts consisted linear experts layer gating network 
input experts plant output previous time step input gating network ratio plant outputs preceding time steps 
ideal linear controller designed mode system 
training targets derived outputs appropriate ideal controller known mode system training trajectories 
parameters gating control networks updated pass sample trajectories contained state transitions 
recurrent mixture controllers trained successfully control order jump linear system trained generalized successfully novel test trajectories 
non recurrent mixture experts failed learn training data order jump linear system note high asymptote training error recurrence 
recurrent mixture controllers able learn control second order jump linear system necessary teacher force system epochs training providing true mode system extra input gating network 
extra input removed epoch error initially increases dramatically system able eventually learn control second order jump linear system autonomously 
note mixture experts system able learn successful control rapidly mixture controllers additional teacher input provided learning completely fails input removed epoch 
epochs error second order model training error non recurrent recurrent time output second order model trajectory recurrent controller output ideal output ideal left training convergence mixtures experts mixtures controllers second order jump linear system 
right sample test trajectory second order jump linear system control mixture controllers 
system switches states times 
second order cases trained mixture controllers able control system modes system behavior detect mode changes automatically 
difficulty designing control jump linear system usually lies identifying state system 
explicit law describing identify switch control modes necessary train mixture controllers learned automatically byproduct learning successfully control system 
performance mixture controllers mixture experts compared complex task requiring non linear control law mode 
task control trajectory ship track object traveling straight line flee object having random walk trajectory 
high degree task interference controls appropriate modes object behaviors 
ship dynamics taken miller sutton 
mixture controllers mixture experts experts 
experts received past measurements object bearing distance velocity ship heading turn rate 
controllers specified desired turn rate ship 
layer gating network received velocity object input 
training targets produced ideal controllers designed object behavior 
ideal controller random walk behavior produced turn rate headed directly away object 
ideal controller intercepting object information object position determine turn rate lead closest possible intercept point 
ideal controllers information available mixture experts mixture controllers 
mixture controllers mixture experts trained sequences target desired actual position incorrect correct time actual desired trajectories ship control mixture experts attempting intercept target 
gating unit activities function time trajectory 
trajectories object changed behaviors multiple times 
weights networks updated pass trajectories 
input gating net task provided instantaneous information mode object behavior provided jump linear tasks 
result mixture experts able achieve minimum level performance task 
recurrent mixture controllers performed better 
differences architectures revealed examining gating network outputs 
recurrence mixture experts gating network determine state object certainty compromised selecting combination correct incorrect control 
controls incompatible uncertainty degrades performance controller 
recurrence gating network mixture controllers able determine target state greater certainty integrating information observations object behavior 
sharper decisions control greatly improve tracking performance 
explored ability mixture controllers learn dynamics switching training trajectories object switched behavior varying frequency 
gating network trained object switched behaviors infrequently sluggish respond transitions noise tolerant gating network trained frequently switching object 
gating network able incorporate frequency transition state model 
discussion described extension mixture experts architecture modelling controlling dynamical systems exhibit multiple modes behavior 
algorithm updating parameters model simple gradient descent procedure 
application technique large scale problems target desired actual position incorrect correct time actual desired trajectories ship control mixture controllers attempting intercept target 
gating unit activities function time trajectory 
note noisy activities seen 
may require development faster converging update algorithms generalized em gem family algorithms variant iterative reweighted squares procedure proposed jordan jacobs hierarchies expert networks 
additional required establish stability convergence rate algorithm adaptive control applications 
jacobs jordan competitive modular connectionist architecture 
neural information processing systems 
jacobs jordan nowlan hinton adaptive mixtures local experts 
neural computation 
jordan jacobs hierarchical mixtures experts em algorithm 
neural computation 
miller sutton werbos neural networks control mit press 
nowlan competing experts experimental investigation associative mixture models 
technical report crg tr department computer science university toronto 
athans gain scheduling potential hazards possible remedies 
ieee control systems magazine 
