information retrieval systems large document collections alistair moffat justin zobel practical information retrieval systems manage large volumes data divided collections may held separate machines 
techniques locating matches queries consider identification probable collections identification documents probable answers 
furthermore large amounts data involved motivates compression dynamic environment compression problematic new text added compression model slowly inappropriate 
describe solutions problems 
show centralised blocked indexes reduce query processing costs multi collection environment careful application text compression techniques allow collections grow orders magnitude necessary 
practical information systems required store gigabytes data supporting rapid query evaluation 
common single site repository separate collections centrally managed stored separate machines evidenced diverse collections trec data 
environments queries may posed set collections individuals set 
queries joint collection resolved having single centralised index department computer science university melbourne victoria australia 
email alistair cs mu oz au department computer science rmit gpo box melbourne victoria australia 
email jz cs rmit oz au documents 
index inevitably duplicates information held index individual collections low space requirements possible index stored compressed may large collections 
centralised index large access may bottleneck query processing 
approach provide centralised index identify collections contain matches queries resolved dispatching hosts collections 
approach advantage distributing query processing costs raises question collection identified contain answers 
possible method index vocabulary collection equivalently index collection single document expectation collection highly ranked vocabulary contain answers 
initial experiments indicated correlation vocabulary rank value collection 
similar problems querying information internet comprehensive search prohibitively expensive 
intermediate extremes possibility centralised index blocks fixed numbers documents expectation highly ranked block contain highly ranked documents ranked block 
explore blocking trec methodology mixed results 
allow reduction size centralised index cost identifying large numbers false blocks blocks rank highly contain highly ranked documents 
trec experiments designed high recall extent problems arise attempting identify highly ranked documents 
documents required typically case ad hoc queries performance improves 
experiments led interesting observations 
appears problem query combining similarity values separate collections weights query terms vary 
tiny perturbations weights substantially perturb rankings th document ranking similarity value numerically greater score achieved top ranked document 
problem investigated twelve months design efficient compression methods text stored dynamic collections 
modifications text databases traditional database systems relatively common text collections continuously extended addition new data 
compression techniques static text databases models computed initial inspection data fixed 
semi static models required queries retrieve documents randomly collections decompression practical documents model 
new text dynamic collection coded semi static model computed previous data compression performance slowly degrades compression efficiency maintained model periodically recomputed collection 
may necessary time database doubles size large collection onerous requirement 
reduce frequency take place constraint documents model slightly relaxed 
mandatory codes allocated words change 
space left model new codes allocated new words appear existing codes retained 
experimented tandem model document compression known words allocated codewords frequency initial seed text novel words stored lexicon allocated ordinal codes 
recency technique allows collections expand factor compression degradation evident 
example collection mb safely allowed grow gb significant compression degradation occurs 
details system described full provide overview technique summarise results obtained 
indexing multiple collections diverse collections data stored single information retrieval system information needs span multiple collections 
exemplified trec data gb contains distinct collections 
queries properly directed single collection set articles wall street journal 
information needs dealt collections shown relevance judgements trec topics 
interested explore queries processed collections stored separately 
approach considered centralised index dispatch query subcollections contain relevant answers 
returned similarity values compiled single ranked list 
combined ranking basis selecting documents presentation answers requested separate collections 
approach obvious application distributed system desirable minimise processing costs appropriate environments collections separate nodes internet 
experimental regime follows 
collection separate index listing word documents containing word document frequencies 
indexes stored word frequencies allow computation inverse document frequencies collection 
collection similarity values computed information collec tion global information available 
quite possible query term high weight collection low weight 
ranking measure cosine measure logarithmic document frequency similarity query document qd delta delta log delta log frequency number documents collection number documents containing centralised index blocks documents number documents block fixed 
words kth document collection recorded occurring block dk collection word frequencies number blocks containing word number containing documents 
regime quite possible block contain combination words document block contain combination problem acute increased 
refer block false match highly ranked contains highly ranked documents 
query evaluation centralised indexes proceed follows 
centralised index find blocks highly ranked respect query 
answers required dr blocks identified certainly highly ranked blocks contain irrelevant documents dr blocks fetched 
fetching blocks guarantee top ranked documents retrieved particularly large highly similar record strength diluted occurring block records containing query terms 
exploration number blocks fetched important theme experiments 
blocks ranked query dispatched collection matching blocks 
collection ranked query purpose centralised index heuristically select subset collections query evaluation 
chose evaluate mechanism documents matching blocks considered reduce processing effort 
collection documents matching blocks top similarity values returned central processor similarity values 
central processor similarity values collection merged produce single ranking answers top retrieved collections collated rank order user 
model query processing illustrated 
consider behaviour centrally indexed system varied 
central index ranking documents directly ranking querying individual collections log values vary collections 
simply requesting top answers may omit documents ranked highly collection fetching blocks document may yield better retrieval 
blocks ranked similarity values returned collections permute ranking generated central index 
different previous approach trec subcollections treated single monolithic 
suppose increased say 
size central index diminishes number blocks containing word decreases size gaps turn allows better index compression 
new size considerably greater old blocks documents contains distinct terms old blocks document 
increase increases possibility false block matches potentially number blocks needs fetched find answers falls matching block contain answer 
varying number blocks considered controls retrieval performance 
number similarity values returned collections index largely unchanged processing costs central index central index index index index documents documents documents collection collection collection document identifiers documents block numbers query sim values doc identifiers architecture centrally indexed information retrieval system tially reduced 
increased central index size central processing costs continue fall diminishing returns 
larger blocks imply higher probability false block match number blocks considered decreased number documents ranked increases 
expect sufficiently large effectively collection ranked produce retrieval effectiveness somewhat defeating purpose central index 
thought experiment limit huge collection single block 
case benefit central index collections need considered example rankings collections widely separated 
likelihood false collection match high expect little benefit coarse level indexing 
note way supposed blocks constructed relatedness topic 
blocks consisted similar documents retrieval performance improve 
experimental results experimented centralised index regarding trec data consisting separate collections ap ap doe fr fr wsj wsj ziff ziff 
centralised index implemented mg index trec data document separators deleted mimic aggregation documents blocks 
reindexing required value tested 
topics transformed mg input removal stopwords sgml markup 
output query list block numbers transformed lists trec document identifiers unix utilities 
precomputed collection document list similarity values query final lists answers computed joining query output documents fully evaluated pt rp average top documents recall precision different block sizes topics values 
process selecting answers collections simulated gives exact values retrieval effectiveness estimate cpu time required phase query evaluation 
baseline indexed full trec collection normal way monolithic collection computed retrieval effectiveness point average assuming documents returned answers query 
result queries effectiveness 
experimented retrieval effectiveness achieved retrieval documents query various values shown 
horizontal axis number br documents considered times number blocks identified highly ranked 
central index identical baseline seen performance independent number documents fetched 
slight peak br indicating may small advantage ranking documents members individual presumably homogeneous collections compared ranking members heterogeneous collection 
expect effect pronounced larger numbers collections sets collections diverse 
higher false block match rapidly significant problem 
blocks records fetching blocks br results loss retrieval effectiveness 
bulk collection processed achieve performance 
problems extent due experimental methodology 
trec procedure fetching records ensure high recall degree certainty relevant documents located 
ad hoc queries smaller number answers typically requested 
test performance central index context rerun experiments assuming answers returned query 
results shown 
case vertical axis records average precision documents retrieved 
seen similar pattern performance disproportionately large number documents processed achieve performance large 
case total amount effort required reduced 
example index blocks documents ranked achieve performance comparable attained index examining just blocks 
equate volume index inspected ranking time case central index examined plus ths document indexes case blocking index size factor mbyte table size central inverted index central index fifth size examined plus ths component indexes net saving index processing time 
table shows sizes central indexes experiments 
subcollection indexes mb 
experiments section summarises experimental runs submitted assessment 
runs topics transformed queries removal sgml tags removal stopwords removal non alphabetic characters 
detailed performance analysis runs appears proceedings 
run control run blocksize extracted top documents central index permuted final ranking similarity query collection weights 
performance topics expected give identical behaviour ranking solely central index global term weights 
run run blocksize top blocks expanded collections query 
final ranking top documents subcollection weights documents contained highly ranked blocks central index 
block contains average just candidate retrieval performance 
dynamic text compression attractive compress contents information retrieval system 
appropriate choice coding scheme semi static word model huffman coding space required store data reduced original time required retrieve data reduced lower data transfer times smaller seek distances disk 
disadvantage approach collection dynamic documents appended new text compressed existing model model parameters slowly inappropriate compression performance degrades 
allow coding new words necessary leave probability space model 
case huffman coding equivalent explicitly reserving family codes new words 
straightforward approach allocate single escape code new word coded escape followed simple representation length followed ascii characters 
stored text grows approach quickly leads progressively worse compression example newspaper database appended text represents chronological progression events new words come frequent example wall street journal declines reagan example relatively infrequent 
code space reserved arbitrary number new codes allocated long new code turn leaves space codes added provided assigned codeword changed 
new words risk ambiguity inserted lexicon known words allocated new code 
sense channels communication encoder decoder 
conventional stream encoded text compression applications 
second channel benefit documents fully evaluated precision documents precision different block sizes topics specialised nature application lexicon terms codewords assigned document accessed decoded prior insertion scheme robust 
success tandem scheme principles 
scheme pass text initially available word model computed canonical huffman codes allocated words 
code set includes escape code calculated estimate rate new words expected appear 
new words auxiliary lexicon words listed order occurrence assigned ordinal codes unambiguous method representing infinitely large integers 
compression process words primary lexicon coded pre calculated huffman codes words auxiliary lexicon coded escape code followed ordinal number auxiliary lexicon 
words novel auxiliary lexicon simply assigned ordinal code installed ordinal code emitted 
particular need novel words decoder case conventional channel adaptive compression scheme 
fixed code disadvantages words frequent appended documents far outnumber seed documents rare original seed text added heuristic allow list auxiliary words self adjusting particular document 
codeword assignment necessity fixed commencement document 
auxiliary word seen document appear second time document 
exploit recency effect adjusted ordering auxiliary lexicon swapping word position front lexicon 
gives improved compression infinite encoding positive integers assign arbitrarily long codewords arbitrarily large integers small integers assigned codewords bounded length 
novel words appear document usually coded shorter codeword second subsequent appearances 
question selecting coding scheme new words 
experimenting variety codes variablelength code parameterised size initial lexicon 
combination components allows text grow factor compression performance significantly degrades illustrated table shows compression performance mb number answers time answer cpu time elapsed time uncompressed compressed speed compressed uncompressed retrieval systems milliseconds answer wall street journal collections wsj wsj 
table lefthand column factor text expanded model computed codes allocated bottom line initial text kb 
second column compressed size achieved percentage original size fixed huffman code characters spell new words appearances third column compression attained tandem model advocated 
base compression corresponding expansion factor 
expansion character tandem factor huffman huffman table compression performance wall street journal varying initial text size decoding improved model fast takes milliseconds decompress typical trec document kb 
small component retrieval time dominated disk access transfer costs 
space saving brought compression means transfer times data compressed seek times 
shows time milliseconds answer randomly retrieve documents compressed uncompressed wsj database respectively mg software 
experiment random list ordinal document identifiers generated system asked fetch documents document number order mimicking effect boolean query 
points plotted average document retrievals run idle machine retrieval system stored local disks 
seen cpu time required answer greater database compressed elapsed time includes disk seek transfer costs 
details compression scheme proposed dynamic collections described full 
explored hypotheses twelve months 
large data trec corpus usefully regarded collection subcollections substantial loss retrieval performance 
extension considered separate collections managed distributed environment 
results mixed effective information retrieval carried central index refer queries appropriate subcollections trec framework expense inspecting non trivial amount subcollection 
hand ad hoc queries involving small number answers efficiently partitioned net saving useful distribution workload 
second hypothesis explored compression effectively applied text dynamic collections just static 
results show seeded little final wsj collection compression results comparable attained complete collection attained 
compression applied dynamic collections little need periodic subsequent rebuilding database 
tim programming support 
supported australian research council key centre knowledge systems centre intelligent decision systems collaborative information technology research institute 
bell cleary witten 
text compression 
prentice hall englewood cliffs new jersey 
bookstein klein ziff 
systematic approach compressing fulltext retrieval system 
information processing management 
bowman danzig schwartz 
research problems scaleable internet resource discovery 
technical report cu cs computer science department university colorado boulder 
cormack 
data compression database system 
communications acm december 
frakes baeza yates editors 
information retrieval data structures algorithms 
prentice hall 
horspool cormack 
constructing word text compression algorithms 
storer cohn editors proc 
ieee data compression conference pages snowbird utah march 
ieee computer society press los alamitos california 
huffman 
method construction minimum redundancy codes 
proc 
ire september 
moffat zobel 
compression fast indexing multi gigabyte text databases 
australian computer journal 
moffat zobel sharman 
text compression dynamic document databases 
technical report tr collaborative information technology research institute rmit university melbourne 
national institute standards technology 
proc 
text retrieval conference trec washington november 
special publication 
schwartz kahle neuman 
comparison internet resource discovery approaches 
computing systems 

practitioner guide data base compression 
information systems 
witten moffat bell 
managing gigabytes compressing indexing documents images 
van nostrand reinhold new york 
