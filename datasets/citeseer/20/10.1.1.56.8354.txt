wait free parallel algorithms union find problem richard anderson university washington heather woll university california san diego november interested designing efficient data structures shared memory multiprocessor 
focus union find data structure 
consider fully asynchronous model computation arbitrary delays possible 
require solutions data structure problem wait free property meaning thread continues progress operations independent speeds threads 
model efficiency best measured terms total number instructions perform sequence data structure operations performed processors 
give wait free implementation efficient algorithm union find 
addition show worst case performance algorithm improved simulating synchronized algorithm simulating larger machine data structure requests support sufficient parallelism 
solutions apply general adversary model considered authors 
preliminary version rd stoc aw 
supported nsf presidential young investigator award ccr digital equipment nsf cer ccr nsf darpa ccr 
email address anderson cs washington edu 
partially supported nsf research initiation award ccr ucsd faculty career development 
email address woll cs ucsd edu 
study problem designing efficient parallel data structures shared memory multiprocessor 
interested amortized complexity series data structure operations 
processor machine assumption data structure requests execute simultaneously 
specific case look union find problem maintain collection disjoint sets support operations merging subsets testing pairs elements set 
solutions apply general adversary model considered authors 
number contributions 
model asynchronous parallel computation incorporates ideas developed field distributed computing 
feel ideas important role play understanding algorithms parallel machines fully synchronous 
give simple asynchronous implementation union find data structure incorporates known sequential heuristics 
provide correctness proof algorithm 
performance algorithm close performance sequential union find certain pathological cases 
study methods improving worst case performance 
method involves simulating sequential machine 
results include improved result write problem br ks respect general adversary 
introduce coarse grained technique improving worst case performance algorithm involve synchronization 
approach far reasonable real implementation 
motivation class parallel machine motivates shared memory multiprocessor 
simplest design parallel computer number shared memory multiprocessors commercially available 
examples machines class include sequent symmetry dec firefly encore multimax 
machines type generally modest number independent processors communicate shared global memory 
operating system provides user set threads executed processors 
threads time shared processors time subset threads may active 
thread executed subject additional delays interrupts page faults 
user view set processors available run highly variable rates 
algorithm designer attempts find algorithm efficiently takes advantage computer time available user 
important aspect type machine asynchronous 
asynchrony arises hardware software levels 
hardware level asynchrony term thread contrast process emphasize user threads access shared address space 
caused factors variable delay bus access different costs accessing cache versus global memory 
software level asynchrony arises interruptions page faults threads swapped threads may run 
delays due software potentially longer exert stronger influence model 
type machine expensive synchronize threads 
particular practical synchronize instruction simulate synchronized machine 
avoid synchronization overhead desirable threads independent possible 
natural approach designing algorithms shared memory multiprocessor thread execute separate data structure request 
done method needed arbitrate access shared data structures 
way commonly done locks give threads exclusive access particular portions data 
asynchronous domain locks cause severe problems thread sets lock may delayed indefinitely threads wait lock 
approach want simple model captures complexities asynchronous environment unusual threads suffer long delays 
key idea borrow field distributed computing wait free implementation data structure 
data structure wait free thread guaranteed complete operation finite number steps independent processing speeds processors 
requiring data structures wait free rule locks 
main thrust research wait free objects relate powers various primitives 
shown primitives referred universal sufficiently powerful may implement wait free data structure 
include universal primitive model 
interested measuring performance data structure operations guaranteeing wait free implementations 
consider cost executing series data structure requests 
means want measure amortized cost sequence 
measure cost algorithm amount performs 
defined sum active times threads 
measure gives convenient comparison sequential algorithm compare threads thread 
see section argument appropriate performance measure model 
major difference papers parallel computation motivated parallel machines small number processors opposed considering massively parallel machines 
means shall generally assume size problem substantially larger number processors 
considering performing set data structure operations threads 
give results parameterized terms interested getting results substantially larger maintaining performance gets close outline section survey related discussing wait free objects models asynchronous computation parallel data structures 
section introduce model discuss choice primitives adversary worst case bounds 
section gives wait free solution union find problem analyzes algorithm run time 
section gives methods improving worst case performance algorithm 
method simulate synchronized machine involves giving new solution write problem 
approach coarse grained approach requires having extra parallelism available far lower overheads far reasonable practice 
coarse grained approach run original algorithm random selection active requests 
section discusses directions extended 
related influenced distinct bodies done distributed computing wait free objects done theory parallel computing models asynchronous computation 
implementation object data structure wait free active threads progress computation independent behavior threads 
parallel computation provides basis performance measures 
give brief survey relevant papers fields 
wait free data structures say implementation data structure wait free finite number steps thread guaranteed complete operation independent actions threads 
implementation relies locks wait free setting lock thread may delayed indefinitely threads spin waiting lock 
substantial amount study wait free objects 
emphasis primarily simple objects atomic registers test set 
series papers established relationships primitives showing primitive simulate simulation impossible 
herlihy unified relating primitives family consensus problems establishing existence universal primitives 
primitive universal wait free object constructed 
primitives atomic append list compare swap universal test set 
plotkin plo showed single bit primitive called sticky bit universal 
main drawback universality results simulations primitive inefficient 
shown hierarchy wait free primitives level strictly powerful preceding level 
universal primitives form top hierarchy 
common data structures stacks queues fall intermediate levels 
complicated data structures programming top level 
data structures top level received relatively little attention 
herlihy studied implementation number data structures terms compare swap 
showed implement functional data structures discussed wait free memory management 
asynchronous ram models researchers begun consider asynchronous versions ram gib rz rz nis msp 
papers introduced different models differing notions run time 
cole introduced asynchronous ram model run time measured rounds round minimal interval time allows processor complete step 
measure run time field distributed computing lam lf way viewing time measured respect slowest processor 
appropriate measure processors subject long delays processor delayed computation takes place free 
nishimura nis nis cole rz analyze run time assuming random interleaving processors 
model applies best processors run close speed opposed stopping long periods time 
cole specify atomic primitives pram implicitly assume atomic assignment done variables simultaneously 
aspnes herlihy ah consider pram support universal primitives 
study limitations machines classify computations performed 
works model closest series papers considering fault tolerant rams ks kps msp 
papers consider model processors may fail goal simulate computation surviving processors 
measure performance terms sum active times processors measure 
papers look problem simulate single step processor algorithm fail asynchronous machine 
kanellakis shvartsman ks introduced fail ram model write problem 
kedem kps gave general simulation result robust implementation variant write problem 
martel msp extended result asynchronous model giving asynchronous algorithm write problem 
main result probabilistic simulation processor algorithm log log processors 
model martel differs important respects 
primitive appears somewhat weaker compare swap second weaker adversary model 
shall return adversary 
model basic model asynchronous shared memory machine 
processor execute instructions standard random access machine 
shared global memory processor local memory 
instruction set includes compare swap primitive 
instructions atomic 
execution machine interleaving atomic instructions 
instructions serialized issue reads writes concurrent exclusive arise 
processors perform simultaneous write memory cell execution cause writes occur serial order 
exposition convenient view certain operations occurring simultaneously 
say set operations occur simultaneously mean operations occur consecutively interleaving operations 
measure performance measure complexity algorithms consider total number instructions executed active threads 
algorithm maximum total possible execution sequences 
clear measure equivalent time measure sequential model computation product time number processors synchronous model parallel computation 
asynchronous world measure wait free algorithms generalization time processor product measure 
fixed distribution activation periods threads minimum algorithm gives minimum time algorithm 
control activation periods designing algorithm minimize gives maximizes efficiency processors 
data structure queries interested finding minimum algorithm executing series data structure operations 
assume operations executed concurrently 
time thread completes data structure request calls routine generate request 
assume underlying algorithm generating making data structure operations 
operations perform requesting thread able deactivate longer counts total 
formal model collection global memory locations communicate data structure requests threads 
memory location contains current query thread thread completes query writes answer location causes new query appear queries assigned threads subsequent queries halt allows thread enter special halt state 
correctness standard approach defining correctness asynchronous algorithm assume atomic instructions threads interleaved linear order 
order algorithm correct behave properly interleavings hw lam 
definition means correctly answer data structure operations done terms serializability 
answers queries said correct answers agree serialization atomic queries 
serialization required consistent order threads execute queries 
formalize definition correctness 
queries performed listed order request threads answer returned answers correspond serialization queries exists permutation oe oe queries queries executed order oe oe single processor sequence answers oe oe consistent order threads executed queries parallel execution finished started oe oe ordering queries starting finishing serialization instructions threads 
adversary express worst case bounds terms adversary 
adversary chooses queries establishes interleaving order 
algorithm randomized adversary may look results random coin deciding thread instruction interleaving 
adversary model br 
strength adversary plays important role results establish 
adversary martel msp substantially weaker adversary 
adversary sets complete interleaving order sees results random numbers 
algorithm martel increases theta theta pn powerful adversary 
primitives willing universal primitive 
universal primitives equivalent terms computational power simulations universal primitives necessarily efficient 
means choice primitive may strong influence results 
want primitive simple possible implement hardware software accepted researchers 
choice compare swap assignment succeeds know current value variable 
compare swap primitive herlihy wait free data structures included instruction set ibm 
code fragment defines compare swap 
main primitive ensure variable overwritten thread reading updating variable 
compare swap return success return failure possible extend compare swap apply records single words 
done making copies records applying compare swap pointer record sure record updated thread 
rely having storage allocator returns clean storage 
give version compare swap applies records 
union find union find data structure maintains collection disjoint subsets ng supports union operation merges pair subsets find identifies current subset containing element 
include operation tests elements contained subset 
important concurrent implementation names sets change making test difficult perform provided primitive 
union find data structure usually implemented collection trees root tree gives current name subset 
union implemented making root tree point root tree find implemented path element root tree 
number implementations union find tar 
give implementation ranked union path halving tar 
adapt path compression wait free implementation 
sequential cost sequence union find operations ranked union path halving path compression nff 
number difficulties arise developing concurrent union find data structure 
example care taken sure simultaneous unions interfere destroy tree structure 
prove algorithm correctly implements union find data structure restrict union operations 
reason value finds depend structure trees possible structure trees may differ concurrent serialized software implementation primitive guarantee operating system deactivate thread executing primitive 
set queries 
applications union find constructing minimum spanning trees finds test elements equivalent 
basic data structure order give precise definitions algorithms necessary algorithms low level 
notation derived language express manipulation pointers arrays kr 
standard sequential data structure union find collection records point form forest 
record field pointer record rank field keep information aids balancing trees 
record pointer points back record record root tree 
implementation introduce additional level indirection 
maintain array entry pointer record field rank field 
field array index 
notation rank field element gamma gamma rank ordering records ranks 
say record record gamma gamma rank gamma gamma rank gamma gamma rank gamma gamma rank notation oe record strictly record equality allowed 
order achieve wait free algorithms able perform atomic update rank fields record 
relying general operation atomic update record subroutine called updates rank fields record root tree 
reason restricted operation allows simplify code 
root rank atomic update rank fields performed failure returned 
assume storage allocator returns record appropriate size pointed live pointer 
old old gamma gamma old gamma gamma rank return failure new new gamma gamma new gamma gamma rank return compare swap old new basic algorithms implementations full detail 
give code find union subsections 
designing routines number pitfalls avoid 
main difficulties prevent thread updates disrupting thread sure separate threads inconsistent views data 
main tool arbitrate threads compare swap primitive 
thread update disrupted thread operation retried 
find implement find path halving 
traverse path root node visit point grandparent 
benefit method halves distance node root 
implement heuristic compare swap assign new value field 
solves problem threads concurrently updating pointer 
note compare swap expensive operation update non root nodes find root nodes 
find gamma gamma gamma gamma compare swap gamma gamma gamma gamma gamma gamma return give version find uses path compression 
difficulty developing concurrent find path compression path root tree altered pass identifies root pass pointers path point root 
possible create cycles graph processors simultaneously perform compressing finds 
key getting find correctly terminate update step soon vertex reached ancestor root originally identified 
vertex identified new root traverse path encounter vertex greater rank rank greater equal gamma gamma gamma gamma oe gamma gamma compare swap gamma gamma gamma gamma return operation tests elements subset 
operation unnecessary sequential case result computed pair finds 
concurrent case important provide primitive names sets may change making difficult tell pair elements subset 
algorithm locates roots algorithm give definite answer finds new roots elements tries 
subtlety elements may cease roots guard thinking elements different sets just root different 
gamma gamma safely say separate components identified root 
find find return true gamma gamma return false go union union algorithm implementation ranked union 
record maintains rank links record smaller rank record larger rank 
records equal rank linked new root rank incremented 
height tree formed ranked unions logarithmic number vertices 
sequential case path root ranks strictly increasing 
difficulties arise concurrent implementation union 
key idea prevents cycles perform links direction consistent ordering records 
roots oe link subtler problem arises ensure different threads consistent views data 
prevent thread viewing oe viewing oe aborting link rank changes identified lesser roots assignment take place 
union find find return xr gamma gamma rank yr gamma gamma rank xr yr xr yr swap swap xr yr xr xr failure go xr yr yr yr update rank guard threads incrementing rank simultaneously 
updating rank succeeds thread update rank new root new root root 
new root ceases root rank updated get adjacent nodes rank 
traverse path node root ranks non decreasing necessarily strictly increasing 
lemma pointer structure forest trees 
proof say pointers consistent agree ordering records gamma gamma pointers consistent record structure forest 
initially record points pointers consistent 
show update rank fields preserves consistency 
places rank fields changed path shortcut find trees linked union rank updated union 
making observation ranks ranks decreased time rank changed record root tree 
consider case find 
suppose assignment gamma gamma find instruction initiated pointers consistent 
version find oe root gamma gamma rank remains unchanged assignment succeeds oe second case field changed point union 
suppose state consistent assignment yr gamma gamma rank 
verify assignment gamma gamma oe assignment succeeds gamma gamma rank xr 
point xr yr xr yr yr gamma gamma rank oe complete proof show rank field updated union consistency preserved 
suppose gamma gamma attempt update rank state consistent update started oe consistency maintained 
update rank succeeds root introduce violation case gamma gamma give formal proof concurrent implementation correctly implements union find 
basic idea proof identify particular instruction interleaving view operation occurring 
restrict union queries 
theorem set union operations 
interleaving atomic instructions threads executing exists serialization consistent threads order request giving exactly responses queries proof construct serialization queries gives answers interleaving instructions 
specifying operations occurs sequence 
suppose union links record record union occurs compare swap inside succeeds 
union discovers elements component occurs union procedure returns 
operation occurs find executed time 
precise moment operation occurs root identified inside find gamma gamma false 
data structure operations 
order data structure operations oe oe oe order occur sequence instructions 
order operations clearly consistent parallel execution queries 
show get set answers 
answer returned query interleaving answer serialization queries 
show cc equivalence relation induced operations interleaving cc equivalence relation induced operations serialization 
claim cc cc shown induction noting operations change relation union merges components interleaving serialization 
definition operation answer query serialization consistent cc just verify query interleaving consistent cc returns true test true shows elements component 
returns false test gamma gamma true meaning root 
means root find completed 
moment distinct roots elements different components operation occurred 
possible extend theorem sequences operations include finds possible different elements roots sets operations interleaved serialization operations 
possible perform unions union union union way chain created having rank having rank zero 
suppose perform union giving rank 
union performed root tree identical ranks 
inserting set queries possible force valid serialization unions result root having rank 
means union root find give different answer 
negative result applies take definition union names resulting set fixed rule 
case naming ranks roots joined 
type union specified theorem extended include finds 
extend just need sure union serialization joins elements exactly manner union interleaving 
performance implementation suffers major performance flaw sequence requests interleaving instructions creates arbitrarily long chains nodes thread thread identify link identify link rank identify link rank identify link constructing chain back identical rank 
call path nodes tree equal ranks equal ranked chain 
equal ranked chains arise sequential case rank root incremented node linked rank 
shall see possible construct equal ranked chains interleaving unions 
turns chains unbounded length constructed threads 
union operations divided operations identifying link performing link updating rank 
denote operations identify link rank 
union performed 
show long chains constructed 
lemma exists sequence requests interleaving instructions creates chain nodes equal rank 
occur threads 
proof suppose wish perform unions union union union gamma 
ranks zero delta delta delta figures show interleavings length records having rank zero 
constructions principle having links threads leapfrog 
construction builds chain back 
thread link thread sets rank thread link records appear rank link allowed succeed 
link complete thread attempts update rank fails 
thread goes link careful interleaving results chain length construction works similar principle builds chain front 
thread thread identify gamma identify gamma gamma link gamma rank gamma identify gamma gamma link gamma gamma rank gamma gamma identify gamma gamma constructing chain front relatively simple fix alleviates problem creating long chains 
problem arises thread initiate second operation processors detect completed operation 
fix perform routine elements involved link union 
union links call 
just find sure root greater rank node immediately root find path 
purposes important compresses path updates rank root 
gamma gamma gamma gamma compare swap gamma gamma gamma gamma gamma gamma gamma gamma rank gamma gamma rank show adding union reduce length equal ranked chain 
bound known tight guess correct bound 
lemma union find routines incorporate create equal ranked chains length greater 
proof long equal ranked chains arise single thread add links chain 
call restricts single thread adding links equal ranked chain front back meaning thread links links chain rank ancestor reason linked call ensures root greater rank equal ranked chain terminated ends link higher ranked node opposed incomplete union 
equal ranked chain length terminated 
show terminated equal ranked chain element distance chain 
gain descendents equal rank distance chain cut half 
distance chain 
gains descendents distance reduced chain 
means node equal ranked chain distance chain 
equal ranked chains length constructed set simultaneous unions performed processors 
sets stage somewhat disappointing worst case performance 
creating chain length threads simultaneously traverse chain 
threads lock step thread theta spite path halving 
repeatedly creating chains traversing worst case behavior 
second case causes additional performed shall see significant problem simultaneous traversal long chains 
union executed thread finds fails 
fails gamma gamma gamma gamma rank changed finds performed link attempted 
refer failures rank failures respectively 
bound total amount bound number times fail 
bill failure cost traversing new link added 
give bound number rank failures 
theorem collection unions theta log rank failures 
proof rank failure occurs linked rank changes link performed 
simple accounting argument bound number rank failures 
rank failure occurs rank log bill failure union 
rank log bill failure thread updated rank update rank increases rank union log elements involved union may ranks changed 
change rank cause gamma rank failures worst case threads fail union 
total number rank changes nodes rank log means total amount threads number rank failures log 
construct set unions causes omega gamma log rank failures 
divide elements groups elements 
group threads conspire cause gamma log rank failures 
threads attempt union initially rank rank log thread performs unions elements group time threads attempt link find rank changed 
number ranks performed group log number rank failures gamma log summing failures groups get lowerbound 
describe worst case performance union find 
theorem worst case series union find operations theta pn nff 
proof lowerbound 
nff term comes sequential lower bound ranked union path halving 
term arises having groups threads simultaneously traverse long chains 
adversary gives set operations interleaving instructions takes omega gamma pn 
threads perform unions threads perform finds 
adversary divides queries phases phase consists partially completing set unions followed performing set finds finishing unions 
th phase unions performed construct chain delta delta delta unions halted links complete path compression done 
find processors execute find 
finds done lock step thread gain path compression 
phase omega gamma yielding omega gamma np 
pn term upperbound follows considering rank failures amount traverse chains equal rank 
nff term follows sequential upperbound 
results rely sequential bound applies number finds number unions 
worst case bound theta pn compared sequential bound theta nff 
says worst case get essentially speedup processors 
put better spin result 
worst case arises tight interleaving instruction high degree contention updating fields records 
real multiprocessor variation rate instructions executed contention reduced performance bad bound suggests worst case set requests 
discuss formal setting counting number times contention occurs parameterizing bounds quantity 
defined rank failure occur link fails rank record changes update 
define compression failure occur compare swap fails inside find 
type failure occurs threads traversing chain lock step threads duplicate splicing elements chain 
shall denote total number rank compress failures 
bounds improve substantially account failures separately 
theorem worst case series union find operations rank compress failures np nff 
proof dominant term cost traversing long chains 
count compress failures separately treat updating pointers finds atomic operations splice elements list 
result follows bound 
adversary strength model consider powerful adversary 
adversary specifies queries decides interleaving instructions 
algorithm uses random numbers adversary may base decisions random numbers 
type adversary called adaptive adversary contrast oblivious adversary required decisions seeing random numbers 
pair results indicate power adversary 
results show natural approaches improving worst case bounds algorithms 
main source worst case performance algorithm set threads simultaneously traverse long chain 
prove pointer model processors access memory cells links adversary force threads expend theta traversing chain length result applies threads allowed randomization 
theorem suppose threads simultaneously traverse chain length adversary force theta performed 
proof adversary forces threads remain lock step 
suppose chain delta delta delta threads start adversary picks thread allows execute reads thread halted threads read thread reactivated allowed read construction proceeds phases th phase threads proceed adversary keeps processors lock step able benefit path compression performed 
adversary traversal long chains expensive avoid construction long chains 
show natural randomized algorithm fails 
suppose adopt strategy union performed elements equal rank direction link chosen random 
implementation difficulties dealing cycles show method yields poor results strategy looks attractive appears long chains rare 
example unions union union union executed expected length longest segment log show adversary defeat strategy cause long chains created high probability 
theorem exists adversary give set union requests causes random union algorithm construct chain length log probability gamma proof difficulty adversary random union algorithm direction links determined 
solve problem adversary causes duplicate set links performed choose link desired direction 
log adversary log requests union 
random union algorithm chooses link probability link probability means log unions results link probability gamma adversary threads execute unions decide directions links 
adversary chooses thread groups unions 
threads chosen linked probability gamma links exist log links exist adversary constructs chain length log results show power adversary defeating various algorithms 
achieve far better bounds union find problem adversary weakened performance measures changed 
average case run time worst case set requests improves substantially take random interleaving model nishimura nis 
random interleaving model safe thread working contention detected threads stopped indefinitely 
adversary allowed base interleavings results random number generator get better worst case bound 
martel msp prevent adversary advantage random number generator having adversary set interleaving order random numbers generated 
weaker adversary possible prevent long chains arising techniques having threads probabilistically decide links succeed 
improved bounds section discuss different techniques improving worst case performance union find algorithm 
simulating synchronous algorithm asynchronous threads 
gives strongest theoretical result unsatisfying clearly practical approach real machine 
approach requires having queries available processing threads 
able trade excess parallelism improved worst case performance 
approach attractive coarse grained practical implemented 
step step simulations approach consider having threads simulate synchronous algorithm running processors 
round simulates exactly instruction synchronous thread 
type simulation discussed asynchronous models papers ks kps msp 
difficult design synchronized union find algorithm efficient sequential algorithm 
source inefficiency asynchronous algorithm arises long chains created 
synchronized algorithm avoid long chains breaking formed 
applying cole vishkin algorithm finding independent set linked list cv 
causes spend log extra time linking step 
gives lemma lemma synchronous algorithm answer union find queries ff log 
order simulate synchronous algorithm thread execute instructions processor 
abstraction capture problem introduced kanellakis shvartsman ks called write problem 
write problem write fixed value cell array size thread writes value location executes instruction associated processor current round 
values written locations round complete round started 
number important details take care turn algorithm write problem simulation synchronous algorithm 
possible threads attempt execute instruction time 
possible set rounds multiple executions instructions change result computation 
referred making computation idempotent 
second problem ensure threads working round 
possible thread delayed middle executing instruction time reactivated processors finished round started new round 
solve problem associating tag memory cell indicating time written 
update tag compare swap operation avoid difficulties concurrent updates 
fact powerful model easier resolve difficulty weaker models msp 
subsection show round synchronous algorithm simulated ffl fixed ffl 
gives result theorem simulating synchronous algorithm sequence union find operations executed np ffl ff log ffl 
type simulation done framework gives improved result appropriate consider 
step step simulation practical solution shared memory multiprocessor suggest gap theoretical framework situation attempting model 
number problems approach lead overheads large considered practical 
problem involved synchronous union find algorithm 
step performing deterministic coin tossing linking step introduces large overhead 
larger problems come simulation 
separate problems simulation probably sufficient rule practical implementation 
requiring tagged memory write double storage greatly slow computation 
secondly simulation require synchronizing time step 
far finer granularity synchronization feasible type machine modeled 
process having thread execute instructions synchronized algorithm means thread acting interpreter advantage compiled code abandoned 
write problem section give solution write problem 
write problem central simulation algorithms considered previously different models 
fail model kanellakis shvartsman ks gave log upperbound processor cell write algorithm 
martel gave bound log log processor cell write algorithm 
martel algorithm randomized assumes adversary set instruction interleaving prior viewing random numbers 
result differs martel algorithm applicable stronger adversary 
write problem general adaptive adversary model previously considered buss br 
give algorithm log log 
algorithm includes result special case 
show omega gamma log lowerbound write problem 
main result ffl exists ffl processor cell algorithm 
contention set permutations difficulty performing write operation rates threads variable possible know advance thread succeed writing particular location 
thread ability perform possible threads delayed indefinitely 
discussion algorithms write problem considering oblivious algorithms 
algorithm oblivious order attempts write cells independent operations processors 
oblivious algorithms solution provide solution processor oblivious write algorithm memory cells takes theta 
oblivious algorithm viewed set permutations pg th permutations gives order processor writes memory cells 
application oblivious algorithms concerned number times values written cells processors simultaneously perform write cell count writes separately 
define contention algorithm 
formally define contention fixing order cells written computing concurrent writes consistent order 
permutations ff contention respect ff denoted cont ff calculated follows suppose elements pg list order elements disappear order ff 
cont ff number times element front list removed 
example ff computing cont 
cont ff front list removed 
shows computation contention detail underlined elements counting contention 
set permutations permutation ff contention respect ff defined cont ff cont ff 
maximum contention cont max ff cont ff 
ff identity permutation cont ff just number left right maxima 
connection generalized arbitrary permutation ff 
lemma permutations ff cont ff equal number left right maxima ff gamma 
proof th element permutation ff gamma ff gamma ff gamma ff gamma position ff 
definition cont ff counts sum front list removed 
front list comes gamma ff 
occurs ff gamma left right maximum ff gamma 
ff ff gamma 
left maxima giving value cont ff 
relating contention number left right maxima quite easy compute expected contention single permutation set permutations 
need bounds probability contention differs substantially expected value requires little 
simple lemma giving expected contention uniformly random permutation respect fixed ordering ff 
result holds fix choose ff random 
lemma ff fixed ordering suppose random permutation pg 
expected value cont ff ln 
proof random permutation ff gamma random permutation problem reduced computing expected number left right maxima random permutation 
value left right maximum appears occurs probability gammai expected number left right maxima gammai extend result case select permutations random 
case need bound probability contention constant multiple expected value 
number left right maxima permutation pg random variable mean standard deviation approximately knu 
variables independent natural proof apply central limit theorem 
approach runs difficulties random variables change order apply central limit theorem rigorously necessary bound rate convergence normal distribution 
get simpler proof viewing random variables sum independent bernoulli trials applying bound established raghavan rag 
convenience restate result 
lemma raghavan sequence independent bernoulli trials psi delta delta delta suppose exp psi ffi prob psi 
ffi ffi ffi ffi proof see rag theorem 
lemma constant ff permutation random set permutations pg prob cont ff cp log 
proof ff permutation random set permutations 
fff gamma sg psi random variable total number left right maxima permutations lemma distribution cont ff exactly distribution psi 
ij random variable left right maximum th permutation psi ij key observation proof set independent random variables 
clear random variables differ subscript independent arise different permutations chosen independently 
argue ip independent 
permutation left right maximum comes elements greater order elements greater matter 
position elements influence left right maximum 
means probability right maximum independent elements left right maxima corresponding random variables independent 
probability ij gammaj exp psi ph ln applying lemma ffi prob psi ln ln ln 
follows choose complete proof 
result show set permutations low contention respect orderings ff 
lemma constant set permutations pg cont cp log proof constant lemma 
ordering ff bad set permutations cont ff cp log lemma follows directly random set permutations expected number bad orderings 
means exists set bad orderings words cont cp log randomized algorithm write problem basic idea write algorithms threads execute operations order set permutations 
order algorithm efficient operation consists block writes 
block additional memory location indicating completed 
refer cells completion bits 
thread write block looks completion bit block set writes memory location block location indicating block complete 
cost writing block completion bit set start write equal size block 
threads block time perform writes block 
advantage method thread considers blocks order thread considers blocks order blocks written thread 
processing tasks different order threads reduce total amount 
lemma relates notion contention amount performed 
block access said occur thread writes block lemma set permutations pg 
suppose threads write blocks thread processes blocks order total number block accesses cont 
block size total number writes threads cont total 
proof consider run algorithm 
construct order view blocks processed order successful writes completion bits 
algorithm interleaving atomic instructions gives permutation ff 
suppose thread succeeds writing block accesses show access counted contribution cont 
suppose attempts write write clearly means completed comes ff 
elements coming completed contributes cont precedes precede ff 
means contributes cont ff permutation cont upperbound interleavings number block accesses 
maximum number writes cells blocks cont including write completion bit 
term included account reads completion bits including case block complete 
apply lemma get simple randomized algorithm write problem 
algorithm case size array greater number threads 
applicable simulating larger synchronous machine smaller machine 
lemma exists randomized thread algorithm write memory cells takes log high probability 
proof divide memory cells blocks size choose random set permutations pg 
high probability cont cp log thread writes blocks order th permutation direct application lemma gives bound 
improve result sense number cells written reduced cost slight increase amount cell 
idea level recursive scheme subdivide block set smaller blocks 
lemma exists randomized thread algorithm write memory cells takes log high probability 
proof suppose threads ft ij pg 
divide memory cells blocks size subdivide block subblocks size choose random set permutations 
fixed cont log high probability 
thread ij processes blocks order block completion bit set ij processes ij processes order establish bound 
fix interleaving instructions 
say writes block ij writes successfully block application lemma says total number times writes summed bounded cont 
writes pessimistic assumption succeed writing applying proof lemma amount done 
putting bounds get bound cont log high probability 
deterministic algorithm write problem adapt ideas randomized algorithm deterministic algorithm 
randomness know construct set permutations low contention rely random set overwhelming probability 
deterministic algorithm increase number levels recursion 
number levels recursion increases size permutations decreases 
reduce size permutations constant claim find set constant time brute force search 
show ffl exists deterministic thread algorithm writing memory cells takes ffl 
suppose integers view computation place ary tree height internal node tree contains single bit corresponds completion bit block leaf nodes contain memory cells 
set gamma permutations cont cq log existence set guaranteed lemma 
turn constant need worry complexity finding set thread node visits children node order permutation thread chooses permutation nodes particular level tree 
choice permutation looking digits ary expansion number thread 
suppose represented ary 
thread considers children node level order give code routine traverse write array increase clarity describe routine tree implementation done efficiently arrays 
notation describe tree 
node gamma gamma vector pointers children gamma gamma pointer th child completion bit internal node gamma gamma bit array index associated leaf node gamma gamma index traverse node delta delta delta node gamma gamma index node gamma gamma bit traverse node gamma gamma delta delta delta node gamma gamma bit thread begins initial call traverse root delta delta delta root root tree delta delta delta ary expansion thread number 
thread visit node tree absence threads algorithm performs write array show completes desired bounds 
key formal proof bound characterize worst case behavior 
order maximize processors adversary keep threads groups threads group lock step 
example top level tree adversary divide threads groups threads 
adversary choose ordering groups maximize contention threads working block cells 
formalize ideas proof 
threads divided groups ary expansions indices 
threads agree digits ary expansions say group 
group threads lock step level access set nodes level node level accessed entire group simultaneously writes completion bit 
say threads synchronized groups groups lock step level lemma exists maximum interleaving threads synchronized groups 
proof proof straightforward reordering argument 
take maximum interleaving reorder instructions synchronized groups decreasing performed 
suppose threads group writes completion bit block 
processes blocks levels exactly order 
completed block encounter incomplete cell reaches completion bit means instructions writing executed interfering threads 
thread accessing completed nodes executing instructions immediately decrease performed 
execute instructions upto write simultaneous write completion bit reordering argument repeated groups working lock step 
lemma sum groups number blocks accessed level cont proof proof induction base case holds entire set threads single block accessing block level 
suppose cont gamma block accesses gamma groups blocks level lemma assume threads synchronized groups 
consider gamma group accesses block level gamma group consists groups 
groups consider blocks level descended order permutations lemma gives bound cont number accesses groups blocks level descended means total number accesses groups blocks level cont prove main theorem section 
theorem ffl exists deterministic algorithm threads simulates instructions ffl 
proof total amount performed proportional total number blocks accessed 
group accesses block level total threads may participate 
lemmas get bound total number blocks accessed log cont log log log log manipulating logarithms log log log log log log log log log log log appropriate choice ffl coarse grained algorithm consider coarse grained approach improving performance algorithm 
method requires number queries performed simultaneously greater number threads 
operations available threads allocate operations threads 
turns thread selects operations random worst case performance improves dramatically 
method defeating adversary appealing simulating synchronization method easily implemented practice low overhead 
alter query model accommodate extra queries implement randomized strategy assume algorithm issues queries batches queries 
thread requests query randomly selected query set available queries 
queries answered new set queries available 
method forces adversary generate queries allows randomization mitigate worst case behavior 
assume minor modification union procedure roots trees ranks set link attempted 
union attempted root immediately precedes path shall sure rank greater rank source inefficiency union find algorithm possible long chains chains length arise traversing chains expensive 
show randomized algorithm better performance long chains created 
long chains arise having threads simultaneously making links path 
thread linking linking result adjacent nodes tree having rank 
adversary model adversary attempts links path turn operations model natural threads select randomly collection query registers 
believe model gives results 
easy 
hand adversary try concentrate links long paths constructed 
basis proof bound number edges chains equal rank 
bound number edges chains equal rank separately bound amount traversing edges amount traversing edges get result 
keep track connected components formed unions define sets edges 
view union undirected edge 
initially union associated component fxg component fyg 
weight component number unions associated component 
unions performed weights components increase 
component weight exceeds unions put heavy set longer associated component 
heavy set formed edges set changed 
lemma number edges chains heavy sets log 
proof fu unions heavy set formed component consider unions succeed linking component linking component vertices order linking 
claim vertices strictly increasing rank 
reason link attempted thread sure greater rank child reached 
means log unions succeed 
heavy sets union may appear sets 
log edges come heavy sets 
lemma expected number edges equal ranked chains came directly components heavy set log 
proof say component active thread process linking component component 
edge part chain equal rank ways adjacent edge heavy set adjacent active component active component adjacent query edge 
case covered lemma 
show expected number edges arise cases 
number active components active component adjacent queries additional queries set aside heavy sets 
query chosen random probability adjacent active component 
expected number queries adjacent active queries 
theorem expected union find operations np log queries executed batches queries queries batch executed random order 
proof lemmas show processing batch queries expected number edges put chains equal rank log 
means total queries number edges put chains equal rank np gamma log 
amount finds expend traversing equal ranked chains np log 
amount exclusive traversing chains log believe possible tighten proof give total approximately log 
show coarse grained approach synchronous approach 
research directions believe done studying data structures asynchronous parallel machines 
natural direction extend look data structures 
interesting questions different data structures maintained simultaneously minimum spanning tree algorithm want keep track disjoint sets associated heap 
room improvement results union find problem 
see improvement worst case bound np rely simulating synchronous algorithm 
interesting direction consider universal primitives compare swap 
possible primitives consider include atomic splice primitive versions compare swap allow multiple variables updated 
authors wish greg barnes paul beame krishna ashok subramanian waarts helpful comments 
ah aspnes herlihy 
wait free data structures asynchronous pram model 
second annual symposium parallel algorithms architectures pages 
anderson 
parallel algorithms generating random permutations shared memory machine 
second annual symposium parallel algorithms architectures pages 
anderson 
wait free primitives list compression 
progress 
aw anderson woll 
wait free parallel algorithms union find problem 
proceedings rd acm symposium theory computation pages 
br buss 
certified write strongly asynchronous pram 
preliminary report 
cv cole vishkin 
deterministic coin tossing applications optimal parallel list ranking 
information computation 
gib gibbons 
practical pram model 
acm symposium parallel algorithms architectures pages 
herlihy 
impossibility universality results wait free synchronization 
proceedings seventh annual acm symposium principles distributed computing pages 
herlihy 
methodology implementing highly concurrent data structures 
second acm sigplan symposium principles practice parallel programming pages 
hw herlihy wing 
axioms concurrent objects 
proceedings fourteenth annual acm symposium principles programming languages pages 
knu knuth 
fundamental algorithms volume art computer programming 
addison wesley 
kps kedem spirakis 
efficient robust parallel computations 
proceedings nd acm symposium theory computation pages 
kr kernighan ritchie 
programming language 
prentice hall 
ks kanellakis shvartsman 
efficient parallel algorithms robust 
proceedings eighth annual acm symposium principles distributed computing pages 
lam lamport 
time clocks ordering events distributed system 
communications acm july 
lam lamport 
multiprocessor computer correctly executes multiprocessor programs 
ieee transactions computers 
lf lynch fischer 
describing behavior implementation distributed systems 
theoretical computer science 
msp martel park 
asynchronous prams synchronous prams 
st symposium foundations computer science pages 
nis nishimura 
asynchronous shared memory parallel computation 
second annual symposium parallel algorithms architectures pages 
nis nishimura 
asynchrony shared memory parallel computation 
phd thesis department computer science university toronto june 
plo plotkin 
sticky bits universality consensus 
proceedings eighth annual acm symposium principles distributed computing pages 
rag raghavan 
probabilistic construction deterministic algorithms approximating packing integer programs 
th symposium foundations computer science pages 
rz cole 
incorporating asynchrony pram model 
acm symposium parallel algorithms architectures pages 
rz cole 
expected advantage asynchrony 
second annual symposium parallel algorithms architectures pages 
tar tarjan 
efficiency linear set union algorithm 
journal acm 
tar tarjan 
data structures network algorithms 
siam 
tarjan van leeuwen 
worst case analysis set union algorithms 
journal acm 
