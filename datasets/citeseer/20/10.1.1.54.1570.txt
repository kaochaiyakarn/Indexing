factor graphs sum product algorithm frank kschischang brendan frey hans andrea loeliger july factor graph bipartite graph expresses global function variables factors product local functions 
factor graphs subsume graphical models including bayesian networks markov random fields tanner graphs 
simple computational rule sum product algorithm operates factor graphs compute exactly approximately various marginal functions distributed message passing graph 
wide variety algorithms developed artificial intelligence signal processing digital communications derived specific instances sum product algorithm including forward backward algorithm viterbi algorithm iterative turbo decoding algorithm pearl belief propagation algorithm bayesian networks kalman filter certain fast fourier transform algorithms 
keywords graphical models factor graphs tanner graphs sum product algorithm marginalization forward backward algorithm viterbi algorithm iterative decoding belief propagation kalman filtering fast fourier transform 
submitted ieee transactions information theory july 
available web www comm utoronto ca frank factor 
department electrical computer engineering university toronto toronto ontario canada frank comm utoronto ca beckman institute north mathews avenue urbana il usa frey cs utoronto ca tech ag ch basel switzerland access ch typeset july 
ii contents factor graphs 
prior art 
sum product algorithm example 
notational preliminaries 
organization 
examples factor graphs indicating set membership tanner graphs 
probability distributions 
examples 
function cross sections projections summaries cross sections 
projections summaries 
summary operators binary operations 
sum product algorithm computation message passing 
sum product update rule 
message passing schedules 
sum product algorithm finite tree 
articulation principle 
generalized forward backward schedules 
example continued 
iii forests 
message semantics general schedules 
applications sum product algorithm forward backward algorithm 
min sum semiring viterbi algorithm 
iterative decoding turbo codes 
belief propagation bayesian networks 
kalman filtering 
factor graph transformations coping cycles grouping nodes multiplying unity 
stretching variable nodes 
spanning trees 
fft 
proof theorem complexity sum product algorithm finite tree code specific simplifications iv factor graphs factor graph bipartite graph expresses global function variables factors product local functions 
suppose real valued function variables written product fa functions fa fb fe corresponding factor graph shown fig 

variable node variable function node factor variable node connected function node argument fd fc fb fa fe factor graph expresses global function factors product local functions fa 
variable function view index subset view 
variable nodes shown circles function nodes shown filled squares 
notation 
fx sg collection variables indexed finite set linearly ordered variable takes values set subset integers usual ordering 
subset denote xe fx subset variables indexed particular assignment value variables referred configuration variables 
configurations variables viewed elements cartesian product called configuration space 
concreteness suppose components configurations ordered fi delta delta delta typical configuration written course configuration equivalent multiple variable assignment vice versa 
abuse notation particular configuration write assignment 
occasion view configurations assignments values variables elements occasion consider fj ae delta delta delta configuration tuple ae called respect set fae respect denoted ae clearly ae abuse notation ae particular respect write xe ae multiple variable assignment ae set configurations denote ce set elements respect ce fae cg 
clearly ce ae ae function elements arguments 
moment require domain equipped binary product denoted delta unit element denoted satisfying delta delta delta delta delta delta delta forms commutative semigroup unity 
reader lose essential cases assuming field real numbers usual product 
usually denote product elements juxtaposition xy occasionally delta suppose collection subsets function factors fe xe fe ae function respect refer factor fe xe local function 
empty interpret corresponding local function arguments constant 
common practice probability theory abbreviated notation arguments function determine function domain denote function theta 
abbreviated notation written xe 
factor graph representation bipartite graph denoted vertex set edge set ffi 
words contains edge fi argument local function fe vertices elements called variable nodes vertices elements called function nodes 
example ff gg gives factor graph shown fig 

translate freely factor graphs labeled variables local functions variable local function view fig 
corresponding factor graph labeled variable indices index subsets index subset view fig 

avoid precise quite tedious mention functions corresponding function nodes variables corresponding variable nodes blur distinction nodes objects associated making legitimate refer say arguments function node edges incident variable useful refer arbitrary edge factor graph 
edge fv wg definition incident function node variable node called variable associated edge denoted fv wg prior art see section factor graphs subsume graphical models signal processing probability theory coding including markov random fields bayesian networks tanner graphs 
original motivation introducing factor graphs explicit commonalities bayesian networks known belief networks causal networks influence diagrams tanner graphs previously explain iterative decoding turbo codes low density parity check codes :10.1.1.73.8252
respect factor graphs applications coding just slight reformulation approach wiberg 
main thesis factor graphs may naturally wide variety fields coding including signal processing system theory expert systems artificial neural networks 
plausible algorithms fields naturally expressed terms factor graphs 
consider algorithm sum product algorithm operates factor graph passing messages edges graph single simple computational rule 
way preview simple example operation sum product algorithm operating factor graph fig 
subsection 
main purpose essentially tutorial illuminate simplicity sum product algorithm general factor graph setting point variety applications 
parallel development aji mceliece develop closely related generalized distributive law alternative approach properties junction trees factor graphs 
aji mceliece point commonalities wide variety algorithms furnish extensive bibliography 
forney gives nice overview development algorithms emphasis applications coding theory 
appearance sum product algorithm coding theory literature probably gallager decoding algorithm low density parity check codes 
optimum minimum probability symbol error detection algorithm codes referred map maximum posteriori probability algorithm algo rithm authors turns special case sum product algorithm applied trellis 
algorithm developed earlier statistics literature earlier classified due welch 
signal processing literature particularly speech processing algorithm widely known forward backward algorithm 
pearl belief propagation belief revision algorithms widely applied expert systems artificial intelligence turn examples sum product algorithm operating bayesian network see textbook treatments 
neural network formulations factor graphs unsupervised learning density estimation see 
coding theory tanner generalized gallager bipartite graph approach codes developed versions sum product algorithm 
tanner approach generalized graphs hidden state variables wiberg 
coding theory current interest called soft output decoding algorithms stems near capacity achieving performance turbo codes introduced berrou 
turbo decoding algorithm formulated bayesian network framework mceliece kschischang frey :10.1.1.73.8252
sum product algorithm example describe precisely section sum product algorithm factor graph forms tree compute function summary marginal 
example consider specific case global function defined real valued represents conditional joint probability mass function collection discrete random variables observation interested say marginal function jy factorization write jy fa fa fb fc fd fe de bcde write fde product fd product fb 
identified various factors need computed obtain jy 
notation summary operator introduced section 
example notation xe called summary xe defined marginal function xe xe obtained summing possible arguments notation jy primary observation computed knowing just fa factor computed knowing just fb fc fde turn fde computed knowing just fd fe products gathered distributed manner factor graph shown fig 

imagine processor associated node factor graph capable performing local computations computing local function products local function summaries imagine processors capable communicating adjacent processors sending messages edges factor graph 
messages descriptions summaries various local function products 
passing messages shown fig 
factors necessary computation available fb fb fa fe fd fa fb fc fe fd fde computing sum product algorithm 
clear processor needs follow single simple computational rule message passed node node edge fv wg product messages arrive edges incident local function summarized variable fv wg associated edge 
reader may verify precisely rule followed generating messages passed factor graph fig 

tree algorithm terminates computing variable node case product incoming messages 
exercise reader may wish verify various factors needed compute marginal function obtained products messages sent sum product algorithm shown fig 
section 
conceptually simple computational procedure operating corresponding factor graph able derive wide variety algorithms mentioned 
notational preliminaries need terminology ideas graph theory 
graph vertex set edge set edges directed edge vertices unordered pair fv wg said incident degree vertex number edges incident set neighbors fw fv wg set vertices share edge clearly distinct neighbors 
function node factor graph set arguments path vertices defined usual sequence distinct edges fv fv gamma vl cycle path vertex 
path said connected vertices considered connected connectedness equivalence relation vertices disjoint equivalence classes induce disjoint subgraphs called connected components comprises single component case majority factor graphs considered said connected 
graph tree connected cycles 
graph tree unique path pair distinct vertices tree vertex said leaf node 
finite tree node leaf nodes 
arbitrary distinct vertices tree leaf node distinct path pass arbitrary distinct means edge incident deleted resulting graph tree 
generally tree graph obtained cutting removing edge fv wg union components denoted gw containing denoted containing trees 
notation intended mnemonic gw subgraph viewed edge fv wg facing direction variables corresponding nodes distinct components factor graph said contribute independently corresponding global function 
generally variable subsets xe xe contribute independently contained distinct components joint probability mass density function collection random variables variables contribute independently corresponding random variables independent 
converse necessarily true 
need useful notation called iverson convention indicating truth logical proposition boolean proposition binary function indicates true ae iverson convention formulas contexts sensible valued quantity 
occasionally square brackets simply brackets cause confusion enclosed quantity cases boolean proposition 
occasion consider binary indicator functions valued functions variables 
convenient graphical representation binary indicator function variables values finite alphabets trellis section 
function exists set ae theta theta 
take set defining set labeled edges directed bipartite graph called trellis section 
take set set left vertices set set right vertices set set edge labels 
triple defines edge left vertex right vertex label example binary variables considered elements field gf trellis sections corresponding xy shown fig 
respectively 
figures trellis sections placed left vertices left right vertices right arrow indicating orientation edge required 
trellis sections corresponding binary indicator functions variables xy 
organization remainder organized follows 
section illustrate broad applicability factor graphs motivate remainder provide number examples factor graphs variety areas including coding theory systems theory probability theory neural networks signal processing 
section study cross sections projections functions formulate general notion summary operator acts function projection create marginal functions 
operation sum product algorithm described section 
briefly described sum product algorithm operates local computational procedure characterized conceptually simple computational rule 
tree prove procedure results exact function marginalization 
appendix provide complexity analysis important case summary operator defined terms sum operation example section section apply sum product algorithm factor graphs section obtain variety known algorithms special cases 
include forward backward algorithm viterbi algorithm pearl belief propagation algorithms bayesian networks kalman filter 
section describe possible transformations may applied factor graph changing function represents 
motivate procedure exact marginalization factor graphs cycles 
application procedure derive fast fourier transform algorithm special case sum product algorithm 
concluding remarks offered section 
examples factor graphs having defined general concept factor graphs give examples way factor graphs may represent useful functions 
section describe applications sum product algorithm graphs 
multi variable functions wish represent factor graph particular classes stand set membership indicator functions value probability distributions 
functions interpreted models set theoretic probabilistic respectively physical system 
example willems system theory starts view system model simply set allowed trajectories configuration space 
factorizations functions give important structural information model 
structure factor graph strong influence performance sum product algorithm see section algorithm exact defined sense graph cycles 
shall see number established modeling styles set theoretic probabilistic correspond factor graphs particular structure 
indicating set membership tanner graphs start set membership indicator functions 
usual index set denote configuration space 
applications particularly coding theory fixed subset think set codewords valid configurations 
applications interested set membership indicator function defined ae course interested situations factors 
particular suppose factor fe xe binary indicator function indicates particular ae locally valid 
global function local functions take values set considered subset reals usual multiplication 
setup configuration valid fe product acts logical conjunction operator global configuration valid valid 
context local functions referred local checks corresponding function nodes factor graph called check nodes 
code ae somewhat loosely refer factor graph representation strictly mean situations factor graph representation indicator function 
refer factor graph set membership indicator function factors product local checks tanner graph 
example 
linear codes course code factor graph representation general 
convenient way construct factor graph linear code start parity check matrix code 
illustrate consider linear code gf defined parity check matrix consisting binary tuples satisfying hx 
linear code parity check matrix approach applies linear codes 
effect row parity check matrix gives equation satisfied equations satisfied 
binary function indicating satisfaction equation introduced product functions indicates membership code 
example rows code membership indicator function written product local indicator functions phi phi phi phi phi phi iverson convention phi denotes sum gf 
corresponding factor graph shown fig 

factor graph binary linear code example 
fig 
special symbol parity checks square sign black square 
fact freely variety symbols function nodes depending type local function 
variable nodes drawn circles double circles fig 
described indicate auxiliary variables states 
example 
logic circuits readers may surprised note quite familiar certain factor graphs example factor graph shown fig 

local checks drawn logic gates remind definition corresponding binary indicator function 
example gate inputs output represents binary indicator function 
viewed factor graph logic circuit fig 
represents global function function takes value arguments form configuration consistent correct functioning logic circuit 
general logic circuit viewed factor graph 
local function corresponding elementary circuit takes value corresponding variables behave locally required circuit 
necessary auxiliary variables directly observable input outputs fig 
may introduced logic gates 
shall see example auxiliary variables give rise particularly nice representations set membership indicator functions 
logic circuit factor graph 
example 
auxiliary variables dealing binary functions indicating membership set ae valid configurations useful introduce auxiliary state hidden variables 
mean set oe set variables indexed called auxiliary variables 
setup view set respect enlarged configuration space introduce set ae configurations enlarged space 
provided elements respect equal consider factor graph valid factor graph forney refer factor graph factor graph set membership indicator function having auxiliary variables tanner wiberg loeliger graph mentioned earlier auxiliary variable nodes indicated double circle factor graph diagrams 
illustrate idea fig 
shows graph binary code example 
addition variable nodes variable nodes auxiliary variables definition local checks drawn generic function nodes black squares terms trellis code shown fig 

trellis defined property sequence edge labels encountered directed path left right leftmost vertex rightmost vertex trellis codeword codeword represented path 
auxiliary variables correspond trellis states local check represents trellis section ith local function counting left indicates triples gamma valid state output state transitions trellis drawn convention indicator functions variables introduced section 
trellis corresponding graph code fig 

example second trellis section left fig 
consists triples alphabet state variables taken respectively numbered bottom top fig 

corresponding check local function graph indicator function 
method described example obtain factor graph trellis completely general applies trellis 
code represented trellis see survey results theory trellis structure codes shows cycle free factor graph exists code fact set membership function 
general purpose introducing auxiliary variables states obtain nice factorizations global function possible 
example 
state space models convenient representations variety signal models 
example generic factor graph fig 
represent time invariant time varying state space model 
fig 
local check represents trellis section indicator function set allowed combinations left state input symbol output symbol right state 
trellis edge labels 
example classical linear state space model equations ax bu cx du zis discrete time index time input variables output variables xm state variables matrices appropriate dimensions 
equation finite infinite field system gives rise factor graph fig 

time check function theta theta theta ax bu cx du words check function enforces local behavior required 
gamma gamma gamma generic factor graph time invariant trellis 
probability distributions turn important class functions represent factor graphs probability distributions 
conditional unconditional independence random variables expressed terms factorization joint probability mass density function factor graphs probability distributions arise situations 
expose primary application interests starting example coding theory 
example 
decoding consider situation modeled coding theory codeword selected uniform probability code length transmitted discrete memoryless channel corresponding output 
channel memoryless definition conditional probability mass density function evaluated particular channel output assumes product form jx jx priori probability selecting particular codeword constant priori joint probability mass function codeword symbols proportional code set membership indicator function 
follows joint probability mass function fx proportional jx course described previous subsection code membership indicator function may factor product local indicator functions 
example binary linear code example phi phi delta phi phi delta phi phi delta jx factor graph shown fig 

see factor graph joint probability mass function codeword symbols channel output symbols obtained simply augmenting factor graph code 
decoding invariably conditional joint probability mass function codeword symbols observation channel output symbols 
discussed detail section general function terms deal scaled factor graphs joint probability density function channel input output binary linear code fig 
cross section observation particular channel output vector 
cross section joint probability mass function defined 
turns factor graph function cross section obtained factor graph function simply removing nodes corresponding observed variables replacing local functions cross sections shown example code fig 

cross section function jx interpreted function parameter example 
markov chains hidden markov models factor graphs arrows general denote joint probability mass function collection random variables 
chain rule conditional probability may express function jx gamma example jx jx jx factor graph representation shown fig 

chain rule factorization situations involving probability distributions local functions form ja collection variables referred parents case motivated similar convention bayesian networks see example indicate child relationship placing arrow edge leading local function followed arrow convention fig 

jx jx jx jx jx jx jx jx jx jx jx jx jx factor graphs probability distributions trivial factor graph chain rule factorization markov chain hidden markov model 
general variables appear arguments jx gamma factor graph fig 
advantage trivial factor graph shown fig 

hand suppose random variables order form markov chain 
obtain nontrivial factorization jx gamma factor graph shown fig 

markov chain example observe directly observe output memoryless channel input obtain called hidden markov model 
joint probability mass density function random variables factors jx gamma jx factor graph shown fig 

hidden markov models widely variety applications see tutorial emphasizing applications signal processing 
strong resemblance factor graphs fig 
factor graphs representing figs 
accidental viewed markov models codes 
course factor graphs graph language describing probability distributions 
examples describe briefly close relationship factor graphs models undirected graphs markov random fields models directed acyclic graphs bayesian networks 
example 
markov random fields markov random field see graphical model undirected graph node corresponds random variable 
graph markov random field mrf distribution satisfies local markov property usual denotes set neighbors words mrf variable independent non neighboring variables graph values immediate neighbors 
mrfs developed statistics variety applications see 
kschischang frey give brief discussion mrfs describe codes :10.1.1.73.8252
recall clique graph collection vertices pairwise neighbors 
fairly general conditions positivity joint probability density sufficient joint probability mass function mrf expressed product collection gibbs potential functions defined set cliques mrf 
authors takes defining property mrf 
means distribution factors vn gamma fe gamma normalizing constant clique 
example cf 
fig 
mrf fig 
express factorization gamma fc cliques graph fv assume additional factors absorbed factors example factor absorbed fc 
clearly precisely structure needed factor graph representation 
factor graph representation may preferable mrf expressing factorization distinct factorizations factorizations different qs may yield precisely underlying mrf graph yield distinct factor graphs 
example coding context mrf ambiguity :10.1.1.73.8252
opposite direction factor graph represents joint probability distribution converted markov random field component second higher power graph :10.1.1.73.8252
factor graph graph vertex set edge vertices path graphical probability models markov random field bayesian network factor graph 
length bipartite decomposes components component involving variable nodes involving function nodes 
arguments function node connected path length arguments form clique example fig 
shows factor graph fig 

theorem proved appendix theorem factor graph represents probability distribution product non negative factors markov random field 
theorem interpreted saying sense factor graph square root markov random field 
example 
bayesian networks bayesian networks see graphical models collection random variables directed acyclic graphs dags 
bayesian networks combined pearl belief propagation algorithm important tool expert systems past decade 
connect bayesian networks belief propagation applications coding theory mackay neal independently re discovered gallager earlier low density parity check codes including gallager decoding algorithm 
papers develop view turbo decoding algorithm instance probability propagation bayesian network code model :10.1.1.73.8252
node bayesian network associated random variable 
denoting set parents set vertices edge incident distribution represented bayesian network assumes form ja parents take 
example cf 
fig 
shows bayesian network expresses factorization jv jv jv markov random fields bayesian networks express factorization joint probability distribution suitable representation factor graph 
factor graph corresponding shown fig 
cf 
fig 

arrows bayesian network useful modeling flow causality practical situations see 
provided required child variable take particular value straightforward simulate bayesian network draw configurations variables consistent represented distribution 
starting variables having parents values assigned parents particular variable simply randomly assigns value local conditional probability distribution ja 
arrow convention factor graphs noted earlier illustrated fig 
allows retain advantage bayesian networks 
note factor graphs general markov random fields bayesian networks describe functions necessarily probability distributions 
furthermore factor graphs stronger property markov random field bayesian network redrawn factor graph information loss converse true 
example 
logic circuits revisited probability models obtained extension behavioral models 
case example 
example consider logic circuit fig 
suppose fu random variables assume particular configurations priori probability distribution 
difficult see joint probability mass function joint probability mass function example factor graph representation joint probability mass function variables logic circuit example 
delta joint probability mass function delta indicator function defined 
factor graph corresponding case factors shown fig 

fig 
includes arrows showing flow causality inputs outputs logic gates 
pair input variables clustered treated single variable 
variable clustering transformations factor graphs discussed section 
general subsystems deterministic input output relationship variables output variable viewed child variable having input variables parents configuration parents corresponding conditional probability distribution assigns unit mass configuration consistent input output relationship 
discussed arrows fig 
useful simulations distribution represented factor graph relatively straightforward go inputs outputs graph 
shall see sum product algorithm useful reasoning opposite direction computing say conditional probability mass functions system inputs hidden variables observed system output 
example models faults various subsystems may able sum product algorithm reason probable cause observed faulty output 
examples give number examples factor graphs variety fields including artificial intelligence neural networks signal processing optimization coding theory 
example 
computer vision neural network models graphical models impressive place field neural network models perception 
see textbook treatment 
traditional artificial neural networks called multilayer perceptrons treat perceptual inference function approximation problem 
example perceptron objective predict relative shift images providing way estimate depth 
initially perceptron parameters set random values perceptron bad predicting depth 
set training images labeled depth values perceptron parameters estimated predict depth pair images 
realistic unsupervised learning situation depth labels provided neural network supposed extract useful structure data 
fruitful approach design algorithms learn efficient source codes data 
parameters probability model adjusted minimize relative entropy empirical data distribution distribution model 
graphical model factor graph framework provides way specify neurally plausible probability models 
neural network factor graph associate local function variable local function gives probability variable activities local input variables 
example probability binary variable binary inputs fx may take form jfx exp gamma ij ij weight edge connecting simplest case create variable input variable 
introduce unobserved hidden latent variables graphical model 
model trained marginal distribution visible variables close empirical data distribution hope hidden variables represent useful features 
details models learning algorithms fall scope brief example 
see details model learning algorithm real valued variables 
example discuss binary version problem clarity 
image pair dimensional contains binary pixels 
training data generated randomly drawing pixel patterns image shifting image pixel right left equal probability produce second image 
fig 
shows examples image pairs pair images placed highlight relative shift 
fig 
shows factor graph structure learned examples image pairs 
initially variable connected variables adjacent layers parameters set random values 
learning weights associated depth variable right shift variables image image image left shift variables image factor graph neural network model depth perception 
examples training cases simplified depth estimation problem 
unneeded edges shown close zero 
remaining edges middle layer variable represents dependence pixel image pixel second image 
middle layer variables separated groups group variable links pixel image pixel left image group right shift relationships represented 
dependencies middle layer variables captured depth variable 
depth activation middle layer variables group shut middle layer variables group may may active 
labeled training data unsupervised learning algorithm extract architecture predict depth 
challenging research problem development algorithms learn structures described larger scale 
real world data images dimensional larger number pixels depth varies image network interact feature detectors sensory modalities 
example 
dft kernel provide example field signal processing widely tool analysis discrete time signals discrete fourier transform 
wn gamma complex valued tuple omega gamma primitive nth root unity 
recall discrete fourier transform complex valued tuple wn gamma gamma omega gamma consider case power concreteness 
express variables binary precisely take values 
write dft kernel take global function terms omega gamma gamma gamma gamma gammax gammax omega gammax relations omega omega omega gamma omega see dft kernel factors product local functions expressed factor graph fig 

observe dft viewed marginal function probability mass function 
composite similar prime factor decompositions result similar factor graph representations dft kernel 
section see factor graph representations lead fast fourier transform fft algorithms 
factor graph discrete fourier transform kernel function 
example 
dynamic programming field optimization formulation called dynamic programming problems consider functions additive composition local functions 
types problems fit naturally factor graph framework provided view multiplication operation real valued addition 
interested minima maxima global function take summary operator min max operation 
interesting observe close relationship interaction graph dynamic programming problem graph corresponding markov random field see example really object defined respect different binary operation function addition dynamic programming case function multiplication markov random field case 
markov random field case interaction graphs recovered second higher power factor graph 
example 
weight enumerating functions non probabilistic example coding theory 
linear code length binary indicator function membership denote hamming weight codeword wt 
indeterminate 
function takes value wt valid codeword zero 
think modified indicator function indicates valid codeword returns hamming weight exponent valid codeword 
define summary operator terms usual addition polynomials hamming weight enumerator factor graph representation obtained augmenting factor graph representation code membership indicator function local functions code example lead factor graph structure fig 

function cross sections projections summaries section collection variables indexed set configuration space variables function variables commutative semigroup factors corresponding factor graph 
cross sections ae subset variable index set xe set variables indexed ae particular respect viewed defined section multiple variable assignment xe ae assignment yields function cross section sne ae example kx ae constant 
factor graph cross section sne ae obtained factor graph simply 
replacing local function having argument corresponding cross section 
omitting variable nodes indexed edges incident 
example factor graph shown fig 

factor graph cross section kx kx kx shown fig 

kx kx factor graphs cross section kx kx kx 
probability mass density function cross section sne ae linearly proportional conditional probability mass density function variables indexed particular ae variables indexed variables contribute independently cross section sne ae contained distinct components factor graph cross section 
component factor graph contribute independently cross section vertices separate factor graph 
probability case table function viewed relation 
projection coordinate 
say corresponding random variables conditionally independent random variables indexed 
variable subsets xe sne contribute independently function scale cross section sne ae configuration looks 
precisely exists function sni cross section sni kx scalar multiple sni 
projections summaries function viewed relation particular subset theta unique element set domain codomain 
consider projection set coordinates domain 
cross section projection function results relation general function 
example projection function shown table coordinate relation shown table 
relation general function particular stand relation element projection converted function introducing operator summarizes sense multiple function values associated configuration relation domain 
example real valued way summarizing multiple function values associated value take sum define new function 
probability mass function marginal probability mass function 
possible summary operation take maximum multiple function values define max 
clearly large number summary operators possible 
introduce notation operator 
xc ac function ae denote xc xb ab new function called marginal summary xb obtained summarizing fixed configuration variables xb multiple function values associated possible configurations arguments xb convenience refer variables xc xb summarized mean course summary corresponding function values 
function table marginal fx summary multiple function values table denoted fx simply refer having summarized 
summary operator apply case ae extend general case arbitrary subsets index set defining xc xb ab xc xb xc xb words marginal xc xb function obtained summarizing arguments xb summarizing variables indexed 
note xc summary function values summary xc 
consider properties summary operator possess 
nonempty subset index set ab denote set functions ab extend notation case empty defining suppose family mappings pair fb cg subsets ae mapping ac ab ac family associates element ac written suffix notation xb ac element xb ab extend family mappings arbitrary defining ac ab ab denote result 
family mappings defined previous paragraph called summary operator valued functions variable index sets axioms satisfied 
ae xd xb xd xc xb 
ae xb delta xd xc xb delta xd xc 
xb delta xc xd xb xd delta xc xd 
axioms modeled properties marginal functions probability theory 
axiom implies marginals obtained sequence stages restrictive summaries sequence yield function 
example table fx fx summarize vice versa obtain marginal function case 
axioms describe summary operators behave respect function products 
ae fixed configuration variables xc function xb constant axiom states constant factored marginal function 
axiom says functions interact arguments common marginal product product marginals 
axiom extends easily case product functions disjoint arguments 
lemma important 
lemma xa xb disjoint contain xa xb xa delta xb proof write xa xb xa xb fxg xa xa xb fxg xa xa xb xa delta xb equality follows applying axiom second equality follows axiom third equality follows assumption xa xb disjoint fourth equality follows application axiom 
lemma clearly extended analogous situation involving product functions arguments intersecting pairwise fxg 
example xa xb xc pairwise disjoint contain xa xb xc xa xb delta xc xa delta xb delta xc summary operators binary operations symbol alphabets finite define summary operator terms commutative associative binary operation denote binary operation thinking sum summary 
insist summary operator satisfy distributive law delta delta delta require delta form semiring delta multiplication operation usually denoted juxtaposition 
arbitrary subsets define marginal function xb xc xb xc snc xb summing configurations variables indexed empty take xb xc xb 
definition clearly gives family mappings associate element ab element ab example marginal respect function table computed ay az distributive law commutativity product operation clear summations performed arbitrary order axiom summary operators satisfied 
furthermore distributive law follows axiom satisfied 
arguments common distribute law implies axiom satisfied 
theorem 
theorem family mappings defined summary operator 
important example summary operator arises case set reals usual multiplication taken ordinary real addition 
joint probability mass function random variables marginal probability mass function generally represents probability density function jointly continuous random variables replacing sums integrals define family mappings take function appropriate marginal function gamma gamma dy dz straightforward exercise verify definition gives family mappings satisfies axioms required summary operators 
possible summary operator reals obtained semiring delta ordinary addition min operator min 
case minimum taken configurations agreeing sum product algorithm having introduced concept factor graph section concept summary operator section section combine concepts describing generic algorithm sum product algorithm operates factor graph sequence local computations 
computations follow single conceptually simple rule combining product summarization operations 
results local computations passed messages edges factor graph 
general large variety possible message passing schedules factor graph possible 
tree family schedules called generalized forward backward schedules cause exactly message pass direction edge tree 
prove result computation set marginal functions specific ae sum product algorithm applied factor graphs cycles 
cycles graph iterative algorithm natural termination result 
contrast case cycles results sum product algorithm operating factor graph cycles general interpreted exact function summaries 
shall clear exciting applications sum product algorithm example decoding turbo codes low density parity check codes arise precisely situations underlying factor graph cycles 
usual collection variables indexed set configuration space variables function variables commutative semigroup delta denote summary operator valued functions 
suppose factors collection subsets corresponding factor graph 
computation message passing sum product algorithm best described imagining processor node underlying factor graph edges represent channels processors may communicate sending messages 
messages valued functions descriptions thereof 
example binary variable values real valued function described vector vector passed message edge equivalently vector gamma contains information convenient taken description 
probably mass function number scalar valued function descriptions gamma log convenient provide adequate description continuous valued drawn parameterized set probability density function exponential family vector containing function parameters description cause form products messages 
mean course products corresponding functions products actual messages 
course functions discrete variable functions described ordered vectors containing function values vector description product component wise product vector descriptions sum product update rule deferring moment question algorithm initialization describe simple computational rule followed sum product algorithm 
sum product update rule message sent node edge product local function unit function variable node messages received edges summarized variable associated note message sent edge fx fg variable node function node function variable associated edge 
denote fv wg message sent node node sum product algorithm 
illustrated fig 
message computations performed sum product algorithm expressed follows ffg fxg factor graph fragment showing sum product algorithm update rules 
variable local function local function variable update rule variable node takes particularly simple form local function include summary product functions simply product 
hand update rule local function node general involves nontrivial function multiplications followed application summary operator 
message passing schedules message sent node edge general depends messages received edges message passing initiated 
circumvent difficulty initially supposing unit message message representing unit function arrived edge incident vertex 
convention node position send message time 
necessary practical implementation assumption message passing synchronized global discrete time clock 
assume message may pass edge direction clock tick message replaces previous message passed edge direction 
message sent node time function local function messages received times prior message passing schedule sum product algorithm factor graph sequence fl ae theta theta set edges considered directed messages pass time schedule node sends message node time obviously wide variety message passing schedules possible 
example schedule theta theta called flooding schedule :10.1.1.73.8252
flooding schedule calls message passed edge direction clock tick 
singleton jl resulting schedule called serial schedule calls message entire graph passed clock tick 
despite generality possible schedules observations 
say vertex message pending edge message send potentially different previous message sent example variable nodes initially messages pending initially send unit message exactly initially assumed sent 
function nodes hand send description local function appropriately summarized edge 
general summary unit function messages passed function nodes messages pending incident edge 
message received node general cause change values messages sent edges incident node 
receipt message edge node causes message pending edges incident course receipt message leaf node creates messages pending edges leaf nodes absorb pending messages non leaf nodes distribute pending messages 
pending messages need sent clock tick definition pending messages potential different previous message sent edge 
necessary pending message sent time 
call message passing schedule idle pending message sent clock tick 
flow pending messages schedule visualized diagrams shown fig 
pending message shown dot near edge 
transmission message indicated attaching arrow dot 
flow time indicated messages sent non negative integer times fig 
shows possible message passing schedules factor graph 
pending messages shown 
fig 
flooding schedule pending messages sent clock tick shown fig 
way schedule defined schedule exactly message passes direction edge shown 
explicitly schedule fig 
fl labels shown fig 

gamma gamma gamma gamma gamma gamma message passing schedules factor factor graph flooding schedule pending messages shown way schedule shown 
computation trellis schedule shown 
schedule factor graph visualized computation trellis shown fig 

trellis vertices depth correspond vertices factor graph 
edges ith trellis section precisely considered directed left right 
ith trellis section left vertices considered depth right vertices depth 
leaf nodes absorb pending messages sum product algorithm uses idle schedule finite tree eventually arrive state nodes messages pending 
happen graph cycles 
example fig 
shows flow messages flooding schedule factor graph single cycle 
state pending message graph time gamma gamma gamma clear algorithm terminates situation messages pending 
fact graph cycle message passing schedule result transmission pending messages transmission message edge cycle eventually cause message reach originating node triggering node send message edge indefinitely 
practice infinite schedules rendered finite truncation 
sum product algorithm terminates finite schedule computing selected subset product messages received variable node messages pending computation equivalent product messages sent received single edge incident shall see finite tree schedule terminating computation yields marginal function gamma gamma flooding schedule factor graph single cycle 
sum product algorithm finite tree articulation principle assume finite tree 
discussed section graph obtained cutting edge fv wg union components denoted fw containing denoted containing 
intuitively operation sum product algorithm information local functions fw flow edge fv wg similarly opposite direction 
course general interested function summaries information fw sent general summarized fv wg variables involved refer intuitive idea articulation principle message sent articulate encapsulate summarize variables attached product local functions fw formally ensure qw fe xe qw set function nodes fw set containing fv wg variables qv xe articulation principle closely related notion state sufficient statistic needs known product functions side cut processors side cut captured articulated message sent cut 
observation tree set variables appear arguments functions side cut set variables appear arguments functions side cut fv wg common xw fv wg follows qw fe xe qw fe xe fv wg message passed needs function fv wg write articulation principle trees fv wg qw fe xe fv wg generalized forward backward schedules family schedules trees called generalized forward backward schedules cause exactly message passed direction edge shall prove message satisfies articulation principle 
complexity analysis schedules appendix special case alphabets finite summary operator defined terms binary operation 
course basic update equations followed add proviso node may send message edge received messages edges incident clearly send message received gamma messages 
refer rule 
rule leaf node leaf node send message initially schedules leaf nodes 
leaf variable node message sent unit function leaf function node message sent description function 
formally initialization leaf variable node leaf function node suppose message sent leaf node edge incident deleted resulting graph observed section tree 
furthermore leaf node position send message received messages edge 
choose leaf nodes compute message send outgoing edge send message delete node edge form new graph 
basic invariant properties sequence graphs constructed way leaf nodes position send message messages sent edge 
clearly process continue just single node remains 
stage graph tree node leaf nodes position send message process stall 
point just single node remains message passed direction edge original graph furthermore received messages edges 
re construct starting choose neighbor adjoin edge fv wg form new graph call send message point received messages edges 
adjoin neighbor corresponding edge form graph sending message newly added vertex 
vertex received messages edges 
continuing manner adjoin neighboring node graph nodes added 
basic invariant properties sequence graphs node received message edges exactly messages direction sent edge 
course properties true graph sequence 
algorithm terminates regenerated computing selected subset product messages received variable node equivalently product messages sent received single edge incident formally termination note finite algorithm terminates finite number steps 
prove correctness equality 
show messages passed operation schedule satisfy articulation principle 
expressed main theorem 
theorem finite tree sum product algorithm follows generalized forward backward schedule messages satisfy articulation principle 
neighbors fv wg fw xw fv wg fw xw product local functions fw proof proceed induction order messages sent algorithm 
statement clearly true leaf node 
show true outgoing messages true incoming messages node follow induction true messages 
designate fv wg outgoing edge suppose equivalent satisfied incoming messages fu vg fu vg variable node fu vg distinct fvg lemma obtain nw nw desired 
local function node nw fu vg assumption message leaf node case 
applying axioms defining summary operator lemma write fw xw hi delta ji delta delta delta cases product fwg noted explicitly equality follows definition fw xw 
equality follows axiom fwg ae follows axiom 
distinct fwg disjoint get axiom 
follows fug follows assumption follows definition 
words message sent required summary 
theorem lemma obtain proof correctness termination condition 
express corollary 
corollary factor graph function suppose finite tree 
variable node denote message passed operation sum product algorithm generalized forward backward schedule 
proof write equality follows fact written product local functions contained disjoint subtrees obtained removing node second equality follows lemma distinct fxg third equality follows theorem 
example continued continue example section corresponds factor graph fig 

abbreviated notation writing abc product fa fb fc local functions 
applying schedule pass messages shown fig 

node sum product rule followed product local functions summarized variable associated edge 
observe product messages passed directions edge contain factors global function 
observation gives termination rule compute product messages passed directions edge incident bcde bcde de abc abcde abce abcd abcde messages passed generalized forward backward schedule 
forests course operation sum product algorithm tree generalizes trivially case forest finite collection components tree 
suppose case components may written xc index set variables kth component product local functions kth component 
compute observe xc xc axiom summary product functions disjoint arguments product summaries simply run sum product algorithm separately component produce summary ae xc component 
done summarizing marginal function xc gamma xc delta delta ae index component containing sum product algorithm applied compute exact marginal functions finite factor graph containing cycles 
message semantics general schedules seen schedule followed tree message passed sum product algorithm clear meaning expressed articulation principle 
subsection consider message semantics general schedules 
section behavior sum product algorithm finite tree easy analyze arbitrary schedule 
factor graph finite tree arbitrary nodes fv fv gamma vl denote sequence distinct edges unique path nodes receive messages immediate neighbors say node influences node time sequence times delta delta delta gamma pending message sent node time sequence say message sequence sent time reaches time note received message necessarily received message nodes path denotes set nodes influenced time earlier induces subtree neighbor denote component tw containing edge fv wg cut 
message sent time mean message sent node node time large possible satisfies analogy theorem 
theorem neighbors message sent time operation sum product algorithm equal product local functions summarized fv wg proof sketch node processor followed articulation principle 
arguments identical proof theorem obtain desired result 
details omitted 
noted finite tree idle schedule eventually arrive time nodes messages pending 
time call time node received messages sent node particular subgraph equal fw theorem implies algorithm arrive result sum product algorithm schedule section 
express result corollary theorem 
corollary factor graph finite tree idle message passing schedule sum product algorithm eventually result state messages pending point algorithm terminated arrive exactly result obtained schedule 
graphs cycles small exception noted know generalization theorems 
difficulty nodes involved cycle influence point clear message semantics involving articulation principle longer apply 
define corrupted node influences path length greater 
impossible node influence path length sends message reply received contains component message 
denote set nodes influenced node latest message passed node node time definition node influences chain messages path chain messages originates definite time 
denote largest time message sent reaches time exception 
provided node corrupted time necessarily implies tree articulation principle applies latest message sent equal product local functions summarized fv wg cycles close message semantics remain clear expressed articulation principle 
graphs cycles basic sum product algorithm compute exact marginals 
discuss methods handling difficulties section applications decoding low density parity check codes turbo codes successful strategy simply ignore cycles proceed idle message passing schedule terminating computation convenient point 
difficult analyze behavior iterative algorithms approach excellent performance confirmed extensive simulation results led explosion interest methods coding theory community 
applications sum product algorithm apply sum product algorithm factor graphs section 
main results derivation variety known algorithms special cases sum product algorithm 
forward backward algorithm forward backward algorithm referred coding theory algorithm map algorithm application sum product algorithm hidden markov model example shown fig 
examples examples figs 
certain variables observed output memoryless channel 
local functions represent real valued conditional probability distributions summary operator real addition 
factor graph forward backward algorithm operates state variables input variables output variables observation output memoryless channel input 
factor graph fig 
represents joint probability distribution random vectors factor graph arise example terminated trellis code time inputs states transmitted symbols received symbols observation find jy posteriori probabilities apps input symbols 
take ordinary real addition summary operator jy xjy factor graph fig 
cycle free quantities computed sum product algorithm 
typical forward backward message passing schedule initialization forward recursion backward recursion termination 
fig 
shows typical schedule sum product algorithm trellis case factor graph representing conditional probability mass function fixed variable nodes degree described section computation performed variable nodes 
note initialization termination steps main schedule involves chain messages passing left right forward chain passing right left backward factor graph 
reason algorithm referred forward backward algorithm 
fact forward backward message chains interact computation occur parallel 
ff ff fl fi fi ffi detailed view messages passed operation forward backward algorithm 
literature forward backward algorithm messages sent channel input variables referred fl messages sent state variables forward step referred ff messages sent state variables backward step referred fi 
refer conditional app ffi 
fig 
gives detailed view messages single trellis section 
local function represents function indicates valid state input output state tuples ith trellis section 
specializing general update equation case find ff ff fl fi fi fl ffi ff fi fl sums summand zero combinations representing valid trellis edge effect sums viewed defined valid trellis edges 
edge ff ff fi fi fl fl 
denoting set edges incident state ith trellis section ff fi update equations re written ff ff fl fi fi fl basic operation forward backward recursion multiply accumulate 
light theorem articulation principle ff conditional probability mass function observation past gamma state ff conditional probability transmitted sequence passed state observation past 
similarly fi conditional probability mass function observation conditional probability transmitted sequence passed state probability transmitted sequence took particular edge ff fl fi ff fl fi 
note interested apps vector vector computed forward backward algorithm 
see tutorial applications forward backward algorithm applications signal processing 
min sum semiring viterbi algorithm suppose interested apps individual symbols interested determining valid codeword largest app 
codeword priori equally amounts maximum likelihood sequence detection 
way accomplish operate sum product algorithm max product semiring replacing real summation max operator 
non negative real valued quantities max max xy xz distributive law satisfied 
denoting summary operator obtained denoting xjy joint conditional probability mass function codeword symbols channel output quantity xjy denotes app sequence 
course interested determining probability finding valid codeword achieves probability 
consider unique state sequence corresponding codeword xjy substitute quantity 
practice carried negative log likelihood domain 
multiplicative decompositions additive structure underlying factor graph unaffected 
max operation min operation deal min sum semiring 
real min min distributive law satisfied 
gammaa ln convenient constants denote summary operator min sum semiring 
interested determining achieved sum product algorithm called min sum algorithm factor graph cycle free determining pair achieves quantity 
consider special case trellis length factor graph fig 
shows ignoring input symbols interested summary compute minimize quantity values particular suppose sl single terminating state 
case quantity computed forward recursion applying steps schedule shown fig 

trellis edge ith trellis section ff ff fl fl ffs fls quantities called state metrics branch metrics respectively correspond similar quantities computed forward step forward backward algorithm 
basic update equation corresponding translates ff min ff fl basic operation add compare select fl interpreted cost traversing edge procedure computes minimum cost traversing initial state final state example forward dynamic programming 
wish compute maximum likelihood value sequence achieves maximum need memory decisions ffs updated 
done variety ways example adjoining ffs survivor string records sequence output symbols best path initially ffl empty string 
survivor strings strings updated follows edge achieves minimum jx denotes string concatenation operator 
termination sl sequence output symbols codeword corresponding sequence achieving maximum likelihood value 
course wish store corresponding input sequence 
unidirectional min sum algorithm applied trellis modified memory survivor sequences usually referred viterbi algorithm 
iterative decoding turbo codes exciting applications sum product algorithm iterative decoding near capacity achieving codes turbo codes low density codes 
extensive simulation results see show sum product decoding algorithms long codes astonishing performance fraction shannon limit cases underlying factor graph cycles 
descriptions way sum product algorithm applied variety compound codes :10.1.1.73.8252
section restrict examples turbo codes low density parity check codes 
turbo codes turbo code parallel concatenated convolutional code encoder structure shown fig 

block data transmitted enters systematic encoder produces parity check streams output 
parity check stream generated standard recursive convolutional encoder viewed form output standard rate convolutional code 
innovation structure turbo code manner second stream generated 
stream generated applying permutation input stream applying permuted stream second convolutional encoder 
output streams transmitted channel 
constituent convolutional encoders typically terminated known state corresponding symbols fig 
transmitted channel 
factor graph representation short turbo code shown fig 

included state variables constituent encoders terminating trellis section data absorbed outputs generated 
turbo code encoder block diagram factor graph 
iterative decoding turbo codes usually accomplished message passing schedule involves forward backward computation portion graph representing constituent code followed propagation messages encoders resulting called extrinsic information turbo coding literature 
followed forward backward computation constituent code propagation messages back encoder 
schedule messages illustrated fig 

low density parity check codes low density parity check ldpc codes introduced gallager early 
ldpc codes defined terms regular bipartite graph 
ldpc code left nodes representing codeword symbols degree right nodes representing checks degree example fig 
illustrates factor graph short low density parity check code 
check enforces condition adjacent symbols parity example 
factor graph low density parity check code 
low density parity check codes turbo codes effectively decoded sum product algorithm example mackay neal report excellent performance results approaching turbo codes amounts flooding schedule 
appendix gives specific binary codes useful practical implementations min sum sum product algorithms 
belief propagation bayesian networks recall example bayesian network defined terms directed acyclic graph vertex represents variable represents joint probability distribution factors 
bayesian networks widely variety applications artificial intelligence expert systems extensive literature exists 
see textbook treatments 
convert bayesian network factor graph straightforward introduce function node factor ja draw edges node parents 
denote child drawing arrow edge function node example conversion bayesian network factor graph shown fig 

turns pearl belief propagation algorithm operating bayesian network equivalent sum product algorithm operating corresponding factor graph 
equations similar pearl belief updating bottom top propagation rules pp 
easily derived general sum product algorithm update equations follows 
forward backward example local functions represent conditional probability distributions summary operator real addition 
messages sent belief propagation 
belief propagation messages sent variable nodes corresponding dashed ellipses particular bayesian network shown fig 

bayesian network edge directed vertex vertex parent child messages sent variables functions parent message sent denoted message sent denoted shown fig 
specific bayesian network fig 

consider central variable fig 

clearly message sent upwards sum product algorithm local function contained ellipse product incoming messages message sent product messages received summarized note local function conditional probability mass function jx jx jx similarly message sent ellipse containing jx jx general denote set parents variables set children 
xja xja termination condition cycle free graphs called belief update equation product messages received factor graph bel xja pearl introduces scale factor resulting messages properly represent probability mass functions 
relative complexity compared simplicity sum product update rule section provides strong pedagogical incentive factor graphs 
pearl presents algorithm called belief revision terms belief revision max product version sum product algorithm applied factor graph corresponding bayesian network 
details straightforward extension omitted 
kalman filtering section derive kalman filter optimal predictor algorithm factor graph time varying discrete time linear dynamical system cf 
input system consists sequence unknown dimensional real valued input column vectors sequence hidden dimensional real valued state vectors meant represent internal dynamics system 
input vector state vector combine linearly produce state vector theta state transition matrix time theta matrix maps input state space 
input vectors may interpreted state transition noise vectors 
output system sequence dimensional real valued vectors output linear function state vector plus linear function dimensional noise vector theta output matrix time theta matrix maps noise process output space 
notice output space may high dimensional output noise may low dimensional consider case matrices 
assume input vectors output noise vectors independent gaussian zero mean 
theta covariance matrix oe oe cov theta gamma gamma delta gamma gamma delta indicates vector transpose 
theta covariance matrix define conditional covariance matrices fi cov jx oe ffi cov jx jx jx simplify expressions 
state sequence initialized setting gaussian vector zero mean covariance fi linear combinations jointly gaussian random variables gaussian fx fy jointly gaussian 
signal structure written terms conditional probability densities 
letting sigma sigmaj exp gamma gamma sigma gamma gamma normal distribution mean covariance matrix sigma jx fi jx ffi description linear dynamical system clear gamma independent gamma gamma jx gamma gamma jx gamma independent gamma gamma jx gamma jx chain rule probability follows joint density observations time gamma states time written gamma jx gamma gamma delta gamma jx gamma gamma jx gamma jx gamma gamma jx gamma jx factor graph global probability density function shown fig 

note fixed zero jx 
factor graph cross section function fixed gamma obtained eliminating nodes fig 
interpreting jx likelihood function parameter delta delta delta gamma gamma jx jx jx jx gamma jx jx jx gamma jx gamma factor graph linear dynamical system model 
consider standard state observer problem problem estimating state past observations gamma minimum mean squared error prediction jy gamma conditional expected value observed outputs 
conditional expectation obtained conditional density jy gamma 
fact really need compute function proportional jy gamma assuming normalize function 
case random variables jointly gaussian normalizing factors computed covariance matrices need computed explicitly 
factor graph cycle free take integration summary operator described section directly apply sum product algorithm compute function proportional jy gamma jy gamma observations need propagate messages forward chain 
denote function node factor graph corresponding jx gamma function node corresponding jx 
fixed zero take variable function message delta dirac function ffi 
evident function variable message jx dx fi ffi dx fi show compute function variable message time function variable message time note messages sent likelihood function nodes state nodes simply jx ffi message sent ffi message sent jx dx fi ffi dx initial function variable message gaussian convolution gaussians gives scaled gaussian function variable messages scaled gaussians 
state variable time factor graph just single edge see fig 
jy gamma predicted mean covariance state past observations exactly equal mean covariance function variable message time observations mean really need keep track means covariances messages scale factors ignored 
sigma mean covariance message sigma fi ffi sigma dx clearly solution integral written closed form simply convolution gaussians 
trick simplifying message rearrange terms exponents gaussians product complete square produce normal distribution integrate unity leaving function interested finding mean covariance message ignore normalization terms introduced rearrangement 
second trick simplifying message complete square mean covariance message evident 
tricks produce message gamma sigma gamma fi gamma ffi gamma gamma sigma gamma fi gamma ffi gamma sigma gamma fi gamma ffi gamma gamma delta gamma fi gamma gamma fi gamma sigma gamma fi gamma ffi gamma gamma fi gamma gamma fi gamma delta sigma gamma fi gamma ffi gamma gamma sigma gamma ffi gamma fi gamma gamma fi gamma sigma gamma fi gamma ffi gamma gamma fi gamma gamma delta dx gamma fi gamma gamma fi gamma sigma gamma fi gamma ffi gamma gamma fi gamma gamma fi gamma delta sigma gamma fi gamma ffi gamma gamma sigma gamma ffi gamma fi gamma gamma fi gamma sigma gamma fi gamma ffi gamma gamma fi gamma gamma delta mean covariance message simplified applying matrix inversion lemma gamma omega gamma gamma gamma omega gamma omega gamma nonsingular 
may interested exercise rest assured done 
simplified form message gamma gamma sigma ffi sigma gamma sigma ffi gamma fi sigma gamma sigma ffi sigma gamma sigma delta inserting definitions fi ffi find mean covariance message expressed gamma sigma oe sigma gamma sigma sigma gamma sigma sigma sigma gamma updates exactly equal updates kalman filtering 
particular called filter gain gamma called innovation sigma estimated mean covariance gamma factor graph transformations coping cycles section describe number straightforward transformations may applied factor graph changing meaning 
applying transformations possible transform factor graph inconvenient structure convenient form 
example possible transform factor graph cycles cycle free factor graph expense increasing complexity local functions messages sent operation sum product algorithm 
transformations quite useful apply derive fast fourier transform algorithm factor graph representing dft kernel 
similar general procedures described transforming graphical probability model cycle free form 
grouping nodes multiplying unity possible group nodes type variable nodes function nodes changing global function represented factor graph 
nodes grouped simply delete incident edges factor graph introduce new node representing pairing connect new node nodes neighbors original graph 
variables alphabets aw respectively pairing mean new variable alphabet theta aw function say argument original graph converted equivalent function argument 
accomplished simply applying projection operator maps writing 
note essentially set arguments argument depend grouping variables increase complexity local functions 
local functions pairing mean product local functions 
arguments set arguments product 
note grouping functions increase complexity variables 
fa fc fb fe fd ff fa fa grouping transformations original factor graph fragment variable nodes grouped function nodes fb fc fe grouped 
grouping nodes may eliminate cycles graph sum product algorithm new graph exact 
example grouping nodes associated factor graph fragment fig 
connecting neighbors nodes new grouped node obtain factor graph fragment shown fig 

notice local function node fe connecting original factor graph appears just single edge new factor graph 
notice local functions connecting 
local functions new factor graph retain dependences old factor graph 
example fb connected pair variables depend global function new factor graph delta delta delta fa delta delta delta fa fb identical global function old factor graph 
fig 
cycle easily removed grouping function nodes 
fig 
grouped local functions corresponding new global function delta delta delta fa delta delta delta fa identical original global function 
case grouping variable vertices function vertices removed cycles factor graph fragment 
remainder graph cycle free sum product algorithm compute exact marginals 
notice sizes messages region graph increased 
example alphabets size ja ja respectively functions represented list values length message passed fd equal product ja jja allow arbitrary factors unity 
essentially convenient set xb variables multiply global function factor unity xb introduce corresponding function node edges factor graph stretching variable nodes operation sum product algorithm message passed edge fv wg local function products summarized variable fv wg associated edge 
outside edges incident particular variable node function dependency represented summary form marginalized 
introduce factor graph transformation extend region graph represented summarized 
denote set nodes reached path length set variable nodes pair replace pair grouping transformation 
function nodes incident modified grouping transformation modification increase complexity 
call stretching transformation imagine node stretched path generally allow arbitrary stretching set nodes stretched allow stretched element set variable nodes reachable node path length 
stretching way retain basic property set nodes paired connecting function nodes induces connected subgraph factor graph 
connected subgraph generates defined set edges represented summarized operation sum product algorithm 
note global function unaffected transformation 
fig 
shows factor graph fig 
shows equivalent factor graph stretched variable nodes 
stretching transformation original factor graph node stretched node representing redundant removed 
single variable stretched factor graph variable nodes represent distinct variables modified variables result stretching transformation distinct 
permit variable stretched may longer hold true 
example markov chain factor graph fig 
stretched variables result factor graph vertices representing pair 
meaning peculiar factor graph remains clear local functions global function essentially unaffected stretching transformations 
changes behavior sum product algorithm example marginalized 
permit appearance multiple variable nodes single variable arise result series stretching transformations 
fig 
illustrates important motivation introducing stretching transformation may possible edge variable node redundant 
local function edge incident set variables original factor graph associated contained union variable sets associated edges incident redundant 
redundant edge deleted factor graph 
redundant edges removed time possible edge redundant presence redundant edge relevant edge removed 
edges incident variable node removed variable node redundant deleted 
example node containing redundant fig 
local function neighboring neighbor stretched 
node edges incident removed shown fig 

note removing variable graph just node representing distinction nodes variables important 
variable node involved cycle nontrivial path 
fy fg ff xg edges variable node function node stretch variable nodes involved edge fx fg redundant deleted incident 
redundant edge corresponding traveling opposite direction 
way cycle broken 
systematically stretching variables cycles deleting resulting redundant edge break cycle possible stretching transformation break cycles graph transforming arbitrary factor graph equivalent cycle free factor graph sum product algorithm produces exact marginals 
done increasing complexity local functions comes expense increase complexity variable alphabets 
subsection method coping cycles factor graph forming spanning tree graph 
spanning tree essentially obtained stretching variables deleting redundant edges 
spanning trees recall spanning tree connected graph connected cycle free subgraph having vertex set general tree spanning trees obtained deleting edges 
component construct tree spanning component resulting spanning forest consider obvious extension 
factor graph component variable node denote set neighbors set function nodes having argument 
tree spanning tree unique path nodes particular element 
suppose stretched variable nodes involved path element resulting transformed factor graph 
theorem edge redundant edges deleted proof edge set variables associated local function incident 
variable path stretched variable nodes path particular stretched neighbor element appears neighboring variable node involving redundant 
removal affect redundant status edge edges may deleted theorem implies sum product algorithm compute marginal functions exactly spanning tree provided variable stretched variable nodes appearing path local function having argument 
intuitively marginalized region involved 
paraphrase california gallo summarize variable time 
fft important observation due aji mceliece various fast transform algorithms developed graph approach 
section translate approach aji mceliece language factor graphs 
factor graph dft kernel section example 
observed dft sequence obtained marginal function 
factor graph fig 
cycles wish carry exact marginalization form spanning tree 
possible spanning trees shown fig 

different choices spanning tree lead possibly different dft algorithms min sum algorithm applied 
cluster local functions shown fig 
essentially defining gamma gamma gammaj gamma gammaj omega discrete fourier transform kernel factor graph particular spanning tree spanning tree clustering stretching transformation 
arrive spanning tree shown fig 

variables result required stretching transformation shown 
redundant included variable nodes observe message sent left right function binary variables represented list complex quantities 
path marginalized added argument list functions 
steps function converted function clearly obtained fast fourier transform instance sum product algorithm 
factor graphs provide natural graphical description factorization global function product local functions 
factor graphs applied wide range application areas illustrated large number examples 
major aim demonstrate single algorithm algorithm operating factor graph single conceptually simple computational rule encompass enormous variety practical algorithms 
seen include forward backward algorithm viterbi algorithm pearl belief propagation algorithm iterative turbo decoding algorithm kalman filter certain fast fourier transform algorithms 
various extensions algorithms example kalman filter forward backward propagation operating tree structured signal model treated derived straightforward manner applying principles enunciated 
defined sum product algorithm terms basic function operations function product function summary 
function product defined general terms involving arbitrary semigroup unity 
likewise summary operation defined general terms operator converts projection function subset coordinates domain function 
important contribution clear set axioms summary operator possess 
flexibility obtained defining concepts general terms reason broad applicability sum product algorithm 
emphasized sum product algorithm applied arbitrary factor graphs cycle free 
cycle free case shown algorithm compute function summaries exactly factor graph finite 
applications processing markov chains hidden markov models underlying factor graph naturally cycle free applications decoding low density parity check codes turbo codes 
case successful strategy simply apply sum product algorithm regard cycles 
cases important obtain equivalent cycle free representation number graph transformations achieve representations 
major motivation writing pedagogical feel topics taught unified manner framework 
learning apply single simple computational procedure student immediately access wide variety algorithms different application areas 
factor graphs afford great flexibility modeling systems 
willems behavioral approach systems traditional input output approach fit naturally factor graph framework 
generality allowing arbitrary functions just probability distributions represented enhances flexibility factor graphs 
factor graphs potential unify modeling signal processing tasks treated separately current systems 
communication systems example channel modeling estimation separation multiple users decoding treated unified way single graphical model represents interactions various elements 
feel full potential approach realized suggest exploration modeling power factor graphs applications sum product algorithm fruitful 
proof theorem assume factors fe xe collection subsets index set fe xe non negative real valued function corresponding factor graph 
show satisfies local markov property 
denote set neighbors adopting index subset view factor graph consider arbitrary fixed node ae set neighbors subset nodes neighbors fe argument 
write jx fx fe xe fe xe fe xe fe xe fe xe fe xe jn equality shown follows 
index set variables observe fe variable argument 
jn fe xe fe xe fe xe fe xe fe xe fe xe alternatively argue follows 
observe variables xe form clique fe xe taken gibbs potential function clique 
assigning unit potential function cliques correspond obtain collection gibbs potential functions cliques known see collection non negative gibbs potential functions linearly proportional probability distribution satisfies local markov property defines markov random field 
complexity sum product algorithm finite tree complexity sum product algorithm difficult analyze general depending implementation dependent details manner local functions represented mapping messages functions back available storage complexity multiplying elements evaluating summary way measure complexity simply count messages case complexity sum product algorithm jej tree jej edges 
account general highly variable complexity needed compute values messages 
section give simplistic complexity analysis sum product algorithm operating finite tree 
assume variable alphabets finite denoting size alphabet ja assume local function xe represented table jf ja values function evaluation performed table lookup 
furthermore assume messages passed sum product algorithm describe corresponding function ordered list function values 
assume summary operator defined terms binary addition operation semiring delta 
assume capability store partial results node partial results involved computation particular message 
node denote oe number additions multiplications local function evaluations table lookups required generate messages needed course operation sum product algorithm 
variable node message sent neighbor simply component wise product messages received edges 
particular additions local function evaluations need performed oe outgoing message gamma incoming messages length ja multiplied gamma multiplies component ja gamma multiplies total 
needs done variable node outgoing message equal incoming message 
course operation sum product algorithm operation done neighbor assume storage partial results number multiplies performed compute messages sent ja gamma iverson convention described section express condition degree marginal function computed multiplying messages sent received edge done ja multiplies total number multiplies ja gamma ja gamma ja delta function node fe perform multiplications additions local function evaluations 
message compute table values representing product xe xe fe computed jf xe multiplies jf xe local function evaluations 
messages received leaf variable nodes trivial actual number computations may value 
done neighbor fe jf ja fe fe jf fe ja summarize multiple function values particular value take requires jf ja gamma additions component jf gamma ja additions total 
repeated neighbor get oe fe jf gamma ja fe ja gamma ja fe ja addition operations total 
define alphabet complexity ff node ja ja fe number multiplications performed scales gamma ff delta function node oe ff code specific simplifications particular decoding applications generic updating rules substantially simplified 
treat important case variables binary functions single variable functions parity checks fig 
fig 

includes particular low density parity check codes previous subsection 
give corresponding simplifications sum product min sum versions algorithm known long ago 

min sum updating min sum update rule corresponding message sent bit check inputs parity checks arbitrary constant 
update rule corresponding message sent parity check bit follows 
sake clarity assume checks bits rule minf minf due arbitrary additive constant message vector collapsed single real number gamma sign number viewed decision value corresponding bit positive negative magnitude number viewed estimate reliability decision 
bit check update rule check bit rule sign min fj jg directly stated general case arbitrary number checked bits 
factor really exclusive operation follows noting cost configuration obtained making individual decision bits setting needed 
second factor follows noting cheapest alternative different value obtained flipping reliable bit 
sum product updating sum product update rule function bit parity check fl inputs parity checks fl arbitrary nonzero scale factor 
update rule function parity check bit follows 
simplicity assume checks bits fl arbitrary nonzero scale factor fl function collapsed single real number bit check update rule far analogy min sum rules sum product rules perfect 
missing sum product analog formulation check bit update rule terms observe operation normalized difference delta gamma general case delta fl gamma fl delta delta gamma delta gamma delta desired check bit update rule terms consists transforming inputs normalized differences delta applying transforming delta back application log likelihood ratios update rules sum product algorithm take particularly interesting form written terms log likelihoods log log logarithms natural base bit check updating rule min sum algorithm 
normalized difference expressed delta gamma gamma gamma gamma tanh check bit update rule tanh gamma tanh note may viewed approximation 
acknowledgments concept factor graphs generalization tanner graphs devised group isit ulm included authors forney jr mackay mceliece tanner wiberg 
benefitted greatly discussions topic took place ulm 
wish forney jr helpful comments earlier versions 
kschischang took place sabbatical leave massachusetts institute technology supported part office naval research 
army research laboratory cooperative agreement daal 
hospitality prof wornell mit gratefully acknowledged 
frey beckman fellow beckman institute advanced science technology university illinois urbana champaign supported arnold beckman foundation 
aji mceliece general algorithm distributing information graph proc 
ieee int 
symp 
inform 
theory ulm germany july 
aji mceliece generalized distributive law preprint available line www systems caltech edu ee faculty 
anderson moore optimal filtering 
englewood cliffs prentice hall 
bahl cocke jelinek raviv optimal decoding linear codes minimizing symbol error rate ieee trans 
inform 
theory vol 
pp 
mar 
baum petrie statistical inference probabilistic functions finite state markov chains annals mathematical statistics vol 
pp 

benedetto iterative decoding serially concatenated convolutional codes electr 
lett vol 
pp 
june 
berrou glavieux near shannon limit error correcting coding decoding turbo codes proc 
icc pp 
geneva may 
dynamic programming 
new york academic press 
dayan hinton neal zemel helmholtz machine neural computation vol 
pp 

forney jr iterative decoding way algorithm proc 
int 
symp 
turbo codes related topics france sept 
frey graphical models machine learning digital communication 
cambridge ma mit press 
frey dayan hinton simple algorithm discovers efficient perceptual codes computational psychophysical mechanisms visual coding jenkin harris eds 
new york ny cambridge university press pp 

frey hinton variational learning non linear gaussian belief networks appear neural computation 
gallager low density parity check codes 
cambridge ma press 
graham knuth patashnik concrete mathematics 
new york ny addison wesley 
hagenauer offer iterative decoding binary block convolutional codes ieee trans 
inform 
theory vol 
pp 
march 
hinton dayan frey neal wake sleep algorithm unsupervised neural networks science vol 
pp 

hinton sejnowski learning relearning boltzmann machines parallel distributed processing explorations microstructure cognition rumelhart mcclelland eds vol 
pp 
cambridge ma mit press 
spatial point processes markov random fields int :10.1.1.73.8252
stat 
rev vol 
pp 

jensen bayesian networks 
new york springer verlag 
kindermann snell markov random fields applications 
providence rhode island american mathematical society 
kschischang frey iterative decoding compound codes probability propagation graphical models ieee selected areas commun vol :10.1.1.73.8252

lauritzen jensen local computation valuations commutative semigroup annals math 
artificial intelligence vol 
pp 

lauritzen spiegelhalter local computations probabilities graphical structures application expert systems journal royal statistical society series vol 
pp 

mackay neal codes sparse matrices cryptography coding 
th ima conference boyd ed lecture notes computer science pp 
berlin germany springer 
mackay error correcting codes sparse matrices submitted ieee transactions information theory 
massey threshold decoding 
cambridge ma mit press 
mceliece trellis linear block codes ieee transactions information theory vol 
pp 
july 
mceliece private communication 
mceliece mackay 
cheng turbo decoding instance pearl belief propagation algorithm ieee selected areas commun vol 

pearl probabilistic reasoning intelligent systems nd ed 
san francisco morgan kaufmann 
preston gibbs states countable sets 
cambridge university press 
rabiner tutorial hidden markov models selected applications speech recognition proceedings ieee vol 
pp 

rumelhart hinton williams learning representations back propagating errors nature vol 
pp 

tanner recursive approach low complexity codes ieee trans 
inform 
theory vol 
pp 
sept 
vardy trellis structure codes appear chapter handbook coding theory huffman eds 
amsterdam elsevier science publishers 
poor dynamic programming models commutativity conditions siam control optimization vol 
pp 
july 
wiberg codes decoding general graphs 
phd thesis linkoping university sweden 
wiberg 
loeliger codes iterative decoding general graphs europ 
trans 
vol 
pp 
sept oct 
willems models dynamics dynamics reported volume walther eds 
new york john wiley sons pp 

