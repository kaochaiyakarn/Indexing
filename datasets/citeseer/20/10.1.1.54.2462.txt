proceedings workshop architectures real time applications april 
accurate instruction cache analysis technique real time systems sung soo lim sang min lee chang yun park shin chong sang kim accurate reliable estimation task worst case execution time wcet crucial scheduling real time tasks 
instruction caches extensively computer systems today impose serious problem analyzing tasks 
problem stems fact cache hit instruction known worst case execution path worst case execution path hand located cache hit instruction known 
cyclic dependency cases leads pessimistic estimation 
proposes analysis technique immune cyclic dependency accurately predicts tasks presence instruction caches 
key proposed technique extension timing schema timing variation due instruction caches accurately accounted 
gives extension proposed technique allows accurate analysis timing variation due data caches 
advances vlsi technology drastically reduced processor cycle times 
dram technology cycle time improvement slow density growth tremendous 
cache memories extensively bridge resultant speed gap high speed processors relatively slow main memory 
cache memories widely hard real time systems guaranteed worst case performance far important average case performance difficulty accurately analyzing timing behavior 
difficulty stems history sensitive nature 
general cache hit memory known worst case execution path worst case execution path hand located cache hit memory known 
describe accurate analysis technique instruction caches 
proposed technique extension timing schema 
proposed technique maintain set instruction hits misses affected preceding statements cache contents affects hits misses instruction succeeding supported part add contract add 
dept computer engineering seoul national university san dong gu seoul korea 
dept computer engineering chung ang university dong gu seoul korea 
statements 
information allows rewrite timing schema reason timing variation resulting history sensitive nature instruction caches 
organized follows 
section survey related 
section discusses proposed analysis technique detail 
section describes extensions proposed technique 
give concluding remarks section 
related caches small buffer memories speeding memory access 
maintain parts main memory expected accessed cpu near 
caches efficient means bridging speed gap high speed processors relatively slow main memory 
designers hard real time systems wary caches systems due unavailability technique accurately analyzing worst case timing behavior 
difficulty accurately analyzing timing behavior caches results mainly sources inter task interference intra task interference 
inter task interference caused task preemption 
task cache blocks displaced newly scheduled task tasks scheduled 
task resumes execution previously displaced blocks experiences burst cache misses 
type cache misses avoided real time systems preemptive scheduling tasks results wide variation task execution times 
variation task execution times eliminated partitioning cache dedicating partitions real time task 
cache partitioning approach eliminates cache unpredictability caused task switches 
suffers cache unpredictability caused intra task interference explained 
intra task interference caches occurs memory block task competes memory block task cache block 
interference results types cache misses capacity misses conflict misses 
capacity misses due finite cache size 
conflict misses hand caused limited set associativity 
types cache misses avoided cache limited size set associativity 
attempts predict tasks 
addressed issues resulting intra interference caches 
notable exception static cache simulation approach statically predicts hits misses instruction data flow analysis 
approach instructions classified categories ffl hit instruction cache 
ffl instruction cache 
ffl instruction misses cache 
subsequent hit cache 
block minimum unit information cache main memory hierarchy 

sample program fragment ffl conflict instruction may may cache 
approach simple number limitations 
limitation analysis conservative 
example consider program fragment 
assume memory blocks mapped cache block memory blocks mapped cache block 
actual execution theta theta gamma cache hits cache misses 
classified conflict theta treated cache misses approach 
limitation approach approach addressed issues locating worst case execution path calculating worst case execution time critical scheduling tasks real time systems 
technique section extension timing schema 
timing schema set formula computing time bounds programming constructs 
example time bound exp computed equations exp exp exp time bounds exp respectively time bounds transfer control respectively 
operation time bounds defined min max instruction cache effects due history sensitive nature instruction caches execution time statement differ depending execution path taken prior statement 
original timing schema difficult accurately account timing variation atomic object timing schema simple time bound 
example consider statement accesses contents cache hit cache block block cache hit hit sample instruction block statement struct timing information block address block block address block time execution structure atomic object instruction blocks sequence cf 

assume instruction cache blocks direct mapped 
direct mapped cache instruction block placed exactly cache block index instruction block number modulo number blocks cache 
example second hit cache bring instruction block cache cache block replaced 
hand cache previously cache prior statement replace cached block 
contrary hits misses guaranteed hit depend cache contents immediately executing statement 
similarly hit depend previous cache contents 
hits misses affect worst case execution time statement 
timing variation represented simple time bound 
furthermore cache contents statement turn affect execution time succeeding statements 
rectify problem resulting timing variation proposed technique extended original timing schema 
extended timing schema associated statement set atomic objects abstracts execution path statement 
note atomic object associated statement corresponding multiple alternative execution paths statement 
atomic object consists sets instruction block addresses execution time estimate 
gives data structure atomic objects block denotes number blocks cache 
data structure set block maintains instruction block addresses hits misses depend cache contents statement 
words set maintains regard sequence instruction instruction block single instruction block loss accuracy analysis 
cycles execution contents atomic object corresponding example cache block instruction block address cache block 
second set block maintains addresses instruction blocks remain cache execution statement 
words set maintains cache block instruction block address cache block 
cache contents determine hits misses instruction block succeeding statements 
execution time estimate execution estimated time needed execute statement 
estimate correctly accounted guaranteed hits misses second previous example 
instruction block hits misses known set conservatively assumed cache initial estimate 
initial estimate refined hits misses known stage analysis 
shows information maintained extended timing schema statement previous example 
choice atomic objects allows rewrite timing schema accurately analyze timing behavior instruction caches 
extension timing schema exp exp phi exp exp exp phi exp exp exp sets atomic objects associated exp respectively set union operation 
operation phi concatenates atomic objects effectively concatenating execution paths 
semantics procedurally defined example consider example 
assume exp statement access instruction blocks respectively 
assume initial execution time estimates exp cycles respectively cache service takes cycles 
example noted execution time estimates refined hits misses instruction block sets determined cache contents left exp remember struct timing information concatenate struct timing information struct timing information struct timing information int null null execution execution execution penalty return semantics phi operation cycles cycles cycles cycles cycles cycles execution execution execution execution execution execution example application timing schema corresponding statement struct timing information prune struct timing information struct timing information int execution execution penalty return execution execution penalty return return null semantics pruning operation hits misses previously unknown assumed cache initial execution time estimate 
proposed technique application extended timing schema check see resulting set atomic objects pruned 
atomic object set safely removed pruned set affecting accuracy worst case timing analysis worst case execution time execution path corresponding atomic object shorter worst case execution time execution path corresponding atomic object set regardless surrounding statements 
example consider resultant atomic objects correspond execution paths statement 
contents atomic objects execution time estimates noticed point maintaining atomic object corresponding path execution path takes longer path regardless preceding succeeding statements know path part worst case execution path program 
condition pruning procedurally specified 
function prune checks execution paths corresponding input atomic objects pruned returns pruned atomic object pruning successful null pruned 
timing schema phi function calls handled similar way 
pruning performed time new set atomic objects derived 
timing schema loop statement exp exp operation sets atomic objects defined fc phi jc loop bound provided external means user input 
timing schema effectively enumerates possible execution sequences occur loop execution 
approach exact computationally intractable 
efficient wcet analysis loop possible making simplifying assumptions 

cache contents invalid entry loop 

loop leaves invalid cache contents 

loop iteration benefits instruction blocks loaded cache immediately preceding loop iteration 
framework problem calculating wcet loop formulated follows input weighted directed graph distinguished vertex find longest weighted path necessarily simple containing exactly arcs consists set nodes corresponding set paths loop special node weights ij execution gamma fv ij execution gamma execution execution gamma phi execution gamma fv words execution time path cache contents execution invalid ij execution time path execution immediately preceded execution path problem easily solved dynamic programming technique 
define maximum weight path necessarily simple containing exactly arcs gamma path exists 
definition gamma write simple formula max fd gamma ji computation method takes effort 
large efficient algorithm possible maximum minimum cycle mean algorithm karp 
weight resulting longest path length max fdn corresponds wcet loop iteration count previous assumptions hold 
cases assumptions hold 
assumptions conservative resulting worst case execution time estimate correct sense underestimate wcet 
degradation accuracy resulting conservative assumptions reduced considering paths time just path 
case node denotes execution sequence paths ij execution time sequence execution immediately preceded execution sequence analysis corresponds analysis loop unrolled times trades increased analysis complexity improved accuracy wcet estimation 
extensions set associative caches considered simplest cache organization called direct mapped cache organization instruction block placed exactly cache block 
general cache organization called way set associative cache organization instruction block placed blocks mapped set cache organization needs policy decides block replace blocks set room block fetched cache lru random policies typically purpose 
replacement policy easy matter implement phi prune operations needed analysis contents set associative cache replacement policy sequence instruction block hit instruction block sequence analyzed case direct mapped caches 
data caches case instruction caches cache hit data known worst case execution path worst case execution path located cache hit data known 
cyclic dependency wcet analysis data caches handled way similar instruction caches 
exception instruction actual addresses data known compile time 
difficult analyze timing variation due data caches longer accurately calculate needed analysis 
added difficulty avoided completely providing simple hardware support form bit load store instruction 
bit called allocate bit decides memory block fetched loaded cache 
data address determined statically bit set zero prevents memory block fetched loaded cache 
bit set allowing fetched block loaded cache 
hardware support analysis data caches identical instruction caches treating addresses known compile time misses completely ignoring calculation 
case hardware support available wcet analysis data caches possible consequential loss accuracy 
set associative cache index mapped set instruction block number modulo number sets cache 
described technique accurately estimates tasks presence instruction caches 
proposed technique set instruction block hits misses affected preceding statements cache contents affects hits misses instruction block succeeding statements maintained application timing schema 
state information allows reason timing variation resulting history sensitive nature instruction caches 
described optimization aims reducing space overhead proposed technique pruning early possible atomic objects corresponding execution paths part worst case execution path 
proposed technique lends straightforward extension data caches allowing unified wcet analysis takes account combined effects instruction data caches pipelining 
bae 
data cache analysis techniques real time systems 
master thesis preparation 
harmon baker whalley 
retargetable technique predicting execution time 
proceedings th real time systems symposium pages 
hennessy patterson 
computer architecture quantitative approach page 
morgan kaufmann publishers san mateo ca 
hill 
aspects cache memory instruction buffer performance 
phd thesis university california berkeley nov 
karp 
characterization minimum cycle mean digraph 
discrete mathematics 
kirk 
process dependent static cache partitioning real time systems 
proceedings th real time systems symposium pages 
kirk 
smart strategic memory allocation real time cache design 
proceedings th real time systems symposium pages 
kirk 
smart strategic memory allocation real time cache design mips 
proceedings th real time systems symposium pages 

lee 
lim min park shin kim 
issues advanced architectural features design timing tool 
submitted th ieee workshop real time operating systems software 

lim 
instruction cache pipelining analysis techniques real time systems 
master thesis preparation 

lim 
lee min park shin kim 
accurate analysis pipelined processors extended timing schema 
working 
mok 
evaluating tight execution time bounds programs annotations 
proceedings th ieee workshop real time operating systems software pages 
mueller whalley harmon 
predicting instruction cache behavior 
unpublished technical report 
park shaw 
experiments program timing tool source level timing schema 
proceedings th real time systems symposium pages 
koza 
calculating maximum execution time real time programs 
journal real time systems sept 
shaw 
reasoning time higher level language software 
ieee transactions software engineering july 
smith 
sequential program prefetching memory hierarchies 
ieee computer pages dec 

real time language schedulability analyzer 
phd thesis university toronto dec 
zhang burns nicholson 
pipelined processors worst case execution times 
journal real time systems oct 
