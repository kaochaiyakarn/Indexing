skill reconstruction induction lq controllers subgoals suc faculty computer information sciences university ljubljana ljubljana slovenia suc fri uni lj si ivan bratko faculty computer information sciences university ljubljana ljubljana slovenia ivan bratko fri uni lj si controlling complex dynamic system plane crane usually requires skilled operator 
control skill typically hard reconstruct introspection 
attractive approach reconstruction control skill involves machine learning operators control traces known behavioural cloning 
common approach behavioural cloning controller induced form rule set decision regression tree maps system states actions 
unfortunately induced controllers usually suffer lack robustness lack typical elements human control strategies subgoals control plan 
new approach behavioural cloning involves induction model controlled system enables identification subgoals operator pursuing various stages execution trace 
underlying formal basis approach behavioural cloning theory lq controllers 
experimental results show approach greatly improves robustness induced controllers offers new way understanding operator skill 
controllers designed machine learning different kinds information available learning system 
approaches reinforcement learning genetic algorithms neural networks typically don prior knowledge system controlled 
humans rarely attempt learn scratch 
extract initial biases strategies prior knowledge system demonstration experienced operators 
control theory doesn consider operator skill 
hand idea behavioural cloning term introduced donald michie michie operator skill development automatic controller 
skilled operator control traces examples machine learning reconstruct underlying control strategy operator executes 
goal behavioural cloning induce successful controller achieve better understanding human operator subconscious skill bratko behavioural cloning successfully problem domains pole balancing production line scheduling piloting sammut operating 
experiments reviewed bratko controllers usually induced form decision regression trees 
successful clones induced form trees rule sets problems generally observed approach ffl typically induced clones brittle respect small changes control task 
ffl clone induction process typically low yield proportion successful controllers induced clones low typically 
ffl resulting clones purely reactive inadequately structured conceptualisations human skill 
lack typical elements human control strategies goals subgoals phases causality 
propose different approach behavioural cloning exploits results control theory 
particular clones take form lq controllers 
approach involves induction approximate models controlled systems 
experimentally demonstrated approach dramatically improves clones robustness respect changes control task yield cloning process 
approach provides way interpreting induced clones terms operator goals subgoals 
reconstruction human operator skill exploits elements theory linear quadratic regulator problems bertsekas dynamics system example behavioural trace considered learning process 
system dynamics learned locally weighted regression 
linear quadratic regulator performs similar operator constructed controller goal directed takes account system dynamics performance robustness achieved 
parameters induced controllers give insight human control skill 
provides interesting possibility studying human control skill apart system dynamics 
bradtke bradtke explored idea lqr case combination reinforcement learning method 
pay attention interpretation optimal policy function terms underlying operator control skill 
structure follows 
section reviews basics lqr theory needed section describes methods construct controllers behavioural traces 
section ideas extended subgoal identification complex control tasks 
section gives experimental results 
linear quadratic regulation systems possible reach desired state step 
systems initially move away desired state order approach 
linear quadratic regulation facilitates policies minimization long term cost function 
system state vector action vector des desired goal state 
lq cost defined inf gamma des gamma des gamma gamma positive definite matrix positive semi definite matrix user defined lowest cost action 
elements matrices set tradeoff cost action components error components 
example set identity matrices sum squared deviations desired performance penalized 
usually human supervisor specifies relative importance state action components suitable adjustments alternative explicit human specification importance various state action components automatic induction matrices operator behavioural traces described section 
consider linear discrete time multivariable dynamic system ax bu state transition function specified matrices vector control task achieve maintain setpoint des satisfies condition des des discrete time step controller observes system state performs action pair incurs cost controller objective select actions drive system des minimum cumulative cost 
heuristic search dynamic programming tackle problems kind assigning numerical value state 
natural measure state value expected sum costs controller starts state executes optimal policy 
function usually called value function cost go function 
cost go function state transition function optimal action particular state easily opt arg min cost go function minimal possible sum costs starting state defined inductively min linear quadratic regulation assumes immediate cost penalizing mahalanobis distance desired performance states actions gamma des gamma des gamma gamma case linear system dynamics assumption system run forever lq quadratic bertsekas expressed lq gamma des gamma des cost matrix associated immediate cost matrices known unique positive definite solution equation initialising running iteration convergence br gamma gamma optimal control theory gives optimal action minimizes cost go function simple gain matrix gamma gamma des pb gamma pa linear system dynamics assumed 
empirical results show robustness lq controllers actual system non linear approximated linear model 
approximating operator value function behavioural cloning lqr framework relies observations 
approximate model controlled system form linear state transition function induced locally weighted regression schaal atkeson available execution traces 

generally cost matrices execution cost defined lq cost function system linear formulas control theory compute state value function corresponding optimal actions 

assume operator actions available execution traces intended optimise lq cost 
case behavioral cloning solve inverse optimal control problem actions find matrices actions approximately optimal 

operator may executing elaborate plan pursues different subgoals different stages execution trace 
cases trace broken stages subgoals reflected different matrices 
develop details idea 
continous trace sampled sequence pairs 
ordered time 
goal state des known advance 
state transition function estimated locally weighted regression 
assuming linear dynamics system compute lq cost go function lq des gamma des gamma des computed solution equation explained 
define lq optimal action action minimizes lq cost particular opt arg min gamma gamma gamma lq delta assuming actions observed trace assuming know matrices compute operator cost go function state gamma 
des gamma des gamma des gamma gamma interested finding matrices produce lq cost go function actions observed trace way closest lq optimal actions 
matrices local optimization minimizing lq fit error des des gamma lq des lq des finding squares fit operator cost go function lq controller cost go function 
corresponding lq controller constructed 
matrices explain operator performing task 
local optimization optimizes matrices number optimization parameters grows square number state variables control variables 
simplification assume diagonal 
case number optimization parameters grows linearly number variables 
reduces complexity local optimization problem improves comprehensibility induced controller 
learning subgoals complex control tasks flying plane example operator policy usually changes time 
achieve final goal operator achieve subgoals 
subgoals define stages policy 
stage ends subgoal reached 
possible approach break execution trace stages hand learn controller stage separately 
possible define stages hand 
operator learns skills practice 
rules underlying skills typically opaque operator able describe completely 
obvious alternative induce subgoals execution trace construct controller stage 
define subgoal point state space approached operator operator policy changes sense lq cost 
accordingly define subgoal candidate xg time step point state space coordinates computed mean states 
change policy detected minimization weighted lq fit error subgoal candidate xg gamma xg execution trace searched subgoal xg minimizes weighted lq fit error 
subgoal xg execution trace divided stages subgoal reached subgoal reached 
stages recursively searched subgoals 
done error divided stage greater error stage 
stage lq controller computed 
controller subgoal approached controller activated 
experimental results container crane section describe experiments lqr cloning domain container bratko systems nonlinear dynamics 
transport container shore target position operations performed positioning trolley bringing target load position rope operation bringing load desired height 
performance requirements include basic safety gap accuracy high capacity possible 
requirement means time transportation minimized 
difficult aspect task control swing rope 
load close goal position swing ideally zero 
crane simulator experiments 
state system specified variables trolley position velocity rope inclination angle phi angular velocity phi rope length velocity control forces applied system force xf trolley horizontal direction force yf direction rope 
experimental data manually controlling crane previous study bratko study students volunteered learn control simulator 
succeeded accomplish task 
remarkable individual differences observed regarding speed controlling characteristics strategy 
operators tended fast reliable operation conservative slower order avoid large rope oscillations 
goal cloning reconstruct individual differences operators style driving crane 
previous experiments domain involve behavioural cloning regression trees combining skills operators 
main problem regression trees swing control large rope oscillations trolley approached goal position 
experimental details complete task successfully operator reach goal position trace sampled frequency hz 
successful trace typically lasts approximately trace gives state action pairs 
local optimization powell method discarding direction largest decrease 
matrices restricted diagonal 
state dimensional action dimensional vector parameters approximated local optimization 
took sec 
pentium hz find matrices construct corresponding controller 
learning subgoals set 
minimize time needed find best subgoal subgoal candidate tested time steps 
took minutes find best candidates 
learn linear model locally weighted regression mean point stage 
learn model operators execution traces trace approximate value function traces operator typically trace operator 
particular reason choice traces feel choices produce similar results 
experimental results experiments clones lqr showed swing control difficult regression tree clones 
controller accelerates causes huge swing rope controller usually manages stabilize rope angle seconds 
experiments done controllers matrices restricted diagonal matrices 
reason restriction simply smaller complexity local optimization 
restricted controllers easier comprehend 
controllers subgoals single lq controllers usually failed accomplish task 
observation lead lq controllers subgoals sought 
xf dx xf dx fi dfi fi dfi trace subject trace clone intuitive reason controllers subgoals 
operators usually strategy trolley far goal strategy trolley near goal position 
stage deviation horizontal speed horizontal force important second stage second stage need large horizontal speed 
behavioural trace trace subject shown left induced clone right 
clone consists lq controllers 
matrices diagonal 
subgoal minimizes weighted lq fit error subgoal second final goal 
stage controller attempts reach point near final goal 
point xg phi phi diagonals matrices stage phi phi ql 
clear deviations desired horizontal velocity angular velocity penalized 
second stage final positioning needed deviations state components respected 
seen goal induced matrices stage des phi phi qx phi phi ql 
behavioural trace trace subject shown left trace induced clone right 
induced clone consists tree stages attains considerably better time original 
phenomenon clone surpassing original cleanup effect observed 
interesting interpret differences control styles operators comparing subgoals matrices clones see strategy conservative resulting actions tends accelerate fast direction price large swing 
stage pays attention oscillations rope 
informative indicators support interpretation values goal des stage 
operator values des 
operator values des 
observation percentage successful controllers induced ones 
significant improvement previous experiments regression trees crane domain reported yield 
robustness controllers tested modifying crane parameters friction trolley trail cargo weight 
learning process parameters original simulator changed clone execution time 
testing parameters changed respect original values 
combinations parameter settings get slightly different system dynamics 
controllers accomplished original task randomly selected tested 
total controllers induced traces original system controllers performed successfully modified systems 
results show controllers robust change system dynamics 
controllers tested robustness xf dx xf dx fi dfi fi dfi trace subject trace clone changes start state test controllers form decision regression trees usually fail 
lq controllers goal directed change start state didn affect performance significantly 
starting horizontal position modified starting rope angle 
amounts combinations different tasks 
nineteen controllers tested accomplished different tasks 
results show induced controllers perform accomplish task faster original operator 
new approach behavioural cloning 
previous cloning problem usually formulated inducing straightforward mapping system states actions 
approach hand involves induction model dynamics controlled system takes account order example state action pairs 
way enables identification subgoals operator pursuing various stages execution trace 
experiments crane domain show automatic breakdown control traces stages corresponding subgoals essential inducing robust controllers 
underlying formal basis approach behavioural cloning theory lq controllers cloning problem done inverse usual problem designing optimal controller 
experimental results show approach comparison previous experiments greatly improves robustness induced controllers yield cloning process 
bertsekas bertsekas dynamic programming deterministic stochastic models prentice hall englewood cliffs bradtke bradtke reinforcement learning applied linear quadratic regulation hanson cowan giles eds advances neural information processing systems pp san mateo ca morgan kaufmann bratko bratko sammut behavioural cloning phenomena results problems automated systems human skills ifac berlin michie michie knowledge learning machine intelligence intelligent systems plenum press new york sammut sammut hurst michie learning fly proceedings ninth international workshop machine learning morgan kaufmann schaal atkeson schaal atkeson assessing quality learned local models advances neural information processing systems morgan kaufmann bratko 
bratko reconstructing human skill machine learning proceedings th european conference artificial intelligence john wiley sons 
