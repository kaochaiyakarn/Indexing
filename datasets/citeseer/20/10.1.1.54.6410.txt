language modeling approach information retrieval jay ponte bruce croft computer science department university massachusetts amherst cs umass edu models document indexing document retrieval extensively studied 
integration classes models goal researchers difficult problem 
argue reason lack adequate indexing model 
suggests better indexing model help solve problem 
feel making unwarranted parametric assumptions lead better retrieval performance 
furthermore making prior assumptions similarity documents warranted 
propose approach retrieval probabilistic language modeling 
estimate models document individually 
approach modeling non parametric integrates document indexing document retrieval single model 
advantage approach collection statistics heuristically retrieval models integral part model 
implemented model tested empirically 
approach significantly outperforms standard tf idf weighting different collections query sets 
past decades probabilistic models document retrieval studied extensively 
general approaches characterized methods estimating probability relevance documents user queries 
component probabilistic retrieval model indexing model model assignment indexing terms documents 
argue current indexing models led improved retrieval results 
believe due unwarranted assumptions models 
taken different approach non parametric estimation allows relax assumptions 
implemented approach empirical results different collections query sets significantly better standard tf idf method retrieval 
take brief look existing models document indexing 
discussion indexing models poisson model due bookstein swanson permission digital hard copy part personal classroom granted fee provided copies distributed profit commercial advantage copyright notice title publication date appear notice copying permission acm copy republish post servers redistribute lists requires prior specific permission fee 
sigir melbourne australia fl acm 
harter 
analogy manual indexing task assign subset words contained document specialty words indexing terms 
probability model intended indicate useful indexing terms means differences rate occurrence documents elite term document satisfy user posing single term query vs property 
success poisson model somewhat limited noted robertson tf quite successful intended behave similarly poisson model 
researchers proposed mixture model poisson distributions order better fit observed data 
margulis proposed poisson model tested idea empirically 
study mixture poisson distributions provides close fit data 
certain sense surprising 
large values fit complex distribution arbitrarily closely mixture parametric models data estimate parameters 
somewhat surprising closeness fit relatively small values reported margulis 
poisson model brought increased retrieval effectiveness spite close fit data 
event semantics underlying distributions obvious poisson case compared poisson case model concept 
apart adequacy available indexing models estimating parameters models difficult problem 
researchers looked problem variety perspectives discuss approaches section 
addition previously mentioned current indexing models assumptions data feel unwarranted 
ffl parametric assumption 
ffl documents members pre defined classes 
approach relax assumptions 
making parametric assumptions done poisson model assumed terms follow mixture poisson distributions silverman said data allowed speak 
feel unnecessary construct parametric model data actual data 
rely non parametric methods 
regarding second assumption poisson model originally idea 
assumed document elite term satisfy user user posed single term query 
time prevailing view come multiple term queries realistic 
general requires combinatorial explosion elite sets possible subsets terms collection 
take view query needs looked individually documents necessarily fall cleanly elite non elite sets 
order relax assumptions avoid difficulties imposed separate indexing retrieval models developed approach retrieval probabilistic language modeling 
approach provides conceptually simple explanatory model retrieval 
time clear mean word model 
view word model information retrieval senses 
sense denotes abstraction retrieval task 
best example vector space model allows talk task retrieval apart implementation details storage media data structures 
second sense word model probabilistic sense refers explanatory model data 
intention poisson model 
add third sense word refer language modeling 
phrase language model speech recognition community refer probability distribution captures statistical regularities generation language 
context retrieval task treat generation queries random process 
generally speaking language models speech attempt predict probability word ordered sequence 
purposes document retrieval model occurrences document level regard sequential effects approach taken 
possible model local predictive effects features phrases left 
regarding query generation random process case queries really generated randomly case retrieval systems endowed knowledge generation process 
treat language generation random process modeled probability distribution focus estimation probabilities means achieving effective retrieval 
approach retrieval infer language model document estimate probability generating query models 
rank documents probabilities 
means data model discriminant function retrieval 
intuition approach view users reasonable idea terms occur documents interest choose query terms distinguish documents collection intuition discussed detail section 
focusing query generation probability opposed probability relevance model require set inferences indexing separate set inferences retrieval 
retrieval systems term frequency document frequency document length statistics 
typically compute tf idf score document length normalization 
example inquery ranking formula shown section 
approach collection statistics term frequency document length document frequency integral parts language model heuristically approaches 
reason standard tf idf scores 
addition length normalization implicit calculation probabilities done ad hoc manner 
remainder organized follows 
section review existing retrieval models 
section describes language modeling approach closely parallels standard approach ir 
section shows effectiveness model empirically 
offer concluding remarks describe directions 
previous mentioned previously 
standard probabilistic indexing model poisson model 
assumptions model subset terms occurring document useful indexing 
harter words identified distribution assigned indexing terms 
documents assumed approximately equal length reasonable assumption data initial studies 
model somewhat similar views probability term assignment analogous term generation probability 
main differences distributional assumptions distinguish subset specialty words assume preexisting classification documents elite non elite sets 
known probabilistic approaches retrieval robertson sparck jones model croft harper model 
models estimate probability relevance document query 
approach differs focus relevance extent process query production correlated 
additional probabilistic model fuhr 
notable feature fuhr model integration indexing retrieval models 
main difference approach fuhr model collection statistics heuristic fashion order estimate probabilities assigning concepts documents 
approach able avoid heuristic methods inferring concepts terms 
probabilistic approach inquery inference network model turtle croft 
similar fuhr model turtle croft integrate indexing retrieval making inferences concepts features 
features include words phrases complex structured features 
evidence multiple feature sets multiple queries combined means bayesian network order infer probability information need user met 
distinction information need query notable feature model 
previously noted approach shifted emphasis probability relevance probability query production 
assume correlated currently attempt model correlation explicitly 
discuss point section 
section discuss probability estimation procedure 
statistic average probability term occurrence 
similar statistic kwok different purpose 
kwok unnormalized average tf estimate importance term respect query 
approach average tf normalized document length estimation generation probability 
wong yao proposed model represented documents probability distribution 
developed separate approaches retrieval utility theory information theory 
regarding probability distribution wong yao maximum likelihood estimator term probabilities 
approach robust estimator 
wong yao utility information theoretic retrieval models somewhat analogous approaches retrieval indexing model apart retrieval model 
terms associated documents maximum likelihood probability estimate discriminant utility theoretic information theoretic function estimate 
approach able avoid extra complexity perform retrieval single probabilistic model 
similar approach taken 
model documents assumed generated stochastic process multinomial model 
task investigated text classification 
document treated sample language model representing class document 
model tf document length integral parts model heuristics models 
discriminant function taken maximum likelihood estimator query document language model 
note query case inferred training set context classification task 
approach conceptually somewhat different clearly related approach shares desirable property collection statistics integral parts model 
initial study deliberately distributional assumptions 
major difference approach rely maximum likelihood estimator robust estimator 
assume documents necessarily drawn language models representing classes interest 
weaker assumption get estimates document language model individually making inferences class membership documents 
models compute query generation probability 
describe development approach 
model description mentioned infer language model document rank estimate producing query model 
estimate probability query language model document maximum likelihood estimate probability term term distribution document pml tf dld tf raw term frequency term document dld total number tokens document assume particular language model query terms occur independently 
gives rise ranking formula pml document 
problems estimator 
obvious practical problem wish assign probability zero document missing query terms 
addition practical consideration probabilistic perspective somewhat radical assumption infer 
fact seen impossible 
assumption non occurring term possible expected chance collection 
cf cs cf raw count term collection cs raw collection size total number tokens collection 
provides reasonable distribution circumvents practical problem 
noted homogeneous databases may need careful estimate collection probability cases absence frequently occurring word word characteristics stopword conceivably contribute score document occur 
problem collections studied heterogeneous nature stopwords removed plan address issue sure approach immune pathological cases 
problem estimator may obvious 
get arbitrary sized sample data md reasonably confident maximum likelihood estimator 
document sized sample distribution 
circumvent problem going need estimate larger amount data 
estimate pml df df document frequency words mean probability documents containing 
robust statistic sense lot data estimate problem 
assuming document containing drawn language model risk mean estimate furthermore mean distinction documents different term frequencies 
order benefit robustness estimator minimize risk model risk term document geometric distribution follows theta tf mean term frequency term documents occurs theta dld way say term count get term occurred average rate 
intuition formula tf gets away normalized mean mean probability estimate 
somewhat related geometric distribution see 
risk function mixing parameter calculation estimate probability producing query document model follows ae pml gamma theta tf cf cs theta gamma formula term probability producing terms query second term probability producing terms 
notice risk function background probability cf cs mentioned earlier 
compute function candidate document rank accordingly 
describe empirical results 
empirical results data performed recall precision experiments data sets 
set trec topics trec disks trec ad hoc task second trec topics trec disk concept fields 
chose query sets quite different 
concept fields essentially lists terms topics natural language queries consisting sentence 
implementation implemented research prototype retrieval engine known test approach 
engine originally implemented high throughput retrieval system context previous topic segmentation 
experiments system tokenization stopping stemming usual way 
implemented standard tf idf weighting language modeling approach 
recall precision experiments table shows results trec topics trec disks 
see eleven point recall precision results non interpolated average precision precision figures top documents values columns compare baseline result new approach 
baseline result obtained inquery ranking formula uses robertson tf score standard idf score defined follows tf tf len idf log log third column reports percent change 
column form count tf idf lm chg sign 
rel 

prec 












undef undef avg 

prec 

















table comparison tf idf language modeling approach trec queries trec disks 
queries performance improved new method count queries performance different 
column reports significance values sign test column likewise wilcoxon test 
entries columns marked star indicate statistically significant difference level 
note sided tests 
notice eleven point recall precision section language modeling approach achieves better precision levels recall significantly levels 
notice significant improvement recall average precision precision precision documents equal number relevant documents query 
second part improvement levels recall statistically significant 
results trec queries trec disk shown table 
see improvement precision levels recall eleven point chart see improvement precision level recall document count 
levels show significant improvement 
improving basic model try improve probability estimates model yield better retrieval performance 
simple improvement estimate developed section smooth estimates average probability terms low document frequency 
estimate average probability terms small amount data sensitive outliers 
order correct binned low frequency data document frequency binned estimate average 
cutoff df low frequency terms turned cutoff critical 
tf idf lm chg sign 
rel 

prec 







gamma undef gamma undef avg 

prec 













table comparison tf idf language modeling approach trec queries trec disk 
new estimate average incorporated ranking formula rerun trec queries trec disks results shown table 
results show statistically significant improvement precision levels recall 
average precision improved 
running new model second query set trec queries trec disk get result shown table 
see significant improvements albeit modest ones levels recall average 
conjecture smaller improvement query set due longer average query length compared query set 
appears low frequency terms effects average due outliers just overestimate underestimate effects cancel terms query 
conjecture verification leave 
novel way looking problem text retrieval probabilistic language modeling conceptually simple explanatory 
feel model provide effective retrieval improved extent conditions met 
language models accurate representations data 

users understand approach retrieval 

users sense term distribution 
feel condition met reasonably approach taken study 
feel models improved 
current language models incorporate knowledge language generation process 
lm lm chg sign 
rel gamma prec 





gamma gamma undef undef gamma undef avg 

prec 






gamma table comparison original language modeling approach new language modeling approach trec queries trec disks 
lm lm chg sign 
rel undef prec 
undef 




gamma gamma 
undef undef undef avg 

prec 
undef undef undef undef undef undef undef undef gamma table comparison original language modeling approach new language modeling approach trec queries trec disk 
possible additional knowledge added models yield better estimates 
regarding point feel model simple explained users intuitive level understanding facilitate formation better queries 
users need want know details model case users general understanding system works able effectively 
users typically instructed pose natural language descriptions information needs queries 
user understands model tend think terms words help system distinguish documents interest 
feel get users think manner able formulate queries better express information needs manner useful retrieval system 
regarding point order users identify useful words feel benefit sense words distributed collection 
case users need want know term distribution detail sense terms useful beneficial 
imagine variety textual graphical tools help users get better sense distribution terms 
especially important win expert users prefer boolean retrieval sense control search 
regarding results study performance different query sets better obtained tf idf weighting 
improvement performance main point 
significant different approach retrieval shown effective 
ability think retrieval new way lead insights obvious approaches 
course converse true viewing approach competing model view number tools investigating retrieval 
second set experiments showed simple smoothing yields results significantly better baseline query sets 
example insight gained approach obvious consequence approaches 
possible elaborate smoothing technique techniques data transformation improve results 
plan investigate matters 
need address estimate default probability 
mentioned current estimator strange cases assign higher probability query term 
happen cases commonly occuring terms terms useful feel address problem order insure robustness model cases 
approach apply smoothing estimator guarantee default probability estimate exceed lowest estimate assign document term occurs 
generative language model intuitive way think query expansion techniques relevance feedback local feedback 
intend derive techniques model attempting explain existing techniques 
acknowledgments authors warren comments aspects numerous useful comments early draft 
ron papka remarks early draft 
tom useful discussions 
material supported part national science foundation library congress department commerce cooperative agreement number eec 
material supported part united states patent trademark office defense advanced research projects agency ito arpa order number issued esc contract number 
opinions findings recommendations expressed material authors necessarily reflect sponsors 
bookstein swanson 
probabilistic models automatic indexing journal american society information science 
pp 

byrd personal communication 

croft harper 
probabilistic models document retrieval relevance information 
journal documentation pp 

fuhr models retrieval probabilistic indexing information processing management 

ghosh hwang tsui 
construction improved estimators multiparameter estimation discrete exponential families 
annals statistics 
greenwood yule 
inquiry nature frequency distribution representative multiple happenings particular occurrence multiple attacks disease repeated accidents 
journal royal statistical society 
pp 

harter probabilistic approach automatic keyword indexing journal american society information science july august 
new probabilistic model text classification retrieval ciir tech 
report 
kwok new method weighting query terms ad hoc retrieval proceedings acm sigir pp 
margulis modeling documents multiple poisson distributions 
information processing management pp 

parzen estimation probability density function mode 
annals mathematical statistics vol 

robertson walker 
simple effective approximations poisson model probabilistic weighted retrieval 
proceedings acm sigir 
pp 

ponte croft 
text segmentation topic proceedings european conference research advanced technology digital libraries 
robertson sparck jones 
relevance weighting search terms journal american society information science vol 

salton automatic text processing 
addison wesley 
silverman density estimation statistics data analysis chapman hall 
scott 
nonparametric density estimators journal american statistical association 
vol 
number 
titterington makov smith 
statistical analysis finite mixture distributions john wiley sons 
turtle croft 
efficient probabilistic inference text retrieval proceedings riao 
wong yao 
probability distribution model information retrieval information processing management pp 

yamron topic detection tracking segmentation task proceedings topic detection tracking workshop oct 

probability functions handbook mathematical functions 
abramowitz stegun ed 
national bureau standards applied mathematics series 

