comparative analysis comparative analysis scheduling policies distributed system simulation helen department informatics aristotle university thessaloniki thessaloniki greece email csd auth gr study scheduling distributed system 
simulation model address performance issues associated scheduling 
policies combine processor scheduling schedule parallel jobs variety workloads 
fairness required competing jobs 
simulated results reveal scheduling methods merit method significantly improves performance provides guarantee fairness individual job execution 
keywords simulation distributed systems scheduling performance 
scheduling jobs distributed systems heavily researched activity 
possible efficiently execute parallel jobs 
achieve critical partition program tasks properly assigning tasks processors scheduling execution distributed processor 
scheduling policies needed improve system performance preserving individual application performance jobs suffer unbounded delays 
primary intent existing research find ways distribute tasks processors order achieve performance goals minimizing job execution time minimizing communication overhead maximizing resource utilization 
cases task sequencing preserved possible achieve fairness individual job execution 
task low priority scheduling method criteria arbitrary number higher priority tasks 
research area focused scheduling processors 
conducted extensive thorough study task scheduling multiprocessor systems 
results study indicate scheduling policies substantial impact performance non adaptive routing strategies 
open queuing network model considered assumed number tasks job exponentially distributed 
kumar study parallel processing system comprising homogenous computers interconnected communication network 
jobs consist series forks joins 
fork job gives rise random number tasks processed independently computers 
sevcik uses remaining 
results study confirm value application characteristics scheduling available 
improvements processor speeds larger main memory sizes expose subsystems significant bottleneck prevents applications achieving full system utilization 
problem serious multiprocessor systems multiple processors share subsystem 
scheduling examined parallel job scheduling 
example study large scale parallel computer systems suggest overlapping demands jobs computation demands jobs offers potential improvement performance 
scheduling examined kwong majumdar seltzer worthington 
studies simulation vol 
issn online print consider processor scheduling 
study task scheduling distributed systems apply fcfs scheduling policy unit 
consider various scheduling methods apply jobs highly variable degrees parallelism 
scheduling distributed processor scheduling studied 
special processor scheduling method called gang scheduling applied job tasks highly dependent need start time execute pace 
degree parallelism jobs highly variable 
study job tasks highly independent execute time order 
different cases job parallelism examined case jobs highly variable degrees parallelism lifetime second case majority jobs exhibit moderate parallelism 
performance combined processor scheduling policies various coefficients variation processor service times different degrees multiprogramming compared 
closed queuing network model distributed system considered incorporates equipment 
goal achieve high system performance conjunction fairness job execution 
knowledge analysis combined processor scheduling appear research literature kind distributed system operating type workload 
experimental study sense results obtained simulation tests measurements real systems 
believe results practical value 
absolute performance predictions derived specific systems workloads study relative performance differing scheduling algorithms broad range workloads analyze changes workload affect performance 
simple systems performance models mathematically analyzed queuing theory provide performance measures 
system branching erlang exponential distributions compute task execution time 
fork join programs scheduling policies different complexities involved 
complex systems analytical modelling typically requires additional simpli comparative analysis fying assumptions influence results 
research efforts devoted finding approximate methods develop tractable models special cases conducting simulations 
precise analysis fork join queuing models known intractable problem 
example kumar derived upper lower bounds mean response time jobs linear fork join structure 
chose simulations possible simulate system direct manner lending credibility results 
detailed simulation models help determine performance bottlenecks architecture assist refining system configuration 
structure follows 
section specifies system workload models section describes scheduling policies section presents metrics employed assessing performance scheduling policies study 
model implementation input parameters described section results simulation experiments analyzed section 
section summarizes findings offers suggestions research 
model methodology system workload models closed queuing network model distributed system considered 
homogeneous independent processors serving queue interconnected high speed network negligible communication delays 
examine system processors 
reasonable current existing medium scale departmental networks workstations 
subsystem may consist array disks multi server disk center modeled single node mean service time consider request forks sub requests served parallel disk servers 
effects memory requirements communication latencies represented explicitly system model 
appear implicitly shape job execution time functions 
covering different types job execution behaviours expect various architectural characteristics captured 
degree multiprogramming constant simulation experiment 
fixed number simulation vol 
issn online print jobs circulating alternatively processors unit 
configuration model shown 
comparative analysis subsystem 
queuing network model interested system balanced program flow considered subsystem service capacity processors 
important part distributed system design workload shared processors subsystem 
involves partitioning arriving jobs tasks executed parallel assigning tasks processors scheduling task execution processor 
includes scheduling jobs subsystem 
jobs partitioned independent tasks run parallel 
number tasks job consists job degree parallelism 
completing execution task waits join point sibling tasks job complete execution 
synchronization tasks required 
price paid increased parallelism synchronization delay occurs tasks wait siblings finish execution 
task assigned randomly queues equal probability 
tasks processor queues executed scheduling method currently employed 
migration pre emption permitted 
technique evaluate performance scheduling disciplines experimentation synthetic workload simulation 
workload considered characterized parameters distribution number tasks job 
distribution task execution time 
distribution service time 
degree multiprogramming 
assume correlation different parameters 
example job small number tasks may longer execution time 
distribution number tasks job different types distribution number tasks job utilised uniform distribution 
assume number tasks jobs uniformly distributed range 
mean number tasks job equal 
normal distribution assume bounded normal distribution number tasks job mean equal 
chosen standard deviation 
number tasks job represented 
represents number processors required job relation holds time job returns service scheduling distributed processors partitioned different number tasks needs different number processors execute 
words degree parallelism constant lifetime system 
obvious jobs uniform distribution case larger variability degree parallelism jobs number tasks normally distributed 
second case jobs moderate degree parallelism close mean 
addition variability jobs degree parallelism impact variability task service demand system performance examined 
high variability task service demand implies proportionately high number service demands small compared mean service time comparatively low number service demands large 
task long service demand starts execution occupies processor long interval time depending scheduling policy may intro simulation vol 
issn online print duce inordinate queuing delays tasks waiting service 
service time distribution parameter represents variability task execution time coefficient variation execution time 
ratio standard deviation task execution time mean 
examine cases regard task execution time distribution task execution times independent identically distributed iid exponential random variables mean task execution times branching erlang distribution stages iid 
coefficient variation mean job leaves processors requests service unit 
service times exponentially distributed mean iid 
notations appear table 
scheduling strategies assume scheduler perfect information making decisions knows task execution time 
service time 
period time job processor queues queue 
describe scheduling strategies employed 
assume scheduling overhead negligible 
processor scheduling policies considered come served fcfs 
strategy tasks assigned queue order arrival 
policy simplest implement 
shortest task stf 
policy assumes priori knowledge task form service demand 
knowledge available tasks processor queues ordered decreasing order service demand 
noted priori information comparative analysis available approximation task execution time available 
stf maximum wait stfmw 
scheduling scheme priority tasks system configurable period time mw 
stf policy applied 
subsystem scheduling policies examined come served fcfs 
disk scheduling policy results suboptimal performance 
scheduling algorithms proposed achieve higher performance information individual requests account 
policy performance yardstick policies compared see job scheduling produces performance benefits 
shortest time stf 
policy chooses request yields shortest time including seek time rotational latency 
stf expected yield best throughput fastest service selected 
algorithm scans entire queue calculating time request take 
selects request shortest expected service time 
obvious method fair job queue large service demand may scheduled long wait queue 
variation stf strategy eliminates problem 
weighted shortest time wstf 
method variation algorithms proposed seltzer worthington 
priority requests pending queue excessive periods time 
priority may slowly increase request ages time limit may set requests served fcfs basis 
algorithm applies standard shortest time technique applies function times computed follows 
assume fcfs policy applied jobs waiting queue time interval greater mean subsystem service time 
means jobs highest priority expected number jobs may bypassed subsystem greater 
simulation vol 
issn online print 
stf calculation actual time multiplied weighting value computed calculating time left request exceed time interval weighted time calculated follows 
tw weighted time actual time tmax equal twait amount time request waiting service tw tmax twait tmax seltzer maximum response time allowed maximum wait time tmax 
simulations seltzer time chosen seconds frequently unix kernel flushes buffer cache 
worthington aged shortest positioning time algorithm 
algorithm adjusts positioning delay prediction subtracting weighted value corresponding amount time request waiting service twait 
resulting effective positioning delay select request twait 
values range 
study policy combinations processor subsystem scheduling policies respectively fcfs fcfs methods examine 
stf stf method fair applied production systems stfmw wstf method intended achieve performance close stf stf policy providing guarantee job suffer unbounded delays 
processor estimated service times assumed uniformly distributed exact value 
performance metrics definitions introduced response time random job time interval dispatching job tasks processor queues service completion processors task job 
comparative analysis response time random job queuing service time job subsystem 
parameters simulation computations table 
table 
notations mrt maximum response time mrt maximum response time system throughput degree multiprogramming coefficient variation mean task execution time mean service time estimation error service time mw maximum wait time threshold stfmw policy represents system performance mrt mrt represent fairness policy applied 
stf stf stfmw wstf policies compared fcfs fcfs relative increase represented dr simulation results discussion model implementation input parameters queuing network model simulated discrete event simulation modelling law independent replication method 
mean value confidence interval evaluated 
confidence intervals mean values 
system considered balanced refer table notations reason chosen balanced program flow average tasks job processors 
processors busy average jobs served unit time 
implies mean service time equal unit service capacity 
simulation vol 
issn online print system examined cases task execution time exponential distribution branching erlang 
degree multiprogramming 
reason various numbers programs examined critical parameter reflects system load 
cases estimation service time required examined estimation errors 
stfmw wstf case examine mw mw results mw case analysed mrt mrt significantly smaller stf stf case performance significantly better performance fcfs fcfs 
performance analysis large number simulation experiments conducted conserve space subset experimental results examined 
figures dr versus depicted figures show ratio mrt ratio mrt stf stf stfmw wstf cases corresponding value fcfs fcfs case 
may drawn results regard processor load case mean processor utilization varies approximately fcfs fcfs stf stf 
corresponding cases utilization lower 
mean unit utilization varies range system balanced 
stf stf performed better methods stfmw wstf performed better fcfs fcfs method 
relative difference performance policies depends degree multiprogramming system load variability processor service times coefficient variation job degree parallelism 
superiority stf stf stfmw wstf fcfs fcfs decreases increasing uniform distribution case stf stf better fcfs fcfs stfmw wstf better 
methods similar performance 
comparative analysis normal distribution case dr little larger 
example stf stf better fcfs fcfs stfmw wstf better fcfs fcfs 
uniform distribution case superiority stf stf stfmw wstf fcfs fcfs increases increases decreases continues increase 
normal distribution case dr increases increases decreases increasing increases dr generally increases 
dr varies differently different values degree multiprogramming increases dr changes similar manner different values mean processor utilization chosen parameter 
reason larger values larger degrees multiprogramming utilization achieved 
example uniform distribution case mean processor utilization fcfs fcfs stf stf stfmw wstf cases respectively dr decreases increasing results achieved 
increases dr starts decrease larger values case 
stf stf case dr increases increasing probable higher higher variability processor service times lower higher advantages stf stf method better exploited 
uniform distribution case highest values observed close obtained 
normal distribution case maximum dr observed 
stfmw wstf case dr higher 
highest value observed uniform distribution case normal distribution case 
dr higher 
figures show cases mrt mrt smaller stfmw wstf case stf stf case 
example uniform distribution case maximum response time processors times larger stf stf case fcfs fcfs case 
stfmw wstf case mrt times larger fcfs simulation vol 
issn online print fcfs case 
normal distribution case ratio response time stf stf case stfmw wstf case 
observe mrt mrt ratios generally decrease increasing large variability service times high produces large service times 
fcfs fcfs case blocking small tasks large task processor queue introduces queuing delays synchronization delays sibling tasks 
time subsystem may starve jobs spend large time waiting queue 
additional simulation experiments conducted assess impact service time estimation error performance scheduling methods require priori knowledge service times 
shows effect service time estimation error system throughput stfmw stf case uniform distribution case 
estimation error set 
graphs show estimation error processor service time marginally affects system performance 
profit gained having exact priori knowledge service times 

dr 
dr stf stf stfmw wstf comparative analysis versus uniform distribution case stf stf stfmw wstf versus uniform distribution case 
dr stf stf stfmw wstf versus uniform distribution case 
dr stf stf stfmw wstf versus normal distribution case 
dr stf stf stfmw wstf versus normal distribution case 
dr stf stf stfmw wstf versus normal distribution case simulation vol 
issn online print ratio mrt mrt mrt stf fcfs mrt stf fcfs mrt stfmw fcfs mrt wstf fcfs 
ratio mrt mrt versus uniform distribution case ratio mrt mrt mrt stf fcfs mrt stf fcfs mrt stfmw fcfs mrt wstf fcfs 
ratio mrt mrt versus uniform distribution case ratio mrt mrt mrt stf fcfs mrt stf fcfs mrt stfmw fcfs mrt wstf fcfs 
ratio mrt mrt versus uniform distribution case ratio mrt mrt mrt stf fcfs mrt stf fcfs mrt stfmw fcfs mrt wstf fcfs 
ratio mrt mrt versus normal distribution case comparative analysis ratio mrt mrt investigated problem distributed system scheduling 
objective identify conditions produce system performance maintaining fairness individual job execution time 
simulation produce results 
policies considered combine scheduling processors subsystem fcfs fcfs stf stf stfmw wstf 
performance policies analyzed compared mrt stf fcfs mrt stf fcfs mrt stfmw fcfs mrt wstf fcfs 
ratio mrt mrt versus normal distribution case ratio mrt mrt mrt stf fcfs mrt stf fcfs mrt stfmw fcfs mrt wstf fcfs 
ratio mrt mrt versus normal distribution case 
versus stfmw wstf policy uniform distribution case research simulation vol 
issn online print various degrees multiprogramming different coefficients variation task execution times different types job parallelism 
simulation results indicate policies merit stf stf policy improves performance fcfs fcfs method provide guarantee individual job service processors unit 
extreme case method delays tasks large comparison mean processor service time jobs need large service time 
processor queues rearranged time new task job added tasks jobs may scheduled 
method normally production systems starvation issue 
stfmw wstf perform stf stf performs better fcfs fcfs fair jobs 
cases yields satisfactory results causing excessive delays system units 
relative performance policies depends degree multiprogramming coefficients variation task execution times job characteristics related degree parallelism 
analysis far complete 
experimentation required examine cases involve preemptive scheduling methods service times higher variability 
greiner de meer trivedi queueing networks markov chains wiley sons new york 
performance implications task routing task scheduling strategies multiprocessor systems 
proc 
ieee euromicro conf 
massively parallel computing systems italy may ieee computer society los alamitos ca usa 
pp 
simulation study task scheduling multiprocessing system simulation journal special issue modelling simulation computer systems networks part april scsi san diego ca usa 
pp 
comparative analysis scheduling strategies multitasking distributed system 
proc 
rd annual simulation symp 
washington usa april ieee computer society los alamitos ca usa 
pp 
gang scheduling scheduling multiprocessor system 
proc 
symp 
performance evaluation computer telecommunication systems vancouver canada july scsi san diego ca usa 
pp 
kumar performance analysis scheduling stochastic fork join jobs multicomputer system ieee transactions parallel distributed systems ieee computer society los alamitos ca usa vol 

pp 
kwong majumdar scheduling multiprogrammed parallel systems informatica 
pp 
law simulation modeling analysis 
nd ed mcgraw hill new york usa 
smirni impact program behavior parallel scheduling 
performance evaluation review 
acm new york usa 
vol 

pp 
seltzer chen ousterhout disk scheduling revisited proc 
winter usenix washington usa january usenix association berkeley california 
usa 
pp 
sevcik application scheduling processor allocation multiprogrammed parallel processing systems performance evaluation elsevier amsterdam holland vol 

pp 
worthington ganger patt scheduling algorithms modern disk drives 
proc 
acm sigmetrics conf 
nashville tn usa may acm new york usa 
pp 
biography helen assistant professor department informatics aristotle university thessaloniki greece 
research interests include performance evaluation multiprocessor scheduling simulation 
simulation vol 
issn online print 
