value directed compression pomdps pascal poupart departement computer science university toronto toronto cs toronto edu craig boutilier department computer science university toronto toronto cs toronto edu examine problem generating state space compressions pomdps way minimally impacts decision quality 
analyze impact compressions decision quality observing compressions allow accurate policy evaluation prediction expected reward affect decision quality 
derive set sufficient conditions ensure accurate prediction respect illustrate interesting mathematical properties confer lossless linear compressions derive iterative procedure finding linear lossy compressions 
elaborate structured representations pomdp find compressions 
partially observable markov decision processes pomdps provide rich framework modeling wide range sequential decision problems presence uncertainty 
unfortunately application pomdps real world problems remains limited due intractability current solution algorithms large part exponential growth state spaces number relevant variables 
ideally mitigate source intractability compressing state space possible compromising decision quality 
aim solving pomdp maximize reward current beliefs world 
compressing belief state agent may lose relevant information results suboptimal policy choice 
important aspect belief state compression lies distinguishing relevant information safely discarded 
number schemes proposed directly indirectly compressing pomdps 
example approaches bounded memory state aggregation dynamic static viewed light 
study effect static state space compression decision quality 
characterize lossless compressions lead error expected value deriving set conditions guarantee decision quality impaired 
characterize specific case linear compressions 
analysis leads algorithms find compression schemes including methods exploit structure pomdp dynamics exhibited graphical models 
extend concepts lossy compressions 
derive somewhat loose upper bound loss decision quality conditions lossless compression required dimensionality met 
propose simple optimization program find linear lossy compressions minimizes bound describe structured pomdp models implement scheme efficiently 
background notation pomdps pomdp defined set states set actions set observations transition function denotes transition probability js observation function denotes probability zjs making observation state reward function denotes immediate reward associated state assume discrete state action observation sets focus discounted infinite horizon pomdps discount factor 
policies value functions pomdps typically defined belief space belief state distribution capturing agent knowledge current state world 
belief state updated response specific action observation pair ha zi bayes rule normalization constant 
denote unnormalized mapping matrix form ij ja zjs 
note belief state reward function viewed respectively jsj dimensional row column vectors 
define 
solving pomdp consists finding optimal policy mapping belief states actions 
value policy expected sum discounted rewards defined number techniques value iteration policy iteration compute optimal approximately optimal policies pomdps 
conditional independence additive separability state space defined set variables pomdps represented concisely factored way specifying transition observation reward functions dynamic bayesian network dbn 
representations exploit fact transitions associated variable depend small subset variables 
representations exploited solve pomdps state space enumeration 
pfeffer showed conditional independence combined form additive separability enable efficient inference dbns 
roughly function additively separated decomposes sum smaller terms 
instance separable exist conditional distributions zjx zjy zjx zjy :10.1.1.158.8490
ensures need know marginals joint distribution infer pfeffer shows additive separability cpts dbn exploited identify families self sufficient variables 
self sufficient family consists set subsets variables marginals subset sufficient predict marginals subsets time step 
require probabilities variables identify self sufficient family containing variables need compute marginals family monitoring belief state 
ideas generalize cases depend actions 
functional flow pomdp dotted arrows compressed pomdp solid arrows belief state accurately predicted 
functional flow pomdp dotted arrows compressed pomdp solid arrows compressed belief state accurately predicted 
invariant krylov subspaces briefly review linear algebraic concepts see details 
vector subspace 
say invariant respect matrix closed multiplication mx 
krylov subspace kr smallest subspace contains invariant respect basis krylov subspace easily generated repeatedly multiplying fx mx 
kr dimensional show linearly independent vector sequence subsequent vectors linear combinations dbn families self sufficient variables naturally correspond invariant subspaces 
instance suppose linear function depends self sufficient family fy 
regress dynamics dbn multiply transition matrix resulting function defined truth values fxg fy zg 
family variables self sufficient subspace linear functions defined truth values family invariant lossless compressions compression state space pomdp allows accurately evaluate policies say compression lossless sufficient information select optimal policy 
provide characterization lossless compressions 
specialize linear case discuss compact pomdp representations 
compression function maps belief state lower dimensional compressed belief state see 
viewed bottleneck sense information bottleneck filters information contained estimate rewards 
desire compression corresponds smallest statistic sufficient accurately predicting current reward belief state accurately predict rewards 
compression exists find mappings interested predicting rewards don really need accurately estimate belief state just predict compressed belief state captures information relevant estimating rewards 
illustrates resulting functional flow represents transition function directly maps compressed belief state compressed belief state 
eq 
replaced weaker sufficient conditions satisfying eq 
evaluate policy compressed pomdp dynamics follows recover original value function eq 
eq 
equivalent theorem satisfy eq 
eq 
holds iff eq 

proof linear compressions say linear compression linear function representable matrix case approximate transition reward functions linear assuming eq 
satisfied 
eq 
rewritten matrix notation linear compression viewed effecting change basis value function columns defining subspace compressed value function lies 
furthermore rank indicates dimensionality compressed state space 
eq 
satisfied columns span subspace contains invariant respect intuitively eq 
says sufficient statistic able predict time step subspace invariant predict current reward subspace contains 
formally theorem satisfy eq 

range contains invariant respect proof eq 
ensures linear combination columns lies range requires columns linear combinations columns invariant respect best linear lossless compression corresponds smallest invariant subspace contains definition krylov subspace kr ft zg 
fact easily compute best lossless linear compression iteratively multiplying krylov basis obtained 
krylov basis form columns compute solving part eq 

solve pomdp compressed state space note technique viewed generalization givan mdp model minimization technique 
interesting note littman proposed similar iterative algorithm compress pomdps predicting observations 
assuming rewards functions observations 
structured linear compressions pomdp specified compactly say dbn size state space may exponentially larger specification 
practical need avoid state enumeration key motivation pomdp compression 
complexity search compression independent state space size 
unfortunately iterative krylov algorithm involves repeatedly multiplying explicit transition matrices basis vectors 
consider ways compact pomdp specification exploited construct linear compression state enumeration 
solution lies exploiting dbn structure context specific independence 
transition observation reward functions represented dbns structured cpts decision trees algebraic decision diagrams matrix operations required krylov algorithm implemented effectively 
approach offer substantial savings dts adds represent basis vectors krylov subspace may larger dimensionality compressed state space original dbn specifications 
alternatively families self sufficient variables corresponding invariant subspaces identified exploiting additive separability 
starting variables depends recursively grow family variables self sufficient respect corresponding subspace invariant necessarily contains assuming tractable self sufficient family compact basis constructed indicator functions subset variables family fx zg subset binary variables basis vectors correspond set 
approach allows quickly identify compression simple inspection additive separability structure dbn 
resulting compression necessarily optimal best corresponding family 
important note dynamics reward compressed pomdp constructed easily state enumeration original dbn model 
pfeffer notes observations tend reduce amount additive separability dbn increasing size self sufficient families 
point lossless compressions pomdps exploit self sufficiency offer acceptable degree compression may exist 
lossy compressions required cases 
ask existence lossless compressions requires form structure pomdp 
argue case 
suppose transition matrix reward vector chosen uniformly random 
odds falls proper invariant subspace essentially zero infinitely vectors full space proper invariant subspaces put 
means pomdp compressed certainly dynamics exhibit structure 
described context specific independence additive separability exploited identify linear lossless compressions 
guarantee optimal compression remains open question types structure similar ways 
lossy compressions generally find effective lossless compressions consider lossy compressions 
propose simple approach find linear lossy compressions satisfy eq 

table outlines simple optimization program find lossy compressions minimize weighted sum max norm residual errors eq 

weights allow vary degree components eq 
min kr rk kt kfk table optimization program linear lossy compressions satisfied 
unknowns program entries constraint kfk necessary preserve scale driven simply setting entries 
multiply constraints nonlinear 
possible solve optimization program solving series lps linear programs 
alternate solving lp adjusts keeping fixed solving lp adjusts keeping fixed 
guarantees objective function decreases iteration converge necessarily local optimum 
max norm error bound quality compression resulting program depends weights ideally set way represents loss decision quality associated compressing state space 
bound error evaluating policy compressed pomdp difference expected total return policy best compressed pomdp true optimal policy max kv fk theorem gives upper bound linear combination max norm residual errors eq 

theorem max kv fk kr max kt fk max jzj omit proof due lack space 
essentially consists sequence substitutions type kabk kak kbk ka bk kak kbk suspect error bound grossly overestimate loss decision quality intend guide setting jz typically greater factor means higher impact loss decision quality intuitively sense error predicting compressed belief state may compound time set significantly higher structured compressions lossless compressions solving program table may intractable due size jsj constraints unknown entries matrix describe techniques allow exploit problem structure find acceptable lossy compression state space enumeration 
approach related basis function model proposed restrict functions small set factors subsets state variables 
ensures number unknown parameters column optimize table assuming small sj variables sj variables unproblematic 
linear number instantiations factor 
keeping factors small maintain manageable set unknowns 
deal jsj constraints exploit structure imposed dbn structure reduce number constraints cases polynomial number state variables 
achieved techniques described rewrite lp fewer constraints generate small subsets constraints incrementally 
techniques involved refer cited papers details 
searching restricted set structured compressions exploiting dbn structure possible efficiently solve optimization program table 
question factor selection remains factors defined 
version question tackled context selecting basis approximately solve mdps 
techniques proposed papers adapted optimization program 
alternative method structuring computation involves additive separability 
subsets variables function compressed state space restrict column separable function column corresponding state parameters viewed weights indicating importance contribution separable function 
family subsets parameters optimize determine entries function 
nonlinear alternating minimization scheme described earlier optimize classes parameters turn 
note number variables dependent size subsets compressed state space furthermore form additive separability lends compact constraint generation techniques mentioned 
discrete search decent subsets interleaved optimization compression mapping fixed sets preliminary experiments report preliminary experiments coffee problem described 
relatively small size states observations actions results viewed simply illustrating feasibility potential algorithms proposed secs 

experiments structured versions secs 
necessary assess degree compression achievable large realistic problems 
dimensional belief space compressed loss dimensional subspace krylov subspace algorithm described section 
compression applied optimization program described table setting weights respectively 
alternating variable technique iterated times best solution chosen random restarts mitigate effects local optima shows loss expected return optimal policy policy computed varying degrees compression executing stages 
loss sampled random initial belief states averaged runs 
policies manage achieve expected returns loss 
contrast average loss random policy 
concluding remarks depth theoretical analysis impact static compressions decision quality 
derived set conditions guarantee compression impair decision quality leading interesting mathematical properties linear compressions allow exploit structure pomdp dynamics 
proposed simple dimensionality compressed space average loss various lossy compressions optimization program search lossy compressions 
preliminary results suggest significant compression achieved little impact decision quality 
research extended various directions 
interesting carry similar analysis terms information theory linear algebra problem identifying information belief state relevant predicting rewards modeled naturally information theoretic concepts 
dynamic compressions analyzed solve pomdp set reasonable policies shrinks allowing greater compression 
boutilier dearden goldszmidt 
stochastic dynamic programming factored representations 
artificial intelligence 
boutilier poole 
computing optimal policies partially observable decision processes compact representations 
proc 
aaai pp portland 
givan dean greig 
equivalence notions model minimization markov decision processes 
artificial intelligence appear 
guestrin koller parr 
max norm projections factored mdps 
proc 
ijcai pp seattle wa 
guestrin koller parr 
solving factored pomdps linear value functions 
ijcai 
planning uncertainty info seattle wa 
guestrin ormoneit 
information theoretic features reinforcement learning 
unpublished manuscript 
hoey st aubin hu boutilier 
spudd stochastic planning decision diagrams 
proc 
uai pp stockholm 
littman 
memoryless policies theoretical limitations practical results 
cliff husbands meyer wilson eds proc 
rd intl 
conf 
sim 
adaptive behavior cambridge 
mit press 
littman sutton singh 
predictive representations state 
proc nips vancouver 
mccallum 
hidden state reinforcement learning instance state identification 
ieee systems man cybernetics 
murphy 
survey pomdp solution techniques 
technical report berkeley 
poupart schuurmans boutilier guestrin 
greedy linear factored markov decision processes 
aaai pp edmonton 
pfeffer 
sufficiency separability temporal probabilistic models 
proc 
uai pp seattle wa 
poupart boutilier schuurmans 
piecewise linear value function approximation factored mdps 
aaai pp edmonton 
saad 
iterative methods sparse linear systems 
pws boston 
schuurmans 
direct value approximation factored mdps 
proc 
nips vancouver 
tishby pereira bialek 
information bottleneck method 
th annual allerton conf 
comm contr 
computing pp 
