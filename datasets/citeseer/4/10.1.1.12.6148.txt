speculative synchronization applying thread level speculation explicitly parallel applications barriers locks flags synchronizing operations widely programmers parallelizing compilers produce race free parallel programs 
times operations placed conservative assumptions program merely code simplicity 
propose speculative synchronization applies philosophy thread level speculation tls explicitly parallel applications 
speculative threads execute past active barriers busy locks unset flags waiting 
proposed hardware checks conflicting accesses violation detected offending speculative thread rolled back synchronization point restarted fly 
tls principle keeping safe thread key proposal speculative barrier lock flag existence safe threads times guarantees forward progress presence access conflicts speculative buffer overflow 
proposal requires simple hardware programming effort 
furthermore coexist conventional synchronization run time 
simulations evaluate compiler hand parallelized applications 
results show reduction time lost synchronization average reduction program execution time average 
proper synchronization threads crucial correct execution parallel programs 
popular synchronization operations programmers parallelizing compilers include barriers locks flags 
example parallelizing compilers typically global barriers separate sections parallel code 
programmers frequently locks barriers form macros openmp directives ensure codes race free 
supported part national science foundation ccr eia eia che darpa gifts ibm intel hewlett packard 
jos mart nez currently computer systems laboratory cornell university ithaca ny usa 
permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
asplos san jose ca usa acm isbn 
jos mart nez josep torrellas department computer science university illinois urbana champaign urbana il usa cs uiuc edu times synchronization operations placed conservatively 
happens programmer compiler determine code sections race free run time 
example data may accessed hashing function conflicts occasional 
conservative synchronization may simplicity disambiguation possible requires effort programmer compiler afford 
unfortunately conservative synchronization may come performance cost stalls threads unnecessarily 
cases threads execute synchronized code stalling 
research thread level speculation tls proposed mechanisms optimistically executing serial codes parallel 
tls special support checks cross thread dependence violations run time forces offending speculative threads squash restart fly 
times safe thread 
speculative threads venture unsafe program sections safe thread executes code 
result speculative useless forward progress guaranteed safe thread 
propose speculative synchronization applies philosophy tls explicitly parallel serial applications 
speculative threads go past active barriers busy locks unset flags waiting 
hardware monitors conflicting accesses 
violation detected offending speculative thread rolled back synchronization point restarted fly 
tls principle keeping safe thread key proposal 
speculative barrier lock flag existence safe threads times guarantees forward progress presence access conflicts speculative buffer overflow 
fact plus support speculative barriers flags sets proposal apart lock free optimistic synchronization schemes similar hardware simplicity transactional memory speculative lock elision 
schemes apply critical sections speculative mechanism guarantee forward progress section 
speculative synchronization requires simple hardware bit line simple logic caches plus support register checkpointing 
retargeting high level synchronization constructs hardware macros openmp directives speculative synchronization transparent programmers parallelizing compilers 
speculative synchronization fully compatible conventional synchronization coexist run time 
evaluation compiler hand parallelized applications shows promising results time lost synchronization reduced average program execution time reduced average 
organized follows section outlines con cept speculative synchronization section describes implementation section software interface section presents evaluation environment section evaluation section compares approach relevant lock free optimistic synchronization schemes proposes adaptive speculative synchronization section describes related 
concept thread level speculation tls extracts speculative threads serial code submits execution parallel safe thread 
speculative threads venture unsafe program sections 
goal extract parallelism code 
tls aware order program sections run single threaded execution 
consequently threads assigned epoch numbers lowest corresponds safe thread 
threads execute hardware checks cross thread dependence violations 
example thread reads variable thread lower epoch number writes true dependence violated 
case offending reader thread squashed restarted fly 
tls systems name dependences cause 
speculative threads keep unsafe memory state buffers tls proposals processor caches fulfill role 
thread squashed memory state discarded 
thread predecessors complete successfully thread safe 
merge memory state system 
memory state speculative thread overflow buffer thread simply stalls 
resume execution predecessors complete successfully restart gets squashed 
safe thread gets squashed due dependences buffer overflow 
forward progress application guaranteed 
speculative synchronization speculative applies tls concepts explicitly parallel serial codes 
goal enable extra concurrency presence conservatively placed synchronization data access conflicts threads exist 
attack problem limit scope tls concepts ways 
support ordering speculative threads single epoch number 
second addition true dependences trigger squash name dependences violated threads 
limitations simplify hardware substantially 
speculative threads allowed speculatively execute past active barriers busy locks unset flags 
conventional synchronization threads waiting allowed execute unsafe code 
lock flag barrier safe threads lock lock owner safe flag producer safe barrier lagging threads safe 
safe threads get squashed stall due speculation 
forward progress application guaranteed 
synchronized region concurrently executed safe speculative threads hardware checks cross thread dependence violations 
tls long dependences violated threads allowed proceed 
access conflicts safe speculative threads violations happen order access safe thread happens access speculative 
order conflict safe speculative thread causes squashing speculative thread rollback synchronization point 
ordering exists speculative threads speculative threads issue conflicting accesses squashed rolled back synchronization point 
safe threads progress regardless success speculative threads performance worst case order conventional synchronization 
speculative threads keep memory state caches safe 
speculative thread safe commits visible memory state system 
circumstances speculative thread safe differ locks flags barriers explain 
cache speculative thread overflow thread stalls waits safe 
limit discussion deadlock free parallel codes codes deadlock run time scope 
furthermore loss generality assume release consistency model 
adapting stricter models trivial 
speculative remains equally relevant models barriers locks flags widely cases 
speculative locks threads competing speculative lock safe thread lock owner 
contenders venture critical section speculatively 
shows example speculative lock threads 
thread lock free acquired owner 
thread safe 
threads lock busy proceeded critical section speculatively 
thread reached acquire point safe 
existence lock owner implications 
final outcome consistent conventional lock lock owner executes critical section atomically speculative threads 
conventional lock speculative threads waiting acquire point 
hand implies correct speculative threads consume values produced lock owner 
hand speculative threads commit owner critical section 
threads completed critical section executing code past release point inside critical section 
threads remain speculative long owns lock 
program order acquire release barrier example speculative lock barrier 
dashed solid circles denote speculative safe threads respectively 
eventually lock owner thread completes critical section releases lock 
point speculative threads completed critical section threads immediately safe commit speculative memory state 
fact completed critical section remembered hardware 
describe implementation detail 
acquiring lock 
race free threads completely executed critical section conflicts owner threads 
hand speculative threads inside critical section thread case compete ownership lock 
acquires lock safe committing speculative memory state 
losers remain speculative 
action release semantically equivalent scenario conventional lock release owner speculative threads past release point nondeterministic order execute critical section atomically threads competing lock acquires ownership enters critical section 
corresponds conventional lock critical section traversed order 
speculative flags barriers flags barriers synchronization operations respectively 
flags variables produced thread consumed 
conventional synchronization consumers test flag proceed reflects permission producer 
speculative synchronization flag value normally stall consumer threads allows proceed speculatively 
threads remain speculative right flag value produced point safe commit state 
forward progress guaranteed producer thread remaining safe 
conceptually barriers equivalent flags producer thread arrive 
speculative synchronization threads arriving barrier speculative continue threads 
threads moving barrier remain safe threads guarantee forward progress 
thread reaches barrier speculative threads safe commit state 
implementation speculative synchronization supported simple hardware describe section 
start describing main hardware module 
explain detail works single multiple locks flags barriers 
speculative synchronization unit main module support speculative synchronization speculative synchronization unit ssu 
ssu consists storage control logic add cache hierarchy processor shared memory multiprocessor 
ssu physically resides chip controller local cache hierarchy typically 
function offload processor operations synchronization variable processor move ahead execute code speculatively 
ssu provides space extra cache line level holds synchronization variable speculation 
extra cache line accessible local remote requests 
ssu allocate 
local cache hierarchy buffer speculative data 
distinguish data accessed speculatively rest ssu keeps speculative bit line local cache hierarchy 
speculative bit line set line read written speculatively 
lines speculative bit set displaced local cache hierarchy 
ssu state bits called acquire release 
logic tag cpu shaded areas show speculative synchronization unit ssu level cache hierarchy 
ssu consists speculative bit conventional line caches acquire release bit extra cache line logic 
acquire release bits set ssu pending acquire release operation respectively synchronization variable 
speculative acquire release bits may set ssu active handling synchronization variable 
ssu idle bits remain zero 
see ssu storage requirements modest 
kb cache mb cache lines ssu needs kb storage 
supporting speculative locks describe ssu works locks examine lock request lock acquire lock release access conflict cache overflow exposed ssu operation 
lock request different primitives implement lock acquire operation loss generality test test set 
shows loop lock loc 
example rest zero value means lock free 
ld loc loc example test test set operation 
processor reaches acquire invokes library procedure section issues request ssu address lock 
point ssu processor proceed independently follows ssu side ssu sets acquire release bits fetches lock variable extra cache line initiates loop obtain lock ownership 
lock busy ssu keeps spinning locally lock updated externally coherence message received 
practice ssu need spin sits cache controller simply wait coherence message retrying 
processor side tls order allow quick rollback squashed threads need checkpoint architectural register state speculative section 
envision done checkpoint mark instruction backs architectural register map actual architectural register values 
checkpoint instruction included library procedure acquire section right request ssu 
flushing pipeline needed 
processor continues execution critical section 
memory system accesses processor acquire program order deemed speculative ssu long acquire bit set 
ssu able distinguish accesses precede acquire program order 
conservative method ensure insert memory fence prior performing checkpoint 
unfortunately approach correct high performance cost 
processor hints similar way asi address tags extend memory addresses issued sparc processors 
case need single bit call processor tag orp tag bit 
tag bit issued processor memory address fed ssu 
checkpointing instruction enhanced reverse tag bit memory operations follow program order 
way processor immediately proceed critical section ssu determine memory accesses checkpoint program order 
ssu sets speculative bit lines accesses tagged appropriately tag bit 
note mechanism impose restriction order processor issues accesses memory 
support cache lines accessed speculatively marked affecting performance 
note thread performs speculative access line dirty cache including coherence protocol write back line memory 
necessary keep safe copy line main memory 
enables conventional dirty bit caches combination speculative bit mark cache lines speculatively written 
time thread squashed section processor completes flushes pipeline dirty cache lines speculative bit set speculative bits restores checkpointed register state 
perform flash invalidate flash clear operations need special hardware cycles 
details section 
lock acquire ssu keeps spinning lock variable reads zero 
point attempts operation statement 
operation fails ssu goes back spin test 
succeeds local processor lock owner 
case thread example section thread releases lock 
case ssu completes action resets acquire bit flash clears speculative bits effectively turning thread safe committing cached values 
point ssu idle 
trying acquire lock read lock owned 
exception mechanism time lock freed owner speculative thread completed critical section 
address case 
backing architectural register values done handful cycles free potentially valuable renaming registers 
lock release processor executes release store synchronization variable memory operations inside critical section completed 
speculative synchronization lock acquired ssu ssu idle release store completes normally 
ssu trying acquire ownership lock ssu intercepts release store takes notice clearing release bit 
enables ssu remember critical section fully executed speculative thread 
call event release speculative 
ssu keeps spinning ownership acquire bit set 
note execution speculative thread disrupted 
general ssu reads lock freed externally attempting operation checks release bit 
release bit set ssu issues operation compete lock described section 
bit clear ssu knows local thread gone release speculative operation completed memory operations prior release 
result ssu aggressively pretend ownership acquired released instantly 
acquire bit cleared speculative bits flash cleared ssu idle 
case thread safe performing operation 
action taken threads example section thread releases lock 
indicated section optimization race free release bit speculative thread cleared memory operations critical section completed conflict free lock value indicates previous lock owner completed critical section 
time speculative thread safe incoming invalidation flight third processor line marked speculative things happen invalidation arrives speculative thread committed thread squashed 
suboptimal correct 
alternatively thread committed invalidation serviced conventionally 
access conflict underlying cache coherence protocol naturally detects access conflicts 
conflicts manifest thread receiving external invalidation cached line external read dirty cached line 
external messages received lines marked speculative serviced normally 
particular messages lock owner safe thread result cache lines marked speculative 
note originator thread message speculative case normally servicing request effectively supporting order conflicts safe speculative thread squashing 
hand speculative thread receives external message line marked speculative conflict resolved squashing receiving thread 
originator thread may safe speculative 
order conflict taken place squash warranted 
squash receiving thread proposal define order speculative threads 
case originator squashed 
triggered squash mechanism proceeds follows ssu flash invalidates dirty cache lines speculative bit course time conventional speculative synchronization processor may executed code past release point 
sophisticated hardware disambiguate order name dependences potentially avoid squash 
indicated section choose support simplicity 
set flash clears speculative bits speculative thread past release point sets release bit 
addition ssu forces processor restore checkpointed register state 
way thread quickly rolls back acquire point 
flash invalidation simply flash clear valid bit qualified speculative dirty bits nand gating 
note invalidate cache lines speculatively read modified coherent main memory 
squash triggered external read dirty speculative line cache node replies supplying data 
coherence protocol regards state cache line stale supplies clean copy memory requester 
similar case conventional protocols node queried directory clean line state exclusive silently displaced cache 
cache overflow cache lines speculative bit set displaced local cache hierarchy record past speculative accesses 
dirty bit set data unsafe 
replacement necessary outermost level local cache hierarchy cache controller tries select cache line marked speculative 
candidate node stalls thread granted ownership lock squashed 
stalling jeopardize forward progress exists lock owner 
lock owner eventually release lock node ssu gains ownership speculative thread gone release speculative operation lock able handle cache conflicts stalling 
safe threads lines marked speculative replace cache lines misses usual 
exposed ssu times may best allow threads speculate certain point 
happen example certain access known irreversible cause conflicts 
case programmer parallelizing compiler force speculative thread spin wait ssu state idle section 
thread wait safe gets squashed 
naturally ssu idle spinning take place 
call action exposing ssu local thread 
general envision speculative synchronization transparent programmer compiler practically cases section important provide mechanism software capability 
supporting multiple locks speculative threads may meet second acquire point 
happen nested locks consecutive critical sections 
approach cases expose ssu thread prior attempting second acquire 
aggressive approach avoid unnecessary stalls 
receiving lock acquire request processor section ssu checks acquire bit 
clear ssu idle service request usual 
ssu busy consider general case acquire request lock variable different currently handled ssu 
case ssu rejects request checkpointing done speculative thread handles second lock ordinary code 
additional support required 
handling second lock ordinary code correct thread speculative accesses lock variable considered speculative 
thread reading value lock line marked speculative cache 
lock busy thread spins locally 
free thread takes proceeds critical section modification lock contained local cache hierarchy speculative access 
lock treated speculative data 
possible final outcomes situation 
hand thread get squashed 
occur conflict thread cached line marked speculative including contains second lock variable 
case squash procedure roll back thread acquire lock handled ssu 
usual updates speculative data discarded 
includes speculative update second lock variable 
hand ssu may complete action lock render thread safe 
commits speculatively accessed data including second lock 
thread originally spinning second lock continue safely 
action taken speculatively thread second lock acquire possibly release commit rest system 
correct thread tried manipulate second lock triggered squash 
special case second acquire lock variable handled ssu 
case ssu holds request thread safe completes execution critical section ssu clears release bit whichever 
ssu completes action usual accepts new acquire request 
case release speculative section ssu simply sets release bit accepts acquire request 
way ssu effectively merges critical sections single 
case second checkpoint performed 
thread eventually commits critical sections 
hand thread gets squashed roll back checkpointed acquire 
speculative flags barriers implement speculative flags leverage release speculative support speculative locks section 
recall scenario ssu speculative thread left release bit clear spinning lock set owner free value 
lock set free value speculative thread safe immediately ssu performing release bit clear 
mechanism exactly matches desired behavior thread speculatively executes past unset flag 
consequently speculative flag read ssu acts exactly case speculative lock request release bit kept clear allow test processor allowed go past unset flag speculatively 
naturally speculative lock event squash release bit set back 
explain section part speculative flag request thread supplies pass value flag ssu 
possible thread speculating past flag may try access flag 
ssu handles situation simply holding access speculative thread safe gets squashed 
barriers implemented locks flags illustrated 
ssu implement speculative locks flags support speculative barriers comes free 
conventional synchronization thread arriving early barrier updates barrier counter count waits spinning statement 
counter update critical section protected lock speculative synchronization local local lock count increment count count total count reset count local toggle unlock unlock local spin example bit reversal barrier code 
thread enter critical section ssu busy second thread arriving barrier surely cause conflicts lock counter forcing rollback thread speculative way synchronization point handled ssu 
thread arrives barrier safe state critical section small preferable reserve ssu upcoming flag spin statement 
consequently threads execute critical section conventionally speculate flag 
support behavior library code barriers section exposes ssu thread attempting acquire speculative threads chance safe commit 
conventional synchronization acquire release thread reaches flag spin statement issues speculative flag request proceeds past barrier speculatively 
thread arrives toggles flag statement threads safe commit 
issues related issues briefly consider support multiprogramming 
multiprogrammed environment operating system may preempt threads application 
speculative thread preempted squashed local ssu freed 
new thread runs processor ssu 
thread rescheduled resumes synchronization point 
hand safe threads handled conventional system particular squashed context switch 
speculative synchronization lock technique may exhibit certain scheduling conditions 
address issue section 
exception handling 
speculative thread suffers exception easy way knowing cause legitimate due consuming incorrect values speculatively 
consequently speculative thread rolled back cases 
false sharing 
implementation uses memory line unit coherence false sharing may cause thread 
implementation benefit existing techniques reduce false sharing 
technique requires word state caches require word speculative bits 
synchronization primitives 
discussion assumed ssu adapted support types synchronization primitives 
example support scalable primitives queue locks case ssu spin location queue content flipped predecessor ssu queue 
general synchronization primitive may different operational performance implications 
analysis issue subject 
summary proposed implementation speculative synchronization key characteristics 
supports speculative execution barriers flags locks unified manner 

safe threads exist times 
safe threads squashed due access conflicts stalled due cache overflow 
performance worst case typically order conventional synchronization 
furthermore order conflicts safe threads speculative threads tolerated 

compatible conventional synchronization legacy code uses conventional synchronization run simultaneously speculative synchronization code program 
implementation additional aspects 
hardware required simple 
second right conditions release speculative case speculative threads commit execution critical section having acquire lock 
third conflicting accesses detected fly offending threads squashed eagerly restarted 
fourth commit squash operations take approximately constant time irrespective amount speculative data number processors 
situations involving multiple locks handled transparently unnecessarily stalling extra cost 
software interface explicit high level synchronization constructs macros openmp directives widely programmers parallelizing compilers produce parallel code 
synchronization constructs provide opportunity enable speculative synchronization transparently 
specifically retarget constructs encapsulate calls ssu library procedures 
library procedures access ssu set memory mapped registers 
ssu library comprises procedures ssu lock addr requests lock acquire operation variable addr 
ssu accepts request processor performs register checkpoint section ssu initiates lock acquire 
case procedure returns nonzero value 
ssu rejects request typically ssu busy variable procedure returns zero 
ssu spin addr value requests spin operation variable addr value pass value 
ssu accepts request processor performs register checkpoint ssu initiates spin 
procedure returns nonzero value 
similarly ssu rejects request procedure returns zero 
ssu idle returns zero ssu busy nonzero value idle available 
library procedures build macros speculative locks flags barriers 
consider table shows example conventional macros left side 
right side shows corresponding speculative macros 
groups macros similar 
differences shown bold face 
speculative lock ss lock speculative spin ss spin macros try utilize ssu revert conventional macros lock spin request rejected 
conventional macro barriers barrier uses typical bit reversal code 
speculative version ss barrier calls new macro expose ssu ss expose 
ssu exposed guarantee safe state continuing section 
counter updated conventional locking 
spin attempted ssu 
conventional macros existing speculative macros proposed lock lock unlock unlock spin barrier lf pid lf pid lock lock lf pid unlock lock unlock lock spin lf pid ss lock ssu lock lock ss unlock unlock ss spin ssu spin spin ss expose ssu idle ss barrier lf pid lf pid ss expose lock lock lf pid unlock lock unlock lock ss spin lf pid table example macros conventional synchronization operations corresponding speculative ones 
barrier code uses typical bit reversal technique 
differences shown bold face 
programmer enable speculative synchronization simply macros conventional ones 
likewise parallelizing compilers trivially enhanced generate code speculative synchronization 
compilation switch generate code speculative macros typically barriers conventional ones 
summary speculative synchronization clean lean software interface programmers parallelizing compilers 
legacy codes run conventional synchronization fully functional 
fact types synchronization coexist run time program 
evaluation environment evaluate speculative synchronization simulations driven parallel applications 
section describe machine architecture modeled applications executed 
architecture modeled execution driven simulation framework model detail cc numa multiprocessor nodes 
system uses release memory consistency model cache coherence protocol lines dash 
node processor level hierarchy write back caches 
processor issue order superscalar register renaming branch prediction nonblocking memory operations 
cache sizes kept small capture behavior real size input data exhibit actual machines suggested larger cache sizes generally favor speculative synchronization fewer overflow induced stalls occur 
shared data pages placed round robin memory modules private data pages allocated locally 
table lists main parameters architecture 
traffic resource contention modeled detail contention network routers constant delay assumed 
conservatively assess cycle penalty checkpoint architectural registers 
processor issue alu ld st branch prediction ghz issue dynamic entry rob integer floating point units ld st entry bit saturating counter branch penalty cycles memory cc numa protocol cache ghz kb lines way cache mhz kb lines way memory bus mhz split transaction width main memory mhz sdram interleaved ns row cache rt ns ns mem 
rt local neighbor ns ns network hypercube routing router mhz pipelined pin pin latency ns endpoint un marshaling ns configuration processors table architecture modeled simulations 
table rt stands minimum round trip latency processor 
number processors cache size parentheses correspond splash applications 
applications executed parallel applications suites different characteristics 
compiler parallelized specfp application applu olden codes annotated parallelization mst hand parallelized splash applications ocean barnes 
applications synchronize locks barriers 
particular applu barrier codes locks barriers 
table summarizes characteristics applications 
parallel applu code generated polaris state ofthe art parallelizing compiler 
olden codes applications operate graphs trees 
annotated compiler programmer easily parallelize 
follow annotations faithfully 
splash applications fine tuned hand parallelized codes 
barnes uses hashing synchronize limited number locks 
experiments configurations barnes different number hashed locks locks barnes coarse locks barnes fine 
code original suite barnes fine 
execute splash applications processors applications scale particularly rest applications executed processors scalable 
conventional synchronization average efficiency parallel execution applications chosen numbers processors 
cases warm cache hierarchy starting collect execution statistics 
simulate applications completion applu reduce number iterations exhibit similar behavior 
evaluation section evaluate applications conventional synchronization speculative synchronization base spec respectively 
assess effectiveness speculative synchronization analyze factors contribute 
effectiveness shows execution time applications base spec systems 
bars normalized base broken categories 
useful time spent computation ultimately profitable 
includes processor busy time stall execution time application description applu lu factorization bitonic sort mst minimum spanning tree ocean barnes fine barnes coarse ocean simulation applu base spec base spec parallelization compiler annotations annotations hand data size nodes nodes body problem hand particles table applications experiments 
mst base spec processors ocean barnes fine barnes coarse average base spec base spec base spec base spec barriers locks overhead squashed sync useful speculative useful safe execution time applications conventional base speculative spec synchronization 
bars normalized base 
ocean barnes run processors applications run processors 
barnes coarse shows brackets execution times normalized barnes fine base 
due memory pipeline hazards 
subdivided useful safe useful speculative depending execution safe speculative respectively 
course useful speculative appears spec 
sync time spent spinning synchronization points 
squashed time wasted speculative threads execution gets ultimately squashed 
overhead time taken handle squash operations including draining processor pipeline load store buffers restoring processor checkpointed register state 
base applications spend average time spinning synchronization points 
naturally impact speculative synchronization largely bounded 
practice speculative synchronization reduces original synchronization time average combine residual synchronization time sync squashed execution time squashed squash overhead overhead 
result average execution time applications decreases 
applications reduction execution time ranges small value barnes fine significant mst 
fraction code executed speculatively sum useful speculative plus squashed 
combined size categories necessarily small applications little synchronization applu 
hand frequent synchronization provides opportunity speculate case mst lesser extent ocean useful speculative plus squashed account total spec time respectively 
average applications half time proves useful useful speculative 
ideally total useful time application remain constant go base useful safe spec useful safe plus useful speculative 
practice see total useful time changes slightly 
reason constructive destructive memory effects speculative computation 
hand speculative execution gets ultimately squashed positive effect prefetching useful clean data caches 
effect observed applu 
hand involve invalidating cache lines modified speculatively 
result may negative effect destroying locality originally caches 
effect observed mst 
general hard predict effect constructive destructive 
focusing non useful execution see largely composed residual synchronization squashed execution time overhead squash mechanism overhead accounts little 
residual due speculative thread bumping barrier case exposed ssu section lock busy case multiple locks section 
residual synchronization squashed execution time represent areas improvement speculative synchronization 
residual synchronization relatively large barnes fine barnes coarse squashed execution time sizable ocean mst 
categories discussed section detail 
numbers brackets top barnes coarse bars show execution time application normalized barnes fine base 
see barnes coarse base takes longer execute barnes fine base 
largely due coarser synchronization 
apply speculative synchronization barnes coarse spec execution time comes longer barnes fine base 
shows speculative synchronization compensate conservative synchronization 
contributing factors focus time lost synchronization related overheads 
compare synchronization time base time lost residual synchronization squashed computation squash overhead spec 
results shown 
break synchronization time barrier barrier sync lock lock sync time speculative flags se codes 
break time lost squashed computation categories depending reason squash true data false time lost sync barnes barnes applu mst ocean fine coarse base spec base spec base spec base spec base spec base spec average base spec overhead squash nd lock squash false data squash true data lock sync barrier sync factors contributing synchronization time related overheads base spec systems 
results normalized base 
ocean barnes run processors applications run processors 
percentages top bars reflect fraction synchronization base 
data nd lock 
true data false data computation squashed due conflicts induced word accesses false data sharing respectively 
recall speculative bits kept line basis false sharing causes conflicts 
nd lock computation squashed due speculative thread conflicting second synchronization variable 
variable necessarily lock ssu exposed barriers section 
shows general synchronization time applications base dominated barriers fact applu synchronize exclusively barriers 
mst barnes coarse exhibit significant lock activity 
important attack synchronization due locks barriers 
shown speculative synchronization significantly reduces contribution lock barriers 
spec bars show residual synchronization time 
caused speculative threads stalling second synchronization point 
large majority residual synchronization time spent barriers crossed threads speculative exposed ssu 
example residual barrier time appears top part tree 
processors move root number processors decreases 
idle processors start synchronizing level wait 
cross barrier speculatively immediately bump stall 
barnes speculative threads stall barriers 
contention locks significantly reduced 
times time lock released owner speculative threads completed critical sections concurrently release speculative section 
point commit competing lock 
reduces lock sync time 
focusing squash time see ocean mst exhibit relatively large fraction squashed 
ocean main source false sharing false data 
mst main contributors squash time word access conflicts true data access conflicts second lock variables nd lock order 
important devise techniques minimize sources 
address issue 
eliminating remaining overheads main overheads remain spec bars attacked changes ssu system 
examine case turn 
false sharing 
general techniques reduce false sharing shared memory multiprocessors benefit speculative synchronization 
techniques require keeping word speculative bits 
careful hurt performance ways 
example data padding ocean may reduce false sharing may give spatial locality application 
true sharing 
sophisticated speculative synchronization protocol reduce cases word conflicts cause 
example order war conflicts need cause system supports multiple versions variable processors 
systems tls incorporate forms multiple version support 
cost hardware support complicated protocol 
nd lock squash 
avoid second lock expose ssu lock barriers speculative thread waits safe 
ssu enter second lock speculatively 
avoids second lock expense disallowing processor speculate simultaneously multiple critical sections 
particular applications approach causes nd lock time simply mutate residual synchronization 
fact execution time slightly higher 
residual synchronization 
minimize residual synchronization design sophisticated ssu handles multiple speculative epochs multiple sets speculative bits 
incidentally support solve problem nd lock 
support complicates ssu nontrivial way resembles tls 
interestingly adding enhancements speculative synchronization support multiple epochs multiple data versions word speculative state obtain system comes close current proposals tls 
understanding full interaction speculative synchronization tls subject current research 
adaptive speculative synchronization proposals hardware lock free optimistic synchronization critical sections 
schemes features complement speculative synchronization 
section describe schemes similar hardware simplicity section describes related 
outline adaptive scheme extends speculative synchronization capture positive aspects lock free synchronization preserving advantages original solution 
call scheme adaptive speculative synchronization 
characteristic tm sle applicability critical sections locks commit lock acquire successful successful safe thread action overflow handled grab lock squash contenders action conflict inside critical section squash squash receiver critical path possible programming effort fly rollback speculative synchronization basic adaptive locks flags barriers release speculative rws conflicts overflow rws possible conflicts overflow needed safe thread affected speculative thread compete acquire continue receiver safe continue receiver speculative squash receiver table comparing speculative mechanisms tm sle speculative synchronization 
receiver denotes thread receives coherence message due access conflict inside critical section 
lock free optimistic synchronization transactional memory herlihy moss transactional memory tm short proposes lock free optimistic synchronization critical sections special transactional instructions support cache hierarchy hold speculative data 
general tm requires code written lock free manner 
threads execute critical sections speculatively coherence protocol helps detect conflicts 
code check conflicts flagged thread 
thread discards changes jumps back critical section 
time thread completes critical conflicts flagged thread commit 
speculative lock elision concurrently goodman propose speculative lock elision sle 
sle dynamically converts lock free codes removing acquire release operations instruction stream processor pipeline 
tm threads execute critical sections speculatively 
sle leverages coherence protocol detect conflicts 
compared tm sle presents important advantages sle requires programming effort codes lock elision mechanism transparent sle fall back conventional synchronization needed see discussion lastly sle features fly thread rollback restart speculative synchronization 
discussion limit discussion speculation critical sections tm sle supports speculation barriers flags 
proposals tm sle allow right conditions execute critical sections need secure lock 
speculative synchronization behavior possible release speculative operation section 
speculative synchronization requires thread grab lock active critical section 
result speculative threads wait lock freed owner commit 
speculative synchronization subject 
conventional locks occurs lock owner preempted scheduler threads left spinning lock 
speculative synchronization preempting lock owner prevents speculative threads committing 
number techniques proposed avoid preempting lock owner 
general concern 
hand tm sle share shortcoming presence conflicts speculative mechanisms embed forward progress guarantee 
threads execute critical section speculatively thread receives ence message due access conflict inside critical section squashed 
result repetitive conflicts may cause threads livelock special action taken 
specifically tm relies software level adaptive backoff increase probability eventual success 
sle certain number failed retries speculative threads abandons lock free mode explicitly acquires lock 
unfortunately sle lock synchronization mutually exclusive thread explicitly grabs lock threads critical section get squashed start spinning busy lock 
problem occurs speculative threads overflow speculative buffers 
sle speculative thread overflow speculative buffer abandon lock free mode explicitly acquire lock 
threads critical section get squashed start spinning busy lock 
tm provide solution problem overflow 
presence conflicts overflow existence lock owner times gives speculative synchronization advantages 
lock owner receive coherence messages due access conflicts inside critical section getting squashed speculative threads execute inside critical section concerned forward progress guaranteed lock owner 
second advantage number speculative threads overflow caches stall compete lock held owner acquiring continue squashing thread involved 
columns table summarize discussion 
table receiver denotes thread receives coherence message due access conflict inside critical section 
proposed adaptive extension extend ssu implement lock free synchronization critical sections show adaptive protocol combines best worlds possible 
basic idea adaptive speculative synchronization operate lock free manner fall back speculative synchronization producing lock owner forward progress compromised 
speculation disabled 
barriers flags handled speculatively base mechanism 
speculative lock request ssu reads lock variable try secure ownership 
threads access critical section speculatively 
similar sle thread venture critical section speculatively regardless lock busy free 
speculative thread completes execution critical section ssu tests value lock 
free thread commits lock free style 
ssu falls release speculative mode section commits lock freed owner 
time acquire operation attempted lock variable 
speculative thread detects conflict execution speculative thread overflow cache ssu proceeds compete lock 
possible outcomes situation 
ssu secures ownership thread safe guaranteeing forward progress 
thread owns lock forward progress guaranteed thread case speculative thread rolls back case conflict section stalls ssu keeps competing lock ownership case cache overflow section 
absence conflicts cache overflow ssu implements lock free speculative synchronization critical sections 
conflicts cache overflow occur smoothly fall back original lock speculative synchronization 
notice lock grabbed thread threads speculative allowed continue 
ssu operates lock free mode needed preserving advantages speculative synchronization 
column table summarizes adaptive speculative synchronization 
related optimistic concurrency control occ sets foundation optimistic synchronization notion versus asking permission 
transactions execute synchronizing undergo validation phase commit atomicity preserved abort restart 
herlihy uses optimistic synchronization construct lock free wait free data objects 
technique may small simple structures unclear deal efficiently larger complex objects high copy overhead 
rinard uses finegrain optimistic synchronization compiler driven parallelization 
conventional synchronization necessary multiple interdependent updates different objects 
general optimistic synchronization requires nontrivial programming effort 
hardware proposals exist lock free optimistic synchronization 
important proposals relate closely herlihy moss transactional memory goodman speculative lock elision sle 
address extensively section 
stone propose hardware optimistic synchronization mechanism called oklahoma update 
speculative state limited specialized reservation registers processor 
requests exclusive access speculative data deferred commit phase called oklahoma update making operation potentially slow traffic intensive 
true conflicts phase resolved buffering external requests invalidations selectively delaying responses 
progress guaranteed buffering provided 
conflicts due false sharing need backoff mechanism guarantee forward progress 
problems affects proposal 
building sle goodman propose transactional lock removal preserve lock free behavior presence conflicts 
timestamps dynamically order threads buffering external requests selectively delaying responses fly order 
special messages avoid deadlocks 
buffering resources provided handle conflicts 
cache overflows handled disabling mechanism falling back conventional lock synchronization 
sato address speculation barriers 
discuss modify caches coherence protocol support speculation 
propose concrete implementation speculative barrier 
evaluation assumes conservative consistency model order processors constant delay model processor memory operations 
gupta fuzzy barrier attacks barrier imbalance decoupling barriers phases moving nonconflicting code originally barrier 
approach requires dependence information compile time 
gharachorloo propose allowing loads execute speculatively ahead incomplete stores precede program order 
allow reordering store operations utilizing hardware exclusive prefetches 
speculation limited maximum number uncommitted instructions processor buffering capacity 
behavior branch predictor acquire loop may adversely affect effectiveness scheme 
pai propose synchronization buffer offload acquire loop improve behavior branch predictor 
propose fuzzy speculative acquires achieve finegrain synchronization require compiler support identify non conflicting accesses critical sections 
propose sc aggressive implementation sc allows reordering load store operations maintaining order history queue speculatively retired instructions 
consistency violations trigger recovery procedure uses history queue reconstruct state instruction fault 
cost recovery grows amount speculative may result slowdowns 
sc shown match performance rc behaved applications attacking reordering general choose specialize speculative execution widely synchronization primitives barriers locks flags 
allows hardware remain simple effective 
checkpoint recovery mechanism combined cache support allows retire large number speculative instructions quickly roll back event misprediction independently amount speculative 
furthermore right conditions speculative threads commit critical section acquiring associated lock 
gharachorloo gibbons propose hardware leverages coherence protocol detect violations sequential consistency 
adve hill explicit synchronization order contending threads critical section leverage coherence protocol achieve fine grain synchronization memory accesses 
employ reserve buffers selectively defer coherence messages conflicting addresses 
speculative synchronization applies philosophy thread level speculation explicitly parallel applications 
threads speculatively execute past active barriers busy locks unset flags waiting 
hardware checks conflicting accesses violation detected offending speculative thread rolled back synchronization point restarted fly 
speculative barrier lock flag existence safe threads times guarantees forward progress presence conflicts speculative buffer overflow 
order conflicts safe speculative threads tolerated causing 
speculative synchronization requires simple register checkpointing cache hardware transparent programmers parallelizing compilers coexist conventional synchronization run time 
critical sections extended scheme adaptive speculative synchronization captures positive aspects lock free synchronization 
threads operate lock free manner system falls back speculative synchronization producing lock owner forward progress compromised 
evaluated compiler hand parallelized applications speculative synchronization 
results promising time lost synchronization reduced average execution time applications reduced average 
identified ways improving speculative synchronization 
currently extending directions 
specifically analyzing ssu best supports types synchronization primitives 
evaluating adaptive speculative synchronization 
analyzing full interaction speculative synchronization tls 
acknowledgments authors sarita adve marcelo mar jes jim goodman anonymous reviewers useful feedback 
adve hill 
unified formalization sharedmemory models 
ieee transactions parallel distributed systems june 
blume eigenmann lawrence lee padua paek pottenger rauchwerger tu 
advanced program restructuring high performance computers polaris 
ieee computer dec 
carlisle rogers 
software caching computation migration olden 
symposium principles practice parallel programming pages santa barbara ca july 
mart nez torrellas 
architectural support scalable speculative parallelization shared memory multiprocessors 
international symposium computer architecture pages vancouver canada june 
dagum menon 
openmp industry standard api shared memory programming 
ieee computational science engineering jan mar 
schonberg 
process management highly parallel unix systems 
usenix workshop unix supercomputers san francisco ca sept 
gharachorloo gibbons 
detecting violations sequential consistency 
symposium parallel algorithms architectures pages hilton head sc july 
gharachorloo gupta hennessy 
techniques enhance performance memory consistency models 
international conference parallel processing pages st charles il aug 

sc ilp rc 
international symposium computer architecture pages atlanta ga may 
gopal smith sohi 
speculative versioning cache 
international symposium high performance computer architecture pages las vegas nv jan feb 
gupta 
fuzzy barrier mechanism high speed synchronization processors 
international conference architectural support programming languages operating systems pages boston ma apr 
hammond wiley olukotun 
data speculation support chip multiprocessor 
international conference architectural support programming languages operating systems pages san jose ca oct 
hennessy patterson 
computer architecture quantitative approach 
morgan kaufmann second edition 
herlihy 
versus asking permission optimistic concurrency control data types 
acm transactions database systems mar 
herlihy 
methodology implementing highly concurrent data objects 
acm transactions parallel languages systems nov 
herlihy moss 
transactional memory architectural support lock free data structures 
international symposium computer architecture pages san diego ca may 
wisniewski scott 
synchronization 
acm transactions computer systems feb 
krishnan torrellas 
direct execution framework fast accurate simulation superscalar processors 
international conference parallel architectures compilation techniques pages paris france oct 
krishnan torrellas 
chip multiprocessor architecture speculative multithreading 
ieee transactions computers sept 
kung robinson 
optimistic methods concurrency control 
acm transactions database systems june 
lenoski laudon gharachorloo gupta hennessy 
directory cache coherence protocol dash multiprocessor 
international symposium computer architecture pages seattle wa may 
lusk overbeek portable programs parallel processors 
holt rinehart winston new york ny 
gonz lez 
clustered speculative multithreaded processors 
international conference supercomputing pages rhodes greece june 
marsh scott leblanc markatos 
firstclass user level threads 
symposium operating system principles pages pacific grove ca oct 
mart nez torrellas 
speculative locks concurrent execution critical sections shared memory multiprocessors 
workshop memory performance issues gothenburg sweden june 
pai ranganathan adve 
evaluation memory consistency models shared memory systems ilp processors 
international conference architectural support programming languages operating systems pages cambridge ma oct 
goodman 
speculative lock elision enabling highly concurrent multithreaded execution 
international symposium microarchitecture pages austin tx dec 
goodman 
transactional lock free execution lock codes 
international conference architectural support programming languages operating systems san jose ca oct 
rinard 
effective fine grain synchronization automatically parallelized programs optimistic synchronization 
acm transactions computer systems nov 
sato ohno nakashima 
mechanism speculative memory accesses synchronizing operations 
international parallel distributed processing symposium pages cancun mexico may 
zhai mowry 
scalable approach thread level speculation 
international symposium computer architecture pages vancouver canada june 
stone stone heidelberg turek 
multiple reservations oklahoma update 
ieee parallel distributed technology nov 
weaver editors 
sparc architecture manual 
ptr prentice hall 
woo singh gupta 
splash programs characterization methodological considerations 
international symposium computer architecture pages santa margherita ligure italy june 

mips superscalar microprocessor 
ieee micro apr 
