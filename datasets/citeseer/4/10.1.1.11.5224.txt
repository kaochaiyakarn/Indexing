detecting subject boundaries text language independent statistical approach richmond kor 
ed 
ac 
uk describe algorithm detect ing subject boundaries text statistical lexical similarity measure 
hearst tackled problem results hearst 
main assumptions change subject accompanied change vo 
assumption introducing new measure word signif able build ro bust reliable algorithm exhibits improved accuracy sacrificing lan guage independency 
automatic detection subject divisions text considered difficult task humans machines 
subject di visions complex tasks text pro cessing text summarisation 
automatic method marking subject boundaries highly de 
hearst hearst addresses prob lem applying statistical method detecting subjects text 
hearst describes algorithm calls text tiling method detecting subject boundaries text 
underlying assump tion algorithm high proba andrew smith aj cogsci ed 
ac 
uk joint authorship centre cognitive science buccleuch place edinburgh eh lw scotland amitay cogsci 
ed 
ac 
uk bility words related certain sub ject repeated subject men tioned 
basic assumption new subject emerges choice vocabulary change stay consistent subject boundaries change subject 
basic notions vocabulary consistency sub ject boundaries lead method dividing text calculating vocabulary similarity adjacent windows text 
potential subject boundary identified assigned correspondence value lexical similarity windows text ei ther side subject boundary 
values potential boundaries plotted graph creating peaks troughs 
troughs represent changes vocabulary underlying assumption change subject 
sion mark inserted significant local min imum detected graph 
hearst measured approximately success detection subject boundaries texts 
decided adopt hearst underlying assump tion change subject entail change vocabulary 
aim algorithm language independent computationally ent possible improving accuracy reliability 
design preprocessing stage significance stage value word biased lexical stage smooth results stage insert breaks stage algorithm structure 
algorithm divided distinct stages 
shows sequential modular structure algorithm 
stage algorithm de scribed detail 
preprocessing stage implementation texttiling algorithm hearst ignores preprocessing claiming af fect results hearst 
preprocessing mean stemming converting upper lower case testing assumption algo rithm change results 
preprocessing conjunction stage algorithm improve results 
impor tant algorithm morphological differences semantically related words resolved words bankrupt bankruptcy example identified word 
calculating significance value word stage hearst treats text bag words statistical analysis 
natural language doubt structured 
different words differing semantic functions rela tionships respect topic discourse 
broadly distinguish extreme categories words content words versus function words 
con tent words introduce concepts means expression ideas facts example nouns proper nouns adjectives 
function words example determiners auxiliary verbs support coordinate combination content words meaningful sentences 
obviously needed form meaningful sentences content words carry weight defining actual topic discourse 
intuition believe advantageous identify content words text 
possible bias calculation lexical correspondences stage account higher significance words relative func tion words 
ideally firstly reduce effect noisy non content words algorithm formance secondly pay attention words high semantic content 
imple mentation hearst attempts having finite list problematic words filtered text statistical analysis takes place hearst 
problematic words primarily function words low semantic content words determiners conjunctions tions common nouns 
church gale church gale men tion correlation word semantic content various measures distribution corpora 
show word rates vary genre genre topic topic author author document document section sec tion paragraph paragraph 
factors tend decrease entropy increase test variables 
test variables men tioned church gale burstiness 
tribute innovation notion burstiness slava katz pertaining topic writes katz notion burstiness characterisation closely related distinct phenomena document level ness multiple occurrence content word phrase single text document contrasted fact documents contain instances word phrase document burstiness burstiness proper close proximity individual stances content word phrase doc ument exhibiting multiple occurrence 
katz highlighted interesting features distri bution content words conform predictions statistical models son 
katz katz states concept named content word topical document content word tends characterised multiple bursty occurrence 
claims single occurrence topically content word phrase possible newly introduced topical entity repeated breaking monotonous effect pronoun emphasis clarity 
claims function words number instances specific content word directly associated document length function document concept ex pressed word 
characteristic distribution pattern topical content words contrasts markedly non topical non content words provide useful aid identifying seman relevant words text 
brief mention done justeson katz justeson katz certain degree relates requirements task 
justeson katz describe lin guistic properties technical terminology formulate algorithm identify tech nical terms document 
gorithm deals complex noun phrases technical terms identified gorithm generally highly topical algorithm provide context sensitive information topical incidence meaning ful phrase relative direct environment 
precisely information needed judge content particular segment text 
katz katz acknowledges calls distinct closely related forms burstiness concentrates modelling inter document distributions content words phrases 
uses inter document distri butions inferences probabilities repeat occurrences content words phrases single document 
divergence tween katz done far task subject boundary insertion requires decides ignore issues coincidental tions non topically content words sim ply equates single occurrence non topical oc multiple occurrence topical occur rence 
implemented method assigns estimated significance score measure context dependent properties local burstiness global frequency 
heart solution problem assigning context values topical significance words text summed formula oi fi word calculation number nearest neigh 
significance arctan dx individual word document dx distance word ith near est neighbour 
st nearest neighbour word nearest occurrence word 
nd nearest neighbour nearest occurrence word ignoring st nearest neighbour 
general ith nearest neighbour near est occurrence word ignoring st nd rd th nearest neighbours 
total number words text 
number occurrences word number nearest neighbours include calculation depends frequency word text 
formula yield significance score lies range high significance low significance 
number normalised indicating low sig indicating high significance 
exact value calculated separately distinct word formula essentially sigmoid function range varying shown fig ure 
constants scale translate function yield desired behaviour derived empirically 
number nearest neighbours consider equation increases word fre quency 
example calculating signif ci word posi text significance values 
frequent words near est neighbours considered 
frequently occurring words number nearest neighbours 
shows main features performance significance assignment gorithm tested sample text 
results different words shown 
general trends important fea tures graph 
firstly elevated significance scores associated local clusters word 
example cluster occurrences soft ware content word document high significance scores 
contrasts relatively isolated occurrences word soft ware middle document deemed little significant oc word function word 
sec frequent words tend receive lower signifi cance scores 
example local clusters word receive relatively low significance scores simply word high frequency document 
conversely high semantic content word occurs cluster receives high significance value 
important result shown graph content words real names re higher significance values function words 
optimal solution problem balancing local density global frequency elusive 
example words centre cluster automatically receive higher score may desirable members cluster assigned score lying narrower range 
contentious issues need investigated ratio occurrences word text total length text order calcu late relative significance measure 
tuition partly derived katz discussion katz relationship document length word frequency exact nature rela various document lengths may reliable 
may consistent consider ratio constant window size words 
advantage simple statistical method distinguishing significant content words non content words words need removed allowing algorithm proceed 
put stage normalised significance score word text 
significance score taken account analysing text subject boundaries 
calculate biased lexical correspondences stage consider sets words set set main aim stage processing concerned calculating correspondence mea sure sets depending similar similarity defined measure lexical correspondence 
words shared set lexical correspondence sets high 
sets share words correspondence low 
subset contains words occur subset contains words occur lexical correspon dence sets calculated simple formula correspondence yields value range 
iai re written adding word word significance value described stage algorithm information taken account re defining iai sl sl significance value assigned word second 
done 
formula takes average biased ratios 
means word counting set counts significance value value insignificant highly significant 
result word affects correspondence measure significance text 
set set word sets 
far word occurs contributes zero jan 
means highly significant word occurring exactly effect insignificant word occurring words significance biasing place words appear formula correspondence subset contains words occur sim subset contains words occur shown 
recall calculated adding word set summing significance values words set 
stage processing looks output significance calculation stage considers sentence break turn starting top document working 
algorithm assigns correspondence measure sentence break follows firstly set generated tak ing words previous fifteen sentences 
set generated words fifteen sentences 
sets generated described formula applied assigns cor value sentence break currently consideration 
algorithm moves sentence break repeats process 
output stage algorithm list sentence break numbers num ber sentences document lexical cor measure 
numbers provide input stage smoothing 
fifteen sentences turns optimum win dow size vast majority texts 
average segment size 
smoothing stage graph plotted lexical correspondence axis sentence number axis 
order distinguish significant peaks troughs minor fluctuations simple smoothing algorithm 
neighbouring points graph 
smoothing 
iui line bisected point labelled perturbed constant amount dee pendent distance new point labelled new 
performed simultaneously ev ery point graph 
process iterated fixed number times 
result noise flattened larger peaks troughs remain slightly smaller 
output stage simply sentence break numbers new smoothed correspon dence values 
inserting subject boundaries stage considering graph described previous sec tion generating subject boundaries simply mat ter identifying local minima graph 
confidence boundary calculated depth local minimum 
depth calcu lated simply average heights peak relative height minimum side minimum 
yields list candidate subject boundaries associated confidence measure 
breaks original text places correspond ing local minima confidence value sat minimum confidence criterion 
cut criterion arbitrary implementation specified run time 
results shows result processing sentences edition times 
sentence number axis plotted correspondence axis win text side sentence 
ao go sentence sentence sentence sentences times newspaper 
actual subject boundaries boundaries error algorithm table times large negative value indicates low degree correspondence small negative value pos itive value indicates high degree correspondence 
vertical lines mark actual article boundaries 
advantage text doubt human judge boundaries occur articles 
local minima graph signify bound aries determined algorithm 
vertical bars signify actual article boundaries 
re sults sentences summarised table 
algorithm located article bound aries precisely boundaries accuracy single sentence 
article boundary identified accuracy sentences 
algorithm paragraph markers 
additional subject boundaries middle articles 
denoted error column 
ex tra subject boundaries long article starting sentence 
worth noting minima occurring article pronounced actual article boundaries selves 
section graph reflects long arti cle contains number different subtopics 
newspaper easy test algorithm 
shows graph expository text sentence psychology written fellow student 
local minima indicate algorithm considers subject boundary occur vertical lines obvious breaks text mainly new headings judged author 
results summarised table 
time algorithm precisely located boundaries 
boundaries accuracy single sentence actual subject boundaries boundaries error algorithm table expository text accuracy sentences 
level accuracy obtained consistently variety different texts 
mentioned algorithm breaks obvious human judge 
noted extra breaks usually de noted smaller minima inspection vast majority sensible places 
algorithm certain resolving power 
subject matter neous number subject breaks algorithm finds decreases 
texts results divisions 
smaller win dow size number sentences look side possible sentence break resolving power algorithm increased making sensitive changes vocabulary 
reliability algorithm decreases increased resolving power 
default window size fifteen sentences works homogeneous texts 
case window size effective 
lower window size increases resolving power de creases accuracy algorithm 
window size parameter implementation 
expository text 
summary investigation believe hearst original intuition lexical correspondences exploited identify subject boundaries sound 
addition significance measure repre sents improvement hearst algorithm imple mented berkeley digital library project 
furthermore algorithm language indepen dent preprocessing stage omitted modest degradation formance 
order improve accuracy language dependent methods considered 
meth ods include insertion conventional dis course markers order detect preferred breaking points repetition syntactic struc ture conventional paragraph openings hand 
method thesaurus human judgement synonymous information real syn anaphora 
issues discussed various articles morris hirst mor ris study discourse markers synonymous information 
interesting line research information stage algorithm discover significant words section attach label 
particu useful information retrieval applications 
problem set assignment data intensive linguistics course organised chris brew hcrc edinburgh university 
jo calder marc moens guidance advice project 
ep src funding 
church gale 

poisson mix tures 
natural language engineering 

topic continuity discourse quantitative cross language study 
john benjamins publishing 
hearst 
multi paragraph segmentation expository text 
acl las cruces nm 
justeson katz 

technical ter linguistic properties algo rithm identification text 
natural language engineering 
katz 
distribution context words phrases text language modelling 
natural language engineering 
morris 
lexical cohesion thesaurus structure text 
technical report csri computer systems research institute uni versity toronto 
morris hirst 

lexical cohesion computed thesaural relations indicator structure text 
computational linguis tics 
