
draft chapter 
gesture recognition matthew turk microsoft research primary goal virtual environments support natural efficient powerful flexible interaction 
interaction technology overly obtrusive awkward constraining user experience synthetic environment severely degraded 
interaction draws attention technology task hand imposes high cognitive load user burden obstacle successful virtual environment experience 
traditional dimensional keyboard mouse oriented graphical user interface gui suited virtual environments 
synthetic environments provide opportunity utilize different sensing modalities technologies integrate user experience 
devices sense body position orientation direction gaze speech sound facial expression skin response aspects human behavior state mediate communication human environment 
cross product communication modalities sensing devices wide range unimodal multimodal interface techniques 
potential techniques support natural powerful interfaces communication virtual environments appears promising 
fully support natural communication want track human movement interpret movement order recognize semantically meaningful gestures 
tracking user head position hand configuration may quite useful directly controlling objects inputting parameters people naturally express communicative acts higher level constructs speech gesture shown schematically 
want interpret output position sensing allow users communicate naturally effortlessly 
goes 
gesture control navigation caves virtual environments smart rooms virtual environments performance spaces 
addition gesture may perceived environment order transmitted compression technique reconstructed receiver 
gesture recognition may influence intentionally unintentionally system model user state 
example look frustration may cause system slow presentation information urgency gesture may cause system speed 
gesture may communication backchannel indicate agreement participation attention conversation turn human body express huge variety gestures appropriate sense 
clearly position orientation body part parameters articulated body model useful features derived measurements velocity acceleration 
facial expressions expressive 
subtle cues hand tension muscle tension locations self contact pupil dilation may 
chapter handbook covered technologies track head hands body 
include instrumented gloves body suits marker optical tracking 
gesture recognition applied virtual environments tracking technologies input 
chapter covered eye tracking devices discussed limitations tracking gaze direction 
chapter cover interpretation tracking data devices order recognize gestures 
focus additional attention passive sensing cameras computer vision techniques recognize gestures 
visual verbal behaviors nodding saying uh huh indicate continue raising finger indicate desire interrupt 

nature gesture gestures expressive meaningful body motions physical movements fingers hands arms head face body intent convey information interact environment 
ref described functional roles human gesture semiotic communicate meaningful information manipulate environment epistemic discover environment tactile experience 
gesture recognition process gestures user known system 
argue gui systems standard mouse keyboard actions selecting items issuing commands gestures interested trivial cases 
static position referred posture configuration pose technically considered gesture include purposes chapter 
virtual environments users need communicate variety ways system users remote environments 
communication tasks include specifying commands parameters navigating space specifying items interest manipulating objects environment changing object values controlling virtual objects issuing task specific commands addition user initiated communication virtual environment system may benefit observing user behavior purposes analysis usability analysis user tasks monitoring changes user state better understanding user intent emphasis communicating user behavior users environments 
messages expressed gesture ways 
example emotion sadness communicated facial expression lowered head position relaxed muscles movement 
similarly gesture indicate simply raised hand palm facing forward exaggerated waving hands head 
general exists mapping concept gesture gestures ambiguous mapping gesture concept gestures completely specified 
speech handwriting gestures vary individuals vary instance instance individual subject effects articulation 
interesting real world example gestures visual communications army field manual serves guide commonly visual signals including hand arm gestures variety situations 
despite richness complexity gestural communication researchers progress understand describe nature gesture 
kendon described gesture continuum depicted defining different kinds gestures spontaneous movements hands arms accompany speech language gestures integrated spoken utterance replacing particular spoken word phrase gestures depict objects actions accompanying speech familiar gestures victory thumbs assorted gestures culturally specific sign languages linguistic systems american sign language defined 
list progresses moving left right association speech declines language properties increase decreases social regulation increases 
goes 
category spontaneous speech associated gesture mcneill defined gesture types iconic representational gestures depicting feature object action event described metaphoric gestures represent common metaphor object event directly beat small gestures associated word emphasis deictic pointing gestures refer people objects events space time 
types gesture modify content accompanying speech may help disambiguate speech similar role spoken intonation 
cassell describe system models relationship speech gesture generates interactive dialogs dimensional animated characters gesture speak 
spontaneous gestures kendon continuum human gestures 
people gesture telephone blind people regularly gesture speaking 
cultures speech associated gesture natural common 
human computer interface truly natural need develop technology understand speech gesture 
despite importance type gesture normal human human interaction research date hci virtual environment technology focuses right side gestures tend ambiguous spontaneous natural learned culture specific 
gestures gestural languages spontaneous natural carry clear semantic meaning may appropriate kinds command control interaction virtual environments tend support 
main exception recognizing integrating deictic mainly pointing gestures known put system bolt 
remainder chapter focus symbolic gestures includes gestures predefined gesture languages deictic gestures 

representations gesture concept gesture loosely defined depends context interaction 
recognition natural continuous gestures requires temporally segmenting gestures 
automatically segmenting gestures difficult ignored current systems requiring starting position time space 
similar problem distinguishing intentional gestures random movements 
standard way gesture recognition variety representations classification schemes 
gesture recognition systems share common structure 
gestures static user assumes certain pose configuration dynamic defined movement 
mcneill defines phases dynamic gesture pre stroke stroke post stroke 
gestures static dynamic elements pose important gesture phases particularly relevant sign languages 
gestures produced continuously gesture affected gesture preceded possibly gesture follows 
articulation may taken account system trained representation supports 
aspects gesture may relevant may need represented explicitly 
describe aspects gesture may important meaning spatial information occurs locations gesture refers information path gesture takes symbolic information sign gesture affective information emotional quality gesture order infer aspects gesture sense human position configuration movement 
done directly sensing devices magnetic field trackers instrumented gloves attached user indirectly cameras computer vision techniques 
sensing technology differs dimensions including accuracy resolution latency range motion user comfort cost 
integration multiple sensors gesture recognition complex task sensing technology varies dimensions 
output sensors directly control parameters navigation speed direction movement virtual object interested interpretation sensor data recognize gestural information 
output initial sensor processing time varying sequence parameters describing position velocities angles relevant body part 
include representation uncertainty indicates limitations sensor processing algorithms 
recognizing gestures parameters pattern recognition task typically involves transforming input appropriate representation feature space classifying database predefined gesture representations shown 
parameters produced sensors may transformed global coordinate space processed produce features directly classification step 
goes 
gestures highly variable person example single person essential capture essence gesture invariant properties represent gesture 
choice representation significant issue building gesture recognition systems create update database known gestures 
hand coding gestures recognized works trivial systems general system needs trained kind learning 
speech recognition systems tradeoff accuracy generality accuracy desired training required 
addition systems may fully trained may adapt time current user 
static gesture pose recognition accomplished straightforward implementation template matching geometric feature classification neural networks standard pattern recognition techniques classify pose 
dynamic gesture recognition requires consideration temporal events 
typically accomplished techniques time compressing templates dynamic time warping hidden markov models hmms bayesian networks 
examples sections 
nice overview hand gesture modeling analysis synthesis huang pavlovic 

pen gesture recognition recognizing gestures dimensional input devices pen mouse considered time 
early sketchpad system light pen gestures example 
commercial systems pen gestures 
examples gesture recognition document editing air traffic control design tasks editing splines 
systems ogi system demonstrated utility pen gesture recognition concert speech recognition control virtual environment 
recognizes pen gestures including map symbols editing gestures route indicators area indicators taps 
oviatt demonstrated significant benefits speech pen gestures certain tasks 
landay myers developed interfaces recognize gestures pen sketching 
commercially available personal digital assistants pdas years starting apple newton com palmpilot various windows ce devices 
pdas perform handwriting recognition allow users invoke operations various albeit quite limited pen gestures 
long landay rowe survey problems benefits gestural interfaces provide insight interface designers 
pen gesture recognition promising hci environments presumes availability proximity flat surface screen 
virtual environments constraining techniques allow user move interact natural ways compelling 
sections cover primary technologies gesture recognition virtual environments instrumented gloves vision interfaces 

tracker gesture recognition number commercially available tracking systems covered chapters input gesture recognition primarily tracking eye gaze hand configuration body position 
sensor type strengths weaknesses context virtual environment interaction 
eye gaze useful gestural interface focus gestures input tracking hands body 

data gloves people naturally hands wide variety manipulation communication tasks 
quite convenient hands extremely dexterous expressive approximately degrees freedom including wrist 
comprehensive thesis hand input sturman showed hand sophisticated input control device wide variety application domains providing real time control complex tasks degrees freedom 
analyzed task characteristics requirements hand action capabilities device capabilities discussed important issues developing hand input techniques 
sturman suggested taxonomy hand input categorizes input techniques dimensions classes hand actions continuous discrete interpretation hand actions direct mapped symbolic resulting categories describe styles hand input 
interaction task evaluated style best suits task 
mulder overview hand gestures human computer interaction discussing classification hand movement standard hand gestures hand gesture interface design 
years commercial devices available measure various degrees precision accuracy completeness position configuration hand 
include instrumented gloves devices mounted hand fingers term data glove include types 
advantages data gloves include direct measurement hand finger parameters joint angles spatial information wrist rotation provides data high sampling frequency easy line sight occlusion problems relatively low cost versions available data translation independent range motion disadvantages data gloves include calibration difficult tethered gloves reduce range motion comfort inexpensive systems noisy accurate systems expensive user forced wear somewhat cumbersome device projects hand input data gloves point reach grab operations sophisticated gestural interfaces 
multi agent architecture detecting pointing gestures multimedia application 
nen hm developed neural network system recognized static gestures allows user interactively teach new gestures system 
hm extend dynamic gestures feature map kfm data reduction 
baudel beaudouin lafon developed system provide gestural input computer giving presentation included gesture notation set guidelines designing gestural command sets 
fels hinton adaptive neural network interface translate hand gestures speech 
glove input recognize australian sign language takahashi kishino japanese manual alphabet 
system lee xu learn recognize new gestures online 
despite fact gestures involve hands research efforts glove gesture recognition glove input 
features recognition degree dynamic gestures considered vary quite bit 
hit lab university washington developed class library allows software developers add gesture recognition capabilities sgi systems including user dependent training handed gesture recognition 
commercial version system available general reality 

body suits known viewing small number strategically placed dots human body people easily perceive movement patterns activities gestures identities aspects bodies motion 
way approach recognition human movements postures optically measure position markers attached body recover time varying articulated structure body 
articulated structure may measured directly sensing joint angles positions electromechanical body sensors 
optical systems require dots small balls placed top user clothing refer body motion capture systems generically body suits 
body suits advantages disadvantages similar data gloves provide reliable data high sampling rate electromagnetic devices expensive cumbersome 
calibration typically non trivial 
optical systems typically cameras process data offline major advantage lack wires tether 
body suits data gloves gesture recognition systems 
wexelblat implemented continuous gesture analysis system data suit data gloves eye tracker 
data sensors segmented time movement inaction key features extracted motion analyzed set special purpose gesture recognizers look significant changes 
picard developed instrumented jacket conductor includes physiological monitoring study correlation affect gesture musical expression 
current optical electromechanical tracking technologies cumbersome contrary desire natural interfaces advances sensor technology enable new generation devices including stationary field sensing devices gloves watches rings just useful current trackers obtrusive 
similarly instrumented body suits currently exceedingly cumbersome may displaced sensing technologies embedded belts shoes shirts pants 
sensing technology long way go reach ideals passive sensing computer vision techniques headway user friendly interface technology 

vision gesture recognition significant disadvantage tracker systems section cumbersome 
detracts immersive nature virtual environment requiring user don unnatural device easily ignored requires significant effort put calibrate 
optical systems markers applied body suffer shortcomings albeit severely 
wished technology provides real time data useful analyzing recognizing human motion passive non obtrusive 
computer vision techniques potential meet requirements 
vision interfaces cameras capture images frame rate hz interpret images produce visual features interpret human activity recognize gestures 
typically camera locations fixed environment may mounted moving platforms people 
past decade significant amount research computer vision community detecting recognizing faces analyzing facial expression extracting lip facial motion aid speech recognition interpreting human activity recognizing particular gestures 
sensors worn body vision approaches body tracking contend occlusions 
point view camera parts user body occluded visible back side user visible camera front 
significantly self occlusion prevents full view fingers hands arms body single view 
multiple cameras adds correspondence integration problems 
occlusion problem full body tracking difficult impossible strong model body kinematics dynamics 
recovering parameters body motion may prerequisite gesture recognition 
fact people recognize gestures leads possible infer parameters directly observe don need parameters accomplish task infer ignore 
mistake consider vision tracking devices data gloves body suits alternative paths 
overlap provide technologies general produce qualitatively quantitatively different output enable different analysis interpretation 
example tracking devices principle detect fast subtle movements fingers user waving hands human vision case best get general sense type finger motion 
similarly vision properties texture color analysis gesture tracking devices 
research perspective observations imply may optimal strategy merely substitute vision date system developed data glove body suit vice versa 
special devices measure human position motion vision uses multipurpose sensor device recognize gestures recognize objects environment transmit video teleconferencing surveillance purposes 
growing interest cmos cameras promise miniaturized low cost low power cameras integrated processing circuitry single chip 
integrated processing sensor conceivably output motion gesture parameters virtual environment 
currently computer vision systems recognition look 
analog cameras feed signal digitizer board may dma transfer directly host memory 
digital cameras bypass analog digital conversion go straight memory 
may preprocessing step images normalized enhanced transformed manner feature extraction step 
features may variety dimensional features statistical properties estimated body parameters analyzed classified particular gesture appropriate 
vision systems gesture recognition vary number dimensions notably number cameras cameras 
combined early stereo late multi view 
speed latency system real time fast low latency support interaction 
structured environment restrictions background lighting speed movement 
user requirements user wear special markers gloves long 
disallowed glasses beard rings 
primary features low level features computed edges regions silhouettes moments histograms 
dimensional representation system construct dimensional model body part classification done view representation 
representation time temporal aspect gesture represented recognition state machine dynamic time warping hmms time compressed template 

head face gestures people interact assortment cues head face convey information 
gestures may intentional unintentional may primary communication mode backchannels span range extremely subtle highly exaggerated 
examples head face gestures include nodding shaking head direction eye gaze raising eyebrows opening mouth speak nostrils looks surprise happiness disgust anger sadness people display wide range facial expressions 
ekman friesen developed system called facs measuring facial movement coding expression description forms core representation facial expression analysis systems 
real time system recognize actions head facial features developed zelinsky feature template tracking kalman filter framework recognize thirteen head face gestures 
moses fast contour tracking determine facial expression mouth contour 
essa pentland optical flow information physical muscle model face produce accurate estimates facial motion 
system generate spatio temporal motion energy templates face different expression templates expression recognition 
oliver describe realtime system tracking face mouth recognized facial expressions head movements 
ohya model coarticulation facial expressions hmm recognition 

hand arm gestures hand arm gestures receive attention study gesture fact gesture recognition consider hand arm gestures 
vast majority automatic recognition systems deictic gestures pointing gestures isolated signs sign languages limited vocabulary syntax 
components bimodal systems integrated speech recognition 
produce precise hand arm configuration coarse motion 
stark kohler developed system recognizing hand poses gestures real time 
segmenting hand background extracting features shape moments fingertip positions hand posture classified 
temporal gesture recognition performed sequence hand poses motion trajectory 
small number hand poses comprises gesture catalog sequence gesture 
similarly described recognized hand gestures head movements 
systems recognize hand postures amidst complex visual backgrounds reported weng cui triesch von der malsburg 
lot interest creating devices automatically interpret various sign languages aid deaf community 
computer vision requiring user wear special built starner hmms recognize limited vocabulary asl sentences 
effort uses hmms recognize sign language netherlands described 
recognition hand arm gestures applied entertainment applications 
freeman developed real time system recognize hand poses image moments orientations histograms applied interactive video games 
cutler turk described system children play virtual instruments interact lifelike characters classifying measurements optical flow 

body gestures section includes tracking full body motion recognizing body gestures recognizing human activity 
activity may defined longer period time normally considered gesture example people meeting open area stopping talk continuing way may considered recognizable activity 
bobick proposed taxonomy motion understanding terms movement atomic elements motion activity sequence movements static configurations action high level description happening context research date focused levels 
pfinder system developed mit media lab number groups body tracking gesture recognition 
forms dimensional representation body statistical models color shape 
body model provides effective interface applications video games interpretive dance navigation interaction virtual characters 
combined pfinder speech recognition interactive environment called visualization space allowing user manipulate virtual objects navigate virtual worlds 
paradiso sparacino pfinder create interactive performance space dancer generate music graphics body movements example hand body gestures trigger rhythmic melodic changes music 
systems analyze human motion virtual environments may quite useful medical rehabilitation athletic training 
example system developed boyd little recognize human gaits potentially evaluate rehabilitation progress 
yamamoto describe system computer vision analyze body motion order evaluate performance 
davis bobick view approach representing recognizing human action temporal templates single image template captures history motion 
technique system interactive immersive narrative environment children 
nice online description project vismod www media mit edu vismod demos 
video surveillance monitoring human activity received significant attention years 
example system developed university maryland tracks people detects patterns activity 

suggestions system design little evaluating utility usability gesture recognition systems 
developing gestural systems learned number lessons way 
guidelines form dos don ts gestural interface designers 
inform user 
discussed section people different kinds gestures purposes spontaneous associated speech structured sign languages 
similarly gesture may play number different roles virtual environment 
compelling gesture types gestures allowed effect clear user 
give user feedback 
feedback essential user know gesture recognized 
inferred action taken system action obvious subtle visual audible confirmation methods 
take advantage uniqueness gesture 
gesture just substitute mouse keyboard 
understand benefits limits particular technology 
example precise finger positions better suited data gloves vision techniques 
gloves body suits may constrain user movement 
usability testing system 
don just rely designer intuition 
avoid temporal segmentation feasible 
current state art segmentation gestures quite difficult 
don tire user 
gesture seldom primary mode communication 
user forced frequent awkward precise gestures user quickly 
example holding arm air repeated hand gestures quickly 
don gestures recognized similar 
ease classification help user 
don gesture 
better done mouse keyboard speech device mode extraneous gesture avoided 
don increase user cognitive load 
having remember wheres gestural interface user 
system gestures intuitive simple possible 
learning curve gestural interface difficult mouse menu interface requires recall just recognition list 
don require precise motion 
especially space tactile feedback difficult highly accurate repeatable gestures 
don create new unnatural gestural languages 
necessary devise new gesture language intuitive possible 

summary directions research efforts referenced chapter just sampling omitted sake brevity 
sources gesture recognition proceedings gesture workshops ref ref ref international conferences automatic face gesture recognition ref ref ref 
done gestural interfaces track recognize human activities pervasive cost effective masses 
progress past decade continuing march computers sensors faster smaller ubiquitous cause optimism 
pdas pen computing continue proliferate pen dimensional gestures common technology transfer dimensional hand head body gestural interfaces 
similarly technology developed surveillance security areas find uses gesture recognition virtual environments 
technology discussed chapter benefits limitations 
devices worn held pens data gloves body suits currently advanced evidenced fact commercial products available 
passive sensing cameras sensors promised powerful general obtrusive technologies 
camps continue improve exist systems new sensing technologies arise give choice virtual environment developers 
savage 

adding intelligence interface 
proceedings ieee virtual reality annual international symposium pp 

piscataway nj ieee press 
cruz defanti surround screen projection virtual reality design implementation cave computer graphics proceedings siggraph acm siggraph august pp 

pavlovic sharma huang gestural interface visual computing environment molecular biologists proc 
second international conference automatic face gesture recognition killington vt oct 
shafer krumm brumitt meyers czerwinski robbins new easyliving project microsoft research proc 
joint darpa nist smart spaces workshop gaithersburg maryland july 
kr ger fr hlich sch th strauss responsive workbench virtual environment ieee 
fels mase graphical musical instrument ieee multimedia magazine vol 
jul sep pp 

les 
gesture recognition www washington edu eve html 
visual signals army field manual fm sept available html 
kendon relationships body motion speech pope eds studies dyadic communication new york pergamon press 
mcneill hand mind gestures reveal thought 
chicago university chicago press 
mcneill 

think gestures nonverbal 
psychological review 
vol jul cassell steedman badler pelachaud stone douville prevost modeling interaction speech gesture proceedings sixteenth conference cognitive science society august 
bolt put voice gesture graphics interface computer graphics 
meaningful gestures human computer interaction hand gestures proc 
third international conference automatic face gesture recognition nara japan apr 
huang pavlovic hand gesture modeling analysis synthesis proc 
international workshop automatic face gesture recognition zurich june 
johnson sketchpad iii dimensional graphical communication digital computer afips spring joint computer conference 


pp 

kurtenbach buxton 
testbed editing contiguous gesture 
sigchi bulletin 
rubine automatic recognition gestures 
ph dissertation carnegie mellon university 
gesture recognition interactive graphical radar image edwards eds progress gestural interaction proceedings gesture workshop springer verlag 
baudel mark interaction paradigm free hand drawing proc 
acm symposium user interface software technology uist cohen johnston mcgee oviatt pittman smith chen 

multimodal interaction distributed applications proceedings fifth annual international multimodal conference multimedia seattle wa november acm press pp 
oviatt multimodal interfaces dynamic interactive maps proceedings chi human factors computing systems 
acm press ny 
zeleznik herndon hughes sketch interface sketching 
computer graphics proceedings siggraph august landay myers 
interactive sketching early stages user interface design 
proceedings chi pages 
long landay rowe pda gesture uses practice insights designers pen user interfaces report csd cs division eecs department uc berkeley berkeley ca 
january 
sturman hand input ph thesis mit media laboratory cambridge ma february 
mulder hand gestures hci technical report school simon fraser university february 
exploiting distant pointing gestures object selection virtual environment fr hlich eds gesture sign language human computer interaction proc 
international gesture workshop bielefeld germany sept 
nen hm gesture driven interaction human factor virtual environments approach neural networks proc 
virtual reality systems british computer society academic press 
hm dynamic gesture recognition neural networks advanced interaction construction fisher eds stereoscopic displays virtual reality systems spie conference electronic imaging science technology vol 
san jose ca 
baudel beaudouin lafon charade remote control objects free hand gestures communications acm vol 
july 
fels hinton glove adaptive gesture formant interface chi denver may 
computer recognition signs proc 
workshop integration gesture language speech de october 
takahashi kishino 
gesture coding experiments hand gesture interface device 
sigchi bulletin april 
lee xu 
online interactive learning gestures human robot interfaces 
ieee international conference robotics automation minneapolis mn 
vol 
pp 
www washington edu people html www com johansson spatio temporal differentiation integration visual motion perception psychological research pp 

rashid system interpretation moving light display pami november pp 

wexelblat feature approach continuous gesture analysis thesis mit media laboratory cambridge ma june 
picard 
conductor jacket testbed research gestural affective expression 
xii colloquium musical informatics italy september 
paradiso hu hsiao wireless multisensor interface dancer feet proc 
international dance technology tempe az feb 
smith white dodge allport paradiso gershenfeld 
electric field sensing graphical interfaces ieee computer graphics applications vol 
may june pp 

fletcher gershenfeld application smart materials wireless id tags remote sensors materials research society fall meeting 
kemeny gee pain kim cmos active pixel image sensors highly integrated imaging systems accepted publication ieee solid state circuits 
ekman friesen 

facial action coding system technique measurement facial movement 
palo alto calif consulting psychologists press 
zelinsky real time visual recognition facial gestures human computer interaction proc 
second international conference automatic face gesture recognition killington vt oct 
moses reynard blake determining facial expressions real time proc 
fifth international conference computer vision cambridge ma 
essa 
pentland 
coding analysis interpretation recognition facial expressions ieee transactions pattern analysis machine intelligence volume ieee computer society press july 
oliver pentland rard lips face real time tracker proc 
ieee conference computer vision pattern recognition puerto rico june 
ohya recognizing abruptly changing facial expressions time sequential face images proc 
ieee conference computer vision pattern recognition santa barbara ca june 
stark kohler video gesture recognition human computer interaction ed modeling virtual worlds distributed graphics november 
history design applications cipolla pentland eds computer vision human machine interaction cambridge university press 
weng cui recognition hand signs complex backgrounds cipolla pentland eds computer vision human machine interaction cambridge university press 
triesch von der malsburg robust classification hand postures complex backgrounds proc 
second international conference automatic face gesture recognition killington vt oct 
starner pentland visual recognition american sign language hidden markov models proc 
international workshop automatic face gesture recognition zurich june 
video sign language recognition hidden markov models fr hlich eds gesture sign language human computer interaction proc 
international gesture workshop bielefeld germany sept 
freeman tanaka ohta computer vision computer games proc 
second international conference automatic face gesture recognition killington vt oct 
cutler turk view interpretation real time optical flow gesture recognition proc 
third international conference automatic face gesture recognition nara japan apr 
bobick movement activity action role knowledge perception motion royal society workshop knowledge vision man machine london england february 
wren azarbayejani darrell pentland pfinder real time tracking human body proc 
second international conference automatic face gesture recognition killington vt oct 
george visualization space testbed multimodal user interface intelligent environments symposium aaai spring symposium series stanford ca march 
paradiso sparacino optical tracking music dance performance fourth conference optical measurement techniques zurich switzerland september october 
boyd little shape motion perception human gaits ieee workshop empirical evaluation methods computer vision cvpr santa barbara ca june 
yamamoto kondo skill recognition proc 
third international conference automatic face gesture recognition nara japan apr 
davis bobick representation recognition human movement temporal trajectories proc 
ieee conference computer vision pattern recognition puerto rico june 
bobick intille davis baird pinhanez campbell ivanov sch tte wilson perceptually interactive immersive story environment mit media lab perceptual computing section technical report november 
revised june 
haritaoglu harwood davis 



real time system detecting tracking people proc 
third international conference automatic face gesture recognition nara japan apr 
coutaz crowley interpreting human gesture computer vision workshop gesture user interface chi denver 
boulic thalmann multi level modelling recognition human actions involving full body motion acm conf 
autonomous agents marina del rey notes term data glove okay generically 
insert figures papers 
communicative intent sensor processing language gestures body parameters positions angles velocities uncertainty communicative modalities 
communication 

kendon gesture continuum feature extraction feature space representation 
pattern recognition systems communicative acts gesture classification gesture db sign languages recognized gestures 
