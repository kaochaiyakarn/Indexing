reducing tlb misses matrix multiplication flame working note goto robert van de department computer sciences university texas austin austin tx cs utexas edu november decade number projects pursued high performance implementation matrix multiplication 
typically projects organize computation inner kernel keeps operands cache streaming parts operands cache 
variants include approaches extend principle multiple levels cache apply principle cache essentially ignoring cache 
intent optimally amortize cost moving data memory layers 
approach proposed fundamentally di erent 
start observing current generation architectures overhead comes translation look aside bu er tlb table misses 
importance caches taken consideration minimization tlb misses drives approach 
result novel approach achieves highly competitive performance broad spectrum current high performance architectures 
somewhat surprising decades research optimal implementation matrix multiplication papers subject appear great regularity 
matrix multiplication continues importance broad range high performance packages support directly indirectly scienti computation depend large degree performance matrix multiplication kernel 
new contributions continue gap performance cpu bandwidth memory continues widen new architectural features introduced computers require new techniques re nements old techniques matrix multiplication 
observations fundamental approach ratio rate oating point computation performed oating point unit rate oating point numbers streamed cache typically relatively small 
cost starting streaming data cache represents signi cant overhead 
large component startup cost streaming data translation look aside bu er tlb misses inherently stall cpu 
observations account contribution casting matrix multiplication terms inner kernel performs operation lls memory addressable tlb table computed columns time tlb misses largely avoided cost tlb misses occur amortized large amount computation cost transposing submatrices matrix multiplication cast inner kernel amortized large amount computation 
practice observations lead implementations attain extremely high performance 
argued exact nature new contribution hard identify 
incorporated form implementations matrix multiplication 
argued known street wisdom incorporated proprietary libraries keep details implementation trade secret 
think exposes issues explicitly contribution body knowledge area 
fact method leads consistently higher performance achieved competing implementations provides support view 
structure follows section discuss research related highperformance implementation matrix multiplication 
basic architectural considerations section 
observations show importance tlb section 
observations translated practical implementation section 
section report performance results implementations various architectures 
concluding remarks follow nal section 
related addition cache memory vector architectures required library developers reformulate linear algebra libraries written terms vector operations 
obtain high performance new machines vector operations blocking take advantage cache necessary 
ibm library included block vector algorithms number linear equation solvers part linpack including lu cholesky solvers dense banded matrices 
implementations highly optimized linear algebra routines performed blocking inner kernel vectorized linear algebra operation blocks cache memory 
wasn late cray combined vector processing cache memory strong impetus linear algebra library community standardize new interface set matrix matrix operations level blas 
primary purpose new set routines support newly proposed libraries lapack 
casting bulk computation terms matrix matrix operations perform operations data blocks data moved data cache amortizing cost movement large number computations 
substantial task providing levels blas pushed vendors 
reward numerically stable libraries lapack provided high performance large variety architectures 
early recognized architectures increasingly complex task providing complete set especially level blas substantial burden vendors 
fortunately shown high performance level blas coded portable casting operations terms matrix multiplication 
reduced cost implementing level blas cost implementing matrix multiplication 
recognized combining blocking strategy carefully crafted inner kernel performs matrix multiplication blocks roughly size cache memory cost implementing level blas reduced cost implementing inner kernel 
ibm idea designing architecture approach coding matrix multiply algorithms referred algorithms architectures expounded applied development ibm power architecture conjunction library architecture 
designing compilers speci cally combination algorithms architecture implementations blas coded fortran assembly code 
late architectures multiple levels cache memory introduced 
came recognition implementation matrix multiplication architecture remain formidable task 
ibm coded operations fortran project berkeley pursued portable implementation matrix multiplication high level language 
idea project automatically generate code combination exhaustive search optimal blocking operands optimal ordering loops discovered 
di erent blocking schemes intended automatically detect optimal di erent caches di erent loop orderings automatically detect movement blocks memory layers best amortized computation 
addition inner kernel automatically generated number registers depth pipelines detected 
expense optimization process took days weeks complete remarkable performance observed 
atlas project university tennessee re ned techniques developed part fast slow registers cache cache 
ram disk expensive cheap registers cache tlb addr 
cache 
ram disk old model new model hierarchical memories viewed pyramid 
new model memory addressable tlb explicitly exposed 
project constraining number di erent implementations generated part search process 
result optimization process completes quickly typically matter hours 
family algorithms model memory hierarchy introduced 
model predicts preliminary experiments implementation intel pentium iii processor show level memory blocking matrices order loops dictated shapes operands size memory layer level pyramid 
algorithms automatically block caches formulating algorithms recursive received great deal attention matrix multiplication important computations matrix factorizations 
focused applying recursion produce new data formats matrices traditional fortran data structures 
view recursion powerful excellent results obtainable 
techniques sense orthogonal addressed recursion data storage algorithm implementation 
basic architectural considerations section high level abstraction architectural features typical modern microprocessor 
memory hierarchy modern microprocessor viewed pyramid fig 

top pyramid processor registers extremely fast access 
bottom disks slower media 
goes pyramid amount memory increases time required access memory nancial cost memory decreases 
second architectural consideration relates page management system 
typical modern architecture uses virtual memory size usable memory constrained size physical memory 
memory partitioned pages xed prescribed size 
table referred page table maps virtual addresses physical addresses keeps track page memory disk 
problem table large mbytes hampers speedy translation virtual addresses physical addresses 
overcome smaller table translation look aside bu er tlb stores information pages kept 
virtual address tlb translation fast 
tlb occurs page table consulted resulting entry moved page table tlb 
signi cant di erence cache tlb cache necessarily stall cpu 
small number cache misses tolerated algorithmic prefetching techniques long data read fast memory exist arrives cpu time needed computation 
tlb contrast causes cpu stall tlb updated new address 
words prefetching mask cache tlb emphasizing tlb consider multiplication ab partition 

cm cmn 

am 

bk partitionings conformal ij ip pj ij loop ordering compute multiplication algorithm ij ip pj ij endfor endfor endfor typical approach optimizing matrix multiplication starts writing inner kernel compute ij ip pj ij approach property cpu attains near optimal performance ip remains cache elements ij pj streamed lower level memory pyramid 
dimensions ip optimized inner kernel attains best performance 
loop created compute submatrices basic approach options 
bene cial especially ip embedded matrix large leading dimension pack contiguous memory tlb misses reduced 
bene cial transpose ip accesses memory contiguous inner products columns ip pj computed update elements ij algorithm algorithm 
ip 
pn 
endfor endfor assumptions observations 
notice assumptions observations re ect absolute truth 
provide point departure discussion 

optimize individual computation 
ip 
pn 
shape 

order optimize bene cial transpose ip compute 

pn 

observation comes fact allows inner products columns ip pj computed accessing memory contiguously 
prevents severe thrashing cache 

important able complete loop entries creating major bubble stream data computation 
way satisfy assumption store contiguously ensuring accessing create tlb 
prominent overhead comes cost accessing ij pj rst time part computation ij pj ij assume cost includes startup latency cost cost proportional size pj large part latency cost lies cost tlb misses associated rst time ij pj accessed 
picking pj ij relatively large row dimension startup cost amortized elements ij pj important ensure pj ts cache streaming data 
data streamed cpu stall second overhead reduces performance comes transposing packing ip relatively square ll cache 
submatrices ij pj relatively narrow means fewer entries tlb devoted submatrices 
practical approach examine considerations ect implementation matrix multiplication current generation microprocessor intel pentium 
observe architecture bandwidth cache registers time takes load oating point number cache register oating point operations single performed pipeline established 
sake argument assume pipelines lled ratio cost load computation 
provided pipelines kept full approach attain high performance 
partition pick ij pj comprised single column 


mn 

am 



kn notice elements ij pj contiguous memory 

consider computation 
ip 
pn 
implement rst transposing ip computing 

pn 

packed contiguous memory transposition ip ip carefully ordered rst element aligned page ij pj ow tlb table ts cache computed loop ij pj ij endfor principle loaded cache tlb transposition ip pages corresponding loaded cache tlb remain duration computation 
streaming data allow computation individual pj ij achieve optimal performance 
practice modi cation may approach 
example tlb entries may data associated indexing code executed 
note number oating point operations performed loading oating point operation streaming established greater bandwidth cache registers bottleneck 
assume ratio equals integer scheme modi ed pj ij consist columns 
case element loaded ops performed element reaches registers 
notice increases number tlb entries devoted pj ij increases means size may reduced 
speci cally chosen rate ops cycle bandwidth double words cycle registers note number registers computation prefetching play important role proposed scheme 
aren registers support pipeline streaming scheme breaks 
note steps determine approximations various parameters 
determine size tlb table 
determine note 
number tlb entries exceed 
reason generally ij pj columns typically require tlb entries provided column isn split pages 
order corrupt tlb entries devoted entries required rst accessed 

size footprint picked exceed pages memory 

constraint item row column dimensions determined experimentally 
matrix dimensions compaq alpha mhz matrix dimensions compaq alpha mhz performance atlas dgemm matrix multiplication compaq alpha mhz 
left performance 
right rate tlb misses relative memory accesses 
experimental results copy copy question results rst experiment reported fig 
show importance copying transposing blocks matrix ip gure show performance atlas dgemm implementation release compaq workstation equipped alpha mhz processor 
left see matrix dimensions reasonable size performance relatively smooth independent matrix size 
right report number tlb misses relative number double words accessed matrix multiplication 
see matrix size increases number misses increases dramatically 
dimensions matrices hit rate tlb misses dramatically reduced 
conclude small matrices atlas copies transposes ip matrix size importantly leading dimension large tlb concerns issue implementation switches copies transposes 
implementation pentium examine considerations ect implementation double precision real bit matrix multiplication intel pentium processor 
importance bandwidths di erent memory layers size tlb table 
verify parameters reported intel pentium designed simple experiment assembly coded kernel written reads data registers software prefetch techniques ensure constant stream maintained possible 
kernel executed repeatedly reading xed amount data registers 
rst time data data volume kbytes intel pentium ghz size kbytes intel pentium ghz left bandwidth various parts memory hierarchy registers 
right performance function footprint read expect data moved di erent layers cache 
amount data read size layer cache expect resident subsequent iterations bandwidth attained subsequent iterations indication bandwidth layer cache registers 
results reported fig 
left 
fig 
left initial spike corresponds data residing cache 
notice advertised bandwidth cache registers double words cycle cycle observed rate cycle kernel 
performance steady cycle kbytes tlb misses expected start occurring 
decline throughput kbytes size cache 
notice region curve marked dashed line measured throughput di ered markedly trial run 
data streamed main memory bandwidth low steady 
pertinent details regarding architectures summarized table 
report experiments establish optimal size table nd parameter mentioned note equal rate ops cycle bandwidth cycle registers experiment parameter note equal 
greater computed addition reading matrix cache need read elements columns pj cache elements ij layer memory keep attaining optimal bandwidth cache 
fig 
right report performance attained approach di erent dimensions chosen processor pentium clock rate ghz number sse registers cache kbytes cache kbytes bandwidth registers cycle bandwidth registers cycle bandwidth ram registers cycle page size kbytes tlb table size entries tlb accessible memory kbytes rate computation ops cycle table architectural details test platform 
matrix multiply xed large 
notice optimal performance attained occupies kbytes pages 
interesting performance pro les graphs fig 
range kbytes show resemblance 
fig 
left demonstrate picking incorrectly ects performance 
reported experiment picked equal 
theory predicts algorithm perform practice bandwidth cache registers achieved idealized circumstances conservative better amortizes cost bringing elements cache registers yields better performance 
comparison libraries assorted architectures compare resulting performance attained high performance implementations dgemm 
details related architectures libraries tested table 
figs 
right left right left report performance attained intel pentium compaq alpha ibm power intel pentium iii respectively 
graphs compare dgemm implementations provided atlas vendor 
notice small matrices performance implementation su ers due copying submatrices general performance competitive smooth insensitive small changes dimension sizes 
fig 
right compare performance approach dgemm implementation developed jointly researchers ut austin intel 
important realize represents family algorithms 
speci implementation reported chosen cache resident pj ij matrix dimensions intel pentium ghz matrix dimensions intel pentium ghz goto mkl atlas goto mkl atlas left performance di erent choices right performance function matrix dimensions approach goto intel mkl library mkl ut knoxville atlas library atlas 
matrix dimensions compaq alpha mhz goto cxml atlas atlas cxml goto matrix dimensions ibm power mhz smp goto atlas goto atlas performance function matrix dimensions approach goto atlas compaq alpha left ibm power right 
compare compaq cxml ibm libraries 
matrix dimensions intel pentium ghz goto mkl atlas goto mkl atlas matrix dimensions intel pentium ghz goto opt 
orig 
original opt 
goto performance function matrix dimensions approach intel pentium iii 
left comparison atlas mkl 
right comparison 
table details regarding architectures libraries targeted section 
architectures processor pentium alpha power pentium iii clock rate mhz cache kbytes kbytes kbytes kbytes cache kbytes mbytes mbytes kbytes tlb size page size kbytes kbytes kbytes kbytes cache line size bytes bytes bytes bytes ops cycle native library mkl cxml mkl version atlas version matrix dimensions intel dual pentium ghz smp implementation goto mkl atlas goto mkl atlas matrix dimensions intel dual pentium ghz smp implementation goto mkl atlas goto mkl atlas performance dual processor implementations di erent libraries dual pentium processor system 
left performance attained 
right speedup relative performance single processor 
streamed cache 
pentium iii processor making cache resident leads inner kernel achieves higher performance evident spike performance fig 
right matrix sizes relatively small 
optimal dimensions 
implies elements computed moving column turn means leading dimension large tlb incurred accessing new column amortizes computation 
solution current part computed contiguous turn requires current part added appropriate part completion computation 
additional operation creates considerable overhead decreases performance attained 
addition transposition amortized computation translates higher overhead transposition 
interestingly larger matrices approaches attain nearly identical performance 
note fig 
right curve labeled original represents implementation collect data method 
curve labeled opt 
represents optimized version method optimization came improved routine copying transposing data 
attempts match performance approach pentium processor implementation processor successful 
believe due small data cache processor combination relatively small di erence bandwidth registers cache cache 
table performance attained hpl implementation massively parallel linpack benchmark 
matrix dimension performance hpl dgemm nb hpl atlas nb smp implementation described method easily construct smp implementation dgemm 
fig 
compare resulting performance libraries processor system 
picture show raw performance attained speedup dual processor implementation relative single processor implementation 
curve ratio dual single processor implementations library 
impact easily measurable impact described approach summarized looking ect performance attained massively parallel linpack benchmark mp linpack 
linpack benchmark measures performance attained architecture solving linear system equations bit arithmetic lu factorization partial pivoting 
highperformance implementations cast lu factorization terms matrix multiplication 
hpl implementation benchmark experiment 
approach implementing dgemm benchmark compute node processor ghz cluster center computational research university bu alo suny 
machine theoretical peak performance sec 
oating point operations second 
table summarizes benchmark results 
indicated block nb grid sizes obtained extensive experimentation 
details meaning parameters see 
ways insights interpreted 
views kernel computes operation inner kernel view contribution considering architectural features tlb bandwidth di erent memory layers registers level cache data resides kernel operates level cache ip chosen reside low memory hierarchy pyramid possible ort optimally amortize cost copy transpose operations required data contiguous memory 
argue automated systems atlas detect approach part optimization ort 
atlas appears yield intel pentium architecture passes cache placing making cache resident 
resulting implementation considerably slower approach 
possible insights re ne automated systems 
second way interpret method view operation ij ip pj ij inner kernel pj taken cache resident ip accessed rows columns cache 
interpretation method member family matrix multiplication algorithms proposed 
notice underlies implementation discussed experimental section 
experiments di erent member family implemented pentium iii processor 
viewing method importance adding tlb considerations pipelining explicitly model underlies apparent 
observation relatively subtle importance optimizing matrix copy transpose routines 
generally discussed papers optimizing matrix multiplication believe cases incorrect result failure properly optimize routines 
particularly obvious results fig 
right 
supports view alternative schemes storing matrices merit observed 
regardless interprets results fact implementations attain better performance attained high quality orts demonstrates value approach 
additional information additional information visit www cs utexas edu users flame goto acknowledgments indebted dr fred dr john comments earlier draft 
performance numbers massively parallel linpack benchmark gathered compute node dell cluster center computational research university bu alo suny 
dr matthew jones orts obtaining numbers 
agarwal 
exploiting functional parallelism power design high performance numerical algorithms 
ibm journal research development sept 
anderson bai bischof demmel dongarra du greenbaum hammarling mckenney sorensen 
lapack portable linear algebra library highperformance computers 
proceedings supercomputing pages 
ieee computer society press los alamitos california 
anderson bai demmel dongarra greenbaum hammarling mckenney sorensen 
lapack users guide 
siam philadelphia 
je bilmes chee chin jim demmel 
optimizing matrix multiply portable high performance ansi coding methodology 
proceedings international conference supercomputing vienna austria july 
choi dongarra walker 
scalable linear algebra library distributed memory concurrent computers 
proceedings fourth symposium frontiers massively parallel computation pages 
ieee comput 
soc 
press 
james demmel jack dongarra jeremy du anne greenbaum sven hammarling danny sorensen 
development linear algebra library highperformance computers 
technical report mcs tm argonne national laboratory sept 
dongarra bunch moler stewart 
linpack users guide 
siam philadelphia 
jack dongarra jeremy du sven hammarling iain du set level basic linear algebra subprograms 
acm trans 
math 
soft march 
jack dongarra iain du danny sorensen henk van der vorst 
solving linear systems vector shared memory computers 
siam philadelphia pa 
dongarra 
performance various computers standard linear equations software linpack benchmark report 
university tennessee computer science technical report cs oct 

applying recursion serial parallel qr factorization leads better performance 
ibm res 
develop 
kyle gallivan william jalby ulrike meier ahmed sameh 
impact hierarchical memory systems linear algebra algorithm design 
csrd report center supercomputing research development university illinois sept 
john fred greg henry robert van de 
flame formal linear algebra methods environment 
acm trans 
math 
soft december 
john greg henry robert van de 
family high performance matrix multiplication algorithms 
alexandrov jack dongarra ren kenneth tan editors computational science iccs part lecture notes computer science pages 
springer verlag 

recursion leads automatic variable blocking dense linear algebra algorithms 
ibm journal research development 
jonsson om ling 
superscalar level blas going evolution portable high performance library 
om editor applied parallel computing large scale scienti industrial problems lecture notes computer science pages 
springer verlag 
jonsson 
minimal storage high performance cholesky factorization blocking recursion 
ibm res 
develop november 
fred 
new generalized matrix data structures lead variety highperformance algorithms 
ronald ping tak peter tang editors architecture scienti software 
kluwer academic press 
greg henry 
blas block data structures 
theory center technical report ctc tr cornell university feb 
greg henry 
flexible high performance matrix multiply self modifying runtime code 
technical report cs tr department computer sciences university texas austin december 
www cs utexas edu users flame pubs 
ibm 
engineering scienti subroutine library guide release 
fourth edition program number 
jonsson om 
recursive blocked algorithms solving triangular matrix equations part sided coupled sylvester equations 
department computing science hpc report ume university 
om ling van loan 
level blas high performance model implementations performance evaluation benchmark 
lapack working note cs univ tennessee nov 
om ling van loan 
level blas high performance model implementations performance evaluation benchmark 
acm trans 
math 
soft 
whaley dongarra cleary 
hpl portable implementation high performance linpack benchmark distributed memory computers 
www netlib org benchmark hpl 
toledo 
locality lu decomposition partial pivoting 
siam journal matrix 
anal 
appl 
vinod anthony skjellum 
framework high performance matrix multiplication hierarchical abstractions algorithms optimized low level kernels 
concurrency computation practice experience 
robert van de 
plapack parallel linear algebra package 
mit press 
clint whaley jack dongarra 
automatically tuned linear algebra software 
proceedings sc 

