feasibility peer peer web indexing search li boon loo joseph hellerstein frans kaashoek david karger robert morris mit lab computer science uc berkeley lcs mit edu cs berkeley edu kaashoek karger rtm lcs mit edu discusses feasibility peer peer full text keyword search web 
classes keyword search techniques proposed flooding queries overlay network gnutella intersection index lists stored distributed hash table 
simple feasibility analysis resource constraints search workload 
study suggests peer peer network capacity naive search techniques attractive web search 
presents number existing novel optimizations search distributed hash tables estimates effects performance concludes combination optimizations bring problem order magnitude feasibility 
suggests number compromises achieve order magnitude 
full text keyword search web arguably important internet applications 
hard problem google currently indexes documents tiny fraction estimated documents web 
centralized search engines google peer peer web search worth studying reasons 
web search offers stress test architectures 
second search resistant centralized search engines censoring manipulated rankings 
third search robust centralized search demise single server site entire search system 
number systems provide keyword search including gnutella kazaa 
systems simple robust technique flooding queries peers 
estimated number documents systems documents typically music files searches examine file meta data title artist 
systems performance problems workloads smaller web 
class systems achieve scalability structuring data far expense flooding commonly called distributed hash tables dhts 
dhts suited exact match lookups unique identifiers directly support text search 
proposals text search dhts :10.1.1.19.7944
ambitious known evaluation system demonstrated full text keyword search performance documents 
tiny fraction size web 
addresses question web search 
estimates size problem size web index rate people submit web searches 
estimates magnitude fundamental resource constraints capacity internet amount disk space available peer hosts 
analysis communication costs naive web search shows require orders magnitude resources available 
evaluates number existing novel optimizations shows combination reduce costs order magnitude available resources 
outlines design compromises eliminate order magnitude difference 
main contribution evaluation fundamental costs constraints web search 
claim definitive answer web search provide framework debating question 
background query consists set search terms words provided user 
result usually list documents contain terms ranked scoring mechanism 
search engines typically precompute inverted index word posting list identifiers documents contain word 
postings intersected query involving term 
intersection large search engines usually highly ranked documents 
systems typically combine ranking factors may include importance documents frequency search terms close terms occur documents 
fundamental constraints search algorithm feasible depends workload available resources algorithm 
estimate workload 
google indexes web documents conservative assume 
assuming words document inverted index contain document identifiers 
dht docid key retrieve document typically byte hash document content 
large docid space simplifies collision avoidance different peers independently generate inserting documents network 
total inverted index size web bytes 
assume system serve queries second google current load 
search system main resource constraints storage bandwidth 
simplify subsequent discussion concrete estimates informed guesses 
storage constraints peer host system limit disk space store piece index assume gigabyte small fraction size typical pc hard disk 
atypical today large desktop applications installed size gb 
inverted index size bytes require pcs assuming compression 
communication constraints query consumes bandwidth wide area internet total bandwidth consumed queries fit comfortably internet capacity 
importance finding information web assume reasonable consume noticeable fraction internet capacity 
dns uses percent wide area internet capacity optimistically assume web search consume 
way estimate internet capacity look backbone cross section bandwidth 
example sum bisection bandwidths internet backbones 
assuming queries second query communication budget megabits roughly megabyte 
optimistic assessment 
way derive reasonable query communication cost assume query send data size document ultimately retrieved 
assuming average web page size kilobytes leads pessimistic query communication budget kilobytes 
rest assumes optimistic budget megabyte communication query 
basic cost analysis section outlines costs naive implementations common text search strategies partition document partition keyword 
partition document scheme documents divided hosts peer maintains local inverted index documents responsible 
query broadcast flooded peers peer returns highly ranked document 
gnutella kazaa partition document 
flooding query peers required hold index require packets size bytes 
query communication cost megabytes times higher budget 
course peers able devote disk space storing index fewer required communication cost proportionately 
partition keyword scheme responsibility words appear document corpus divided peers 
peer stores posting list word responsible 
dht map word peer responsible 
number proposals way :10.1.1.19.7944
query involving multiple terms requires postings terms sent network 
simplicity discussion assume term query 
cheaper send smaller postings peer holding larger posting list peer perform intersection ranking return highest ranking document identifiers 
analysis queries search engine mit edu shows average query move bytes postings network 
queries involved just term 
mit edu web pages scaling size web pages suggests average query require megabytes requiring factor improvement 
queries expensive average 
consider search 
google reports documents contain contain 
query send gb network exceeding budget 
analysis imply partition promising scheme requiring factor improvement 
focus partition keyword allows draw decades existing research fast inverted index intersection 
see applying variety techniques bring partition keyword scheme order bandwidth consumption document approach 
optimizations section discuss optimization techniques partition keyword 
evaluate optimizations data set mit edu queries web pages crawled mit 
caching precomputation peers cache posting lists sent query hoping avoid receiving queries 
technique reduces average query communication cost mit query trace 
modest improvement attributed fact queries appear trace 
precomputation involves computing storing intersection different posting lists advance 
precomputing term pairs feasible increase size inverted index significantly 
popularity query terms follows zipf distribution effective precompute intersections pairs popular query terms 
term pairs possible term pairs popular terms precomputed mit data set average query communication cost reduced 
compression compression provides greatest reduction communication cost sacrificing result quality 
bloom filters bloom filter represent set compactly cost small probability false positives 
simple round bloom intersection node sends bloom filter posting list 
receiving node intersects bloom filter posting list sends back resulting list 
original sender filters false positives 
result compression ratio result set small propose multiple rounds bloom intersections 
case best case compression ratio assumes intersection empty posting lists similar sizes 
compression ratio increased rounds bloom filter exchange compressed bloom filters give improvement resulting compression ratio approximately 
gap compression gap compression effective gaps sorted posting list small 
reduce gap size propose periodically remap bit hashes dense numbers number documents 
mit data set gap compression dense ids achieves average compression ratio 
gap compression added advantage bloom filters incurs extra round trip time compression ratio independent size final intersection 
adaptive set intersection adaptive set intersection exploits structure posting lists avoid having transfer entire lists 
example intersection requires element exchange implies empty intersection 
contrast computing intersection requires entire posting list transferred 
adaptive set intersection conjunction gap compression 
mit data set upper bound improvement achieved top gap compression resulting compression ratio 
clustering gap compression adaptive set intersection effective posting lists bursty 
utilize statistical clustering techniques group similar documents term occurrences 
assigning adjacent similar documents posting lists 
probabilistic latent semantic analysis plsa group mit web documents clusters 
documents cluster assigned contiguous 
clustering improves compression ratio adaptive set intersection gap compression 
rounds yield little improvement 
technique improvement caching precomputation bloom filters gap compression gc adaptive set gc clustering gc table optimization techniques improvements compromises table summarizes performance gains different techniques proposed far 
promising set techniques result reduction average communication costs 
achieving improvement require distributed renumbering clustering algorithms complex 
reduction leaves average query communication cost order magnitude higher budget 
extra improvement needed 
leads softer realm accepting compromises gain performance 
compromising result quality reynolds vahdat suggest streaming results users incremental intersection 
assuming users usually satisfied partial set matching results allow savings communication users terminate queries early 
incremental intersection effective intersection big relative postings significant number matching results generated needing transfer entire posting list incremental results useful likelihood users terminate queries early increased incremental results prioritized ranking function 
achieve effect fagin algorithm fa conjunction ranking function generate incremental ranked results 
posting lists sorted ranking function top ranked incrementally transferred node intersection 
unfortunately ranking func suggests preferable precompute term pairs big posting lists small intersections reduce storage overhead precomputation 
tions applicable 
examples applicable ranking functions include pagerank term frequencies font sizes 
example ranking function fa proximity query terms 
limiting choices useful ranking functions left incremental results ranked compared results commercial search engines 
alleviate shortcoming propose relevance feedback allows users control change order posting list intersections performed 
leads potential improvements user experiences may result earlier query termination 
incorporating user feedback middle search query introduces number challenges designing appropriate result browsing feedback interfaces 
mentioned earlier incremental intersection results effective final result set big relative intersecting posting lists 
illustrate consider posting lists corresponding intersection 
computing matching results require transferring average elements smaller posting list quantify savings incremental results mit data set 
average computing results incremental intersection results reduction communication cost expect greater performance gains larger web corpus 
savings incremental intersection especially significant expensive queries 
google reports results roughly need shipped retrieve top ranked documents containing 
reduces communication cost significantly kb budget megabyte query 
compromising structure megabyte communication budget derived bisection backbone bandwidth internet 
aggregate bandwidth summed links probably larger bisection 
compromise network structure exploit incremental ranked intersection combined compression unfortunately compression ratio reduced result 
aggregate bandwidth better performance 
proposal replicate entire inverted index copy isp 
rough analysis entire inverted index replicated isps increase communication budget query 
highlights challenges faced building web search engine 
main contribution lies conducting feasibility analysis web search 
shown naive implementations web search feasible mapped possible optimizations 
effective optimizations bring problem order magnitude feasibility 
proposed possible compromises quality results structure system 
combination optimizations compromises bring feasibility range web search 
acknowledgments research conducted part iris project project iris net supported national science foundation cooperative agreement 
ani 
gnutella 
gnutella wego com 
google press center technical highlights 
www google com press highlights 
html 
ingram record industry plays kazaa 
www com 
kazaa 
www com 
deep web surfacing hidden value 
www press umich edu bergman html 
gnutella scale 
really 
www com jpr doc gnutella html 
magazine directory internet service providers 
demaine lopez ortiz munro 
adaptive set intersections unions differences 
proceedings th annual acm siam symposium discrete algorithms soda january 
fagin lotem naor 
optimal aggregation algorithms middleware 
symposium principles database systems 

keyword set search system peer peer networks 
master thesis massachusetts institute technology june 
harren hellerstein huebsch loo shenker stoica 
complex queries dht peer peer networks 
st international workshop peer peer systems iptps march 
hellerstein avnur chou olston raman roth haas 
interactive data analysis control 
ieee computer 
hofmann 
probabilistic latent semantic analysis 
proc 
uncertainty artificial intelligence uai stockholm 
mitzenmacher 
compressed bloom filters 
twentieth acm symposium principles distributed computing august 
page brin motwani winograd 
pagerank citation ranking bringing order web 
technical report stanford digital library technologies project 
ratnasamy francis handley karp shenker 
scalable content addressable network 
proceedings acm conference berkeley ca august 
reynolds vahdat 
efficient peer peer keyword searching 
unpublished manuscript june 
rowstron druschel 
pastry scalable decentralized object location routing largescale peer peer systems 
lecture notes computer science 
stoica morris karger kaashoek balakrishnan 
chord scalable peer peer lookup service internet applications 
proceedings acm sigcomm conference pages 
tang xu mahalingam 
psearch information retrieval structured overlays 
hotnets october 
thompson miller wilder 
wide area traffic patterns characteristics 
ieee network vol 
pp 
november december 
witten moffat bell 
managing gigabytes compressing indexing documents images 
may 
zhao kubiatowicz joseph 
tapestry infrastructure fault tolerant widearea location routing 
technical report ucb csd uc berkeley apr 

