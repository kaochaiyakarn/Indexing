pstore secure peer peer backup system christopher kenneth barr arvind stanley arvind mit edu effort combine research peer peer systems techniques incremental backup systems propose pstore secure distributed backup system adaptive peer peer network 
pstore exploits unused personal hard drive space attached internet provide distributed redundancy needed reliable effective data backup 
experiments node network show files mb dataset retrieved nodes failed 
top reliability pstore includes support file encryption versioning secure sharing 
custom versioning system permits arbitrary version retrieval similar cvs 
pstore provides functionality network bandwidth requires storage capacity simpler local tape backup schemes representative workload 
current backup systems personal small office computer users usually rely secondary site storage data 
site backups provide data redundancy vulnerable localized catastrophe 
sophisticated site backups possible usually expensive difficult manage centralized form redundancy 
independent backup systems current peerto peer systems focus file sharing distributed archiving distributed file systems anonymous publishing 
motivated strengths weaknesses current peer peer systems specific desires users needing backup personal data propose pstore secure peer peer backup system 
pstore provides user ability securely backup files restore files distributed network untrusted peers 
insert pstore developed october december project mit distributed computer systems 
update retrieve delete commands may invoked various user interfaces command line file system gui user needs 
pstore maintains snapshots file allowing user restore snapshot date 
low level versioning primitive permits usage models 
example works progress may backed hourly user revert known copy entire directory tree stored recover disk crash 
pstore primary design goals reliability security resource efficiency 
pstore provides reliability replication copies available servers case servers malicious unavailable 
client data replicated nodes control pstore strives provide reasonable security private data readable owner data remotely deleted owner unwanted changes data easily detected 
backups frequent large pstore aims reduce resource usage sharing stored data exchanging data necessary 
section discusses related systems 
pstore draws strengths discarding functionality adds overhead complexity application specific domain data backup 
section outlines pstore architecture section presents implementation 
section evaluates design terms goals stated section concludes 
related peer peer backup system major components underlying peer peer network backup versioning framework 
done fields individually little literature integrating 
distributed storage systems wealth distributed storage systems 
peer peer file sharing systems napster gnutella wide provide mechanism file search retrieval large group users 
napster handles searches centralized index server gnutella uses broadcast queries 
systems focus information retrieval publishing 
freenet provides anonymous publication retrieval data adaptive peer peer network :10.1.1.10.4919
anonymity provided means including encrypted search keys data caching lookup paths source node spoofing probabilistic time live values 
freenet deletes data infrequently accessed room insertions 
eternity proposes redundancy information dispersal secret sharing replicate data adds anonymity mechanisms prevent selective denial service attacks 
document queries broadcast delivery achieved anonymous remailers 
free haven publius mojo nation secret sharing achieve reliability author anonymity :10.1.1.20.417:10.1.1.125.3017
content distribution system providing secure authenticated access readonly data replicated database 
sf cfs aims achieve high performance redundancy compromising integrity read file system :10.1.1.159.9358
complete database replication cfs inserts file system blocks distributed storage system uses chord distributed lookup mechanism 
past system takes similar layered approach uses pastry distributed lookup mechanism :10.1.1.1.1674
lookups chord pastry scale log number nodes system 
farsite similar cfs provides distributed file system cooperative peers uses digital signatures allow delete operations file data 
systems proposed schemes enforce storage quotas distributed storage system 
mojo nation relies trusted third party increase user quota contributes storage network cpu resources system 
past system suggests smart cards authentication maintain storage quotas :10.1.1.1.1674
system proposes interesting quota scheme peer monitoring nodes monitor peers report badly behaving nodes 
versioning backup existing distributed storage systems discussed intended sharing archiving providing distributed file system 
result systems provide specific support incremental updates versioning 
file changes incremental evolution source code documents aspects binary files significant amount exploiting similarities save bandwidth storage space :10.1.1.10.8444
concurrent versioning system popular software development teams combines current state text file set commands necessary incrementally revert file original state 
network appliances incorporates file system storage devices 
provides transparent snapshots file system selected instances allowing file system data viewed current state time past 
overlap file versions enable reduction network traffic required update older versions files 
rsync algorithm updating files client identical server 
client breaks file fixed size blocks sends hash block server 
server checks version file contains blocks hash value client hashes 
server sends client blocks matching hash instructs client reconstruct file 
note server hashes fixed size blocks byte offset just multiples block size 
reduce time required hashing byte offset rsync algorithm types hash functions 
rsync slower cryptographic hash function fast rolling hash establishes probable match 
lbfs uses file fbl fbl ver 
ver 
ver 
fb fb fb fb fb fb fb file block list file blocks shows file equal sized blocks shows new version added updating file block list adding single new file block 
block hashes help reduce data needs transmitted updating file :10.1.1.10.8444
rsync fixed block sizes lbfs uses content dependent fingerprints determine file block boundaries 
system architecture discussing details pstore architecture overview system works possible implementation 
pstore user invokes pstore client helps generate keys mark files backup 
user notes files important client uses choices decide backup file replicas 
insert file pstore computes identifier specific user file 
identifier chosen way conflict identically named files owned users 
file encrypted symmetric encryption prevent members pstore network seeing potentially private contents 
file broken digitally signed blocks signed metadata assembled indicates blocks reassembled 
metadata blocks inserted peer peer network 
file changes backed changes file stored 
retrieve file user specifies name version browses pstore directory hierarchy 
metadata retrieved indicates look blocks belonging desired version 
file blocks retrieved signatures examined ensure file integrity 
data structures section describes data structures manage files directories versions 
data structures designed reliability security resource efficiency 
file blocks lists file blocks pstore file represented file block list fbl file blocks fb 
fb contains portion file data fbl contains ordered list fbs pstore file 
fbl pieces information fb file block identifier uniquely identify fb content hash unencrypted fb length fb bytes fb data offset original file 
illustrates relationship fbl fbs 
uses notation indicate hash encrypted contents file block traditional file converted pstore file simply breaking file fixed size fbs creating appropriate fbl 
file attributes permissions date creation stored fbl 
fbl contains version information form additional ordered list fbs file version 
fb list new version created adaptation rsync algorithm 
revised algorithm uses fb hash length offset information efficient comparison need retrieve actual fbs 
adaptation extends rsync support varying fb lengths arise addition new fbs pstore file evolves care taken match largest possible portion previous version 
duplicate fbs de duplicates created 
simply referenced fbl 
saves storage space network traffic particularly advantageous low bandwidth network connections 
new changed portions file broken new fbs appropriate size referenced fbl inserted network 
final result depicted pstore file reconstruct version duplicate fbs 
advantage pstore versioning scheme corruption fb necessarily preclude retrieval versions version information unified data cvs 
versions include corrupt fb remain intact 
pstore allows files grouped directories 
pstore directory simply text file listing name file subdirectory contained directory 
directory represented pstore file mechanism directory versioning 
file block lists file blocks encrypted symmetric keys preserve privacy 
contrast peer peer publishing networks encryption aid anonymity deniability content node owners :10.1.1.10.4919
file blocks encrypted convergent encryption 
convergent encryption uses hash unencrypted fb contents symmetric key encrypting fb 
block sharing different users feasible users fb key encryption 
convergent encryption sense shared unencrypted content hash stored external fbl decryption 
encrypted symmetric key derived user private key 
means user encrypted key simplifying key management 
data chunks purposes pstore file insertion retrieval distributed peer peer network fbs treated 
viewed data chunk denoted identifier public metadata digital signature actual data 
data chunk network retrieved specifying identifier 
public metadata signed owner private key owner public key included data chunk 
allows verify view public metadata owner change public metadata 
mentioned pstore uses hash encrypted fb contents file block identifier 
fb retrieved compare rehash data chunk identifier verify data tampered 
public metadata fb chunk contains identifier authentication deleting fb chunks 
fb chunk specified formally follows salt type ka fb fb cfb type indicator fb chunk opposed fbl chunk 
type included ensure correct sharing deletion chunks 
identifier salt replication discussed section 
hash filename poor fbl chunk identifier multiple users similarly named files creating unwanted key collisions 
users file name different contents kept separate maintain consistency privacy 
hash actual fbl poor chunk identifier change version easily recovered current local copy file 
pstore uses namespace filename identifier similar freenet signed subspace keys :10.1.1.10.4919:10.1.1.10.4919
pstore user private namespace notation cryptographic primitives way hash encrypted key decrypted key ka public key belonging private key corresponding ka superscript encryption decryption indicates symmetric scheme public key scheme 
operator indicates concatenation 
user files inserted retrieved eliminating unwanted fbl chunk identifier collisions different users 
pstore user creates private namespace creating private public key pair 
pstore provides flexibility user multiple namespaces users share namespace 
namespace filename identifier formed concatenating private key pstore pathname filename salt 
results hashed form actual identifier 
addition providing unique namespace user allows immediate location known files need traverse directory structure 
fbl chunk specified formally follows path filename salt type timestamp ka fbl deterministic function derive common symmetric key user private key 
timestamp included prevent replay attacks 
type salt similar manner fbs 
public key contained public metadata provides ownership information useful implementing secure chunk deletion described section 
ownership information may useful verifying user exceeding quota 
unfortunately attaching ownership information anonymity difficult pstore 
anonymity primary goal pstore feel acceptable compromise 
content hash public metadata provides mechanism verifying integrity chunk 
hash publicly visible immutable hash data contents chunk match result content hash public metadata 
fbs direct relationship fbl identifier fbl contents 
attacker switch identifiers 
storing identifier fbl public metadata comparing requested search key prevents substitution attacks 
data structures pstore relies chord facilitate peer peer storage due attractive logn guarantees concerning search times 
freenet chord assume specific data access pattern achieve search times integrates nicely pstore primarily data insert usage model 
low level primitive chord burden extraneous functionality ill suited distributed backup system absolute anonymity file caching intermediate nodes 
replication pstore supports exact copy chunk replication increase reliability backup 
chunks stored different peers peer fails chunk retrieved remaining peers 
sophisticated information dispersal techniques exist decrease total storage required maintaining reliability 
pstore uses exact copy chunk replication simplify implementation techniques certainly applicable may included pstore 
distribute chunk replicas randomly identifier space salt added creating identifier 
salt predetermined sequence numbers simplify retrieval replicas 
replication technique differs chain replication user sends data node requesting store copy data pass node counter expired 
malicious broken nodes chain reduce effectiveness chain replication refusing pass data potentially preventing replicas reaching benign nodes 
pstore replication technique avoids problem sending replicas directly target nodes 
systems rely caching frequently accessed files retrieval path increase data replication data backup application poorly suited form caching :10.1.1.159.9358:10.1.1.10.4919
file insertion common file retrieval pstore data backup applications 
accessed backup shared 
fbl user fbl user ver 
ver 
fb fb fb fb ver 
sharing file blocks blocks shared user user shared different versions file user caching lookup path cached owner local machine 
fbs shared rarely accessed 
sharing file sharing peer peer networks pstore user directly local storage space contributes system contains encrypted data users 
encourage fair adequate donation storage space pstore require quota policy amount space available user pstore backups proportional amount personal storage space contributed system 
users vested interest making sure data stored efficiently 
techniques decrease space required store file pstore increase effective pstore capacity owner file 
address issue pstore permits sharing file block level capture redundancy single file different versions files users 
fb sharing occurs explicitly versioning described section 
exploiting similarity versions technique saves storage space reduces network traffic significant performing frequent backups 
fb sharing occurs implicitly duplicate files owned different users 
techniques increase effective capacity user include data compression information dispersal algorithms 
adopt terminology replicas refer copies generated pstore enhance reliability duplicates refers logically distinct files identical content 
implicit fb sharing result hash encrypted contents file block identifier 
convergent encryption ensures identical file blocks encrypted key allowing multiple users securely share fbs 
file sharing users quite common users backup entire disk image disk image contain common operating system application files 
study showed storage space desktop computers microsoft headquarters reclaimed duplicate content removed 
illustrates example users inserted identical file 
notice user modified file inserted new version fbs shared 
shared inserted network private namespace 
users identical different identifiers stored separately network 
content hash fbl fbl identifier permits fbl sharing version histories file attribute information file content identical 
similar technique store inodes cfs :10.1.1.159.9358
unfortunately drastically increases complexity updating file 
entire virtual path traversed find fbl fbl modified virtual path traversed update appropriate hash values 
pstore allowed fbl sharing number shared small version history file attributes shared identical 
pstore source node pstore client asynchronous function call pstore library asynchronous rpc udp socket asynchronous rpc unix socket network backend simulator backend pstore allows sharing directory information actual file data fb sharing keeps version information file attributes distinct user 
deletion assume policy users insert amount data proportional amount storage contributed pstore users may reasonably demand explicit delete operation 
user may want limit number versions fbl remove files free space newer important files 
explicit delete operations peer peer systems rare potential misuse malicious users 
systems freenet chord free haven rely removing infrequently accessed files file expiration dates 
removing infrequently accessed files unacceptable solution pstore definition backups rarely accessed needed 
expiration dates ill suited backup system reasons 
impossible user renew chunks modification longer exist user machine 
second user may unable refresh data due hardware crash exactly case backup needed 
exceptions include publius attaches indicator file acceptable users duplicate indicate file deletion farsite uses digital signatures authorize deletions 
pstore uses digital signatures form public metadata mentioned section 
public metadata thought ownership tag authorizes owner delete chunk 
storage node keeps ownership tag list chunk 
fb chunks chord pstore implementation pstore node chord pstore node chord may ownership tags fbl chunk ownership tag 
user request delete chunk inserting delete chunk network 
delete chunk identifier chunk delete data 
storage node receives delete chunk examines ownership tag associated chunk 
public keys match ownership tags delete chunk delete allowed proceed 
appropriate ownership tag removed ownership tags chunk removed 
provides general form counting prevent deleting chunk users files owned user chunk 
notice malicious user delete chunk ownership tag associated malicious user 
malicious user append ownership tag user remove ownership tag delete command chunk 
chunk remain network long empty 
implementation implemented pstore original code third party libraries encryption algorithms asynchronous programming 
pstore uses rsa public key encryption rijndael aes symmetric key encryption sha cryptographic hashing 
shows components involved pstore implementation 
pstore clients linked pstore library provide various user interfaces 
current implementation provides command line interface inserting updating retrieving deleting single files public private key generation 
addition chord backend peer peer storage simulator backend developed stores chunks local disk debugging evaluation purposes 
runs node network maintains database chunks inserted node 
current system acts proof concept implementation 
certain features pstore architecture omitted 
pstore directories implemented effort handle large files efficiently 
quotas important production pstore system implementation provide mechanism quota enforcement 
evaluation realistic workloads assembled test various aspects pstore evaluate meets goals reliability minimal resource usage 
workload models software development team backs project nightly 
time development process able revert older version file 
consists nightly snapshots development pstore includes total files mb 
workload models individual users occasionally back entire hard disk case emergency 
chose windows machines linux machines redhat mandrake 
due resource constraints modeled disk collecting files 
files chosen pseudo random number generator resulting workload includes total files mb 
final workload contains files mb taken user home directory hourly daily snapshots 
workloads provide diverse testset different file types file sizes number files amounts versioning 
test reliability brought network nodes hosts backed 
ordinarily pstore node separate host hosts allowed manageable test environment successfully retrieved files percent total number failed nodes node network file availability vs node failures logical separation nodes allowed fair reliability study 
nodes killed measure files retrieved remaining nodes percentage entire dataset 
results show backup availability function failed nodes 
denotes number instances file inserted network 
expected increasing increases availability backup set 
consists fewer larger files reliability usually number failed nodes 
nodes left network replicas sufficient bring back files workloads 
observed reliability pstore system generalized follows 
fraction failed nodes uniform assignment chunks nodes due sha hashing probability block available file blocks retrievable blocks available probability small similar availability may maintained network scales long remains unchanged 
remaining experiments rely properties pstore underlying network performed pstore simulator 
simulator allowed analysis performed prior integration chord 
figures show efficiency pstore working 
figures compare techniques maintaining versioned backups local tape back ups tape pstore versioning pstore versioning pstore cvs versioning cvs 
tape test simulated cp command copy files new directory night 
test versioning algorithm described section 
simply inserts additional version different pstore filename creating separate fbl version 
test uses pstore versioning algorithm 
evaluate pstore versioning method established versioning scheme pstore back cvs repository files 
files retrieved manipulated cvs program relying pstore versioning 
tests entire cvs repository file retrieved deleted network 
cvs produce new version new repository file inserted network 
shows network bandwidth usage versioning technique inserting nightly snapshot 
notice snapshot pstore chunk overhead public metadata cause pstore tests bandwidth tape test 
versions test requires bandwidth tape tests pstore versioning avoids inserting identical inter version data network 
cvs test uses drastically bandwidth new version requires retrieval entire cvs repository consequently data associated previous version 
amount bandwidth restoring versions analyzed 
tape tests similar test retrieve entire version 
cvs test drastically bandwidth versions retrieved just desired version 
shows storage required network methods 
stacked white bar indicates additional amount storage required implicit block sharing turned 
versioning block sharing pstore nearly equivalent local tape backup exception storage required chunk overhead 
subsequent versions similar identi bandwidth usage mb storage required mb local tape backup pstore versioning pstore versioning pstore cvs date backup bandwidth usage backup local tape backup pstore versioning pstore versioning pstore cvs block sharing date backup required storage cal implicit block sharing reduce required storage sophisticated versioning algorithms 
cvs tests reap benefit block sharing 
due explicit block sharing versioning increased storage requirement implicit block sharing turned illustrated lack visible white bars tests 
cvs tests able reduce storage required implicit block sharing enabled 
scheme separate version resulting additional fbl overhead scheme uses fixed block sizes regardless similarities previous versions resulting efficient inter version sharing 
clearly rsync algorithm pstore storage required mb actual file data fbl data chunk overhead block size bytes storage vs block size find overlap file versions comparing smaller blocks 
decreasing block size appears simple way decrease required storage pstore versioning 
practice storage required actual data decreases due effective versioning size fbl amount public metadata increases due greater number blocks 
increase overhead outweighs modest decrease actual stored data see 
snapshot shown days exhibit similar trends 
reasonable expect common blocks users running operating system 
test amount block sharing measured inserting workload pstore 
unique public private key pairs user test convergent encryption 
linux datasets saved total inserted bytes block sharing windows datasets saved 
sets inserted simultaneously saved 
number lower farsite study probably owing homogenous nature farsite workload compared heterogenous sparse nature workload 
research suggests interesting directions secure peer peer backup systems 
recall scheme pstore rsync style versioning scheme provide similar functionality logical directories 
user wants view files certain date user simply retrieves files logical directory corresponding date 
figures show scheme reasonable storage bandwidth demands mentioned section scheme fails efficiently exploit inter version sharing 
version broken fixed size blocks irrespective similarities previous versions 
blocks shared versions block occurs version offset 
specifically designed help divide new version file blocks efficiently especially similar blocks versions different offsets common scenario user inserting data middle new version 
scheme keep previous version information version creates separate fbl 
observations suggest modified scheme interesting alternative pstore system 
scheme modified lbfs style versioning efficiently exploit inter version 
lbfs divide new version file fbs lbfs works fingerprints file data portions file match older file implicitly shared similar data different offset new version 
new scheme simply contain list hashes fbs file 
convergent encryption enabling securing sharing users 
conserve bandwidth new scheme new peek primitive checks see chunk content hash exists peer peer network 
duplicate content hash exists need insert new chunk hash network sending signed command may necessary correctly update ownership tag list chunk 
new scheme resemble inodes similar bandwidth gains resulting hash tree possible hash di fbl represents children directory entire subtree beneath directory 
new scheme simpler implement pstore interesting compare pstore terms bandwidth storage requirements 
experimenting pstore discovered digitally signing chunk adds significant performance bandwidth storage overheads 
observed fbs fb metadata larger actual fb data 
largely result including user public key chunk 
feel cost digital signatures outweighed significant benefits 
digital signatures key secure deletion mentioned section traditional deletion techniques ill suited backup usage models 
second digital signatures provide useful tool implementing effective quota management infrastructure signature effectively tags data ownership 
cooperative trusted peer peer networks may suitable assume users exceed suggested quotas 
environment secure deletion replaced long expiration dates 
eliminate need include public key chunk lead better performance due processing reduced bandwidth smaller disk space overhead 
pstore uses chunk replication various cryptographic techniques revised versioning algorithm achieve primary design goals reliability security resource efficiency 
described proof concept implementation pstore architecture provides command line interface file insertion update retrieval delete network untrusted peers 
show small number replicas sufficient provide adequate reliability modest network size pstore provide significant bandwidth storage savings 
savings useful context quota system users concerned effective capacity network situations users disk network ideas matured various discussions professor robert morris mit laboratory computer science 
bandwidth constraints 
pstore novel system brings developments peer topeer storage domain data backup versioning 
anderson 
eternity service 
proceedings st international conference theory applications cryptology 
bolosky douceur ely theimer 
feasibility serverless distributed file system deployed existing set desktop pcs 
measurement modeling computer systems pages 
brown katcher walters watson 
advances snapshot technology 
technical report tr network 
chen goldberg gottlieb yianilos 
prototype implementation archival intermemory 
proceedings fourth acm international conference digital libraries 
clarke sandberg wiley hong :10.1.1.10.4919
freenet distributed anonymous information storage retrieval system 
proceedings workshop design issues anonymity unobservability pages berkeley ca jul 
international computer science institute 
concurrent versions system 
www org 
dabek kaashoek karger morris stoica balakrishnan 
building peer peer systems chord location service 
proceedings th ieee workshop hot topics operating systems pages 
dabek kaashoek karger morris stoica :10.1.1.159.9358
wide area cooperative storage cfs 
proceedings th acm symposium operating systems principles october 
dingledine freedman molnar 
free haven project distributed anonymous storage service 
proceedings workshop design issues anonymity unobservability pages berkeley ca jul 
international computer science institute 
druschel rowstron :10.1.1.1.1674
past largescale persistent peer peer storage utility 
proceedings th ieee workshop hot topics operating systems may 
fu kaashoek mazi res 
fast secure distributed read file system 
proceedings th usenix symposium operating systems design implementation pages oct 
gnutella protocol specification 
distributed search services sep 
mojo nation 
www net 
muthitacharoen chen mazi res :10.1.1.10.8444
low bandwidth network file system 
proceedings th acm symposium operating systems principles pages oct 
napster 
www napster com 
national institute standards technology 
secure hash standard 
technical report nist fips pub department commerce may 
national institute standards technology 
advanced encryption standard aes 
technical report nist fips pub department commerce nov 
rabin 
efficient dispersal information security load balancing fault tolerance 
acm apr 
rivest shamir 
method obtaining digital signatures public key cryptosystems 
communications acm feb 
tridgell 
rsync algorithm 
technical report tr cs australian national university jun 
waldman mazi res 
censorship resistant publishing system document 
th acm conference computer security nov 
waldman rubin cranor 
publius robust tamper evident censorship resistant web publishing system 
proceedings th usenix security symposium aug 

