appear proceedings ieee international conference robotics automation icra taipei taiwan may omnidirectional vision autonomous helicopter stefan gaurav sukhatme robotic embedded systems laboratory center robotics embedded systems department computer science university southern california los angeles california usa robotics usc edu gaurav robotics usc edu design implementation omnidirectional vision system sideways looking sensing autonomous helicopter 
demonstrate capabilities system visual servoing task designed required helicopter locate move centroid number visual targets 
results showing task successfully completed pioneer ground robot equipped omnidirectional vision system preliminary test flight results show system generate appropriate control commands helicopter 
helicopters particularly useful aerial vehicles number tasks especially takeoff landing space limited steady flight low speed needed 
size high cost operating helicopters limit tasks 
smaller scale autonomous helicopters offer viable alternative full scale versions tasks aerial surveillance communications bridging 
order unmanned aerial vehicle uav navigate safely environment tall obstacles monitor features horizontal plane uav equipped sideways looking sensors sort 
laser range finders provide accurate range information obstacle avoidance scene reconstruction 
commercially available laser limited scanning prohibitively heavy power hungry 
vision successfully feature tracking navigation tasks particularly useful richness information received 
ccd cam passive sensors typically draw little current light compactly packaged 
standard lenses limited field view order sense large area camera needs actuated 
gives partial information scene point time scene stitching techniques needed 
omnidirectional lens give degree semi spherical field view enabling vision system track features scene camera 
multiple features different parts scene tracked simultaneously 
properties omnidirectional lens suited movement characteristics helicopter 
helicopter essentially instantaneously move direction space lens allows see direction moving having pan tilt camera direction 
omnidirectional vision tasks feature tracking surveillance navigation scene reconstruction visual servoing localization 
control autonomous helicopter done downwards looking camera standard lens omnidirectional cameras ground robots little vision control helicopter omnidirectional lens done 
uav omnidirectional sensing capabilities various applications 
class tasks locating centroid number features space maintaining position centroid 
example simultaneously monitor number features optimal position monitoring centroid 
uav acting hub position facilitate communications 
omnidirectional vision system image capture system comprised omnidirectional lens remote reality coupled sony xc black white ccd camera 
lens field view degrees horizontal degrees vertical plane 
gives semi spherical field view horizon degrees camera mounted lens pointing downwards 
system designed sideways looking sensing blind spot degrees considered acceptable 
wireless video transmitter transmit video signal pc equipped frame grabber captures frames resolution 
helicopter platform experimental test bed avatar autonomous vehicle aerial tracking reconnaissance radio controlled model helicopter built bergen chassis 
helicopter carries onboard processing power sensors form pc stacks running linux running qnx rt dgps board compass crossbow laser altimeter ccd camera omnidirectional lens 
linux stack consists pentium ii mhz processor imagination px frame grabber 
stack image capturing running vision code 
qnx stack includes pentium iii mhz processor running low level helicopter control code 
drivers sensors run stack input sensors broadcast ground station logging 
ground station laptop running qnx 
stacks equipped wireless ethernet cards communication ground station 
send high level control commands differential gps corrections helicopter 
description avatar control architecture 
helicopter test bed onboard processing power linux stack insufficient running vision code wireless video transmitter transmit video signal second ground station ghz pentium iv pc 
introduced transmission noise signal hampered feature detection 
linux stack upgraded handle vision code running onboard eliminate transmission noise 
initially ccd camera mounted rigidly landing gear helicopter high frequency vibrations gas engine caused motion blur image 
reduce vibrations transmitted camera mount designed decoupled camera landing gear 
mount mount shown consists frame series elastic bands suspend camera 
elastic bands chosen low spring constant low amplitude high frequency vibrations helicopter transmitted camera 
greatly reduce amount motion blur image seen compared 
rigid mount decoupled mount images rigid decoupled mounts showing blur reduction pioneer platform ground experiment active media pioneer dx 
pioneer fitted omnidirectional camera mounting camera vertical pod cm ground level shown 
camera mounted lens facing downwards helicopter 
resulted small portion fov occluded mount affected pioneer performance completing task problem mount helicopter 
pioneer equipped pentium ii mhz processor run low level control code 
code run player stage environment 
helicopter ghz wireless video transmitter transmit video signal ground station vision code run 
code produced high level control commands rate hz transmitted pioneer wireless ethernet 
pioneer fitted centroid finding task order illustrate capabilities omnidirectional vision system simple task designed 
number visual targets placed environment surrounding robot robot required locate move centroid targets point equidistant targets 
task simplified dimensions placing targets horizontal plane 
image processing preprocessing feature recognition algorithm run image various image processing operations applied attempt highlight salient features 
median filter applied remove white additive noise preserve edge sharpness 
original image black image negated reducing number regions contains 
thresholding applied convert image greyscale binary threshold value chosen manually run time desired features preserved undesired features lost 
image described section followed segmentation connected component labelling described 
shows original spherical image shows image processing performed 
feature detection algorithm described section invariant image skew nec original image final image essary unwarp spherical image obtained omnidirectional lens 
geometric properties lens known projection function calculated performing 
properties known lens performed mapping points spherical image px corresponding points perspective image pu geometrical properties images 
see 
geometrical mapping calculated quadrant spherical image 
example mapping quadrant sin cos unwarp width unwarp width unwarp height unwarp width unwarp width spherical image unwarp width unwarp height image illustration process feature recognition hu moments discussed hu moments feature recognition 
system trained certain feature feature recognized regardless orientation scaling translation 
technique invariant skewing feature letter detected skewed degrees horizontally degrees vertically 
technique previously successfully detecting feature painted autonomous vision landing 
centroid finding algorithm order find centroid visual targets necessary know relative distance target 
targets size area target image indication distance target 
algorithm runs follows image find area position detected target position task 
xn calculate average maximum minimum areas targets positions largest smallest targets amax amin xmax xmin 
amax amin threshold calculate offsets average area minimum maximum areas amax amin determine action take move away xmax move xmin loop causes robot move away closest target move farthest target targets roughly distance threshold 
useful property technique necessary know actual distance target relative distances 
illustrates algorithm 
note size solid line circles represents relative size targets seen robot dotted line circles represent average size targets 
step greater robot moves farthest target 
step larger robot moves away closest target 
result robot moves centroid targets 
robot centroid step area target average area targets step centroid finding algorithm experimental setup omnidirectional vision system developed autonomous helicopter decided system tested ground robot 
help eliminate problems system helicopter easier conduct experiments debug code ground vehicle helicopter 
experiments done pioneer robot robot complete centroid finding task consistently experiment conducted helicopter 
autonomous flight possible new helicopter platform data collected onboard sensors 
helicopter flown pilot control vicinity visual targets centroid finding algorithm run 
gps coordinates heading helicopter logged commands generated algorithm 
test flights data analyzed see appropriate control commands generated algorithm gps coordinate centroid recorded helicopter heading location compared 
pioneer experiment cm white black background visual target 
version experiment designed version outdoor targets closer pioneer size reduced accordingly scale outdoor experiment maximum distance targets helicopter effective recognition determined resolution camera size outdoor targets cm 
outdoor experiment targets placed circumference circle diameter 
indoor experiment diameter reduced 
helicopter experiment conducted pioneer experiment conducted experimental results pioneer experiment pioneer robot conducted placing robot position see visual targets centroid targets 
algorithm run robot attempted locate move centroid targets 
task considered completed robot stabilized cm true centroid targets 
runs completed 
areas detected targets recorded intervals time completing task 
experiment conducted indoors gps determine position robot relative centroid 
alternative indication effectiveness algorithm average minimum maximum areas plotted time 
example plot shows max min values converge ave value indicating robot converges point approximately equidistant targets 
effectiveness feature recognition algorithm evaluated examining number raw processed frames captured noting number area pixels amax amin time ave max min target areas time correctly detected 
total frames detected false detections 
helicopter test flights completed described section 
data analyzed looking instances detected noting helicopter position heading time control command generated 
command trying move helicopter centroid targets considered correct 
analysis showed appropriate commands generated time 
shows spherical image taken flight corresponding processed image 
lines drawn center processed image indicates identified 
vertical line shows desired heading control command generated image 
ground experiment effectiveness feature recognition technique evaluated 
total frames detected false detections 
design implementation sideways looking sensor autonomous helicopter omnidirectional vision system 
effectiveness system demonstrated completing visual servoing task required number features identified simultaneously large field view environment 
data experiments show task completed successfully ground robot 
images taken flight shown vision system centroid finding algorithm generate appropriate control commands tested pilot controlled model helicopter 
plan run full experiment helicopter flying autonomously 
achieved omnidirectional vision control helicopter intend capability tasks flying obstacles buildings visually servoing position monitor area interest specific window building 
acknowledgments sponsored part nasa jpl caltech contract darpa dabt upenn mars program 
doug wilson support flight trials 
larry matthies charles brett kennedy andrew johnson compact low power axis scanning laser rangefinder mobile robots september 
ryan miller site mapping cmu autonomous helicopter proceedings th international conference intelligent autonomous june 
gregory hager peter belhumeur efficient region tracking parametric models geometry illumination ieee transactions pattern analysis machine intelligence vol 
pp 

baker nayar theory catadioptric image formation proceedings iccv bombay india january pp 

terry boult frame rate omnidirectional surveillance tracking www cse lehigh edu track omnidirectional sensing applications ieice transactions information systems vol 
pp 
mar 
peng chang martial hebert omni directional visual servoing human robot interaction proceedings ieee rsj international conference intelligent robots systems iros october vol 
pp 

ishiguro trivedi ocular stereo real time human tracking panoramic vision sensors theory applications kang editors springer verlag 
kanade collins lipton burt wixson advances cooperative multi sensor video surveillance proceedings darpa image understanding workshop volume pages november 
winters santos victor vision navigation environmental representations omnidirectional camera ieee transactions robotics automation 
winters santos victor omni directional vision robot navigation proc 
ieee workshop omnidirectional vision 
kang szeliski scene data recovery omnidirectional stereo ieee conference computer vision pattern pp 

roland ben scene reconstruction cylindrical panoramic images thad starner finding location omnidirectional video wearable computing platform iswc pp 

montgomery sukhatme autonomous landing unmanned aerial vehicle ieee international conference robotics automation washington may pp 

sharp sastry vision system landing unmanned aerial vehicle proceedings ieee international conference robotics automation pp 

pedro garcia gaurav sukhatme montgomery vision safe landing autonomous helicopter robotics autonomous systems accepted appear 
usc autonomous flying vehicle homepage usc edu avatar sty vaughan howard sukhatme mataric valuable player robot device server distributed control ieee rsj intl 
conf 
intelligent robots systems iros hawaii 
vaughan stage multiple robot simulator tech 
rep iris institute robotics intelligent systems university southern california 
gonzalez woods digital image processing addison wesley 
ioannis pitas digital image processing algorithms prentice hall 
hu visual pattern recognition moment invariants ire transactions information theory vol 
pp 

