ieee transactions multimedia vol 
june active learning framework content information retrieval cha zhang student member ieee chen member ieee propose general active learning framework content information retrieval cbir 
framework guide hidden annotations order improve retrieval performance 
object database maintain list probabilities indicating probability object having attributes 
training learning algorithm samples objects database presents annotator assign attributes 
sampled object probability set zero depending corresponding attribute assigned annotator 
objects annotated learning algorithm estimates probabilities biased kernel regression 
knowledge gain defined determine objects annotated system uncertain 
system presents sample annotator assigned attributes 
retrieval list probabilities works feature vector calculate semantic distance objects user query object database 
distance objects determined weighted sum semantic distance low level feature distance 
algorithm tested synthetic databases real databases dimensional models 
cases retrieval performance system improves rapidly number annotated samples 
furthermore show active learning outperforms learning random sampling 
index terms active learning attribute tree biased kernel regression content information retrieval semantics dimensional model retrieval 
content information retrieval cbir attracted lot research interest years 
typical cbir system image retrieval system includes major aspects feature extraction high dimensional indexing system design 
aspects feature extraction basis cbir 
features extract data low level features 
result semantically similar objects may lie far feature space completely different objects may stay close 
features designed general specific cbir systems showed retrieval performance gap low level features high level semantic meanings manuscript received april revised february 
supported part nsf career award 
associate editor coordinating review approving publication dr zhang 
authors department electrical engineering carnegie mellon university pittsburgh pa usa email andrew cmu 
edu andrew cmu edu 
publisher item identifier 
ieee objects major obstacle successful retrieval systems 
relevance feedback hidden annotation shown powerful tools bridging gap low level features high level semantics 
widely text retrieval relevance feedback proposed rui interactive tool content image retrieval 
proven powerful tool major focus research area 
relevance feedback moves query point relevant objects selectively weighs features low level feature space user feedback 
low level features set semantically similar objects lie space clusters querying object cluster able retrieve semantically similar objects clusters space 
similar approaches proposed relevance feedback build semantic relationships inside database 
systems grouped objects database small semantic clusters related clusters semantic weights 
updating clusters semantic weights user feedback 
solution problem hidden annotation 
attaching boolean attributes images database cox experiments hidden annotation bayesian image retrieval system pichunter showed positive results :10.1.1.108.9375
study hidden annotation preprocessing stage retrieval system referred learning stage user system 
existing systems hidden annotation annotate objects database full annotation annotate subset database manually selected partial annotation 
database larger full annotation increasingly difficult manual effort involved 
partial annotation relatively affordable heavy manual labor 
database partially annotated traditional pattern classification methods derive semantics objects annotated 
clear annotation sufficient specific database best subset objects annotate active learning determine objects annotated 
learning stage system provides sample objects automatically annotator 
sample objects selected information annotation sample object provide decrease uncertainty system 
object annotated giving maximum information knowledge gain system selected 
machine learning literature idea maximizing expected information query studied name active zhang chen active learning framework cbir learning learning queries 
revisited cox updated display query result 
detailed survey active learning literature section ii 
key assumption low level feature space describe semantic meaning inferable 
means low level feature space objects close semantically similar able infer knowledge 
notice assumption allows objects semantic meaning lie different places feature space handled normal relevance feedback 
assumption hold relevance feedback hidden annotation able help improving retrieval performance database fully annotated 
solution circumstance find better low level features objects 
assume semantic meanings objects database characterized multilevel attribute tree 
attribute tree general attributes level tree necessarily exclusive 
object database maintain list probabilities indicating probability object having corresponding attribute 
object annotated probabilities set zero depending corresponding attributes annotated characterize object 
objects annotated estimate attribute probabilities annotated neighbors 
kernel regression employed fulfill task 
list probabilities able tell object system uncertain propose sample annotator 
list probabilities works feature vector calculate semantic distance objects query object 
final similarity measurement objects determined weighted sum semantic distance low level feature distance 
synthetic database dimensional model database examples show algorithm performance retrieval system improves rapidly number annotated models cases outperforms approach randomly choosing objects annotate 
organized follows 
section ii introduce general criterion active learning approach 
section iii presents details proposed algorithm 
discuss joint semantic low level feature similarity measurement section iv 
show experimental results section conclude section vi 
ii 
general criterion active learning learning interface attribute tree structure fig 
shows learning annotation interface system 
left hand side list attributes annotated 
right hand side sample object image model system proposes 
basic operation annotator check attributes sample model press annotate button system get annotation information sample model 
fig 

learning interface tree annotation structure 
system attributes form tree structure multiple levels 
attribute tree node attribute 
attributes higher level nodes general lower level nodes 
default assume attribute lower level nodes checked attributes higher level nodes parent nodes checked 
simple example aircraft lies level highest level tree structure general jets lies second level 
object jets aircraft decision tree classification applications nodes parent node attribute tree necessarily exclusive 
example aircraft classic jets tree structure general natural annotation 
annotation starts attributes tree structure 
necessary annotator may add rename remove attributes level 
annotator asked check attributes sample object 
attribute annotator check assume annotator implies object attribute 
active learning general criterion choose samples types machine learning algorithms find statistically optimal way select training data 
pursuing optimal way machine referred active learning 
traditional machine learning research learner typically works passive recipient data active learning enables learner ability collect data 
representative active learning 
specific interested specific form active learning selective sampling 
goal selective sampling reduce number training samples need annotated examining objects annotated selecting informative ones annotator 
approaches proposed selective sampling 
ieee transactions multimedia vol 
june seung proposed algorithm called query committee qbc generates committee classifiers query chosen principle maximal disagreement classifiers 
freund extended qbc result wide range classifier forms 
gave theoretical proofs assumptions effect training annotated data achieved cost obtaining data note annotated labeling logarithmic fraction 
nigam mccallum modified qbc algorithm combination active learning traditional expectation maximization em algorithm 
muslea introduced algorithm called testing 
similar qbc algorithm designed apply problems redundant views problems multiple disjoint sets attributes features learn target attribute 
lewis gale described approach called uncertainty sampling :10.1.1.16.3103
idea classifier tells class sample gives uncertainty score data sample annotated 
sample chosen classifier confident 
uncertainty sampling reported size training data reduced fold text classification :10.1.1.16.3103
need find general criterion measure information annotation provide system 
objects database attributes annotator wants annotation 
attributes form attribute tree 
object define probability probability object attribute object annotated having attribute annotated having attribute object annotated estimated neighboring annotated objects described section iii 
order derive expected information gain annotate certain object define uncertainty measurement follows uncertainty measurement function attribute probabilities object want uncertainty measurement properties 
object annotated know object uncertain object attributes large 
third property strict sense various functions defined satisfy properties 
instance assume case attribute concerned 
known entropy uncertainty measurement represents entropy function 
define uncertainty measurement multiple attributes section iii 
important factor affects benefit annotator give system 
distribution objects low level feature space 
annotating objects high probability region low probability region may give system different amounts information turn leads different retrieval performance 
define knowledge gain annotator give system annotating object defined knowledge gain probability density function pdf object estimated section iii uncertainty measurement defined 
criterion choosing sample object find unlabeled object maximum knowledge gain iii 
proposed approach proposed approach follows 
initialize probability lists prior probabilities database 
pdf estimated 
small number objects randomly chosen annotated initialization step algorithm 
probability list re calculated randomly annotated objects 
system starts select object maximum knowledge gain asks annotator annotate 
objects database update probability lists neighbors newly annotated 
system searches object maximum knowledge gain asks annotator annotate 
loop keeps going annotator stops database fully annotated 
estimate probability density function probability density function important factors defined knowledge gain 
machine learning literature efficient ways density estimation na density estimator bayesian networks mixture models density trees kernel density estimator known parzen windows 
kernel density estimator 
kernel method updating probability lists subsection 
probability density estimation independent probability list updating needs calculated offline annotation algorithms employed 
choose kernel isotropic gaussian function assume features normalized 
window estimation hyper sphere centered concerned object radius super sphere named bandwidth kernel density estimator literature 
normally constant bandwidth 
feature vector object density estimation position locates zhang chen active learning framework cbir euclidian distance neighboring object center object choice bandwidth important effect estimated probabilities 
size neighborhood large estimation suffer low resolution 
hand small size may cause local overfitting hurts generalization ability estimation 
optimal parzen window size studied extensively literature 
optimal bandwidth determined minimizing integrated squared error ise mean integrated squared error mise 
adaptive bandwidth proposed 
simplicity choose constant bandwidth maximum distance object closest neighbor scalar 
experiments find normalized feature space selecting gives results 
detailed experiments shown section update probability lists assume prior knowledge probability lists annotation 
prior probability object attribute experimental results show guess prior probability influence annotation efficiency 
annotation annotator supposed check attributes query model attributes annotator check assumed belonging object children nodes checked 
set attributes annotator annotated object including having children nodes checked 
new list probabilities object annotation 
recall basic assumption section annotated models tend infer knowledge nearby neighbors 
model neighbors annotated probability list needs updated 
objects far annotated objects want link semantic meanings 
semantic meaning extension fits framework kernel regression 
annotated objects anchor points known probability values 
objects annotated attribute probabilities interpolated 
assume attribute probabilities independently interpolated kernel regression 
mentioned earlier object annotated having attribute probability increase 
drop 
annotated objects considered anchor points low level feature space 
consider example attributes feature vectors currently annotated objects corresponding probabilities defined object corresponding 
proposed simple biased kernel regression algorithm estimate unannotated object feature vector probability object having attribute prior probability object belongs attribute tendency object prior probability 
degenerates normal kernel regression 
weight exists equivalent distance satisfies kernel bandwidth object predicted 
case biased kernel regression viewed putting virtual anchor point distance point predicted set probability virtual anchor point having attribute prior probability 
weights defined bandwidth object bandwidth similar effects final result estimate pdf kernel density estimator 
kernel bandwidth pdf estimation subsection kernel regression 
obviously annotated object closer query point assigned higher weight gives influence predicted value coherent basic assumption 
fig 
explains reason biased kernel regression normal kernel regression 
horizontal axis feature value vertical axis probability corresponding object certain attribute 
notice normal kernel regression fig 
feature value far away anchor points ends horizontal axis weight small predicted probability close 
mainly due normalization weights denominator 
effect expected 
assumption close annotated objects infer knowledge current object far objects 
words object far neighbors annotated expect probability remain similar prior probability 
fig 
shows result biased kernel regression set equal prior probability set 
obvious biased kernel regression suitable approach estimate prior probability annotated objects far away 
ieee transactions multimedia vol 
june notice predicted curve pass anchor point fig 

nice property kernel regression 
probabilistic point view object certain feature vector annotated having attribute probable object having feature vector attribute 
proven number anchor points goes infinite kernel bandwidth small result kernel regression asymptotically converges actual probability distribution 
database huge computational cost probability list updating low 
kernel regression newly annotated object change object probability list far away 
bandwidth kernel function determines hyper sphere inside object probability lists updated 
objects easily database organized tree similar structures 
probabilities objects estimated parametrically 
example assume models belonging attribute follow gaussian distribution gaussian mixture distribution necessary 
having new model annotated equivalent adding new training example gaussian gaussian mixture 
model chosen annotate system confident 
approach smooth transition annotation full annotation database fully annotated parametric model record annotation object database 
kind approach imposes strong global structure low level feature space 
model distribution right performance fig 

normal kernel regression biased kernel regression 
system may suffer 
comparison approach imposes structures feature space local 
local structures offer better opportunity fit database knowledge database 
uncertainty measure probabilities updated learning algorithm searches models annotated model annotation annotator provide extra information 
discussion section ii model produces maximum knowledge gain 
order calculate gain need find uncertainty measurement probability density model 
described estimation pdf section iii 
discuss way determine uncertainty measurement 
section ii gave general properties uncertainty measurement want 
mentioned attribute annotate objects entropy measure uncertainty uncertainty measurement object entropy function probability object characterized attribute 
zhang chen active learning framework cbir multiple attributes uncertainty defined joint probability attributes 
represents joint probability object having having attributes 
sum taken possible combinations attributes object 
impossible estimate joint probabilities simplified method approximate 
certain object certain attribute define individual entropy uncertainty object defined weighted sum entropies attributes total number attributes semantic weight attribute 
semantic weights related level tree attributes 
level attribute 
weights defined constant 
current implementation set experiments 
justification weighted entropy approximation detailed 
uncertainty measure probability density estimate section iii able calculate knowledge gain simply multiplying 
system proposes object maximum gain asks annotator annotate 
iv 
joint similarity measure semantic low level features hidden annotation needs integrated retrieval system order provide better retrieval performance 
previous annotation regarded boolean vector 
normalized hamming distance combine influence annotation acted new feature retrieval 
database partially annotated annotations learning neural networks train similarity measurement 
system model list attribute probabilities including query model user provides 
query model chosen database probability list 
normal case hidden annotation largely improving performance inside database queries 
query model selected outside database estimate probabilities section iii 
alternatively user annotate query model providing retrieval system 
probability list complete description annotations associated high level semantics 
treat list probabilities feature vector similar low level features color texture shape 
semantic distance objects defined total number attributes semantic weight attribute defined attribute probabilities models 
item probability objects disagreeing attribute 
choose form weighted sum measure disagreement simple effective practice 
attributes lower level weight smaller give penalty disagreement attributes lower level 
intuitively disagreement car aircraft larger classic aircraft jets aircraft 
property defined semantic distance objects compared annotated probabilities defined semantic distance automatically degenerate hamming distance assume level attribute tree widely literature 
forms semantic distances defined 
assumes attributes system exclusive distance measures assume normalized probability vector object kl divergence 
need distance measure distance low level feature space 
objects simply weighted euclidean distance total number features normalized low level features objects respectively weight set importance feature 
current implementation features equally weighted normalization 
distance models weighted sum semantic distance low level feature distance semantic weight low level feature weight respectively methods specify weights 
example ieee transactions multimedia vol 
june fixed constant proportional number objects annotated database 
current system weights inverse proportional entropy query object 
retrieval system knows query prefers search database mainly semantic features low level features 
hidden annotations annotator models far away may annotated having attributes means small semantic distance 
integration semantic annotations similarity measurement effectively works warping low level feature space semantically similar objects closer 
illustrated fig 
distributed cars low level feature space 
car annotated 
compute final similarity similar attribute probabilities final similarity score higher low level features considered due introducing item 
experiments performed experiments synthetic database real database 
due page limit refer detailed experiments 
main drawn 
active learning performs better random sampling database tested saving number annotations large 
fairly large range kernel bandwidth defined performance similar larger bandwidth typically gives stable performance 
adaptive kernel bandwidth help improve performance 
bias weight impact system performance 
show experimental results real retrieval system 
database objects downloaded internet 
database consists objects 
third objects 
features comparing models proposed literature 
system features extracted object 
region features proposed including volume surface ratio aspect ratio moment invariants fourier transform coefficients 
features normalized range 
experiment active learning algorithm distinguish 
measure annotation efficiency testing final retrieval performance retrieval system 
system multilevel attribute tree structure define performance measurement follows 
specific query top retrieved results average matching error results measured fig 

annotations warp feature space 
semantic distance query retrieved object calculated ground truth data 
indicates average matching error top retrieved objects respect query 
smaller better performance system query system performance evaluated number objects database take object database query calculate average matching error 
final performance system measured average average matching error objects 
performance comparison active learning algorithm random sampling algorithm model database fig 

start algorithms models randomly chosen annotated 
fixed bandwidth kernel density estimation kernel regression 
bandwidth set defined 
biased kernel regression choose weight prior probability performance top retrieved results reported 
horizontal axis fig 
number samples annotated including initial randomly drawn samples 
vertical axis average matching error database measured 
curve closer bottom left corner considered better performance 
fig 
obvious active learning algorithm works better random sampling approach 
test algorithm model database attributes 
airplane category extended subcategories jets helicopters divided categories characters shapes buildings fig 
shows performance algorithm versus random sampling 
algorithm works better random sampling algorithm improvement significant fig 
synthetic database 
may due feature space model database 
classes specified classes may violate assumption proposed section objects classes local inferable property may hold 
zhang chen active learning framework cbir fig 

performance comparison algorithm random sampling model database attributes 
fig 

performance comparison algorithm random sampling model database attributes 
vi 
discussions proposed general approach add hidden annotation active learning information retrieval 
considered natural attribute tree structure annotation 
object annotated instant determined knowledge gain system annotating 
defined knowledge gain product pdf uncertainty measurement 
order evaluate uncertainty object gave object list attribute probabilities computed neighboring annotated objects kernel regression 
obtained uncertainty object giving explicit function probabilities 
proposed algorithm outperforms random sampling algorithm experiments performed shows hidden annotation active learning powerful tool improve performance cbir 
hidden annotation relevance feedback different strategies serve different purposes 
normal relevance feedback accumulate semantic knowledge able tune query quickly 
hidden annotation hand tries accumulate knowledge annotator 
application dependent choose choose 
knowledge accumulation turned depending user 
active learning may concern annotator preference user 
annotator may expert user may criteria similarity 
modify algorithm allow user feedback 
define distance weighted sum semantic distance low level feature distance weights semantic distance low level feature distance adjusted relevance feedback 
part 
compare approach lewis gale approach approach designed text classification information retrieval :10.1.1.16.3103
approach general easily modified classification problems 
ieee transactions multimedia vol 
june acknowledgment authors dr cohn carnegie mellon university helpful discussions suggestions 
reviewers helped improve quality 
rui huang 
chang image retrieval past proc 
dec 
harman relevance feedback revisited proc 
th annu 
int 
acm sigir conf 
research development information retrieval pp 

rui huang ortega mehrotra relevance feedback power tool interactive content image retrieval ieee trans 
circuits syst 
video technol vol 
pp 
sept 
ishikawa faloutsos mindreader query database multiple examples proc 
th vldb conf new york 
rui huang optimizing learning image retrieval proc 
ieee june 
tian hong huang update relevant image weights content image retrieval support vector machines proc 
icme vol 
pp 

minka picard interactive learning society models mit media laboratory perceptual computing section cambridge ma 
cox miller minka papathomas yianilos bayesian image retrieval system pichunter theory implementation psychophysical experiments ieee trans 
image processing vol 
pp 
jan 
lee 
ma zhang information embedding user relevance feedback image retrieval spie int 
conf 
multimedia storage archiving systems iv boston ma sept pp 

lu hu zhu zhang yang unified framework semantics feature relevance feedback image retrieval systems acm multimedia 
ma manjunath texture features learning similarity proc 
ieee pp 

freund seung shamir tishby selective sampling query committee algorithm advances neural information processing systems 
cambridge ma mit press 
query content software dimensional models databases management proc 
digital imaging modeling int 
conf 
advances pp 

pr shape spectrum descriptor melbourne australia mpeg iso iec jtc sc wg mpeg 
zhang chen efficient feature extraction objects mesh representation proc 
icip thessaloniki greece 
seung opper sompolinsky query committee proc 
th annu 
acm workshop computational learning theory pittsburgh pa july 
freud seung shamir tishby information prediction query committee advances neural informations processing systems 
san mateo ca morgan kaufmann 
nigam mccallum employing em pool active learning text classification proc 
th icml 
lewis gale sequential algorithm training text classifiers proc :10.1.1.16.3103
acm sigir london pp 

lewis sequential algorithm training tex classifiers corrigendum additional data sigir forum vol 
pp 

muslea minton knoblock selective sampling testing crm workshop combining selecting multiple models machine learning montreal qc canada apr 
cohn ghahramani jordan active learning statistical models artif 
intell 
res 
pp 

krogh vedelsby neural network ensembles cross validation active learning advances neural information processing systems tesauro touretzky leen eds 
cambridge ma mit press vol 

ger ritter obermayer active learning self organizing maps oja kaski eds 
amsterdam netherlands elsevier 
duda hart pattern classification scene analysis 
new york wiley 
guttman trees dynamic index structure spatial searching proc 
sigmod conf boston ma june pp 

silverman density estimation statistics data analysis 
new york chapman hall 
koller learning approximation stochastic processes proc 
icml 

chiu comparative review bandwidth selection kernel density estimation statistica sinica pp 

scott variable kernel density estimation annals statistics pp 

cover thomas elements information theory 
new york wiley 
zhang chen new active learning approach contentbased information retrieval amp 
cha zhang received degrees department electronic engineering tsinghua university china respectively 
currently pursuing ph degree department electrical computer engineering carnegie mellon university pittsburgh pa july july intern microsoft research beijing china 
research interest includes information retrieval pattern recognition machine learning image rendering virtual reality image video compression streaming signal processing published technical papers holds patents 
served publicity chair th international packet video workshop pittsburgh 
chen received degree electrical engineering national taiwan university taipei taiwan ph degrees electrical engineering california institute technology pasadena respectively 
department electrical computer engineering carnegie mellon university pittsburgh pa professor 
directs advanced multimedia processing laboratory striving turn multimedia technologies science fiction reality 
research interests include multimedia signal processing communication audio visual interaction biometrics processing graphics bioinformatics building collaborative virtual environments 
august october worked visual communications research department bell laboratories holmdel nj labs research red bank nj senior technical staff member principle technical staff member 
published technical papers holds patents 
edited book advances multimedia systems standards networks new york marcel dekker 
dr chen received charles prize outstanding independent research electrical engineering 
recipient national science foundation career award 
helped create technical committee multimedia signal processing founding chair multimedia signal processing workshop ieee signal processing society 
endeavor evolved founding ieee transactions multimedia ieee international conference multimedia expo joining efforts multiple ieee societies 
appointed editor chief ieee transactions multimedia 
