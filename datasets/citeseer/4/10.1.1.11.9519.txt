re examination text categorization methods reports controlled study statistical signi cance tests text categorization methods support vector machines svm nearest neighbor knn classi er neural network nnet approach linear leastsquares fit llsf mapping naive bayes nb 
focus robustness methods dealing skewed category distribution performance function training set category frequency 
results show svm knn llsf signi cantly outperform nnet nb number positive training instances category small methods perform comparably categories su ciently common instances 
automated text categorization tc supervised learning task de ned assigning category labels pre de ned new documents likelihood suggested training set labelled documents 
raised open challenges statistical learning methods requiring empirical examination ectiveness solving real world problems high dimensional category distribution labelled documents 
topic spotting newswire stories example commonly investigated application domains tc literature 
increasing number learning approaches including regression models nearest neighbor classi cation bayesian probabilistic approaches decision trees inductive rule learning neural networks line learning support vector machines :10.1.1.54.6608:10.1.1.11.6124:10.1.1.11.6124:10.1.1.32.9956:10.1.1.109.2516:10.1.1.39.6139:10.1.1.14.6535
rich literature provides valuable information individual methods clear comparison di cult published results directly comparable 
example tell performance nnet wiener statistically signi cantly better worse permission digital hard copies part personal classroom granted fee provided copies distributed profit commercial advantage copies bear notice full citation page 
copy republish post servers redistribute lists requires prior specific permission fee 
sigir berkley ca usa copyright acm 
yiming yang xin liu school computer science carnegie mellon university pittsburgh pa usa www cs cmu edu yiming performance svm joachims di erent data collections evaluations methods statistical signi cance analysis conducted verify impact di erence data performance variation classi ers :10.1.1.11.6124
naive bayes classi ers exhibited relatively poor performance previous studies hand papers claimed nb methods perform surprisingly gaining popularity lately 
di cult understand claimed strengths naive bayes methods evaluations non comparable performance measures tested selected subsets benchmark collections top common categories total 
clear claimed precisely surprisingly mean statistically signi cant better methods statistically di erent top performing classi ers published worse best ones better expectation authors 
claims speci ed empirical evidence far 
questions addressed 
open question tc research robust methods solving problems skewed category distribution 
categories typically extremely nonuniform distribution practice meaningful compare performance di erent classi ers respect category frequencies measure ectiveness method depends amount data available training 
evaluation scores speci categories reported performance analysis function categories seldom seen tc literature 
commonly methods compared single score accuracy error rate averaged measure see section de nition category assignments documents 
single valued performance measure dominated classi er performance common categories rare categories depending performance computed micro averaging versus macro averaging 
matter performance average computed single score prohibits ne grained analysis respect training set frequencies categories 
address evaluation problems conducting controlled study known text categorization methods nnet svm nb knn llsf 
methods published relatively strong performance scores previous evaluations partial comparison directly compared controlled study thorough statistical signi cance analysis focus :10.1.1.11.6124:10.1.1.109.2516
speci cally contains new contributions provides directly comparable results methods new benchmark corpus reuters 
currently published results llsf nnet nb corpus full set categories available 
knn published results available lower results previous version collection :10.1.1.11.6124:10.1.1.109.2516
svm published results contain su cient details statistical signi cance analysis 
proposes variety statistical signi cance tests di erent standard performance measures including measures category assignments average precision category ranking suggests way jointly tests cross method comparison 
observes performance classi er function training set category frequency analyzes robustness classi ers dealing skewed category distribution 
task corpus performance measures evaluation results comparable published results tc evaluations chose topic spotting newswire stories task reuters corpus data 
corpus new benchmark lately tc evaluations re ned version older versions reuters reuters tc methods evaluated results older versions may directly comparable results new version :10.1.1.54.6608:10.1.1.109.2516:10.1.1.39.6139
version reuters obtained eliminating unlabelled documents selecting categories document training set test set 
process resulted categories training test sets 
eliminating documents belong categories obtained training set documents test set documents vocabulary unique words stemming word removal 
number categories document average 
category distribution skewed common category training set frequency categories instances categories instances 
shows category distribution training set 
documents frequency category rank common rare category distribution reuters evaluating ectiveness category assignments classi ers documents standard recall precision measure 
recall de ned ratio correct assignments system divided total number correct assignments 
precision ratio correct assignments system divided total number system assignments 
measure initially introduced van rijsbergen combines recall precision equal weight form rp scores computed binary decisions individual category rst averaged categories 
computed globally binary decisions number total test documents number categories consideration 
way called macro averaging way called micro averaging 
micro averaged widely cross method comparisons macro averaged cases 
understood micro averaged scores recall precision tend dominated classi er performance common categories macro averaged scores uenced performance rare categories 
providing kinds scores informative show evaluation cross method comparison section 
error additional measure de ned ratio wrong assignments system divided total number system assignments 
classi ers svm support vector machines svm relatively new learning approach introduced vapnik solving class pattern recognition problems 
structural risk minimization principle error bound analysis theoretically motivated 
method de ned vector space problem nd decision surface best separates data points classes 
order de ne best separation introduce margin classes 
figures illustrate idea 
simplicity case dimensional space linearly separable data points idea generalized high dimensional space data points linearly separable 
decision surface linearly separable space hyperplane 
solid lines gures show possible decision surfaces correctly separates groups data 
dashed lines parallel solid ones show move decision surface causing misclassi cation data 
distance set parallel lines referred margin 
svm problem nd decision surface maximizes margin data points training set 
precisely decision surface svm linearly separable space hyperplane written arbitrary data point classi ed vector constant learned training set decision line solid smaller margin distance parallel dashed lines 
decision line maximal margin 
data points dashed lines support vectors 
linearly separable data 
letting yi xi denote training set yi classi cation positive example negative example class svm problem nd satis es constraints xi yi xi yi vector norm minimized 
svm problem solved quadratic programming techniques :10.1.1.15.9362
algorithms solving linearly separable cases extended solving linearly non separable cases introducing soft margin hyperplanes mapping original data vectors higher dimensional space new features contains interaction terms original features data points new space linearly separable :10.1.1.15.9362
relatively cient implementations svm include sv light system joachims sequential minimal optimization smo algorithm platt :10.1.1.11.6124
interesting property svm decision surface determined data points ex distance decision plane 
points wk called support vectors ective elements training set points removed algorithm learn decision function 
property svm theoretically unique di erent methods knn llsf nnet nb data points training set optimize decision function 
interesting know theoretical distinction leads signi cant performance di erences svm methods practice 
joachims applied svm text categorization compared performance classi cation methods reuters corpus 
results show svm outperformed methods tested experiments results published apte published better results decision tree approach boosting 
comparison quite informative points missing questionable thorough statistical signi cance tests lacking 
performance analysis respective category distribution especially rare categories provided 
knn result reported lower knn results 
addressing points decided re test svm sv light system joachims version knn 
knn knn stands nearest neighbor classi cation wellknown statistical approach intensively studied pattern recognition decades 
knn applied text categorization early stages research 
top performing methods benchmark reuters corpus version apte set top performing methods include llsf yang decision trees boosting apte neural networks wiener :10.1.1.54.6608
knn algorithm quite simple test document system nds nearest neighbors training documents uses categories neighbors weight category candidates 
similarity score neighbor document test document weight categories neighbor document 
nearest neighbors share category thenthe neighbor weights category added resulting weighted sum likelihood score category respect test document 
sorting scores candidate categories ranked list obtained test document 
thresholding scores binary category assignments obtained 
decision rule knn written cj knn sim di di cj bj di cj classi cation document di respect category cj sim di similarity test document training document di bj threshold binary decisions 
convenience cosine value measure similarity documents similarity measures possible 
category speci threshold bj automatically learned validation set documents 
subset training documents test documents learn optimal threshold category 
optimal mean threshold yielded best score validation documents 
note di erence thresholding method thresholding method joachims knn experiment 
joachims simply sorted con dence scores test document assigned top ranking category correct category 
simple light sv system publicly available www ai cs uni dortmund de forschung verfahren svm light svm light eng html 
method allow system assign multiple categories document necessarily optimal strategy knn classi er documents category 
suspect simpli cation joachims reason low performance knn assertion con rmed experiments versions knn reuters see results section 
llsf llsf stands linear squares fit mapping approach developed yang 
regression model automatically learned training set documents categories 
training data represented form input output vector pairs input vector document conventional vector space model consisting words weights output vector consists categories binary weights corresponding document 
solving linear squares training pairs vectors obtain matrix word category regression coe cients fls arg min bk matrices training data corresponding columns pair input output vectors matrix fls solution matrix de ning mapping arbitrary weighted categories 
sorting category weights ranked list categories obtained input document 
thresholding category weights category assignments input document obtained 
system automatically learn optimal threshold category de nition knn 
llsf knn di er statistically methods similar performance applications compared methods including categorization reuters news stories med line bibliographical abstracts mayo clinic diagnoses 
compared robustness dealing rare categories main foci study 
nnet neural network nnet techniques intensively studied arti cial intelligence 
nnet approaches text categorization evaluated reuters corpus wiener ng 
respectively 
wiener tried perceptron approach hidden layer layered neural networks hidden layer 
ng uses perceptrons 
systems separate neural network category learning non linear mapping input words complex features document space toa category 
wiener experiments suggested advantage combining multiple class nnet higher level categories class networks lowest level categories compare performance class nnet class nnet category 
experiments nnet reuters practical consideration training cost 
training nnet usually time consuming classi ers 
costly train nnet category decided train nnet categories reuters 
sense nnet approach exactly previous reported ones leave comparison research 
decided hidden layer nodes empirically chosen section 
implemented nnet system cient handling sparse document vectors 
nb naive bayes nb probabilistic classi ers commonly studied machine learning 
increasing number evaluations nb methods reuters published :10.1.1.21.988
basic idea nb approaches joint probabilities words categories estimate probabilities categories document 
naive part nb methods assumption word independence conditional probability category assumed independent conditional probabilities words category 
assumption computation nb classi ers far cient exponential complexity non naive bayes approaches word combinations predictors 
versions nb classi ers 
studies multinomial mixture model reported improved performance scores version commonly versions nb data collections including reuters 
improved model evaluated common categories common ones total categories reuters results allow complete comparison previously reported nb methods methods full set reuters categories 
confusing aspect evaluations nb non conventional accuracy measure proportion correct category assignments total assignments number test documents document assigned category 
narrowly de ned accuracy equivalent tothe standard precision category document assumption classi ers equivalent standard recall assuming document correct category 
equivalent standard de nition accuracy text categorization literature proportion correct assignments binary decisions category document pairs 
standard accuracy measure de ned documents multiple categories narrowly de ned accuracy 
leads confusion non comparable performance measures text categorization evaluations collections contributing di culty cross collection comparisons 
provide comparable results nb reuters ran multinomial mixture model nb mccallum evaluated output standard performance measures introduced section 
signi cance tests designed set signi cance tests comparing systems various performance measures 
de ne tests rst discuss suitability respect performance measures 
nb classi ers mccallum publicly available bow library cmu www cs cmu edu mccallum bow 
micro sign test test sign test designed comparing systems binary decisions document category pairs 
notation number binary decisions system product number test documents number categories ai measure success system ith decision 
means correct means incorrect bi measure success system ith decision number times ai bi di er number times ai larger bi 
null hypothesis binomial distribution bin 
alternative hypothesis binomial distribution bin meaning system better system value sided computed binomial distribution null hypothesis nx symmetrically ifn value extreme computed formula kx value indicates signi cance level observed evidence null hypothesis system better worse system value sided approximately computed standard normal distribution macro sign test test sign test designed comparing systems paired values individual categories 
notation number unique categories ai score system ith category 
bi score system ith category 
number times ai bi di er number times ai larger bi 
test hypotheses value sided computation micro test 
macro test test test comparing systems paired values individual categories 
notation de ned test add items di ai bi di erence ai bi simple average di values null hypothesis 
alternative hypothesis 
value computed distribution degree freedom standard normal distribution 
macro test rank transformation compare systems values rank transformation values systems individual categories pooled sorted values replaced corresponding ranks 
distinction test refer test test 
notation rank score system ith category 
rank score system ith category 
rank di erence number times simple average values null hypothesis 
alternative hypothesis 
compute value sided distribution degree freedom standard normal distribution 
comparing proportions test performance measures proportions recall precision error accuracy compare performance scores systems 
pa pb performance scores systems respectively na nb numbers trials samples evaluation systems respectively 
de nition na nb depends performance measures recall categories precision number assigned system accuracy error number pairs 
compute na pa nb pb observed proportion na nb total na nb trials 
null hypothesis pa pb alternative hypothesis pa pb 
compute value sided pa pb na nb distribution degree freedom standard normal distribution 
test allow systems evaluated di erent test collections test collection 
case na nb computation simpli ed pa pb pa pb testing methods described test test designed evaluate performance systems micro level pooled decisions individual document category pairs 
hand test test designed evaluate macro level performance scores category unit measure 
macro tests test may robust reducing uence outliers risks insensitive su ciently sensitive performance comparison ignores absolute differences values 
test sensitive tothe absolute values overly sensitive scores highly unstable low frequency categories 
test compromise extremes sensitive test outliers sensitive sign test reserve order distinct values 
tests perfect performance measures performance analysis respect category distribution jointly test better choice 
related literature sign tests reported cohen method comparison micro level category assignments lewis comparison paired values individual categories 
evaluation experiments set applied statistical feature selection preprocessing stage classi er statistic information gain criterion measure word category associations words features 
di erent feature set sizes tested size optimized global score classi er chosen classi er 
result selected features nnet features nb features knn llsf features svm 
empirical settings knn set 
choice previous parameter optimization learned training data reuters 
number singular value llsf computation set previous parameter optimization learned training data reuters 
number hidden units middle layer nnet set 
choice produces best score nnet validation set part training data reuters varied number hidden units 
svm tested linear non linear models ered sv obtained slightly better result linear svm non linear models 
linear version representative svm cross method comparison 
results table summarizes global performance scores 
points table worth discussion 
micro averaged score svm slightly lower best svm scores reported joachims possibly di erence term weighting scheme document presentation due minor di erences data preparation 
joachims document frequency terms tf directly tf 
difference signi cant 
micro averaged score knn noticeably higher knn score reported joachims 
tested simpli ed knn joachims assign top ranking category document obtained score 
contrasting tests suggest simpli cation optimal necessary knn 
micro averaged score nb significantly higher nb score obtained joachims 
analysis mccallum implemented models multinomial mixture model tested better multivariate bernoulli model joachims tested 
experiment con rmed mccallum 
better model nb svm knn llsf 
cross classi er comparison table summarizes statistical signi cance tests 
column table obtain complete partial order classi ers 
micro level analysis pooled binary decisions suggests sv knn nb classi ers insigni cant performance di erences grouped set 
hand macro level analyses test test test onthe scores suggest somewhat di erent grouping ordering classi ers fsv knn fnb inconsistent grouping orderings classi ers biases performance measures 
signi cance test dominated performance classi ers common categories macro level signi cance tests re ective performance classi ers rare categories 
necessarily mean signi cance tests invalid contrary table performance summary classi ers method mir mip mif maf error svm knn lsf nnet nb mir micro avg recall mip micro avg prec mif micro avg maf macro avg 
table statistical signi cance test results test test test test svm knn svm llsf knn llsf svm nnet knn nnet llsf nnet nb knn nb llsf nb svm nb nnet means value means value means value 
table test applied multiple measures mir mip error svm knn svm llsf knn llsf svm nnet knn nnet llsf nnet nb knn nb llsf nb svm nb nnet means di erent tests provide complementary analyses classi ers 
combine evidence di erent tests 
example test test test agree value range con dent suggested signi cance case agree 
table shows additional micro level performance analysis test multiple measures 
error rate comparison leads ordered list equivalent classes fsv llsf nnet nb indicates better classi er smaller error left hand side right hand side 
order classi ers suggested tests similar observed micro level sign tests svm knn grouped llsf nnet longer grouped 
test recall mir precision mip informative observations jointly 
example nb knn recall precision conclude knn signi cantly better hand knn versus svm decide better test outcomes recall precision agreement 
figures compare performance curves classi ers respect training set frequency categories 
curves obtained dividing horizontal axis equal sized intervals averaging scores interval classi er interpolating interval average scores 
focuses training set frequency range covering total unique categories nnet nb clearly worse easy rank 
shows performance curves full range training set frequencies categories ectiveness classi ers similar common categories training set frequency higher compared relative performance rare categories 
macro averaged macro averaged knn llsf svm nnet nb training set frequency category performance curves rare categories 
knn llsf svm nnet nb training set frequency category performance curves categories 
controlled study signi cance analyses known text categorization methods 
main signi cance analyses applied macro level evaluation text categorization systems jointly cross method comparison 
outcome signi cance test depends choice performance measure sensitivity ofthe test training set frequency categories tested 
micro level performance pooled category assignments sign test error proportion test suggest svm knn signi cantly outperform classi ers nb signi cantly classi ers 
respect macro level category level performance analysis signi cance tests conducted suggest svm knn llsf belong class signi cantly outperforming nb nnet 
acknowledgment bora verifying results statistical signi cance tests yue pan extending nb method allow category ranking multiple labels document 
apte damerau weiss 
language independent automated learning text categorization models 
proceedings th annual acm sigir conference 
apte damerau weiss 
text mining decision rules decision trees 
proceedings conference learning workshop learning text web 
douglas baker andrew mccallum 
distributional clustering words text categorization 
inproceedings th ann int acm sigir conference development information retrieval sigir pages 
berry lindgren 
statistics theory methods 
brooks cole paci grove california 
william cohen 
text categorization relational learning 
twelfth international conference machine learning icml 
morgan kaufmann 
william cohen yoram singer 
context sensitive learning methods text categorization 
sigir proceedings th annual international acm sigir conference research development information retrieval 

cortes vapnik 
support vector networks 
machine learning 
dasarathy 
nearest neighbor nn norms nn pattern classi cation techniques 
mcgraw hill computer science series 
ieee computer society press las alamitos california 
fuhr lustig tzeras 
air rule multistage indexing systems large subject elds 
editor proceedings riao 
hayes weinstein 
construe tis system content indexing database new stories 
second annual conference innovative applications articial intelligence 
iwayama tokunaga 
cluster text categorization comparison category search strategies 
proceedings th ann int acm sigir conference development information retrieval sigir pages 
thorsten joachims :10.1.1.11.6124
text categorization support vector machines learning relevant features 
european conference machine learning ecml 
koller sahami 
hierarchically classifying documents words 
fourteenth international conference machine learning icml pages 
lam ho 
generalized instance set automatic text categorization 
proceedings th ann int acm sigir conference development information retrieval sigir pages 
david lewis robert schapire james callan ron papka 
training algorithms linear text classi ers 
sigir proceedings th annual international acm sigir conference development information retrieval 

lewis ringuette 
comparison learning algorithms text categorization 
inproceedings third annual symposium document analysis information retrieval sdair 
masand waltz 
classifying news stories memory reasoning 
th ann int acm sigir conference research development information retrieval sigir pages 
mccallum nigam 
comparison naivebayes text classi cation 
workshop learning text categorization 
tom mitchell 
machine learning 
mcgraw hill 
moulinier 
learning bias issue text categorization problem 
technical report lip universite paris vi 
moulinier ganascia 
text categorization symbolic approach 
proceedings fifth annual symposium document analysis information retrieval 
ng goh low 
feature selection perceptron learning usability case study text categorization 
th ann int acm sigir conference research development information retrieval si gir pages 
osuna freund girosi 
support vector machines training applications 
memo 
mit lab 
platt 
minimal optimization fast algorithm training support vector machines 
technical report mst tr 
microsoft research 
tzeras hartman 
automatic indexing bayesian inference networks 
proc th ann int acm sigir conference development information retrieval sigir pages 
van rijsbergen 
information retrieval 
butterworths london 

nature statistical learning theory 
springer new york 
wiener pedersen weigend 
neural network approach topic spotting 
proceedings fourth annual symposium document analysis information retrieval sdair 
yang 
expert network ective cient learning human decisions text categorization retrieval 
th ann int acm sigir conference development information retrieval sigir pages 
yang 
sampling strategies learning ciency text categorization 
aaai spring symposium machine learning information access pages 
yang 
evaluation statistical approaches text categorization 
journal information retrieval appear 
yang chute 
example mapping method text categorization retrieval 
acm transaction information systems tois 
yang pedersen 
feature selection statistical learning text categorization 
fourteenth international conference machine learning pages 
