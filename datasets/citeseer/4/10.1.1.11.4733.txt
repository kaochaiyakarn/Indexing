emeralds small memory real time microkernel kang shin microsoft real time computing lab microsoft way department eecs redmond wa university michigan ann arbor mi microsoft com eecs umich edu emeralds extensible microkernel embedded real time distributed systems real time microkernel designed small memory embedded applications 
applications run slow mhz processors just kbytes memory keep production costs mass produced systems keep weight power consumption low 
feasible applications os small size kbytes low overhead kernel services 
commercial embedded oss rely carefully optimized code achieve efficiency emeralds takes approach redesigning basic os services task scheduling synchronization communication system call mechanism characteristics small memory embedded systems small code size priori knowledge task execution communication patterns 
new schemes overheads various os services reduced compromising os functionality 
real time computing systems behave predictably unpredictable environments 
predictability ensured system level services important real time operating system rtos 
rtos ensure real time tasks complete deadlines low priority execution communication activities able block higher priority tasks extended period 
wide variety real time applications multimedia industrial automation control variety hardware systems single board computers distributed systems multiprocessors resulted dozens designed support applications 
commercial psos qnx reported supported part nsf mip onr 
opinions findings recommendations authors necessarily reflect views funding agencies 
earlier version th acm symposium operating systems principles sosp 
done author university michigan 
vxworks support stand distributed systems 
research spring kernel designed multiprocessors research oss harmony rt mach distributed platforms 
designed relatively powerful processors networks mind processors megabytes memory networks tens mbit bandwidth 
fact just code size megabytes 
acceptable real time applications robotics telemetry multimedia 
real time computing today longer limited high powered expensive applications 
embedded real time control applications slow processors small memories tens kilobytes slow networks mbit bandwidth 
main reasons restricted hardware ffl keep production costs mass produced items home portable electronics automotive control systems 
ffl keep weight power consumption low avionics space applications 
category systems automotive engine abs controllers cellular phones produced volumes millions units 
keeping unit costs vital systems savings dollar unit translate millions dollars savings 
second category cost may primary limiting factor weight power consumption restrictions simply allow elaborate hardware 
result hardware feasible applications cheap slow processors limited amounts memory 
small memory embedded systems perform increasingly complex tasks 
automotive engine controllers sophisticated control algorithms increasing number sensors precisely control engine minimize exhaust emissions 
counteract jittery human operator stabilize picture 
cellular phones filtering algorithms produce clear sound 
algorithms run slow processors tens kilobytes chip rom static ram external memory increases cost volume weight power consumption target applications 
severe hardware restrictions mentioned applications till os 
application directly managed hardware resources 
applications sophisticated due additional functions introduced continuing approach infeasible application code difficult modify impossible port 
product development cycle long expensive application designer include os functionality application code 
need os small memory embedded applications opened new market small size low overhead 
provide predictable services efficient small size 
maximum acceptable kernel code size kbytes kernel services task scheduling system calls interrupt handling incur minimal overheads 
commercial vendors responded demand products psos select dozen small real time kernels 
approach take core set os services task scheduling semaphores timers interrupt handling implement optimized carefully crafted code package os 
emeralds rtos designed small memory embedded systems 
abovementioned commercial emeralds provides core set os services small sized kernel approach achieving efficiency emeralds rely carefully crafted code new os schemes algorithms 
focus key os services ffl task scheduling ffl semaphores ffl intra node message passing ffl memory protection system call overhead 
areas designed innovative schemes lower os overheads compromising os functionality making computational resources available execution application tasks 
achieve basic characteristics common small memory embedded systems small kernel application code size priori knowledge task communication execution patterns 
characteristics real time applications schemes task scheduler applicability small memory embedded systems 
section describe performance requirements rtos satisfy feasible embedded applications 
section presents brief overview emeralds 
section shows emeralds real time embedded os different generalized microkernels mach spin :10.1.1.117.6702
sections give details scheduling synchronization message passing system call schemes respectively 
performance schemes evaluated section conclude section 
embedded application requirements target embedded applications single chip microcontrollers relatively slow processing cores motorola derivatives running mhz 
typical examples motorola intel controllers 
rom ram chip limits memory size inter node networking issues discussed covered 
kbytes 
applications uniprocessor cellular phones home electronics distributed consisting nodes interconnected low speed mbit network automotive avionics control systems 
despite hardware restrictions rtos provide comprehensive set services 
task scheduling 
task synchronization semaphores 
task communication message passing 
memory protection 
interaction external environment interrupt handling 
clock timer services 
note disks small memory embedded systems file system part rtos 
basic services deal hardware devices chip timer processor interrupt handling mechanism overhead dictated primarily hardware 
optimizing kernel code os designer little reduce overhead services 
remaining services opportunities innovative optimizations 
thrust emeralds come new optimized solutions embedded systems known problems scheduling synchronization communication page table memory protection certain characteristics common embedded applications 
remainder section discusses improvements areas important embedded systems hurdles overcome reduce overhead os services 
task scheduling consider periodic task runs ms just task task scheduler run twice ms task released task completes 
considering typical os operations take slow processors concerned typical task workload consists tasks tasks having periods ms scheduler execution cpu time 
embedded application programmers till preferred cyclic time slice scheduling techniques entire schedule calculated line run time tasks switched fixed schedule 
reduces scheduler run time overhead introduces problems ffl schedules calculated hand difficult costly modify task characteristics change application design process 
heuristics calculate schedules result non optimal solutions feasible workloads may get rejected 
ffl cyclic schedulers give poor response times high priority aperiodic tasks arrival times tasks anticipated line 
ffl workload contains short long period tasks case control applications resulting time slice schedule quite large consuming significant amounts memory 
embedded systems having tasks aperiodic activities cyclic schedulers longer suitable task scheduling 
alternative turn priority driven schedulers rate monotonic rm earliest deadline edf task priorities run time decisions task execute 
schedulers require costly line analysis easily handle changes workload design process handle aperiodic tasks 
run time scheduling decisions incur overhead cpu time 
calls new task scheduling schemes lower overheads free time application tasks described section 
task synchronization object oriented oo programming ideal designing real time software 
real time systems deal real world entities objects ideal modeling entities object internal data represents physical state entity temperature pressure position rpm object methods allow state read modified 
notions encapsulation modularity greatly help software design process various system components sensors actuators controllers modeled objects 
oo paradigm real time software simply collection threads execution invoking methods various objects 
conceptually oo paradigm appealing gives benefits reduced software design time software re 
benefits come cost 
methods object synchronize access object data ensure mutual exclusion 
semaphores typically purpose provide monitor construct 
semaphore system call time object method invoked semaphore operations acquire release heavily os primitives oo design 
calls new efficient schemes implementing semaphore locking emeralds described section 
task communication traditional mechanism exchange information tasks message passing mailboxes 
scheme task prepares message invokes system call send message mailbox message retrieved receiver task 
scheme suitable certain purposes major disadvantages ffl passing message may take processor motorola 
tasks embedded applications usually need exchange messages second overhead unacceptable 
ffl task needs send message multiple tasks send separate message 
disadvantages application designers typically forced global variables exchange information tasks 
unsound software design practice reading writing variables regulated way introduce subtle hard trace bugs software 
requires new mechanisms intertask communication 
selected state message paradigm protected global variables available information exchange tasks 
optimized basic state message scheme reduce execution overhead memory consumption described section 
memory protection providing memory protection requires maintaining page tables programming memory management unit 
increases size kernel adds overhead kernel services contrary primary goal building small fast kernel 
need memory protection time shared systems 
user processes protected possibly malicious processes 
embedded systems processes cooperative try intentionally harm process making memory protection extraneous 
bugs application code manifest malicious faults 
example suppose pointer program left uninitialized 
pointer writing process easily corrupt process kernel 
message passing shared memory ipc processes threads scheduling memory management protection synchronization semaphores condition variables timers clock services kernel support user level device drivers interrupt handling kernel device drivers communication protocol architecture devices sensors actuators networks multi threaded user processes device drivers emeralds kernel emeralds architecture 
memory protection access cause trap kernel recovery action may taken providing form software fault tolerance 
memory protection fault may detected cpu crashes possibly catastrophic consequences 
emeralds kernel mapped user level address space 
way system call reduces trap jump appropriate kernel address need switch address spaces 
details section 
overview emeralds emeralds microkernel real time operating system written language 
emeralds salient features shown 
ffl multi threaded processes full memory protection processes 
threads scheduled kernel 
ffl ipc message passing mailboxes 
shared memory support provided 
optimized local message passing 
ffl semaphores condition variables synchronization priority inheritance semaphores 
ffl support communication protocol stacks 
ffl highly optimized context switching interrupt handling 
ffl support user level device drivers 
provide services small sized kbytes kernel certain characteristics embedded applications 
target applications memory file system needed 
embedded application designers know resources threads mailboxes reside node naming services necessary allowing considerable savings code size 
nodes embedded applications typically exchange short simple messages 
threads talking directly network device drivers emeralds built protocol stack 
details regarding protocol stacks device drivers emeralds system calls techniques reduce code size emeralds 
techniques emeralds provides rich set os services just kbytes code 
embedded rtos small efficient 
remainder focus new kernel schemes reducing overheads scheduling synchronization message passing system calls 
emeralds different microkernel optimization active area research years little effort addressing needs real time systems small memory embedded ones 
microkernels designed general purpose computing mach spin researchers focused optimizing kernel services thread management ipc virtual memory management :10.1.1.13.9310:10.1.1.117.6702:10.1.1.111.7918:10.1.1.158.4191
virtual memory concern target applications 
thread management ipc important reasons general purpose computing 
sources os overhead different embedded real time systems general purpose computing systems necessitates different optimization techniques 
thread management concern typical microkernels kernel large number threads user level thread switching overhead stack threads minimized case user level threads kernel export correct interface threads :10.1.1.13.9310
concerns apply emeralds 
emeralds kernel managed threads kernel threads 
system call user thread enters protected kernel mode simply calls appropriate kernel procedure see section 
important real time environment threads scheduled properly ensure timely completion real time tasks 
emeralds optimizing thread management takes form ensuring low overhead transition user kernel modes providing efficient real time scheduling threads 
ipc important microkernels rpc communicate user level servers 
frequently accessed services file systems virtual memory implemented servers 
embedded systems need services 
emeralds inter node networking implemented user level server accessed infrequently nodes loosely coupled 
ipc important embedded systems inter task communication address emeralds 
task synchronization receive attention design microkernels crucial importance embedded systems 
little research conducted area focused primarily multiprocessors interested uniprocessor locking 
summary design optimized os small memory real time embedded applications largely explored area research 
embedded systems quickly part everyday life designing oss targeted specifically embedded applications important witnessed emergence commercial see section emeralds step direction 
combined static dynamic scheduler task scheduler overhead broken components run time overhead schedulability overhead run time overhead time consumed execution scheduler code 
managing queues tasks selecting highest priority task execute task blocks unblocks 
schedulability overhead defined gamma ideal schedulable utilization 
workload scheduler highest workload utilization scheduler feasibly schedule ideal conditions scheduler run time overhead ignored 
best explained examples 
consider workload tasks ng 
task period execution time deadline assume stated see methods derive schedulability conditions restriction relaxed 
note inside kernel tasks represented threads 
workload utilization obviously scheduler schedule workload 
edf dynamic priority scheduler gives highest priority earliest deadline task schedule workloads ideal condition edf run time overhead ignored 
edf utilization edf schedule ideal conditions 
schedulers static priority rm scheduler schedules tasks fixed priorities tightness 
example workload may schedulable rm slightly increased workload may longer schedulable ideal conditions 
workload rm 
means cpu time wasted scheduling policy refer schedulability overhead edf zero schedulability overhead high run time overhead 
rm low run time overhead depending workload cause significant schedulability overhead 
rest section analyze sources overheads devise scheduler low schedulability run time overheads gives better performance edf rm 
note static dynamic priority schedulers advantages disadvantages mentioned 
example dynamic schedulers general handle aperiodic tasks better static schedulers 
hand static schedulers may provide better guarantees completion critical tasks processor overload situations 
detailed discussion issues scope 
interested readers referred comparisons various scheduling methodologies 
focus schedulability run time overhead properties edf rm schedulers 
run time overhead run time overhead deltat parsing queues tasks adding deleting tasks queues 
running task blocks os update data structures identify task blocked pick new task execution 
call overheads associated steps blocking overhead deltat selection overhead deltat respectively 
similarly blocked task unblocks os update internal data structures incurring unblocking overhead deltat os pick task execute newly unblocked task may higher priority previously executing selection overhead incurred 
task blocks unblocks period unblocked period blocks executing time units 
means minimal scheduler run time overhead task deltat deltat deltat incurred period 
overhead greater uses blocking system calls execution 
application dependent assume half tasks block execution waiting message signal sent half tasks 
simplicity say task suffers run time overhead deltat deltat deltat deltat 
run time scheduler overhead figured workload utilization deltat significantly greater utilization deltat ignored 
calculate deltat edf rm scheduling policies 
emeralds implemented edf follows 
blocked unblocked tasks lie single unsorted queue 
sense task priorities change continually edf especially priority inheritance semaphores cause repeated changes thread priorities described section keeping queue sorted worth overhead 
tasks blocked unblocked changing variable appropriate task control block tcb 
select task execute entire list parsed earliest deadline ready task picked 
scheme deltat deltat deltat number tasks 
deltat counted twice task block unblock operation deltat edf increases rapidly increases 
typical implementation rm queue ready tasks sorted fixed task priorities 
blocking unblocking involve deletion insertion list sorted order 
emeralds chose different implementation allows optimize semaphores discussed section run time overhead stays typical implementation 
blocked unblocked tasks single queue sorted priority task 
single pointer points highest priority ready task deltat task execute 
block task variable updated tcb edf updated 
scheduler parses queue till finds ready task queue sets point task 
deltat takes time 
hand unblocking task involves checking unblocked task higher priority task 
simply reset point newly unblocked task takes time 
rm deltat edf deltat 
deltat counted task block unblock operation deltat counted twice deltat deltat deltat deltat significantly rm edf especially large 
schedulability overhead mentioned edf zero schedulability overhead run time overhead ignored scheduler better edf 
previous shown average time misses deadline rm scheduling workload table 
rm 
see rm edf consider workload shown table 
task deadline workload feasible edf 
ms ms table typical task workload 
feasible edf rm 
shows happens workload scheduled rm 
time interval tasks execute run released 
rm higher priority shorter run execute second time missed deadline 
workload infeasible rm illustrates rm non zero schedulability overhead 
hand edf schedule workload run run second time earlier deadlines second invocations workload feasible 
csd balance edf rm going back workload table notice troublesome task task workload infeasible rm 
tasks longer periods easily scheduled scheduler rm edf 
observation basis combined static dynamic csd scheduler 
csd tasks scheduled edf deadline 
trouble task taken care low overhead rm policy schedule remaining tasks way run time overhead csd edf edf queue length halved little rm 
schedulability overhead csd edf zero rm 
total scheduling overhead csd significantly edf rm 
csd scheduler maintains queues tasks 
queue dynamic priority dp queue contains tasks scheduled edf 
second queue fixed priority fp queue contains tasks scheduled rm fixed priority scheduler deadline monotonic simplicity assume rm policy fp queue 
workload ng tasks sorted rm priority tasks shorter periods lower index troublesome task workload 
tasks placed dp queue fp queue 
csd gives priority dp queue fp queue 
sense tasks dp queue higher rm priority shorter periods task fp queue 
single counter keeps track number ready tasks dp queue 
incremented dp task ready decremented dp task blocks 
scheduler invoked checks counter 
greater zero dp queue parsed pick earliest deadline ready task 
dp queue skipped completely scheduler picks highest priority ready task fp queue pointed 
run time overhead csd mentioned csd zero schedulability overhead 
run time overhead depends task blocked unblocked dp fp task 
possible cases 
dp task blocks deltat constant edf deltat depends ready tasks left dp queue 
real time schedulability analysis interested worst case overhead occurs ready tasks dp queue 
deltat time parse dp queue deltat edf queue length deltat 

dp task unblocks deltat constant edf 
ready task definitely dp queue just unblocked deltat time parse long dp queue deltat 

fp task blocks deltat rm queue length gamma deltat gamma 
regarding deltat need know dp task ready 
possible task just blocked fp task task executing dp tasks ready 
dp queue ready tasks scheduler just selects fp queue 
deltat rm 

fp task unblocks deltat constant rm 
dp queue may may ready tasks worst case deltat assume deltat 
analysis total scheduler overhead csd deltat deltat block deltat deltat unblock task block unblock operation 
dp tasks fp tasks overhead equals gamma 
means long list parsed twice dp tasks worst case long list parsed fp tasks 
comparing edf long list parsed twice rm long list parsed see run time overhead csd significantly edf considering median see section slightly greater rm 
considering csd schedulability overhead easily outperforms edf rm 
corroborated performance measurements section 
schedulability test task set ng tasks sorted priority tasks shorter periods lower index feasible edf deltat edf deltat edf deltat edf 
workload feasible rm min td deltat rm practice equation need evaluated finite number values described 
schedulability csd tested follows 
check dp tasks feasible edf udp deltat dp check feasibility fp tasks follows min td deltat check done fp tasks goes considers dp tasks having higher priority fp task goes 
best possible length dp queue workload iteratively 
start assuming perform schedulability test 
successful keep increasing schedulability test passes exceeds case workload feasible csd 
reducing run time overhead csd csd main advantage uses edf deliver schedulable utilization cuts back run time overhead keeping dp queue short 
number tasks workload increases dp queue length increases degrades csd performance 
rectify situation modify csd keep run time overhead control number tasks increases 
controlling dp queue run time overhead csd effective execution time task dp queue increases deltat dp depends length dp queue deltat dp increases rapidly increases degrades performance csd 
solution problem split dp queue queues dp dp 
dp tasks higher rm priority shorter periods scheduler gives dp priority dp 
call modified scheme csd queues 
properly allocating tasks dp dp discussed section note dp dp expected significantly shorter original dp queue run time overhead csd original csd scheme call csd discussed 
run time overhead csd run time overheads csd derived reasoning csd section 
overheads different cases shown table length dp queue total number dp tasks gamma length dp queue 
table shows run time overhead associated dp tasks significant improvement csd 
dp tasks shortest period tasks workload ones execute frequently responsible scheduling overhead 
reducing run time overhead associated tasks leads csd performing significantly better csd 
dp dp fp task deltat gamma blocks deltat max gamma task deltat unblocks deltat max gamma max gamma total run time overhead gamma gamma table run time overheads csd 
total values assume dp queue longer dp queue max gamma gamma typically case 
run time overhead dp tasks reduced csd gamma 
similarly overhead fp tasks reduced gamma 
allocating tasks dp dp dp tasks periods split evenly dp dp 
queue length half original dp queue 
cut run time overhead scheduling dp tasks half give best possible reduction scheduler overhead 
tasks different periods factors considered dividing tasks dp dp ffl tasks shortest periods responsible scheduler run time overhead 
example suppose deltat ms task ms responsible deltat cpu overhead task ms responsible 
means tasks short periods kept dp keep deltat dp small 
dp tasks dp 
deltat dp deltat dp balance tasks dp longer periods deltat queues approximately balanced 
ffl balancing run time overhead queues sole criterion allocating tasks dp dp scheduling overhead considered 
dp tasks split queues longer incur zero schedulability overhead 
tasks dpx queue scheduled edf queues scheduled rm dp tasks statically higher priorities dp tasks csd non zero schedulability overhead 
tasks allocated dp dp minimize sum run time schedulability overheads 
example consider workload table 
suppose run time overhead results putting tasks increasing number queues increases overhead parsing prioritized list queues measurements showed increase negligible microsecond going queues 
dp rest dp tasks dp cause deadline see 
putting dp may lead slightly higher run time overhead lower schedulability overhead meet deadline 
exhaustive search schedulability test described find best possible allocation tasks dp dp fp queues 
search runs schedulability test times queues 
takes minutes mhz ultra sun workstation workload tasks 
schedulability test csd assume task set ng tasks sorted rm priority 
dp tasks scheduled edf tasks feasible deltat dp dp tasks priority dp tasks dp tasks scheduled edf 
modify test fp tasks dp tasks 
check schedulability dp task test treats dp tasks having higher priority runs checks deadlines dp tasks runs decide invocations priority invocation min td deltat dp deltat dp function dxe excludes invocation released time deadline exceeds il gamma gamma test dp tasks uses critical time zone assumption valid dp dp tasks utilization deltat dp dp dp dp task respectively 
note check deadlines critical time zone assumption automatically valid rate monotonic analysis 
test fp tasks csd minor modifications min td deltat dp dp fp dp dp fp task respectively 
csd general scheduling framework csd limited just queues 
extended queues 
extreme cases queue queues equivalent rm intermediate cases give combination rm edf 
expect csd slightly better performance csd confirmed evaluation results section performance gains expected taper number queues gets large increase schedulability overhead having multiple edf queues starts exceeding reduction run time overhead 
workload best number queues best number tasks queue exhaustive search computationally intensive task discussed 
demonstrated usefulness general csd scheduling framework beneficial real systems 
efficient semaphore implementation previous lowering overhead semaphore operations focused relaxing semaphore semantics get better performance coming new semantics new synchronization policies 
problem approach new modified semantics may suitable particular applications usually wide applicability 
took approach providing full semaphore semantics priority inheritance optimizing implementation semaphores exploiting certain features embedded applications 
step designing efficient semaphores look way semaphores typically implemented various systems identify distinct steps involved locking unlocking semaphores try eliminate optimize steps incur greatest overhead characteristics common small memory embedded applications 
standard semaphore implementation standard procedure lock semaphore summarized follows sem locked priority inheritance add caller thread wait queue block wait sem released time thread execution context switch lock semaphore unlock semaphore typical scenario showing thread attempting lock semaphore held thread unrelated thread executing blocked 
lock sem priority inheritance needed real time systems avoid unbounded priority inversion 
high priority thread calls acquire sem semaphore locked thread priority temporarily increased 
priority inheritance medium priority thread tm get control cpu preempting remains blocked semaphore causing priority inversion 
priority inheritance keep running unlocks semaphore 
point priority go back original value unblocked continue execution 
notice semaphore free acquire sem called semaphore lock operation little overhead 
fact case counter incremented variables updated 
real time systems interested worst case overheads semaphores occurs semaphore locked thread thread invokes acquire sem call 
shows typical scenario situation 
thread wakes completing unrelated blocking system call calls acquire sem 
results priority inheritance context switch current lock holder 
releases semaphore priority returns original value context switch occurs steps outlined 
tasks scheduled edf context switches responsible largest overhead deltat incurred takes time remaining operations take time 
reason focus optimization efforts eliminating context switches result performance improvement dp tasks 
fp tasks context switches incur fixed albeit significant overhead eliminating context switch beneficial fp tasks dp tasks 
priority inheritance pi steps take gamma time task removed fp queue re inserted sorted order new priority 
remaining operations take time block operation pi operation preceding block unblock context switch executes calls acquire sem priority inheritance block context switch executes calls release sem undo priority inheritance unblock context switch operations involved locking semaphore scenario shown resets block operation doesn 
fp tasks focus optimization efforts pi operations 
implementation emeralds going back want eliminate context switch 
want optimize pi steps 
deal occurs unblocked blocking system call call wait event message arrival timer expiry 
executes calls acquire sem block semaphore locked idea event occurs letting run execute 
go release semaphore activated point saving 
implemented follows 
part blocking call just preceding acquire sem instrument code code parser described add extra parameter indicates semaphore intends lock semaphore case 
event occurs unblocked os checks available 
unavailable priority inheritance current lock holder occurs right 
added waiting queue remains blocked 
result scheduler picks execute eventually releases unblocked part release sem call comparing see context switch eliminated 
semaphore lock unlock pair operations incur context switch resulting considerable savings execution time overhead dp tasks see section performance results 
fp tasks want optimize pi steps takes gamma time 
time thread execution context switch lock semaphore unlock semaphore switch new semaphore implementation scheme 
context switch eliminated 
pi step inherits priority easily optimized observation new priority position fp queue just ahead position 
parsing fp queue find correct position insert insert directly ahead parsing queue reduces overhead 
want reduce overhead second pi step 
step returns original priority 
want having parse entire queue 
incorrect solution remember neighbors original position queue attempt return position inserting neighbors 
neighbors undergo priority inheritance position queue change scheme 
solution emeralds switch positions queue part pi operation inherits priority 
puts correct position new priority acts place holder remember original position queue 
question safe put position lower dictated priority 
answer 
long stays blocked position queue 
unblocks releases semaphore time switch positions restoring original priorities 
scheme pi operations take time 
complication arises inherits priority third thread attempts lock semaphore inherits priority 
case place holder just goes back original position 
involves extra step compared simple case described initially overhead 
note optimizations pi operations possible scheduler implementation keeps ready blocked tasks queue 
fp queue contained ready tasks kept place holder tcb queue 
code parser emeralds blocking calls take extra parameter identifier semaphore locked upcoming acquire sem call 
parameter set gamma blocking call acquire sem 
semaphore identifiers statically defined compile time emeralds commonly case oss small memory applications trivial write parser examines application code inserts correct semaphore identifier argument list blocking calls just preceding acquire sem calls 
application programmer manual modifications code 
schedulability analysis new scheme viewpoint schedulability analysis concerns regarding new semaphore scheme refer back 
thread block call preceding acquire sem 
happen event occurred call 

safe delay execution may higher priority doing priority inheritance earlier occur 
regarding concern block call preceding acquire sem context switch saved 
situation continue execute till reaches acquire sem context switch occur 
scheme really provides context switch saved acquire sem call preceding blocking call 
savings occur run time really matter calculation worst case execution times schedulability analysis 
second concern answer safe execute earlier 
concern may deadline 
happen circumstances wait release semaphore complete 
schedulability analysis point view really happens chunks execution time swapped affecting completion time applicability new scheme going back suppose lock holder blocks event releasing semaphore 
standard semaphores able execute till reaches thread execution context switch lock sem 
preempted switch thread block higher priority thread preempts locks semaphore blocks incurs full overhead acquire sem context switch saved 
acquire sem scheme stays blocked 
gives rise concern new semaphore scheme may deadline 
priority lower call case 
different problem arises higher priority call case 
suppose semaphore free event occurs 
unblocked start executing 
call acquire sem wakes preempts locks blocks event 
resumes calls acquire sem blocks unavailable 
context switch saved benefit comes semaphore scheme 
problems occur thread blocks holding semaphore 
problems resolved follows 
making small modification semaphore scheme change problem case problem case leaves problem address 
looking larger picture considering threads just show problem easily circumvented semaphore scheme works blocking situations occur practice discussed 
modification semaphore scheme problem illustrated necessitates small modification scheme 
want block higher priority thread locks unblock releases prevent executing locked situation case recall event occurs os checks available unblocking extend scheme os adds special queue associated queue holds threads completed blocking call just preceding acquire sem called acquire sem 
thread get added queue part blocking call just preceding acquire sem 
calls acquire sem os removes queue puts threads re time thread execution context switch lock sem 
unlock sem 
switch stays blocked switch ts block signal situation lock holder blocks signal thread queue blocked state 
calls release sem os unblocks threads queue 
modification remaining concern cases execution delayed threads possibly lower priority execute may deadline 
concern addressed 
applicability various blocking situations types blocking ffl wait internal event wait signal thread reaches certain point 
ffl wait external event environment 
event periodic aperiodic 
blocking internal events handshake threads typical scenario type blocking thread enter object lock semaphore block waiting signal thread stays blocked 
perfectly safe delay lower priority lock releases release receives signal letting execute earlier leads releasing earlier leaves time complete deadline 
blocking external events external events periodic aperiodic 
periodic events polling usually interact environment blocking occur 
blocking calls wait aperiodic events sense calls inside object 
possibility aperiodic event may occur long time 
thread blocks waiting event inside object may keep object locked long time preventing threads making progress 
usual practice semaphores locked blocking aperiodic event 
short dealing external events periodic aperiodic affect applicability semaphore scheme commonly established ways handling external events 
state messages intertask communication performance point view global variables ideal sharing information tasks reading writing global variables regulated subtle bugs crop application code 
state messages global variables pass messages tasks variables managed code generated automatically software tool application designer 
fact application designer know global variables interface programmer mailbox message passing interface 
state messages meant replace traditional message passing meant efficient alternative traditional message passing wide range situations explained 
state message semantics state messages solve single writer multiple reader communication problem 
imagine state message mailboxes associated senders receivers task send state message mailbox call writer task tasks read mailbox call reader tasks 
way state message mailboxes behave differently traditional mailboxes call differences summarized 
ffl associated writers 
writer may send message multiple readers receive message 
ffl new message overwrites previous message 
ffl reads consume messages standard mailboxes read operation pops message message queue 
ffl reads writes non blocking 
reduces number context switches suffered application tasks 
usefulness real time systems piece data sensor reading valid certain duration time new reading 
suppose task reads sensor supplies reading task sends messages message useless second message date sensor reading 
traditional mailboxes queues communication read old sensor reading get new 
multiple tasks need sensor reading send separate message 
state messages streamline entire process 
sm associated known tasks sm contains reading certain sensor 
time reads sensor send value sm 
tasks want receive sensor value perform individual read operations sm receive date reading 
sent message sm reads task reader task get message having process outdated messages 
importantly reader reads writes reader get message time blocking perfect sense real time systems data received reader valid date useful calculations 
single writer multiple reader situation quite common embedded real time systems 
time data produced task may sensor reading calculated value sent tasks state messages 
situations blocking read operations necessary task wait event occur 
traditional message passing semaphores 
state messages replace traditional message passing situations replace inter task communication requirements embedded applications 
previous state messages mars os implemented 
state message implementation systems described follows 
problem global variables passing messages reader may read half written message synchronization readers writers 
problem solved deep circular buffer state message 
associated pointer writer post messages readers retrieve latest message 
deep buffer scheme guarantee data corrupted read reader large state messages infeasible limited memory target applications 
solution limits having readers repeat read operation get uncorrupted data 
saves memory cost increasing read time microseconds assumption writers readers run separate processors shared memory 
architecture possible reader preempt writer 
want state messages communication readers writers cpu increasing read overheads 
situation depending relative deadlines readers writers may hundreds ensure correct operation 
solution problem provide os support state messages reduce possible cases 
follows describe implementation state messages including calculation case readers writers residing cpu 
describe system call included emeralds support state messages 
implementation state messages emeralds maximum number bytes cpu read write instruction 
processors bytes 
tool produces customized code implementation state messages depending message length exceeds 
case simple 
assigns byte global variable state message provides macros writer write variable readers read 
note simple case perfectly safe global variables 
complication possible global variable length writer accidentally overwrite value written variable writer 
problem occur state messages definition writer 
case assigns deep circular buffer state message 
slot buffer bytes long 
state message byte index initialized 
readers read slot writer writes slot incremented write complete 
way readers get consistent copy message 
calculating buffer depth address issue set depth buffer 
possible reader starts reading slot buffer preempted reading part message resumes writer done number write operations message 
greater largest value take max xmax time calculation max write operations denoted excluding write gamma pw gamma dw writes xmax 
maximum time reader take execute read operation including time reader may stay preempted 
tasks complete deadlines ensured scheduler maximum time task preempted gamma deadline execution time 
time execute read operation gamma gamma largest number write operations possible occur situation shown write occurs late possible just deadline writer remaining writes occur soon possible right writer period 
max gamma gamma pw gamma dw pw pw dw writer period deadline respectively 
calculated max slow readers turns readers long periods deadlines call slow readers result max large say memory needed buffer emeralds provides system call executes read operation described disables interrupts copying message buffer atomic operation 
call slow readers faster readers standard read operation 
doing depends faster readers memory saved 
disadvantage system call takes longer standard read operation 
system call invoked slow readers invoked infrequently extra overhead second negligible 
note write operation unchanged matter readers slow fast 
memory protection system calls benefits memory protection mentioned earlier section practical implementation memory protection efficient small sized 
fact small null null null null null null null null null null null null null null null null null null null null null null null null null null level second level third level code data stack typical page table emeralds 
specially commercial ones include memory protection belief negative impact performance unacceptable 
show belief unfounded 
get efficient small sized implementation memory protection full fact target applications memory 
enabled reduce total size page table kbytes relying special hardware features 
virtual memory systems disk backing stores need distinguish unmapped pages swapped disk 
memory systems distinction needed 
allows page table trimmed hierarchical nature page tables 
example motorola level page tables 
third level page table represents kbytes address space 
process segments code data stack kbytes page table shown 
entries level page table null second level page tables exist 
attempt access address covered invalid entry result trap kernel indicating bug software 
similarly second level page table entry valid third level page tables exist 
way total size page table just bytes page size kbytes 
third level page tables needed segment exceeds kbytes 
example specific mc modern cpus provide level page tables similar parameters 
oss virtual memory disk backing stores small page tables achieve hardware support 
linux uses segment registers processors user code kernel code user data user stack kernel data kernel stack free free typical address space emeralds 
area labeled kernel stack interrupts area labeled user stack user kernel 
distinguish unmapped swapped pages 
vax vms uses page table length register vax achieve goal 
depending hardware support embedded systems feasible increases hardware costs 
small size page tables saves memory enables optimizations mapping kernel address space 
typical bit emeralds address space shown 
type mapping switch user kernel involves just trap switches cpu user kernel supervisor mode jump appropriate address need switch address spaces 
system call code emeralds designed take parameters straight user stack possible kernel user address space need copy parameters user space kernel space 
assembly code making system calls point kernel stack pointer user stack minor stack adjustments 
result system calls emeralds involving servers overhead comparable subroutine call see section 
note mapping kernel user address space feasible emeralds kernel data segment small 
operating systems standard virtual memory size kernel data segment large due large page tables directly mapping address space feasible 
oss windows nt lazy mapping scheme portions kernel data segment dynamically mapped user address spaces needed incurs high unpredictable overhead manipulating page tables system call needs access data discovers page mapped current address space 
schemes appropriate embedded systems high overhead unpredictability 
emeralds mapping kernel address space achieved having appropriate second level page table entries point common third level page tables map kernel 
size process page table affected 
address space set page table needed leading low overhead 
kernel areas protected corruption buggy user code page table entries mark read user mode 
way user processes protected kernel protected user processes 
performance evaluation emeralds implemented motorola processor 
code size just kbytes 
emeralds ported powerpc super hitachi sh motorola microcontroller popular automotive control applications 
section evaluate benefits scheduling semaphore messagepassing system call schemes far 
evaluations performed mhz mc kbyte caches 
measurements mhz chip timer 
emeralds evaluated scientific research laboratory ford motor automotive engine control 
initial testing focused basic os overheads related interrupt handling context switching event signaling timer services 
evaluation covered commercial addition emeralds evaluation results section 
csd scheduler subsection evaluate usefulness csd scheduling wide variety workloads comparing csd edf rm 
particular want know best scheduler scheduling overheads run time schedulability considered 
edf rm run time overheads emeralds measured mhz motorola processor separate kbytes instruction data caches table 
run time overhead csd derived values discussed sections 
overhead parse list queues csd find queue ready tasks measured queue 
table shows run time overhead rm sorted heap linked list hold tasks 
total run time overhead deltat heap queue 
real time workloads tasks heaps feasible rest section measurements queues 
test procedure involves generating random task workloads workload scaling execution times tasks workload longer feasible scheduler 
edf queue rm queue rm sorted heap deltat dlog deltat dlog deltat table run time overheads edf rm number tasks 
shows measurements rm heap linked list 
measurements mhz chip timer 
utilization workload infeasible called breakdown utilization 
expect scheduling overheads considered csd highest breakdown utilization 
scheduling overheads function number tasks workload tested schedulers workloads ranging 
generate workloads random task periods execution times 
scale execution times check feasibility schedulability tests sections workload infeasible 
run time overhead priority schedulers depends number tasks periods tasks scheduler invoked time task blocks unblocks 
short period tasks lead frequent invocation scheduler resulting high run time overhead long period tasks produce opposite result 
tests vary number tasks periods tasks 
generating base workload fixed producing workloads dividing periods tasks factor 
allows evaluate impact varying task periods various scheduling policies 
generate base task workloads randomly selecting task periods period equal probability single digit ms double digit ms triple digit ms 
figures show breakdown utilizations task periods divided respectively 
task periods relatively long ms 
run time overheads low allows edf perform close theoretical limits 
csd performs better edf 
csd lower total scheduling overhead increases edf strong dependency begins degrade performance 
periods ms range 
moderate length periods initially edf better rm edf run time overhead increases point rm superior 
csd overhead edf csd lower overhead rm turn lower overhead edf large 
shows similar results 
task periods range ms short periods allow rm quickly overtake edf 
csd continues superior 
number tasks csd csd csd edf rm average breakdown utilizations csd edf rm task periods scaled factor 
number tasks csd csd csd edf rm average breakdown utilizations csd edf rm task periods scaled factor 
number tasks csd csd csd edf rm average breakdown utilizations csd edf rm task periods scaled factor 
figures show comparison varieties csd 
show significant performance improvement seen csd csd especially large minimal improvement observed csd csd 
run time overhead continues decrease increase schedulability overhead reduction run time overhead 
csd expected give significantly better breakdown utilization csd workloads easily partitioned queues increasing schedulability overhead rarely case 
dp tasks statically higher priority dp tasks dp tasks higher priority dp tasks 
number queues increases schedulability overhead starts increasing edf rm 
expect increases performance csd quickly reach maximum start decreasing reduced schedulability increased overhead managing queues increases queue 
eventually approaches performance csd degrade rm 
results confirm superiority csd scheduling framework compared edf rm 
results show csd suffers high run time overhead large csd overcomes problem significant increase schedulability overhead 
way csd delivers consistently performance wide range task workload characteristics 
increasing number queues gives improvement performance schedulability overhead starts increasing rapidly queues yields minimal improvement performance 
number threads standard implementation new implementation worst case performance measurements dp tasks 
overhead standard implementation increases twice rapidly new scheme 
semaphore scheme thread enters object acquires semaphore protecting object exits object releases semaphore 
cumulative time spent operations represents overhead associated synchronizing thread access objects 
determine overhead reduced scheme measured time acquire release pair operations standard semaphores new scheme compared results 
semaphore scheme eliminates context switch optimizes priority inheritance mechanism fp tasks performance scheme depends relevant tasks dp fp queue number tasks queue 
shows semaphore overheads tasks dp queue number tasks queue varied 
context switch overhead linear function number tasks dp queue deltat acquire release times increase linearly queue length 
standard implementation overhead involves context switches new scheme incurs measurements standard scheme slope twice new scheme 
typical dp queue length scheme gives savings standard implementation improvement savings grow larger dp queue length increases 
fp queue standard implementation linearly increasing overhead new implementation overhead constant priority inheritance takes time 
context switch eliminated 
result acquire release overhead stays constant number threads standard implementation new implementation worst case performance measurements fp tasks 
overhead standard implementation increases linearly new scheme constant overhead 
state messages mailboxes send bytes receive bytes receive slow bytes table overheads sending receiving byte messages 

fp queue length improvement standard implementation 
general scheme gives performance improvements depending tasks involved locking unlocking semaphore dp fp queue length queue 
state messages table shows comparison overheads state messages mailbox message passing 
measurements message sizes bytes exchange sensor readings actuator commands embedded control applications 
overhead state message operations due copying message mailbox ipc overheads allocation deallocation kernel data structures manipulation message queues state messages clearly outperform mailboxes small message lengths typical embedded applications 
example application exchanges byte messages second assume received tasks long periods receive slow mailboxes give overhead ms state messages results overhead overhead null subroutine call null system call table comparison overheads null subroutine system calls 
ms 
overhead decreases message multiple recipients mailboxes separate send needed recipient send state messages 
efficient system calls table shows comparison overheads null subroutine call null system call 
incurs extra overhead context switch needed kernel mapped address space 
comparison commercial scientific research laboratory srl ford motor evaluated performance emeralds commercial embedded automotive engine control 
include nucleus psos select rtx rtos executive mc 
initial testing srl focused measuring overheads basic os services interrupt handling task switching timers clock tick mhz motorola microcontroller 
results shown results released srl identify measurements os refer commercial os os 
number interrupts second engine controller service depends engine speed 
high rpm revolutions minute controller sees interrupts rate various overhead ranging cpu time 
emeralds best overhead 
os lower overhead compared oss higher ram overhead bytes tasks compared bytes oss including emeralds os infeasible small memory embedded systems srl standards 
results show far basic os overheads concerned emeralds implementation quite efficient 
gives various performance measurements earlier section distorted due poor implementation basic os services 
mmu results version emeralds memory protection 
interrupts sec os os os os os os os os emeralds os os overhead due interrupts periodic task switches ms clock tick timer 
srl planning detailed evaluation measure effect os overheads varying number resources threads semaphores mailboxes application 
small memory embedded applications commonplace automotive home electronics avionics complexity applications increasing 
result embedded applications previously managed hardware resources directly need embedded handle increased complexity application 
efficient small size feasible slow cheap processors small memory applications 
commercial embedded rely optimized code achieving efficiency design emeralds took different approach 
identified key os services responsible large portion os overhead seen applications re designed services new schemes exploit certain characteristics common embedded applications 
area task scheduling csd scheduler creates balance static dynamic scheduling deliver greater breakdown utilization reduction scheduling overhead compared edf rm 
task synchronization new implementation semaphores eliminates context switch reduces priority inheritance overhead achieve improvement semaphore lock unlock times 
semaphore scheme wide applicability compared optimization schemes certain applications 
message passing emeralds uses state message paradigm incurs overhead mailbox message passing message sizes typical embedded applications 
previous schemes state messages scheme bounds ram overhead providing os support state messages 
mapping kernel address space emeralds reduces overhead system calls null system call takes null subroutine call mhz mc 
plan focus networking issues 
investigated networking small number nodes 
investigate ways efficiently cheaply interconnect large number clusters embedded processors 
cluster small number nodes connected 
clusters interconnected cheap shelf networks new protocols designed allow efficient real time communication clusters 
type networking needed aircraft ships factories allow various semi independent embedded controllers may small memory may coordinate activities 
acknowledgment authors steven scott ford srl comparative evaluation data emeralds commercial embedded 
shin ramanathan real time computing new discipline computer science engineering proceedings ieee vol 
pp 
january 
thompson psos embedded real time computing compcon pp 

architectural overview qnx proc 
usenix workshop microkernels kernel architectures april 
vxworks programmer guide wind river systems 
shin kandlur dodd rosenberg distributed real time operating system ieee software pp 
september 
stankovic ramamritham spring kernel new paradigm real time operating systems acm operating systems review vol 
pp 
july 
gentleman realtime applications multiprocessors harmony proc 
east pp 
october 
tokuda nakajima rao real time mach predictable real time system proc 
usenix mach workshop october 
art programming embedded systems academic press 
smart networks control ieee spectrum vol 
pp 
june 
user manual embedded system products 
shin non preemptive scheduling messages controller area network real time control applications proc 
real time technology applications symposium pp 
may 
shin scheduling messages controller area network real time cim applications ieee trans 
robotics automation pp 
april 
accetta baron bolosky golub rashid tevanian young mach new kernel foundation unix development proc 
summer usenix pp 
july 
bershad savage pardyak sirer fiuczynski becker chambers eggers extensibility safety performance spin operating system proc :10.1.1.117.6702
symp 
operating systems principles pp 

jones rosu 
rosu cpu reservations time constraints efficient predictable scheduling activities proc 
symp 
operating systems principles pp 
october 
liu layland scheduling algorithms multiprogramming hard real time environment journal acm vol 
pp 
january 
ishikawa tokuda mercer object oriented real time programming language ieee computer vol 
pp 
october 
dijkstra cooperating sequential processes technical report technical university eindhoven netherlands 
habermann synchronization communicating processes communications acm vol 
pp 
march 
hoare monitors operating system structuring concept communications acm vol 
pp 
october 
kopetz damm koza distributed fault tolerant real time systems mars approach ieee micro vol 
pp 
february 
shin efficient host protocol processing architecture realtime audio video traffic appear proc 
network operating system support digital audio video nossdav july 
shin emeralds microkernel embedded real time systems proc 
real time technology applications symposium pp 
june 
liedtke beyer szalay years experience kernel os operating systems review pp 
april 
draves bershad rashid dean continuations implement thread management communication operating systems proc 
symp 
operating systems principles pp 

anderson bershad lazowska levy scheduler activations effective kernel support user level management parallelism proc :10.1.1.13.9310
symp 
operating systems principles pp 

liedtke improving ipc kernel design proc :10.1.1.158.4191
symp 
operating systems principles pp 

rashid tevanian young golub baron black bolosky chew machine independent virtual memory management paged uniprocessor multiprocessor architectures ieee transactions computers vol :10.1.1.111.7918
pp 
august 
mellor crummey scott algorithms scalable synchronization shared memory multiprocessors acm transactions computer systems vol 
pp 
february 

wang priority inheritance spin locks multiprocessor real time systems nd international symposium parallel architectures algorithms networks pp 

krishna shin real time systems mcgraw hill 
ramamritham stankovic scheduling algorithms operating systems support real time systems proceedings ieee vol 
pp 
january 
lehoczky sha ding rate monotonic scheduling algorithm exact characterization average case behavior proc 
real time systems symposium 

leung whitehead complexity fixed priority scheduling periodic real time tasks performance evaluation vol 
pp 
december 
experimental implementations priority inheritance semaphore specification kernel th project international symposium pp 

tokuda nakajima evaluation real time synchronization real time mach second mach symposium pp 

usenix 
sha rajkumar lehoczky priority inheritance protocols approach realtime synchronization ieee trans 
computers vol 
pp 

shin efficient semaphore implementation scheme embedded systems appear ieee real time technology applications symposium 
operating system automotive applications sae international congress exposition pp 
february 
sae technical series 
kopetz non blocking write protocol solution real time synchronization problem proc 
real time systems symposium pp 

levy jr computer programming architecture vax digital press 
inside windows nt microsoft publishing 
user manual motorola 
mc user manual motorola 
katcher engineering analysis fixed priority schedulers ieee trans 
software engineering vol 
pp 
september 

