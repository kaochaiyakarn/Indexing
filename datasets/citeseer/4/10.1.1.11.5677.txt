simulation dynamic data replication strategies data grids szymanski department computer science rensselaer polytechnic institute troy ny cs rpi edu ewa deelman information sciences institute university southern california marina del rey ca deelman isi edu data grids provide geographically distributed resources large scale data intensive applications generate large data sets 
ensuring efficient access huge widely distributed data hindered high latencies internet 
address problems developed data grid simulator simulates cost driven replication technique dynamically replicate data grid 
replication decisions driven estimation data access gains replica creation maintenance costs turn factors runtime accumulated read write statistics network latency bandwidth replica size 
simulation results demonstrate replication improves data access time data grids gain increases size datasets involved 
data grid connects collection hundreds geographically distributed computers storage resources located different parts world facilitate sharing data resources 
data grids enable scientists different universities research laboratories collaborate solve large scale computational problems 
size data needs accessed data grid order terabytes today soon expected reach petabytes 
major barrier supporting fast data access grid high latencies wide area networks internet 
barrier impacts scalability total grid system 
propose dynamic memory middleware allows grid nodes automatically replicate data needed 
goals replication reduce access latency improve data availability dynamically adapting changes user network behavior 
order evaluate approach developed grid simulator 
simulator provides modular simulation framework model different data grid configurations resource specifications 
replica management service introduce offers transparent data replication runtime system evaluates data access gains creation maintenance costs replication moving copying data 
gains costs replication decisions calculated factors accumulated read write statistics network latency bandwidth replica size system reliability 
replication cost model formulated optimization problem minimizes sum total access costs data grid replica creation maintenance costs 
address scalability propose overlay replicated data alternative logical configurations ring tree configuration 
configurations organized top 
replica distribution spanning graph chosen depending application design sharing patterns 
ring topology peer peer replication presence multiple master replicas 
tree topology exploits geographical locality 
preliminary results single trace file static data replication 
contributions twofold results large network configurations data files introduce adaptative cost driven replication technique 
design concepts simulator results simulated dynamic repli cation techniques typical data grid architecture proposed cern european organization nuclear research implemented grid physics network griphyn 
ar gue replica management system propose offers better performance existing ap proaches offers highly dynamic optimized solution scalable replica distribution mechanisms :10.1.1.20.6836
related rise interest modeling data grid environments simulating different data replication techniques basic file replication protocols 
increase data production data sharing needs widening global scientific community growing need improving data access performance data availability 
different studies conducted model scientific experiments settings configurations cms atlas experiments large collider laser interferometer gravitational observatory sloan digital sky survey 
studies led initiation projects griphyn project eu datagrid project 
currently projects static user driven replication services provided globus toolkit globus replica location service 
simulation framework introduced data replication combined job scheduling 
contrast approach introduced uses prediction function spatial time locality regardless data access cost datagrid 
approach proposed automatically creating replicas typical decentralized peer peer network 
goal create certain number replicas site guarantee minimal availability requirements 
different replication caching strategies simulated grid environments discussed combination scheduling algorithms studied 
replication algorithms proposed assumption popular files site popular sites 
take different approach evaluating replica creation placement network attributes data popularity spatial time locality 
simulation design modular simulator built top network simulator ns provides basic grid network specification nodes links messages 
introduces application level services implemented top existing ns protocols 
allows specify different types nodes different node resources cost function parameters replication strategy 
data exchanged nodes application level data passed ns node packets 
addition packets representing grid user requests start grid data transmission ns transfer control simulation 
simulates replication decision node generates new ns traffic forwarding requests nodes sending requested data client 
separation network simulation strata grid node replication enables existing package ns add grid specific elements simulation 
main considerations designing simulator model data grid architecture interactions individual grid components realistically possible 
simulation architecture proposed cern experiments 
assume multi tier grid topology study 
main storage site nodes client nodes simulation model replication service responsible initiating data replication needed 
addition multiple replicas files placed multiple locations data request data management services locate replica yielding shortest access time 
determine access existing replica create new delete 
runtime component dynamically evaluates application users needs adapts replicas distribution meet needs 
architecture evaluate model ns network simulator enables generate different network topologies 
able simulate specifics replication grid introduced separate grid simulator top ns 
additional simulator extends original semantics node object ns 
node grid able specify storage capacity organization local data files relative processor performance maintain list neighbors peer replica nodes 
shows simulation model topology experiments 
shown different node models data server nodes main storage site user nodes cache intermediate nodes 
cache nodes represent nodes grid hierarchy higher storage capacities user nodes smaller storage site 
nodes may contain parts data stored main storage sites 
placing data intermediate nodes efficiently accessible users 
user client nodes represent network nodes access requests generated 
network interface model specified link object provided ns 
link object model parameters physical interconnections simulated network link bandwidth latency 
simulator architecture simulation constructed assuming node data grid computational power may provide data storage resources 
shown node consists basic ns node storage element replica manager monitoring agent maintains replica routing table 
replica manager decision create delete replicas 
decision statistics collected site network characteristics 
data access frequencies data file connection bandwidth information storage space availability 
collect data replica manager contains monitoring module agent responsible computing number data requests generated node number requests received nodes 
data collected evaluated replica placement algorithm optimizer cost function 
simulation client nodes generate data access requests 
client runs set jobs require accessing certain data files 
jobs running time simulated associating processing time file 
client runs sequence jobs concurrently clients 
client nodes assumed limited storage space caching 
generating request client checks data requested available locally 
node maintains replica routing table allows locate closest replica site node forward request 
time new replicas created deleted replica routing tables updated accordingly 
subsection explains tables updated 
replication algorithm hierarchical property data grid organized simulations multi layered trees 
nodes placed higher levels higher storage capacity 
client nodes placed lowest level 
level nodes organized ring topologies facilitate data access level nodes peer peer model 
initially routing tables contain address node parent siblings hierarchy 
initial requests generated forwarded higher level 
replication placement policy formulated optimization problem 
node system data object associated nonnegative read rate av nonnegative write rate iv represent traffic generated node local domain related object cw write cost object cr read cost object cw cr ai ratio write cost node replicas object system total data transfer cost object node xv ilv ize node containing object sum edge costs path bandwidth 
represent set nodes system ri replica set object ri denote replica object closest node node added ancestor replica tree object tv partition nodes serviced access requests object assuming added ri 
represent total read rate nodes partition tv tv represent total write rate partition 
incremental data transfer placing replica expressed formula ri lr itv size ri adding ri decreases read cost node tv size ri increases write cost node tv size ri change costs 
total data transfer cost object replica set cost ri cost ri structure data grid associated read write patterns object term equation constant 
need consider problem maximizing cost cost ri ri veri formula expresses data transfer cost object improved placement set replicas ri 
runtime system access cost statistics compares replications gains replication costs update cost informs replica management service place replica node 
replica manager decides create local replica space available replica deleted space new 
replica manager deletes accessed replica 
decision evaluation formula rates access requests replica number nodes requesting replica 
replica created node information propagated siblings children node 
subsequent access requests replicas forwarded closest replica site closest path 
determine path bandwidth node connections evaluated determine efficient routes access data 
replica routing tables updated accordingly reflect information 
replica routing tables implement functionality replica catalogs implemented data management component globus toolkit 
tables provide mapping logical file names physical locations data grid 
working extend functionalities integrate model globus model 
simulation results simulation configuration study carried model tier datagrid topology 
table shows parameters study 
number sites total number datasets connectivity bandwidth server cache cache cache mb cache client mb total number requests table simulation parameters initially files placed main storage site root 
data access patterns temporal geographical data locality 
accessed files accessed files accessed node accessed siblings children 
model site allocated storage resources proportional location grid hierarchy 
main storage site allocated storage element hold master files 
client nodes storage space 
results experiments consisted running simulation model described 
topology consisted tier tree cache nodes tier nodes children cache nodes 
cache nodes tier children client nodes 
total client nodes cache levels cache nodes main storage site 
goal simulations evaluate replication approach replication approach 
shows average response time read requests files simulation 
file sizes ranged mb gb 
results show dynamic replication improves data transfer response time datagrid 
average response time dynamic replication replication different dataset sizes shows dynamic replication outperforms static replication 
static replication files interest set users placed closer users 
decision previously known popularity data different users datagrid 
approach satisfy demands constantly changing set users case real 
running simulation higher network bandwidths performance high load scenarios increases noticeably 
results promising show dynamic replication improves dramatically performance datagrid 
performance dynamic replication vs static replication replication requests load describe design datagrid simulator 
give description simulation model simulated configurations 
performance results replication hierarchical grid topology various scenarios 
addressed problem replication data grid environments investigating decentralized dynamic replication services improve data access time data availability bandwidth consumption scalability system 
cost function dynamically evaluates replica placement policy comparing replica maintenance costs data access gains creating replica location 
results promising show dynamic replication outperforms static approach 
note approach significant advantages compared static approach 
decentralized distributed computing model second dynamically adapts user network behavior improving performance system 
plan validate model real 
interested exploring different replication algorithms cost models 
integrating services replica location system globus toolkit 
allcock foster chervenak deelman kesselman lee sim shoshani williams 
high performance remote access climate simulation data challenge problem data grid technologies 
proceedings sc denver november 
allcock chervenak foster kesselman tuecke secure efficient data transport replica management high performance data intensive computing ieee mass storage conference 
allcock chervenak foster kesselman salisbury tuecke data grid architecture distributed management analysis large scientific datasets journal network computer applications 
william bell david cameron luigi paul millar kurt stockinger simulation dynamic grid replication proc 
rd int ieee shop grid computing grid appear baltimore usa november 
chervenak deelman foster guy hoschek iamnitchi kesselman stockinger stockinger tierney framework constructing scalable replica location services 
proceedings supercomputing sc november 
european data grid project 
datagrid architecture 
www eu datagrid org foster kesselman globus metacomputing infrastructure toolkit intl supercomputer applications 
foster kesselman tuecke 
anatomy grid enabling scalable virtual organizations 
international supercomputer applications 
foster kesselman 
data grid architecture draft february griphyn technical report griphyn 
foster kesselman 
eds grid blueprint new computing infrastructure morgan kaufmann 
tt foster grid new infrastructure tst century science physics today 

grid physics network griphyn 
www griphyn org szymanski deelman data replication strategies grid environments proceedings icap appear beijing china october 
ns network simulator 
www mash 
cs 
berkeley 
edu ns 
ranganathan foster identifying dynamic replication strategies high performance data grid proceedings international grid computing workshop denver november 
ranganathan foster design evaluation replication strategies high perfor mance data grid international conference computing high energy nuclear physics beijing september 
ranganathan iamnitchi foster improving data availability dynamic model driven replication large peer peer communities global peer peer computing large scale distributed systems workshop berlin germany may 
stevens woodward defanti catlett way national technology grid communications acm 


stockinger samar allcock foster tierney file object replication data grids proceedings tenth international symposium high performance distributed computing hpdc ieee press august 
tuecke foster replica selection globus data grid proceedings ieee cm international conference cluster computing grid ccgrid pp 
ieee computer society press may 
