principled feature selection relevancy filters wrappers ioannis dept biomedical informatics vanderbilt university ioannis 

edu aliferis dept biomedical informatics vanderbilt university 

edu kohavi john number disadvantages filter approach feature selection problem steering research algorithms adopting wrapper approach :10.1.1.30.525
show approach inherently better practical feature selection algorithm needs consider learner classification metric evaluating learner performance 
process formally define feature selection problem re examine relationship relevancy filter algorithms establish connection kohavi john definition relevancy markov blanket target variable bayesian network faithful data distribution 
theoretical results lead principled ways designing optimal filter algorithms example 
feature selection classification feature called variable selection classification important problem consider able attention decades 
section formally define versions feature selection problem discuss previous definitions meet needs practitioner 
purpose feature selection fold theoretically sample limit features better learning experiments involving practical algorithms selection features yields models better generalization performance full feature set 
second reason desiring reduce number variables required learning may unnecessarily expensive observe 
example medicine unnecessary variable may cost hundreds thousands dollars observation may addition entail risks patients health 
third parsimonious models easier understand computationally expensive performing inference prediction 
feature selection tool deepen researchers understanding characteristics structure domain orient subsequent experimentation eventually development detailed domain theory unnecessary variables tion difficult 
despite significant research field standard acceptable general definition feature selection problem reached 
call papers special issue variable feature journal machine learn ing research jmlr variable selection refers problem selecting input variables predictive outcome 
kohavi john define subset features accuracy induced classifier maxi mal :10.1.1.30.525:10.1.1.30.525
similar definition feature selection problem discover set features parameters classifier minimizes expected loss loss function 
problems discuss definitions distinguish possible features sets maximal accuracy minimal loss incorporate instances problem cost features important trade accuracy cost observations required 
lack standard definitions hard analyze arguments favor feature selection algorithms argument kj filter algorithms defined 
attempt definition problem enables analysis theoretical properties feature selection 
definition 
feature selection problem fsp 
feature selection problem tuple sample input patterns defined feature set target variable classification algorithm producing prediction model performance metric classifier model selected features 
lution problem feature subset maximizes projection data features technical simplicity loss generality impose constraint included selected features 
typical feature selection algorithms appeared literature tackle specific instances definition problem full generality 
example kj definition matches loss function preference feature sets exhibit loss accuracy 
definition metric requires parameter selected feature set account loss function incorporate feature observation costs possibly trade accuracy smaller feature subsets 
notice classification algorithm definition fixed part problem 
solution problem feature subset optimizes metric learner 
problem practitioners really solve 
free choose classifier interested optimizing metric possible available classifiers 
confusion feature selection depicted definition feature selection editors special issue feature selection process selecting features predictive outcome classifier prediction power measured 
measured classifier maximum classifiers 
discussion suggests appropriate definition definition 
feature selection problem fsp 
feature selection problem tuple semantics definition 
solution problem feature subset learning algorithm maximizes 
goals ultimate real life uses learnt model 
established distinction feature selection algorithms kj filters wrappers 
definition 
types feature selection algorithms 
wrapper feature selection algorithm fsp search procedure space possible feature subsets uses classification algorithm evaluation metric assessing quality states feature subsets 
filter variable se lection algorithm algorithm selects variables evaluating metric output classification algorithm fsp wrapper search procedure space possible subsets possible classification algorithms 
notice filter may learner metric select features 
case difference wrapper may different definition feature selection problem 
filter algorithm wrapper 
example recursire feature elimination algorithm rfe linear support vector machine svm trained data half fea tures corresponding smallest weights vector normal optimal hyperplane eliminated recursively 
log linear svms models corresponding feature sets produced way maximum performance selected performance measured combination success rate acceptance rate svm model char 
classifier induce final model linear svm performance metric rfe wrapper method filter 
settings distinction wrappers filters blurs 
relevancy filters section suggest relevancy defined feature subsets individual features subsets labeled relevant correspond solutions feature selection problems filter algorithm essentially implements relevancy definition 
definitions refer problem fsp second fsp 
third definition possible maximizes possible metrics metric characteristic problem practitioner allowed choose known classifier loss mean squared loss trade accuracy cost features optimized depends nature problem relevancy feature selection volume artificial intelligence journal devoted concept relevancy 
researchers interested concept context feature selection justification step feature selection semantics relevancy suggest intuition relevant variable included selected variables irrelevant variables 
implicit consensus community relevancy defined independent classifier evaluation metric relevance variable depend probability distribution data svms example build final model 
formally relevant set variables solution fsp fsp independent learner performance metric sample limit joint distribution close approximation real distribution population data instances 
filters independent computable definition relevancy corresponds number exact approximate filtering algorithms implement definition return relevant features 
conversely filter algorithm corresponds definition relevancy employs dis tribution data 
scientific community agree satisfying appropriate definition relevancy matter designing efficient filters determining relevant set variables 
attractive property ideal definition select relevant variables independent discussion suggests definition 
definition relevancy tt target set functions pw feature set pw set possible distributions defined words definition relevancy rule labeling features relevant irrelevant probability distribution data 
definitions kj blum langley intentionally define functions pw feature set target definitions sections follow :10.1.1.111.7659:10.1.1.30.525
notice fsp solutions 
addition feature belong sets just 
case label relevant features union sets correspondance relevant features solutions fsp lost may longer solution 
true intersection solution sets 
loss correspondance lead confusion attempts distinguish sets features kj define weakly strongly relevant features intent strongly relevant ones required maximum accuracy weakly relevant ones may may needed 
counter suggest relevancy definition labeling individual features relevant irrelevant label feature subsets relevant specifically subsets solutions feature selection problem 
definition 
definition relevancy tt tar get aset functions pw feature set returns set feature subsets probability distribution data 
relevancy definitions independent learner metric solve fsp section examine kj argument filter algorithms prove definition relevancy necessarily needs consider classifier metric provide alternative definition relevancy 
kj closely examine number previous definitions relevancy examples definitions fail classify variables relevant desired properties 
subsequently provide improved definition relevancy satisfies intuition relevancy previous examples definition exist learners set relevant variables solution variable selection problem 
kj argue convincingly general case relevancy tied specific classifier concept relevancy little relevant irrelevant features may required optimal classifications 
quote relevance feature imply optimal feature subset somewhat surprisingly irrelevance imply optimal feature subset different algorithms different biases feature may help algorithm may hurt 
feature selection pro cess interacts classifier induce final model 
course talk relevancy mean definition implicit conjecture definition relevancy independent learner desired property relevant variables definition solution fsp consider fsp 
formally prove theorem 
concept relevancy tt defined independent metric set relevant feature subsets probability distribution solutions fsp fsp data sample drawn proof 
set relevant feature subsets target probability distribution data relevancy definition tt 
feature subset 
define feature subset 
set means tt labels subsets relevant 
case pick feature selection subset arbitrarily create metric assigns score subset subset exists 
cases relevant feature subsets maximize metric 
theorem proves relevancy take consideration function metric definition feature selection problem 
prove fsp take consideration algorithm theorem 
concept relevancy tdt metric defined independent classifier set relevant feature subsets probability distribution solutions fsp data sample drawn proof 
loss classifier maximizes accuracy classifier 
binary distribution infer 
simple bayes classifier sbc 
definition relevancy may label sets relevant feature subsets 
selecting minimum loss maximum sbc sample limit 
sample 
classifier runs input returns reverse classification definition relevancy returns relevant variable algorithm better subset 
definition relevancy returns relevant feature subset algorithm better subset performs worse performs better 
wrong uninformative definition relevancy return sets relevant get different scores different algorithms 
words cases know metric probability distribution data classifier label feature sets relevant irrelevant way exists algorithm solves feature selection problem 
kj implicit conjecture right 
knowing metric necessary condition defining relevancy feature selection problems knowing classifier necessary condition defining relevancy fsp 
fashion knowing necessary condition designing optimal filter algorithms 
significant number definitions relevancy feature selection appeared literature particular mentioned counter suggest definition 
feature subset relevant fsp target classifier metric data solution problem fsp 
similarly fsp 
free lunch theorems wrappers section consider limitations wrapper approach particularly prove subjected constraints free lunch theorem search optimization 
wrapper approaches display considerable short require training evaluation performance classifier variable subset considered search compu expensive necessary repeat feature selection different classifier solve classification problem wrappers advantage wrapper approach feature subset space fsp explicitly implicitly searched guaranteed discover optimal feature subset classification learner evaluation metric data distribution 
smallest problems exhaustive search computationally prohibited wrappers provide optimality guarantees 
wrappers designed independent algorithm metric treat objective function optimized black box 
fsp perform heuristic search space possible feature subsets 
black box optimization searches wrappers subject results free lunch nfl theorem optimization discuss 
nfl states measure performance proximity output value maximum value black box optimization search averaged possible finite number mentioned filters may train evaluate classifiers attempt select features case filters optional 
objective functions problem landscapes 
specifically finite search space states finite space objective values set possible objective functions defined spaces 
nfl states performance pair algorithms averaged 
wrapper objective function metric practical purposes takes finite number output values numbers represented bits machine 
theorem 
nfl holds fsp wrappers choice metric classifier uncon strained 
proof 
finite 
suffices show objective function realizable 
metric unconstrained function qs simply assign qs qs metric fixed need show function qs qs qs distribution data algorithm realizes 
minus loss classifier accu racy distribution feature 
clas consist rules form output bj 
assume states containing included search space 
notice rule fires feature subset binary encoding number feature subset containing third fourth feature starting right cor responds 
setting bj get bj setting bj get 
ao get ao ao bj 
function realizable metric fixed 
implications designing filters wrappers theorems kj arguments employ extreme classifiers point 
example kj show handicapped classifier limited perceptron classifier requires irrelevant vari ables included selected features problems relevance defined definition 
mean filtering algorithms fsp perform problems classifiers typically practice 
similar fashion just nfl holds wrappers mean averaged problems occur practice wrapper superior performance wrappers 
kj argument valid principle fsp 
mentioned practice interested solving fsp 
researcher modeler filtering algorithm apply limited perceptron classifier trying powerful classifiers 
fsp spelled researchers real problem try tackle number feature selection papers manual meta search performed limited number classifiers essentially attempting optimize metric feature subsets classifiers simultaneously 
example kj wrappers naive bayes decision trees 
practitioner choose feature subset algorithm maximizes accuracy 
draw discussion principle filters wrappers need consider metric algorithm order optimal efficient respectively 
designing feature selection algorithms target specific classes metrics algorithms 
approach feature selection inherently superior dismissed 
designing optimal filters armed new understanding relevancy filters proceed design optimal filters special cases 
relevancy definitions kj concept markov blanket target variable mb 
relationship relevant features mb explored 
mb solution classes feature selection problems 
regarding notation denote variable values vi target variable value remaining set variables si si joint value si si 
shorthand denote instantiation instantiation vl set variables equation holds vl 
similarly expresses fact instantiation equation hold 
denote conditional independence 
avoid technical difficulties conditional prob ability defined case assume joint probability distribution structural zeros possible instantiations variables positive probability matter small 
kj definition :10.1.1.30.525
strong relevancy 
variable strongly relevant exists vi xi st vi si st yi tis st 
definition 
weak relevancy 
variable weakly relevant relevant exists subset variables si exists vi si vi vi vi tis definition 
relevancy 
feature weakly strongly rel feature irrelevant relevant definition 
markov blanket 
markov blanket denoted mb minimal set variables variable indepen dent mb vv mb turns mb unique coincides set strongly relevant features distributions faithful bayesian network 
distributions faithful bn strongly relevant features ones belong inter section markov 
define concepts prove properties 
definition 
bayesian network 
set discrete variables joint probability distribution possible instantiations directed acyclic graph set variables nodes correspond toone members 
require node probabilistically independent parents markov condition 
call triplet bayesian network bn 
known property bns joint probability distribution represented bn 
definition 
separation 
variables separated set variables bn exists adjacency path path ignoring ordering edges collider ofp collider node incoming edges belong path descendent nodes path 
definition graph theory infer proposition 
variable direct edge separated subset variables parent common child separated subset variables contains common child 
definition 
faithfulness 
graph bn faithful joint probability distribution feature set dependence entailed say data generating process faithfully represented sample limit produces data joint probability distribution faithful bn faithful probability distribution faithful 
follows markov condition conditional independence entailed faithfulness markov condition establish close relationship graph probability distribution allow associate statistical properties graph properties terminology spirtes glymour scheines faithful terminology pearl perfect map dag isomorph proposition 
faithful bn separation captures conditional dependence independence re lations encoded graph implies nodes separated independent theorem 
unique mb faithful bn set parents children parents children proof 
neapolitan shows set parents children parents children separates variable 
call set prove minimal mb 
proposition separates parent child remove proposition children belong separate parent common child parents common children removed prove unique 
assume set separates variable 
similar argument see contain parents children parents children minimal unique 
theorems associate relevancy 
theorem 
faithful bn variable strongly relevant mb 
proof 
suppose strongly relevant belong mb 
recall definition kj strong relevancy definition si mb si 
mb subset si follows si si si 
defini tion strongly relevant contrary assumed 
conversely prove mb strongly relevant 
definition separation definition see member mb separated si remaining set variables 
turn implies proposition conditionally dependent si vi si si strongly relevant 
theorem 
faithful bn variable weakly relevant strongly relevant undirected path proof 
consider undirected path set separated conditionally dependent proposition 
definition kj strongly relevant weakly relevant 
conversely weakly relevant set ti 
path separated set proposition conditionally independent set weakly relevant 
corollary irrelevant features path bn faithful probability distribution 
faithfulness proposition hold typical deterministic relations example possible multiple markov mbi mbn 
case strongly relevant features ones intersection markov set oi mbi omit proof due lack space 
mb solution feature selection problem section summarizes conditions mb solution feature selection problems 
definition mb carries information required estimate probability distribution data 
exact distribution required calibrated classification output classifier probable class distribution class membership 
calibration required learning applications cost sensitive decisions corresponds mean squared loss 
example order apply decision theory agent know probability distribution just probable classification 
quite probable loss metric features mb required features belong mb 
calibrated classification features mb required 
proposition 
mb solution fsp sample limit drawn faithful bn calibrated classifier approximate probability distribu tion metric strictly decreasing mean squared loss preference smaller sub sets 
mb solution fsp 
drawn faithful bn solution fsp problem smallest mb 
optimal filter algorithm definitions theoretical results just academic interest 
directly lead design optimal filter algorithms special case proposition algorithm provably identifies mb optimal filter algorithm conditions stated proposition 
incremental association markov blanket iamb algorithm 
iamb introduced available request authors identifies mb assumptions 
data generated processes faithfully represented bayesian net works 

exist reliable statistical conditional independence tests measures associations checking independence strength association variable set variables assumptions violated output serves heuristic approximation mb 
experimental results iamb reported 
iamb consists forward phase backward phase 
estimate mb kept set cmb 
forward phase variables belong mb possibly false positives enter cmb backward phase false positives identified removed cmb mb 
heuristic iamb identify potential mb example calibrated neural networks bayesian network learners phase forward cmb cant true cant true cant false cms assoc cmb cmb cmb cmb cant true phase ii backward variable cmb ifi cmb remove fi om cmb endif endfor return cmb incremental association markov blanket iamb algorithm 
members phase start empty candidate set mb cmb admit iteration variable largest association conditioned cmb 
function assoc measures strength association features cmb 
association variable conditioned cmb vanishes independent cmb 
heuristic admissible sample limit members mb enter cmb eventually 
number parametric non parametric measures associations conditional independence tests implement functions assoc sound sample limit various data sampling assumptions 
sample limit lamb provably output correct mb metrics see proof 
re examine concepts relevancy feature selection problem distinction wrappers filters 
prove concept relevancy defined independent classifier final induced model met ric evaluating performance corresponds solutions feature selection problem filter algorithms need consider parameters optimal 
similarly prove wrappers subject free lunch theorem consider parameters 
optimal feature selection possible special cases design optimal feature selection algorithms attainable constraining application domain terms classifiers loss functions tailoring algorithms terms 
calibrated classification markov blanket target variable optimal feature set 
markov blanket corresponds strongly relevant features defined kohavi john data faithful bayesian network 
algorithm provably discovers markov blanket optimally solves special case feature selection problem 
agresti 
categorical data analysis probability mathematical statistics 
john wiley sons 
aliferis ioannis 
markov ket induction feature selection 
technical report dsl discovery systems laboratory department biomedical informatics vanderbilt university 
blum langley :10.1.1.111.7659
selection relevant features examples machine learning 
artificial intelligence 
cooper evaluation machine learning methods predicting pneumonia mortality 
artificial intelligence medicine 
duda hart stork 
pattern classification 
john wiley sons second edition 
isabelle guyon jason weston stephen vladimir vapnik 
gene selection cancer classification support vector machines 
machine learning 
kohavi john :10.1.1.30.525
wrappers feature subset selection 
artificial intelligence 
huan liu hiroshi motoda editors 
feature ex traction construction selection data mining perspective 
international series engineering computer science 
kluwer 
marvin 
computational geometry 
mit press expanded edition 
neapolitan 
probabilistic reasoning expert systems 
john wiley sons 
pearl 
probabilistic reasoning intelligent systems 
morgan kaufmann san mateo ca 
spirtes glymour scheines 
causation prediction search 
mit press second edition 
jason weston mukherjee olivier chapelle massimiliano pontil tomaso poggio vladimir vapnik 
feature selection svms 
nips pages 
david wolpert william macready 
free lunch theorems optimization 
ieee transactions evolutionary computation april 
