telegraphcq continuous dataflow processing uncertain world chandrasekaran owen cooper deshpande michael franklin joseph hellerstein wei hong krishnamurthy sam madden raman fred reiss shah increasingly pervasive networks leading world data constantly motion 
world conventional techniques query processing developed assumption far static predictable computational environment sufficient 
query processors adaptive dataflow necessary 
telegraph project developed suite novel technologies continuously adaptive query processing 
generation telegraph system called telegraphcq focused meeting challenges arise handling large streams continuous queries high volume highly variable data streams 
describe system architecture underlying technology report ongoing implementation effort leverages postgresql open source code base 
discuss open issues research agenda 
deployment pervasive communications infrastructure ranging short range wireless ad hoc sensor networks globe spanning intra internets enabled new applications process analyze react disparate data near real time manner 
examples include event business processing profile data dissemination query processing streaming data sources network monitors sensors mobile devices 
applications challenges met existing database data management technology 
challenges stem large scale funded part nsf iis si eia ibm faculty partnership award program research funds intel microsoft uc micro program 
permission copy fee part material granted provided copies distributed direct commercial advantage vldb copyright notice title publication date appear notice copying permission large data base endowment 
copy republish requires fee special permission endowment proceedings cidr conference university california berkeley intel berkeley laboratory ibm almaden research center telegraph cs berkeley edu deeply networked nature unpredictability environment need close interaction users 
emerging networked environments data commodity interest commodity value realized moved needed 
contrast traditional data processing environments data assumed reside statically known locations data new applications constantly moving changing 
fluidity leads view data management emerging applications dataflow processing monitor react streams information pass network 
data movement implies adaptivity traditional database query processing approaches inappropriate substrate build dataflow processing support number reasons streaming data contrast traditional database systems query processor operate pulling data disk say iterator model target applications involve streaming data data continually pushed query processor 
subtle difference dramatic implications design query processor 
importantly traditional query processor orchestrate movement handling data query processor data streams react arriving data 
arrival rate data streams may extremely high bursty placing constraints processing time memory usage typically data processed fly arrives disk background 
furthermore traditional processor rely detailed statistics data stored system reliable statistics streaming data readily available 
important note data streams time ordering inherently important queries streaming data significantly different queries traditional data 
continuous queries cq dataflow processing applications monitoring filtering aspect queries continuously active 
new data arrives query processor routed set active queries 
continuous query processing turns traditional database system architecture head 
traditional system arrival queries initiates access stored collection data arrival data initiates access stored collection queries 
expected inversion dictates different approach query processor architecture 
important aspect continuous queries streams executed effectively infinite 
queries infinite streams require different query semantics non blocking query operators new support fault tolerance 
operators continuously return incremental results may need defined process subsets windows input 
furthermore continuous queries extremely longlived susceptible changes time performance load data arrival rates data characteristics 
care taken reduce amount state queries accumulate state preserved possibly migrated fault tolerance load balancing 
shared processing combination longrunning continuous queries fly processing data streams necessitates new mechanisms sharing query processing 
order avoid blocking having interrupt dataflow data processed simultaneously queries require flows system 
processing query individually slow wasteful resources queries commonality 
shared processing fundamental capability system 
furthermore shared processing robust addition new queries removal old ones time fly adaptivity essential component solution shared processing continuous queries 
sources unpredictability number features target applications render existing static query processing techniques inappropriate 
mentioned deeply networked environments highly volatile due number communications links disparate systems devices involved data loss particularly sensor networks uncertainty due unavailability load information statistics cost estimates remote systems remotely stored sensed data 
second dataflow processing part larger control loop query results may affect environment redirect query processing data production 
cases users directly interacting system results stream 
users may choose modify queries basis previously returned information factors 
system able gracefully adjust response user needs 
reasons outlined developed new architecture shared continuous dataflow processing 
approach distinguished projects data stream query processing cccc emphasis adaptability 
designed data management components system able quickly evolve adjust radical changes data availability content systems network characteristics user needs context 
considerations served guiding principles underlying design telegraphcq 
telegraphcq background telegraph project uc berkeley began early goal developing adaptive dataflow architecture supporting wide variety networked applications 
telegraph concept grew earlier projects adaptive relational query processing aimed building systems adjust processing fly response changes user needs intermittent delays accessing data wide area networks ufa 
basic technologies underlying telegraph developed provide adaptivity individual dataflow graphs 
version telegraph deployed support federated facts figures fff query system deep web data 
fff attempt exploit commonality concurrently active queries 
focused single user scenario providing efficient early partial results queries interactive user control rh 
built prototypes extending telegraph support shared processing streams cacq mshr psoup cf 
prototypes demonstrated substantial advantages adaptive framework shared processing streams showed adaptivity framework extended incorporate sharing 
systems significant limitations 
particular systems restricted processing data fit memory investigate scheduling resource management issues queries little overlap explicitly deal notion quality service qos adapting resource limitations explore opportunities varying degree adaptivity tradeoff flexibility overhead 
building initial prototypes embarked complete redesign reimplementation system focus support shared continuous query processing query data streams 
refer system telegraphcq distinguish telegraph project broader focus adaptive dataflow general emphasize challenges addressing new implementation 
remainder describe ongoing design telegraphcq focusing addresses challenges outlined 
reviewing basic adaptive mechanisms telegraph 
adaptive building blocks main components telegraph shown 
telegraph consists extensible set composable dataflow modules operators produce consume records manner analogous operators traditional database query engines modules composable network routers 
modules composed multi step dataflows exchanging records api called mf support communication push asynchronous pull synchronous modalities 
dataflows initiated clients ad hoc query language basic version sql scripting language representing dataflow graphs explicitly 
telegraph maintains metadata catalog data ingress wrappers gateways provide access variety data sources including remote web peer peer sources internet local caches files live sensor networks 
client communication telegraph done tcp ip sockets applet running remote browser local command line interfaces 
module types shown telegraph contains types modules ingress caching modules responsible interfacing external data sources 
ingress modules fairly traditional wrappers html xml screen called telegraph screen proxy fetching data popular peer peer networks called local file reader modules akin read access methods relational database reach remote data sources local disks indexes 
modules may cache data locally hide network delays 
addition sophisticated ingress modules built send messages back network 
example sensor proxy may send control messages adjust sample rate sensor network queries currently processed mf 
similarly module able pass bindings remote websites perform lookups 
query processing telegraph query processing performed routing tuples query modules 
modules pipelined non blocking versions standard relational operators joins selections projections grouping aggregation duplicate elimination 
addition telegraph uses special type module known state module stem rdh 
stems described section 
adaptive routing telegraph rely traditional query plan constructs query plan contains adaptive routing modules able re optimize plan continuous basis query running 
eddies modules adaptively decide route data query operators tuple tuple modules request parsing sq exp dataflows catalog query processing join se lect stem pro ject group sort adaptive routing eddy flux juggle ingress caching file reader sensor pro xy pro xy screen telegraph architecture inte module comm api basis ah choosing orderings commutative modules :10.1.1.34.8546
juggle performs online reordering prioritizing records content 
flux routes tuples machines cluster support parallelism load balancing fault tolerance 
architecturally modules indistinguishable traditional modules simply consume produce records usual api 
modules serve roles traditionally handled offline query optimizer ordering operations choice access query modules partitioning replication dataflows multiple machines 
modules reconsider revise decisions query flight 
adaptive processing eddies stems particular relevance development telegraphcq flexibility obtained combining eddy adaptive tuple routing module state modules stems 
role eddy continuously route tuples set modules routing policy 
eddies intended support partially completely commutative set modules inputs outputs connected eddy 
topology allows eddy intercept tuples flow modules observing module behavior choosing order tuples take modules 
modules processes tuple generate tuples concatenating input tuple tuples send back eddy routing 
module optionally return bounce back eddy requires additional processing 
tuple sent eddy output modules connected eddy successfully handled 
eddy shuts connected modules input streams base tables reached module finished processing tuples sent 
order enable tuples routed individually tuple additional state associated 
exact structure location state eddy stems depends routing policy implementation minimum eddy representing single query state indicate set connected modules successfully visited tuple 
note state may attached tuple ah similar tuples may logically batched associated common state information stored eddy 
stem temporary repository tuples essentially corresponding half traditional join operator 
stores homogeneous tuples tuples spanning set tables formed query processing supports insert build search probe optionally delete eviction operations 
kinds tuples routed stem 
tuple build tuple routed added set tuples 
tuple probe tuple routed returns concatenated matches eddy 
concatenated matches tuples join satisfy query predicates evaluated columns order speed processing stems augmented indexes 
example shows example eddy stems implement symmetric hash join relations 
join shown hash index built join attributes stem 
tuple arrives sent build tuple stems sent probe tuple 
st matches produced stem routed output 
routing combined hash indexes stems implements adaptive symmetric hash join 
approach naturally extended provide way symmetric joins 
different example stems consider join table joined remote index table web lookup form wrapped 
best way implement index joins remote sources asynchronous fashion described gw requiring stem rendezvous buffer hold tuples pending matches index 
order minimize latency stem built cache previous expensive lookups hn 
dataflow looks identical probes routed eddy directly index access method plans described combined single nearly identical plan contains eddy stems access methods case eddy essentially run query plans time routing tuples different ways sharing building stems 
sense eddy doing online competitive optimization spirit considers choice access methods join algorithms change mind multiple times run query tuples accessed plan reused minimal wasted effort 
described differently eddy stems dynamically design hybrid join algorithm 
eddies stems dynamically control decisions query optimization including module ordering choice query spanning tree choosing pairs relations join 
benefits query processing eddies stems addressed detail raman rdh includes experiments showing performance benefits join hybridization 
important note number combination modules connected eddy including course eddies 
individual eddy provides scope adaptivity modules input output eddy considered eddy adaptive decision making contribute overhead thereof 
intermodule communication glue binds various modules form query plan inter module communications api call 
key advantage allow query plans mixture push pull connections modules able execute query plans combination streaming static data sources 
api designed modules written manner agnostic inputs outputs pushed pulled combination 
insight interactive adaptive streaming systems traditional iterator model breaks query processor afford block waiting long running modules complete slow web pages return results individual sensors may run power temporarily disconnected 
way deal problems interpose exchange modules graf producers consumers query plan 
exchange producer running thread machine delivers results exchange module queues synchronously delivers consumer needed 
exchange consumer forced block data available due iterator model 
blocking limit adaptivity 
allow pairs modules connected various types queues 
example pull queue implemented blocking dequeue consumer side blocking enqueue producer side 
implemented non blocking enqueue dequeue control returned consumer queue empty 
non blocking dequeue allows consumer pursue computation yield processor data available 
course desired provide exchange semantics blocking dequeue non blocking enqueue 
flux scaling dataflow processing scalability key concern dataflow processing systems 
traditional approach scaling query horizontally partition constituent operators shared cluster dataflow processing execute dg 
volatile environments ones telegraph intended optimal partitioning internal state input streams dataflow constituent operators change time 
execute efficiently operators periodically adjust partitioning executing 
operators large changing internal state online repartitioning especially difficult costly 
shared environment machines experience faults causing portions continually executing dataflows lose accumulated operator state flight data 
deal volatilities introduce module called flux flux generalization exchange module graf exchange opaque dataflow module interposed producer consumer operator pair pipelined partitioned dataflow 
addition data partitioning routing functions exchange flux provides additional features load balancing fault tolerance 
load balancing provided online repartitioning input stream corresponding internal state operators consumer side 
flux state movement protocol employs buffering reordering mechanisms smoothly repartition operator state machines minimal impact ongoing processing 
flux provides fault tolerance dataflows leveraging state movement mechanisms replicate operator internal state flight data 
critical dataflows require high availability flux provides loosely coupled process pair mechanism quick failover 
failure flux automatically recovers lost data operator state remaining non faulty machines continues processing human intervention 
online repartitioning mechanisms take provide efficient rebalancing execution 
addition flux parameterized provide varying degrees replication different levels dataflow partition basis modules partitioned flux fault tolerant load balancing exchange cluster 
flexibility allows unneeded reliability traded improved performance 
essence flux exposes reliability quality service knob dataflows 
inserting flux appropriate points dataflow designer build dataflow degrades controlled fashion face resource imbalances machine faults shared platform 
initial cq approaches having philosophy core mechanisms original telegraph system describe early extending support shared continuous query processing 
main components cacq extension eddy stems mechanisms support multiple continuous queries mshr psoup extension cacq supports access previously arrived data intermittent connectivity cf 
schemes implemented relatively natural extensions initial telegraph implementation described section 
cacq cacq continuous query engine exploit adaptive query processing framework telegraph 
key innovation cacq modification eddies execute multiple queries simultaneously 
accomplished essentially having eddy execute single super query corresponding disjunction individual queries posed clients system 
extra state called tuple lineage maintained tuple passes cacq process help determine clients output disjunctive cacq query transmitted 
key feature cacq grouped filters optimize selections shared execution individual queries 
grouped filter index boolean factors attribute 
new query inserted system decomposed individual boolean factors 
single variable boolean factors inserted appropriate grouped filters 
multi variable boolean factors inserted stems 
eddy subsequently routes tuple enters system grouped filters stems interested 
details tuple lineage grouped filters execution joins stems described madden mshr 
performance experiments reported indicate due adaptive nature cacq system able match significantly exceed performance existing static continuous query systems variety workloads 
psoup psoup extends mechanisms developed cacq main ways allows queries access historical data adds support disconnected operation users register queries system return intermittently retrieve latest answers 
key innovation psoup treats data queries symmetrically allowing new queries applied old data new data applied old queries 
indexing queries query stem thought generalization notion grouped filter 
psoup supports intermittent connectivity separating computation query results delivery results 
psoup continuously computes answers active queries effectively materializing results specifically requested 
shown essential idea psoup execution model queries treat query processing symmetric join data queries 
client registers query select clause query extracted inserted query stem applied previously arrived data stored data stems 
application new queries old data psoup executes queries historical data 
similarly new data element arrives inserted appropriate data stem applied previously specified queries stored query stem 
act applying new data old queries psoup supports continuous queries 
psoup continually runs data query join materializing results special results structure 
queries psoup contain time window specification 
previously registered query invoked window imposed results structure retrieve current results 
materialization results key supporting disconnected operation enables efficient support set queries 
performance study cf shows benefits psoup materialization strategy 
telegraphcq telegraph implementation extensions built date enabled explore novel implementations adaptive cq processing mechanisms showed significant advantages traditional approaches range application scenarios 
discussed section prototypes number limitations addressing development telegraphcq system 
specifically designing telegraphcq focus issues scheduling resource management groups queries support core data variable adaptivity dynamic qos support parallel cluster processing distribution 
section overview window query semantics supported telegraphcq 
describe design system focusing leveraging postgresql code base 
discuss open issues currently addressing design 
data stem query stem streaming data sources build data probe probe symmetric join psoup psoup queries window semantics telegraphcq telegraphcq supports continuous queries combination tables data streams 
deal data streams length unbounded certain operations joins run finite windows streams 
order support variety query types telegraphcq supports rich windowing schemes portion stream arrived portions arrive 
telegraphcq provides flexible mechanisms delivering query results generated windows 
engine allows results execution query consecutive windows pushed user cacq pulled user demand psoup 
section describe windowing functionality provided telegraphcq 
briefly discuss impact functionality design 
windows input streams popular windowing schemes context stream query processing landmark sliding windows gks 
landmark queries older window fixed newer window moves forward arrival new tuples stream 
contrast sliding window queries ends move forward unison arrival new tuples 
semantics offered landmark sliding windows cover small fraction interesting applications data streams 
example landmark sliding windows capture semantics query executed arrival tuples describe windows occur past 
example consider browsing system user want query historical portions stream windows move backwards starting time 
traditional landmark sliding windows applications 
semantics queries telegraphcq follows 
instant time window stream defines set tuples query executed 
execution query produces set output query user sequence sets set associated instant build clients time 
telegraphcq allows multiple simultaneous notions time logical sequence numbers physical time 
order accommodate loosely synchronized distributed data sources treat time partial order complete order 
designed algebra extends standard relational operators operate streams allow stream defined notion time transformed stream 
support general windows landmark sliding windows described 
done loop construct declare sequence windows user desires answers query variable moves timeline iterates left right ends inclusive window sequence stopping condition query defined respect variable 
loop contains statement stream query input corresponding statement assumed static table default 
loop group streams exhibit window transition behavior note notion loop intended powerful lowlevel mechanism user level query language construct 
syntax loop follows initial value continue condition change stream left right stream left right demonstrate functionality window mechanism examples 
queries examples schema daily closing prices stocks long timestamp char float assume stream starts logical timestamp 
entry trading day stock symbol 
simplicity assume microsoft msft trading stream 

snapshot query queries execute exactly window 
example select closing prices msft days trading 
select timestamp msft transition behavior windows determined units define windows increment statement continuation condition loop 

landmark query input windows queries fixed point timeline forward moving endpoint 
example select days trading day closing price msft greater 
keep query standing system trading days 
select timestamp msft 
sliding query input windows queries forward moving points 
example fifth trading day starting today calculate average closing price msft trading days 
keep query standing trading days 
note st start time query 
select avg msft st st st st notice window hops moving smoothly timeline 
windows defined move demand reverse timestamp direction appropriately setting increment statement loop 

temporal band join queries join tuples stream tuples timestamp 
example trading days starting today select stocks closed higher msft day 
keep query standing trading days 
select msft msft timestamp timestamp st st effect window semantics system design different types windows impose significantly different requirements design query processor underlying storage manager 
fundamental issue logical tuple sequence number vs physical wall clock timestamps 
memory requirements window known priori case memory requirements depend fluctuations data arrival rate 
issue related memory requirements type window query 
consider execution max aggregate stream 
landmark window possible compute answer iteratively simply comparing current maximum newest element window expands 
hand sliding window computing maximum requires maintenance entire window 
direction movement hop size windows distance consecutive windows defined loop significant impact query execution 
instance hop size window exceeds size window portions stream involved processing query 
telegraphcq design overview having notion windowed queries telegraphcq supports describe ongoing implementation 
section outline software architecture telegraphcq focusing adapting architecture postgresql enable shared processing continuous queries streaming sources 
describe new components comprise telegraphcq 
approach considerable analysis hand decided throw existing java prototypes implement completely new system 
considerations choosing java systems development project case riding factor decision heavily leverage open source postgresql code base 
telegraphcq quite different traditional query processor fair amount code surrounding main query processing modules profitably reuse 
shows basic process structure postgresql 
postgresql uses process connection model 
data structures shared multiple processes buffer pool latches located shared memory 
forks new server processes response new client connections 
server process listener responsible accepting requests connection returning data client 
new query arrives parsed optimized compiled access plan processed query executor 
components minimal change telegraphcq shaded dark gray 
include listener system catalog query parser optimizer 
components shown light gray executor buffer manager access methods pieces expect leverage significant changes 
addition adopting front postgresql server executor buffer manager disk fork new connection queries listener access plan access methods buffer pool results parser optimizer client catalog architecture postgresql components postgresql get access important client side call level interface implementations shown odbc jdbc 
chief challenge postgresql supporting telegraphcq features designed streaming data continuous queries shared processing adaptivity 
major issue postgresql process connection model implementation thread safe performance reasons multithreading important feature telegraphcq design 
pragmatic approach implementation existing process model reuse old code venture multi threading exclusively new code 
shows adding telegraphcq functionality postgresql code base 
shows ovals processes comprise telegraphcq server 
processes connected shared memory infrastructure 
rightmost process picture frontend contains listener catalog parser optimizer 
actual query processing takes place separate process called executor 
wrapper process host data ingress operators 
postgresql listens wellknown port forks frontend process fresh connection receives 
connection multiple open cursors proxy service shown right collect individual requests clients instantiate multiple cursors single connection 
necessary multiple proxies overcome limitations number permitted open cursors connection 
listener accepts multiple continuous queries adds dynamically running executor 
query received server parses analyzes optimizes adaptive plan plan includes adaptive operators described section 
plans placed query plan queue shared memory segment executor 
executor continually picks fresh queries shared memory segment 
plans dynamically folded running queries executor 
query results placed client specific output queues located shared memory segments 
listener picks results output queues sends client proxy distribution clients 
telegraphcq executor key challenge designing new executor mapping shared continuous processing model thread structure allow adaptivity incurring minimal overhead 
theory single eddy running single thread run queries system cacq psoup including involving totally unrelated streams 
approach number problems eddy mechanism intended generalized scheduler 
example tailored enforce policies resource management disjoint classes queries 
expect support large numbers active standing queries need avoid overhead associated making query separate thread need multiple threads order exploit smp cluster parallelism 
result telegraphcq executor developed multi threaded approach threads provide execution context multiple queries encoded non preemptive state machine programming model 
term execution object eo describe threads control telegraphcq executor 
eo mapped single system thread 
note shows system single eo instantiated 
eo consists scheduler event queues set non preemptive dispatch units dus executed scheduling policy 
eos visible operating system dus merely abstractions represent entities perform system 
dus responsible maintaining state 
dus non preemptive follow model described section gives control scheduling 
du run modes 
single traditional postgresql query plan standard query executor 

single eddy query plan style operators 

shared continuous query mode eddy style operators 
postgresql telegraphcq uses surrogate objects represent tuples query processing 
running traditional plans telegraphcq uses postgresql telegraphcq executor qp dus buffer pool telegraphcq wrapper shared memory infrastructure query plans output queues disks telegraphcq frontend listener parser optimizer catalog telegraphcq architecture proxy clients format surrogates 
running context eddy due continuously changing join order intermediate tuples multitude formats 
addition carry extra information bitmaps cacq 
enhanced surrogate object format represent intermediate tuples eddy modes 
key design decision executor map queries model pre scheduled eo system threads containing non preemptive dus 
goal separate queries classes significant potential sharing 
determination set streams tables queries defined call query footprint 
current implementation create query classes disjoint sets footprints 
intend investigate sophisticated sharing schemes techniques maintaining adjusting classes queries enter leave system 
ingress operators final aspect system discuss wrapper mechanism allows data streamed system 
wrapping streams newly arriving streamed data accessed mechanisms similar previously arrived static data 
overarching principle telegraphcq avoid blocking operations save accesses disk 
reason wrappers telegraphcq placed separate process accessed non blocking manner la 
types sources supported 
pull sources traditional federated database systems 

push sources connections initiated wrapper push client data source push server 
pull push client sources wrapper connects source 
contrast push server sources connect known port served wrapper process 
case responsibility fetching data network wrapper process uses pool threads implement non blocking network 
streamed data delivered wrapper process executor 
produces tuples stream preparing materialization buffer pool possibly disk direct delivery executor 
tuples buffer pool pages accessed scanner operator similar standard scan operators classic systems driven window descriptors 
processing streamed data partially disk area going design discussed section 
discussion open issues previous sections outlined ongoing implementation shared continuous query processing streams leveraging existing traditional database engine 
basic concepts approach defined core operators system rests developed large number important open design questions addressing part telegraphcq effort 
section briefly discuss issues 
query grouping sharing 
mentioned section telegraphcq executor partitions queries execution objects queries eo tend high degree overlap 
approach allows logical operations share physical stems filters 
open issue determining overlap required group new query existing execution object 
policy partitioning queries questions best policies routing tuples operators single eo remain 
cacq simple extension ticket policy ah shown provide reasonable performance workloads 
remains demonstrated best effort techniques provide adequate performance large class queries 
furthermore approaches date optimized global throughput provide mechanism prioritizing queries preventing single expensive query starving 
significant open problems respect complexity quality routing policies understanding ticket schemes perform variety workloads compare np hard optimal schedule computations modifying schemes adjust priority individual queries evaluating feasibility terms computational complexity quality sophisticated schemes 
adapting adaptivity 
adaptive mechanisms designed perform environments little cost information available estimates information unreliable long term 
tuple operator routing decisions 
fine granularity scheduling course come cost observed scenarios previous java implementation routing decisions consume significant portions execution time 
reason believe techniques play key role telegraphcq batching tuples dynamically adjusting frequency routing decisions order reduce tuple costs fixing operators adapting number order operators scheduled decision reduce operator costs 
adjustments constitute pair knobs turned observations rate change relative selectivity vary change slow selectivity constant tuples routed large fixed sequences operators change fast selectivities vary wildly small groups tuples routed individually scheduled operators 
knobs serve primary mechanism adapting adaptivity telegraphcq implementing requires investigation proper mechanisms batching fixing policies automatically turning knobs rates change relative selectivity 
disk issues qos 
interesting issues arise considering disk storage streaming applications 
issue concerning design storage manager technique stream remote data diverse push pull sources disk executor buffer pool 
buffer pool manager tuned accept new bursty streaming data service queries access historical data 
buffer pool replacement eviction policies satisfy multiple simultaneous requests issuing shared query processor 
addition scenarios huge numbers queries periodically active windows query stems addition data stems may need flushed disk 
case periodic nature windows provides knowledge exploited prefetching queries disk 
streaming nature data coupled types queries describe section raise interesting questions concerning design access methods best suited different kinds windows backwards moving windows hopping windows sliding windows 
issue implement underlying file system 
log structured file system enhance write performance windowed queries type section read workload disk resembles periodic data broadcasting systems require different data layout 
currently designing storage subsystem exploits sequential write workload providing broadcast disk style read behavior 
effort includes investigation effects different eddy routing policies disk access behavior 
queries accessing data spans memory disk raise significant quality service issues terms deciding drop system danger falling incoming data stream 
earlier juggle operator dynamic pipeline processing uf provide mechanisms pushing user preferences query execution process 
techniques need integrated telegraphcq 
egress modules 
analogous ingress modules plan investigate mechanisms managing delivering results encapsulated egress operators 
operators responsible handling results query execution engine accommodate different modalities client interaction 
example push egress operators support interaction clients continually streamed query results egress operators may log data support intermittent retrieval results 
operators encapsulate fault tolerance mechanisms support mobile clients periodically disconnected may encapsulate transcoding services clients different capabilities 
importantly efficiently support result delivery large numbers clients need operators provide aggregation buffering services interface better external overlay delivery networks 
cluster distributed implementations 
currently extending flux module serve basis cluster implementation telegraphcq 
roadmap distributed implementation 
form distribution integration telegraphcq tag system aggregation ad hoc sensor networks step planned distribution telegraphcq engine 
related large volume related telegraph project underlying technology 
discussed detail papers describing individual telegraph components 
focus projects related telegraphcq system 
continuous queries proposed terry purpose filtering documents stream user requests specified sql language 
seshadri slr early effort deal problem defining executing database style queries sequenced data 
niagaracq xml engine supports continuous queries changing data 
niagaracq builds static plans different continuous queries systems allows queries share module input 
bonnet bgs bs describe devices modeled adts extensible database allow different kinds queries 
define types queries posed streaming data historical snapshot longrunning queries 
stream bw data stream processing project focus computing approximate results understanding memory requirements posed queries 
particular project goals understand efficiently run queries bounded amount memory 
aurora cccc system allows users specify quality ofservice requirements queries uses specifications determine shed load 
tribeca sh considers novel query modules streams multiplexers 
publish subscribe systems related 
sift yf selective document dissemination system allows users subscribe text documents specifying set weighted keywords 
earlier projects suggest reversal roles queries data filtering systems inverted index queries 
xfilter af yfilter xml document filtering engines group efficiently apply xpath queries incoming documents 
fabret observe systems apply newly published events existing subscriptions match new subscriptions existing events 
solution focuses problem grouping optimizing subscription matching arrival new data 
research focussed developing algorithms perform specific functions sequenced data 
lee lsm studies learn distributions stream detect anomalies 
gehrke gks considers problem computing correlated aggregate queries streams presents techniques obtaining approximate answers single pass 
yang yw yw discusses data structures computing maintaining aggregates streams 
sadri propose sql ts extension sql language express sequence queries time series data 
ideas sharing queries related problem multi query optimization 
originally posed sellis sell topic especially group iit bombay dsrs 
multi query optimization typically shares relational subexpressions appear plans multiple snapshot queries 
contrast telegraphcq shares modules multiple continuous queries ability share flexible similar point madden mshr comparing cacq niagaracq 
deployment pervasive networking leading world data constantly motion 
world conventional techniques query processing developed assumption far static predictable computational environment sufficient 
query processors idea adaptive dataflow necessary 
telegraph project developed suite novel technologies implementing continuously adaptive query processing 
described ongoing implementation generation telegraph system called telegraphcq 
telegraphcq focused meeting challenges arise due need handle large numbers continuous queries high volume data streams 
telegraphcq differs data stream cq projects due focus extreme adaptivity novel infrastructure required support adaptivity 
implementation early stage long list open research issues 
initial results positive experiences succession increasingly sophisticated prototypes believe telegraphcq excellent platform build applications explore issues deeply networked data management 
af franklin efficient filtering xml documents selective dissemination information 
vldb 
ah avnur hellerstein eddies continuously adaptive query processing 
sigmod 
dynamic query optimization rdb vms 
icde 
acharya alonso franklin zdonik broadcast disks data management asymmetric communications environments 
sigmod 
babcock models issues data stream systems 
pods 
bgs bonnet gehrke seshadri sensor databases 
mdm 
bs bonnet seshadri device database systems 
icde 
bw babu widom continuous queries data streams 
sigmod record sep 
cccc carney monitoring streams new class data management applications 
vldb 
chen dewitt tian wang niagaracq scalable continuous query system internet databases 
sigmod 
cf chandrasekaran franklin streaming queries streaming data 
vldb 
dg dewitt gray parallel database systems high performance database systems 
cacm 
fischer franklin yfilter efficient scalable filtering xml documents demonstration 
icde 
dns dewitt naughton schneider evaluation non equijoin algorithms 
vldb 
dsrs roy sudarshan pipelining multi query optimization 
pods 
fabret filtering algorithms implementation fast publish subscribe systems 
sigmod gks gehrke korn srivastava computing correlated aggregates continual data streams 
sigmod 
graf graefe 
query evaluation techniques large databases 
acm comp 
surveys june 
gupta sudarshan viswanathan query scheduling multi query optimization 
ideas 
gw goldman widom practical approach combined querying databases web 
sigmod 
hellerstein interactive data analysis control ieee computer august 
hellerstein 
adaptive query processing technology evolution ieee data engineering bulletin june 
harren complex queries dht peer peer networks 
iptps 
hn hellerstein naughton query execution techniques caching expensive methods 
sigmod 
kohler morris chen jannotti kaashoek click modular router 
acm tocs madden franklin hong tiny aggregation service ad hoc sensor networks osdi 
mf madden franklin stream architecture queries streaming sensor data icde 
mshr madden shah hellerstein raman continuously adaptive continuous queries streams 
sigmod 
rdh raman deshpande hellerstein state modules adaptive query processing icde appear 
rh raman hellerstein partial results online query processing 
sigmod 
raman raman hellerstein online dynamic reordering interactive data processing 
vldb 
roy seshadri sudarshan efficient extensible algorithms multi query optimization 
sigmod 
sell sellis multiple query optimization acm tods march 
shah hellerstein chandrasekaran franklin flux adaptive repartitioning operator continuous query systems 
icde appear 
shah madden franklin hellerstein java support data intensive systems experiences building telegraph dataflow system acm sigmod record dec 
sh sullivan tribeca system managing large databases network traffic 
usenix 
slr seshadri livny ramakrishnan sequence query processing 
sigmod 
sadri zaniolo optimization sequence queries database systems 
pods 
terry goldberg nichols oki continuous queries append databases 
sigmod 
uf urhan franklin xjoin reactively scheduled pipelined join operator 
ieee data engineering bulletin 
ufa urhan franklin cost query scrambling initial delays 
sigmod 
wa wilschut apers dataflow query execution parallel main memory environment 
distributed parallel databases 
yg yan garcia molina sift information dissemination system 
acm tods 
yw yang widom temporal view self maintenance 
edbt 
yw yang widom incremental computation maintenance temporal aggregates 
icde 
