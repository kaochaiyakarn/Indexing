database schema matching machine learning feature selection jacob berlin motro information software engineering department george mason university fairfax va ami gmu edu 
schema matching problem finding mappings attributes semantically related database schemas important aspect database applications schema integration data warehousing electronic commerce 
unfortunately schema matching remains largely manual labor intensive process 
furthermore effort required typically linear number schemas matched pair schemas match easier previous pair 
describe system called automatch uses machine learning techniques automate schema matching 
primarily bayesian learning system acquires probabilistic knowledge examples provided domain experts 
knowledge stored knowledge base called attribute dictionary 
pair new schemas need matched corresponding database instances automatch uses attribute dictionary find optimal matching 
report initial results automatch project 
schema matching problem finding mappings attributes semantically related database schemas 
schema matching problem important current issue database applications schema integration data warehousing electronic commerce 
unfortunately schema matching remains largely manual labor intensive process 
furthermore effort required typically linear number schemas matched pair schemas match easier previous pair 
database applications require schema matching limited environments set member information sources small stable 
applications scale larger communities member sources schema matching bottleneck broken automating matching process 
discuss system called automatch automating schema matching process 
primarily bayesian learning system acquires probabilistic knowledge examples schemas mapped domain experts knowledge base database attributes called attribute dictionary 
roughly speaking dictionary characterizes different banks 
eds caise lncs pp 

springer verlag berlin heidelberg database schema matching machine learning feature selection attributes means possible values probability estimates values 
furthermore dictionary may extended contain attribute metadata probabilistic interpretation attribute names string patterns 
pair client schemas need matched corresponding database instances automatch matches dictionary 
probabilistic methods attempt match attribute client schema attribute client schema resulting individual scores optimization process minimum cost maximum flow network algorithm finds optimal matching client schemas respect sum individual attribute matching scores 
overcome problem large dictionaries caused large attribute domains automatch employs statistical feature selection techniques learn efficient representation examples 
attribute represented minimal set informative values 
attribute dictionary human understandable aggressive reduction number values 
example schemas may contain thousands values able focus learning small subset consisting initial values 
results initial experimentation automatch encouraging show performance exceeds measured harmonic mean soundness completeness matching process 
attribute dictionary built automatch conjecture employed knowledge asset schema matching systems 
remainder organized follows 
section describes basic methodology automatch particular probabilistic information acquired knowledge base infer optimal matchings client schemas 
section describes alternative methods reducing size knowledge base feature selection 
section explains experiment 
section summarizes contributions suggests research directions 
brief discussion published approaches related automatch 
related thorough discussion schema matching techniques implementations 
mention approaches compare automatch 
automated schema matching classified rule learner 
system rule approach schema integration 
system determines affinity attributes schemas pair wise fashion 
affinity comparisons attribute names structure domain types scored interval 
process relies thesauri determine semantic relationships 
system uses hierarchical clustering jacob berlin motro affinity values group related attributes 
set unification rules employed interactively guide user construction integrated schema 
contrast automatch considers schema information automatch considers instance information 
furthermore knowledge pre coded thesaurus unification rules knowledge automatch learned examples 
learner system uses neural networks identify similar attributes different schemas 
system uses combination schema instance information 
schema information includes information data types field length constraint information 
instance information includes information value distributions character ratios numeric mean variance 
type information system exploits determines numerical value interval 
tuple numerical values attribute signature attribute 
system uses signatures cluster similar attributes schema 
system uses signatures cluster centers train neural network output attribute category input signatures 
new schema system determines signature schema attribute type schema instance information training 
signatures applied neural network determine category respective attributes 
contrast automatch uses fixed set features learning automatch combines feature selection learning find optimal set features problem domain 
furthermore discovers matches attribute clusters automatch discovers matches individual attributes 
methodology section describes basic methodology automatch providing details data structures algorithms 
begins intuitive description approach formal description problem 
approach automatch knowledge base schema attributes constructed examples 
new client schemas need matched corresponding database instances automatch checks client attribute attribute dictionary obtaining individual matching scores pair client attribute dictionary attribute 
client dictionary attribute scores combined generate client client attribute scores 
illustrate assume attribute client scheme attribute client scheme attribute dictionary assume matching scored matching scored matching receives score 
combine individual scores sum combinations possible example product 
database schema matching machine learning feature selection turn individual client client attribute scores combined generate schema schema matching scores 
illustrate assume schemas assume client client attribute scores andw 
schema matching scored 
schema matchings scored similarly 
subsequent optimization process automatch finds schema matching highest schema schema score 
formalization problem formalization relational model 
confident methods extended models objectoriented semi structured models 
database schema simply finite set attributes 
database schemas bp cq mapping subset subset 
assume knowledge base database attributes called attribute dictionary denoted knowledge base attribute characterized select set possible values probability estimates 
addition assume scoring function attribute dictionary pair database schemas pair corresponding database instances matching issues value real number indicates goodness matching 
problem find best matching schemas 
description leaves major issues discussed detail 
nature attribute dictionary scoring function 
optimization finding best schema matching 
issues discussed subsections 
attribute dictionary scoring function attribute dictionary consists finite set schema attributes ar 
attribute attribute dictionary characterized set possible values probability estimates 
attribute dictionary serves knowledge base accumulates information attributes 
attempts match attributes client schemas refer knowledge base 
bayesian learning populate attribute dictionary example values provided domain experts 
recall intuitive description section task determine client dictionary attribute scores 
client attribute denote dictionary attribute denote set values observed values derived instance client schema belongs 
jacob berlin motro probability maps observing values represent unconditional probability observing values represent conditional probability observing values maps bayes theorem states 
referred posterior probability maps reflects probability mapping holds values observed 
posterior probability serves score client attribute dictionary attribute letting sequence values vn assuming conditional independence values mapping client dictionary attribute score vk 
attribute values may conditionally independent assumption shown acceptable approach aimed reducing number probabilities tractable amount sacrificing optimality 
build attribute dictionary attribute learn store probability estimates dictionary attributes values note need learn term determined requirement 
probability client attribute maps proportion examples provided domain expert mapped probability attribute value occurs mapping holds estimated counting occurrences set examples provided domain expert 
remaining terms learned similar fashion 
numeric data values assume normal distribution normal probability density function estimate conditional probabilities 
thorough discussion algorithms estimating terms reported 
critical selection process reduces number values maintained attribute discussed section 
optimal schema matching assume schemas corresponding instances denote attribute dictionary 
scores calculated attribute schema attribute dictionary 
threshold adopted scores threshold interpreted evidence mapped results may represented weighted tripartite graph nodes correspond attributes edges correspond matches edge weights correspond posterior probabilities 
database schema matching machine learning feature selection fig 

weighted tripartite graph representing individual attribute attribute scores shows graph simple case andd 
tripartite graph node left right partitions connected node center partition threshold implies general graph need full 
recall intuitive description section client dictionary attribute scores wi combined generate client client attribute scores 
note client attributes may matched dictionary attribute 
example may matched score score score 
note associating dictionary attribute attribute match providing common type matching attribute pair 
turn client client attribute scores generating schema schema scores 
example schema matching comprising receives score 
obviously number possible matchings high simple process enumerates matchings scores 
obvious approach matching choose client attribute probable dictionary attribute 
instance example jacob berlin motro highest determine mapped 
mapping established schema attributes share node attribute dictionary 
example assume highest best mapped assume highest best mapped best matched 
problem approach easily leads ambiguity 
example optimal mappings correspond edges weights established match schemas attribute mapping ambiguous 
furthermore approach easily leads match optimal mappings correspond edges weights andw 
avoid pitfalls impose additional constraint matching 
specifically limit search schema mappings paths attributes free intersections 
attributes client scheme map dictionary attribute 
resulting problem solved efficient flow network techniques 
extend tripartite graph ways 
add nodes graph source node left connected nodes target node right connected nodes 
split attribute dictionary node nodes connected correspond ing node 
reconnect edges appropri ate ain aout node 
edge direction capacity cost 
edges directed away source node target node capacity edge flow edge 
cost new edges added graph 
cost old edges negation edge weight 
shows new graph example 
edge capacities costs omitted clarity 
reason negation weights algorithm searches minimum wish find maximum finding maximum equivalent finding minimum negation 
modifications find matching schemas conforms constraints minimum cost maximum flow network algorithm 
current implementation automatch leda software package purpose 
specifically source outgoing edges capacity target incoming edges capacity attributes matched side maximum flow 
seek find edges graph minimum cost supporting maximum flow 
edges set correspond optimal mapping attributes 
note client schemas number attributes attributes larger schema 
tripartite necessarily full optimal matching may leave attributes database schema matching machine learning feature selection fig 

minimum cost maximum flow graph finding optimal schema matching smaller schema 
undesirable consequence simply indicates client schemas include attributes unique schemas 
optimal selection dictionary values recall attribute dictionary automatch represents attribute set possible values probability estimates 
schema attributes contain text number needed probabilities proportional number unique values attribute 
attribute assume thousands values imposing considerable space processing requirements 
furthermore probabilities equally informative 
uninformative irrelevant misleading noise 
critical consideration methods reduce dictionary representation attributes retaining informative values 
machine learning terminology values called features reduction process called feature selection 
reduce size automatch dictionary tested compared statistical feature selection strategies mutual information information gain likelihood ratio 
strategies jacob berlin motro commonly feature selection knowledge strategy purpose 
discuss feature selection strategy turn 
common approaches feature assigned score feature scores calculated probability estimates attribute dictionary 
approaches higher scores better 
scores calculated approach percentage highest scoring features retained ties broken arbitrarily 
normalize probabilities remaining features sum unity 
statistical feature selection imposes little overhead approach 
contrast machine learning approaches neural networks rule learners execute respective learning algorithms feature selection completed 
mutual information mutual information previously feature selection strategy information retrieval tasks 
mutual information value attribute defined mi log 
independent mutual information zero 
intuitively measure event value occurs client attribute andp measure event client attribute mapped dictionary attribute mi measure occurrence events 
example events independent occurrence unbiased mutual information 
purpose characterizing dictionary attributes wish retain values greatest score regardless favor score values mi approach formula max log log 
values highest chosen characterization attribute actual number values chosen discussed section 
information gain information gain machine learning determine value particular feature 
client attribute dictionary attribute issue maps 
issue may formatted binary message 
database schema matching machine learning feature selection denote probability maps assume knowledge proportion attributes mapped popular target mappings 
entropy information content message log log 
assume know new fact new entropy information content message log log 
assume know alternative fact new entropy information content message log log 
may combined probability entropy information content message 
information gained knowing presence absence likelihood ratio ig 
likelihood ratio value attribute defined measures retrospective support occurrence 
likelihood ratio produces scores interval 
value feature provides support 
likelihood ratios greater indicate feature supports likelihood ratios indicate feature supports task hand wish retain features provide support regardless favor features favor interval higher values indicating stronger support features favor interval lower values indicating stronger support 
consequently difficult likelihood ratio defined higher scores necessarily better 
reason adjustment inverts likelihood ratios support placing scale likelihood ratios support choose stronger supports lr max 
strategy produces scores interval higher scores better 
jacob berlin motro experimentation setting experiment experiment methods discussed built attribute dictionary computer retail information attributes inventory 
data experiment taken web sites different computer retailers gateway 
total relations extracted 
data collected line html web pages imported relational database tables accessible odbc protocol 
experiment data procedure data mining called stratified cross validation briefly describe see complete description 
schemas manually mapped attribute dictionary 
partitioned schemas folds approximately equal size 
folds learning fold testing repeated experiment possible combinations folds 
test fold chose schemas time possible combinations automatch match schemas 
manually constructed mappings judge mappings automatch concluded 
measuring performance measure performance schema matching result interpreted set mapping decisions pairs schema attributes bi cj ranges attributes ranges attributes 
attribute mapping decisions falls sets true positives decision map bi tor cj correct 
false negatives decision map bi tor cj incorrect 
false positives decision map bi tor cj incorrect 
true negatives decision map bi tor cj correct 
ratio proportion true positives cases thought positive measures accuracy automatch decides true 
proportion positives detected automatch complete set positives measures ability detect positives 
specifically application ratio measures soundness discovery process ratio measures completeness 
ratios known field information retrieval precision recall shall refer soundness completeness schema matching process 
simplify comparison feature selection approaches combined soundness completeness single performance measure harmonic mean 
harmonic mean precision recall database schema matching machine learning feature selection information retrieval single performance measure preferred 
harmonic mean mapping problem calculated andc soundness completeness discovery process percent reduction feature space 
harmonic mean assumes high values soundness completeness high 
maximizing harmonic mean thought best compromise soundness completeness 
measure performance feature selection strategies discussed section determine harmonic mean soundness completeness strategy increase percentage feature space discarded 
reduce feature space increments percent percent feature space discarded 
interpreting results measured performance automatch attempt optimizing dictionary feature selection bayesian approach score matches section flow graph approach optimize matches section 
cross validation achieved performance measured harmonic mean soundness completeness 
separate experiment random guessing match schemas achieved performance 
compared feature selection strategies section assessed impact schema matching 
shows performance schema matching feature selection strategies 
axis percentage low scoring features discarded axis performance measured harmonic mean soundness completeness 
leftmost point graph corresponds experiment feature selection 
initially feature reduction feature selection strategies improve performance 
strategies perform comparably reduction 
levels reduction ig lr continue produce improved matching performance relative feature selection mi falls performance feature selection 
feature selection strategies improve performance compared initial performance feature selection level sustain improvement varies 
observation indicates approaches acceptable reducing feature space 
furthermore seeking ambitious reduction feature space lr preferable ig preferable mi 
jacob berlin motro lr ig mi fig 

harmonic mean soundness completeness axis feature set reduced increments percent axis described automated solution known problem database schema matching 
approach uses bayesian machine learning statistical feature selection minimum cost maximum flow network algorithm find optimal matching attributes semantically related schemas 
significant findings contributions automatch system new viable approach eliminate schema matching bottleneck modern database applications 
results encouraging show performance exceeds measured harmonic mean soundness completeness attribute matching process 
statistical feature selection improve performance automatch 
improvement areas storage requirements auxiliary knowledge base computational costs matching algorithm quality soundness completeness results 
estimate statistical feature selection improve performance automated schema matching approaches deal high dimensional feature spaces 
statistical feature selection incurs little overhead automatch probabilistic learning approach 
learning feature selection consists simply normalizing probabilities remaining features 
contrast machine learning approaches neural networks rule learners execute respective learning algorithms feature selection completed 
database schema matching machine learning feature selection performance experiments promising user interaction necessary complete matching process 
research plan building user interface allows domain expert adjust attribute mappings proposed automatch 
furthermore interface allow iterative adjustment user adjusts mappings re apply automatch remaining unmapped attributes 
important benefit user interaction automatch system able learn continuously 
new matches provided user interface learner able combine information learned 
note significantly different re executing entire learning algorithm 
continuous learning possible due statistical nature learning algorithm 
new matches validated user learn additional examples updating frequency counts features 
initial experimentation encouraging admittedly limited scale 
additional experimentation planned validate preliminary 
authors wish joseph naor important suggestions area network flows 

ahuja thomas magnanti james orlin 
network flows theory algorithms applications 
prentice hall 


leda users manual version 

ricardo baeza yates berthier ribeiro neto 
modern information retrieval 
acm press 

jacob berlin motro 
automated discovery content virtual databases 
proceedings ninth international conference cooperative information systems pages 

castano valeria de 
schema analysis reconciliation tool environment heterogeneous databases 
proceedings international database engineering applications symposium pages 

anhai doan pedro domingos alon halevy 
reconciling schemas disparate data sources machine learning approach 
proceedings acm special interest group management data sigmod 

pedro domingos michael pazzani 
conditions optimality simple bayesian classifier 
proceedings th international conference machine learning pages 

pat langley wayne iba kevin thompson 
analysis bayesian classifiers 
proceedings tenth national conference artificial intelligence pages 
jacob berlin motro 
wen li chris clifton 
heterogeneous databases neural networks 
proceedings th international conference large data bases pages 

wen li chris clifton 
tool identifying attribute correspondences heterogeneous databases neural networks 
data knowledge engineering 

jayant madhavan philip bernstein rahm 
generic schema matching cupid 
proceedings th international conferences large databases pages 

ren miller laura haas mauricio hern ndez 
schema mapping query discovery 
proceedings th international conferences large databases pages 

tom mitchell 
machine learning 
mcgraw hill 

judea pearl 
probabilistic reasoning intelligent systems networks plausible inference 
morgan kaufmann 

rahm philip bernstein 
matching schemas automatically 
technical report msr tr microsoft redmond wa february 

mehran sahami susan dumais david heckerman eric horvitz 
bayesian approach filtering junk mail 
aaai workshop learning text categorization 

ian witten eibe frank 
data mining practical machine learning tools techniques java implementations 
morgan kaufmann 

