role context question answering systems jimmy lin dennis quan vineet sinha bakshi david huynh boris katz david karger laboratory lcs technology square cambridge ma usa vineet boris karger ai mit edu despite advances natural language question answering technology problem designing effective user interfaces largely unexplored 
conducted user study investigate problem discovered users prefer paragraph sized chunk text just exact phrase answer questions 
furthermore users generally prefer answers embedded context regardless perceived reliability source documents 
users research topic increasing amount text returned users significantly decreases number queries pose system suggesting users utilize supporting text answer related questions 
believe results serve guide developments question answering user interfaces 
keywords question answering information retrieval user interface natural language question answering important technique information access provide users exactly information need flooding documents wade 
current state art systems answer nearly questions spanish explorer discovered mississippi unrestricted domain 
despite significant improvements underlying technology problem designing effective interfaces largely unexplored 
believe natural response presentation style question answering systems focus plus context closely related overview plus detail presentation style 
current question answering systems extract answers textual documents text surrounding answer serves natural source context key concept presentation styles noted 
performed user study explore question text question answering system return user effects source reliability trustworthiness source text extracted scenario size user asking single question set related questions 
related context information retrieval systems extensively studied 
effectiveness spatial temporal contextual clues category labels top ranking related sentences explored empirically user studies web environment 
furthermore interactive track trec generated interest interface issues associated information retrieval systems 
compared single document multidocument view ir results question answering task 
study inconclusive hinted presenting document time just effective displaying multiple documents required cognitive effort 
unclear results directly applied question answering systems role context question answering systems support browsing justify answer offer related information 
knowledge studies regarding effects context conducted specifically question answering systems 
interface conditions focus plus context framework account natural language discourse principles developed different interface conditions 
context simply text surrounding answer varied length different interface conditions 
exact answer 
exact answer returned 
example exact answer battle april 
exact answers named entities dates locations names 
answer sentence 
exact answer returned sentence answer extracted 
answer paragraph 
exact answer returned paragraph answer extracted sentence containing answer highlighted 
answer document 
exact answer returned full document answer extracted sentence containing answer highlighted 
experimental method graduate undergraduate computer science students years old asked participate computer experiment 
participants experienced searching information web experience question answering systems 
purpose study investigate effectiveness actual question answering system isolate criteria effective interfaces study worked system answer test questions accuracy 
answers taken electronic version encyclopedia 
copyright held author owner 
chi april ft lauderdale florida usa 
acm 
source reliability phase study implemented click experiment determine context user needed order accept reject answer depending perceived trustworthiness source document 
eighteen relatively obscure question answer pairs user randomly labeled trusted answer obtained neutral generally reputable source encyclopedia biased answer obtained source known biased viewpoints advocacy site particular special interest group unknown answer obtained source authority established personal homepage 
major goal phase determine context user needed order accept reject answer source document user required judgment regarding validity system response 
focus phase perceived reliability source actual source source citation 
answer source labeled trust conditions described 
furthermore actual answer context change labeling 
start trial exact answer indication source reliability 
user choices accept believe answer move question reject believe answer move question request information request information 
user requested information interface condition click information gave answer sentence interface condition second gave answer paragraph interface condition third gave answer document interface condition 
entire document user choose accept reject 
scenario size second phase study participants asked directly interact sample question answering system 
goal complete series scenarios quickly possible 
scenario consisted single question set closely related questions topic 
phase user study total scenarios single question questions questions questions 
scenario randomly associated fixed interface condition 
previous phase users request context 
scenario considered complete user entered answer question clicked button 
goal phase measure time number queries required complete scenario 
users told interact question answering system way wanted typing questions necessary reading little contextual information desired results surveys showed users liked answer paragraph interface condition best size chunk information exact answer interface condition 
noted sentence doesn give just exact answer 
particular pronouns posed big problem sentences pronouns taken context meaningfully interpreted 
coreference resolution technology integrated question answering systems address issue 
trusted unknown sources users needed paragraph average form judgment answer trusted sources users needed paragraph 
anova analysis revealed difference number clicks statistically significant difference biased unknown conditions ns 
multi question scenarios answer document interface condition resulted lower average completion time difference statistically significant ns 
small variations completion time single question scenarios statistically significant proved control experiments 
multi question scenarios different interface conditions statistically significant impact completion time effect number questions needed complete scenario significant 
document interface condition users asked half questions average exact answer interface condition 
acknowledgments supported darpa contract number additional funding provided mit ntt collaboration mit project oxygen packard foundation fellowship ibm 
wish participants study time mark ackerman greg comments 

moldovan harabagiu tools question answering 
proceedings trec 

leung apperley review taxonomy presentation techniques 
acm transactions interaction 

green marchionini plaisant shneiderman previews overviews digital libraries designing surrogates support visual information seeking 
technical report cs tr department computer science university maryland 

park kim effects contextual navigation aids browsing diverse web systems 
proceedings chi 

dumais cutrell chen optimizing search showing results context 
proceedings chi 

white jose finding relevant documents top ranking sentences evaluation alternative schemes 
proceedings sigir 

belkin keller kelly sikora sun support question answering interactive information retrieval rutgers trec interactive track experience 
proceedings trec 
