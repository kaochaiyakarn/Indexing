dynamic aggressive scheduling techniques power aware real time systems rami melhem daniel pedro alvarez address power aware scheduling periodic hard real time tasks dynamic voltage scaling 
solution includes parts static line solution compute optimal speed assuming worst case workload arrival line speed reduction mechanism reclaim energy adapting actual workload online adaptive speculative speed adjustment mechanism anticipate early completions executions average case workload information 
solutions guarantee deadlines met 
simulation results show reclaiming algorithm saves striking energy static algorithm 
speculative techniques allow additional approximately savings reclaiming algorithm 
study establish solving instance static power aware scheduling problem equivalent solving instance scheduling problem concave reward functions 
decade research community addressed low power system design problems multidimensional effort 
going research important implications real time systems design simply applications running power limited systems inherently impose temporal constraints response time real time communication satellites 
variable voltage scheduling framework involves dynamically adjusting voltage frequency supported defense advanced research projects agency parts project contract 
computer science department george mason university fairfax va 
mail cs gmu edu 
done author university pittsburgh 
computer science department university pittsburgh pittsburgh pa 
mail melhem cs pitt edu 
computer science department university pittsburgh pittsburgh pa 
mail cs pitt edu 

de av 
mexico df 
mail cs mx 
done author visiting university pittsburgh 
cpu speed major research area power aware computer systems 
real time systems proposed schemes focus minimizing energy consumption system meeting deadlines 
yao provided static line scheduling algorithm assuming aperiodic tasks worst case execution times 
heuristics line scheduling aperiodic tasks hurting feasibility periodic requests proposed 
non preemptive power aware scheduling investigated 
concentrating periodic tasks identical periods effects having upper bound voltage change rate examined heuristic solve problem 
slowing processor single task eligible execution explored 
lorch smith addressed variable voltage scheduling tasks soft deadlines 
static solution general periodic model tasks potentially different power consumption characteristics provided 
scheduling schemes studies exclusively worst case execution time wcet guarantee timeliness system lack ability dynamically take advantage unused computation time 
fact real time applications usually exhibit large variation actual execution times example reports ratio worst case execution time best case execution time high typical applications 
consequently dynamically monitoring reclaiming unused computation time show fact powerful approach obtain considerable power savings minimize effects designing system wcet information usually conservative prediction actual execution time 
additional improvements possible statistical workload information investigate aggressive schemes anticipate early completions executions speculatively reduce cpu speed 
approach immediately raises intertwined questions level aggressiveness probability distribution actual workload issue guaranteeing timing constraints aggressive modes 
obvious solutions problems simultaneously practical efficient order applicable line 
goes saying dynamic reclaiming aggressive techniques preserve feasibility task system deadline missed worstcase scenario may take place speed adjustment decision 
note study addressed dynamic energy reclaiming issues speculation power aware scheduling cyclic periodic task models context systems discrete voltage levels 
systems able operate continuous voltage spectrum rapidly reality advances power supply electronics cpu design 
example crusoe processor able dynamically adjust clock frequency mhz steps 
best knowledge concept speculative speed reduction introduced authors tasks sharing common deadline considered 
organization identify address dimensions power aware scheduling real time systems develop efficient algorithms periodic task model 
effectiveness reducing energy consumption improved simultaneous consideration dimensions complement 

static line solution compute optimal speed task level assuming worst case workload arrival section 
section show solving instance static power aware realtime scheduling problem equivalent solving instance reward scheduling problem 

line speed adjustment mechanism dynamically reclaim energy tasks complete consuming worst case workload section 

line adaptive speculative speed adjustment mechanism anticipate compensate probable early completions executions section 
emphasize context real time systems components designed cause deadlines missed worst case scenario aim meet timing constraints simultaneously dynamically reducing power consumption possible 
system model notation ready time deadline real time task denoted respectively 
indicator worst case workload variable voltage speed settings due nature actual execution time dependent cpu speed worst case number required cpu cycles appropriate measure worst case workload see section 
worst case number processor cycles required denoted note constant speed cycles second execution time task schedule real time tasks said feasible task receives ac cpu cycles deadline ac actual number cpu cycles actual workload assume cpu speed changed minimum speed smin minimum supply voltage necessary keep system functional maximum speed smax smin smax normalize speed values respect smax framework voltage speed changes take place context switch time state saving instructions execute 
report voltage speed change performed strong arm sa processor 
negligible voltage change overhead incorporated worst case workload task 
assume process descriptor task extra fields related speed settings addition conventional fields 
denotes current cpu speed executing 
field denotes nominal speed indicator default speed task dispatched operating system sets prior dynamic speed adjustment 
power consumption processor speed assumed strictly increasing convex function represented polynomial second degree 
task occupies processor time interval energy consumed interval dt 
detailed analysis periodic power aware scheduling consider set 
tn periodic realtime tasks 
period denoted equal deadline current invocation 
refer th invocation task tasks assumed independent ready 
ready time deadline define tot total utilization task set maximum speed smax tot note schedulability theorems periodic real time tasks imply tot necessary condition feasible schedule assume tot 
optimal static solution reward approach scheduling analyzing periodic model depth correlate reward scheduling framework power aware scheduling real time tasks 
scheduling framework encompasses real time scheduling models imprecise computation increased reward increased service exploit timeliness precision trade 
underline correlation prove preserved regardless task model aperiodic periodic preemptive nonpreemptive long aim reach solution worst case workload 
reward scheduling framework real time task comprises mandatory part optional part worst case execution times denoted respectively 
mandatory part runs producing output acceptable quality subsequently enhanced optional part limits available computational capacity 
quantify quality improvement non decreasing reward function associated optional execution denotes service time receives 
realistic applications best represented concave reward functions 
feasible reward schedule mandatory part fully executed task deadline optional parts may remain partially executed deadlines 
formally define reward scheduling problem 
reward scheduling problem consider uniprocessor scheduling reward real time task set 
tn 
time point determine optimal schedule interval mandatory part complete timely fashion task deadline optional part receives service units time maximize total system reward 
determination optimal schedule clearly involves computation optimal optional service times 
noting reward accrued optional part increase upperbound computation expressed optimization problem objective find values maximize subject 
exists feasible schedule values hand real time power aware scheduling problem stated follows 
real time power aware scheduling rt pas problem consider cpu variable voltage speed smin smax facility power consumption strictly increasing convex function polynomial second degree 
set 
tn real time tasks task subject worstcase workload expressed number required cpu cycles time point determine schedule processor speed minimize total energy consumption dt interval 
considering periodic task model execution time task instance ij considered separate unknown 
relating scheduling problems observe convexity speed power function allows deduce formal proof 
proposition safely commit constant cpu speed execution task requiring cpu cycles increasing energy consumption 
note determination rt pas problem effectively equivalent determining cpu time allocation denoted 
ready establish connection rt pas reward scheduling problems 
proposition solving instance rt pas problem equivalent solving instance reward scheduling problem concave reward functions 
proof prove statement formulate computation optimal speed values optimization problem 
total energy consumption constant speed assumption task expressed tot 
observe minimum maximum speed bounds impose natural lower upper bounds cpu allocation words inequality smax smin satisfied 
computation optimal cpu allocation assignments formalized optimization problem minimize subject smax smin 
exists feasible schedule values consider variable transformation smax smin smax smax smax 
transformation interpreted follows assigned smax units cpu time mandatory execution 
allocation exceeding minimum amount considered optional execution total cpu allocation exceed upper bound smin allocate cpu time increasing increase energy savings speed power relation 
difficult see transformation re writing optimization problem reaches formulation general reward scheduling problem defined equations 
reward function clearly concave smax smax convex 
see result stating convex functions increasing convex 
setting smax observing multiplication smax affect convexity justify concavity 
specific solution periodic task sets section static optimal solution variable voltage scheduling problem periodic task model assuming task presents worst case workload processor instance 
underline equivalence obtained section results justify proposition formally done reach principles outlined 
proposition optimal speed minimize total energy consumption meeting deadlines constant equal max smin tot 
speed periodic hard real time policy fully utilize processor earliest deadline laxity obtain feasible schedule 
proof observe convex nature power speed function suggests try maintain uniform speed fully utilizing cpu extent possible 
tot smin speed tot leads clearly schedule fully utilized idle time stretching task equal proportions words case achieving total effective task utilization sp tot 
tot smin minimum cpu speed available stretch task executions possible 
case speed max smin tot result total effective task utilization greater 
scheduling policy achieve cpu utilization earliest deadline laxity complete task instances deadlines speed dynamic reclaiming algorithm dynamic reclaiming algorithm detecting early completions adjusting reducing speed tasks fly order provide additional power savings meeting deadlines 
aim perform comparisons actual execution history canonical schedule static optimal schedule instance presents worst case workload processor runs constant speed cpu speed adjusted task dispatch times able say task dispatched earlier determine amount additional cpu time dispatched task safely slow execution refer additional cpu time earliness dispatched task 
providing details approach underline simple approach equates earliness previously unused cpu time blindly slows processor safe approach 
see consider task system parameters 
worst case utilization task set equal optimal speed static version smax proposition 
task presents worst case workload instance edf schedule obtained 
suppose completes 
static optimal schedule early leaving unused computation time units deadline 
units cpu time recall th instance task deadline require worst case workload 
see computing managing earliness trivial task 
due periodic nature tasks consider clearly impractical priori produce keep entire static optimal schedule execution 
order simultaneously address problems feasibility efficiency tasks execute complete re arrive dynamically actual schedule produced choose keep update data structure called queue helps compute earliness tasks dispatched 
time actual execution queue contains information tasks active running ready time worst case static optimal schedule words queue ready queue time 
assume information obtained task queue time identity task task number arrival time instance period boundary earlier deadline instance period boundary rem remaining execution time time static optimal speed clearly values easily computed periodic task model 
note queue time contains information instances rem 
queue contains elements number tasks ready queue exceed total number tasks schedule 
omit instance number referring queue elements clarity compromised 
approach assumes tasks scheduled edf policy 
edf edf earliest deadline tasks deadlines task earliest arrival time highest priority fifo policy case deadline arrival times equal task lowest index highest priority 
edf priority ordering essential approach provides total order priorities 
assume queue ordered edf priorities 
denote edf priority level task low values denote high priorities 
point ready relate queue computation earliness factor 
denote remaining worst case execution time task speed time set nominal speed task proposition task execute unused computation time slack task queue having strictly higher priority contribute earliness finished actual schedule 
total earliness rem rem sx rem sx 
understand result note dispatched tasks higher priority queue finished actual schedule currently highest edf priority finished implementing queue queue easily implemented rules 
initially queue empty 

arrival task pushes worst case execution time nominal speed queue correct edf priority position happens arrival re push return 

time elapses elements queue updated consumed accordingly rem field head queue decreased rate equal passage time 
rem field head reaches zero element removed queue update continues element 
update done queue empty 
observation time queue updated rules contains tasks ready time static optimal schedule rem field contains remaining allotted time active instance time observation stems queue ordered edf order arriving task pushes remaining worst case execution time nominal speed queue queue updated head reflecting fact task highest edf priority running task finished removed queue 
effectively yields dynamic image ready queue time note dynamic reduction rem need performed clock cycle efficiency perform reduction task preempted completes account time elapsed update 
approach relies facts speed adjustment decision taken arrival preemption completion times necessary accurate queue points speeds changed points update rem reflect 
second points task effectively executed non preemptively 
ready generic dynamic reclaiming algorithm shown 
procedure reduce speed allocating extra units time worst case remaining load subject smin constraint 
generic sense amount additional time allocation step specified may assume value compromising correctness 
theorem establishes schedules produced ahead theorem time execution rem ready task formal proof theorem 
focusing exclusively task completion times theorem implies actual schedule task instance completes completion time feasible proving correctness corollary yields feasible schedule edf priority workload greater worst case workload 
note specific algorithm specify exact amount earliness parameter speed reduction 
natural choice rule reduce speed profit full earliness 
call variation simply dynamic reclaiming algorithm dra 
incorporating task extension ote technique slow execution task ready queue worst rules 
compute section assign 
initialize queue empty list 

new arrival insert queue information regarding new task rem value correct edf order 

event arrival completion consider head queue decrease rem value amount elapsed time event 
rem smaller time elapsed event remove head update time elapsed event repeat update element 
done elapsed time 

tx dispatched time 
set sx sx 
consult queue compute indicator earliness amount tx 
reduce speed task tx giving tx extra time units sx speed reduce tx sx 
event preemption completion task say decrease value remaining execution time time elapsed task dispatched 

generic dynamic reclaiming algorithm procedure speed reduce tx 
set sx 
sx smin sx smin 
return sx 
speed reduction procedure case completion time current speed extend event arrival closest deadline task 
technique conjunction scheduling policy add new rule improve dra 
nta arrival time task instance system recall speed step dra time dispatched 

ready task nta sx speed reduce 
words reduce speed idle cpu time nta 
call improved technique dr ote 
clearly holds 
proposition instances meet deadlines dra meet deadlines algorithm dr ote 
experimental results order experimentally evaluate performance dra implemented periodic scheduling simulator edf policy 
implemented schemes static uses constant speed switches power mode smin ready task ote static optimal speed scheme conjunction task extension dynamic reclaiming dra implemented variations ote technique dr ote dra respectively 
experiments investigated average performance schemes large spectrum worst case utilization tot variability actual workload 
particular focused average energy consumption task sets containing tasks 
periods tasks chosen randomly interval 
minimum speed smin set 
nominal speed set tot optimality choice shown section 
variability actual workload achieved modifying wcet bcet ratio worst case best case execution time ratio 
ran experiments actual execution time follows normal probability distribution function mean standard deviation set wcet bcet wcet bcet respectively wcet bcet suggested 
choices ensure average execution times fall interval bcet wcet 
task set simulated execution lcm times lcm common multiple 
pn measured average energy consumption experiment cubic power speed function 
remarkable result ote scheme provides substantial improvements techniques continuously smax execution reclaiming shown entire spectrum provides marginal improvement pure dra 
result indicates entire power savings obtained initially committing fully utilizes cpu static scheme dynamic reclaiming algorithm 
improve readability graphs show results dr ote results identical pure dra 
effect utilization shows energy consumption techniques varying utilization task set results uniform probability distribution function similar 
repeated simulations task sets having different number tasks 
full results lack space mention main trends remain similar task system 
expected main determinant workload total utilization variability actual workload 
utilization static ote dra 
normalized energy consumption tasks 
wcet bcet tot wcet bcet equal 
results normalized respect static reclaim unused computation time 
observe major patterns normalized energy consumption schemes insensitive variations tot due fact scheme optimal nominal speed results having similar effective utilization value tot words utilization decreases speed decreases making cpu fully utilized 
dra definitive advantage static ote utilization values energy consumption system dra system uses static ote 
ote performs better static improvement usually 
implies large power savings reported continuously smax task sets due largely shutting processor processor idle result actual workload 
starts optimal static speed potential additional savings due ote technique limited 
effect wcet bcet ratio simulation results confirmed prediction energy consumption highly dependent variability actual workload 
normalized average energy consumption task sets function wcet bcet ratio tot shown 
terms shape percentage difference curves utilization values fairly similar 
experiments arrived wcet bcet cpu time reclaim dynamically energy consumption wcet bcet ratio static ote dra 
effect variability actual workload tasks load techniques expected 
actual workload starts decreasing increasing wcet bcet ote dra able reclaim unused computation time able save additional energy 
dra capable providing considerably higher power savings ote difference increases rapidly wcet bcet ratio 
instance savings dra wcet bcet better performance ote entire spectrum 
increase wcet bcet power savings dra continue increase improvement impressive case ratio 
expected workload system converges rapidly worst case workload increasing wcet bcet ratio remember mean probability distribution wcet bcet 
aggressive speed reduction dra dr ote algorithms provide sound dynamic speed reclaiming mechanisms guarantee feasibility ahead static worst case optimal schedule tasks start finish scheduled time 
feasible time optimal assumption instances worst case workload 
constant speed actual execution times task instances exhibit large variation starting task assumption conservative 
current system state suggests may assume speculatively current instances probably computational demand lower worst case 
adopt aggressive approach reducing speed running task certain conditions level lower suggested dr ote 
speculative move shift task worst case completion time point actual high workload 
pessimistic scenario turns true ready increase cpu speed guarantee feasibility tasks 
hamper significant power savings convexity power speed curve suggests uniform speed achieve average speed value interval time 
hand case actual workload turns lower worst case actual schedule ahead low speed achieving higher power savings 
powerful system design principle common case efficient 
translates settings worst case workload occurs rarely having schedule average close average cases achieved reducing cpu speed 
having rationale aggressive speed management techniques address provide solutions important issues 
feasibility reduce speed aggressively ready guarantee timing constraints task schedule may longer ahead second issue determination aggressiveness level may possible show existence feasible schedule aggressive speed reduction move justified expected workload system may reasonable adopt conservative speed reduction decrease probability speed increases cause high energy consumption 
natural solution pre defined speed reduction bound sb attempt decrease cpu speed aggressive speed adjustment 
observing average workload appropriate estimator actual computational demand choose parameterize aggressiveness level respect optimal speed average workload 
specifically optimal speed workload instance requires exactly average computational demand determined probability distribution function 
generally may set sb constant smin sb smax smin smax 
observe changing range provides complete spectrum aggressive techniques 
spectrum smin usually smaller corresponds extreme aggressiveness attempt obtain lowest speed level running task subject feasibility achieved executing tasks high speeds choice supposing current workload worst case workload 
spectrum setting smax reflects dr ote algorithm 
main point spectrum scheme limits aggressiveness speed bound exactly reflects view slowing cpu hurt aggregate power savings long run 
feasibility aggressive schemes mentioned attempt aggressively reduce cpu speed risk exceeding worst case completion times current schedule running ready arrive tasks 
general check consequences aggressive decision non trivial problem linked response time analysis complications edf especially addressed dynamic fashion runtime 
study adopt simple approach restricts aggressive power management occur limit effects upto event arrival deadline task 
results section indicate aggressive schemes potential providing additional power savings conservative feasibility test limited horizon 
predict completion time currently ready task extend event arrival deadline speculatively reduce speed guaranteeing complete event definition earlier equal deadline 
care taken order guarantee timely completions ready tasks waiting ready queue lower priority level execution completion tasks delayed completes 
possible way guarantee feasibility case increase speed suitable ready task run effectively equivalent increasing time allocation decreasing time allocation amount 
clearly point system blindly decrease speed original change instance 
generalize ready tasks guaranteed run consecutively complete task arrival time nta worst case workload arbitrarily swap cpu time allocations particular reduce speed increasing speeds 
fact exists highest priority ready task guaranteed complete nta may provide portion time allocation certain conditions 
guarantee complete nta complete time allocation swapping worst case scenario 
computations take account slack time completed tasks queue edf priority lower may contribute worst case cpu allocation 
dynamic reclaiming 
speed adjustments adhere smin smax sb bounds 
incorporate aggressive speed reduction technique add new rule previous algorithm obtaining new algorithm aggressive dr 
nta sx ready tasks addition call aggressive 
procedure speed increase increases speed remove units time allocation worst case remaining workload respect speed subject smax procedure aggressive transfers slack time perform speed increase increasing nominal speed dispatched current speed set rule rules consider new increased speed trying reduce speed due possible earliness detection 
assume new nominal speed returns preemption lowest speed known guarantee feasible schedule case task presents worst case load processor aggressive speed adjustments 
underline nominal speed instances unchanged equal formal proof regarding correctness adjustment routine provided 
evaluation aggressive scheme conducted experiments assess performance aggressive scheme abbreviated agr settings section 
speed bound sb speculative speed adjustment equal aggressiveness factor set 
relative energy consumption agr respect dra shown task sets normal distribution function utilization 
results show consistent advantage agr dra spectrum 
improvement decreases utilization approaches tasks assume nominal default speed aggressive speed reduction expense increasing speed possible 
effect variability actual workload shown 
agr provided better performance dra various wcet bcet ratios 
increasing ratio improves relative performance agr speculative moves justified frequently 
speed bound restrictions possible approach aggressive scheme adhere parameterized speed bound reducing speed step dynamic reclaiming 
approach assumes reducing speed procedure aggressive speed adjustment notation algorithm invoked time ready task highest edf priority denoted tasks ready completed unused computation time queue edf priority lower denoted tm decreasing order priorities 
algorithm cost slight abuse notation expression refer rem value completed task queue time current speed assignments denoted sm task arrival occur time nta 
algorithm max smin return decrease speed determine maximum amount additional cpu time assigned subject smin aggressiveness level constraints max smin 
adjust order extend nta nta nta 
qa transferred slack amount 
find largest increase speed min reducing speed min qa extra time qa extra time ready speed increase extra time commit new default speed instance completed queue min extra time rem qa qa speed reduce 
aggressive speed adjustment procedure hurt total performance long run prevents doing earliness factor justify doing 
distinguish variations aggressive scheme denote original scheme new variation aggressive dr aggressive dr respectively agr agr short 
correctness new scheme follows cor procedure speed increase tx 
sx 
sx smax sx smax 
return sx 
speed increase procedure utilization dra agr 
normalized energy consumption wcet bcet agr agr slows processor agr 
evaluation agr agr section results simulations performed compare algorithms agr agr 
simulation settings identical section 
utilization wcet bcet ratio changed performance agr agr hardly distinguishable 
wcet bcet ratio dra agr 
effect variability actual workload load utilization wcet bcet ratio changing aggressiveness level deeply affects results shown 
curves shown utilization wcet bcet parameter settings similar behavior 
performances dra static insensitive parameter maximum power savings obtained algorithm agr typically 
represents improvement yielding net advantage dra 
agr reaches minimum energy consumption usually 
curve suggests unbounded extreme aggressiveness small values hinders power savings instance schemes consume energy dra 
increase value move balanced aggressiveness levels aggressive schemes preferable dra agr agr outperforms dra respectively 
power savings reach maximum agr agr performance starts degrade 
remarkably agr consumes considerably higher energy agr due fact algorithm run large values algorithm reluctant reclaim transfer cpu time speed higher agr suffer effect automatically uses earliness information perform initial speed reduction considers speed bound sb aggressively reducing speed 
large values agr remains better dra guaranteed converge bcet wcet example 
hand agr converges ote shown value actual speed starts aggressive dynamic reclaiming possible sb case cpu speed reduced ote 
summary keeping range committing aggressiveness level aims achieve close produces best results yielding additional dra dr ote energy savings may high 
techniques power aware realtime computing variable voltage scheduling 
solution comprised parts static solution compute optimal speed worst case workload line speed adjustment mechanism reclaims unused time actual workload speculative speed adjustment mechanism expected workload 
knowledge time aggressive safe techniques anticipate provision early completions periodic real time scheduling 
simulation results show reclaiming algorithm saves striking energy static algorithm aggressiveness parameter static dra agr agr 
effect bounding factor aggressive schemes tasks utilization wcet bcet takes account load system 
quite significant result shows lifetime mobile battery operated devices extended average twice levels static solutions 
considering data previous conclude batteries extended order magnitude longer power management schemes 
preliminary aggressive techniques allow additional savings reclaiming algorithm 
conclude aggressive aggressive causes algorithms perform poorly 
currently studying conservative approaches stopping aggressiveness event believe lead energy savings 
melhem alvarez 
optimal scheduling periodic real time tasks 
ieee transactions computers february 
melhem alvarez 
determining optimal processor speeds periodic real time tasks different power characteristics 
proceedings th euromicro conference real time systems delft netherlands june 

enhancing performance fault tolerance reward scheduling 
ph dissertation university pittsburgh august 
dey kurose towsley 
line scheduling policies class iris increasing reward increasing service real time tasks 
ieee transactions computers july 
ernst ye 
embedded program timing analysis path clustering architecture classification 
computer aided design iccad 
pp 

chandrakasan 
efficient controller variable supply voltage low power processing 
symposium vlsi circuits pp 
havinga smith 
design techniques low power systems 
journal systems architecture 
vol 
hong qu potkonjak srivastava 
power optimization variable voltage core systems 
proceedings th design automation conference dac hong potkonjak srivastava 
line scheduling hard real time tasks variable voltage processor 
computer aided design iccad 
pp 

hong qu potkonjak srivastava 
synthesis techniques low power hard real time systems variable voltage processors 
proceedings th ieee real time systems symposium rtss madrid december 
krishna lee 
voltage clock scaling adaptive scheduling techniques low power hard real time systems 
proceedings th ieee real time technology applications symposium washington may 
liu layland 
scheduling algorithms multiprogramming hard real time environment 
journal acm pp 

liu 
lin 
shih 
yu chung yao zhao 
algorithms scheduling imprecise computations 
ieee computer may 
lorch smith 
improving dynamic voltage scaling algorithms pace 
proceedings acm sigmetrics conference cambridge ma june 
luenberger linear nonlinear programming addison wesley reading massachusetts 
melhem 
compiler assisted dynamic power aware scheduling real time applications 
workshop compilers operating systems low power philadelphia pa october 
yu meg 
high efficiency variable voltage cmos dynamic dc dc switching regulator 
ieee international circuits conference pp pedram 
power minimization ic design principles applications 
acm transactions design automation electronics systems 
pp 
january 
langendoen sips 
dynamic voltage scaling low power microprocessor 
th international conference mobile computing networking mobicom rome italy july 
rajkumar lee lehoczky siewiorek 
resource allocation model qos management 
proceedings th ieee real time systems symposium december 
shin choi 
power conscious fixed priority scheduling hard real time systems 
proceedings th design automation conference dac 
www transmeta com yao demers shenker 
scheduling model reduced cpu energy 
ieee annual foundations computer science pp 

