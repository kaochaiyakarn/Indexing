instruction selection resource allocation scheduling aviv retargetable code generator srinivas devadas department eecs mit department eecs mit lcs mit edu devadas mit edu aviv retargetable code generator produces optimized machine code target processors different instruction set architectures 
aviv optimizes minimum code size 
retargetable code generation requires development heuristic algorithms instruction selection resource allocation scheduling 
aviv addresses code generation subproblems concurrently current code generation systems address sequentially 
accomplishes converting input application graphical split node dag representation specifies possible ways implementing application 
information embedded representation set heuristic branch bound step performs functional unit assignment operation grouping register bank allocation scheduling concurrently 
detailed register allocation carried second step estimates register requirements generated step ensure high quality final assembly code 
near optimal code generated basic blocks different architectures reasonable amounts cpu time 
framework allows accurately evaluate performance different architectures application code 
hardware software design embedded systems variety reasons manufacturers profit integrating entire system single integrated circuit 
designing entire complex system application specific integrated circuit asic economical practical 
furthermore time market requirements place greater burdens designers fast design cycles increasing amount system functionality implemented software relative hardware 
hardware software design methodology designers partition system functionality hardware software 
target processor called embedded processor selected existing processor designs asip application specific instruction set processor designed execute software 
hardware software asip resulting system evaluated hardware software simulator 
partitioning processor design repeated acceptable system developed 
complexity grows programming optimization hand longer practical 
hand coding virtually eliminates possibility changing processor architecture 
argue order able explore processor design space automatically retargetable compilation strategy required 
overview aviv retargetable code generator developing retargetable code generator aviv inputs application program machine description target processor 
machine description written isdl instruction set description language includes instruction set specification architectural information 
aviv produces code optimized minimal size run target processor 
code size optimization cost function focusing embedded processors size chip rom critical issue 
varying machine description evaluating resulting object code design space hardware software components effectively explored 
aviv focuses architectures exhibiting instruction level parallelism ilp including long instruction word vliw architectures 
retargetable code optimization requires development heuristic algorithms instruction selection resource allocation scheduling 
aviv addresses code generation subproblems concurrently current code generation systems address sequentially 
main reason current code generators address problems sequentially simplify decision making code generation 
decisions phase profound effect phases 
aviv converts application code graphical split node dag representation specifies possible ways implementing application basic blocks target processor 
information embedded representation set heuristic branch bound step performs functional unit assignment operation grouping register bank allocation scheduling concurrently 
detailed register allocation carried second step required loads spills due limits available registers generated scheduled step 
ensures valid detailed register allocation undoing chosen operation groupings functional unit assignments 
organization section ii describes compiler framework aviv code generator 
section iii presents split node dag formulation retargetable code generation 
section iv formulates code generation problem covering problem split node dag 
section presents previous retargetability code generation comparisons 
results code generator ongoing compiler project section vi 
ii 
compiler framework illustrates compiler framework aviv code generator 
compiler front receives source program written 
performs machineindependent optimizations generates intermediate format description suif 
isdl machine description target processor generated hand high level cad tool 
compiler back takes suif isdl description inputs assembly code specific optimized target processor 
isdl description create assembler 
automatically generated assembler transforms code produced compiler binary file input simulator 
focuses back aviv code generator 
aviv uses suif compiler conjunction spam compiler front 
front converts source program intermediate form consisting expression dags control flow information 
performs machine independent optimizations loop unrolling transformations extract machine independent parallelism 
starting point aviv compiler number basic block dags connected control flow information 
sample basic block dag shown 
aviv focuses extracting machine stanford university intermediate format synopsys princeton aachen mit assembly isdl isdl binary source code assembler generator compiler front compiler back assembler simulation environment suif aviv architecture design fig 

retargetable code generation framework aviv basic block fig 

basic block dag dependent parallelism isdl description target processor 
accomplished converting basic block dags expression trees split node dags 
instruction set information contained isdl machine description create databases create split node dag described section iii 
databases stores correlation target processor operations suif basic operations suchas add sub 
information comes rtl description instruction 
second database stores possible data transfers explicitly stated target machine description subsequently expanded include multiple step data transfers 
machine description describes constraints instructions exist target processor 
information remove constrained operations databases ensuring creating split node dag contain legal mappings suif operations target machine operations 
iii 
split node dag split node dag definition split node dag representation contains necessary information generate code perform operations original basic block dag target processor 
addition allows exploration parallelism achievable target architecture basic block 
split node dag provides information multiple ways operation performed target processor 
example add suif node split nodes representing different functional units perform add operation 
split node dag includes data transfer information 
important include data transfer nodes cost covering dag include cost transferring data units 
including transfer nodes transfers automatically scheduled operations 
syntactically split node dag similar dag representing operations performed block code 
split node dag additional types nodes split nodes data transfer nodes 
split node corresponds operation node original dag 
immediate non data transfer node descendants split node correspond possible ways operation may performed target processor 
data transfer nodes inserted path split node immediate operation descendants correspond data transfers required path 
split node dag explicitly represents possible implementations block code target processor 
operation im dm instr mem data mem add sub add mul sub add mul fig 

example target architecture im dm dm im transfer nodes split nodes fig 

split node dag grouping functional unit assignment register bank allocation scheduling performed simultaneously split node dag 
implementation block code corresponds set instructions operations assigned execution unit data transfers units accounted 
stage detailed register allocation performed estimate number registers required register bank insert loads spills available resources exceeded 
guarantees modify instruction selection detailed register allocation 
creating split node dag clarify structure split node dag create basic block 
example vliw target processor 
processor unit perform addition add subtraction sub 
unit perform addition add subtraction sub multiplication mul 
unit perform addition add multiplication mul 
unit contains register file perform operation time 
architecture includes instruction memory im data memory dm connects units memories 
information required generate split node dag extracted isdl target machine description described section ii 
illustrates result converting basic block dag split node dag 
split node children corresponding multiple units perform add mul sub operations target architecture 
note paths split nodes set operation nodes 
edge connecting operations original basic block dag split multiple edges representing possible paths operation operation edges result transfer unit data transfer node added edge 
includes multi level paths direct transfer path available target architecture 
split node dag structure easily incorporate complex instructions basic operations utilizing initial pattern matching phase detects nodes original expression operation functional unit assignment main tasks instruction selection vliw processors 
data transfers inserted pairs operations executed different functional units 
explore possible split node functional unit assignments estimate cost assignment select lowest cost assignments explore detail foreach selected assignment insert required data transfers generate maximal groupings nodes executed parallel select minimal cost set maximal groupings covers nodes final solution lowest cost solution fig 

algorithm covering split node dag dag covered complex instruction supported target processor 
generating split node dag additional edges corresponding matched complex instructions added addition basic operation matches 
control flow aviv receives collection basic blocks connected control flow information input 
code generated basic blocks methods section iv 
code corresponding control flow instructions jumps needs generated 
conventional tree covering algorithms step 
aviv currently targets minimum code size control flow optimizations speculative execution improve performance expense code size incorporated 
iv 
code generation split node dag goal code generator cover split node dag minimal cost set target processor instructions 
methodology addresses instruction selection resource allocation code generation concurrently phases mutually dependent performing sequentially generally results non optimal code 
covering dag aviv code generator performs functional unit assignment operation data transfer grouping instructions register bank allocation scheduling 
detailed register allocation peephole optimizations performed second step 
describes algorithm covering dag minimal cost set instructions 
introduce multiple heuristics order reduce runtime algorithm sacrificing quality results 
algorithm begins exploring possible split node functional unit selecting lowest cost assignments explore detail 
selection heuristic cost function described section iv 
selected assignments explored detail 
data transfers required functional unit assignment added section iv 
nodes current assignment including transfer nodes merged maximal groupings nodes executed parallel section iv 
maximal groupings correspond vliw instructions 
heuristic selection process section iv covers nodes current assignment minimal cost set maximal groupings 
accurate cost reflecting number instructions required cover nodes maintained 
assignment resulting lowest cost selected final solution 
exploring split node functional unit assignments step covering split node dag select target processor operation functional unit cover split node 
split node dag node selected cover subtract split node node selected cover multiply split node 
number possible split node covering assignments quickly calculated multiplying number possible target processor operations covering split node example theta theta 
small basic block results possible assignments 
typical basic blocks multiplicative growth number possible split node functional compl sub mul mul add add add add add add sub fig 

pruning search space split node assignments unit assignments quickly prohibitively cpu intensive explore possible cases 
step algorithm prune search space selecting split node functional unit assignments explore depth 
selection cost function takes account main factors contributing higher cost measured number instructions covering dag 
factors amount parallelism due split node covering assignments number data transfers required assignment 
important include factors cost function allows optimize instruction selection scheduling phases code generation concurrently 
calculating cost function possible functional unit assignments take long 
prune search space possible assignments calculating incremental cost split node encountered continue search split node assignments minimum incremental cost 
tested order increasing level top split node dag 
purpose illustrating cost function assume sub nodes split node dag feed sink node complement compl function executed unit 
assign cost required transfer node executed parallel due current functional unit assignment 
shows incremental cost node locations search space pruned marked 
incremental cost sub node executed unit require transfer compl node executed preclude possible parallel execution 
sub cost requires data transfer unit compl function 
search space pruned sub node 
incremental cost implementing mul operation unit paths explored 
examine paths include mul operation unit 
performing add unit introduces incremental cost due transfers required load operands 
require transfer sub operation executed unit 
preclude possible merging add mul mul operation executed unit 
add unit hand incurs incremental cost operands transfer sub operation required additional precludes merging add mul operations executed unit 
result example select assignments sub add operations performed unit 
adding required transfers selected split node covering assignment required data transfer nodes added 
case single data transfer path step straightforward pair nodes requires data transfer possible selection data transfer node 
architectures containing multiple transfer paths may possibility fig 

matrix finding maximal cliques gen max clique clique index number nodes executed parallel nodes current clique adding preclude adding node index pruning condition return add clique number nodes executed parallel nodes current clique gen max clique clique added max index fig 

pseudo code generating maximal cliques data transfer 
problem resembles initial problem selecting best split node covering number options grows multiplicatively 
apply heuristic order select possible transfer paths cost function solely parallelism 
maximal groupings selected set possible split node covering assignments corresponding data transfer nodes want explore assignments depth find result minimum cost set target processor instructions cover nodes assignment 
rest section term assignment refer collection functional unit assignments cover split nodes associated transfer nodes 
goal examine nodes groups nodes executed parallel target processor 
grouping vliw instruction 
want select minimal cost set vliw instructions cover nodes assignment 
order reduce total cost vliw instructions required cover split node dag preferable select instructions parallelism provided target processor 
groupings nodes examine maximal groupings maximal cliques parallel nodes 
words subsets larger clique considered possible grouping 
note node assignment explored covered clique 
possible clique contain node 
maximal cliques group operation nodes data transfer nodes 
generating maximal cliques create theta matrix representing pairwise parallelism number nodes current assignment split node dag 
matrix contains element executed parallel 
operations different functional units having directed path performed parallel 
shows matrix split node dag consisting nodes row example specifies add unit performed parallel mul unit 
maximal cliques generated example 
pseudo code shown describes algorithm generating maximal cliques pairwise parallelism matrix 
routine gen max clique called parent routine loop iterates nodes starting clique node 
value argument index set starting clique node number 
gen max clique routine loop adds nodes preclude addition nodes current clique 
nodes added meet criterion second loop spawns recursive calls gen max clique call new node added clique 
new node executed parallel nodes current clique preclude addition nodes 
process repeated new clique new nodes added point maximal clique 
condition follows fact index generated cliques generated recursive call 
terminate branch 
example suppose clique fjg adding node clique preclude selection node 
cliques clique fi jg started clique fig seed 
reducing number maximal cliques generated generating maximal cliques time consuming portion algorithm 
order improve runtime implemented heuristic allows merging nodes level bottom level top solution dag close 
generally idea merge nodes levels top bottom different chances merging preclude merging nodes allow greater parallelism 
incorporating heuristic improves runtime fewer maximal cliques generated maintains quality results 
eliminating illegal instructions maximal clique generation phase merges nodes data dependence executed different functional units single instructions cliques 
merging solely criterion insufficient guarantee legality instructions target processor 
illegal groupings described constraints section isdl description 
proposed instruction compared constraints target processor 
constraints met illegal instruction maximal clique split instructions smaller cliques constraints met 
selecting minimum cost set maximal cliques maximal cliques generated step find minimum cost set cliques cover nodes assignment 
covering algorithm begins empty solution set 
selects maximal clique covers largest number remaining uncovered nodes children covered nodes bottom split node dag scheduled nodes depend creating schedule cliques selected register requirements exceed available resources 
available resources determined performing liveness analysis selected maintaining running upper bound number required registers register bank 
selecting clique remaining cliques shrunk longer include covered nodes 
process repeated nodes covered 
case tie cliques cover equal number nodes algorithm differentiates lookahead cost function estimates number cliques required cover rest nodes particular clique added solution set 
event remaining cliques contain nodes require spill memory order satisfy register resource constraints algorithm determines covered node spilled 
decision needed resource number parent nodes require spilled value reloaded memory 
node spilled selected required load spill nodes added transfer node fig 

inserting loads spills split node dag original split node dag split node dag augmented load spill nodes split node dag transfer nodes longer required removed shown 
node selected node spill transfer node nodes removed 
new maximal cliques generated remaining uncovered nodes including new load spill nodes 
covering algorithm continues new maximal cliques remaining uncovered nodes 
covering solution assignment required minimum cost set cliques cover nodes selected final assignment 
order cliques selected determines schedule cliques instructions 
final covering solution set shrunk maximal cliques cover split node dag 
implies unit assignment operation data transfer nodes merged vliw instructions register bank allocation performed including addition load spill necessary determined 
remaining task detailed register allocation 
detailed register allocation perform detailed register allocation conventional graph coloring algorithms 
guaranteed able color register bank graph number registers analyzed variable lifetimes instruction selection scheduling step 
possible inserted load spill operations required lifetime analysis inserting operations pessimistic 
peephole optimization performing detailed register allocation determined particular load spill needed peephole optimization performed attempt improve schedule 
remove unnecessary loads spills try compact schedule moving operations empty slots dependency constraints allow 
may may reduce final number required instructions 
related section presents brief survey compiler literature pertains retargetable compilers comparison 
briefly review representative research projects area mimola chess ilp approach wilson 
mimola mimola distinguishing feature microcode compiler infers rules code generation directly structural description net list target architecture behavioral description instruction set 
advantage approach machine description synthesis target architecture generation 
difficult compiler find code optimizations having explicit behavioral information 
includes retargetable code generator takes algorithm expressed high level maps user defined instruction set produce optimized machine code target asip commercial processor core 
uses mixed structural behavioral level model 
mixed model includes enumeration possible partial instructions netlist describing data path topology definition register classes 
converts high level source program hierarchy control data flow graphs 
distinguishing feature pattern matching phase pre sorted tree patterns allow pruning search tree possible target processor instruction matches 
determines best implementation cdfg target processor including support complex instruction recognition utilization 
global scheduling register allocation performed 
compaction assembly linkage phases produce machine code 
general framework similar 
aviv determining globally optimum solution considers instruction selection resource allocation scheduling concurrently performing various code generation steps sequentially 
chess chess retargetable code generation system targeting fixedpoint digital signal processors asips 
generates machine code target processor described nml language provides feedback suited target processor application 
nml target processor description translated instruction set graph isg mixed structural behavioral representation processor 
isg models connectivity encoding restrictions structural hazards 
code generation process translates input algorithm cdfg 
code selection covers cdfg patterns correspond partial instructions supported instruction set called bundles 
making exhaustive list possible bundles bundle instructions fly searching valid paths isg 
chess phase code generation performed separately order ensure phase coupling intermediate scheduling view constructed phase takes account constraints imposed previous phase 
chess driven nml differs isdl particularly way constraints handled 
constraints isdl allow code generator treat operations completely orthogonal 
illegal operation combinations removed maximal cliques constraints 
nml hand attributed grammar production rules define instruction set 
legal groupings operations explicitly listed 
isdl descriptions concise result easier code generator handle 
stated phase code generation performed separately independently 
aviv focused solving various code generation problems concurrently 
wilson wilson integer linear programming ilp approach code generation behavioral model target processor 
similar chess code generation begins translating high level source language data flow graph dfg 
designer supply optimization hints 
pattern matching recognize complex instructions 
possible schedule attempts minimize overhead costs spills memory address calculations identified 
register assignment including necessary spills memory performed 
cornerstone optimizations ilp solver simultaneously scheduling instruction selection register assignment compaction select alternative spill addressing candidates 
constraints considered simultaneously ilp formulation trade offs various optimizations leading globally optimal solution 
problem ilp solvers code generation finding optimal solution far cpu intensive 
ilp solver sufficient information structure problem order intelligent decisions prune basic block original dag split node dag registers spills instr solution cpu time nodes nodes regfile inserted hand aviv secs ex ex ex ex ex ex ex table code generation experiments example target architecture basic block original dag split node dag registers spills instr solution cpu time nodes nodes regfile inserted hand aviv secs ex ex ex ex ex table ii code generation experiments target architecture ii search space 
general user supplied hints required produce code reasonable amount cpu time 
vi 
experiments ongoing implemented preliminary version retargetable code generator run experiments basic blocks 
examples generic basic blocks occur dsp application code 
examples simple basic blocks part conditional statement loop 
examples simple basic blocks loops unrolled twice 
aviv generated code basic blocks targeting minimum code size 
results example target architecture summarized table table summarizes number nodes original dags basic blocks examined number nodes equivalent split node dags example architecture 
compares number instructions hand coding solution aviv 
handcoded results optimal 
number instructions equals number clock cycles required execute basic block target architecture 
examples run registers register file 
examples require spills memory 
examples rerun registers register file show happens required number registers exceeds available resources 
examples resulted spills memory results examples respectively 
note optimal solutions examples require spills 
solutions aviv initial functional unit assignment cost function detect functional unit assignments result spills memory 
see aviv results quite close optimal 
cpu times shown finding solutions measured sun microsystems ultra 
aviv incorporates multiple heuristics turned desired 
example selecting possible split node assignments generate possible assignments 
heuristics level top bottom reduce number maximal cliques generated turned 
parentheses results running examples heuristics turned 
note turning heuristics result exact algorithm code generation explore possible schedules 
clear pruning heuristics generate quality results fraction cpu time required find optimum solution 
purpose developing split node dag structure heuristic algorithms covering enable retargetable code generation 
mind changed target architecture removing sub operation functional unit completely removing functional unit 
results architecture summarized table ii 
seen basic blocks removing functional unit degrade performance 
flexibility aviv retargetable code generation system allows exploration different architectures best 
currently working modifying initial functional unit assignment cost function incorporate register resource limits detect assignments require spills memory 
addition working peephole optimization methods applied detailed register allocation 
acknowledgments research supported nsf contract mip 
gupta de micheli 
hardware software digital systems 
ieee design test computers pages september 
devadas 
isdl instruction set description language retargetability 
proceedingsof th conference pages june 
stanford compiler group 
suif library edition 
spam research group 
spam compiler user manual edition 
chaitin auslander chandra cocke hopkins markstein 
register allocation coloring 
computer languages 
marwedel 
tools design digital processors 
proceedings th design automation conference pages 
paulin flexible firmware development environment embedded systems 
code generation embedded processors pages 
kluwer academic publishers 
chess retargetable code generation embedded dsp processors 
code generation embedded processors pages 
kluwer academic publishers 
wilson ilp approach code generation 
code generation embedded processors pages 
kluwer academic publishers 
may paulin 
instruction set matching selection dsp asip code generation 
proceedings european design test conference pages feb 

nml machine description formalism 
technical report tu berlin 
