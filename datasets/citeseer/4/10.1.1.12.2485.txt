concept discovery text dekang lin patrick pantel department computing science university alberta edmonton alberta canada cs ualberta ca broad coverage lexical resources wordnet extremely useful 
include rare senses missing domain specific senses 
clustering algorithm called cbc clustering committee automatically discovers concepts text 
initially discovers set tight clusters called committees scattered similarity space 
centroid members committee feature vector cluster 
proceed assigning elements similar cluster 
evaluating cluster quality difficult task 
new evaluation methodology editing distance output clusters classes extracted wordnet answer key 
experiments show cbc outperforms known clustering algorithms cluster quality 
broad coverage lexical resources wordnet extremely useful applications word sense disambiguation leacock chodorow miller pasca harabagiu 
include rare senses missing domain specific senses 
example wordnet words dog computer sense hyponym person 
rare senses difficult coreference resolution system wordnet enforce constraint personal pronouns refer person 
hand wordnet misses user interface object sense word dialog software manuals 
way deal problems clustering algorithm automatically induce semantic classes lin pantel 
clustering algorithms represent cluster centroid members kmeans mcqueen representative element medoids kaufmann rousseeuw 
averaging elements cluster centroid cluster may unduly influenced elements marginally belong cluster elements belong clusters 
example clustering words contexts words features group words tend appear similar contexts 
instance state names clustered way tend appear contexts list court campaign capital governor driver license illegal sth 
primary sales tax senator create centroid state names centroid contain features list airport business district fly mayor mayor subway state names new york washington names cities 
single representative cluster may problematic individual element idiosyncrasies may shared members cluster 
propose clustering algorithm cbc clustering committee centroid cluster constructed averaging feature vectors subset cluster members 
subset viewed committee determines elements belong cluster 
carefully choosing committee members features centroid tend typical features target class 
example system chose committee members compute centroid state cluster illinois michigan minnesota iowa wisconsin indiana nebraska vermont 
result centroid contains features list evaluating clustering results difficult task 
introduce new evaluation methodol ogy editing distance output clusters classes extracted wordnet answer key 
previous clustering algorithms generally categorized hierarchical partitional 
hierarchical agglomerative algorithms clusters constructed iteratively merging similar clusters 
algorithms differ compute cluster similarity 
single link clustering similarity clusters similarity similar members complete link clustering uses similarity similar members 
average link clustering computes similarity average similarity pairs elements clusters 
complexity algorithms number elements clustered jain murty flynn 
chameleon hierarchical algorithm employs dynamic modeling improve clustering quality karypis han kumar 
merging clusters consider sum similarities pairs elements clusters average link clustering 
drawback approach existence single pair similar elements unduly cause merger clusters 
alternative considers number pairs elements similarity exceeds certain threshold guha rastogi kyuseok 
may cause undesirable mergers large number pairs similarities barely exceed threshold 
chameleon clustering combines approaches 
means clustering large data sets complexity linear number elements clustered 
means family partitional clustering algorithms iteratively assigns element clusters centroid closest recomputes centroid cluster average cluster elements 
means complexity efficient clustering tasks 
initial centroids randomly selected resulting clusters vary quality 
sets initial centroids lead poor convergence rates poor cluster quality 
bisecting means steinbach karypis kumar variation means begins set containing large cluster consisting element iteratively picks largest cluster set splits clusters replaces split clusters 
splitting cluster consists applying basic means algorithm times keeping split highest average similarity 
hybrid clustering algorithms combine hierarchical partitional algorithms attempt high quality hierarchical algorithms efficiency partitional algorithms 
buckshot cutting karger pedersen tukey addresses problem randomly selecting initial centroids means combining average link clustering 
buckshot applies average link random sample elements generate clusters 
uses centroids clusters initial centroids means clustering 
sample size quadratic running time average link buckshot efficient nlogn 
parameters usually considered small numbers 
word similarity lin represent word feature vector 
feature corresponds context word occurs 
example threaten context 
word occurred context context feature 
value feature pointwise mutual information manning feature word 
context fc frequency count word occurring context pointwise mutual information defined mi rc ri rc fi total frequency counts words contexts 
known problem mutual information biased infrequent words features 
multiplied mi discounting factor compute similarity words cosine coefficient salton mcgill mutual information cbc algorithm cbc consists phases 
phase compute element top similar elements 
experiments 
phase ii construct collection tight clusters elements cluster form committee 
algorithm tries form committees possible condition newly formed committee similar existing committee 
condition violated committee simply discarded 
final phase algorithm element assigned similar cluster 

phase find top similar elements computing complete similarity matrix pairs elements obviously quadratic 
dramatically reduce running time advantage fact feature vector sparse 
indexing features retrieve set elements feature 
compute top similar words word sort features mutual information compute pairwise similarities words share high mutual information feature 
phase ii find committees second phase clustering algorithm recursively finds fight clusters scattered similarity space 
recursive step input list elements clustered similarity database phase thresholds 
step element cluster top similar elements average link clustering 
cluster discovered compute score icl icl number elements average pairwise similarity elements store highest scoring cluster list step sort clusters descending order scores 
step list committees initially empty 
cluster sorted order compute centroid averaging frequency vectors elements computing mutual information vector centroid way individual elements 
similarity centroid committee previously added threshold add step empty done return step element similarity committee threshold add list dues step empty done return return union output recursive call phase ii input replacing output list committees 

phase ii cbc 
algorithm finds set tight clusters called committees identifies residue elements covered committee 
say committee covers element element similarity centroid committee exceeds high similarity threshold 
algorithm recursively attempts find committees residue elements 
output algorithm union committees recursive step 
details phase ii 
step score reflects preference bigger tighter clusters 
step gives preference higher quality clusters step cluster kept similarity previously kept clusters fixed threshold 
experiments set 
step terminates recursion committee previous step 
residue elements identified step residues algorithm terminates recursively apply algorithm residue elements 
committee discovered phase defines final output clusters algorithm 

phase iii assign elements clusters phase iii element assigned cluster containing committee similar 
phase resembles means element assigned closest centroid 
means number clusters fixed centroids change element added cluster added committee cluster 
evaluation methodology cluster evaluation schemes proposed 
generally fall categories comparing cluster outputs manually generated answer keys referred classes embedding clusters application evaluation measure 
example approach considers average entropy clusters measures purity clusters steinbach karypis kumar 
maximum purity trivially achieved element forms cluster 
example second approach evaluates clusters smooth probability distributions lee pereira 
entropy scheme assume answer key defines elements supposed clustered 
set clusters answer key 
define editing distance dist number operations required consistent say consistent mapping clusters classes cluster elements belong class allow editing operations merge clusters move element cluster 

example applying transformation rules clusters 
classes answer key clusters transformed sets reconstruct classes rule sets merge operations step sets move operation step 
baseline clustering element cluster 
define quality set clusters follows dist dist suppose goal construct clustering consistent answer key 
measure interpreted percentage operations saved starting versus starting baseline 
aim construct clustering consistent opposed clustering identical senses may exist corpus generate experiments extract answer classes wordnet 
word dog belongs person animal classes 
newspaper corpus person sense dog best extremely rare 
reason expect clustering algorithm discover sense dog 
baseline distance dist exactly number elements clustered 
assumption element belongs exactly cluster 
transformation procedure follows 
suppose classes answer key 
start list empty sets labeled class answer key 

cluster merge set class largest number elements cluster tie broken arbitrarily 

element set class element classes move element set 
dist number operations performed transformation rules shows example 
cluster containing merged set arbitrarily chose second 
total number operations 
experimental results generated clusters news corpus cbc compared classes extracted wordnet miller 

test data extract classes wordnet estimate probability random word belonging subhierarchy synset hyponyms 
frequency counts synsets semcor corpus leacock estimate probability subhierarchy 
semcor fairly small corpus frequency counts synsets lower part wordnet hierarchy sparse 
smooth probabilities assuming siblings equally parent 
class defined maximal subhierarchy probability threshold 
minipar lin english parser parse gb words newspaper text trec collection ap newswire la times san jose mercury speed words second piii mb memory 
collected frequency counts grammatical relationships contexts output minipar compute pointwise mutual information values section 
test set constructed intersecting words wordnet nouns corpus total mutual information contexts exceeds threshold wordnet low coverage proper names removed capitalized nouns 
constructed test sets consisting words consisting words 
removed answer classes words occur test sets 
table summa test sets 
sizes wordnet classes vary lot 
classes contain words largest class contains words 
classes words largest class contains words 
available www cs ualberta ca minipar htm table 
description test sets experiments 
data total avg 
features total set words word classes table 
cluster quality clustering algorithms test sets 
algorithm cbc means buckshot bisecting means chameleon average link complete link single link 
cluster evaluation clustered test sets cbc clustering algorithms section applied evaluation methodology previous section 
table shows results 
columns editing distance evaluation measure 
test set higher score algorithms higher number average features word 
means buckshot algorithms set number clusters maximum number iterations 
sample size buckshot 
bisecting means algorithm applied basic means algorithm twice section maximum iterations split 
implementation chameleon unable complete clustering reasonable time due time complexity 
table shows means buckshot average link similar performance 
cbc outperforms algorithms data sets 

manual inspection cluster wn wordnet class largest intersection precision defined table 
clusters discovered cbc features top highest mutual information wordnet classes largest intersection cluster 
rank members top features wn hand rifle blast barrel fire point artifact artifact machine gun shotgun pull discharge fire go ann gun 
automatic fire kill open fire shoot automatic rifle threaten automatic stopwatch pest fruit fly flea beetle killer bee predator cricket supervision discipline oversight control governance decision making jurisdiction blend mix mixture combination juxtaposition combine amalgam synthesis hybrid employee client patient applicant individual participant volunteer recipient caller giver control population swarm attract breed eat feed repel breakdown lack loss assume exercise exert maintain retain seize tighten bring operate place put remain dip addto pour stir curious eclectic ethnic odd potent unique unusual benefit care housing benefit provide require give offer provide indigent animal animate beast brute creature fauna act human action human activity group grouping wi cbc discovered clusters 
sorted precision 
table shows clusters evenly distributed precision ranking top features highest mutual information 
words clusters listed descending order similarity cluster centroid 
cluster include wn 
underlined words wn 
cluster clearly cluster second 
wordnet word pest curiously person hierarchy 
words stopwatch belong clusters low similarity cluster centroid 
third cluster represents kind control 
wordnet legal power sense jurisdiction hyponym social control supervision oversight governance 
fourth cluster mixtures 
words blend mix event mixing wordnet result mixing 
cluster consumers 
consumer class wordnet addict alcoholic big buyer client concert consumer customer cutter diner drug addict drug user drunk eater feeder fungi head addict home buyer patron policy holder purchaser reader regular shopper smoker subscriber taker user vegetarian wearer cluster word client belongs wordnet consumer class 
cluster ranked low wordnet failed consider words patient consumers 
table shows lowest ranking cbc clusters fairly coherent 
features associated cluster classify previously unseen words existing clusters 
table shows clusters containing word cell discovered various clustering algorithms 
underlined words represent words belong cell class wordnet 
cbc cluster corresponds exactly wordnet cell class 
means buckshot produced fairly coherent clusters 
cluster constructed bisecting means obviously inferior quality 
consistent fact bisecting means lower score compared cbc means buckshot 
table clusters representing cell concept clustering algorithms 
algorithms clusters largest intersection wordnet cell class 
cbc buckshot bisecting means white blood cell red blood cell brain cell cell blood cell cancer cell nerve cell embryo neuron receptor serum handwriting cancer cell thyroid body part hemoglobin red blood cell nerve cell urine gene chromosome embryo plasma heart valve ovary white blood cell lymph node heart colon cell blood brain cell central nervous system spinal cord blood cell cornea prostate brain spleen organ nervous system tissue marrow liver lung marrow kidney human body lining handwriting cancer cell vein body part polyp coronary artery thyroid membrane red blood cell plasma gene gland embryo nerve cell chromosome skin white blood cell ovary blood heart spinal cord cell colon blood vessel lymph node brain cell central nervous system blood cell cornea prostate organ brain spleen nervous system tissue marrow liver lung bone marrow kidney line police academy sphere influence sandbox downtown mountain camera kitchen sink voting booth drawer cell roof stadium classroom toilet kitchen bathroom wordnet class blood cell brain cell cancer cell cell cone egg nerve cell neuron red blood cell rod white blood cell clustering algorithm cbc automatically discovering concepts text 
handle large number elements large number output clusters large sparse feature space 
discovers clusters tight clusters called committees 
experiments showed cbc outperforms known hierarchical partitional hybrid clustering algorithms cluster quality 
example experiment cbc outperforms means 
comparing cbc clusters wordnet classes find errors cbc wordnet 
evaluating cluster quality difficult task 
new evaluation methodology editing distance output clusters classes extracted wordnet answer key 
authors wish reviewers helpful comments 
research partly supported natural sciences engineering research council canada gp scholarship 
cutting karger pedersen tukey 
scatter gather cluster approach browsing lat ge collections 
proceedings sigir 
pp 

copenhagen 
guha rastogi kyuseok 
rock robust clustering categorical 
proceedings icde 
pp 

sydney australia 
jain flynn 
data clustering review 
acm computing 
rousseeuw 
clustering means 
dodge 
ed 
statistical data analysis norm 
pp 

elsevier holland amsterdam 
karypis hah 
chameleon clustering algo thm dynamic modeling 
ieee computer special issue data analysis mining 
leacock 
building semantic concordances 
wordnet electronic lexical database edited 
pp 

mit ess 
leacock chodorow miller 
statistics 
relations sense identification 
computational linguistics 
lee pereira 
distributional ity models clustering rs 
neat est neighbors 
proceedings 
pp 

college pat md lin 
efficient broad coverage principle parser 
proceedings 
pp 

kyoto japan 
lin 
automatic retrieval clustering words 
proceedings acl 
pp 

montreal canada 
lin pantel 
induction semantic classes fi om natural language text 
proceedings sigkdd 
pp 

san francisco ca 
manning 
foundations statistical natural language processing 
mit press 
mcqueen 
classification analysis 
proceedings th berkeley symposium mathematics statistics probability 
miller 
wordnet online lexical database 
international journal lexicography 
pasca hat 
role wordnet open question answering 
proceedings naacl workshop wordnet lexical resources 
pp 

pittsburgh pa salton mcgill 
modern information retrieval 
mcgraw hill 
steinbach karypis 
compat ison document ng techniques 
technical report 
computer science engineering university minnesota 
