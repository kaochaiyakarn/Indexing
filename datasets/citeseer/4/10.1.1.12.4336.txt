probabilistic name address cleaning standardisation peter department computer science australian national university canberra act australia peter anu edu au tim churches centre epidemiology research new south wales department health locked mail bag north sydney nsw australia health nsw gov au justin xi zhu department computer science australian national university canberra act australia absence shared unique key ensemble nonunique personal attributes names addresses link data disparate sources 
data matching widely assembling data warehouses business mailing lists foundation longitudinal epidemiological health related studies 
unfortunately names addresses captured non standard varying formats usually degree spelling typographical errors 
important data transformed clean standardised format processed 
traditional approaches cleaning standardisation personal information domain speci rules need considerable con guration highly skilled users 
describe alternative approach probabilistic hidden markov models 
experiments various health related administrative data sets show compared rules approach probabilistic system cumbersome exible complex data produces accurate results 
keywords hidden markov models data cleaning data mining record linkage biomedical informatics epidemiology 

real world data collections contain noisy incomplete incorrectly formatted information 
data cleaning standardisation important rst steps data pre processing data stored data warehouses analysis 
cleaning standardisation personal names addresses especially important data integration sure misleading redundant information introduced duplicate records 
related data integration data linkage task linking records belonging entity patient customer business data sets 
called record linkage data linkage important domains longitudinal epidemiological studies census related statistics cleaning mailing lists fraud crime detection systems 
main task data cleaning standardisation conversion raw input data de ned consistent forms resolution inconsistencies way information represented encoded 
personal data captured stored typographical variations 
data may recorded captured various possibly obsolete formats data items may missing contain errors 
personal data useful valuable needs cleaned standardised de ned format 
example nicknames expanded full names various abbreviations converted standardised forms validated ocial postcode lists 
settings desirable able detect remove duplicate records data set order reduce costs business improve accuracy data analysis 
de duplication corresponds linking data set 
unique entity identi er key shared data sets linked process record linkage trivial 
case 
data analysis data mining projects data required analysis contained separate databases share common unique entity identi er 
cases probabilistic record linkage techniques need merge data :10.1.1.39.5567
typically range non unique personal data items names addresses dates date birth link records belonging entity patient customer 
data linkage improve data quality integrity allow reuse existing data sources new studies reduce costs orts data acquisition 
order maximise likelihood successful data linkage data cleaned standardised 
example comparing name component string doc peter miller variation name miller peter result non match properly cleaned standardised name elds title name surname title di er title doctor resulting partial match 
australasian data mining workshop copyright main app 
rd miller main peter rd app 
address name date geocode locality doc canberra canberra title surname year month day postcode territory 
unit type name 
peter miller main canberra act apartment road doctor example name address standardisation 
historical collections administrative health data transactional business databases nowadays contain tens hundreds millions records new data added rate millions records 
computing power increased tremendously decades large scale data cleaning linking resource intensive process 
relatively advances decade way data linkage undertaken 
researchers started explore area rst encouraging results machine learning techniques reported :10.1.1.37.5212:10.1.1.3.9195:10.1.1.31.109:10.1.1.11.7722
processes data standardisation data linkage various names di erent user communities 
statisticians speak record data linkage process referred data scrubbing pre processing data cleaning computer scientists database community called merge purge processing data integration etl extraction transformation loading commercial processing customer databases business mailing lists :10.1.1.37.5212:10.1.1.31.109
historically statistical computer science community developed techniques cross 
reports project aims developing new improved techniques data standardisation data linkage biomedical data sets 
focus improved performance allowing standardise link larger data sets improved quality techniques machine learning data mining 
prototype software febrl freely extensible biomedical record linkage currently development febrl written free open source python programming language published free open source license allowing researchers customise software particular needs 
hope febrl allow biomedical researchers standardise link data sets reduced cost due free availability software reduction human resources needed 
section introduce task data cleaning standardisation personal names addresses detail 
traditional approaches rules need customised user data sets linkage needs section alternative technique probabilistic hidden markov models hmms 
having write sophisticated complex rules adjusted various data sets see project web site datamining anu edu au linkage html hmm approach needs training records data set standardised 
section show training data created semi automatically ort skill required write rules section rst results showing probabilistic approach result highly accurate standardised data small training sets 
section presents overview related section gives outlook current directions project 

cleaning personal information aim data cleaning standardisation process transform raw input data records containing names addresses personal information date birth gender de ned consistent form shown 
personal information categorised broad classes names addresses dates birth categorical attributes sex birth identifying numbers tax le numbers 
deals rst classes 
addresses separated parts geocode part contains street postal address information locality part contains town suburb names postcode state country information 
seen table component split output elds containing basic piece information 
name geocode locality title number postcode gender guess name locality name type locality quali er alt quali er territory surname unit number country alt surname unit type property name institution name date institution type day number month type year table supported output elds 
assume raw input data records stored text les database tables input components text strings 
task allocate words numbers raw input appropriate output elds clean standardise values output elds 
approach data cleaning standardisation steps 
firstly input strings cleaned 
secondly split list words numbers characters tagged look tables mainly names addresses hard coded rules numbers hyphens commas 
tagged lists segmented output elds probabilistic hidden markov models 
discuss step detail sections 
australasian data mining workshop copyright cleaning cleaning step involves converting letters lower case followed various general corrections sub strings correction lists stored text les modi ed user 
correction lists pairs strings original replacement 
original string raw input sting replaced corresponding replacement string 
example variations known aka replaced string known 
various kinds brackets quoting characters replaced vertical bar facilitates tagging segmenting subsequent steps 
correction lists allow replacement string empty string case original string input removed 
example original string abbrev removed input record setting replacement string 
note name component di erent correction list geocode locality components corrections speci names addresses 
output cleaning step cleaned string ready tagged step 
tagging input component string cleaned step split white space boundaries list words numbers characters punctuation marks possible separators 
look tables hardcoded rules list elements assigned tags 
hard coded rules include example tagging element hyphen comma slash number alphanumeric word tags titles names surnames postcode locality names unit types countries assigned words listed look tables 
list supported tags table 
look tables loaded text les modi ed user 
word word sequence look table tagged replaced corresponding corrected entry look table 
possible word listed look table 
consequently assigned tag see example name word peter 
words look table match hard coded tagging rules assigned un unknown tag 
title words doctor doc md phd example assigned title word tag ti replaced standardised word dr 
look tables searched greedy matching algorithm searches longest tuple elements match entry look tables 
example tuple words macquarie fields matched entry look table locality name macquarie fields shorter entry macquarie look table 
output tagging step list elements words numbers separators corresponding list tags 
example assume raw input string name component doc 
peter paul miller converted cleaning step string doc peter paul miller 
assuming doc listed title look table corrected dr assigned ti tag 
assuming peter listed male name tag description name geocode locality lq locality quali er words lt ln locality town names lt tr territory state names lt cr country names lt institution type words lt institution names lt pa postal address type words lt pc lt ut unit type words lt wn names lt wt type words lt st saint names lt lt ti title words lt sn surnames lt gf female names lt gm male names lt pr name pre words lt sp name separators lt known bo baby similar lt sequences ne word lt surname born ii letter words initials hc hy hyphen hc hc comma hc hc sl slash hc hc numbers digits hc nu numbers hc hc digits alpha numeric words hc hc vb vertical bar hc hc various brackets ru lt lt un unknown lt lt table supported tags look tables lt hard coded rules hc 
surname look tables assigned tags gm sn 
word paul male name look table assigned gm 
assume name miller surname look table assigned tag sn 
peter assigned tags permutations tag sequences possible dr peter paul miller ti gm gm sn ti sn gm sn question tag sequences elements word list assigned appropriate output elds 
problem solved probabilistic hidden markov models segmentation step discussed 
segmenting having list elements words numbers characters separators corresponding tag lists task australasian data mining workshop copyright surname start title simple example hidden markov model name component 
assign elements appropriate output elds 
traditional approaches rules element tag ti corresponding word assigned title output eld 
probabilistic hidden markov models :10.1.1.131.2084
advantages hidden markov models robustness respect previously input sequences fact trained clerical sta requiring high level analysis programming skills create complex rules accommodate special cases data set 

markov models traditional data cleaning standardisation systems apply various rule approaches task parsing raw data 
example uses initial tokenisation phase followed re entrant rule parsing token re writing phase 
approach uses lexicon tokenisation tagging described uses probabilistic approach hidden markov models assign element cleaned tagged input list particular output eld 
hidden markov models hmms developed widely speech natural language processing :10.1.1.131.2084
powerful machine learning technique able handle new forms data robust fashion 
computationally ecient develop evaluate 
hmms name address standardisation :10.1.1.37.3740:10.1.1.11.7722
hmm probabilistic nite state machine set states transition edges states nite dictionary discrete observation output symbols 
edge associated transition probability state emits observation symbols dictionary certain probability distribution 
special states start state 
start state hmm generates sequence observation symbols ok making transitions state state reached 
observation symbol generated state state probability distribution observation symbols 
output sequence generated various paths hmm di erent probabilities 
observation sequence interested probable path hmm generated sequence 
viterbi algorithm ecient way compute probable path observation sequence :10.1.1.131.2084
state start title middle sur state name name name start title name middle name surname state obser 
start title middle sur symbol name name name ti gm gf sn un table example name hmm transition observation probabilities 
distribution transition observation probabilities learned training data 
training record example path observation sequence 
dictionary output symbols created training data states hmm normally xed de ned training 
training data cover possible combinations states observations testing application hmm unseen unknown data encountered 
able deal cases smoothing techniques need applied enable unseen data handled eciently 
techniques laplace absolute discounting basically assign small observation probabilities unseen observations symbols states 
states distinct words training expected encounter unknown symbols frequently 
smoothing techniques re ect fact assigning unseen symbols states higher relative probability 
shows simple hmm example name component states 
start states virtual states stored hmm symbols emitted states 
start state list initial state probabilities probabilities give likelihood sequence starting certain state 
example name starts likelihood followed conditional probability surname probability 
original words numbers elements input records directly tag sequences discussed section hmm observation symbols order derived hmms general allow hmms trained data set similar distinct data sets little loss performance 
tags limits size observation dictionary 
hmm trained sequences tags tag input element generated tagging step input viterbi algorithm australasian data mining workshop copyright returns path state sequence tag sequence hmm plus corresponding probability 
path highest probability taken corresponding state sequence assign elements input appropriate output elds 
example assuming name example input name string doc 
peter paul miller cleaned tagged explained section word list tag sequences dr peter paul miller ti gm gm sn ti sn gm sn tag sequences viterbi algorithm name hmm transition observation probabilities listed table rst tag sequence ti gm gm sn assigned path hmm corresponding observation symbols brackets start title ti gm gm surname sn resulting probability path transition probability state start state title probability symbol ti observed state title transition probability title state 
probable path second sequence ti sn gm sn start title ti sn gm surname sn result probability rst tag sequence expected 
hmm states elements input word list associated corresponding output elds 
example dr title peter name paul middle name alternative name miller surname 
hidden markov model training data cleaning standardisation system hmm names addresses geocode locality corresponding states listed table table 
output elds contain word hmms appropriately states elements assigned corresponding output eld 
transition observation probabilities hmms trained collections records annotated manually taken similar data set data standardisation 
training records hmm learns characteristics data set 
state description title state baby state baby son daughter state known andor state name state name state name hyphen state name opening bracket state name closing bracket state alternative name state alternative name state coma state comma sname surname state sname surname state surname hyphen state surname opening bracket state surname closing bracket state alternative surname state alternative surname state pref name pre state pref name pre state state elements thrown away table name hidden markov model states 
requiring highly trained programming sta maintain large number rules cover kinds special cases exceptions modi ed new data set data train hmm created clerical sta couple days new data source 
furthermore training process accelerated bootstrapping training data sets derived similar data sources 
training data consists sequences tag hmm state pairs 
sequence training record hmm hmm learns characteristics data set training examples training 
maximum likelihood estimates matrix transition observation probabilities hmm derived accumulating frequency counts type transition output symbol tag training records 
frequency important records training data set reasonably representative data set standardised 
hmms quite robust unseen data overly troubled records training data set represent unbiased sample records target data 
example possible add training records represent unusual records degrading performance hmms typical records 
hmms degrade gracefully perform records previously structure 
simple set training examples name component hmm look gf sn sname un sn sname gf gm un sname gf gm sname gf un sn sname line example corresponds training record contains sequence corresponds australasian data mining workshop copyright state description number state name state name state quali er state type state unit number state unit type state property name state property name state institution name state institution name state institution type state postal address number state postal address type state state hyphen sla state slash coma state comma opening bracket state closing bracket state loc locality name state loc locality name state locality quali er state pc postcode state ter territory name state ter territory name state cntr country name state cntr country name state state elements thrown away table address hidden markov model states 
ular path various hidden unobserved states hmm corresponding observation symbols tags 
new data set hmms names addresses created main steps 
small number records original data set selected randomly tagged described section 
output step tag sequences input record name address component 
training records edited manually user choosing correct tag sequence created input record adding appropriate hmm state tags selected tag sequence 
resulting small number training records examples second step train rst rough hmm third step create larger set training records randomly selected original data set 
training records tag sequence includes hmm states 
user go training records correct tags hmm states wrong 
le containing training records original input commented user easily check training record correct needs modi ed 
examples address training records show original input string cleaned input string tagging routine tagged word list concatenated back string corresponding tag sequence taken training example 
note original input tagged input commented python comment character hash 
richard st nsw richard street new south wales nu un wt ln loc pc pc tr ter miller pl manley nsw miller place new south wales nu sl sla nu un wt ln loc pc pc tr ter bootstrapping approach single user create validate days training records able standardise real world data sets high accuracy shown section 

standardisation results developed evaluated febrl system routinely collected health data sets contain personal identifying details 
access data sets purpose project approved australian national university human research ethics committee relevant data nsw department health 
data sets project held secure computing facilities australian national university nsw department health head 
access data sets project strictly limited investigators 
investigators system administrators computing facilities required sign con dentiality agreement responsibilities legislative protection associated criminal penalties misuse orded data 
order minimise invasion privacy necessarily associated identi ed data medical health status details personal details apart name data sets date birth data sets sex residential address removed data sets project 
febrl software development multi platform capable able tag clean segment names address bit unix bit windows platforms problems modi cations 
address standardisation performance febrl system typical australian address data evaluated data sets 
rst subset approximately addresses taken uncorrected electronic copies nsw death certi cates completed medical practitioners years 
information systems captured data underwent number major changes period 
majority data entered handwritten forms 
second data set random sample records residential addresses drawn nsw statistics collection years 
collection contains abstracts admission public private sector acute care hospital nsw 
data extracted range computerised hospital information systems smaller proportion entered forms 
australasian data mining workshop copyright number tests carried 
initial bootstrap hidden markov model hmm trained random death certi cate dc records form larger training set randomly chosen dc records 
hmm derived second training set standardise randomly chosen dc records records unusual patterns observation symbols frequency examined corrected added training set results produced hmm incorrect 
new hmm derived augmented training set process repeated times resulting addition approximately extra training records bringing total number training records 
hmm emerged process designated hmm standardise randomly chosen dc test records accuracy standardisation assessed 
laplace smoothing subsequent tests 

hmm standardise randomly chosen statistics collection isc records accuracy assessed 
words hmm trained data source dc standardise addresses di erent data source isc retraining hmm 

additional randomly chosen address training records derived data collection mdc added training records described larger training set train hmm 
hmm re standardise sets randomly chosen test records described steps results evaluated 

approximately training records archetypes records wrongly standardised preceding tests added training set produce hmm 
hmm re standardise dc isc test sets 
hmm considered tted model particular records test sets practice researchers tting maximise standardisation accuracy speci data sets particular study 

way comparison record test data sets standardised commercial software conjunction rule set developed re ned investigators tc kl course years isc dc address data 
tests records judged accurately standardised elements input address string exception punctuation allocated correct output eld values output elds correctly transformed canonical form required 
record judged incorrectly standardised element input string allocated output eld element allocated hmm method test data set hmm hmm hmm auto records stan death certi cates statistics collection table proportion correctly standardised address records numbers percentages 
wrong output eld 
due resource constraints investigators blinded process standardise records 
results shown table 
results indicate hmm approach described produces standardisation accuracies comparable produced established rulebased system data set rules developed superior results di erent data set 
words hmm approach appears sensitive particular characteristics data source developed rule system 
addition results indicate hmms trained maximum likelihood estimates quite robust respect source training data performance improved addition small number unrepresentative training records represent dicult cases 
records accurately standardised hmms average cent data elements input record allocated correct output elds words incorrectly standardised records considerable utility 
test records elements wrongly assigned foreign addresses speaking countries 
performance respect similar 
addition small number deterministic postprocessing rules expected yield higher accuracies versions febrl system 
name standardisation accuracy measurements names conducted subset nsw data collection mdc 
subset contained records personal information medical details women birth new south wales australia year period data entered hand written forms data years extracted directly variety computerised information systems 
random subset records sample non empty name component selected split test sets containing records 
fold cross validation study performed folds having training set records remaining records test set 
training records tagged person hours bootstrapping method explained section 
hidden markov models trained smoothing laplace absolute discount smoothing respectively 
australasian data mining workshop copyright compared variation format residential addresses names mdc homogeneous 
randomly selected names simple form surname form surname surname surname 
trained hmms non zero transition probabilities hmm states linked non zero transitions active hmm part 
table shows accuracy results hmm name standardisation algorithm implemented febrl prototype software 
simple form names rules approach accurate achieving better 
variations hmm approach higher names wrongly standardised 
di erences ect smoothing method report results unsmoothed hmm 
cases errors standardisation occurred unsmoothed smoothed hmms maximum records standardised di erently records 
min max average stddev hmm rules table name standardisation fold cross validation numbers percentages 
especially problematic names names surnames 
hmms misclassi ed middle name rst surname second name 
due large number names simple form surname results high transition probability rst name state rst surname state sname 
second name assigned rst surname real surname second surname 
problems surnames listed name look table tagged name tag gf gm case hmms wrongly assigned second name name surname output eld 
clear results additional rules usefully added rules name standardisation rule post processing hmm segmentation process 
simple example rules hmm approaches surname name re assign second name word surname assuming names generally written surnames opposite way 

related terms data cleaning data cleansing data standardisation data scrubbing data pre processing etl extraction transformation loading synonymously refer general tasks transforming source data derived operational transactional information systems clean consistent sets records suitable loading databases data warehouses linking data sets 
data standardised central task data linkage identify records source data sets represent realworld entity 
computer science literature process called object identity merge purge problem 
fuzzy techniques methods information retrieval address data linkage problem varying degrees success 
approach represent text records document vectors compute cosine distance vectors 
possibility sql language allows approximate joins cluster building similar records decision functions decide records represent entity 
methods include statistical outlier identi cation pattern matching clustering association rules approaches 
sorting data sets group similar records comparing records sliding window technique similar blocking applied traditional record linkage approaches 
accuracy linkage improved having smaller window sizes performing passes data di erent compound keys having large window size pass 
corresponds applying blocking strategies record linkage process 
machine learning techniques applied data linkage years 
authors describe hybrid system rst step uses unsupervised clustering small sample data set create data classi er second step classify records links non links 
authors directly address problem data cleaning standardisation approximate string comparison algorithms able deal variations strings 
clustering large high dimensional data sets applications matching discussed 
authors propose step clustering algorithm rst step uses cheap approximate distance metrics form overlapping canopies second step clustered traditional approaches 
approach learns eld speci string edit distance weights binary classi er support vector machines svm nd duplicate records text databases 
commercial software data cleaning standardisation available various vendors see project web page non exhaustive list data cleaning data integration software 
products proprietary technologies rules 
automatch suite data cleaning linkage software example improved simple far simple regular expression rules initial lexicon tokenisation phase followed re entrant rule parsing token re writing phase 
probabilistic approaches hand allow creation training data time consuming fashion 
hidden markov models traditionally applied areas signal speech processing text recognition image processing applied tasks information extraction extracting names titles keywords publication abstracts segmentation addresses bibliographic records input string containing address segmented de ned output elds :10.1.1.131.2084
approach discussed di ers address words directly tags hmms results system handle unseen data robustly computationally ecient due smaller dictionaries output symbols 
australasian data mining workshop copyright 
outlook probabilistic approach task cleaning personal names addresses hidden markov models 
process important rst step data loaded databases data warehouses necessary data linked integrated data 
shown probabilistic approach easier cumbersome compared traditional rule approach result higher accuracy 
methods part prototype software system published open source license downloaded project web page see datamining anu edu au linkage html 
currently developing new methods data linkage probabilistic approach developed fellegi sunter extended 
main foci improve linkage performance applying techniques high performance parallel computing improving linkage quality exploring machine learning techniques clustering predictive modelling 
aim provide researchers users biomedical related areas ability clean standardise link larger data sets reduced costs due reduction human resources needed free availability software 
acknowledgments project equally funded australian national university anu nsw department health anu industry collaboration scheme 
authors everybody supported project helped happen ole nielsen markus stephen roberts david 
specially grateful kim lim centre epidemiology research nsw department health input design prototype software helping test debug 

bell sethi matching records national medical patient index communications acm vol 
september 
borkar deshmukh sarawagi automatic segmentation text structured records proceedings acm sigmod international conference management data santa barbara california 
cohen whirl approach integration overview proceedings aaai workshop ai information integration 
aaai press 
verykios elmagarmid tailor record linkage toolbox proceedings icde san jose usa 
fellegi sunter theory record linkage 
journal american statistical society 
galhardas florescu shasha simon extensible framework data cleaning technical report inria 
gill methods automatic record matching linking national statistics national statistics methodology series london 
han kamber data mining concepts techniques morgan kaufmann 
hernandez stolfo merge purge problem large databases proceedings sigmod conference san jose 
monitoring health care national administrative data collections phd thesis australian national university canberra may 
randell assessment name matching algorithms technical report department computing science university newcastle tyne uk 
lutz python pocket second edition reilly associates january 
maletic marcus data cleansing integrity analysis proceedings conference information quality iq boston october 
automatch user manuals technologies maine 
mccallum nigam ungar ecient clustering high dimensional data sets application matching knowledge discovery data mining 
nahm bilenko mooney approaches handling noisy variation text mining proceedings icml workshop text learning pp sydney australia july 
newcombe kennedy record linkage making maximum discriminating power identifying information communications acm vol 

philips double search algorithm user journal vol 
june 
porter winkler approximate string comparison ect advanced record linkage system research report rr bureau census 
rabiner tutorial hidden markov models selected applications speech recognition proceedings ieee vol :10.1.1.131.2084
february 
rahm data cleaning problems current approaches ieee bulletin technical committee data engineering vol 
december 
australasian data mining workshop copyright seymore 
mccallum rosenfeld learning hidden markov model structure information extraction proceedings aaai workshop machine learning information extraction 
verykios elmagarmid houstis automating approximate record matching process information sciences vol 
july 
verykios elmagarmid dalal completeness accuracy record matching process proceedings mit conference information quality boston ma october 
winkler state record linkage current research problems census research report rr 
winkler quality large databases research report rr bureau census 
frequency dependent probability measures record linkage research report rr statistical research division bureau census july 
program extracting probable matches large file record linkage research report rr statistical research division bureau census march 
australasian data mining workshop copyright 
