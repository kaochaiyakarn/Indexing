ijcai workshop planning uncertainty incomplete information pro pp 
seattle washington august 
solving factored pomdps linear value functions carlos guestrin computer science dept stanford university guestrin cs stanford edu daphne koller computer science dept stanford university koller cs stanford edu ronald parr computer science dept duke university parr cs duke edu partially observable markov decision processes pomdps provide coherent mathematical framework planning uncertainty state system fully observed 
problem finding exact pomdp solution intractable 
computing solution requires manipulation piecewise linear convex value function specifies value possible belief state 
value function represented set vectors dimension equal size state space 
nontrivial problems vectors large representation feasible preventing exact pomdp algorithms 
propose approximation scheme vector represented linear combination basis functions provide compact approximation value function 
show representation exploited allow efficient computations approximate value policy iteration algorithms context factored pomdps transition model specified dynamic bayesian network 
years partially observable markov decision processes pomdps basic semantics optimal planning decision theoretic agents stochastic environments state system fully observed 
pomdp framework system modeled set states evolve stochastically 
key problem representation virtually real life domain state space quite large 
large mdps significant internal structure modeled compactly structure exploited representation 
factored pomdps boutilier poole approach representing large structured pomdps compactly 
framework state implicitly described assignment set state variables 
dynamic bayesian network dbn dean kanazawa allow compact representation transition model exploiting fact transition variable depends small number variables 
furthermore momentary rewards decomposed sum rewards related individual variables small clusters variables 
observations decomposed observation variables giving evidence small subset variables 
large pomdp represented compactly factored model finding optimal policy intractable exact pomdp solutions exp hard littman cases undecidable madani algorithms require manipulation piecewise linear value function piece representation linear number states exponential number state variables 
approach approximate solution approximate value function compact representation 
represent piece value function linear combination basis functions basis function restricted domain depends small number state variables 
allows address cost representing value function 
furthermore algorithm exploits structure factored pomdp value function perform value policy iteration efficiently compact representation 
partially observable markov decision processes section briefly traditional approach solving pomdps details littman partially observable markov decision process pomdp defined tuple finite set jsj states finite set joj possible observations set jaj actions reward function 
ir represents reward obtained agent state action set markovian transition models action represents probability going state state action corresponding set observation models gives probability making observation action transitioning state assuming pomdp infinite horizon rewards discounted exponentially discount factor 
agent directly observe state system possible maintain probability distribution states 
denote belief state jsj vector probability system state agent takes action observation possible update belief state simple application bayes rule 
value iteration incremental pruning belief state summarizes information previous observations sufficient statistic 
possible recast pomdp fully observable continuous mdp state jsj dimensions represents possible belief states 
continuous state mdp solved value iteration algorithm relies successive applications dynamic programming dp update rule max smallwood sondik proved optimal value function horizon piecewise linear convex 
precisely represented maximum linear functions function corresponding value particular step policy 
value function represented finite set jsj dimensional vectors real numbers value belief state max hb 
standard dot product hb 

dp step preserves piecewise linearity convexity value function set vectors represent step value function generate new set vectors represent step value function 
discussed step value function maximum set linear functions step policy 
number policies enormous view policy branching tree branch possible observation step branch possible action agent take response action 
total number possible strategies jaj joj induces vector linear function step value function 
fortunately vectors redundant strategies represent suboptimal 
words belief state vector larger set hb hb vectors called dominated vectors affect value function pruned set vectors representing value function affecting 
incremental pruning algorithm cassandra cassandra key insight pruning operation performed incrementally alleviating need generate large set vectors cases reducing size linear program generated 
incremental pruning extensions shown empirically faster alternative algorithms value iteration pomdps 
provide formal description incremental pruning algorithm extend case factored pomdps section 
key step value iteration algorithm dp step generate step value function step value function 
perform step back projecting set vectors step value function obtain set vectors step value function 
operation convenient divide dp backup eq 
steps max joj value functions piecewise linear convex 
value function represented unique minimal set vectors 
denote sets represent set vectors step value function 
define backprojection vector note vector normally constructed element time iterating joj generate new set vectors generate vectors need definition 
cross sum sets vectors defined new set vectors generated generate vectors actual value function maximum vectors 
discussed resulting set vectors contains redundancies due dominated vectors 
represent value function compactly pruning dominated vectors leaving ones participate defining value function 
define operation prune prune fg prune pointwise dominated vectors repeat vector solve dominated remove find best empty return 
algorithm performing pruning operation 
return true return false 
algorithm checking pointwise domination 
shown cassandra perform operation incrementally due identity prune joj prune prune joj algorithm perform prune operation due white white summarized 
ways prune vectors set 
simplest case pair vectors larger states 
smaller pruned function 
case occurs vector dominated single vector dominated set vectors call set dominance 
case write linear program test general type dominance shown 
linear program seeks find belief state difference value vector gives belief state hb value set max hb maximal 
distance non positive vector dominated set discarded 
find best vector belief state performed best function add minimal set 
best function uses lexicographic operator lex break ties littman computed value function derive optimal policy implicitly represented value function arg max policy iteration alternative approach value iteration search space policies 
fully observable mdps policy iteration best max maxg hb max max lex max max hb return max algorithm finding vector gives maximal value belief state solve linear program variables bs maximize subject hb 
return dominated return linear program checking set vectors dominates vector successful converges faster value iteration 
sondik suggested policy iteration pomdps proposing policy represented finite state machine 
hansen proposed practical implementable version policy iteration pomdps proved converges optimal policy 
showed empirically mdps policy iteration converges faster tha value iteration 
section review hansen policy iteration algorithm 
hansen algorithm represents policies finite state machines 
algorithm iterates policies starting initial finite state machine 
iteration composed steps 
value determination compute value acting 

policy improvement computed value function update finite state machine 
finite state machine 
tuple 
machine state observation represented action associate machine state machine state observing key step hansen algorithm value determination step 
finite state machine 
compute value acting policy represents 
note particular machine state policy fully determined 
value function associated finite state machine starting machine state linear value function 
view finite state machine entirety representing choice policies choice machine state 
optimal value function associated machine maximum set vectors machine state insight perform value determination machine state solving set linear equations unknowns coefficients linear functions associated different machine states system contains jsj dimensional vector machine state th component expected discounted value starting finite state controller machine state environment state linear system contains jmj 
jsj equations unknowns jsj coefficients vectors jmj machine states 
linear system solved exactly small problems 
policy improvement step high level similar analogous step mdps 
construct policy greedy relative current value function compute new value function 
pomdps process follows 
observation select action gives highest payoff assuming value function represents long term payoff step 
operation executed performing dp step giving value function step lookahead 
value function represented set vectors 
construct policy optimal relative step lookahead updating finite state machine 
formally take vectors associated current finite state machine 
define set perform dp step described obtain minimal set vectors set vectors forms basis definition new finite state machine 
note union vector associated particular action 
furthermore defined cross sum sets vectors observation 
associated set vectors observation constituent vectors derived backprojection linear value function associated machine state 
denote particular machine state 
intuitively represents value function derived policy take action seeing observation go machine state behave 

define 

updating vectors vector perform update 

successor links state existing machine state 
simply ignore 
add machine state 
dominates value function vector associated existing machine state 
eliminate transitions point point 
prune 
machine state corresponding vector long reachable machine state corresponding vector factored pomdps linear value functions exact algorithms previous sections find optimal policies small problems restricted problems tens states due computational complexity 
attempt solve complex problems boutilier poole proposed framework factored pomdps represent large problems compactly 
furthermore propose algorithm exploiting representation improve efficiency exact computation value function 
subsequently hansen feng extended algorithm implementation solve larger problems 
approaches assumption vectors composing value function represented tree structure assigns value individual components vector 
vectors composing value function structure amenable representation approaches give exponential reduction amount space needed represent vector 
vectors composing value function amenable tree structured representation 
discussed koller parr exact value functions simple factored systems grow exponentially size 
researchers proposed linear approximation approximate value function represented linear combination basis function 
approach proposed variety mdps tsitsiklis van roy applied factored mdps koller parr guestrin show small set basis functions provide high quality approximation high dimensional value function 
apply idea pomdps approximation individual value function vectors comprise pomdp value function 
section show value policy iteration algorithms factored pomdps exploit compact representation efficient computation 
representation factored pomdps factored pomdp set states described set random variables fx xn takes values finite domain dom 
state defines value dom variable general pomdp framework action specifies transition model observation model 
case factored pomdps represented dynamic bayesian network dbn dean kanazawa denote variable current time variable step 
transition graph associated action layer directed acyclic graph nodes fx xn denote parents graph parents 
simplicity exposition assume parents arcs dbn variables consecutive time slices 
assumption relaxed algorithm somewhat complex 
node associated conditional probability distribution cpd parents 
transition probability defined value variables parents 
transition dynamics pomdp defined separate dbn model hg action represent conditional probability distributions associated action parents 
represent observation space 
observations described set observation variables fo associate set observation variables action set observable variables different different actions 
simplicity exposition assumptions 
assume parents observations depend state reached action taken 
second assume observation variables leaves represented value variables parents 
see eventually need assume set parents parents large 
words action focuses attention agent certain part system 
example factory maintenance agent fixing particular machine observe state machine fixing neighboring machines 
assumption reasonable settings 
note need common assumption koller parr action directly influence small subset variables system 
factory agent take single action turns machines factory 
need provide compact representation reward function 
assume reward function factored additively set localized reward functions depends small set variables 
definition function restricted domain dom 
ir 
restricted shorthand part instantiation corresponds variables set functions restricted variable cluster fx xn reward function state defined ir 
factored linear value functions discussed think vector representation value function value function 
example policy iteration vector associated machine state represents expected discounted reward obtained state policy finite state machine starting algorithm compute approximations piecewise linear value function maintaining approximate representations vector 
fully observable mdps popular choice approximate value functions fully observable mdps uses linear regression 
define space allowable value functions ir jsj set basis functions fh linear value function function written coefficients 
define linear subspace ir jsj spanned basis functions useful define jsj matrix columns basis functions viewed vectors 
approximate value function represented aw 
idea linear value functions dynamic programming proposed initially bellman explored tsitsiklis van roy koller parr guestrin basic idea follows solution algorithms value iteration policy iteration value functions algorithm takes step results value function outside space project result back space finding value function space close case factored mdps argued problems approximated linear combination functions refers small number variables 
precisely value function said factored linear value function linear value function basis restricted subset variables factory example basis function binary variable representing state machine factory basis function value machine operational 
basis functions pairs machines directly correlated output input 
shown fully observable mdp case koller parr guestrin factored value functions provide key doing efficient computations exponential sized state sets factored mdps 
key insight restricted domain functions including basis functions allow certain basic operations implemented efficiently 
context pomdps vector represented linear combination basis function representation exploited computational benefits 
example compute value belief state vector compactly hb 
xc refer settings variables consistent represent marginal belief state variables compute value belief state exactly summing full exponentially large belief state 
factored linear value functions admit efficient implementation important operations 
find maximum factored linear function exponentially large state space precisely assume function linear combination functions domain restricted goal find max find state maximized 
observed koller parr maximize function dynamic programming cost networks dechter see guestrin description algorithm 
second key computational step projection vector linear subspace induced set basis functions 
form projection depends choice norm 
formally definition projection operator mapping ir jsj said projection norm 
aw arg minw kaw vk 
norms previously weighted koller parr koller parr max norm guestrin purposes possible 
rest projection better theoretical motivation experimental performance guestrin projection known task finding chebyshev solution overdetermined linear system equations cheney problem defined finding arg min bk denote projection operation focus cases cw form subset similarly factored linear function 
words want approximate factored function linear combination particular basis functions small domain 
discussed guestrin solution eq 
general performed linear program state space 
importantly show linear program reformulated alternative set variables factored representation functions 
max norm projection performed effectively having resort explicit enumeration entire exponentially sized state space 
see guestrin detailed algorithm 
efficient algorithms factored pomdps section show basic operations incremental pruning algorithm policy iteration pomdps executed efficiently factored pomdps factored linear approximate value function 
main operations deal dp step particular computing backprojections testing dominance value determination 
steps necessary algorithms policy iteration algorithm 
remaining operations algorithms easily implemented way grow size state space 
find efficient algorithms main operations efficient implementation incremental pruning policy iteration factored pomdps 
factored dp step key step algorithms dp step takes step value function generates associated step value function 
cases basic operation backprojection vector eq 

factored backprojection observed koller parr context mdps backprojection value function domain restricted set function domain restricted backprojection parents transition model 
formally abuse notation define backprojection set parents transition graph parents 
show jo oa settings right hand side conditioning bar represent assignment variables specified note conditioning term necessary parents guarantee settings summation consistent value vector resulting composed sum restricted domain functions having domain restricted backprojection basis functions union backprojection observation variables parents 
transition model sparse variables small number parents basis functions observation sets large component value functions compactly represented manipulated 
projection vectors note function generated backprojection vectors need space spanned basis functions 
project back space 
interested finding set weights arg minw kaw note showed section linear combination restricted domain functions 
discussed section optimization performed efficiently closed form solving linear program 
generate vectors applying applying sure space spanned basis functions 
define non minimal set vectors approximation testing dominance key operation incremental pruning eliminate dominated vectors set vectors obtain minimal set 
discussed section types dominance 
simplest pointwise dominance occurs pair vectors smaller state 
second general set dominance occurs vector dominated single vector set vectors 
section show test types dominance factored pomdps explicitly enumerating exponentially large state space 
pointwise dominance pointwise dominance testing pair vectors algorithm checks state pomdp 
explicit case illustrated perform test state 
factored pomdps procedure computational cost exponential number state variables making intractable 
fortunately vectors represented linear combination basis functions reformulate question test max value variables assignment formulation equivalent pointwise dominance question maximum negative states 
easy verify test condition efficiently factored linear value functions efficient algorithm maximization state space discussed section 
precisely apply algorithm 
set dominance second type dominance necessary pruning dominated vectors set dominance 
interested testing vector dominated set vectors 
described section test performed explicit state space case solving linear program shown linear program seeks find belief state difference value vector gives belief state hb value set max hb maximal 
distance nonpositive vector dominated set discarded 
problem explicit formulation linear program contains variables jsj represent belief state number states exponential number state variables 
linear program requires exponentially variables 
show section factored representation vectors allows generate compact linear program test dominance 
note belief variables necessary represent constraint hb section showed need explicit representation belief state compute dot products 
need marginals variables domains basis functions compute dot product exactly 
shown eq 
repeat hb domain basis function restricted subset variables simplification hints linear program need variable belief state concisely needs maintain factored representation belief state 
consider reformulating linear program set domination follows variables fb maximize subject fb represents legal belief state 
unfortunately straightforward formulation adequate easy ensure variables marginals associated single coherent probability distribution assume example state space defined variables clusters fa bg fb cg fc dg fd ag 
distributions clusters guarantee derived single joint distribution easy check marginals locally consistent example easily construct linear equations represent constraint local consistency general imply global consistency easy construct examples marginals locally consistent single joint distribution consistent 
address problem notion decomposable models lauritzen spiegelhalter models local consistency imply global consistency 
construct graph nodes variables distribution edge nodes variables appear cluster 
graph clusters shown dashed edge 
triangulate graph add edges loops length greater edge cuts loop 
example add aaa model probability distribution 
dashed edge construct set cliques maximal fully connected subgraphs graph 
example cliques consider marginal distributions cliques fb fb straightforward verify sets numbers distributions agree marginals shared variables consistent joint distribution generally original clusters subset clique graph 
denote variables clique denote assignment variables 
define clique tree nodes cliques graph edges selected satisfy running intersection property cliques clique tree variable clique path tree 
separators intersection clusters directly connected clique tree edge clique tree 
assignment separator variables denoted dom represent assignments values consistent assignment test set marginal distributions fb represents coherent probability distribution testing dom js dom js construction define factored linear program precisely solves set domination problem 
simply variables lp shown 
note inequality constraint factored representation hb belief state represented compactly fb check dominance belief state closed form considering belief states fb yielding exponential saving size linear program 
techniques provided far allow dp step exploit structure factored pomdp order speed computation 
allow implement approximate version value iteration factored pomdps 
solve linear program variables maximize subject lp infeasible return dominated return fb factored linear program checking set vectors dominates vector factored value determination provide factored algorithm policy iteration need provide efficient algorithm additional task task value determination approximating value policy represented finite state machine 
explicit case machine state associated vector represents value state policy described finite state machine starting machine state explicit case compute values exactly solving set linear equations shown eq 

number states exponential number state variables making exact computation values intractable 
resort approximation scheme factored linear value functions 
approximation framework vector represented weights 
jmj vectors machine state 
denoted weight vector associated machine state gives basis function formalize approximation problem want find weights vectors simultaneously value determination equations eq 
satisfied possible terms max norm error 
words trying find approximate set value functions machine state minimize difference approximate value functions backprojection 
want close aw eq 
problem written factored pomdps min jmj max note appear value function lefthand term backprojection right hand term 
easy manipulate expression form eq 
value determination algorithm fully observable mdps guestrin discussed section optimization performed efficiently solving factored linear program 
exploit structure factored pomdps find efficiently approximations value policy represented finite state machine 
policy improvement step implemented efficiently unchanged techniques described testing dominance 
perform approximate policy iteration efficiently factored pomdps 
discussion new algorithms performing approximate value policy iteration pomdps 
algorithms approximate vector composes piecewise linear convex value functions linear combination basis functions dealing problem exponentially large representations vectors 
furthermore representation allows operations approximate value policy iteration performed efficiently factored pomdps 
show factored structure exploited approximate version incremental pruning algorithm cassandra policy iteration pomdps algorithm hansen interesting step deal directly simultaneous factored observations observation variables observed time step 
bellman bellman 
polynomial approximation new computational technique dynamic programming 
math 
comp 

dynamic programming 
academic press new york 
boutilier poole boutilier poole 
computing optimal policies partially observable decision processes compact representations 
proceedings thirteenth national conference artificial intelligence aaai portland oregon august 
aaai press 
cassandra cassandra littman zhang 
incremental simple fast exact method partially observable markov decision processes 
uncertainty artificial intelligence proceedings thirteenth conference pages providence rhode island august 
morgan kaufmann 
cheney cheney 
approximation theory 
chelsea publishing new york ny nd edition 
dean kanazawa thomas dean kanazawa 
model reasoning persistence causation 
computational intelligence 
dechter dechter 
bucket elimination unifying framework reasoning 
artificial intelligence 
guestrin carlos guestrin daphne koller ronald parr 
max norm projections factored mdps 
proceedings seventeenth international joint conference artificial intelligence ijcai seattle washington august 
morgan kaufmann 
hansen feng eric hansen feng 
dynamic programming pomdps factored state representation 
fifth international conference artificial intelligence planning scheduling breckenridge colorado april 
hansen eric hansen 
finite memory control partially observable systems 
phd thesis university massachusetts amherst amherst massachusetts 
koller parr koller parr 
computing factored value functions policies structured mdps 
proceedings sixteenth international joint conference artificial intelligence ijcai 
morgan kaufmann 
koller parr koller parr 
policy iteration factored mdps 
proceedings sixteenth conference uncertainty artificial intelligence uai stanford california june 
morgan kaufmann 
lauritzen spiegelhalter steffen lauritzen david spiegelhalter 
local computations probabilities graphical structures application expert systems 
journal royal statistical society 
littman michael littman 
algorithms sequential decision making 
phd thesis department computer science brown university providence rhode island 
madani madani condon hanks 
undecidability probabilistic planning infinite horizon partially observable markov decision process problems 
proceedings sixteenth national conference artificial intelligence aaai florida july 
aaai press 
smallwood sondik smallwood sondik 
optimal control partially observable markov processes finite horizon 
operations research 
sondik sondik 
optimal control partially observable markov decision processes infinite horizon discounted costs 
operations research 
tsitsiklis van roy tsitsiklis van roy 
feature methods large scale dynamic programming 
machine learning 
white white 
survey solution techniques partially observed markov decision processes 
annals operations research 
