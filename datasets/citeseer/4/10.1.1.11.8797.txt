technical report idsia january gentle universal algorithmic agent aixi marcus hutter idsia ch lugano switzerland marcus idsia ch www idsia ch marcus keywords artificial intelligence algorithmic probability sequential decision theory rational agents value function solomono induction kolmogorov complexity reinforcement learning universal sequence prediction strategic games function minimization supervised learning 
decision theory formally solves problem rational agents uncertain worlds true environmental prior probability distribution known 
solomono theory universal induction formally solves problem sequence prediction unknown prior distribution 
combine ideas get parameter free theory universal artificial intelligence 
give strong arguments resulting aixi model intelligent unbiased agent possible 
outline number problem classes including sequence prediction strategic games function minimization reinforcement supervised learning aixi model formally solve 
major drawback aixi model uncomputable 
overcome problem construct modified algorithm ectively intelligent time space bounded agent 
computation time order discussed topics formal definitions intelligence order relations horizon problem relations aixi theory ai approaches 
marcus hutter technical report idsia contents agents known probabilistic environments cybernetic agent model 
strings 
ai model known deterministic environment 
ai model known prior probability 
probability distributions 
explicit form ai model 
environments 
constants limits 
sequential decision theory 
universal sequence prediction 
algorithmic information theory 
uncertainty probabilities 
algorithmic probability universal induction 
loss bounds pareto optimality 
universal algorithmic agent aixi universal ai model 
optimality aixi 
value bounds separability concepts 
pareto optimality ai 
choice horizon 
outlook 

important environmental classes sequence prediction sp 
strategic games sg 
function minimization fm 
supervised learning examples ex 
aspects intelligence 
time bounded aixi model time limited probability distributions 
idea best vote algorithm 
extended chronological programs 
valid approximations 
ective intelligence order relation 
universal algorithmic agent aixi universal time bounded aixi agent 
limitations open questions 
remarks 
discussion general remarks 
outlook open questions 
big questions 

annotated bibliography index chapter gives mathematical theory intelligence 
aixi model parameter free optimal reinforcement learning agent embedded arbitrary unknown environment 
science artificial intelligence ai may defined construction intelligent systems analysis 
natural definition systems input output stream 
intelligence complicated 
faces creativity solving problems pattern recognition classification learning induction deduction building analogies optimization surviving environment language processing knowledge 
formal definition incorporating aspect intelligence di cult 
known facets intelligence formulated goal driven precisely maximizing utility function 
su cient study goal driven ai biological goal animals humans survive spread 
goal ai systems useful humans 
problem special cases know utility function environment agent operate advance 
mathematical theory coined aixi supposed solve problems 
assume availability unlimited computational resources 
important observation ai problem trivial 
playing chess optimally solving np hard problems trivial driving car surviving nature don 
reason challenge define problems mention algorithm 
words ai problem defined 
may view aixi suggestion mathematical definition ai 
aixi universal theory sequential decision making akin solomono celebrated universal theory induction 
solomono derived optimal way predicting data previous observations provided data sampled computable marcus hutter technical report idsia probability distribution 
aixi extends approach optimal decision making agent embedded unknown environment 
main idea replace unknown environmental distribution bellman equations suitably generalized universal distribution 
state space space complete histories 
aixi universal theory adjustable parameters making assumptions environment sampled computable distribution 
algorithmic complexity perspective aixi model generalizes optimal passive universal induction case active agents 
decision theoretic perspective aixi suggestion new implicit learning algorithm may overcome computational problems previous reinforcement learning algorithms 
strong arguments aixi intelligent unbiased agent possible 
outline number problem classes including sequence prediction strategic games function minimization reinforcement supervised learning aixi model formally solve 
major drawback aixi model 
overcome problem construct modified algorithm ectively intelligent time space bounded agent 
computation time order discussed topics formal definitions intelligence order relations horizon problem relations aixi theory ai approaches 
article meant gentle discussion aixi model 
mathematically rigorous treatment subtleties proofs see author works annotated bibliography section 
section provides introductory textbooks original publications algorithmic information theory sequential decision theory 
chapter presents theory sequential decisions general form called ai model actions observations may depend arbitrary past events 
clarify connection bellman equations discuss minor parameters including size spaces lifetime agent universal choice mind 
optimality ai obvious construction 
chapter sense induction possible subject long philosophical controversies 
highlights principle multiple explanations occam razor bayes rule conditional probabilities 
solomono elegantly unified aspects formal theory inductive inference universal probability distribution closely related kolmogorov complexity length shortest program computing rapid convergence unknown true environmental distribution tight loss bounds arbitrary bounded loss functions finite alphabet shown 
pareto optimality sense predictor performs better equal environments strictly better shown 
view results fair say problem sequence prediction possesses universally optimal solution 
chapter active case reinforcement learning algorithms usually unknown 
succeed state space small ectively small generalization techniques 
algorithms restricted universal algorithmic agent aixi markovian domains problems optimally trading exploration versus exploitation nonoptimal learning rate prone diverge ad hoc 
formal solution proposed generalize solomono universal prior include action conditions replace ai model resulting ai aixi model claim universally optimal 
investigate expect universally optimal agent clarify meanings universal optimal discussed topics formal definitions intelligence order relation horizon problem pareto optimality aixi 
chapter show number ai problem classes fit general aixi model 
include sequence prediction strategic games function minimization supervised learning 
formulate problem class natural way known construct formulation ai model show equivalence 
consider consequences replacing 
main goal understand sense problems solved aixi 
chapter major drawback aixi precisely asymptotically computable implementation impossible 
overcome problem construct modified model superior time space bounded algorithm 
computation time order solution requires implementation order logic definition universal turing machine proof theory system 
chapter discuss topics general interest 
various topics including concurrent actions observations choice spaces treatment encrypted information peculiarities mortal embodies agents 
continue outlook research including optimality scaling implementation approximation elegance extra knowledge training aixi tl 
include personal remarks non computable physics number wisdom consciousness 
annotated bibliography conclude 
agents known probabilistic environments general framework ai viewed design study intelligent agents rn 
agent cybernetic system internal state acts output environment cycle perceives input environment updates internal state 
cycle follows 
split input regular part reward called reinforcement feedback 
time time environment provides non zero reward agent 
task agent maximize utility defined sum rewards 
probabilistic environment described conditional probability inputs agent condition agent outputs environments type 
give formal expressions outputs agent maximize total expected reward sum called value 
model called ai model 
ai marcus hutter technical report idsia problem brought form problem maximizing utility formally solved known 
furthermore study special aspects ai model 
introduce probability distributions describing environments independent episodes 
occur problem classes studied section special case general separable probability distributions defined section 
clarify connection bellman equations sequential decision theory discuss similarities di erences 
discuss minor parameters model including size input output spaces lifetime agent universal choice mind 
remarkable section essence sequential decision theory nm bel bt sb new form 
notation formulas needed sections simply developed 
major remaining problems 
problem unknown true probability distribution solved section computational aspects addressed section 
cybernetic agent model way start thinking intelligent systems consider generally cybernetic systems ai usually called agents 
avoids having struggle meaning intelligence 
cybernetic system control circuit input output internal state 
external input internal state agent calculates deterministically stochastically output 
output action modifies environment leads new input perception 
continues ad infinitum finite number cycles 
definition agent model agent system interacts environment cycles 
cycle action output agent determined policy depends history environment reacts action leads new perception input determined deterministic function probability distribution depends history cycle starts 
explained section need reward assignment cybernetic system 
input divided parts standard input reward input input output represented strings deterministic cybernetic system modeled turing machine called policy agent determines re action perception 
environment computable modeled turing machine 
interaction agent environment illustrated follows universal algorithmic agent aixi agent tape environment tape unidirectional input output tapes bidirectional working tapes 
agent environment fact upper tape serves input tape output tape lower tape serves output tape input tape reading head left writing head symbols written read 
mutually inaccessible working tapes containing secrets 
heads move way 
th cycle writes reads writes reads followed th cycle 
process starts cycle heads tape start working tapes empty 
want call turing machines behaving way chronological turing machines 
continuing notations strings probability distributions appropriate 
strings denote strings alphabet alternatively interpreted non empty subset prefix free set binary strings 
length analogous definitions hold call th input word th output word letter 
string represents input output chronological order 
due prefix property uniquely separated words 
words appearing strings chronological order 
introduce abbreviations empty string xm analogously yx yx mxm 
ai model known deterministic environment define chronological turing machine partial function named output turing machine input cycle read 
analogous way define 
conversely partial recursive chronological function define corresponding chronological turing machine 
agent environment pair note possible additional dependence mentioned definition eliminated recursive substitution see 
similarly marcus hutter technical report idsia produces unique sequence pq pq pq pq pq 
look definitions see nice symmetry cybernetic system environment 
intelligence agent 
credit assignment comes game removes symmetry somewhat 
split input rx regular part reward ir 
define 
goal agent maximize received rewards 
called reinforcement learning 
reason asymmetry eventually humans environment agent communicate want dictate wrong way round 
way learning agent learns environment conversely prevents agent intelligent environment prevent environment learning agent environment interpret outputs regular reward part 
environment just forced learn agent cases restrict reward values ib interpreted positive feedback called correct negative feedback called bad error 
restrict lifetime number cycles agent large finite value 
pq km total reward called utility agent receives environment cycles natural call agent maximizes called total utility best arg max pq km pq km pq condition nil 
states shall consistent sense history 
finite number di erent behaviors agent search space finite 
assumed known ectively determined pre analyzing behaviors 
main reason restricting finite ensure computability limit exist 
ease defined computed optimal policy remarkable 
just unrealistic assumption completely known deterministic environment 
ai model known prior probability weaken assumptions replacing environment probability distribution chronological functions 
interpreted ways 
environment behaves stochastically defined true environment deterministic subjective probabilistic information environment true environment 
combinations cases possible 
assume known describes true stochastic behavior environment 
case unknown agent having beliefs environment lies heart ai model described section 
argmax maximizes 
maximum choose lexicographically smallest definiteness 
universal algorithmic agent aixi best intelligent agent maximizes expected utility called value function pq defines ai model 
definition ai model ai model agent policy maximizes expected total reward argmax need concept value function slightly general form 
definition true generating value function agent perception consists regular input reward ir 
cycle value km yx defined expectation reward sum actions generated policy fixed history yx say km yx value policy environment history yx shorter true generating value yx total value give formal definition km assume cycle history yx 
yx ask best output set environments producing history 
say consistent history yx expected reward cycles history called value policy conditional probability km yx pq km 
policy environment determine history yx deterministic case history longer deterministically determined depends outcome stochastic process 
new cycle adds new information agent 
indicated dots symbols 
cycle maximize expected rewards account information history yx information agent start deterministic case 
furthermore want generalize finite lifetime dynamical computable called horizon 
original finite lifetime agent maximizes cycle expected rewards 
discussion choices delayed section 
rewards maximized arg max km yx set systems consistent current history 
depends step determine writing environment replies conditional probability 
probabilistic outcome provides new information agent 
cycle starts determining di ers fixed 
marcus hutter technical report idsia note implicitly depends 
recursively inserting define chronological function computable finite computable 
constant show policy coincides ai model 
proves km yx km yx consistent yx similarly 
obvious 
call ai model 
deterministic model reduces deterministic case discussed subsection 
important maximize sum rewards instance greedy maximize reward done sequence prediction 
example environment sequence chess games cycle corresponds move 
game positive reward agent won game illegal move 
agent maximizing rewards means trying win games short possible time avoiding illegal moves 
performance reached choose larger typical game lengths 
maximization reward bad chess playing agent 
reward finer evaluating number agent play bad chess 
ai model depends addressed section 
get final universal ai model idea replace universal probability defined 
motivated fact converges certain sense model longer depends parameters truly universal 
remains show behaves intelligently 
continue step step 
develop alternative equivalent formulation ai model 
functional form suitable theoretical considerations especially development time bounded version section iterative recursive formulation subsections appropriate explicit calculations sections 
probability distributions greek letters probability distributions underline arguments indicate probability arguments 
probability infinite string starts drop index clear arguments xn xn 
call probability distribution deterministic exactly argument 
universal algorithmic agent aixi need conditional probabilities derived bayes rule 
prefer notation preserves chronological order words contrast standard notation flips 
extend definition conditional case convention arguments underlined argument probability variable non underlined arguments represent conditions 
convention bayes rule form 
equation states probability string followed equal probability divided probability 
abbreviation strings starting 
introduced notation suitable defining conditional probability environment reacts condition output agent environment chronological input depends yx 
probabilistic case means yx yx independent arguments dropped 
probability distributions property called chronological 
conditions underlined additional conditioning obtained bayes rule yx yx yx yx yx yx yx yx 
yx yx second equation equation applied times 
explicit form ai model define ai model di erent way yx yx true probability input cycle history yx 
yx true chronological prior probability environment reacts provided actions agent 
assume cybernetic model depicted page valid 
define value yx expected reward sum cycles outputs generated agent maximizes expected reward sum responses environment drawn adding get reward including cycle probability yx conditional probability yx yx 
expected reward sum cycles yx km yx yx yx yx ask chooses choose maximize rewards 
expected reward cycles yx chosen km yx max km yx see 
induction start yx km completely defined 
summarize cycle formula km yx max yx yx yx marcus hutter technical report idsia max km yx max km yx action max value 


km yx yx yx yx expected reward observation max max max max yx max yx tree algorithm ib introduce dynamical computable called horizon 
lifetime agent achieve optimal behavior limited agent maximizes cycle expected rewards 
discussion choices delayed section 
horizon function yx actual history cycle output agent explicitly arg max km yx turn defines policy environment responds probability yx yx 
cycle starts 
unfold recursion give non recursively arg max max max ym xm 
xm yx yx direct interpretation probability inputs cycle agent outputs actual history yx yx yx 
reward case 
xm 
best expected reward obtained averaging maximizing done chronological order correctly incorporate dependency history 
essentially algorithm tree mic rn 
ai model optimal sense policy leads higher expected reward 
value general policy written form km yx 
rm yx yx clear interpretations iterative environmental probability relates functional form way yx universal algorithmic agent aixi identification show hut theorem equivalence functional iterative ai model actions functional ai model coincide actions recursive iterative ai model environments identified 
environments restrictions form prior probability apart chronological probability distribution 
hand see order prove rigorous reward bounds prior probability satisfy separability condition defined 
introduce strong form separability factorizes products 
assume cycles grouped independent episodes episode consists cycles yx yx nr simplest case episodes length rl 
depends episode show arg max km yx arg max kt yx min 
di erent episodes completely independent sense inputs di erent episodes statistically independent depend episode 
outputs depend corresponding episode independent actual episodes 
note independent choice long su ciently large 
episodes length choose horizon independent means problem limit 
limit performed general case su ciently separable problem choice discussed detail 
restrictive cover ai problems occurs practice form repeated problem solving worth studied 
example agent play games chess repeatedly minimize different functions di erent games functions completely independent environmental probability factorizes factor corresponds game function minimization 
details see appropriate sections strategic games function minimization 
probably easier derive suitable reward bounds universal ai model defined section separable cases marcus hutter technical report idsia introduced 
step definition proof general case separable problems 
goal paragraph show notion step definition analysis general case separable constants limits mind universal agent complex interactions intelligent complex human 
think agent input comes digital video camera output image monitor valuation restrict primitive binary ib 
think constant sizes limits say actual number inputs outputs reasonably large compared typical size input output words sizeable 
limit expresses fact total lifetime number cycles agent far small allow possible input occur try possible output identically repeated inputs outputs 
expect useful outputs 
interesting lengths inputs complexity inputs defined 
environment usually perfect 
agent interact non perfect human tackle non deterministic world due quantum mechanics chaos case sequence contains noise leading complexity probability distribution input sequence di erent 
assume noisy world operates simple computable rules 
rules world highly compressed 
may allow environments new aspects appear causing non bounded 
limits explicitly stated 
simpler models examples size constants violate limits limits reader bear mind 
interested theorems degenerate limits 
order avoid cumbersome convergence existence considerations assumptions 
assumption finiteness assume input perception space finite output action space finite rewards non negative bounded max humans simulate screen output device drawing pictures 
exist truly stochastic processes di cult question 
quantum indeterminacy comes close 
universal algorithmic agent aixi horizon finite 
finite bounded separately ensure existence expectations needed finite ensures argmax 
exists maxima attained finite avoids various technical philosophical problems section positive rewards needed time bounded ai tl model section 
theorems generalized relaxing finiteness assumptions 
sequential decision theory relate bellman equations bel sequential decision theory identifying complete histories yx states yx yx state transition matrix value function action cycle bt rn 
due complete histories state space ai model assumes stationarity markov property complete accessibility environment 
state occurs lifetime system 
reasons explicit formulation useful enforce pseudo recursive bellman equation form 
mind universal system complex interactions action perception spaces huge video images action perception occurs usually lifespan agent 
obvious universal similarity relation state space ective reduction size impossible principle problem determining long known computable finite 
things dramatically change unknown 
reinforcement learning algorithms klm sb bt commonly case learn unknown succeed state space small ectively small generalization function approximation techniques 
case solutions ad hoc restricted domains serious problems state space exploration versus exploitation prone diverge non optimal learning rate 
universal optimal solution problem far 
central theme article new model argue formally solves problems optimal way 
true probability distribution learned directly replaced universal prior converges universal sequence prediction section deals question predictions unknown environments 
brief description important philosophical attitudes regarding inductive reasoning inference describe accurately mean induction motivate focus sequence prediction tasks 
important concept occam razor simplicity principle 
show best way predictions shortest simplest description data sequence seen marcus hutter technical report idsia far 
general ective descriptions obtained help general recursive functions equivalently programs turing machines especially universal turing machine 
length shortest program describing data called kolmogorov complexity data 
probability theory needed deal uncertainty 
environment may stochastic process gambling houses quantum physics described objective probabilities 
uncertain knowledge environment leads beliefs modeled subjective probabilities 
old question left open choose priori probabilities solved solomono universal prior closely related kolmogorov complexity 
solomono major result universal subjective prior converges true objective environment probability assumption needs known 
computable 
problem unknown environment solved problems inductive type sequence prediction classification 
important highly non trivial aspect intelligence inductive inference 
simply speaking induction process predicting past precisely process finding rules past data rules guess data 
weather stock market forecasting continuing number series iq test non trivial examples 
making predictions plays central role natural artificial intelligence general machine learning particular 
induction problems phrased sequence prediction tasks 
instance obvious time series prediction includes classification tasks 
having observed data times task predict th symbol sequence prequential approach daw skips intermediate step learning model observed data model predict prequential approach avoids problems model consistency separate noise useful data issues 
goal predictions prediction quality usually measured loss function shall minimized 
key concept define solve induction problems occam razor simplicity principle says entities multiplied necessity may interpreted keep simplest theory consistent observations theory predict solomono formal solution quantify occam razor terms kolmogorov complexity introduce notion subjective objective probabilities 
algorithmic information theory intuitively string simple described words string ones complex short description random string shortest description specifying bit bit 
restrict discussion universal algorithmic agent aixi binary strings non mathematical objects may assume default coding binary strings 
furthermore interested ective descriptions restrict decoders turing machines 
choose universal called prefix turing machine unidirectional binary input output tapes bidirectional working tape 
define conditional prefix kolmogorov complexity cha gac kol lev binary string length shortest program outputs binary string definition kolmogorov complexity universal prefix turing machine conditional prefix kolmogorov complexity defined shortest program outputs min min simple strings generated short programs low kolmogorov complexity irregular random strings shortest description high kolmogorov complexity 
important property nearly independent choice furthermore shares properties shannon entropy information measure superior respects 
brief excellent universal complexity measure suitable quantifying occam razor 
severe disadvantage finitely computable 
major algorithmic property enumerable 
general non string objects specify default coding define object object especially numbers pairs abbreviate 
important information theoretic properties listed abbreviate 
abbreviate 
theorem information properties kolmogorov complexity log logn ii 
iii iv xy ib ib recursive computable vi vii log ib recursive marcus hutter technical report idsia equalities remain valid conditioned 

stated valid additive constant size valid logarithmic accuracy 
properties common shannon entropy measure information content string 
gives upper bound 
ii kraft inequality implies lower bound valid means exceptions 
providing side information increase code length requiring extra information decrease code length iii 
coding separately helps iv transforming increase information content 
shows switching coding scheme means recursive bijection leaves unchanged additive terms 
non trivial result symmetry information vi analogue bayes rule 
vii hart mdl principle ris approximates log 
uncertainty probabilities probabilities real aspects world 
outcome observation experiment deterministic involves physical random processes 
kolmogorov axioms probability theory formalize properties probabilities 
case experiments probabilities assigned events interpreted limiting frequencies frequentist view applications limited case 
probabilities bayes rule major tools computing posterior probabilities prior ones 
instance initial binary sequence probability bit 
probability observing time past observations computed bayes rule true generating distribution sequences known see sections 
problem know true distribution cases weather stock market forecasting 
uses probabilities characterize agent degree belief plausibility characterize physical random processes 
relevant interpretation probabilities ai 
somewhat surprising plausibilities shown respect kolmogorov axioms probability bayes rule assuming plausible qualitative rules follow cox 
plausibility degree belief bayes rule 
bayes rule allows computing posterior probabilities plausibilities prior ones leaves open question determine priors 
statistical physics principle indi erence symmetry principle maximum entropy principle exploited determine prior probabilities occam razor general assign prior probabilities situation especially cope domains typical ai 
strictly speaking just definition conditional probabilities 
universal algorithmic agent aixi algorithmic probability universal induction occam razor appropriately interpreted compromise principle indi erence tells assign high low priori plausibility simple complex strings complexity measure monotone decreasing function satisfy criterion 
satisfy probability axioms bit careful 
solomono sol sol defined universal prior probability output universal turing machine starts provided fair coin flips input tape 
formally defined sum called minimal programs outputs string starting inequality follows dropping terms shortest computing strictly speaking normalized acceptable correctable 
derive bound ln ln ln inequality 
equality exchanged sum logarithm eliminated resulting product bayes rule 
inequality 
computable sequence finite implies 
means environment computable sequence digits binary representation having seen digits correctly predicts digit high probability recognizes structure sequence 
assume true sequence drawn distribution true objective probability unknown 
posterior subjective belief related true objective posterior probability 
solomono sol crucial result posterior subjective beliefs converge true objective posterior probabilities computable 
precisely showed ln finite computable infinite sum finite di erence tends zero probability 
shows estimate may reasonable thing 
loss bounds pareto optimality predictions eventually basis decision action leads reward loss 
ir received loss performing marcus hutter technical report idsia prediction decision action th symbol sequence 
prediction causal prediction scheme 
true probability symbol 
expected loss predicting 
total expected loss su ered scheme predictions goal minimize expected loss 
generally define sequence prediction scheme called sp argmin minimizes expected loss 
known obviously best prediction scheme sense achieving minimal expected loss 
proven loss bound universal predictor hut hut ln ln shows asymptotically achieves optimal average loss rapid convergence 
finite finite finite 
bound implies ln shows causal predictor whatsoever achieves significantly expected loss view results fair say ignoring computational issues problem sequence prediction solved universal way 
di erent kind optimality pareto optimality 
universal prior sense predictor leads equal smaller loss environments 
improvement achieved predictor environments balanced deterioration environments hut 
universal algorithmic agent aixi active systems game playing sg optimization fm reduced induction systems 
main idea generalize universal induction general agent model described section 
generalize include conditions replace rational agent model resulting ai aixi model 
way problem true prior probability usually unknown solved 
convergence shown indicating ai model behave optimally computable unknown environment reinforcement feedback 
main focus section investigate expect universally optimal agent clarify meanings universal optimal unfortunately bounds similar loss bound sp case hold active agent 
forces lower expectation universally optimal agents introduce weaker universal algorithmic agent aixi performance measures 
show ai pareto optimal sense policy yielding higher equal value environments strictly higher value 
universal ai model definition ai model 
developed formalism suggest universal ai model 
suitably generalize universal subsection replace true unknown prior probability ai ai model generalized ai sense ai model universal discussed 
functional formulation define universal probability ai environment just definition easier collecting formulas section replacing get definition ai agent functional form 
history yx policy functional ai agent arg max max pq km cycle pq km total reward cycles agent interacts environment dropped denominator independent constant multiplicative factor change argmax iterative formulation universal probability obtained inserting functional yx replacing iterative ai agent outputs arg max max max ym xm 
xm yx yx cycle history yx equivalence functional iterative ai model proven section true chronological especially talk ai model respect 
slightly depends choice universal turing machine 
defined additive constant 
ai model depends choice rx expect bias spaces necessary similar reader may expect point 
reason program exists functionally equivalent program 
identify objects coding relative fixed turing machine example function binary coding 
hand binary string define 
marcus hutter technical report idsia chosen su ciently simple strings length choosing word space optimal maxima suprema exist case shown 
non trivial dependence horizon function discussed 
apart unimportant details ai agent uniquely defined 
doesn depend assumption environment apart generated computable unknown 
probability distribution 
convergence similarly show expected squared di erence finite computable turn shows yx yx converges yx yx probability 
line reasoning pure 
change analyze loss reward bounds analogous 
take finite product bayes rule see yx yx converges yx yx 
generally case bounded horizon follows yx yx yx yx max confident outputs ai model converge outputs ai model bounded horizon 
want call ai model universal independent unbiased model free able solve solvable problem learn learnable task 
call universal model universally optimal program solve learn significantly faster terms interaction cycles 
ai model parameter free converges ai model optimal expect model converge faster ai analogy sp claim expect aixi universally optimal main claim 
sense intention remaining sections define statement rigorously give support 
intelligence order relation 
define expected reward cycles policy similar 
extend definition programs consistent current history 
km yx pq km normalization necessary interpreting km expected reward unneeded 
consistent policies define modification way outputs consistent current history yx unaltered current cycles definition km take policies consistent ones 
mean converge limiting value 
universal algorithmic agent aixi definition intelligence order relation call policy equally intelligent write yx km yx km yx 
yields circumstance higher expected reward algorithm ai agent maximizes km ai model intelligent agent 
universal order relation sense free parameters specific assumptions environment 
proof reliable intelligence order believe true prove ai universally optimal 
ask useful ordering policies practical interest intermediate intelligence help guide constructing intelligent systems reasonable computation time 
ective intelligence order relation defined section useful practical point view 
optimality aixi section outline ways optimality proof aixi 
sources inspiration sp loss bounds proven section optimality criteria adaptive control literature mainly linear systems kv 
value bounds aixi expected sense weaker sp loss bounds problem class covered aixi larger class induction problems 
convergence proven su cient establish convergence behavior aixi model behavior ai model 
focus approaches general optimality proof meant universal optimality 
step investigate expect aixi meant universal optimality 
learner aixi may converge optimal informed decision maker ai senses 
possibly relevant concepts statistics consistency self self ciency asymptotic finite convergence kv pareto optimality defined 
concepts stronger necessary weaker desirable suitable start 
self defined asymptotic convergence average true value ai optimal value apart convergence speed self aixi closely correspond loss bounds proven sp 
investigate properties desirable circumstances aixi model satisfies properties 
show universal model including aixi general self optimizing 
hand show aixi pareto optimal sense policy performs better equal environments strictly better 
limited environmental classes 
problem defining proving general value bounds feasible considering step restricted concept classes 
marcus hutter technical report idsia analyze aixi known classes markovian environments especially new classes forgetful relevant asymptotically learnable uniform pseudo passive defined section 
generalization aixi general bayes mixtures 
approach generalize aixi ai general bayes mixture distributions class multi set enumerable semi measures enumerated turing machine ai coincides aixi 
multi set passive ective environments aixi reduces predictor shown perform 
show loss value bounds generalize wider classes asymptotically hut 
promising classes ones described section 
especially ergodic mdps showed ai self optimizing 
obviously demand chance finding self optimizing policy exists self optimizing policy 
key result hut necessary condition su cient 
generally key prove absolute results specific problem classes prove relative results form exists policy certain desirable properties ai possesses desirable properties 
tasks solved policy ai blamed failing 
environmental classes allow self optimizing policies include processes classification tasks certain classes pomdps th order ergodic mdps environments repeated games prediction problems 
note approach environmental class corresponding model ai approach pursued article universal aixi model analyzed environmental classes 
value bounds separability concepts 
values km associated ai systems correspond roughly negative loss sp systems 
sp interested small bounds loss excess unfortunately simple value bounds ai terms km analogous loss bound hold 
di culties specifying expect hold ai ai system claims universally optimal 
consequently proof don know prove 
sp important property proving error bounds complexity 
see ai case useful bounds terms 
study restricted problem classes consider bounds depending properties complexity 
exhibit di culties examples introduce concepts may useful proving value bounds 
despite di culties claiming useful value bounds firmly believe order relation correctly formalizes intuitive meaning intelligence ai agent universally optimal 
pseudo passive example 
choose want compare true expected value independent universal algorithmic agent aixi universal policy best policy naively expect existence policy best maximizes apart additive corrections lower order best 
policies called self optimizing kv 
note candidate universal best depends hand policy ai agent maximizes definition 
thought guess expect best approximately maximize 
hold 
consider problem class set environments iy environment kronecker symbol xy defined 
action decides go heaven rewards hell rewards bad 
clear known optimal policy output cycle hand unbiased policy best independent actual outputs 
independent actual choice environment choice catastrophic best 
single agent perform environments equals best zero 
shown best satisfy expect 
problem classes holds instance sp 
sp just reformulation appropriate choice best di ers see section 
expect hold inductive problems environment influenced output agent 
want call passive inductive environments 
want call satisfying best pseudo passive 
expect inductive pseudo passive 
example 
give example demonstrate di culties establishing value bounds 
large 
consider deterministic environments single complex output correct wrong 
problem class defined yx log way independent policy find correct trying certain order 
cycles di erent tested 
di erent possible gives erroneous outputs cycles 
number errors true true ai model best possible error bound expect depends 
derive bound section inductive environments 
unfortunately mainly interested cycle course reward feedback depends agent output 
mind sequence prediction true sequence influenced agent 
marcus hutter technical report idsia region see section bound trivial 
interesting bounds deterministic depending sp case 
bounds depend additional properties consider specialized bounds restricted problem classes 
case probabilistic similar 
sp useful bounds terms bounds ai 
drawback ai unbiased ai system errors rewards bound terms errors rewards ai 
way gross bounds 
assume reasonable number cycles information perceived ai agent contains lot information true environment information coded form 
assume complexity condition known order 
consider theorem bounding sum rewards quantities cycles terms function bound cycles terms 
bound replaced small bound cycles 
show ensure assume information form cycles 
way gross bound useful 
section similar argument prove ai able learn supervised 
asymptotic learnability 
weaken hope getting bound applicable wider problem classes passive 
consider sequence 
caused ai 
history yx ai output cycle compare ai output history yx produced ai 
ai maximizes expected value ai causes lower best equal km di ers expected number suboptimal choices ai outputs di erent ai cycles 
weigh deviating cases severity 
especially expected rewards km equal close taken account definition weight factor km yx km yx 
details matter qualitative discussion 
important di erence stick history produced ai count wrong decision error 
wrong decision example cycle longer counts losing rewards counts wrong decision 
sense fairer 
shouldn blame somebody single wrong decision just little information available order correct decision 
ai model deserve called asymptotically optimal probability making wrong decision tends zero 
say asymptotically learned ai satisfied 
claim ai asymptotically learn problem relevance ai asymptotically optimal 
included qualifier relevance sure strange spoiling expect irrelevant universal algorithmic agent aixi perspective ai 
field learning asymptotic learnability theorems di cult prove 
proof feasible 
unfortunately asymptotic learnability theorems weak useful practical point 
point right direction 
uniform convergence expect km km defined converge defined probability 
problem km di erent choices nearly equal km km possible due non continuity argmax cured weighted described 
serious second problem explain 
argmax yr converge argmax yr su cient know yr yr yr yr proven 
need convergence true output reward alternate outputs reward 
converges converges uniformly addition yx yx yx yx yx yx holds constant expected sense 
call satisfying uniform 
uniform show appropriately weighted bounded horizon max unfortunately relevant uniform 
concepts 
briefly mention concepts 
markovian defined depending cycle 
yx yx yx 
say generalized th order markovian yx yx yx yx fixed property similarities defined 
called stationary 
call forgetful yx yx yx yx independent yx fixed probability 
say lim exists 
details section give example limit sense 
summary 
introduced concepts useful proving value bounds including forgetful relevant asymptotically learnable uniform generalized markovian pseudo passive sorted approximately order decreasing generality 
want call separability concepts 
general relevant asymptotically learnable called weakly separable restrictive pseudo passive called strongly separable qualifiers qualitative rigid sense 
non separability concepts deterministic course class chronological pareto optimality ai subsection shows pareto ai analogous sp 
total expected reward policy ai model central interest judging performance marcus hutter technical report idsia ai 
know policies ai higher value 
general policy estimate closer outperforms environment simply hand system probably performs worse environments 
know advance may ask exists policy better equal performance environments strictly better performance clearly render suboptimal 
show definition pareto optimality policy called pareto optimal policy strict inequality 
theorem pareto optimality ai alias pareto optimal 
pareto optimality regarded necessary condition agent aiming optimal 
practical point view significant increase environments may desirable causes small decrease 
impossibility balanced improvement demanding condition pure pareto optimality 
hut shown ai optimal 
choice horizon significant arbitrariness ai model lies choice horizon function 
discuss choices natural give preliminary 
discuss ad hoc choices specific problems discussion section section context finite strategic games 
interested universal choices fixed horizon 
lifetime agent known practice large finite choice maximizes correctly expected reward 
usually known advance cases time willing run agent depends quality outputs 
reason desirable outputs delayed results marginal reward increase 
incorporated damping rewards 
instance assume survival agent cycle proportional past reward exponential damping appropriate bounded 
expression converges case solve problem introduced new arbitrary time scale damping introduces time scale 
prone problems undiscounted case discussed 
dynamic horizon universal harmonic discounting 
largest enumerable horizon guaranteed finite reward sum obtained discount precisely argmax yk lim mk kmk exists 
universal algorithmic agent aixi currently attractive universal discount 
similar near harmonic discount log 
generally time scale invariant damping factor introduces dynamic timescale 
cycle contribution cycle damped factor ective horizon case choice qualitatively models behavior 
introduced arbitrary time scale limited multiple fraction length current history 
avoids pre selection global time scale choice appeal humans age years usually plan lives years human 
practical point view model serve needs theoretical point feel uncomfortable limitation horizon 
note choose introduce number justified 
infinite horizon mathematical solution 
naive limit may turn defined previous discussion superfluous 
suggest limit defined finite 
defined dependence explicit 
set outputs cycle choices 

define model output best output consistent arbitrary large choice choosing lexicographically smallest correspond inferior lim exists finite 
generally unique naive limit lim exists 
note limit lim km yx needs exist construction 
average reward di erential gain 
raw average reward 
help take arbitrary policy time steps optimal policy remaining steps 
policies give average 
mdp environments single recurrent class define relative di erential gain ber 
general environments interested di erential gain infinite acceptable di erential gains totally ordered 
major problem existence di erential gain converges ir oscillate 
just old convergence problem slightly di erent form 
immortal agents lazy 
construction leads mathematically elegant parameter ai model 
unfortunately story 
limit cause undesirable results ai model special happen ai model define 
consider 
output shall give reward output shall give 
agent achieve consecutive positive rewards sequence length 
lifetime ai agent outputs cycles remaining cycles marcus hutter technical report idsia lead highest possible total reward fragmentation sequences reduce ai agent delay point switching indefinitely output leading total reward obviously worst possible behavior 
ai agent explore rule trying applies behavior ai agent simplest rules covering past data dominate 
finite exactly want infinite ai model probably fails just ai model 
point weakness ai model ai fails agent better ai 
bad point far reaching consequences starting large reason example highly non local time may violate weak separability conditions 
convergence ai ai infinite horizon 
paragraph considered consequences ai model 
consider ai model approximation ai model large objection large choices yx yx proven approximation yx yx satisfied 
seen limit causes problem certain output independent bounded develop separability property 
certain limit safe 
limit worsens behavior ai finitely cycles acceptable 
suppose rewards longer trusted approximation sense randomly disturbed decreasing influence choice claim supported property 

sure choice marginal importance long chosen su ciently large low complexity instance choice turn central topic ai model planning aspect ai system general 
suppose limit ai model results correct behavior weakly separable proof conjecture true probably give interesting insights 
outlook expert advice approach 
considered expected performance bounds predictions solomono prior 
dual currently popular approach prediction expert advice wm invented littlestone warmuth vovk 
wm performs environment relative set experts predictor competes predictor expectation environments computable distribution 
philosophically compromising assumptions prediction strategies environment weak 
investigate wm generalized case active agents universal algorithmic agent aixi result model dual aixi 
believe answer negative positive side show necessity occam razor assumption aixi 
actions random variables 
uniqueness choice generalized aixi model explored 
originally alternatives ruled alternative possible 
defining treat agent actions universally distributed random variables bayes rule 
structure aixi 
algebraic properties structure aixi investigated depth 
extract essentials aixi lead axiomatic characterization aixi 
benefit axiomatic approach 
clearly exhibit assumptions separate essentials technicalities simplify understanding important guide finding proofs 
restricted policy classes 
development section scaled restricted classes policies may define argmax instance consider finite class quickly computable policies 
mdps quickly computable ciently computed monte carlo sampling 
maximizing finitely policies selects asymptotically best policy ergodic mdps hut 
tasks require intelligence solved naturally formulated maximization expected utility framework agents 
gave explicit expression decision theoretic agent 
main remaining problem unknown prior probability distribution ai environment 
conventional learning algorithms unsuitable handle large unstructured state spaces converge theoretically minimal number cycles handle non stationary environments appropriately 
hand universal ideas algorithmic information theory solves problem unknown prior distribution induction problems 
explicit learning procedure necessary automatically converges unified theory universal sequence prediction decision theoretic agent replacing unknown true prior ai appropriately generalized universal ai gave strong arguments resulting ai model universally optimal 
furthermore possible solutions horizon problem discussed 
section outline number problem classes ai model solve 
include sequence prediction strategic games function minimization especially ai learns learn supervised 
section develop elegant equivalent functional form ai model 
define universal intelligence order relation discuss sense ai intelligent agent construct modified time bounded computable ai tl version 
marcus hutter technical report idsia important environmental classes order give support universality optimality ai theory apply ai section number problem classes 
include sequence prediction strategic games function minimization especially ai learns learn supervised 
classes give concrete examples illuminate scope problem class 
formulate problem class natural way problem known construct formulation ai model prove equivalence 
consider consequences replacing 
main goal understand problems solved ai 
highlight special aspects problem class 
sections give better picture ai model 
study aspect problem class 
subsections read selectively 
essential understand remaining sections 
sequence prediction sp introduced ai model unification ideas sequential decision theory universal probability distribution 
expect ai behave identically sp faced sequence prediction problem things simple see 
ai model sequence prediction 
seen section predict sequences known unknown prior distribution sp consider binary sequences 
ib known prior probability sp 
want show ai model sequence prediction 
see prediction sp agent 
simplicity discuss special error loss xy xy kronecker symbol defined ab 
specify ai model sequence prediction 
choice natural system output interpreted prediction th bit string consideration 
means binary ib 
reaction environment agent receives reward prediction correct prediction erroneous 
question input cycle 
choice inform agent correct th bit string set reward conjunction prediction true bit inferred information redundant 
need additional feedback 
set having agent performance change include redundant information merely complicates notation 
prior probability ai ai model ai ai sp sp drop superscripts clear arguments equal case 
intuitively clear formally avoid notational conflicts agent inputs universal algorithmic agent aixi shown hut maximizing reward km identical greedily maximizing immediate expected reward kk exploration exploitation tradeo prediction case 
ai acts arg max kk yx arg max ai yr yr arg max sp 
equation definition agent prediction replaced second equation definition km equation ai model predicts maximal probability 
prediction independent choice exactly prediction scheme deterministic sequence prediction known prior sp described section special error loss 
model optimal ai optimal minimal number expected errors maximal expected reward compared sequence prediction scheme 
clear value km closely related expected loss 
show lm valid general loss functions 
ai model sequence prediction 
want universal ai model ai sequence prediction try derive error loss bounds analogous 
ai case agent output cycle interpreted prediction th bit string consideration 
reward inputs 
analysis di cult symmetric hold 
hand ai converges ai limit hold asymptotically sense 
expect proven ai holds approximately ai 
ai model behave similarly solomono prediction sp 
especially expect error bounds similar 
making rigorous di cult 
general remarks section 
note bounds hold general valid ai pseudo passive environments 
concentrate special case deterministic computable environment environment sequence consider simplest horizon model maximize reward 
su cient sequence prediction reward cycle depends output earlier decisions 
choice way su cient satisfactory full ai model single choice serve ai problem classes 
ai allow sequence prediction universal choice definitely su ce complicated ai problems 
analysis general case challenge 
ai model reduces arg max yr yr arg max yr environmental response correct prediction 
show hut number wrong predictions ai marcus hutter technical report idsia ai model environments bounded ai computable deterministic environment string 
intuitive interpretation wrong prediction eliminates program size 
size smaller larger policies mislead agent wrong prediction program size making correct prediction 
policies bounds total number errors 
derived finite bound ai unfortunately weak compared 
reason strong bound sp case error eliminates halve programs 
ai model su cient realistic applications bound sharp strong feeling currently weak arguments better bounds proportional analogous exist 
current proof technique strong achieving 
argument better bound formal similarity argmax unable construct example sequence ai errors 
strategic games sg 
important class problems strategic games chess 
fact subsumed game theory general includes huge variety games simple games chance roulette combined strategy backgammon purely strategic games chess checkers go 
game theory describe political economic competitions coalitions 
nearly ai problem brought form game 
intention game players perform actions partial observable consequences 
goal player maximize utility function win game 
players assumed rational account information posses 
di erent goals players usually conflict 
game theory see ft rn nm 
interpret ai system player environment models rational player environment provides reinforcement feedback see agent environment configuration satisfies criteria game 
hand ai system handle general situations interacts optimally environment environment rational player conflicting goals 
strictly competitive strategic games 
restrict deterministic strictly competitive strategic games alternating moves 
player move round followed move player 
game rounds consists game theory games chess called extensive strategic reserved di erent kind game 
universal algorithmic agent aixi sequence alternating moves game cycle game final board situation evaluated 
player tries maximize player tries minimize simplest case player won game player won draw 
assume fixed game length independent actual move sequence 
games variable length maximal possible number moves add dummy moves pad length optimal strategy nash equilibrium players minimax strategy arg min max min max min 
arg max min max min 
note minimax strategy optimal players behave rationally 
instance player limited errors player able discover past moves exploit improve performance deviating minimax strategy 
classical game theory nash equilibria take account limited rationality ai agent 
ai model game playing 
demonstrate applicability ai model games 
ai system takes position player 
environment provides evaluation symmetric situation take second ai system player simplicity take environment second player assume environmental player behaves minimax strategy 
environment serves perfect player teacher albeit crude tells agent game won lost 
minimax behavior player expressed deterministic probability distribution sg sg arg min max min probability player move sg 
defined 
clearly ai system receives feedback 
game receive positive negative neutral feedback win loss draw 
environmental prior probability ai sg environment minimax player plus crude teacher ai true prior probability question behavior ai ai agent 
turns set ai agent minimax player optimal ai sg see hut formal proof 
playing sequence marcus hutter technical report idsia games special case described section identical factors equal episode lengths minimax environment ai behaves minimax strategy ai arg max min max min yx rn yx rn choice long horizon ai model game playing 
going specific ai model rules game explicitly modeled prior probability ai universal model ai ask rules learned assigned rewards main reason studying case repeated games just game arises 
single game cycle non trivial feedback game late useful games 
case repeated games limited feedback log bits information game outcomes win loss draw frequency 
game number games necessary learn game complexity game 
apart extremely simple games estimate far optimistic 
ai agent information game moves random win games merely pure luck 
probability agent loses near information content feedback game log 
situation remains large number games 
principle game learnable long sequence games minimal feedback long 
important point learning scheme extra information learn game quickly ai 
expect true ai factorizes case games fixed length ai satisfies strong separability condition 
case variable game length entanglement low 
ai su ciently separable allowing formulate prove reward bounds ai 
learn realistic games tic tac toe crosses realistic time provide feedback 
achieved intermediate help game 
environment give positive negative feedback bad move agent 
demand move valued adapted gained experience agent way approximately half moves half bad order maximize information content feedback 
complicated games chess feedback necessary practical point view 
way increase feedback far bits cycle train agent teaching moves 
called supervised learning 
despite fact ai model reward feedback able learn supervised shown section 
way start simple games containing certain aspects true game switch true game agent learned simple game 
universal algorithmic agent aixi di culties expected going 
eventually ai converge minimax strategy ai realistic case environment perfect minimax player ai detect exploit weakness opponent 
want comment input output space ai system 
practical applications possibly include illegal moves 
set moves robotic arm agent move wrong knock figures 
simple way handle illegal moves interpreting losing moves terminate game 
input image video camera shot move set moves environment includes set states game board 
discussion section handles case 
need explicitly design systems space specific game 
discussion ai agent informal reason game playing sg agent nearly complexity fully general ai quantitative results ai agent di cult impossible obtain 
function minimization fm applications examples 
problems reduced function minimization problem fm 
minimum real valued function ir domain approximate minimum usually limited resources 
popular example traveling salesman problem tsp 
set di erent routes towns length route task find route minimal length visiting cities 
problem np hard 
getting approximations limited time great importance various applications 
example minimization production costs mpc car constraints 
set alternative car designs production methods compatible specifications cost alternative related example finding materials bio molecules certain properties mat 
solids minimal electrical resistance maximally cient modifications aromatic molecules taste close possible 
ask nice paintings npt 
set existing imaginable paintings characterizes person likes painting agent paintings likes 
examples 
tsp rigorous mathematical point view algorithm usually known 
principle minimum exhaustive search computational resource limitations 
mpc modeled reliable su ciently accurate way 
mat need accurate physical models unavailable di cult solve implement 
npt judgement person painting 
evaluation function implemented scanning brain possible today technology 
di erent limitations depending application mind 
implementation available tested arguments marcus hutter technical report idsia determined environment 
want approximately minimize function calls possible conversely find close possible approximation minimum fixed number function evaluations 
available quickly inferred agent evaluation quick important minimize total time needed imagine new trial minimum candidates plus evaluation time consider computational aspects ai till section concentrate case available dominates computational requirements 
greedy model 
fm model consists sequence trial fm agent minimum true function value returned environment 
randomize model assuming probability distribution functions 
reasons doing 
really know exact function npt example model uncertainty probability distribution importantly want parallel ai classes sp model started probability distribution replaced get universal solomono prediction sp 
want thing 
probabilistic case includes deterministic case choosing ff true function 
final reason deterministic case trivial known agent internally virtually check function arguments output correct minimum 
assume countable finite discrete measure computable functions 
probability function values fm start model minimizes expectation function value output account previous information arg min 
type greedy algorithm just minimizing feedback su cient sequence prediction sp su cient classification cf described 
su cient function minimization example demonstrates 
take 
di erent functions shall equiprobable function expectation cycle just arithmetic average possible function values independent argmin defined take lexicographically minimum universal algorithmic agent aixi ambiguous case 
assume true environment function 
expectation agent knows expectation arithmetic average 
agent output feedback 
continue forever 
agent motivated explore smaller expectation 
obviously want 
greedy model fails 
agent ought try outputs time 
general reason failure greedy approach information contained feedback depends output fm agent actively influence knowledge receives environment choice may advantageous collect certain knowledge greedy sense nonoptimal choice minimize expectation immediately 
compensated long run exploiting knowledge 
sp received information current bit sequence independent sp predicts bit 
reason greedy strategy sp case optimal 
general fm model 
get useful model think carefully really want 
fm agent output minimum output limited number cycles average values minimal su ce just small possible 
subtle important di erences settings analyzed discussed detail hut 
concentrate minimizing average equivalently sum function values 
define fm model minimize sum building average summation minimizing performed correct chronological order 
similar reasoning get fm arg min min ym zm 
zm 
construction fm model guarantees optimal results usual sense model knowing expected produce better results 
interesting case ai unknown 
define case fm model replacing assign high probability functions low complexity 
define qx problem definition general undecidable tm implementation function defined way uncomputable approximable 
need analogous definition natural fm marcus hutter technical report idsia fm equivalent inserting uncomputable 
show fm enumerable semi measure dominates enumerable probability distributions form 
alternatively constrained sum analogous definitions equivalent 
definition ensures symmetry arguments fm yz yz incorporates general knowledge function minimization 
extra knowledge low information content complexity expect fm perform worse 
reason deviate point 
define loss fm argmin replaced min additionally replaced fm expect fm fm bounded way justifies computable computable deterministic case 
arguments ai model 
hut proven fm sense ceases searching minima test finite infinite set di erent infinite su ciently large horizon currently rigorous results quality guesses fm agent guesses optimal definition 
true distribution finite expect fm agent solve exploration versus exploitation problem universally optimal way converges ai models function 
ai model function minimization way 
output cycle guess minimum fm model 
reward high small function values 
choice reward natural 
feedback binary ir countable subset ir computable reals rational numbers 
feedback function value 
provided rewards set section 
change see choice really doesn matter set 
ai prior probability ai fm 
inserting show ai fm fm defined 
proof simple fm model general structure similar full ai model 
expect problem going fm ai 
thing ai model learn ignore feedbacks information contained task simple cycle provides data point simple function learn 

tsp trivial ai model non trivial ai model 
reason just implements internal complete search ff tsp see sol discussion symmetric universal distributions unordered data 
universal algorithmic agent aixi contains necessary information 
ai outputs exact minimum tsp solution course unacceptable performance perspective 
long give cient approximation contributed solution tsp ai true problem computable easily accessible 
tsp example done replace np complete problem uncomputable ai model computable ai model said computation time 
simply overkill reduce simple problems ai 
tsp simple problem respect consider ai model seriously 
examples inaccessible complicated ai model provide true solution minimization problem explicit definition needed ai ai computable version ai defined section 
supervised learning examples ex developed ai models provide frame reinforcement learning 
environment provides feedback informing agent quality earlier output assigns reward output sense reinforcement learning explicitly integrated ai models 
ai maximizes true expected reward ai model universal environment independent reinforcement learning algorithm 
type learning method supervised learning presentation examples ex 
problems learned method association problems type 
examples agent reconstruct partially missing corrupted parts complete relation contains cases consists pairs possibly missing part 
applications examples 
learning functions presenting pairs asking function value presenting 
falls category 
basic example learning properties geometrical objects coded way 
di erent objects characterized size small big colors red green blue shapes square circle object property object possesses property 
relation graph single valued function 
teaching child pointing objects saying tree look green beautiful establishes relation object property pairs pointing possibly di erent tree asking corresponds partially pair object missing part completed child saying tree 
final example want give chess 
seen principle chess learned reinforcement learning 
extreme case environment provides reward agent wins 
learning rate completely practical point view 
reason low amount information feedback 
practical method teaching chess example games form marcus hutter technical report idsia sensible board state move sequences 
contain information legal moves explanation 
games teacher ask agent move presenting board state 
evaluate answer agent 
supervised learning ai model 
define ex model follows environment presents inputs agent cycle 
agent expected output cycle evaluated 
simplify discussion output expected evaluated 

complete description environment probability distribution examples questions depending 
wrong examples occur relations probability distributed 
example prior probability case knowledge valuation output restricts possible relations consistent 
prior probability input sequence output sequence ai 
sequence 
dummies regular behavior starts example 
ai model optimal construction ai computable prior expect near optimal behavior universal ai model additionally satisfies separability property 
give motivation ai model takes account supervisor information contained examples learns faster reinforcement 
keep fixed assume 
simplify discussion 
short codes contribute ai 
distributed computable probability distribution short code large hu man code distribution expect coded dominant contributions ai way plausible assumption input tape matter 
bit cycle usually learned relation learned cycles appropriate examples 
coding evolves independently feedbacks maximize feedback agent learn output agent invent program extension extracts 
searches outputs coded re coding size extension order universal algorithmic agent aixi 
learn agent requires feedback information content 
compare reinforcement learning 
pairs 
coding short code absent 
rewards force agent learn expected size 
information content order 
practice learning phase information content bits 
required number cycles learn reinforcement cases larger 
ai designed told learn supervised learns take advantage examples supervisor 
learned examples rewards necessary process 
remaining task learning learn supervised simple task complexity rewards necessary 
aspects intelligence ai variety general ideas methods developed 
previous subsections seen problem classes formulated ai 
claim universality ai model want ai methods incorporated ai model looking structure 
methods directly included emergent 
claim list complete 
probability theory utility theory heart ai models 
probabilities true universal behaviors environment 
utility function called total reward maximized 
maximization expected utility function probabilistic environment usually called sequential decision theory explicitly integrated full generality model 
sense includes probabilistic generalization deterministic reasoning object reasoning true false statements prediction environmental behavior 
reinforcement learning explicitly built due rewards 
supervised learning emergent phenomenon section 
algorithmic information theory leads universal estimate prior probability horizon series process selecting maximal values may interpreted planning 
series form informed search case ai heuristic search ai interpreted heuristic minimax strategy game playing case ai subsumed 
ai model converges minimax strategy environment minimax player take advantage environmental players limited rationality 
problem solving occurs form maximize expected reward 
knowledge accumulated ai stored form specified working tape 
kind information representation inputs marcus hutter technical report idsia exploited 
problem knowledge engineering representation appears form train ai model 
practical aspects language image processing learned ai scratch 
theories fuzzy logic possibility theory dempster shafer theory partly outdated partly reducible bayesian probability theory che che 
interpretation consequences evidence gap yx yx may similar dempster shafer theory 
boolean logical reasoning external world plays best emergent role ai model 
methods don contained ai model emergent phenomena 
ai model construct short codes environmental behavior ai see section construct short action programs 
analyze interpret programs realistic environments find unused new ai methods programs 
pure speculation point 
important trying ai practically usable ai methods genetic algorithms neural nets may useful 
main thing wanted point ai model lack important known property intelligence known ai methodology 
missing computational aspects addressed section 
time bounded aixi model bothered non computability universal probability distribution 
universal models ective form 
section outline previous models results modified generalized time bounded case 
situation bad 
enumerable approximable exists algorithm produce sequence outputs eventually converging exact output sure reached 
convergence extremely slow type asymptotic computability direct practical important 
program calculates reasonable time cycle reasonable intelligent output sort computability assumption general purpose computer su cient power able behave intelligent way basis ai justifying hope able construct agents eventually reach outperform human intelligence 
contrary viewpoint see pen pen 
necessary discuss meant reasonable time intelligence su cient power 
interested section computable version ai ai agent superior equal computation time cycle superior mean intelligent need order relation intelligence 
best result think ai computation time intelligent computation time ai possible universal algorithmic agent aixi reached final goal construction intelligent algorithm computation time just universal measure set computable measures time ai may exist 
realistically hope construct ai agent computation time cycle constant idea run programs length time cycle pick best output 
total computation time sort idea typing monkeys eventually writing shakespeare applied various forms contexts theoretical computer science 
realization best vote idea case straightforward outlined section 
idea related basing decision majority algorithms 
democratic vote idea lw sequence prediction referred weighted majority 
time limited probability distributions literature find time limited versions kolmogorov complexity dal dal ko time limited universal lv lv sch 
utilize adapt see far get 
way define universal chronological sum enumerable chronological computation time size yx yx show reduces ai defined 
assume true environmental prior probability ai equal su ciently accurately approximated reasonable size 
ai problems fall class 
function minimization section computation fm feasible 
cases sequences section predicted easily calculated sp known 
classifier problem probability distribution cf examples cases elementary 
ai problems easy type 
strategic games section environment usually highly complex strategic player sg di cult calculate argue environmental player may limited capabilities 
easy think di cult calculate physical probabilistic environment chemistry 
number interesting applications restricted class ai problems time space bounded environment worth studied 
superscripts probability distribution indicate length maximal computation time 
defined determined computation time multiplicatively dominates type 
ai model prior probability universal relative ai models way ai universal ai enumerable chronological argmax selects marcus hutter technical report idsia highest expected utility km weighted average ai determined weighted majority 
expect ai outperform bounded ai analogous unrestricted case 
analyze computability properties ai ai compute definition enumerate chronological enumerable length computation time done similarly unbounded case described lv hut 
enumerable functions length computable time converted chronological probability distributions 
evaluate function di erent arguments 
computable time yx 
computation time ai depends size evaluated times 
possible optimize algorithm perform computation time ai cycle 
assume computation time exactly arguments brute force time calculating sums maxs ai combining get ai ai result proposed structure universal ai agent computation time times computation time special ai agent 
unfortunately class ai systems brute force evaluation completely uninteresting practical point view 
context chess result says ai superior time brute force minimax strategy computation time factor computation time matter ai agent practically useless brute force minimax chess player reasonable time poor player 
note case binary sequence prediction computation time coincides ai factor 
class ai includes non incremental sequence prediction algorithms size computation time 
non incremental mean information previous cycles taken account speeding computation current cycle 
shortcomings mentioned ones approach cured subsection deviating standard way defining time bounded sum functions programs 
idea best vote algorithm general agent chronological program form introduced section general include ai system intelligent systems 
assume tm simulated linear time 
universal algorithmic agent aixi interested programs length computation time cycle 
important point time limited setting incremental computing cycle information previous cycles stored working tape re 
probably practically interesting non incremental ai system 
construct policy precisely policies cycle outperform time length limited ai systems cycle runs programs selects best output best vote type algorithm compared weighted majority algorithm subsection 
ideal measure quality output expected reward km yx pq km pq km pq 
pq program maximizes km selected 
dropped normalization independent change order relation solely interested 
furthermore normalization km yx max km yx enumerable important 
extended chronological programs functional form ai model convenient maximize km consistent current history yx restriction possibly inconsistent program exists program consistent current history identical cycles time limited best vote algorithm restrictive demand prove universality compare algorithms cycle just consistent ones 
inconsistent algorithm may best cycles 
inconsistent programs include input yx possible 
necessary knows output case 
pq definition km valuations emerging sequence starting yx emerging continued applying problem need km select best policy unfortunately km uncomputable 
structure definition km similar brute force approach approximate km requires computation time solve problem similar way supplementing program estimates km time combine calculation extend notion chronological program yx chronological order 
marcus hutter technical report idsia valid approximations suggest output allowed rate arbitrarily high want reliable criterion selecting best demand policy allowed claim better define logical predicate va called valid approximation true satisfies km 
va yx km yx restrict attention programs va proven formal axiomatic agent 
important point km enumerable 
ensures existence sequences programs va proven lim km sequences 
may defined naive approximation scheme enumeration km terminated time steps approximation obtained far corresponding output convergence km ensures km claimed universally optimal value approximated provable arbitrarily time 
approximation uniform matter selected allowed change cycle cycle 
possibility consider check km online cycle pre check va constructing proof working tape special case km evident construction cases guarantee km sets trivially satisfies km hand problem prove va simply analyze internal structure recognize shows validity internally cycle cycle easy assumption cycle cycle check special case pre proof va 
ective intelligence order relation section introduced intelligence order relation ai systems expected reward km need order relation claimed reward interpreted approximation 
definition ective intelligence order relation call ectively equally intelligent yx yx yx claims higher reward estimate enumerable partial order relation extended chronological programs 
restricted valid approximations orders policies quality outputs ability justify outputs high universal algorithmic agent aixi universal time bounded aixi agent describe algorithm underlying universal time bounded ai agent 
essentially selection best algorithms time length bounded exists proof va length 
create binary strings length interpret coding mathematical proof formal logic agent va formulated 
take strings proofs va keep corresponding programs 
eliminate length 
modify way output temporarily written auxiliary tape 
stops steps internal output copied output tape 
steps forced arbitrary written output tape 
set modified programs 

start cycle 
run extended input yx outputs redirected auxiliary tape yx step performed incrementally adding yx input tape continuing computation previous cycle 

select program highest claimed reward argmax 
write output tape 

receive input environment 

cycle goto step 
easy see theorem holds 
theorem optimality extended chronological incremental program length computation time cycle exists proof va defined length algorithm constructed subsection depending ectively equally intelligent see definition size log tl setup time setup computation time cycle cycle 
roughly speaking theorem says exists computable solution ai problem explicitly constructed algorithm solution 
theorem quite general limitations open questions discuss 
construction algorithm needs specification formal logic system axioms inference rules 
proof sequence formulas formula axiom inferred previous formulas sequence applying inference rules 
details hut related construction textbook logic proof theory fit sho 
marcus hutter technical report idsia need know provability turing machines formalized 
setup time main theorem just time needed verify proofs needing time 
limitations open questions formally total computation time cycles increases linearly order coe cient unreasonably large factor known drawback best democratic vote models taken comments factor assumed reasonable size 
don take limit consider reasonable practical usefulness time bound somewhat limited due additional additive constant 
larger typically va superior justify outputs large 
possible produce outputs reasonable time takes unreasonably long time justify outputs su ciently high think certain complexity level onwards policies process constructing output completely separated sort justification process 
justification translatable reasonable time reasonable estimate km inconsistent programs able continue strategies started policies 
happen policy steers environment direction specialized 
foreign policy able displace loosely connected episodes 
probably problem think chess game usually di cult continue game strategy di erent player 
game usually advantageous replace player better game 
problem su ciently separable cient valid approximations va true provable long proof exists 
remarks idea suggesting outputs justifying proving reward bounds implements aspect human thinking 
possible reactions input 
reaction possibly far reaching consequences 
limited time tries estimate consequences possible 
reaction valued best selected 
inferior human thinking estimates rigorously proved proofs constructed blind exhaustive search behaviors length checked 
inferior sense necessary computation time sense quality outputs 
universal algorithmic agent aixi practical applications cases short slow programs performing task computation digits exist long quick programs 
di cult prove long program equivalent short possible prove time bounded kolmogorov complexity 
similarly method proving bounds km give high lower bounds explicitly executing short slow programs mainly contribute km dovetailing length time limited programs known elementary idea typing monkeys 
crucial part developed selection criterion intelligent agent 
construction ai due km ensuring arbitrary close approximations km expect behavior ai converges behavior ai limit sense 
depending know assume program size computation time cycle able achieve computable ai model capabilities 
strongest assumption existence turing machine outperforms human intelligence ai time frame unfortunately large constant factor 
discussion section reviews achieved article discusses topics general interest 
various topics including concurrent actions observations choice spaces treatment encrypted information peculiarities mortal embodies agents 
continue outlook research 
ideas various sections concentrate non technical open questions general importance including optimality scaling implementation approximation elegance extra knowledge training aixi tl 
include personal remarks non computable physics number wisdom consciousness 
article concludes 
general remarks section remarks topics general interest 
logically disconnected subsections discuss concurrent actions observations choice spaces treatment encrypted information peculiarities mortal embodies agents 
game theory 
game theory wants model situation simultaneous actions ai models serial simultaneity simulated withholding environment current agent output marcus hutter technical report idsia received agent 
formally means yx yx independent output ai agent simultaneous type view behavior interpreted action 
sense aixi action maximizes utility function reward assumption environment acts 
situation di erent game theory environment second player tries optimize utility see section 
input output spaces 
various examples chosen di erently specialized input output spaces clear principle unnecessary large spaces set strings length serve need turing reduced specific presentation needed internally aixi agent 
clear generic interface camera monitor learning tic tac toe example adds task learning vision drawing 
aixi tl deals encrypted information 
encrypt message key size give away key algorithm encryption size 
take key message encrypt message key 
system learn described length 
little information needed learn bits 
sense decryption easy 
problem may extremely slow algorithm finding prime factors public key rsa 
note aixi talking computation time talking information ciency learning number interaction cycles 
key ideas separate data ciency computation time ciency 
course real world computation time matters invented 
job best length time bounded agent apart time factor huge set time 
set time instance rsa example find factorization decryption easy course 
mortal embodied agents 
examples gave article particularly section mainly agents predictors optimizers learners 
peculiarities reinforcement learning autonomous embodied robots real environments 
reward robot solves task want 
minimal requirement robot hardware functions properly 
robot starts malfunction capabilities degrade resulting lower reward 
attempt maximize reward robot maintain 
problem parts malfunction quickly appropriate actions performed flat batteries time 
worse robot may perfectly battery nearly empty suddenly operation death resulting minimal zero reward 
little time learn maintain late 
autonomous embodied robot start scratch rudimentary built capabilities may rudimentary allows survive 
animals survive due reflexes innate behavior internal reward attached condition organs guarding environment childhood 
universal algorithmic agent aixi di erent species emphasize di erent aspects 
reflexes innate behaviors stressed lower animals versus years safe childhood humans 
variety solutions available constructing autonomous robots detail 
problem connected possibly limited embodied agents especially rewarded humans su ciently intelligent agents may increase rewards psychologically manipulating human teachers threatening 
general sociological problem successful ai cause specifically aixi 
intelligence superior humans capable manipulating 
absence manipulable humans reward structure serves survival function aixi may directly hack reward feedback 
increase long term survival aixi probably resist kind manipulation humans don take hard drugs due long term catastrophic consequences 
outlook open questions ideas studies stated various sections article especially problems sections 
outlook contains non technical open questions regarding aixi tl general importance 
value bounds 
rigorous proofs non asymptotic value bounds ai major theoretical challenge general ones tighter bounds special environments rapidly mixing mdps 
aixi performance criteria proved 
necessary practical point view study continuous classes restricted policy classes infinite may lead useful insights 
scaling aixi 
direct implementation model best possible toy environments due large factor computation time 
applications aixi theory 
seen examples integrate problem classes aixi model 
conversely ai model restricted forms 
done way theory universal induction insights minimum description length principle lv ris domain finite automata fmg 
aixi model similarly serve super model definition universal unbiased intelligence specialized models derived 
implementation approximation 
reasonable computation time aixi model solution ai see point disagree 
model step elimination factor giving universality certainly di cult task 
try select programs prove va clever way mere enumeration improve performance destroying universality 
kinds ideas genetic algorithms advanced theorem provers see hut elegant theoretical solution 
marcus hutter technical report idsia incorporated 
problem 
computability 
transferred ai problem just di erent level 
shift advantages disadvantages presents way solution 
want stress reduced ai problem mere computational questions 
general systems author aware depend complexity assumptions environment far clear universally optimal 
computational questions highly complicated reduction non trivial result 
formal theory computable great step solving problem merits ai di erent respect see previous item 
elegance 
researchers ai believe intelligence complicated condensed formulas 
combining methods explicit knowledge right way 
theoretical point view disagree aixi model simple serve needs 
practical point view agree extent reduce computational burden provide special purpose algorithms methods probably related reduce complexity input output spaces appropriate pre post processing methods 
extra knowledge 
need incorporate extra knowledge 
cycles format 
long algorithm interpret data size aixi agent understand data cycles see section 
environment complicated extra knowledge small show bound reduces roughly ln cycle 
special purpose algorithms cheating say special purpose algorithms implemented aixi 
boundary implementation training aixi model 
training 
said training process specific aixi model discussed literature various forms disciplines sol sch 
serious discussion place 
repeat course important knowledge evaluate agent output reasonable way 
maximize information content reward start simple tasks give positive reward approximately better half outputs big questions subsection devoted big questions ai general aixi model particular personal touch 
non computable physics brains 
possible objections ai universal algorithmic agent aixi general aixi particular 
non computable physics weird turing computable ai impossible 
world relevant humans mainly computable believe necessary integrate non computable devices ai system 
clever nearly convincing godel argument penrose pen pen non computational physics exist relevant brain opinion convincing loopholes 
evolution number wisdom 
serious problem evolutionary information gathering process 
shown number wisdom contains compact tabulation undecidable problems binary digits cha 
enumerable computation time increasing rapidly recursive function 
enormous computational power evolution developed coded genes significantly guides human reasoning 
short intelligence complicated evolution cleverly designed algorithm size slow 
evolution taken place add information genes brain structure ai system means important part missing principally impossible derive cient algorithm simple formal definition ai 
consciousness 
probably biggest question consciousness want give physical analogy 
quantum field theory accurate universal physical theory invented 
developed big question regarding interpretation wave function collapse open 
extremely interesting philosophical point view completely irrelevant practical point view believe valid consciousness field artificial intelligence 
philosophically highly interesting practically unimportant 
consciousness explained day question 
major theme article develop mathematical foundation artificial intelligence 
easy task intelligence ill defined faces 
specifically goal develop theory rational agents acting optimally environment 
touched various scientific areas including reinforcement learning algorithmic information theory kolmogorov complexity computational complexity theory information theory statistics solomono induction levin search sequential decision theory adaptive control theory 
started observation tasks require intelligence solved naturally formulated maximization expected utility framework agents 
functional iterative formulation decision theoretic agent section general cover ai problem classes demonstrated examples 
main remaining problem unknown theory collapse practical importance solved 
marcus hutter technical report idsia prior probability distribution environment 
conventional learning algorithms unsuitable handle large unstructured state spaces converge theoretically minimal number cycles handle nonstationary environments appropriately 
hand solomono universal ideas algorithmic information theory solves problem unknown prior distribution induction problems demonstrated section 
explicit learning procedure necessary automatically converges unified theory universal sequence prediction decision theoretic agent replacing unknown true prior appropriately generalized universal section 
gave various arguments resulting aixi model intelligent parameter free environmental application independent model possible 
defined intelligence order relation give rigorous meaning claim 
furthermore possible solutions horizon problem discussed 
section outlined aixi model solves various problem classes 
included sequence prediction strategic games function minimization especially learning learn supervised 
list easily extended problem classes classification function inversion 
major drawback aixi model uncomputable precisely asymptotically computable implementation impossible 
overcome problem constructed modified model ectively intelligent time space bounded algorithm section 
computation time order way overcoming large multiplicative constant hut expense unfortunately larger 
possible research discussed 
main directions prove general special reward bounds aixi super model explore relation specialized models improve performance giving universality 
results show artificial intelligence framed elegant mathematical theory 
progress elegant computational theory intelligence 
annotated bibliography introductory textbooks 
book hopcroft ullman new revision authored motwani readable elementary automata theory formal languages computation theory 
artificial intelligence book rn russell norvig gives comprehensive overview ai approaches general 
excellent algorithmic information theory kolmogorov complexity solomono induction consult book li vitanyi lv 
reinforcement learning book sutton barto sb requires background knowledge describes key ideas open problems great applications field 
tougher rigorous book bertsekas tsitsiklis sequential decision theory provides convergence proofs ber 
universal algorithmic agent aixi algorithmic information theory 
kolmogorov kol suggested define information content object length shortest program computing representation 
solomono sol invented closely related universal prior probability distribution binary sequence prediction sol sol function inversion minimization sol 
chaitin cha cha invention called algorithmic information theory 
literature applications see lv 
interesting applications cha sch vw 
related topics weighted majority algorithm invented littlestone warmuth lw universal forecasting vovk levin search lev pac learning introduced valiant val minimum description length lv ris 
resource bounded complexity discussed dal dal fmg ko pf resource bounded universal probability lv lv sch 
implementations rare mainly due schmidhuber con sch sch 
excellent reviews philosophical touch lv sol 
older general review inductive inference see angluin 
sequential decision theory 
ingredient ai model sequential decision theory 
need maximum expected utility principle algorithm mic rn 
book von neumann morgenstern nm seen initiation game theory contains algorithm special case 
literature reinforcement learning sequential decision theory vast refer textbooks sb bt 
author contributions 
issues addressed article scattered various reports publications author ai model introduced discussed march hut page long report 
succinct descriptions published hut hut 
ai model argued formally solve number problem classes including sequence prediction strategic games function minimization reinforcement supervised learning hut 
variant ai shown self optimizing pareto optimal hut 
construction general fastest algorithm defined problems hut arose construction time bounded ai tl model hut 
tight hut error hut hut loss hut bounds solomono universal sequence prediction scheme proven 
loosely related ideas market economy reinforcement learner gradient reinforcement planner implemented 
papers available www idsia ch marcus ai 

am indebted proof read article 
angluin smith 
inductive inference theory methods 
acm computing surveys 
bel bellman 
dynamic programming 
princeton university press new jersey 
marcus hutter technical report idsia ber bertsekas 
dynamic programming optimal control vol 
ii 
athena scientific belmont massachusetts 
volumes 
bt bertsekas tsitsiklis 
neuro dynamic programming 
athena scientific belmont ma 
cha chaitin 
length programs computing finite binary sequences 
journal acm 
cha chaitin 
theory program size formally identical information theory 
journal acm 
cha chaitin 
algorithmic information evolution 
nicolis perspectives biological complexity press pages 
che cheeseman 
defense probability 
joshi editor proceedings ninth international joint conference artificial intelligence pages los altos california 
morgan kaufmann 
che cheeseman 
inquiry computer understanding 
computational intelligence 
con conte genetic programming estimates kolmogorov complexity 
genetic algorithms proceedings th international conference pages 
cox cox 
probability frequency reasonable expectation 
american journal physics 
dal daley 
minimal program complexity sequences restricted resources 
information control 
dal daley 
inference optimal descriptions 
theoretical computer science 
daw dawid 
statistical theory 
prequential approach 
statist 
soc 

fit melvin fitting 
order logic automated theorem proving 
graduate texts computer science 
springer verlag berlin nd edition 
fmg feder merhav gutman 
universal prediction individual sequences 
ieee transactions information theory 
ft fudenberg tirole 
game theory 
mit press cambridge massachusetts 
gac 
symmetry algorithmic information 
russian academy sciences doklady 
mathematics soviet mathematics doklady 
hopcroft motwani ullman 
automata theory language computation 
addison wesley nd edition edition 
hut hutter 
theory universal artificial intelligence algorithmic complexity 
technical report cs ai pages 
arxiv org abs cs ai 
hut hutter 
convergence error bounds universal prediction general alphabet 
proceedings th conference machine learning ecml pages 
hut hutter 
general loss bounds universal sequence prediction 
proceedings th international conference machine learning icml pages 
hut hutter 
new error bounds solomono prediction 
journal computer system sciences 
universal algorithmic agent aixi hut hutter 
universal theory artificial intelligence algorithmic probability sequential decisions 
proceedings th conference machine learning ecml pages 
hut hutter 
universal sequential decisions unknown environments 
proceedings th european workshop reinforcement learning 
hut hutter 
fastest shortest algorithm defined problems 
international journal foundations computer science 
hut hutter 
optimality universal bayesian sequence prediction 
submitted 
www idsia ch marcus ai ps 
hut hutter 
self optimizing pareto optimal policies general environments bayes mixtures 
proceedings th annual conference computational learning theory colt lecture notes artificial intelligence pages sydney australia 
springer 
hutter schmidhuber 
gradient reinforcement planning policy search methods 
proceedings th european workshop reinforcement learning 
hutter schmidhuber 
market reinforcement learning partially observable worlds 
proceedings international conference artificial neural networks icann pages 
klm kaelbling littman moore 
reinforcement learning survey 
journal ai research 
ko 
ko 
notion infinite pseudorandom sequences 
theoretical computer science 
kol kolmogorov 
approaches quantitative definition information 
problems information transmission 
kv kumar varaiya 
stochastic systems estimation identification adaptive control 
prentice hall englewood cli nj 
lev levin 
universal sequential search problems 
problems information transmission 
lev levin 
laws information conservation non growth aspects foundation probability theory 
problems information transmission 
lv li vitanyi 
learning simple concepts simple distributions 
siam journal computing 
lv li vitanyi 
inductive reasoning kolmogorov complexity 
journal computer system sciences 
lv li vitanyi 
philosophical issues kolmogorov complexity invited lecture 
kuich editor proceedings automata languages programming icalp volume lncs pages berlin germany 
springer 
lv li vitanyi 
kolmogorov complexity applications 
springer nd edition 
lw littlestone warmuth 
weighted majority algorithm 
th annual symposium foundations computer science pages research triangle park north carolina 
ieee 
lw littlestone warmuth 
weighted majority algorithm 
information computation 
marcus hutter technical report idsia mic michie 
game playing game learning automata 
fox editor advances programming non numerical computation pages 
pergamon new york 
nm von neumann morgenstern 
theory games economic behavior 
princeton university press new jersey 
osborne rubenstein 
course game theory 
mit press cambridge massachusetts 
pen penrose 
emperor new mind 
oxford 
pen penrose 
shadows mind search missing science consciousness 
oxford univ press 
pf 
forecasting algorithm information theory 
technical report centre universitaire informatique university geneva 
ris rissanen 
stochastic complexity statistical inquiry 
world scientific publ 

rn russell norvig 
artificial intelligence 
modern approach 
prentice hall englewood cli 
sb sutton barto 
reinforcement learning 
cambridge ma mit press 
sch schmidhuber 
discovering neural nets low kolmogorov complexity high generalization capability 
neural networks 
sch schmidt 
time bounded kolmogorov complexity may help search extra terrestrial intelligence seti 
bulletin european association theoretical computer science 
sch schmidhuber 
optimal ordered problem solver 
technical report idsia idsia 
sch schmidhuber 
speed prior new simplicity measure yielding near optimal computable predictions 
kivinen sloan editors proceedings th annual conference computational learning theory colt lecture notes artificial intelligence pages sydney australia july 
springer 
sho shoenfield 
mathematical logic 
addison wesley 
sol solomono 
formal theory inductive inference part 
inform 
control 
sol solomono 
complexity induction systems comparisons convergence theorems 
ieee trans 
inform 
theory 
sol solomono 
applications algorithmic probability artificial intelligence 
uncertainty artificial intelligence pages 
elsevier science publishers 
sol solomono 
discovery algorithmic probability 
journal computer system sciences 
sol solomono 
kinds probabilistic induction 
computer 
schmidhuber zhao wiering 
shifting inductive bias success story algorithm adaptive levin search incremental self improvement 
machine learning 
val valiant 
theory learnable 
communications acm 
universal algorithmic agent aixi vovk 
universal forecasting algorithms 
information computation 
vw vovk watkins 
universal portfolio selection 
proceedings th annual conference computational learning theory colt pages new york 
acm press 
index accessibility action random actions concurrent adaptive control agent intelligent agents embodied immortal lazy mortal ai model equivalence recursive iterative form special aspects ai model axiomatic approach general bayes mixture optimality pareto optimality structure optimality aixi model approximation computability implementation algorithm best vote incremental non incremental alphabet angluin animals approximation aixi model value valid artificial intelligence elegant complex asymmetry asymptotic convergence learnability autonomous robots average reward axiomatic approach ai model barto bayes rule bayes mixture general innate bellman bertsekas bias boosting bound bound boost value bounds value brain non computable chaitin chaos cheeseman chronological function order turing machine complete history complexity input sequence kolmogorov computability aixi model concept class restricted concepts separability concurrent actions observations universal algorithmic agent aixi consciousness consistency consistent policy constants conte control adaptive convergence asymptotic finite uniform cox cryptography rsa cybernetic systems cycle daley dawid decision suboptimal wrong decryption degree belief deterministic environment di erential gain discounting harmonic universal dynamic horizon ciency embodied agents encrypted information environment deterministic forgetful inductive markovian passive probabilistic pseudo passive real stationary uniform environmental class limited episode evolution expected utility algorithm tree experiment expert advice prediction exploitation exploration environment fair coin flips environment dynamic feder feedback negative positive finite convergence fitting fixed horizon forgetful environment fudenberg functional form godel incompleteness gain di erential game theory general bayes mixture general bayes mixture ai model marcus hutter technical report idsia generalization techniques generalized universal prior genetic algorithms greedy gutman harmonic discounting example history complete hopcroft horizon choice dynamic fixed infinite problem human humans hutter sequence image immortal agents implementation aixi model inconsistent policy incremental algorithm independent episodes inductive environment infinite horizon information encrypted input regular reward input device input space choice input word intelligence ective order intermediate order relation intermediate intelligence internal reward iterative formulation kaelbling knowledge incorporate ko kolmogorov complexity kolmogorov kolmogorov complexity time limited kumar lazy agents learnable asymptotically task learning reinforcement rate levin li lifetime limited environmental class limits littlestone littman manipulation markov markovian th order environment maximize reward merhav michie universal algorithmic agent aixi model ai universal monitor monte carlo moore morgenstern mortal agents intelligent agent motwani neumann noise noisy world non computable brain physics non deterministic world non perfect norvig number wisdom observations concurrent example optimal policy optimality ai model universal order relation ective intelligence intelligence universal osborne output output device output space choice output word pareto optimality ai model passive environment penrose perception perfect physical random processes physics non computable quantum wave function collapse policy consistent extended chronological inconsistent optimal restricted class self optimizing policy iteration prediction expert advice prefix property prequential approach probabilistic environment probability distribution probability distribution conditional problem horizon relevant solvable program extended chronological proof pseudo passive environment quantum physics random action real environment recursive formulation reduction state space reflex marcus hutter technical report idsia reinforcement learning relevant problem restricted concept class restricted domains reward average internal maximize total rissanen robots autonomous rsa cryptography rubenstein russell scaling aixi schmidhuber schmidt self optimizing policy self self universal time limited separability concepts sequence training sequences set prefix free shoenfield smith solomono solvable problem state environmental internal stationarity stationary environment string empty length strings structure ai model suboptimal decision sutton tape bidirectional unidirectional task learnable theorem provers theory see particular theory time bound tirole training sequence tsitsiklis turing machine chronological head typing monkeys ullman underline uniform convergence environment universal ai model discounting generalized prior optimality order relation time limited universe utility expected valiant valid approximation value value bound universal algorithmic agent aixi bounds justification valid approximation value iteration varaiya video camera vitanyi vote best democratic vovk warmuth watkins wave function collapse wiering zhao 
