proceedings conference empirical methods natural language processing emnlp philadelphia july pp 

association computational linguistics 
kernel methods relation extraction dmitry aone anthony dmitry aone anthony sra com sra international fair lakes ct fairfax va usa application kernel methods extracting relations unstructured natural language sources 
introduce kernels defined low parse representations text design efficient algorithms computing kernels 
devised kernels conjunction support vector machine voted perceptron learning algorithms task extracting person affiliation organization location relations text 
experimentally evaluate proposed methods compare feature learning algorithms promising results 
information extraction important unsolved problem nlp 
problem extracting entities relations text documents 
examples entities people organizations locations 
examples relations person affiliation organization location 
relation means particular person affiliated certain organization 
instance sentence john smith chief scientist contains person affiliation relation person john smith organization 
address problem extracting relations natural language text 
propose machine learning approach relation extraction novel methodology information extraction kernel methods vapnik cristianini shawe taylor 
believe shallow parsing important prerequisite information extraction 
shallow parsing provides robust mechanism producing text representations effectively entity relation extraction 
step relation extraction approach powerful shallow parsing compo nent information extraction system aone ramos 
system com cascading finite state machines identify names noun phrases restricted set parts speech text 
system classifies noun phrases names refer people organizations locations producing entities 
input relation extraction system shallow parse noun phrases names marked relevant entity types 
relation extraction problem shallow parse classification problem section 
shallow parse turned example label reflects relation interest expressed shallow parse 
learning system uses labeled examples output model applied shallow parses obtain labels extract relations 
unique property kernel methodology explicitly generate features 
precisely example longer feature vector common machine learning algorithms 
examples retain original representations shallow parses learning algorithms computing similarity kernel function 
examples allows learning system implicitly explore larger feature space computationally feasible processing feature learning algorithms 
conduct experimental evaluation approach section 
compare approach feature linear methods roth promising results 
related information extraction problem relation extraction natural language texts previously addressed message understanding conferences muc 
number systems developed relied parsing manual pattern development identifying relations interest see example aone 
adaptive system miller aegis muc lexicalized probabilistic context free grammars augmented semantic information produce semantic parse text detecting organization location relations 
popular probabilistic formalisms information extraction hid den markov models hmm bikel maximum entropy markov models memm conditional random fields crf lafferty 
online learning algorithms learning lin ear models perceptron winnow coming increasingly popular nlp problems roth 
algorithms exhibit num ber attractive features incremental learning scalability large number examples 
applications shallow parsing munoz information extraction roth yih exhibit state art performance 
linear models feature imposes constraints exploiting long range dependencies text 
section compare kernel function similarity function satisfy ing certain properties see cristianini shawe taylor details 
methods approach relation extraction problem 
introduce class kernel machine learning methods apply relation ex traction 
kernel machine learning learning algorithms rely feature representation objects 
object transformed collection features fn producing dimensional vector 
cases data easily expressed features 
example nlp problems feature representations produce inherently local representations objects computationally infeasible generate features involving long range dependencies 
kernel methods vapnik cristianini shawe taylor attractive alter native feature methods 
kernel meth ods retain original representation objects objects algorithms com puting kernel similarity function pair objects 
cases may possible compute similarity function terms certain features enumerating features 
excellent example subsequence kernels lodhi 
case objects strings characters similarity kernel function computes number common subsequences characters strings 
de spite exponential number features subsequences possible compute sub sequence kernel polytime 
able take advantage long range features strings enumerating features explicitly 
section extend subsequence kernel operate shallow parses relation extraction 
pertinent example parse tree kernels collins duffy ob jects represent trees kernel function computes number common subtrees trees 
tree kernel voted perceptron learning algorithm freund schapire shown deliver excel lent performance improving penn treebank parsing 
number learning algorithms operate kernels examples 
models produced learning algorithms expressed examples kernels 
algorithms process examples computing kernels called dual learning algorithms 
support vector machine svm cortes vapnik learning algorithm allows dual formulation provides rigorous rationale resisting fitting vapnik 
discovery kernel methods existing learning algorithms shown dual analogues 
instance perceptron learning algorithm easily represented dual form cristianini shawe taylor 
variance reducing improvement perceptron voted freund schapire ro bust efficient learning algorithm easy implement 
shown exhibit performance comparable svm 
section experimentally evaluate svm voted perceptron relation extraction 
show formalize relation ex traction learning problem 
problem formalization consider sentence john smith chief scientist 
shallow parsing system produces representation sentence shown 
convert shallow parse tree examples person affiliation relation 
type relation holds person organization 
nodes shallow parse tree referring people john smith node type person pnp nodes 
organization node tree refers organization 
create example person affiliation relation person node organization note tree produced know person pnp nodes refer person 
dt tv 
type der type shallow parse representation sentence john smith chief scientist hard corn types pnp der prep denote personal noun phrase determiner adjective preposition respectively 
node shallow parse tree assigning attributes nodes specifying role node plays person affiliation relation 
person organization consideration receive member affiliation roles respectively 
rest nodes receive roles reflecting participate relation 
attach label example asking question node role member node role affiliation semantically affiliated sentence 
sentence generate positive examples shown 
note generating examples pnp organization eliminated nodes belong common subtree organization pnp removing irrelevant subtrees 
summarize relation example shallow parse nodes augmented role attribute node shallow parse belongs common subtree comprising relation entities consideration 
formalize notion relation ex ample 
define notion example node 
definition node set attributes 
attributes named 
denote value attribute name node type person role member 
example ence label type person type pnp text smith role oe head scientist role member coq 
head scientist pnp label head scientist role nber text text role oe role head scientist role label role text text role role affiliation person affiliation examples generated shallow parse 
label means examples express rela tion 
definition unlabeled relation example defined inductively follows node pair relation example denote empty sequence 
node pt sequence relation examples 
pair pt relation example 
say parent 
pt children denote element example pair second element example pair shorthand refer denote 
labeled relation example unlabeled relation example augmented label 
example positive negative 
define kernels relation examples represent similarity shallow parse trees 
kernels relation extraction kernels parse trees previously defined collins duffy 
kernels enumerated implicitly subtrees parse trees number common subtrees weighted appropriately measure similarity parse trees 
operating shallow parse trees focus problem relation extraction parsing different definition kernels 
define matching function similarity function nodes 
matching function defined nodes de nodes 
example nodes may types roles match 
nodes roles ble types node matching function equal equal 
similarity function nodes computed terms nodes attributes 
relation examples de fine similarity function terms similarity function parent nodes similarity function kc children 
formally means kc different definitions similarity function kc children give rise different 
give general definition kc terms similarities children subsequences 
intro duce helpful notation similar lodhi 
denote sequence indices say sequence indices 
length sequence relation example denote sequence children 
distinct types compatible example pnp may compatible person 
similarity function denote pl js 
de fine similarity function kc follows kc ct ij ij 
js formula enumerates subsequences relation example children matching parents accumulates similarity subsequence adding corresponding child examples similarities decreases similarity factor spread subsequences children sequences 
similarity children sequences sum matching subsequences similarities 
theorem states define kernel mild assumptions proof omitted lack space 
theorem kernels nodes 
defined kernel relation examples 
consider special case kc subsequences assumed contiguous give efficient algorithm computing kc 
section address general case subsequences allowed sparse non contiguous 
contiguous subtree kernels contiguous subtree kernels similarity function kc enumerates children contiguous subsequences subsequence 
slightly abuse notation section making stand formula 
kc pi 
ii core kernel computation resides formula 
formula enumerates contiguous subsequences children sequences 
give fast algorithm computing kc ker nel values children runs time ran ra number children respectively 
kc computed suffixes children sequences subsequence starts indices respectively 
xl ij length longest sequence matching states children starting indices respectively max recurrences hold boundary conditions ln ln recurrence follows observation match matching pair cl sequences participated computation extended matching pair pi cl 
easily compute kc 
time space complexity kc compu tation ran kernel values children 
relation examples complex ity computing pi sum computing kc matching internal nodes complexities constant 
sparse subtree kernels sparse subtree kernels general definition similarity children se quences expressed 
previous section give efficient algorithm computing kc 
algorithm runs time mn ker nel values children number children respectively 
derivation efficient programming algorithm sparse subtree computation full version lack space 
list recurrences computing kc 
kc ra kc ra kc akc cq cq acq cq cq acq pi cq ac cq xc cq ac pl 
cq boundary conditions kc min cq min min cq min min seen recurrences time complexity algorithm ran assuming 
space complexity mn 
experiments section apply kernel methods extracting types relations text person affiliation ion ion 
person organization part person affiliation relation person member employed organization 
founder example defined affiliated stated happens employee 
organization location part organization location relation organization headquarters location 
single division located particular city necessarily located city 
nuances relation definitions extraction problem difficult allow fine grained distinctions relationships connect entities text 
experimental methodology text corpus experiments comprises news articles different news agencies publications associated press wall street journal washington post los angeles times philadelphia inquirer 
existing shallow parsing system generate shallow parses news articles 
generated relation examples shallow parses relations described section 
retained examples shallow parsing system major mistakes generated examples labeled retained exam ples expressed relation obtained positive examples person affiliation relation positive examples org location relation 
relation randomly split set examples training set examples testing set examples 
obtained models running learning gorithms kernels appropriate training set testing models test set computing performance measures 
order get stable performance estimates averaged performance results random train test splits 
report standard performance esti mates precision recall measure experiment 
describe experimental setup algorithms evaluation 
kernel methods configuration evaluated kernel learning algorithms support vector machine svm cortes vapnik voted perceptron freund schapire 
svm joachims implementation algorithm custom kernels incorporated 
implemented voted perceptron algorithm described freund schapire 
implemented contiguous sparse subtree kernels incorporated kernel learning algorithms 
kernels set 
domain specific information kernels encapsulated matching similarity functions nodes 
class type class type pi text text normalized computed kernels algorithms 
normalization corresponds standard unit norm normalization examples feature space corresponding kernel space cristianini shawe taylor pi linear methods configuration evaluated feature algorithms learning linear discriminant functions naive bayes duda hart winnow littlestone 
function class combines types single equivalence class class pnp person class organization class lnp location class type type types 
implemented algorithms spirit snow system roth 
algorithms learn models exam ple produce score label predict label corresponding larger score 
algorithms feature designed features relation extraction problem 
features conjunctions conditions involving text type role attributes neighboring example nodes 
list features lack space 
experimental results performance results relation extraction shown table 
results indicate kernel methods exhibit excellent performance fare better feature algorithms relation extraction 
results highlights importance kernels algorithms sparse subtree kernels significantly better contiguous counterparts 
results show performance voted perceptron accurate compared algorithms organization location relation person affiliation relation 
phenomenon probably attributed fact organization location examples noisy boundary cases 
training set regularization performed svm crucial noise tolerant perceptron voting mechanism 
performance naive bayes organization location relation notable performs better elaborate algorithms 
approach kernel machine learning methods extracting relations natural language sources 
defined kernels shallow parse representations text designed efficient dynamic programming algorithms computing kernels 
applied svm voted perceptron learning algorithms kernels incorporated person affiliation org location recall precision measure recall precision measure naive bayes winnow voted perceptron contig 
svm contig 
voted perceptron sparse svm sparse table relation extraction performance percentage points tasks relation extraction 
com pared performance kernel methods feature methods concluded kernels lead superior performance 
intend apply kernel methodology sub problems information extraction 
example shallow parsing entity extraction mechanism may learned combined seam fashion relation extraction formal ism 
furthermore realworld extraction results requires discourse resolution collapses entities noun phrases pronouns set equivalence classes 
plan apply kernel methods discourse processing 
supported darpa evidence extraction link discovery pro gram 
aone ramos 

rees largescale relation event extraction system 
proceedings anlp 
aone halverson hampton 

sra description system muc 
proceedings muc 
bikel schwartz weischedel 

algorithm learns name 
machine learning 
collins duffy 

convolution kernels natural language 
proceedings nips 
cortes vapnik 

support vector net works 
machine learning 
cristianini shawe taylor 

support vector machines learning methods 
cup duda hart 

pattern classification scene analysis 
john wiley new york 
freund schapire 

large margin classification algorithm 
machine learning 
cristianini duffy schummer haussler 

support vector machine classification validation cancer tissue samples microarray expression 
bioinformatics 
haussler 

convolution kernels discrete struc tures 
uc santa cruz technical report ucs 
joachims 

text categorization support vector machines learning relevant features 
proceedings ecml 
joachims 

learning text classifiers support vector machines 
kluwer academic publishers dordrecht nl 
lafferty 

conditional random fields probabilistic models segmenting labeling sequence data 
proceedings icml 
littlestone 

learning quickly irrelevant attributes abound new linear threshold algorithm 
machine learning 
lodhi saunders shawe taylor cristianini watkins 

text classification string kernels 
journal machine learning research 
freitag 

maximum entropy markov models information extraction segmentation 
proceedings international conference machine learning 
miller crystal fox ramshaw schwartz stone weischedel 

algorithms learn extract information bbn description sift system 
proceedings muc 
munoz punyakanok roth 

learning approach shallow parsing 
tr university illinois urbana champaign 
roth yih 

relational learning propositional algorithms information extraction case study 
proceedings 
roth 

learning natural language 
proceedings ijcai 
vapnik 

statistical learning theory 
john wiley 
