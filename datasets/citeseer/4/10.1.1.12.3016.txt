relating new language models information retrieval traditional retrieval models hiemstra de vries university twente ctit box ae enschede netherlands hiemstra en ctit 
nl years exciting new approaches information retrieval introduced number different research groups statistical language models retrieval 
relates retrieval algorithms suggested approaches widely accepted retrieval algorithms developed traditional models information retrieval boolean model vector space model probabilistic model 
shows ex efficient retrieval algorithms matching terms computation 
conditions language models information retrieval surprisingly similar tf 
weighting developed vector space model relevance weighting developed traditional probabilistic model 
suggests new method relevance weighting new method rank documents giving boolean queries 
experimental results trec collection indicate language modelling approach outperforms traditional approaches 
information retrieval areas natural language processing statistics successfully applied 
models ranked retrieval developed late early today salton vector space model robertson sparck jones probabilistic model 
despite success real breakthrough statistical models natural language processing come information retrieval community speech recognition community 
statistical techniques successfully applied speech shannon noisy channel model gram models hidden markov models today sorts applications instance part speech tagging optical character recognition statistical translation stochastic context free grammars 
shown statistical language models successfully applied speech model information retrieval 
past years show remarkably large number publications statistical language models compute ranking documents query 
ponte croft suggest language models information retrieval :10.1.1.54.6410
estimation risk functions overcome problem small sample sizes 
hiemstra kraaij introduce ranking linear interpolation global local probabilities publications groups 
miller hidden markov models ranking including bi grams model word phrases method performing blind feedback 
berger lafferty developed model includes statistical translation model synonyms related words :10.1.1.43.7803:10.1.1.43.7803
similar model developed cross language information published ctit technical report tr ctit may www ctit utwente nl retrieval hiemstra de jong kraaij 
ng introduced model uses ratio conditional probability query document prior probability query including method query expansion 
song croft model includes bi grams introduced turing re estimation smooth document models 
adds discussion showing language models information retrieval fact similar traditional retrieval models 
shows existence efficient retrieval algorithms matching terms computation 
conditions language models information retrieval interpreted belonging family tf 
idf term weighting algorithms developed traditional vector space model 
conditions language models interpreted odds probability relevance traditional probabilistic model information retrieval introducing new method relevance weighting search terms 
introduces new method rank documents boolean queries 
traditional retrieval models section gives brief description retrieval models think influential modern information retrieval research vector space model probabilistic model boolean model 
section mentions history gives indication models stand today 
vector space model traditional vector space model best characterised attempt rank documents similarity query document 
calculations vector space model geometry term dimension multidimensional space queries documents points vectors space similarity usually measured cosine measure computes angle vectors 
documents queries weighted vectors element weights cosine measure defined similarity el dk qk second major achievement researchers developed vector space model family tf 
idf term weights 
weights term frequency tf factor measuring frequency occurrence terms document query texts inverse document frequency idf factor measuring inverse number documents contain query document term 
cosine measure vector lengths normalised 
components tf idf length normalisation calculated various formulas reported letter combination 
weighting algorithms lnu ltu uses combination document length average document length cosine measure length normalisation :10.1.1.50.9950
algorithm outperforms cosine versions trec collections lacks metaphor measuring angle vectors 
probabilistic model important characteristic probabilistic model attempt rank documents probability relevance query 
documents queries represented binary vectors vector element indicating document attribute term occurs document query 
probabilities probabilistic model uses odds means document relevant means document relevant 
model called binary independence assumption assuming relevance attributes statistically independent 
formula rewritten formula includes values term presence resulting oc po match ing terms relevance information available model improve retrieval performance 
relevance information available model behaves vector space model idf weights ignoring length normalisation poorer tf 
idf weights :10.1.1.33.3649
trec trec developers probabilistic model tried considerable num ber new term weighting algorithms led bm bm best match term weighting algorithm algorithm includes components tf idf length normalisation 
robertson walker motivated best match algorithms probabilistic model simple approximations poisson model indicated result guided experimentation theory 
extended boolean model introduced traditional boolean model oldest 
boolean model allows operators boolean algebra query formulation major disadvantage boolean system able rank returned list documents 
numerous extensions boolean model suggested provide ranked list documents 
extensive comparison terms theoretical properties retrieval effectiveness extended boolean models conducted lee 
lee measured retrieval effectiveness boolean queries trec subcollections 
best performing extended boolean models norm model developed salton vector space model geometry fuzzy set model suggested paice 
publications extended boolean models norm model probably popular performing models 
croft turtle copied behaviour norm model inference network architecture propose belief revision operator equivalent norm case 
discussion vector space model probabilistic model stand different approaches information retrieval 
similarity query document probability relevance distribution terms relevant non relevant documents 
approaches proven valuable guiding research information retrieval 
advocates models interpret models quite loosely preferring methods perform experimentally methods strong theoretical motivation 
language modelling approach information retrieval shares interesting characteristics traditional models section 
presents strong theoretical motivation language modelling approach shows approach outperforms weighting algorithms developed traditional models 
statistical language models retrieval statistical language models information retrieval builds simple language model document collection 
query documents ranked probability language model document generated query 
simple unigram models gram models retrieval may instructive describe process generating query model physical process 
informal description urn model metaphor metaphor urn models give insight 
drawing balls random replacement urn consider process drawing words random replacement document 
suppose selects document document collection draws random time replacement words document hands words query terms system 
system educated guess document words came calculating document probability words sampled ranking documents accordingly 
intuition users reasonable idea terms occur documents interest choose query terms accordingly :10.1.1.54.6410
practice query terms occur relevant documents 
modelled slightly complicated urn model 
case person draws random words decides draw draw randomly relevant document randomly entire collection 
decision drawing relevant document assigned probability 
probability called relevance weight term defines distribution term relevant non relevant documents 
ad hoc retrieval non words query assigned relevance weight 
user feedback re estimate relevance weight query term 
model boolean queries treating sampling process query allowing draw specified disjunction term 
example probability drawing term information drawing term retrieval term filtering document calculated model introduced additional modelling assumptions 
furthermore model extended additional statistical processes model differences vocabulary query vocabulary documents 
statistical translation added process sampling terms document assuming translation term depend document sampled 
cross language retrieval english queries french document collection uses sampling metaphor follows french word sampled document word translated english probability estimated parallel corpus 
definition corresponding probability measures ideas mentioned probability measures defined rank documents query 
probability query tn length sampled document document identifier defined equation 

tn ai ti aip ti formula probability drawing term randomly collection probability drawing term randomly document ai relevance weight term 
query term assigned relevance weight ai term treated exact matching system assign zero probability documents term occur 
query term assigned relevance weight term treated word term influence final ranking 
section shown probability measure rewritten tf 
idf term weighting algorithm 
miller leek schwartz showed equation interpreted state hidden markov model define state transition probabilities tid define emission probabilities 
evaluation boolean queries straightforward 
urn model metaphor draw different terms mutually exclusive 
term drawn document probability drawing term information term retrieval 
axioms probability theory see mood probability disjunction terms draw sum probabilities drawing single terms 
line reasoning introduced model possible translations alignments document terms query terms :10.1.1.43.7803
disjunction possible translations tij term position defined follows 
ti ti 
ai tij aip line reasoning queries interpreted just unstructured queries defined equation 
put differently unstructured queries implicitly assumed queries 
relevance weight hi assigned query term system behave traditional boolean model information retrieval assigning zero probability documents exactly match boolean query 
statistical translation added probability measures assuming translation term depend document occurs 
nn english query length english term position mi possible french translations tij equation ml ndd ii ai alp berger lafferty statistical translation model information retrieval differs equa tion global information ni global information tij :10.1.1.43.7803:10.1.1.43.7803:10.1.1.43.7803
parameter estimation said section practice information retrieval term frequency document frequency main components term weighting algorithms 
term frequency tf defined number times term occurs document document frequency dr defined number documents term occurs 
estimation tid equation done follows 
ti ti tf df ti ti ti af viewpoint language models retrieval viewpoint urn model metaphor equation obvious method estimation 
argue equation violates axioms probability theory ti ti ti ti ti ti occur documents 
equation preferred method estimation collection frequency cf defined number times term occurs entire collection 
ci ti ed ti ti ti ti ci ed ti method :10.1.1.43.7803:10.1.1.43.7803:10.1.1.54.6410
historic reasons tries relate language modelling approach traditional approaches remainder method 
equation language modelling approach information retrieval gives strong theoretical backup tf 
idf term weighting algorithms backup provided traditional retrieval models 
prior probability document relevant assumed uniformly distributed case formulas suffice 
alternatively assumed prior probability document relevant proportional length document equation 
ea tf included final ranking algorithm adding logarithm equation document scores final step see section table 
relevance weighting information relevant documents available relevance weights ai constant non word query 
optimum value constant change different applications 
high relevance weights result rankings obey conditions ordination level ranking documents containing query terms ranked documents containing query terms 
high relevance weights choice applications aim high precision applications short queries web search engines 
low relevance weights choice applications aim high precision recall points applications relatively long queries instance trec evaluations 
trec experiments described section value ai 
documents judged relevant user re estimate relevance weights separately 
notice simply proportions relevant non relevant documents contain query term directly estimate new relevance weight done probabilistic model 
searching best relevance weights term frequencies terms relevant documents taken account 
possible approach relevance weighting em algorithm expectation maximisation algorithm 
step step relevance weighting query terms em algorithm algorithm iteratively maximises probability query 
tn relevant documents dr iteration process starts relevance weights initialised default values position query 
iteration estimates new relevance weight doing step step value relevance weight change significantly anymore 
probability measure term weighting algorithm similar probabilistic model probability measures ranking documents rewritten format easy implement 
presence weighting scheme opposed presence absence weighting scheme assigns zero weight terms document 
presence weighting schemes implemented vector product formula 
section presents resulting algorithms 
relation tf 
idf relevance weighting look basic probability measure introduced equation tid ii hi dividing formula ii hi ti affect ranking hi ti value document 
doing results document ranking function somewhat similar ng likelihood ratio formula 
tn ii monotonic transformation document ranking function produce ranking documents 
product weights formula implemented sum logarithmic weights 
doing replacing ti ti estimates defined equation results log ti dr hi df ti tf resulting formula interpreted tf 
weighting algorithm document length normalisation formula interpreted odds probability relevance di traditional probabilistic model follows tf ti tf 
idf weight term ti document inverse length document tf odds probability relevance query term position hi tdf constant document term query weights vector product formula account multiple occurrences term query 
resulting vector product version ranking formula displayed 
vector product formula query term weight document term weight score wq match ing terms wq tf wa log tf 
weighting algorithm discussion purpose show language modelling approach information retrieval flexible model implement approaches information retrieval 
reason differs considerably publications compare retrieval models frame 
claim language modelling approach may result tf 
idf term weighting ty component component fall logarithm making ty algorithm tf algorithm 
shown section prefer collection frequencies document frequencies making algorithm 
may similar objections comparison language modelling approach probabilistic model 
occurrence probability odds directly related distribution terms relevant non relevant documents related measure point probabilistic model directly estimated model binary independence assumption shown section 
despite differences think similarity language model information retrieval traditional models important gives insight tfidf term weighting works combination relevance weighting done bm algorithm works 
boolean queries section suggested calculation probability possible translations model boolean queries :10.1.1.43.7803
disjunction possible translations tij source language query term position defined equation follows 
ti til ti ti ti tim df tij tf addition associative commutative calculate probability separately adding 
respectively document frequencies term frequencies disjuncts added resulting formula similar original line interpolation glob local probabilities equation 
added frequencies replace df tf weighting formula 
ti ti ti ti ti tim ai df tij tf tij tf similar algorithm introduced hm line stemming 
hm algorithm boolean grouping 
collection frequencies document frequencies method nice line generation treating morphological variants disjuncts produce exactly results line stemming documents 
query tables boolean query left hd side equation index stemmed query right hd side index stemmed porter stemmer 
extended boolean models mentioned section produce sine results queries 
funny table tables tabled assumed boolean queries ways conjunctive norm form 
true queries generated module morphological component generally formulated boolean queries 
language modelling approach boolean models mentioned section distributive laws hold conventional boolean expressions valid 
instance equivalent traditional boolean model generally case language models extended boolean models 
language model questionable query valid query refers drawing terms document contradicts refers drawing term document 
experiments section manually formulated boolean queries converted automatically conjunctive normal form 
complex boolean expressions contradict number draws instance disjunction word phrases funny tables amusing chairs converted conjunctive normal form 
queries deserve additional attention evaluations 
experimental results section results experiments 
experiments done trec collection 
experiment serves illustrate language model retrieval performs situations call respectively similarity query documents probability relevance estimation relevant documents ability process boolean structured queries 
mirror dbms experiments done mirror dbms prototype database management system es designed multimedia web retrieval 
mirror dbms combines content management data management single system 
main advantage integration facility combine information retrieval traditional data retrieval 
furthermore information retrieval researchers experiment easily new retrieval models combining various sources information 
important benefit advanced information retrieval research web retrieval speech retrieval cross language retrieval 
require representations content hard handle traditional file approach slow traditional database systems 
documents queries preprocessed follows 
tokenisation done assuming non letters including hyphens word boundaries 
words appearing smart list removed including specific trec domain document relevant 
remaining words stemmed porter stemmer 
reported experiments index 
language model runs non uniform prior probability relevance equation correct different document lengths 
results ad hoc task experiment trec style automatic ad hoc experiment trec topics 
serves illustrate language modelling approach performs task relevance information available system rely similarity query documents 
experiment compares average precision different term weighting algorithms 
salton buckley call original tf 
idf cosine normalisation 
second probabilistic model introduced robertson sparck jones 
lnu ltu bm described respectively :10.1.1.33.3649:10.1.1.50.9950
lnu ltu slope parameter set 
bm tuning parameters set kl ks experiment shows original probabilistic model original vector space model task 
bm lnu ltu algorithms perform better considerably worse compared language model 
ftp ftp cs cornell edu pub smart run precision recall average precision probabilistic lnu ltu bm lm table results ad hoc queries results relevance weighting second experiment takes relevant documents topic estimate relevance weights retrospectively determine optimal performance collection 
experiment done robertson sparck jones cranfield collection traditional probabilistic model 
purpose experiment fold 
firstly experiment shows language model relevance weighting method performs compared relevance weighting traditional probabilistic model bm formula 
secondly comparing performance experiments previous section experiments show gained system perfect knowledge distribution terms relevant non relevant documents 
run precision recall average precision probabilistic bm lm table results retrospective relevance weighting experiment shows language model increase performance increase performance traditional probabilistic model better performance increase bm algorithm 
closer inspection runs shows methods decrease average precision respectively queries 
alarming relevance feedback method decrease performance weights retrospectively 
language model clue relevance weighting algorithm suboptimal 
said section algorithm optimises probability query generated relevant documents 
optimal algorithm optimise probability relevance query 
research relevance feedback algorithms language modelling approach information retrieval needed 
results boolean retrieval third experiment uses manually formulated boolean queries 
experiment boolean queries formulated trec topics 
wild cards multi term expressions replaced boolean equivalents connector wild cards connector multi term expressions 
experiment tries answer questions 
experiment shows language model performs compared norm model 
experiments reported salton binary query weights tf 
idf document weights norm experiments 
experiments done weights ltu weights documents 
secondly measures additional benefit extended boolean models versions model boolean operators 
norm model reduced vector model assigning value parameters 
higher value say show improved results 
language model similar knob 
experiment lm vector done throwing away boolean operators just leaving terms 
boolean operators lm boolean show improved results compared 
run precision recall average precision norm norm norm norm lm vector lm boolean table results boolean queries experiment shows gained special treatment boolean operators 
special treatment boolean operators absolute impact norm model language model gain mean average precision 
term weighting bigger impact retrieval performance 
automatic ad hoc experiments language model outperforms ltu weights turn outperform traditional weights 
document vs collection frequencies experiments described equation alternative equation 
section gives results experiments equation 
run precision recall average precision lm adhoc lm rel 
weights lm vector lm boolean table results equation comparison results table language model results table indicates collection frequencies equation document frequencies equation tendency perform little bit worse runs nearly bad generally assumed see 
new language models information retrieval compared traditional models information retrieval vector space model probabilistic model boolean model 
showed language modelling approach shares interesting characteristics vector space model probabilistic model respectively gives elegant justification tf 
idf weights powerful new method relevance weighting query terms 
showed language modelling approach suggests new method extended boolean retrieval 
experiments trec collection indicate language modelling approach outperforms traditional methods 
side effect language models retrieval introduced new ways thinking popular information retrieval tools words stemmer 
hard talk stopping stemming terms traditional models 
fact words removed remaining words documents queries stemmed really suggested motivated traditional models 
language modelling approach terms assigned zero relevance weight 
terms affect final ranking suggests removed done words traditional models 
stemming language modelling approach evaluate boolean queries generated user request grouping morphological variations word boolean operator 
shown section boolean implemented simply adding respectively term frequencies collection frequencies disjuncts 
line morphological generation produce exactly results line stemming giving stemmer theoretical sound interpretation language modelling approach 
language modelling approach clearly outperforms traditional probabilistic model nice theoretical properties 
models relevance explicitly tries relate relevance weighting probability ranking principle 
research point possible relate relevance weighting algorithm language model directly probability ranking principle hopefully give formal proof algorithm expected improve performance 
reported funded part dutch telematics institute project 
fs consulting making boolean queries available trec participants 
berger lafferty 
information retrieval statistical translation 
proceedings nd acm sigir conference research development information retrieval sigir pages 
berger lafferty 
weaver system document retrieval 
proceedings eighth text retrieval conference trec 
nist special publications appear 
church gale 
inverse document frequency measure deviations poisson 
armstrong 
eds nlp large corpora kluwer academic publishers 
church mercer 
special issue computational linguistics large corpora 
computational linguistics 
dempster laird rubin 
maximum likelihood incomplete data em algorithm plus discussions 
journal royal statistical society 
croft turtle 
computationally tractable probabilistic modelling boolean operators 
proceedings th cm sigir conference research development information retrieval sigir pages 
harman 
effective 
journal american society information science 
hiemstra 
linguistically motivated probabilistic model information retrieval 
proceedings second european conference research advanced technology digital libraries ecdl pages 
hiemstra 
probabilistic justification tf 
idf term weighting information re trieval 
international journal digital libraries appear 
hiemstra de jong 
disambiguation strategies cross language informa tion retrieval 
proceedings third european conference research advanced technology digital libraries ecdl pages 
hiemstra kraaij 
trec ad hoc cross language track 
proceedings seventh text retrieval conference trec pages 
nist special publication 
kraaij hiemstra 
trec language gie information retrieval 
proceedings eighth text retrieval conference trec 
nist special publications appear 
lee 
analyzing effectiveness extended boolean models information retrieval 
technical report tr cornell university 
cs tr cs cornell edu 

belief revision operator document ranking extended boolean models 
proceedings nd cm sigir conference research development information retrieval sigir pages 
miller leek schwartz 
bbn trec hidden markov models information retrieval 
proceedings seventh text retrieval conference trec pages 
nist special publication 
miller leek schwartz 
hidden markov model information retrieval system 
proceedings nd acm sigir conference research development information retrieval sigir pages 
mood editors 
theory statistics second edition 
mcgraw hill 
ng 
maximum likelihood ratio information retrieval model 
proceedings eighth text retrieval conference trec 
nist special publications appear 
paice 
soft evaluation boolean search queries information retrieval systems 
information technology research development ponte croft :10.1.1.54.6410
language modelling approach information retrieval 
proceedings st cm sigir conference research development information retrieval sigir 
porter 
algorithm suffix stripping 
program 
robertson 
probability ranking principle ir 
journal documentation 
robertson sparck jones 
relevance weighting search terms 
journal american society information science 
robertson walker 
simple effective approximations poisson model probabilistic weighted retrieval 
proceedings th acm sigir conference research development information retrieval sigir pages 
robertson walker beaulieu :10.1.1.33.3649
okapi trec automatic ad hoc filtering vlc interactive 
proceedings seventh text retrieval conference trec pages 
nist special publication 
salton buckley 
term weighting approaches automatic text retrieval 
information processing management 
salton fox wu 
extended boolean information retrieval 
communications acm 
salton mcgill editors 
modern information retrieval 
mcgraw hill 

document retrieval mps information server report trec experiment 
proceedings th text retrieval conference trec pages 
nist special publication 
singhal buckley mitra :10.1.1.50.9950
pivoted document length normalization 
proceedings th acm sigir conference research development information retrieval sigir pages 
song croft 
general language model information retrieval 
proceedings eighth international conference information knowledge management cikm 
turtle croft 
comparison text retrieval models 
computer journal 
de vries 
content multimedia database management systems 
phd thesis centre telematics information technology university twente 
de vries hiemstra 
mirror dbms trec 
proceedings eighth text retrieval conference trec 
nist special publications appear 
wong yao 
modelling information retrieval probabilistic inference 
cm transactions information systems 

