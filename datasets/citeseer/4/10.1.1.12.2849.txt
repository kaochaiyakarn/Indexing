replication strategies highly available peer peer storage bhagwan david moore stefan savage geoffrey voelker investigating strategies replication design implement highly reliable peer peer systems 
particular comparing object blocking replication pursuing erasure codes blocking replication novel technique achieving high reliability systems primarily composed hosts poor availability 
briefly different replication strategies exploring strategies influenced application characteristics host availability preliminary simulation results 
past years peer peer networks extremely popular mechanism large scale content sharing 
traditional client server applications centralize management data highly reliable servers peer topeer systems distribute burden data storage computation communications administration thousands individual client workstations 
popularity approach exemplified systems napster gnutella driven popularity unrestricted music distribution newer expanded potential application base generalized distributed file systems persistent anonymous publishing wide area databases support high quality video distribution :10.1.1.20.417:10.1.1.159.9358:10.1.1.125.3017:10.1.1.115.4299
wide spread attraction peer peer model arises primarily potential low cost scalability enhanced availability 
ideally peer topeer system efficiently multiplex resources connectivity workstations users time protecting users transient persistent failures subset components 
goals trivially engineered 
peer peer systems gnutella scaled poorly due overhead locating content network 
consequently developing efficient lookup algorithms consumed academic area :10.1.1.111.1818:10.1.1.140.3129:10.1.1.142.752:10.1.1.105.3673
challenges providing high availability systems poorly understood studied 
particular traditional distributed systems individual components peer peer system experience order magnitude worse availability individually administered workstations may turned join leave system intermittent connectivity constructed low cost low reliability components 
study popular peer peer file sharing system majority peers application level availability rates percent :10.1.1.160.7346:10.1.1.160.7346
result peer peer systems employ form replication provide acceptable service users 
systems napster gnutella replication occurs implicitly file downloaded user implicitly replicated user workstation 
systems explicitly manage replication mask failures availability object fundamentally linked popularity users repeat department computer science engineering university california san diego access different replicas find available host 
generation peer peer storage systems cooperative file system cfs recognize need mask failures user implement basic replication strategy independent user workload :10.1.1.159.9358
best replicate data build highly available peer peer systems open problem 
exploring replication strategy design tradeoffs interdependent axes application characteristics 
demands storage system utility associated making piece data available depend application 
small file applications common workloads significantly different availability requirements large file streaming media workloads 
replica placement 
existing systems cfs assume failures independent uniformly distributed understood 
placement replicas measured estimated failure distributions significant impact application availability 
replication granularity 
file replication allows simple low overhead implementations naming lookup block level replication allows increased performance parallel downloads better balancing large file objects 
block level erasure coding enhance availability providing flexibility block level replication surprisingly minimal state requirements file designs 
whitepaper briefly different replication strategies exploring strategies influenced application characteristics host failure distributions preliminary simulation results 
application characteristics peer peer systems wide range applications including music video sharing wide area file systems archival file systems software distribution 
key properties peer peer applications impact replication object sizes timeliness object download 
larger objects take longer replicate cumbersome manage naturally motivate block level replication 
conventional blocking large objects reliability system depends increasingly large number hosts available time 
result availability object inversely related size larger object worse availability 
second relationship data requested time delivered 
example traditional unix file system applications usually require entire file object delivered application buffer cache application forward progress 
order data delivered variations delay rarely significant impact 
contrast streaming media workloads typically require data surrounding current playout point available particular data delivered timely fashion application operate correctly 
replica placement purposes reliability peer peer systems ignore availability characteristics underlying workstations networks implemented 
particular systems recognize wide variability availability hosts system 
saroiu gribble fewer percent gnutella peer systems network level availability excess percent half remainder availability percent :10.1.1.160.7346:10.1.1.160.7346
wide variability system place replicas blindly replicas required placing hosts low availability fewer highly available hosts 
predictable circumstances peer failures may correlated 
example independent investigations client workstation availability shown strong time zone specific diurnal patterns associated patterns 
consequence placing replicas phase time zones may sound replication strategy 
replica granularity gnutella napster employ file replication files replicated hosts system nodes download files 
file replication simple implement low state cost maintain state proportional number replicas 
cost replicating entire files operation cumbersome space time particularly systems support applications large objects audio video software distribution 
block level replication divides file object ordered sequence fixed size blocks 
approach benefits 
individual parts object may named independently block level system may download different parts object simultaneously different peers reduce download time 
unit replication small fixed cost replicate individual block small distributed peers 
block level representation allows large files spread peers file larger single peer able store 
tradeoffs 
order locate individual blocks block level system maintain state proportional product number replicas number blocks object 
seriously downloading object requires hosts storing block replicas available reconstruct entire object time object requested 
replicated block unavailable object unavailable 
example measurements cfs system block level replicas show percent replicas fail probability block unavailable percent :10.1.1.159.9358
object consists blocks expected availability entire object percent 
dependency motivating factors erasure codes blocking replication 
erasure codes ec reed solomon tornado codes provide property set original blocks reliability host failure probability blocks file conventional ec reliability function number blocks file host failure probability :10.1.1.21.9363
reconstructed coded blocks taken set kn typically close andk typically small constant 
addition ec block level replication provides advantages 
dramatically improve availability increased intra object redundancy tolerate loss individual blocks compromising availability file 
example storage requirements duplicate blocks object code blocks ec blocks 
blocks distributed nodes standard block replication hosts block available reconstruct object 
ec block replication hosts storing ec replicas need available reconstruct object 
second ability reconstruct object distinct subsets ec blocks permits low overhead randomized lookup implementation competitive state file replication 
maintain location replica block system ec blocks simply track location peer holding block belonging object 
client desires object simply request random blocks data returned reconstruct object 
approach surprisingly efficient 
object consisting ec blocks expected number blocks downloaded random fashion nlogn penalty logn unnecessary blocks downloaded 
replication host failure initial experiment explore tradeoff conventional block replication block replication erasure codes simulate replication distribution single file idealized system hosts 
file divided fixed size blocks replicated 
replicated blocks randomly assigned hosts uniform failure probability 
simulate random host failure determine file recoverable system assuming ideal lookup system perfect network conditions 
file recoverable failures blocks survive reconstruct original contents 
repeat experiment times measure fraction times file completely recoverable 
purposes experiment define fraction reliability system 
term storage redundancy refer amount storage replication technique uses 
storage redundancy blocking techniques different amounts storage replicate file 
conventional case storage redundancy simply number replicas file 
erasure coded case redundancy introduced replication encoding process 
case storage redundancy number replicas times encoding redundancy 
comparing strategies storage redundancy fair comparing number replicas 
shows simulation results idealized system function storage redundancy host failure probability 
redundancy introduced conventional case replication 
storage redundancy conventional case simply number replicas system 
hand erasure coded case redundancy introduced replication file encoding 
file consisting blocks encoded ek blocks call encoding redundancy stretch factor :10.1.1.21.9363:10.1.1.21.9363
take account sources redundancy storage redundancy erasure coded scenario product number replicas encoding redundancy 
simulations 
see host failure probabilities replication schemes achieve high reliability 
higher host failure probabilities reliabilities techniques diverge magnitude divergence depends number blocks file 
away block size case block file corresponds file replication 
note conventional curve case best reliability compared blocks file 
multiple blocks file number blocks file roughly corresponds size file assume constant block size 
small number blocks file small files techniques quickly diverge reliability 
erasure coded blocks increases reliability system flexibility choosing hosts reconstruct file 
conventional block replication decreases reliability sensitive high host failure probability 
peer topeer file systems average file size small average number blocks file small effect severe high host failure probabilities 
peerto peer systems serve large files music video conventional block replication poor reliability host failure probabilities close 
implication results conventional blocking scattering blocks large number relatively unreliable hosts system reliable 
decoupling exactly blocks required reconstruct file hosts storing replicas blocks erasure coded replication able achieve excellent reliability underlying hosts quite unreliable 
reliability erasure coding increases decreases larger files 
summary investigating strategies replication design implement highly reliable peer peer systems 
particular comparing object blocking replication pursuing erasure codes blocking replication novel technique achieving high reliability systems primarily composed hosts poor availability 
ad dition investigating application properties object size timeliness delivery workload properties object popularity network properties host availability influence replication strategies 
initial experiments indicate erasure codes blocking replication promising exploring 
eventually plan implement results prototype system practical evaluation 
bolosky douceur ely theimer :10.1.1.159.9358
feasibility serverless distributed file system deployed existing set desktop pcs 
measurement modeling computer systems pages 
byers luby mitzenmacher :10.1.1.21.9363
digital fountain approach reliable distribution bulk data 
proceedings acm sigcomm pages 
dabek kaashoek karger morris stoica :10.1.1.159.9358
widearea cooperative storage cfs 
proceedings th acm symposium operating system principles sosp 
dingledine freedman molnar 
free haven project distributed anonymous storage service 
workshop design issues anonymity unobservability pages 
edonkey homepage edonkey com 
gnutella homepage gnutella wego com 
gribble halevy ives suciu 
databases peer peer 
proceedings fourth international workshop web databases webdb june 
kubiatowicz bindel chen eaton geels gummadi rhea weatherspoon weimer wells zhao :10.1.1.160.7346
oceanstore architecture global scale persistent storage 
proceedings acm asplos 
marc waldman cranor 
publius robust tamper evident censorship resistant web publishing system 
proc 
th usenix security symposium pages august 
moore 
caida analysis code red 
napster homepage www napster com 

theory error correcting codes 
john wiley sons rd edition 
ratnasamy francis handley karp shenker 
scalable content addressable network 
proceedings acm sigcomm 
rowstron druschel 
pastry scalable decentralized object location routing large scale peer peer systems 
middleware pages 
saroiu gummadi gribble :10.1.1.160.7346
measurement study peer peer file sharing systems 
mmcn 
stoica morris karger kaashoek balakrishnan 
chord scalable peer peer lookup service internet applications 
proceedings acm sigcomm 
zhao kubiatowicz joseph 
tapestry infrastructure fault tolerant wide area location routing 
technical report ucb csd berkeley april 
